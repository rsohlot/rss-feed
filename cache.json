{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": [
        {
          "id": "https://mlinproduction.com/?p=936",
          "author": "Luigi",
          "description": "In my previous post, I briefly described how leading companies use experimentation to optimize their products and services and evolve them to the point of feeling elegant, efficient, and magical. These companies have developed mature experimentation programs (ExPrs), including the… Read More \nThe post What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02) appeared first on ML in Production.",
          "link": "https://mlinproduction.com/experimentation-program-stakeholders/?utm_source=rss&utm_medium=rss&utm_campaign=experimentation-program-stakeholders",
          "publishedOn": "2022-04-02T14:03:58.000Z",
          "wordCount": 1691,
          "title": "What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=13479",
          "author": "MLM Team",
          "description": "Sponsored Post Unlike traditional online courses, Foster Provost’s workshops will give you the chance to engage live with a world-class […]\nThe post 10 seats remaining | A series of live ML strategy workshops appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/10-seats-remaining-a-series-of-live-ml-strategy-workshops/",
          "publishedOn": "2022-04-19T17:56:48.000Z",
          "wordCount": 493,
          "title": "10 seats remaining | A series of live ML strategy workshops",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/image1.png"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13478",
          "author": "MLM Team",
          "description": "Sponsored Post By Luis Bermudez This blog walks through a process for experimenting with hyperparameters, training algorithms and other parameters […]\nThe post Guide to Iteratively Tuning GNNs appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/guide-to-iteratively-tuning-gnns/",
          "publishedOn": "2022-04-18T17:14:51.000Z",
          "wordCount": 1907,
          "title": "Guide to Iteratively Tuning GNNs",
          "imageUrl": "https://www.kdnuggets.com/wp-content/uploads/sigopt_guide_tuning_gnn_8.png"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13410",
          "author": "Zhe Ming Chng",
          "description": "Big data, labeled data, noisy data. Machine learning projects all need to look at data. Data is a critical aspect […]\nThe post Managing Data for Machine Learning Project appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/managing-data-for-machine-learning-project/",
          "publishedOn": "2022-04-18T13:00:12.000Z",
          "wordCount": 8936,
          "title": "Managing Data for Machine Learning Project",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/25260822078_88802ea8fa_h.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13468",
          "author": "Adrian Tam",
          "description": "In the old days, it was a tedious job to collect data, and sometimes very expensive. Machine learning projects cannot […]\nThe post Web Crawling in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/web-crawling-in-python/",
          "publishedOn": "2022-04-15T18:05:18.000Z",
          "wordCount": 3625,
          "title": "Web Crawling in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-ray-bilcliff-4805619-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13457",
          "author": "Adrian Tam",
          "description": "When we talk about managing data, it is quite inevitable to see data presented in tables. With column header, and […]\nThe post Massaging Data using Pandas appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/massaging-data-using-pandas/",
          "publishedOn": "2022-04-13T14:00:08.000Z",
          "wordCount": 7442,
          "title": "Massaging Data using Pandas",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-mark-de-jong-6939449-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13454",
          "author": "MLM Team",
          "description": "By Vincent Granville, Ph.D., Author at MLtechniques.com Sponsored Post Very deep neural networks (VDNN) illustrated with data animation: a 40 second […]\nThe post Very Deep Neural Networks Explained in 40 Seconds appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/very-deep-neural-networks-explained-in-40-seconds/",
          "publishedOn": "2022-04-12T16:37:13.000Z",
          "wordCount": 1213,
          "title": "Very Deep Neural Networks Explained in 40 Seconds",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/dnn.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13442",
          "author": "Adrian Tam",
          "description": "Python is a general-purpose computation language, but it is very welcomed in scientific computing. It can replace R and Matlab […]\nThe post Scientific Functions in NumPy and SciPy appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/scientific-functions-in-numpy-and-scipy/",
          "publishedOn": "2022-04-12T02:24:11.000Z",
          "wordCount": 3561,
          "title": "Scientific Functions in NumPy and SciPy",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/04/pexels-nothing-ahead-4494641-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13440",
          "author": "Mitch Bartlett",
          "description": "Sponsored Post Join the UK’s most forward-thinking technologists and business professionals this June in a celebration of emerging technology. Machine […]\nThe post Win tickets to The AI Summit London 2022 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/win-tickets-to-the-ai-summit-london-2022/",
          "publishedOn": "2022-04-05T21:04:02.000Z",
          "wordCount": 489,
          "title": "Win tickets to The AI Summit London 2022",
          "imageUrl": "https://www.kdnuggets.com/wp-content/uploads/informa-ai-summit-lopndon-header-mlm-20220405.png"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13385",
          "author": "Daniel Chung",
          "description": "Logging is a way to store information about your script and track events that occur. When writing any complex script […]\nThe post Logging in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/logging-in-python/",
          "publishedOn": "2022-04-04T20:00:58.000Z",
          "wordCount": 6639,
          "title": "Logging in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/pexels-ilaria-122588-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13344",
          "author": "Zhe Ming Chng",
          "description": "When working on code, whether we know it or not, we often come across the decorator design pattern. This is […]\nThe post A Gentle Introduction to Decorators in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/a-gentle-introduction-to-decorators-in-python/",
          "publishedOn": "2022-04-01T23:00:40.000Z",
          "wordCount": 3926,
          "title": "A Gentle Introduction to Decorators in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/pexels-olya-kobruseva-6560995-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13373",
          "author": "Adrian Tam",
          "description": "Compared to other programming exercises, a machine learning project is a blend of code and data. You need both to […]\nThe post A Guide to Getting Datasets for Machine Learning in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/a-guide-to-getting-datasets-for-machine-learning-in-python/",
          "publishedOn": "2022-03-31T01:00:09.000Z",
          "wordCount": 3526,
          "title": "A Guide to Getting Datasets for Machine Learning in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/pexels-olha-ruskykh-7166023-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13400",
          "author": "Mitch Bartlett",
          "description": "Sponsored Post Building successful machine learning products requires mastering ML Strategy, including problem formulation, evaluation, and tactics for dealing with […]\nThe post Interactive ML Strategy course with Foster Provost starting April 7 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/interactive-ml-strategy-course-with-foster-provost-starting-april-7/",
          "publishedOn": "2022-03-29T19:41:10.000Z",
          "wordCount": 500,
          "title": "Interactive ML Strategy course with Foster Provost starting April 7",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/Scholarsite.webp"
        },
        {
          "id": "https://machinelearningmastery.com/?p=13355",
          "author": "Mehreen Saeed",
          "description": "Datasets from real-world scenarios are important for building and testing machine learning models. You may just want to have some […]\nThe post A Guide to Obtaining Time Series Datasets in Python appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/a-guide-to-obtaining-time-series-datasets-in-python/",
          "publishedOn": "2022-03-29T02:07:33.000Z",
          "wordCount": 4266,
          "title": "A Guide to Obtaining Time Series Datasets in Python",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/03/IMG_0628-scaled.jpg"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": "https://eng.uber.com",
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "c1051aee6c3bb071b4069fd2ddca91a6b4c288d9",
          "author": "Dan Ferguson",
          "description": "AWS CodeArtifact allows developers to connect internal code repositories to upstream code repositories like Pypi, Maven, or NPM. AWS CodeArtifact is a powerful addition to CI/CD workflows on AWS, but it is similarly effective for code-bases hosted on a Jupyter notebook. This is a common development paradigm for Machine Learning developers that build and train […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/secure-aws-codeartifact-access-for-isolated-amazon-sagemaker-notebook-instances/",
          "publishedOn": "2022-04-22T16:56:29.000Z",
          "wordCount": 2726,
          "title": "Secure AWS CodeArtifact access for isolated Amazon SageMaker notebook instances",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/19/ML-4423-image001-whitebackground.png"
        },
        {
          "id": "21a3046ba8f883173c962ba36d5d48c49efd00e8",
          "author": "Uday Narayanan",
          "description": "Amazon Textract is a machine learning (ML) service that automatically extracts text, handwriting, and data from any document or image. Amazon Textract now offers the flexibility to specify the data you need to extract from documents using the new Queries feature within the Analyze Document API. You don’t need to know the structure of the […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/specify-and-extract-information-from-documents-using-the-new-queries-feature-in-amazon-textract/",
          "publishedOn": "2022-04-21T17:32:12.000Z",
          "wordCount": 3204,
          "title": "Specify and extract information from documents using the new Queries feature in Amazon Textract",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/21/specify-extract-textract.jpg"
        },
        {
          "id": "4d89b7000b553a0ed3675113cd8b7856b5e91b3b",
          "author": "Ashish Lagwankar",
          "description": "Organizations use collaborative document authoring solutions like Salesforce Quip to embed real-time, collaborative documents inside Salesforce records. Quip is Salesforce’s productivity platform that transforms the way enterprises work together, delivering modern collaboration securely and simply across any device. A Quip repository captures invaluable organizational knowledge in the form of collaborative documents and workflows. However, finding […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/search-for-knowledge-in-quip-documents-with-intelligent-search-using-the-quip-connector-for-amazon-kendra/",
          "publishedOn": "2022-04-20T01:50:58.000Z",
          "wordCount": 1816,
          "title": "Search for knowledge in Quip documents with intelligent search using the Quip connector for Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/19/ML-8536-image001.jpg"
        },
        {
          "id": "c724effc75362e3687819604539d3a515b9ddb13",
          "author": "Chanki Nathani",
          "description": "Conversational interfaces (or chatbots) can provide an intuitive interface for processes such as creating and monitoring tickets. Let’s consider a situation in which a recent hire on your team is required to cut tickets for office equipment. To do so, they have to interact with a ticketing software that the organization uses. This often requires […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/integrate-servicenow-with-amazon-lex-chatbot-for-ticket-processing/",
          "publishedOn": "2022-04-19T16:55:07.000Z",
          "wordCount": 3130,
          "title": "Integrate ServiceNow with Amazon Lex chatbot for ticket processing",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/15/ML-3932-image001-new2.png"
        },
        {
          "id": "f9202ebc8ef6c1f2afaaf179eacafa3188aae5db",
          "author": "Ying Hou",
          "description": "Automatic speech recognition (ASR) is a commonly used machine learning (ML) technology in our daily lives and business scenarios. Applications such as voice-controlled assistants like Alexa and Siri, and voice-to-text applications like automatic subtitling for videos and transcribing meetings, are all powered by this technology. These applications take audio clips as input and convert speech […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/fine-tune-and-deploy-a-wav2vec2-model-for-speech-recognition-with-hugging-face-and-amazon-sagemaker/",
          "publishedOn": "2022-04-15T19:53:54.000Z",
          "wordCount": 3163,
          "title": "Fine-tune and deploy a Wav2Vec2 model for speech recognition with Hugging Face and Amazon SageMaker",
          "enclosure": {
            "length": "136188",
            "type": "audio/wav",
            "url": "https://datashare.ed.ac.uk/bitstream/handle/10283/343/MKH800_19_0001.wav"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/13/ML-7125-image003-1260x261.png"
        },
        {
          "id": "e2fb9c1df3de2070a33e6590c79d6fb66231bf6e",
          "author": "Dipkumar Mehta",
          "description": "Banking and financial institutions review thousands of credit applications per week. The credit approval process requires financial organizations to invest time and resources in reviewing documents like W2s, bank statements, and utility bills. The overall experience can be costly for the organization. At the same time, organizations have to consider borrowers, who are waiting for […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-virtual-credit-approval-agent-with-amazon-lex-amazon-textract-and-amazon-connect/",
          "publishedOn": "2022-04-15T17:48:03.000Z",
          "wordCount": 2542,
          "title": "Build a virtual credit approval agent with Amazon Lex, Amazon Textract, and Amazon Connect",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/15/ML-7548-image013.jpg"
        },
        {
          "id": "681eb7cd028c64101dbdc23c7af7af61a3cc8aa9",
          "author": "Arnaud Lauer",
          "description": "You can establish feature stores to provide a central repository for machine learning (ML) features that can be shared with data science teams across your organization for training, batch scoring, and real-time inference. Data science teams can reuse features stored in the central repository, avoiding the need to reengineer feature pipelines for different projects and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/control-access-to-amazon-sagemaker-feature-store-offline-using-aws-lake-formation/",
          "publishedOn": "2022-04-13T18:54:26.000Z",
          "wordCount": 2871,
          "title": "Control access to Amazon SageMaker Feature Store offline using AWS Lake Formation",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/12/ML-8495-image001.png"
        },
        {
          "id": "06e1c05fec26be8f89c634c5de937fdd773f426a",
          "author": "Brian Yost",
          "description": "Amazon Lex can add powerful automation to contact center solutions, so you can enable self-service via interactive voice response (IVR) interactions or route calls to the appropriate agent based on caller input. These capabilities can increase customer satisfaction by streamlining the user experience, and improve containment rates in the contact center. In both the self-service […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/manage-dialog-to-elicit-amazon-lex-slots-in-amazon-connect-contact-flows/",
          "publishedOn": "2022-04-13T15:09:58.000Z",
          "wordCount": 1918,
          "title": "Manage dialog to elicit Amazon Lex slots in Amazon Connect contact flows",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/06/ML-8879-image001-whitebackground-1139x630.png"
        },
        {
          "id": "0d01c636ffdbb651bb76c8c2f8ff1eb0118a73b1",
          "author": "Joshua Levy",
          "description": "In many industries, it’s critical to extract custom entities from documents in a timely manner. This can be challenging. Insurance claims, for example, often contain dozens of important attributes (such as dates, names, locations, and reports) sprinkled across lengthy and dense documents. Manually scanning and extracting such information can be error-prone and time-consuming. Rule-based software […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-custom-entity-recognizer-for-pdf-documents-using-amazon-comprehend/",
          "publishedOn": "2022-04-08T17:32:30.000Z",
          "wordCount": 1954,
          "title": "Build a custom entity recognizer for PDF documents using Amazon Comprehend",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/25/image-46.png"
        },
        {
          "id": "c460ad7425a2142b35a23d87bcece5f7ff3037a6",
          "author": "Bob Strahan",
          "description": "Amazon Kendra is a highly accurate and easy-to-use intelligent search service powered by machine learning (ML). Amazon Kendra offers a suite of data source connectors to simplify the process of ingesting and indexing your content, wherever it resides. For many organizations, Box Content Cloud is a core part of their content storage and lifecycle management […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/getting-started-with-the-amazon-kendra-box-connector/",
          "publishedOn": "2022-04-08T16:10:06.000Z",
          "wordCount": 1853,
          "title": "Getting started with the Amazon Kendra Box connector",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "9770db1640db4792d317e78fe4a612d13b6f8025",
          "author": "Jay Rao",
          "description": "Amazon Rekognition Custom Labels is a fully managed computer vision service that allows developers to build custom models to classify and identify objects in images that are specific and unique to your business. Rekognition Custom Labels doesn’t require you to have any prior computer vision expertise. You can get started by simply uploading tens of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/receive-notifications-for-image-analysis-with-amazon-rekognition-custom-labels-and-analyze-predictions/",
          "publishedOn": "2022-04-06T16:46:32.000Z",
          "wordCount": 2176,
          "title": "Receive notifications for image analysis with Amazon Rekognition Custom Labels and analyze predictions",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/04/01/ML-3899-image031.jpg"
        },
        {
          "id": "0e8423c3b0ca2b8aa2fd2cab118be4196def0bbd",
          "author": "Peyman Razaghi",
          "description": "The built-in Amazon SageMaker XGBoost algorithm provides a managed container to run the popular XGBoost machine learning (ML) framework, with added convenience of supporting advanced training or inference features like distributed training, dataset sharding for large-scale datasets, A/B model testing, or multi-model inference endpoints. You can also extend this powerful algorithm to accommodate different requirements. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/customize-the-amazon-sagemaker-xgboost-algorithm-container/",
          "publishedOn": "2022-04-05T17:24:58.000Z",
          "wordCount": 1535,
          "title": "Customize the Amazon SageMaker XGBoost algorithm container",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/18/ML-2441-archdiag.png"
        },
        {
          "id": "b427fe772702e9e6bb92c140946b1bcd9c5c6dc0",
          "author": "Nathalie Rauschmayr",
          "description": "Research over the past few years has shown that machine learning (ML) models are vulnerable to adversarial inputs, where an adversary can craft inputs to strategically alter the model’s output (in image classification, speech recognition, or fraud detection). For example, imagine you have deployed a model that identifies your employees based on images of their […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/detect-adversarial-inputs-using-amazon-sagemaker-model-monitor-and-amazon-sagemaker-debugger/",
          "publishedOn": "2022-04-05T17:19:32.000Z",
          "wordCount": 3547,
          "title": "Detect adversarial inputs using Amazon SageMaker Model Monitor and Amazon SageMaker Debugger",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/29/ML-7609-image005.jpg"
        },
        {
          "id": "093bc4f91e188e1a2e2f385311b63204025f2c19",
          "author": "Rumi Olsen",
          "description": "As more organizations move to machine learning (ML) to drive deeper insights, two key stumbling blocks they run into are labeling and lifecycle management. Labeling is the identification of data and adding labels to provide context so an ML model can learn from it. Labels might indicate a phrase in an audio file, a car […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-mlops-sentiment-analysis-pipeline-using-amazon-sagemaker-ground-truth-and-databricks-mlflow/",
          "publishedOn": "2022-04-04T19:43:42.000Z",
          "wordCount": 2188,
          "title": "Build an MLOps sentiment analysis pipeline using Amazon SageMaker Ground Truth and Databricks MLflow",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/17/ML-5351-image002-1-657x630.png"
        },
        {
          "id": "44ec1f237a527c498cfe53252dabc3cb1f64d1ce",
          "author": "Sanjay Tiwary",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning (ML). Amazon Kendra reimagines search for your websites and applications so your employees and customers can easily find the content they’re looking for, even when it’s scattered across multiple locations and content repositories within your organization. Amazon Kendra supports a variety of document formats, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enable-amazon-kendra-search-for-a-scanned-or-image-based-text-document/",
          "publishedOn": "2022-04-04T18:07:45.000Z",
          "wordCount": 1648,
          "title": "Enable Amazon Kendra search for a scanned or image-based text document",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/25/ML-6030-image001-feature-1065x630.png"
        },
        {
          "id": "2aeebc95eb280c09dba0b3c96cc6c229198abe7f",
          "author": "Kai Loreck",
          "description": "Customer service calls require customer agents to have the customer’s account information to process the caller’s request. For example, to provide a status on an insurance claim, the support agent needs policy holder information such as the policy ID and claim number. Such information is often collected in the interactive voice response (IVR) flow at […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/interpret-caller-input-using-grammar-slot-types-in-amazon-lex/",
          "publishedOn": "2022-04-04T16:45:41.000Z",
          "wordCount": 1869,
          "title": "Interpret caller input using grammar slot types in Amazon Lex",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "9b427ae3ef63dc190c6b7ccb9890b546fe95fc05",
          "author": "Susant Mallick",
          "description": "For customers looking to implement a GxP-compliant environment on AWS for artificial intelligence (AI) and machine learning (ML) systems, we have released a new whitepaper: Machine Learning Best Practices in Healthcare and Life Sciences. This whitepaper provides an overview of security and good ML compliance practices and guidance on building GxP-regulated AI/ML systems using AWS […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/whitepaper-machine-learning-best-practices-in-healthcare-and-life-sciences/",
          "publishedOn": "2022-04-01T18:16:40.000Z",
          "wordCount": 1032,
          "title": "Whitepaper: Machine Learning Best Practices in Healthcare and Life Sciences",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/827bfc458708f0b442009c9c9836f7e4b65557fb/2020/06/03/Blog-Post_thumbnail.png"
        },
        {
          "id": "8298a7a5db1b264ac6c37c3867417c3928769e17",
          "author": "Roop Bains",
          "description": "Data science and data engineering teams spend a significant portion of their time in the data preparation phase of a machine learning (ML) lifecycle performing data selection, cleaning, and transformation steps. It’s a necessary and important step of any ML workflow in order to generate meaningful insights and predictions, because bad or low-quality data greatly […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/prepare-data-from-databricks-for-machine-learning-using-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2022-03-31T23:07:22.000Z",
          "wordCount": 2668,
          "title": "Prepare data from Databricks for machine learning using Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/24/ML-8541-image001-1232x630.png"
        },
        {
          "id": "baf199adf9d92a5962f4ec20ce81ff5fa0421b0d",
          "author": "Dwayne Browne",
          "description": "Today, customers interact with brands over an increasingly large digital and offline footprint, generating a wealth of interaction data known as behavioral data. As a result, marketers and customer experience teams must work with multiple overlapping tools to engage and target those customers across touchpoints. This increases complexity, creates multiple views of each customer, and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/personalize-cross-channel-customer-experiences-with-amazon-sagemaker-amazon-personalize-and-segment/",
          "publishedOn": "2022-03-29T17:41:54.000Z",
          "wordCount": 3000,
          "title": "Personalize cross-channel customer experiences with Amazon SageMaker, Amazon Personalize, and Twilio Segment",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/21/ML-6845-image001.jpg"
        },
        {
          "id": "e75f3ef671be2d0ce497a26f64eec80bfff4f07b",
          "author": "Dan Iancu",
          "description": "This is blog post is co-written by Theresa Cabrera Menard, an Applied Scientist/Geographic Information Systems Specialist at The Nature Conservancy (TNC) in Hawaii. In recent years, Amazon and AWS have developed a series of sustainability initiatives with the overall goal of helping preserve the natural environment. As part of these efforts, AWS Professional Services establishes […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automated-scalable-and-cost-effective-ml-on-aws-detecting-invasive-australian-tree-ferns-in-hawaiian-forests/",
          "publishedOn": "2022-03-29T16:53:41.000Z",
          "wordCount": 3408,
          "title": "Automated, scalable, and cost-effective ML on AWS: Detecting invasive Australian tree ferns in Hawaiian forests",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/15/blog_pic4.png"
        },
        {
          "id": "97aaf4a45fb3f98dbca55c0fa275d369e8dd1ccf",
          "author": "Peter Chung",
          "description": "Amazon SageMaker Autopilot helps you complete an end-to-end machine learning (ML) workflow by automating the steps of feature engineering, training, tuning, and deploying an ML model for inference. You provide SageMaker Autopilot with a tabular data set and a target attribute to predict. Then, SageMaker Autopilot automatically explores your data, trains, tunes, ranks and finds […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automatically-generate-model-evaluation-metrics-using-sagemaker-autopilot-model-quality-reports/",
          "publishedOn": "2022-03-29T16:47:55.000Z",
          "wordCount": 3055,
          "title": "Automatically generate model evaluation metrics using SageMaker Autopilot Model Quality Reports",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/03/22/confusion-matrix-638x630.png"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2110.01670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mason_E/0/1/0/all/0/1\">Eric Mason</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mhaskar_H/0/1/0/all/0/1\">Hrushikesh Mhaskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_A/0/1/0/all/0/1\">Adam Guo</a>",
          "description": "A recent paper (Neural Networks, {\\bf 132} (2020), 253-268) introduces a\nstraightforward and simple kernel based approximation for manifold learning\nthat does not require the knowledge of anything about the manifold, except for\nits dimension. In this paper, we examine how the pointwise error in\napproximation using least squares optimization based on similarly localized\nkernels depends upon the data characteristics and deteriorates as one goes away\nfrom the training data. The theory is presented with an abstract localized\nkernel, which can utilize any prior knowledge about the data being located on\nan unknown sub-manifold of a known manifold.\n\nWe demonstrate the performance of our approach using a publicly available\nmicro-Doppler data set, and investigate the use of different preprocessing\nmeasures, kernels, and manifold dimensions. Specifically, it is shown that the\nlocalized kernel introduced in the above mentioned paper when used with PCA\ncomponents leads to a near-competitive performance to deep neural networks, and\noffers significant improvements in training speed and memory requirements. To\ndemonstrate the fact that our methods are agnostic to the domain knowledge, we\nexamine the classification problem in a simple video data set.",
          "link": "http://arxiv.org/abs/2110.01670",
          "publishedOn": "2022-04-23T00:53:50.495Z",
          "wordCount": null,
          "title": "A manifold learning approach for gesture recognition from micro-Doppler radar measurements. (arXiv:2110.01670v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.10510",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ovsianas_A/0/1/0/all/0/1\">Andrius Ovsianas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fernandes_D/0/1/0/all/0/1\">David Fernandes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1\">Nikolas N&#xfc;sken</a>",
          "description": "In this work we explore a new framework for approximate Bayesian inference in\nlarge datasets based on stochastic control (i.e. Schr\\\"odinger bridges). We\nadvocate stochastic control as a finite time and low variance alternative to\npopular steady-state methods such as stochastic gradient Langevin dynamics\n(SGLD). Furthermore, we discuss and adapt the existing theoretical guarantees\nof this framework and establish connections to already existing VI routines in\nSDE-based models.",
          "link": "http://arxiv.org/abs/2111.10510",
          "publishedOn": "2022-04-23T00:53:50.493Z",
          "wordCount": null,
          "title": "Bayesian Learning via Neural Schr\\\"odinger-F\\\"ollmer Flows. (arXiv:2111.10510v8 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_O/0/1/0/all/0/1\">Oleksandr Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molander_K/0/1/0/all/0/1\">Karin Molander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunne_R/0/1/0/all/0/1\">Robert Dunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Stephen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masek_K/0/1/0/all/0/1\">Kevin Masek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_E/0/1/0/all/0/1\">Erica Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lisa Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Travers_D/0/1/0/all/0/1\">Debbie Travers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brecher_D/0/1/0/all/0/1\">Deena Brecher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delaney_D/0/1/0/all/0/1\">Deb Delaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montgomery_K/0/1/0/all/0/1\">Kyla Montgomery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reilly_C/0/1/0/all/0/1\">Christian Reilly</a>",
          "description": "Sepsis is a life-threatening condition with organ dysfunction and is a\nleading cause of death and critical illness worldwide. Accurate detection of\nsepsis during emergency department triage would allow early initiation of lab\nanalysis, antibiotic administration, and other sepsis treatment protocols. The\npurpose of this study was to determine whether EHR data can be extracted and\nsynthesized with the latest machine learning algorithms (KATE Sepsis) and\nclinical natural language processing to produce accurate sepsis models, and\ncompare KATE Sepsis performance with existing sepsis screening protocols, such\nas SIRS and qSOFA. A machine learning model (KATE Sepsis) was developed using\npatient encounters with triage data from 16 participating hospitals. KATE\nSepsis, SIRS, standard screening (SIRS with source of infection) and qSOFA were\ntested in three settings. Cohort-A was a retrospective analysis on medical\nrecords from a single Site 1. Cohort-B was a prospective analysis of Site 1.\nCohort-C was a retrospective analysis on Site 1 with 15 additional sites.\nAcross all cohorts, KATE Sepsis demonstrates an AUC of 0.94-0.963 with\n73-74.87% TPR and 3.76-7.17% FPR. Standard screening demonstrates an AUC of\n0.682-0.726 with 39.39-51.19% TPR and 2.9-6.02% FPR. The qSOFA protocol\ndemonstrates an AUC of 0.544-0.56, with 10.52-13.18% TPR and 1.22-1.68% FPR.\nFor severe sepsis, across all cohorts, KATE Sepsis demonstrates an AUC of\n0.935-0.972 with 70-82.26% TPR and 4.64-8.62% FPR. For septic shock, across all\ncohorts, KATE Sepsis demonstrates an AUC of 0.96-0.981 with 85.71-89.66% TPR\nand 4.85-8.8% FPR. SIRS, standard screening, and qSOFA demonstrate low AUC and\nTPR for severe sepsis and septic shock detection. KATE Sepsis provided\nsubstantially better sepsis detection performance in triage than commonly used\nscreening protocols.",
          "link": "http://arxiv.org/abs/2204.07657",
          "publishedOn": "2022-04-23T00:53:50.488Z",
          "wordCount": null,
          "title": "Accurate detection of sepsis at ED triage using machine learning with clinical natural language processing. (arXiv:2204.07657v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassanin_M/0/1/0/all/0/1\">Mohammed Hassanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1\">Saeed Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radwan_I/0/1/0/all/0/1\">Ibrahim Radwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad S Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1\">Ajmal Mian</a>",
          "description": "Inspired by the human cognitive system, attention is a mechanism that\nimitates the human cognitive awareness about specific information, amplifying\ncritical details to focus more on the essential aspects of data. Deep learning\nhas employed attention to boost performance for many applications.\nInterestingly, the same attention design can suit processing different data\nmodalities and can easily be incorporated into large networks. Furthermore,\nmultiple complementary attention mechanisms can be incorporated in one network.\nHence, attention techniques have become extremely attractive. However, the\nliterature lacks a comprehensive survey specific to attention techniques to\nguide researchers in employing attention in their deep models. Note that,\nbesides being demanding in terms of training data and computational resources,\ntransformers only cover a single category in self-attention out of the many\ncategories available. We fill this gap and provide an in-depth survey of 50\nattention techniques categorizing them by their most prominent features. We\ninitiate our discussion by introducing the fundamental concepts behind the\nsuccess of attention mechanism. Next, we furnish some essentials such as the\nstrengths and limitations of each attention category, describe their\nfundamental building blocks, basic formulations with primary usage, and\napplications specifically for computer vision. We also discuss the challenges\nand open questions related to attention mechanism in general. Finally, we\nrecommend possible future research directions for deep attention.",
          "link": "http://arxiv.org/abs/2204.07756",
          "publishedOn": "2022-04-23T00:53:50.486Z",
          "wordCount": null,
          "title": "Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingxuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beurer_Kellner_L/0/1/0/all/0/1\">Luca Beurer-Kellner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Deep learning has recently achieved initial success in program analysis tasks\nsuch as bug detection. Lacking real bugs, most existing works construct\ntraining and test data by injecting synthetic bugs into correct programs.\nDespite achieving high test accuracy (e.g. >90%), the resulting bug detectors\nare found to be surprisingly unusable in practice, i.e., <10% precision when\nused to scan real software repositories. In this work, we argue that this\nmassive performance difference is caused by distribution shift, i.e., a\nfundamental mismatch between the real bug distribution and the synthetic bug\ndistribution used to train and evaluate the detectors. To address this key\nchallenge, we propose to train a bug detector in two phases, first on a\nsynthetic bug distribution to adapt the model to the bug detection domain, and\nthen on a real bug distribution to drive the model towards the real\ndistribution. During these two phases, we leverage a multi-task hierarchy,\nfocal loss, and contrastive learning to further boost performance. We evaluate\nour approach extensively on three widely studied bug types, for which we\nconstruct new datasets carefully designed to capture the real bug distribution.\nThe results demonstrate that our approach is practically effective and\nsuccessfully mitigates the distribution shift: our learned detectors are highly\nperformant on both our constructed test set and the latest version of open\nsource repositories.",
          "link": "http://arxiv.org/abs/2204.10049",
          "publishedOn": "2022-04-23T00:53:50.485Z",
          "wordCount": null,
          "title": "On Distribution Shift in Learning-based Bug Detectors. (arXiv:2204.10049v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Meng Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1\">Fei Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojuan Ma</a>",
          "description": "Persuading people to change their opinions is a common practice in online\ndiscussion forums on topics ranging from political campaigns to relationship\nconsultation. Enhancing people's ability to write persuasive arguments could\nnot only practice their critical thinking and reasoning but also contribute to\nthe effectiveness and civility in online communication. It is, however, not an\neasy task in online discussion settings where written words are the primary\ncommunication channel. In this paper, we derived four design goals for a tool\nthat helps users improve the persuasiveness of arguments in online discussions\nthrough a survey with 123 online forum users and interviews with five debating\nexperts. To satisfy these design goals, we analyzed and built a labeled dataset\nof fine-grained persuasive strategies (i.e., logos, pathos, ethos, and\nevidence) in 164 arguments with high ratings on persuasiveness from\nChangeMyView, a popular online discussion forum. We then designed an\ninteractive visual system, Persua, which provides example-based guidance on\npersuasive strategies to enhance the persuasiveness of arguments. In\nparticular, the system constructs portfolios of arguments based on different\npersuasive strategies applied to a given discussion topic. It then presents\nconcrete examples based on the difference between the portfolios of user input\nand high-quality arguments in the dataset. A between-subjects study shows\nsuggestive evidence that Persua encourages users to submit more times for\nfeedback and helps users improve more on the persuasiveness of their arguments\nthan a baseline system. Finally, a set of design considerations was summarized\nto guide future intelligent systems that improve the persuasiveness in text.",
          "link": "http://arxiv.org/abs/2204.07741",
          "publishedOn": "2022-04-23T00:53:50.484Z",
          "wordCount": null,
          "title": "Persua: A Visual Interactive System to Enhance the Persuasiveness of Arguments in Online Discussion. (arXiv:2204.07741v2 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.13322",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiaguo Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yuming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Menghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haofeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>",
          "description": "Learning to hash pictures a list-wise sorting problem. Its testing metrics,\ne.g., mean-average precision, count on a sorted candidate list ordered by\npair-wise code similarity. However, scarcely does one train a deep hashing\nmodel with the sorted results end-to-end because of the non-differentiable\nnature of the sorting operation. This inconsistency in the objectives of\ntraining and test may lead to sub-optimal performance since the training loss\noften fails to reflect the actual retrieval metric. In this paper, we tackle\nthis problem by introducing Naturally-Sorted Hashing (NSH). We sort the Hamming\ndistances of samples' hash codes and accordingly gather their latent\nrepresentations for self-supervised training. Thanks to the recent advances in\ndifferentiable sorting approximations, the hash head receives gradients from\nthe sorter so that the hash encoder can be optimized along with the training\nprocedure. Additionally, we describe a novel Sorted Noise-Contrastive\nEstimation (SortedNCE) loss that selectively picks positive and negative\nsamples for contrastive learning, which allows NSH to mine data semantic\nrelations during training in an unsupervised manner. Our extensive experiments\nshow the proposed NSH model significantly outperforms the existing unsupervised\nhashing methods on three benchmarked datasets.",
          "link": "http://arxiv.org/abs/2201.13322",
          "publishedOn": "2022-04-23T00:53:50.483Z",
          "wordCount": null,
          "title": "Learning to Hash Naturally Sorts. (arXiv:2201.13322v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.13514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guillaume_A/0/1/0/all/0/1\">Antoine Guillaume</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vrain_C/0/1/0/all/0/1\">Christel Vrain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wael_E/0/1/0/all/0/1\">Elloumi Wael</a>",
          "description": "Shapelet-based algorithms are widely used for time series classification\nbecause of their ease of interpretation, but they are currently outperformed by\nrecent state-of-the-art approaches. We present a new formulation of time series\nshapelets including the notion of dilation, and we introduce a new shapelet\nfeature to enhance their discriminative power for classification. Experiments\nperformed on 112 datasets show that our method improves on the state-of-the-art\nshapelet algorithm, and achieves comparable accuracy to recent state-of-the-art\napproaches, without sacrificing neither scalability, nor interpretability.",
          "link": "http://arxiv.org/abs/2109.13514",
          "publishedOn": "2022-04-23T00:53:50.482Z",
          "wordCount": null,
          "title": "Random Dilated Shapelet Transform: A New Approach for Time Series Shapelets. (arXiv:2109.13514v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1807.06919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1\">Cinjon Resnick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1\">Alexander Peysakhovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Model-free reinforcement learning (RL) requires a large number of trials to\nlearn a good policy, especially in environments with sparse rewards. We explore\na method to improve the sample efficiency when we have access to\ndemonstrations. Our approach, Backplay, uses a single demonstration to\nconstruct a curriculum for a given task. Rather than starting each training\nepisode in the environment's fixed initial state, we start the agent near the\nend of the demonstration and move the starting point backwards during the\ncourse of training until we reach the initial state. Our contributions are that\nwe analytically characterize the types of environments where Backplay can\nimprove training speed, demonstrate the effectiveness of Backplay both in large\ngrid worlds and a complex four player zero-sum game (Pommerman), and show that\nBackplay compares favorably to other competitive methods known to improve\nsample efficiency. This includes reward shaping, behavioral cloning, and\nreverse curriculum generation.",
          "link": "http://arxiv.org/abs/1807.06919",
          "publishedOn": "2022-04-23T00:53:50.481Z",
          "wordCount": null,
          "title": "Backplay: \"Man muss immer umkehren\". (arXiv:1807.06919v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10277",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Valsecchi_D/0/1/0/all/0/1\">Davide Valsecchi</a>",
          "description": "The reconstruction of electrons and photons in CMS depends on topological\nclustering of the energy deposited by an incident particle in different\ncrystals of the electromagnetic calorimeter (ECAL). These clusters are formed\nby aggregating neighbouring crystals according to the expected topology of an\nelectromagnetic shower in the ECAL. The presence of upstream material\n(beampipe, tracker and support structures) causes electrons and photons to\nstart showering before reaching the calorimeter. This effect, combined with the\n3.8T CMS magnetic field, leads to energy being spread in several clusters\naround the primary one. It is essential to recover the energy contained in\nthese satellite clusters in order to achieve the best possible energy\nresolution for physics analyses. Historically satellite clusters have been\nassociated to the primary cluster using a purely topological algorithm which\ndoes not attempt to remove spurious energy deposits from additional pileup\ninteractions (PU). The performance of this algorithm is expected to degrade\nduring LHC Run 3 (2022+) because of the larger average PU levels and the\nincreasing levels of noise due to the ageing of the ECAL detector. New methods\nare being investigated that exploit state-of-the-art deep learning\narchitectures like Graph Neural Networks (GNN) and self-attention algorithms.\nThese more sophisticated models improve the energy collection and are more\nresilient to PU and noise, helping to preserve the electron and photon energy\nresolution achieved during LHC Runs 1 and 2. This work will cover the\nchallenges of training the models as well the opportunity that this new\napproach offers to unify the ECAL energy measurement with the particle\nidentification steps used in the global CMS photon and electron reconstruction.",
          "link": "http://arxiv.org/abs/2204.10277",
          "publishedOn": "2022-04-23T00:53:50.480Z",
          "wordCount": null,
          "title": "Deep learning techniques for energy clustering in the CMS ECAL. (arXiv:2204.10277v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maumela_J/0/1/0/all/0/1\">Joshua Tshifhiwa Maumela</a>",
          "description": "Dissolved Gas-in-oil analysis (DGA) is used to monitor the condition of\nbushings on large power transformers. There are different techniques used in\ndetermining the conditions from the data collected, but in this work the\nArtificial Intelligence techniques are investigated. This work investigates\nwhich gases in DGA are related to each other and which ones are important for\nmaking decisions. When the related and crucial gases are determined, the other\ngases are discarded thereby reducing the number of attributes in DGA. Hence a\nfurther investigation is done to see how these new datasets influence the\nperformance of the classifiers used to classify the DGA of full attributes. The\nclassifiers used in these experiments were Backpropagation Neural Networks\n(BPNN) and Support Vector Machines (SVM) whereas the Principal Component\nAnalysis (PCA), Rough Set (RS), Incremental Granular Ranking (GR++) and\nDecision Trees (DT) were used to reduce the attributes of the dataset. The\nparameters used when training the BPNN and SVM classifiers are kept fixed to\ncreate a controlled test environment when investigating the effects of reducing\nthe number of gases. This work further introduced a new classifier that can\nhandle high dimension dataset and noisy dataset, Rough Neural Network (RNN).",
          "link": "http://arxiv.org/abs/2204.10193",
          "publishedOn": "2022-04-23T00:53:50.475Z",
          "wordCount": null,
          "title": "Condition Monitoring of Transformer Bushings Using Computational Intelligence. (arXiv:2204.10193v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kogkalidis_K/0/1/0/all/0/1\">Konstantinos Kogkalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moortgat_M/0/1/0/all/0/1\">Michael Moortgat</a>",
          "description": "The syntactic categories of categorial grammar formalisms are structured\nunits made of smaller, indivisible primitives, bound together by the underlying\ngrammar's category formation rules. In the trending approach of constructive\nsupertagging, neural models are increasingly made aware of the internal\ncategory structure, which in turn enables them to more reliably predict rare\nand out-of-vocabulary categories, with significant implications for grammars\npreviously deemed too complex to find practical use. In this work, we revisit\nconstructive supertagging from a graph-theoretic perspective, and propose a\nframework based on heterogeneous dynamic graph convolutions aimed at exploiting\nthe distinctive structure of a supertagger's output space. We test our approach\non a number of categorial grammar datasets spanning different languages and\ngrammar formalisms, achieving substantial improvements over previous state of\nthe art scores. Code will be made available at\nhttps://github.com/konstantinosKokos/dynamic-graph-supertagging",
          "link": "http://arxiv.org/abs/2203.12235",
          "publishedOn": "2022-04-23T00:53:50.448Z",
          "wordCount": null,
          "title": "Geometry-Aware Supertagging with Heterogeneous Dynamic Convolutions. (arXiv:2203.12235v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Weijie Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>",
          "description": "Industrial control systems (ICSs) are facing increasing cyber-physical\nattacks that can cause catastrophes in the physical system. Efficient anomaly\ndetection models in the industrial sensor networks are essential for enhancing\nICS reliability and security, due to the sensor data is related to the\noperational state of the ICS. Considering the limited availability of computing\nresources, this paper proposes a hybrid anomaly detection approach in\ncloud-edge collaboration industrial sensor networks. The hybrid approach\nconsists of sensor data detection models deployed at the edges and a sensor\ndata analysis model deployed in the cloud. The sensor data detection model\nbased on Gaussian and Bayesian algorithms can detect the anomalous sensor data\nin real-time and upload them to the cloud for further analysis, filtering the\nnormal sensor data and reducing traffic load. The sensor data analysis model\nbased on Graph convolutional network, Residual algorithm and Long short-term\nmemory network (GCRL) can effectively extract the spatial and temporal features\nand then identify the attack precisely. The proposed hybrid anomaly detection\napproach is evaluated using a benchmark dataset and baseline anomaly detection\nmodels. The experimental results show that the proposed approach can achieve an\noverall 11.19% increase in Recall and an impressive 14.29% improvement in\nF1-score, compared with the existing models.",
          "link": "http://arxiv.org/abs/2204.09942",
          "publishedOn": "2022-04-23T00:53:50.447Z",
          "wordCount": null,
          "title": "Hybrid Cloud-Edge Collaborative Data Anomaly Detection in Industrial Sensor Networks. (arXiv:2204.09942v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.09139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilault_J/0/1/0/all/0/1\">Jonathan Pilault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhattami_A/0/1/0/all/0/1\">Amine Elhattami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Multi-Task Learning (MTL) networks have emerged as a promising method for\ntransferring learned knowledge across different tasks. However, MTL must deal\nwith challenges such as: overfitting to low resource tasks, catastrophic\nforgetting, and negative task transfer, or learning interference. Often, in\nNatural Language Processing (NLP), a separate model per task is needed to\nobtain the best performance. However, many fine-tuning approaches are both\nparameter inefficient, i.e., potentially involving one new model per task, and\nhighly susceptible to losing knowledge acquired during pretraining. We propose\na novel Transformer architecture consisting of a new conditional attention\nmechanism as well as a set of task-conditioned modules that facilitate weight\nsharing. Through this construction (a hypernetwork adapter), we achieve more\nefficient parameter sharing and mitigate forgetting by keeping half of the\nweights of a pretrained model fixed. We also use a new multi-task data sampling\nstrategy to mitigate the negative effects of data imbalance across tasks. Using\nthis approach, we are able to surpass single task fine-tuning methods while\nbeing parameter and data efficient (using around 66% of the data for weight\nupdates). Compared to other BERT Large methods on GLUE, our 8-task model\nsurpasses other Adapter methods by 2.8% and our 24-task model outperforms by\n0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger\nvariant of our single multi-task model approach performs competitively across\n26 NLP tasks and yields state-of-the-art results on a number of test and\ndevelopment sets. Our code is publicly available at\nhttps://github.com/CAMTL/CA-MTL.",
          "link": "http://arxiv.org/abs/2009.09139",
          "publishedOn": "2022-04-23T00:53:50.440Z",
          "wordCount": null,
          "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data. (arXiv:2009.09139v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bennett_M/0/1/0/all/0/1\">Michele Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balusu_J/0/1/0/all/0/1\">Jaya Balusu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_K/0/1/0/all/0/1\">Karin Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleczyk_E/0/1/0/all/0/1\">Ewa J. Kleczyk</a>",
          "description": "The COVID-19 pandemic has dramatically changed how healthcare is delivered to\npatients, how patients interact with healthcare providers, and how healthcare\ninformation is disseminated to both healthcare providers and patients.\nAnalytical models that were trained and tested pre-pandemic may no longer be\nperforming up to expectations, providing unreliable and irrelevant learning\n(ML) models given that ML depends on the basic principle that what happened in\nthe past are likely to repeat in the future. ML faced to two important\ndegradation principles, concept drift, when the underlying properties and\ncharacteristics of the variables change and data drift, when the data\ndistributions, probabilities, co-variates, and other variable relationships\nchange, both of which are prime culprits of model failure. Therefore, detecting\nand diagnosing drift in existing models is something that has become an\nimperative. And perhaps even more important is a shift in our mindset towards a\nconscious recognition that drift is inevitable, and model building must\nincorporate intentional resilience, the ability to offset and recover quickly\nfrom failure, and proactive robustness, avoiding failure by developing models\nthat are less vulnerable to drift and disruption.",
          "link": "http://arxiv.org/abs/2204.10227",
          "publishedOn": "2022-04-23T00:53:50.426Z",
          "wordCount": null,
          "title": "The Silent Problem -- Machine Learning Model Failure -- How to Diagnose and Fix Ailing Machine Learning Models. (arXiv:2204.10227v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_M/0/1/0/all/0/1\">Maxime Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdier_J/0/1/0/all/0/1\">Jean-Charles Verdier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nkashama_D/0/1/0/all/0/1\">D&#x27;Jeff K. Nkashama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frappier_M/0/1/0/all/0/1\">Marc Frappier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tardif_P/0/1/0/all/0/1\">Pierre-Martin Tardif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabanza_F/0/1/0/all/0/1\">Froduald Kabanza</a>",
          "description": "Anomaly detection has many applications ranging from bank-fraud detection and\ncyber-threat detection to equipment maintenance and health monitoring. However,\nchoosing a suitable algorithm for a given application remains a challenging\ndesign decision, often informed by the literature on anomaly detection\nalgorithms. We extensively reviewed twelve of the most popular unsupervised\nanomaly detection methods. We observed that, so far, they have been compared\nusing inconsistent protocols - the choice of the class of interest or the\npositive class, the split of training and test data, and the choice of\nhyperparameters - leading to ambiguous evaluations. This observation led us to\ndefine a coherent evaluation protocol which we then used to produce an updated\nand more precise picture of the relative performance of the twelve methods on\nfive widely used tabular datasets. While our evaluation cannot pinpoint a\nmethod that outperforms all the others on all datasets, it identifies those\nthat stand out and revise misconceived knowledge about their relative\nperformances.",
          "link": "http://arxiv.org/abs/2204.09825",
          "publishedOn": "2022-04-23T00:53:50.405Z",
          "wordCount": null,
          "title": "A Revealing Large-Scale Evaluation of Unsupervised Anomaly Detection Algorithms. (arXiv:2204.09825v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allot_A/0/1/0/all/0/1\">Alexis Allot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leaman_R/0/1/0/all/0/1\">Robert Leaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dogan_R/0/1/0/all/0/1\">Rezarta Islamaj Do&#x11f;an</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jingcheng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Li Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kai_W/0/1/0/all/0/1\">Wang Kai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuefu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagherzadeh_P/0/1/0/all/0/1\">Parsa Bagherzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergler_S/0/1/0/all/0/1\">Sabine Bergler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatnagar_A/0/1/0/all/0/1\">Aakash Bhatnagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhavsar_N/0/1/0/all/0/1\">Nidhir Bhavsar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yung-Chun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Sheng-Jie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wentai Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavchioski_I/0/1/0/all/0/1\">Ilija Tavchioski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shubo Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otmakhova_Y/0/1/0/all/0/1\">Yulia Otmakhova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yepes_A/0/1/0/all/0/1\">Antonio Jimeno Yepes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Honghan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dufour_R/0/1/0/all/0/1\">Richard Dufour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labrak_Y/0/1/0/all/0/1\">Yanis Labrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_N/0/1/0/all/0/1\">Niladri Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_K/0/1/0/all/0/1\">Kushagri Tandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laleye_F/0/1/0/all/0/1\">Fr&#xe9;jus Laleye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakotoson_L/0/1/0/all/0/1\">Lo&#xef;c Rakotoson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chersoni_E/0/1/0/all/0/1\">Emmanuele Chersoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinghang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_A/0/1/0/all/0/1\">Annemarie Friedrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujari_S/0/1/0/all/0/1\">Subhash Chandra Pujari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chizhikova_M/0/1/0/all/0/1\">Mariia Chizhikova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivadasan_N/0/1/0/all/0/1\">Naveen Sivadasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivadasan_N/0/1/0/all/0/1\">Naveen Sivadasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>",
          "description": "The COVID-19 pandemic has been severely impacting global society since\nDecember 2019. Massive research has been undertaken to understand the\ncharacteristics of the virus and design vaccines and drugs. The related\nfindings have been reported in biomedical literature at a rate of about 10,000\narticles on COVID-19 per month. Such rapid growth significantly challenges\nmanual curation and interpretation. For instance, LitCovid is a literature\ndatabase of COVID-19-related articles in PubMed, which has accumulated more\nthan 200,000 articles with millions of accesses each month by users worldwide.\nOne primary curation task is to assign up to eight topics (e.g., Diagnosis and\nTreatment) to the articles in LitCovid. Despite the continuing advances in\nbiomedical text mining methods, few have been dedicated to topic annotations in\nCOVID-19 literature. To close the gap, we organized the BioCreative LitCovid\ntrack to call for a community effort to tackle automated topic annotation for\nCOVID-19 literature. The BioCreative LitCovid dataset, consisting of over\n30,000 articles with manually reviewed topics, was created for training and\ntesting. It is one of the largest multilabel classification datasets in\nbiomedical scientific literature. 19 teams worldwide participated and made 80\nsubmissions in total. Most teams used hybrid systems based on transformers. The\nhighest performing submissions achieved 0.8875, 0.9181, and 0.9394 for macro\nF1-score, micro F1-score, and instance-based F1-score, respectively. The level\nof participation and results demonstrate a successful track and help close the\ngap between dataset curation and method development. The dataset is publicly\navailable via https://ftp.ncbi.nlm.nih.gov/pub/lu/LitCovid/biocreative/ for\nbenchmarking and further development.",
          "link": "http://arxiv.org/abs/2204.09781",
          "publishedOn": "2022-04-23T00:53:50.402Z",
          "wordCount": null,
          "title": "Multi-label classification for biomedical literature: an overview of the BioCreative VII LitCovid Track for COVID-19 literature topic annotations. (arXiv:2204.09781v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09831",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Cheng_L/0/1/0/all/0/1\">Lixue Cheng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sun_J/0/1/0/all/0/1\">Jiace Sun</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Miller_T/0/1/0/all/0/1\">Thomas F. Miller III</a>",
          "description": "We introduce an unsupervised clustering algorithm to improve training\nefficiency and accuracy in predicting energies using molecular-orbital-based\nmachine learning (MOB-ML). This work determines clusters via the Gaussian\nmixture model (GMM) in an entirely automatic manner and simplifies an earlier\nsupervised clustering approach [J. Chem. Theory Comput., 15, 6668 (2019)] by\neliminating both the necessity for user-specified parameters and the training\nof an additional classifier. Unsupervised clustering results from GMM have the\nadvantage of accurately reproducing chemically intuitive groupings of frontier\nmolecular orbitals and having improved performance with an increasing number of\ntraining examples. The resulting clusters from supervised or unsupervised\nclustering is further combined with scalable Gaussian process regression (GPR)\nor linear regression (LR) to learn molecular energies accurately by generating\na local regression model in each cluster. Among all four combinations of\nregressors and clustering methods, GMM combined with scalable exact Gaussian\nprocess regression (GMM/GPR) is the most efficient training protocol for\nMOB-ML. The numerical tests of molecular energy learning on thermalized\ndatasets of drug-like molecules demonstrate the improved accuracy,\ntransferability, and learning efficiency of GMM/GPR over not only other\ntraining protocols for MOB-ML, i.e., supervised regression-clustering combined\nwith GPR(RC/GPR) and GPR without clustering. GMM/GPR also provide the best\nmolecular energy predictions compared with the ones from literature on the same\nbenchmark datasets. With a lower scaling, GMM/GPR has a 10.4-fold speedup in\nwall-clock training time compared with scalable exact GPR with a training size\nof 6500 QM7b-T molecules.",
          "link": "http://arxiv.org/abs/2204.09831",
          "publishedOn": "2022-04-23T00:53:50.402Z",
          "wordCount": null,
          "title": "Accurate Molecular-Orbital-Based Machine Learning Energies via Unsupervised Clustering of Chemical Space. (arXiv:2204.09831v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_V/0/1/0/all/0/1\">Vaidehi Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ziyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Samson Zhou</a>",
          "description": "Online learning with expert advice is a fundamental problem of sequential\nprediction. In this problem, the algorithm has access to a set of $n$ \"experts\"\nwho make predictions on each day. The goal on each day is to process these\npredictions, and make a prediction with the minimum cost. After making a\nprediction, the algorithm sees the actual outcome on that day, updates its\nstate, and then moves on to the next day. An algorithm is judged by how well it\ndoes compared to the best expert in the set.\n\nThe classical algorithm for this problem is the multiplicative weights\nalgorithm. However, every application, to our knowledge, relies on storing\nweights for every expert, and uses $\\Omega(n)$ memory. There is little work on\nunderstanding the memory required to solve the online learning with expert\nadvice problem, or run standard sequential prediction algorithms, in natural\nstreaming models, which is especially important when the number of experts, as\nwell as the number of days on which the experts make predictions, is large.\n\nWe initiate the study of the learning with expert advice problem in the\nstreaming setting, and show lower and upper bounds. Our lower bound for i.i.d.,\nrandom order, and adversarial order streams uses a reduction to a custom-built\nproblem using a novel masking technique, to show a smooth trade-off for regret\nversus memory. Our upper bounds show novel ways to run standard sequential\nprediction algorithms in rounds on small \"pools\" of experts, thus reducing the\nnecessary memory. For random-order streams, we show that our upper bound is\ntight up to low order terms. We hope that these results and techniques will\nhave broad applications in online learning, and can inspire algorithms based on\nstandard sequential prediction techniques, like multiplicative weights, for a\nwide range of other problems in the memory-constrained setting.",
          "link": "http://arxiv.org/abs/2204.09837",
          "publishedOn": "2022-04-23T00:53:50.401Z",
          "wordCount": null,
          "title": "Memory Bounds for the Experts Problem. (arXiv:2204.09837v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09934",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_R/0/1/0/all/0/1\">Rongjie Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lam_M/0/1/0/all/0/1\">Max W. Y. Lam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ren_Y/0/1/0/all/0/1\">Yi Ren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>",
          "description": "Denoising diffusion probabilistic models (DDPMs) have recently achieved\nleading performances in many generative tasks. However, the inherited iterative\nsampling process costs hindered their applications to speech synthesis. This\npaper proposes FastDiff, a fast conditional diffusion model for high-quality\nspeech synthesis. FastDiff employs a stack of time-aware location-variable\nconvolutions of diverse receptive field patterns to efficiently model long-term\ntime dependencies with adaptive conditions. A noise schedule predictor is also\nadopted to reduce the sampling steps without sacrificing the generation\nquality. Based on FastDiff, we design an end-to-end text-to-speech synthesizer,\nFastDiff-TTS, which generates high-fidelity speech waveforms without any\nintermediate feature (e.g., Mel-spectrogram). Our evaluation of FastDiff\ndemonstrates the state-of-the-art results with higher-quality (MOS 4.28) speech\nsamples. Also, FastDiff enables a sampling speed of 58x faster than real-time\non a V100 GPU, making diffusion models practically applicable to speech\nsynthesis deployment for the first time. We further show that FastDiff\ngeneralized well to the mel-spectrogram inversion of unseen speakers, and\nFastDiff-TTS outperformed other competing methods in end-to-end text-to-speech\nsynthesis. Audio samples are available at \\url{https://FastDiff.github.io/}.",
          "link": "http://arxiv.org/abs/2204.09934",
          "publishedOn": "2022-04-23T00:53:50.401Z",
          "wordCount": null,
          "title": "FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis. (arXiv:2204.09934v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1\">Jun Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Ting Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jieping Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xian Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingsong Chen</a>",
          "description": "Due to the prosperity of Artificial Intelligence (AI) techniques, more and\nmore backdoors are designed by adversaries to attack Deep Neural Networks\n(DNNs).Although the state-of-the-art method Neural Attention Distillation (NAD)\ncan effectively erase backdoor triggers from DNNs, it still suffers from\nnon-negligible Attack Success Rate (ASR) together with lowered classification\nACCuracy (ACC), since NAD focuses on backdoor defense using attention features\n(i.e., attention maps) of the same order. In this paper, we introduce a novel\nbackdoor defense framework named Attention Relation Graph Distillation (ARGD),\nwhich fully explores the correlation among attention features with different\norders using our proposed Attention Relation Graphs (ARGs). Based on the\nalignment of ARGs between both teacher and student models during knowledge\ndistillation, ARGD can eradicate more backdoor triggers than NAD. Comprehensive\nexperimental results show that, against six latest backdoor attacks, ARGD\noutperforms NAD by up to 94.85% reduction in ASR, while ACC can be improved by\nup to 3.23%.",
          "link": "http://arxiv.org/abs/2204.09975",
          "publishedOn": "2022-04-23T00:53:50.393Z",
          "wordCount": null,
          "title": "Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation. (arXiv:2204.09975v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raheman_A/0/1/0/all/0/1\">Ali Raheman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolonin_A/0/1/0/all/0/1\">Anton Kolonin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fridkins_I/0/1/0/all/0/1\">Igors Fridkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ansari_I/0/1/0/all/0/1\">Ikram Ansari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishwas_M/0/1/0/all/0/1\">Mukul Vishwas</a>",
          "description": "In this paper, we explore the usability of different natural language\nprocessing models for the sentiment analysis of social media applied to\nfinancial market prediction, using the cryptocurrency domain as a reference. We\nstudy how the different sentiment metrics are correlated with the price\nmovements of Bitcoin. For this purpose, we explore different methods to\ncalculate the sentiment metrics from a text finding most of them not very\naccurate for this prediction task. We find that one of the models outperforms\nmore than 20 other public ones and makes it possible to fine-tune it\nefficiently given its interpretable nature. Thus we confirm that interpretable\nartificial intelligence and natural language processing methods might be more\nvaluable practically than non-explainable and non-interpretable ones. In the\nend, we analyse potential causal connections between the different sentiment\nmetrics and the price movements.",
          "link": "http://arxiv.org/abs/2204.10185",
          "publishedOn": "2022-04-23T00:53:50.392Z",
          "wordCount": null,
          "title": "Social Media Sentiment Analysis for Cryptocurrency Market Prediction. (arXiv:2204.10185v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>",
          "description": "Contrastive learning is widely used for recommendation model learning, where\nselecting representative and informative negative samples is critical. Existing\nmethods usually focus on centralized data, where abundant and high-quality\nnegative samples are easy to obtain. However, centralized user data storage and\nexploitation may lead to privacy risks and concerns, while decentralized user\ndata on a single client can be too sparse and biased for accurate contrastive\nlearning. In this paper, we propose a federated contrastive learning method\nnamed FedCL for privacy-preserving recommendation, which can exploit\nhigh-quality negative samples for effective model training with privacy well\nprotected. We first infer user embeddings from local user data through the\nlocal model on each client, and then perturb them with local differential\nprivacy (LDP) before sending them to a central server for hard negative\nsampling. Since individual user embedding contains heavy noise due to LDP, we\npropose to cluster user embeddings on the server to mitigate the influence of\nnoise, and the cluster centroids are used to retrieve hard negative samples\nfrom the item pool. These hard negative samples are delivered to user clients\nand mixed with the observed negative samples from local data as well as\nin-batch negatives constructed from positive samples for federated model\ntraining. Extensive experiments on four benchmark datasets show FedCL can\nempower various recommendation methods in a privacy-preserving way.",
          "link": "http://arxiv.org/abs/2204.09850",
          "publishedOn": "2022-04-23T00:53:50.390Z",
          "wordCount": null,
          "title": "FedCL: Federated Contrastive Learning for Privacy-Preserving Recommendation. (arXiv:2204.09850v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wahed_M/0/1/0/all/0/1\">Muntasir Wahed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabassum_A/0/1/0/all/0/1\">Afrina Tabassum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lourentzou_I/0/1/0/all/0/1\">Ismini Lourentzou</a>",
          "description": "Contrastive learning has gained popularity as an effective self-supervised\nrepresentation learning technique. Several research directions improve\ntraditional contrastive approaches, e.g., prototypical contrastive methods\nbetter capture the semantic similarity among instances and reduce the\ncomputational burden by considering cluster prototypes or cluster assignments,\nwhile adversarial instance-wise contrastive methods improve robustness against\na variety of attacks. To the best of our knowledge, no prior work jointly\nconsiders robustness, cluster-wise semantic similarity and computational\nefficiency. In this work, we propose SwARo, an adversarial contrastive\nframework that incorporates cluster assignment permutations to generate\nrepresentative adversarial samples. We evaluate SwARo on multiple benchmark\ndatasets and against various white-box and black-box attacks, obtaining\nconsistent improvements over state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2204.10314",
          "publishedOn": "2022-04-23T00:53:50.389Z",
          "wordCount": null,
          "title": "Adversarial Contrastive Learning by Permuting Cluster Assignments. (arXiv:2204.10314v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.03892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_B/0/1/0/all/0/1\">Bo Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1\">Shiping Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kaibo Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tingwen Huang</a>",
          "description": "Differentiable architecture search has gradually become the mainstream\nresearch topic in the field of Neural Architecture Search (NAS) for its high\nefficiency compared with the early NAS (EA-based, RL-based) methods. Recent\ndifferentiable NAS also aims at further improving the search performance and\nreducing the GPU-memory consumption. However, these methods are no longer\nnaturally capable of tackling the non-differentiable objectives, e.g., energy,\nresource-constrained efficiency, and other metrics, let alone the\nmulti-objective search demands. Researches in the multi-objective NAS field\ntarget this but requires vast computational resources cause of the sole\noptimization of each candidate architecture. In light of this discrepancy, we\npropose the TND-NAS, which is with the merits of the high efficiency in\ndifferentiable NAS framework and the compatibility among non-differentiable\nmetrics in Multi-objective NAS. Under the differentiable NAS framework, with\nthe continuous relaxation of the search space, TND-NAS has the architecture\nparameters ($\\alpha$) been optimized in discrete space, while resorting to the\nprogressive search space shrinking by $\\alpha$. Our representative experiment\ntakes two objectives (Parameters, Accuracy) as an example, we achieve a series\nof high-performance compact architectures on CIFAR10 (1.09M/3.3\\%, 2.4M/2.95\\%,\n9.57M/2.54\\%) and CIFAR100 (2.46M/18.3\\%, 5.46/16.73\\%, 12.88/15.20\\%)\ndatasets. Favorably, compared with other multi-objective NAS methods, TND-NAS\nis less time-consuming (1.3 GPU-days on NVIDIA 1080Ti, 1/6 of that in\nNSGA-Net), and can be conveniently adapted to real-world NAS scenarios\n(resource-constrained, platform-specialized).",
          "link": "http://arxiv.org/abs/2111.03892",
          "publishedOn": "2022-04-23T00:53:50.384Z",
          "wordCount": null,
          "title": "TND-NAS: Towards Non-Differentiable Objectives in Differentiable Neural Architecture Search. (arXiv:2111.03892v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Pretrained language models have achieved state-of-the-art performance when\nadapted to a downstream NLP task. However, theoretical analysis of these models\nis scarce and challenging since the pretraining and downstream tasks can be\nvery different. We propose an analysis framework that links the pretraining and\ndownstream tasks with an underlying latent variable generative model of text --\nthe downstream classifier must recover a function of the posterior distribution\nover the latent variables. We analyze head tuning (learning a classifier on top\nof the frozen pretrained model) and prompt tuning in this setting. The\ngenerative model in our analysis is either a Hidden Markov Model (HMM) or an\nHMM augmented with a latent memory component, motivated by long-term\ndependencies in natural language. We show that 1) under certain non-degeneracy\nconditions on the HMM, simple classification heads can solve the downstream\ntask, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy\nconditions, and 3) our recovery guarantees for the memory-augmented HMM are\nstronger than for the vanilla HMM because task-relevant information is easier\nto recover from the long-term memory. Experiments on synthetically generated\ndata from HMMs back our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.09226",
          "publishedOn": "2022-04-23T00:53:50.371Z",
          "wordCount": 669,
          "title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning. (arXiv:2106.09226v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.06377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawamura_R/0/1/0/all/0/1\">Rina Kawamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tae_J/0/1/0/all/0/1\">Jaesung Tae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Sally Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizutani_T/0/1/0/all/0/1\">Tomoe Mizutani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>",
          "description": "Fast-developing fields such as Artificial Intelligence (AI) often outpace the\nefforts of encyclopedic sources such as Wikipedia, which either do not\ncompletely cover recently-introduced topics or lack such content entirely. As a\nresult, methods for automatically producing content are valuable tools to\naddress this information overload. We show that recent advances in pretrained\nlanguage modeling can be combined for a two-stage extractive and abstractive\napproach for Wikipedia lead paragraph generation. We extend this approach to\ngenerate longer Wikipedia-style summaries with sections and examine how such\nmethods struggle in this application through detailed studies with 100\nreference human-collected surveys. This is the first study on utilizing web\nresources for long Wikipedia-style summaries to the best of our knowledge.",
          "link": "http://arxiv.org/abs/2112.06377",
          "publishedOn": "2022-04-23T00:53:50.364Z",
          "wordCount": 602,
          "title": "Surfer100: Generating Surveys From Web Resources on Wikipedia-style. (arXiv:2112.06377v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.05329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_P/0/1/0/all/0/1\">Pritam Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1\">Ali Etemad</a>",
          "description": "We present CrissCross, a self-supervised framework for learning audio-visual\nrepresentations. A novel notion is introduced in our framework whereby in\naddition to learning the intra-modal and standard synchronous cross-modal\nrelations, CrissCross also learns asynchronous cross-modal relationships. We\nshow that by relaxing the temporal synchronicity between the audio and visual\nmodalities, the network learns strong generalized representations. Our\nexperiments show that strong augmentations for both audio and visual modalities\nwith relaxation of cross-modal temporal synchronicity optimize performance. To\npretrain our proposed framework, we use 3 different datasets with varying\nsizes, Kinetics-Sound, Kinetics400, and AudioSet. The learned representations\nare evaluated on a number of downstream tasks namely action recognition, sound\nclassification, and retrieval. CrissCross shows state-of-the-art performances\non action recognition (UCF101 and HMDB51) and sound classification (ESC50 and\nDCASE). The codes and pretrained models will be made publicly available.",
          "link": "http://arxiv.org/abs/2111.05329",
          "publishedOn": "2022-04-23T00:53:50.357Z",
          "wordCount": 610,
          "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity. (arXiv:2111.05329v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Renzhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zheyan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>",
          "description": "Despite the remarkable performance that modern deep neural networks have\nachieved on independent and identically distributed (I.I.D.) data, they can\ncrash under distribution shifts. Most current evaluation methods for domain\ngeneralization (DG) adopt the leave-one-out strategy as a compromise on the\nlimited number of domains. We propose a large-scale benchmark with extensive\nlabeled domains named NICO++ along with more rational evaluation methods for\ncomprehensively evaluating DG algorithms. To evaluate DG datasets, we propose\ntwo metrics to quantify covariate shift and concept shift, respectively. Two\nnovel generalization bounds from the perspective of data construction are\nproposed to prove that limited concept shift and significant covariate shift\nfavor the evaluation capability for generalization. Through extensive\nexperiments, NICO++ shows its superior evaluation capability compared with\ncurrent DG datasets and its contribution in alleviating unfairness caused by\nthe leak of oracle knowledge in model selection.",
          "link": "http://arxiv.org/abs/2204.08040",
          "publishedOn": "2022-04-23T00:53:50.357Z",
          "wordCount": null,
          "title": "NICO++: Towards Better Benchmarking for Domain Generalization. (arXiv:2204.08040v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grillotti_L/0/1/0/all/0/1\">Luca Grillotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1\">Antoine Cully</a>",
          "description": "Quality-Diversity algorithms provide efficient mechanisms to generate large\ncollections of diverse and high-performing solutions, which have shown to be\ninstrumental for solving downstream tasks. However, most of those algorithms\nrely on a behavioural descriptor to characterise the diversity that is\nhand-coded, hence requiring prior knowledge about the considered tasks. In this\nwork, we introduce Relevance-guided Unsupervised Discovery of Abilities; a\nQuality-Diversity algorithm that autonomously finds a behavioural\ncharacterisation tailored to the task at hand. In particular, our method\nintroduces a custom diversity metric that leads to higher densities of\nsolutions near the areas of interest in the learnt behavioural descriptor\nspace. We evaluate our approach on a simulated robotic environment, where the\nrobot has to autonomously discover its abilities based on its full sensory\ndata. We evaluated the algorithms on three tasks: navigation to random targets,\nmoving forward with a high velocity, and performing half-rolls. The\nexperimental results show that our method manages to discover collections of\nsolutions that are not only diverse, but also well-adapted to the considered\ndownstream task.",
          "link": "http://arxiv.org/abs/2204.09828",
          "publishedOn": "2022-04-23T00:53:50.322Z",
          "wordCount": null,
          "title": "Relevance-guided Unsupervised Discovery of Abilities with Quality-Diversity Algorithms. (arXiv:2204.09828v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Sadaf Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Naixing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiang Xu</a>",
          "description": "Applying deep learning (DL) techniques in the electronic design automation\n(EDA) field has become a trending topic. Most solutions apply well-developed DL\nmodels to solve specific EDA problems. While demonstrating promising results,\nthey require careful model tuning for every problem. The fundamental question\non \"How to obtain a general and effective neural representation of circuits?\"\nhas not been answered yet. In this work, we take the first step towards solving\nthis problem. We propose DeepGate, a novel representation learning solution\nthat effectively embeds both logic function and structural information of a\ncircuit as vectors on each gate. Specifically, we propose transforming circuits\ninto unified and-inverter graph format for learning and using signal\nprobabilities as the supervision task in DeepGate. We then introduce a novel\ngraph neural network that uses strong inductive biases in practical circuits as\nlearning priors for signal probability prediction. Our experimental results\nshow the efficacy and generalization capability of DeepGate.",
          "link": "http://arxiv.org/abs/2111.14616",
          "publishedOn": "2022-04-23T00:53:50.322Z",
          "wordCount": null,
          "title": "DeepGate: Learning Neural Representations of Logic Gates. (arXiv:2111.14616v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_K/0/1/0/all/0/1\">Kaushik Balakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_D/0/1/0/all/0/1\">Devesh Upadhyay</a>",
          "description": "The task of 2D human pose estimation is challenging as the number of\nkeypoints is typically large (~ 17) and this necessitates the use of robust\nneural network architectures and training pipelines that can capture the\nrelevant features from the input image. These features are then aggregated to\nmake accurate heatmap predictions from which the final keypoints of human body\nparts can be inferred. Many papers in literature use CNN-based architectures\nfor the backbone, and/or combine it with a transformer, after which the\nfeatures are aggregated to make the final keypoint predictions [1]. In this\npaper, we consider the recently proposed Bottleneck Transformers [2], which\ncombine CNN and multi-head self attention (MHSA) layers effectively, and we\nintegrate it with a Transformer encoder and apply it to the task of 2D human\npose estimation. We consider different backbone architectures and pre-train\nthem using the DINO self-supervised learning method [3], this pre-training is\nfound to improve the overall prediction accuracy. We call our model BTranspose,\nand experiments show that on the COCO validation set, our model achieves an AP\nof 76.4, which is competitive with other methods such as [1] and has fewer\nnetwork parameters. Furthermore, we also present the dependencies of the final\npredicted keypoints on both the MHSA block and the Transformer encoder layers,\nproviding clues on the image sub-regions the network attends to at the mid and\nhigh levels.",
          "link": "http://arxiv.org/abs/2204.10209",
          "publishedOn": "2022-04-23T00:53:50.321Z",
          "wordCount": null,
          "title": "BTranspose: Bottleneck Transformers for Human Pose Estimation with Self-Supervised Pre-Training. (arXiv:2204.10209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richter_J/0/1/0/all/0/1\">Jasmine Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faion_F/0/1/0/all/0/1\">Florian Faion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_D/0/1/0/all/0/1\">Di Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becker_P/0/1/0/all/0/1\">Paul Benedikt Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sielecki_P/0/1/0/all/0/1\">Piotr Sielecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaeser_C/0/1/0/all/0/1\">Claudius Glaeser</a>",
          "description": "In order to make autonomous driving a reality, artificial neural networks\nhave to work reliably in the open-world. However, the open-world is vast and\ncontinuously changing, so it is not technically feasible to collect and\nannotate training datasets which accurately represent this domain. Therefore,\nthere are always domain gaps between training datasets and the open-world which\nmust be understood. In this work, we investigate the domain gaps between\nhigh-resolution and low-resolution LiDAR sensors in object detection networks.\nUsing a unique dataset, which enables us to study sensor resolution domain gaps\nindependent of other effects, we show two distinct domain gaps - an inference\ndomain gap and a training domain gap. The inference domain gap is characterised\nby a strong dependence on the number of LiDAR points per object, while the\ntraining gap shows no such dependence. These fndings show that different\napproaches are required to close these inference and training domain gaps.",
          "link": "http://arxiv.org/abs/2204.10024",
          "publishedOn": "2022-04-23T00:53:50.320Z",
          "wordCount": null,
          "title": "Understanding the Domain Gap in LiDAR Object Detection Networks. (arXiv:2204.10024v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09947",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Anderlini_L/0/1/0/all/0/1\">Lucio Anderlini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Barbetti_M/0/1/0/all/0/1\">Matteo Barbetti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Derkach_D/0/1/0/all/0/1\">Denis Derkach</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kazeev_N/0/1/0/all/0/1\">Nikita Kazeev</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Maevskiy_A/0/1/0/all/0/1\">Artem Maevskiy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mokhnenko_S/0/1/0/all/0/1\">Sergei Mokhnenko</a>",
          "description": "The increasing luminosities of future data taking at Large Hadron Collider\nand next generation collider experiments require an unprecedented amount of\nsimulated events to be produced. Such large scale productions demand a\nsignificant amount of valuable computing resources. This brings a demand to use\nnew approaches to event generation and simulation of detector responses. In\nthis paper, we discuss the application of generative adversarial networks\n(GANs) to the simulation of the LHCb experiment events. We emphasize main\npitfalls in the application of GANs and study the systematic effects in detail.\nThe presented results are based on the Geant4 simulation of the LHCb Cherenkov\ndetector.",
          "link": "http://arxiv.org/abs/2204.09947",
          "publishedOn": "2022-04-23T00:53:50.318Z",
          "wordCount": null,
          "title": "Towards Reliable Neural Generative Modeling of Detectors. (arXiv:2204.09947v1 [physics.ins-det])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.10460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_B/0/1/0/all/0/1\">Boyang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishwar_P/0/1/0/all/0/1\">Prakash Ishwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheutz_M/0/1/0/all/0/1\">Matthias Scheutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1\">Shuchin Aeron</a>",
          "description": "Invariance principle-based methods, for example, Invariant Risk Minimization\n(IRM), have recently emerged as promising approaches for Domain Generalization\n(DG). Despite the promising theory, invariance principle-based approaches fail\nin common classification tasks due to the mixture of the true invariant\nfeatures and the spurious invariant features. In this paper, we propose a\nframework based on the conditional entropy minimization principle to filter out\nthe spurious invariant features leading to a new algorithm with a better\ngeneralization capability. We theoretically prove that under some particular\nassumptions, the representation function can precisely recover the true\ninvariant features. In addition, we also show that the proposed approach is\nclosely related to the well-known Information Bottleneck (IB) framework. Both\nthe theoretical and numerical results are provided to justify our approach.",
          "link": "http://arxiv.org/abs/2201.10460",
          "publishedOn": "2022-04-23T00:53:50.317Z",
          "wordCount": null,
          "title": "Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Douglas_A/0/1/0/all/0/1\">Alyson Douglas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manshausen_P/0/1/0/all/0/1\">Peter Manshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinshausen_N/0/1/0/all/0/1\">Nicolai Meinshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stier_P/0/1/0/all/0/1\">Philip Stier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>",
          "description": "Estimating the effects of continuous-valued interventions from observational\ndata is critically important in fields such as climate science, healthcare, and\neconomics. Recent work focuses on designing neural-network architectures and\nregularization functions to allow for scalable estimation of average and\nindividual-level dose response curves from high-dimensional, large-sample data.\nSuch methodologies assume ignorability (all confounding variables are observed)\nand positivity (all levels of treatment can be observed for every unit\ndescribed by a given covariate value), which are especially challenged in the\ncontinuous treatment regime. Developing scalable sensitivity and uncertainty\nanalyses that allow us to understand the ignorance induced in our estimates\nwhen these assumptions are relaxed receives less attention. Here, we develop a\ncontinuous treatment-effect marginal sensitivity model (CMSM) and derive bounds\nthat agree with both the observed data and a researcher-defined level of hidden\nconfounding. We introduce a scalable algorithm to derive the bounds and\nuncertainty-aware deep models to efficiently estimate these bounds for\nhigh-dimensional, large-sample observational data. We validate our methods\nusing both synthetic and real-world experiments. For the latter, we work in\nconcert with climate scientists interested in evaluating the climatological\nimpacts of human emissions on cloud properties using satellite observations\nfrom the past 15 years: a finite-data problem known to be complicated by the\npresence of a multitude of unobserved confounders.",
          "link": "http://arxiv.org/abs/2204.10022",
          "publishedOn": "2022-04-23T00:53:50.316Z",
          "wordCount": null,
          "title": "Scalable Sensitivity and Uncertainty Analysis for Causal-Effect Estimates of Continuous-Valued Interventions. (arXiv:2204.10022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.06662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_P/0/1/0/all/0/1\">Pengzhou Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1\">Kenji Fukumizu</a>",
          "description": "NOTE: This preprint has a flawed theoretical formulation. Please avoid it and\nrefer to the ICLR22 publication https://openreview.net/forum?id=q7n2RngwOM.\nAlso, arXiv:2109.15062 contains some new ideas on unobserved Confounding.\n\nAs an important problem of causal inference, we discuss the identification\nand estimation of treatment effects under unobserved confounding. Representing\nthe confounder as a latent variable, we propose Intact-VAE, a new variant of\nvariational autoencoder (VAE), motivated by the prognostic score that is\nsufficient for identifying treatment effects. We theoretically show that, under\ncertain settings, treatment effects are identified by our model, and further,\nbased on the identifiability of our model (i.e., determinacy of\nrepresentation), our VAE is a consistent estimator with representation balanced\nfor treatment groups. Experiments on (semi-)synthetic datasets show\nstate-of-the-art performance under diverse settings.",
          "link": "http://arxiv.org/abs/2101.06662",
          "publishedOn": "2022-04-23T00:53:50.316Z",
          "wordCount": null,
          "title": "Intact-VAE: Estimating Treatment Effects under Unobserved Confounding. (arXiv:2101.06662v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chanyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwangbo_J/0/1/0/all/0/1\">Jemin Hwangbo</a>",
          "description": "For autonomous quadruped robot navigation in various complex environments, a\ntypical SOTA system is composed of four main modules -- mapper, global planner,\nlocal planner, and command-tracking controller -- in a hierarchical manner. In\nthis paper, we build a robust and safe local planner which is designed to\ngenerate a velocity plan to track a coarsely planned path from the global\nplanner. Previous works used waypoint-based methods (e.g.\nProportional-Differential control and pure pursuit) which simplify the path\ntracking problem to local point-goal navigation. However, they suffer from\nfrequent collisions in geometrically complex and narrow environments because of\ntwo reasons; the global planner uses a coarse and inaccurate model and the\nlocal planner is unable to track the global plan sufficiently well. Currently,\ndeep learning methods are an appealing alternative because they can learn\nsafety and path feasibility from experience more accurately. However, existing\ndeep learning methods are not capable of planning for a long horizon. In this\nwork, we propose a learning-based fully autonomous navigation framework\ncomposed of three innovative elements: a learned forward dynamics model (FDM),\nan online sampling-based model-predictive controller, and an informed\ntrajectory sampler (ITS). Using our framework, a quadruped robot can\nautonomously navigate in various complex environments without a collision and\ngenerate a smoother command plan compared to the baseline method. Furthermore,\nour method can reactively handle unexpected obstacles on the planned path and\navoid them. Project page\nhttps://awesomericky.github.io/projects/FDM_ITS_navigation/.",
          "link": "http://arxiv.org/abs/2204.08647",
          "publishedOn": "2022-04-23T00:53:50.315Z",
          "wordCount": null,
          "title": "Learning Forward Dynamics Model and Informed Trajectory Sampler for Safe Quadruped Navigation. (arXiv:2204.08647v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bandara_W/0/1/0/all/0/1\">Wele Gedara Chaminda Bandara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Remote-sensing (RS) Change Detection (CD) aims to detect \"changes of\ninterest\" from co-registered bi-temporal images. The performance of existing\ndeep supervised CD methods is attributed to the large amounts of annotated data\nused to train the networks. However, annotating large amounts of remote sensing\nimages is labor-intensive and expensive, particularly with bi-temporal images,\nas it requires pixel-wise comparisons by a human expert. On the other hand, we\noften have access to unlimited unlabeled multi-temporal RS imagery thanks to\never-increasing earth observation programs. In this paper, we propose a simple\nyet effective way to leverage the information from unlabeled bi-temporal images\nto improve the performance of CD approaches. More specifically, we propose a\nsemi-supervised CD model in which we formulate an unsupervised CD loss in\naddition to the supervised Cross-Entropy (CE) loss by constraining the output\nchange probability map of a given unlabeled bi-temporal image pair to be\nconsistent under the small random perturbations applied on the deep feature\ndifference map that is obtained by subtracting their latent feature\nrepresentations. Experiments conducted on two publicly available CD datasets\nshow that the proposed semi-supervised CD method can reach closer to the\nperformance of supervised CD even with access to as little as 10% of the\nannotated training data. Code available at https://github.com/wgcban/SemiCD",
          "link": "http://arxiv.org/abs/2204.08454",
          "publishedOn": "2022-04-23T00:53:50.313Z",
          "wordCount": null,
          "title": "Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images. (arXiv:2204.08454v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09790",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Galaz_Garcia_F/0/1/0/all/0/1\">Fernando Galaz-Garcia</a>, <a href=\"http://arxiv.org/find/math/1/au:+Papamichalis_M/0/1/0/all/0/1\">Marios Papamichalis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Turnbull_K/0/1/0/all/0/1\">Kathryn Turnbull</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lunagomez_S/0/1/0/all/0/1\">Simon Lunagomez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Airoldi_E/0/1/0/all/0/1\">Edoardo Airoldi</a>",
          "description": "We provide a general framework for constructing probability distributions on\nRiemannian manifolds, taking advantage of area-preserving maps and isometries.\nControl over distributions' properties, such as parameters, symmetry and\nmodality yield a family of flexible distributions that are straightforward to\nsample from, suitable for use within Monte Carlo algorithms and latent variable\nmodels, such as autoencoders. As an illustration, we empirically validate our\napproach by utilizing our proposed distributions within a variational\nautoencoder and a latent space network model. Finally, we take advantage of the\ngeneralized description of this framework to posit questions for future work.",
          "link": "http://arxiv.org/abs/2204.09790",
          "publishedOn": "2022-04-23T00:53:50.312Z",
          "wordCount": null,
          "title": "Wrapped Distributions on homogeneous Riemannian manifolds. (arXiv:2204.09790v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.01490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xudong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_L/0/1/0/all/0/1\">Long Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Stella X. Yu</a>",
          "description": "Pseudo-labels are confident predictions made on unlabeled target data by a\nclassifier trained on labeled source data. They are widely used for adapting a\nmodel to unlabeled data, e.g., in a semi-supervised learning setting.\n\nOur key insight is that pseudo-labels are naturally imbalanced due to\nintrinsic data similarity, even when a model is trained on balanced source data\nand evaluated on balanced target data. If we address this previously unknown\nimbalanced classification problem arising from pseudo-labels instead of\nground-truth training labels, we could remove model biases towards false\nmajorities created by pseudo-labels.\n\nWe propose a novel and effective debiased learning method with pseudo-labels,\nbased on counterfactual reasoning and adaptive margins: The former removes the\nclassifier response bias, whereas the latter adjusts the margin of each class\naccording to the imbalance of pseudo-labels. Validated by extensive\nexperimentation, our simple debiased learning delivers significant accuracy\ngains over the state-of-the-art on ImageNet-1K: 26% for semi-supervised\nlearning with 0.2% annotations and 9% for zero-shot learning. Our code is\navailable at: https://github.com/frank-xwang/debiased-pseudo-labeling.",
          "link": "http://arxiv.org/abs/2201.01490",
          "publishedOn": "2022-04-23T00:53:50.311Z",
          "wordCount": null,
          "title": "Debiased Learning from Naturally Imbalanced Pseudo-Labels. (arXiv:2201.01490v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10020",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Terashima_R/0/1/0/all/0/1\">Ryo Terashima</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamamoto_R/0/1/0/all/0/1\">Ryuichi Yamamoto</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_E/0/1/0/all/0/1\">Eunwoo Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shirahata_Y/0/1/0/all/0/1\">Yuma Shirahata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yoon_H/0/1/0/all/0/1\">Hyun-Wook Yoon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Jae-Min Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tachibana_K/0/1/0/all/0/1\">Kentaro Tachibana</a>",
          "description": "Data augmentation via voice conversion (VC) has been successfully applied to\nlow-resource expressive text-to-speech (TTS) when only neutral data for the\ntarget speaker are available. Although the quality of VC is crucial for this\napproach, it is challenging to learn a stable VC model because the amount of\ndata is limited in low-resource scenarios, and highly expressive speech has\nlarge acoustic variety. To address this issue, we propose a novel data\naugmentation method that combines pitch-shifting and VC techniques. Because\npitch-shift data augmentation enables the coverage of a variety of pitch\ndynamics, it greatly stabilizes training for both VC and TTS models, even when\nonly 1,000 utterances of the target speaker's neutral data are available.\nSubjective test results showed that a FastSpeech 2-based emotional TTS system\nwith the proposed method improved naturalness and emotional similarity compared\nwith conventional methods.",
          "link": "http://arxiv.org/abs/2204.10020",
          "publishedOn": "2022-04-23T00:53:50.310Z",
          "wordCount": null,
          "title": "Cross-Speaker Emotion Transfer for Low-Resource Text-to-Speech Using Non-Parallel Voice Conversion with Pitch-Shift Data Augmentation. (arXiv:2204.10020v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongquan Yang</a>",
          "description": "Recent studies have demonstrated the effectiveness of the combination of\nmachine learning and logical reasoning in inventing advanced artificial\nintelligence technologies. One-step abductive multi-target learning (OSAMTL),\nan approach that only combines machine learning and logical reasoning in a\none-step balanced way, has as well shown its effectiveness in handling complex\nnoisy labels of a single noisy sample in medical histopathology whole slide\nimage analysis (MHWSIA). However, OSAMTL is not suitable for the situation\nwhere diverse noisy samples (DiNS) are provided for a learning task. In this\npaper, giving definition of DiNS, we propose one-step abductive multi-target\nlearning with DiNS (OSAMTL-DiNS) to expand the original OSAMTL to handle\ncomplex noisy labels of DiNS. Applying OSAMTL-DiNS to tumour segmentation for\nbreast cancer in MHWSIA, we show that OSAMTL-DiNS is able to enable various\nstate-of-the-art approaches for learning from noisy labels to achieve more\nrational predictions.",
          "link": "http://arxiv.org/abs/2110.10325",
          "publishedOn": "2022-04-23T00:53:50.275Z",
          "wordCount": 640,
          "title": "One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10269",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gibbs_J/0/1/0/all/0/1\">Joe Gibbs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Holmes_Z/0/1/0/all/0/1\">Zo&#xeb; Holmes</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1\">Matthias C. Caro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ezzell_N/0/1/0/all/0/1\">Nicholas Ezzell</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1\">Andrew T. Sornborger</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Much attention has been paid to dynamical simulation and quantum machine\nlearning (QML) independently as applications for quantum advantage, while the\npossibility of using QML to enhance dynamical simulations has not been\nthoroughly investigated. Here we develop a framework for using QML methods to\nsimulate quantum dynamics on near-term quantum hardware. We use generalization\nbounds, which bound the error a machine learning model makes on unseen data, to\nrigorously analyze the training data requirements of an algorithm within this\nframework. This provides a guarantee that our algorithm is resource-efficient,\nboth in terms of qubit and data requirements. Our numerics exhibit efficient\nscaling with problem size, and we simulate 20 times longer than Trotterization\non IBMQ-Bogota.",
          "link": "http://arxiv.org/abs/2204.10269",
          "publishedOn": "2022-04-23T00:53:50.269Z",
          "wordCount": 582,
          "title": "Dynamical simulation via quantum machine learning with provable generalization. (arXiv:2204.10269v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10231",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosales_Perez_A/0/1/0/all/0/1\">Alejandro Rosales-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_S/0/1/0/all/0/1\">Salvador Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrera_F/0/1/0/all/0/1\">Francisco Herrera</a>",
          "description": "Support vector machines (SVMs) are popular learning algorithms to deal with\nbinary classification problems. They traditionally assume equal\nmisclassification costs for each class; however, real-world problems may have\nan uneven class distribution. This article introduces EBCS-SVM: evolutionary\nbilevel cost-sensitive SVMs. EBCS-SVM handles imbalanced classification\nproblems by simultaneously learning the support vectors and optimizing the SVM\nhyperparameters, which comprise the kernel parameter and misclassification\ncosts. The resulting optimization problem is a bilevel problem, where the lower\nlevel determines the support vectors and the upper level the hyperparameters.\nThis optimization problem is solved using an evolutionary algorithm (EA) at the\nupper level and sequential minimal optimization (SMO) at the lower level. These\ntwo methods work in a nested fashion, that is, the optimal support vectors help\nguide the search of the hyperparameters, and the lower level is initialized\nbased on previous successful solutions. The proposed method is assessed using\n70 datasets of imbalanced classification and compared with several\nstate-of-the-art methods. The experimental results, supported by a Bayesian\ntest, provided evidence of the effectiveness of EBCS-SVM when working with\nhighly imbalanced datasets.",
          "link": "http://arxiv.org/abs/2204.10231",
          "publishedOn": "2022-04-23T00:53:50.262Z",
          "wordCount": 716,
          "title": "Handling Imbalanced Classification Problems With Support Vector Machines via Evolutionary Bilevel Optimization. (arXiv:2204.10231v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frigo_O/0/1/0/all/0/1\">Oriel Frigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Gaffe_L/0/1/0/all/0/1\">Lucien Martin-Gaff&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wacongne_C/0/1/0/all/0/1\">Catherine Wacongne</a>",
          "description": "In this paper we present a new approach for feature fusion between RGB and\nLWIR Thermal images for the task of semantic segmentation for driving\nperception. We propose DooDLeNet, a double DeepLab architecture with\nspecialized encoder-decoders for thermal and color modalities and a shared\ndecoder for final segmentation. We combine two strategies for feature fusion:\nconfidence weighting and correlation weighting. We report state-of-the-art mean\nIoU results on the MF dataset.",
          "link": "http://arxiv.org/abs/2204.10266",
          "publishedOn": "2022-04-23T00:53:50.242Z",
          "wordCount": 523,
          "title": "DooDLeNet: Double DeepLab Enhanced Feature Fusion for Thermal-color Semantic Segmentation. (arXiv:2204.10266v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.08916",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ding_K/0/1/0/all/0/1\">Kexin Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_M/0/1/0/all/0/1\">Mu Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1\">Zichen Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qiao Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arnold_C/0/1/0/all/0/1\">Corey W. Arnold</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Metaxas_D/0/1/0/all/0/1\">Dimitri N. Metaxas</a>",
          "description": "Image-based characterization and disease understanding involve integrative\nanalysis of morphological, spatial, and topological information across\nbiological scales. The development of graph convolutional networks (GCNs) has\ncreated the opportunity to address this information complexity via graph-driven\narchitectures, since GCNs can perform feature aggregation, interaction, and\nreasoning with remarkable flexibility and efficiency. These GCNs capabilities\nhave spawned a new wave of research in medical imaging analysis with the\noverarching goal of improving quantitative disease understanding, monitoring,\nand diagnosis. Yet daunting challenges remain for designing the important\nimage-to-graph transformation for multi-modality medical imaging and gaining\ninsights into model interpretation and enhanced clinical decision support. In\nthis review, we present recent GCNs developments in the context of medical\nimage analysis including imaging data from radiology and histopathology. We\ndiscuss the fast-growing use of graph network architectures in medical image\nanalysis to improve disease diagnosis and patient outcomes in clinical\npractice. To foster cross-disciplinary research, we present GCNs technical\nadvancements, emerging medical applications, identify common challenges in the\nuse of image-based GCNs and their extensions in model interpretation,\nlarge-scale benchmarks that promise to transform the scope of medical image\nstudies and related graph-driven medical research.",
          "link": "http://arxiv.org/abs/2202.08916",
          "publishedOn": "2022-04-23T00:53:50.227Z",
          "wordCount": 688,
          "title": "Graph Convolutional Networks for Multi-modality Medical Imaging: Methods, Architectures, and Clinical Applications. (arXiv:2202.08916v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parker_J/0/1/0/all/0/1\">Julian D. Parker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlecht_S/0/1/0/all/0/1\">Sebastian J. Schlecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabenstein_R/0/1/0/all/0/1\">Rudolf Rabenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_M/0/1/0/all/0/1\">Maximilian Sch&#xe4;fer</a>",
          "description": "Discrete-time modeling of acoustic, mechanical and electrical systems is a\nprominent topic in the musical signal processing literature. Such models are\nmostly derived by discretizing a mathematical model, given in terms of ordinary\nor partial differential equations, using established techniques. Recent work\nhas applied the techniques of machine-learning to construct such models\nautomatically from data for the case of systems which have lumped states\ndescribed by scalar values, such as electrical circuits. In this work, we\nexamine how similar techniques are able to construct models of systems which\nhave spatially distributed rather than lumped states. We describe several novel\nrecurrent neural network structures, and show how they can be thought of as an\nextension of modal techniques. As a proof of concept, we generate synthetic\ndata for three physical systems and show that the proposed network structures\ncan be trained with this data to reproduce the behavior of these systems.",
          "link": "http://arxiv.org/abs/2204.10125",
          "publishedOn": "2022-04-23T00:53:50.219Z",
          "wordCount": null,
          "title": "Physical Modeling using Recurrent Neural Networks with Fast Convolutional Layers. (arXiv:2204.10125v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10212",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Juhwan Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Justin N. Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharaibeh_Y/0/1/0/all/0/1\">Yazan Gharaibeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zimin_V/0/1/0/all/0/1\">Vladislav N. Zimin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dallan_L/0/1/0/all/0/1\">Luis A. P. Dallan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pereira_G/0/1/0/all/0/1\">Gabriel T. R. Pereira</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vergara_Martel_A/0/1/0/all/0/1\">Armando Vergara-Martel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kolluru_C/0/1/0/all/0/1\">Chaitanya Kolluru</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hoori_A/0/1/0/all/0/1\">Ammar Hoori</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bezerra_H/0/1/0/all/0/1\">Hiram G. Bezerra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wilson_D/0/1/0/all/0/1\">David L. Wilson</a>",
          "description": "Compared with other imaging modalities, intravascular optical coherence\ntomography (IVOCT) has significant advantages for guiding percutaneous coronary\ninterventions. To aid IVOCT research studies, we developed the Optical\nCoherence TOmography PlaqUe and Stent (OCTOPUS) analysis software. To automate\nimage analysis results, the software includes several important algorithmic\nsteps: pre-processing, deep learning plaque segmentation, machine learning\nidentification of stent struts, and registration of pullbacks. Interactive\nvisualization and manual editing of segmentations were included in the\nsoftware. Quantifications include stent deployment characteristics (e.g., stent\nstrut malapposition), strut level analysis, calcium angle, and calcium\nthickness measurements. Interactive visualizations include (x,y) anatomical, en\nface, and longitudinal views with optional overlays. Underlying plaque\nsegmentation algorithm yielded excellent pixel-wise results (86.2% sensitivity\nand 0.781 F1 score). Using OCTOPUS on 34 new pullbacks, we determined that\nfollowing automated segmentation, only 13% and 23% of frames needed any manual\ntouch up for detailed lumen and calcification labeling, respectively. Only up\nto 3.8% of plaque pixels were modified, leading to an average editing time of\nonly 7.5 seconds/frame, an approximately 80% reduction compared to manual\nanalysis. Regarding stent analysis, sensitivity and precision were both greater\nthan 90%, and each strut was successfully classified as either covered or\nuncovered with high sensitivity (94%) and specificity (90%). We introduced and\nevaluated the clinical application of a highly automated software package,\nOCTOPUS, for quantitative plaque and stent analysis in IVOCT images. The\nsoftware is currently used as an offline tool for research purposes; however,\nthe software's embedded algorithms may also be useful for real-time treatment\nplanning.",
          "link": "http://arxiv.org/abs/2204.10212",
          "publishedOn": "2022-04-23T00:53:50.218Z",
          "wordCount": 734,
          "title": "OCTOPUS -- optical coherence tomography plaque and stent analysis software. (arXiv:2204.10212v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Hao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabi_W/0/1/0/all/0/1\">Wassim Jabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Juyong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Bailin Deng</a>",
          "description": "The freeform architectural modeling process often involves two important\nstages: concept design and digital modeling. In the first stage, architects\nusually sketch the overall 3D shape and the panel layout on a physical or\ndigital paper briefly. In the second stage, a digital 3D model is created using\nthe sketch as a reference. The digital model needs to incorporate geometric\nrequirements for its components, such as the planarity of panels due to\nconsideration of construction costs, which can make the modeling process more\nchallenging. In this work, we present a novel sketch-based system to bridge the\nconcept design and digital modeling of freeform roof-like shapes represented as\nplanar quadrilateral (PQ) meshes. Our system allows the user to sketch the\nsurface boundary and contour lines under axonometric projection and supports\nthe sketching of occluded regions. In addition, the user can sketch feature\nlines to provide directional guidance to the PQ mesh layout. Given the 2D\nsketch input, we propose a deep neural network to infer in real-time the\nunderlying surface shape along with a dense conjugate direction field, both of\nwhich are used to extract the final PQ mesh. To train and validate our network,\nwe generate a large synthetic dataset that mimics architect sketching of\nfreeform quadrilateral patches. The effectiveness and usability of our system\nare demonstrated with quantitative and qualitative evaluation as well as user\nstudies.",
          "link": "http://arxiv.org/abs/2201.09367",
          "publishedOn": "2022-04-23T00:53:50.210Z",
          "wordCount": 715,
          "title": "Sketch2PQ: Freeform Planar Quadrilateral Mesh Design via a Single Sketch. (arXiv:2201.09367v3 [cs.GR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09792",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rowe_F/0/1/0/all/0/1\">Francisco Rowe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mahony_M/0/1/0/all/0/1\">Michael Mahony</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tao_S/0/1/0/all/0/1\">Sui Tao</a>",
          "description": "Given an increasingly volatile climate, the relationship between weather and\ntransit ridership has drawn increasing interest. However, challenges stemming\nfrom spatio-temporal dependency and non-stationarity have not been fully\naddressed in modelling and predicting transit ridership under the influence of\nweather conditions especially with the traditional statistical approaches.\nDrawing on three-month smart card data in Brisbane, Australia, this research\nadopts and assesses a suite of machine-learning algorithms, i.e., random\nforest, eXtreme Gradient Boosting (XGBoost) and Tweedie XGBoost, to model and\npredict near real-time bus ridership in relation to sudden change of weather\nconditions. The study confirms that there indeed exists a significant level of\nspatio-temporal variability of weather-ridership relationship, which produces\nequally dynamic patterns of prediction errors. Further comparison of model\nperformance suggests that Tweedie XGBoost outperforms the other two\nmachine-learning algorithms in generating overall more accurate prediction\noutcomes in space and time. Future research may advance the current study by\ndrawing on larger data sets and applying more advanced machine and\ndeep-learning approaches to provide more enhanced evidence for real-time\noperation of transit systems.",
          "link": "http://arxiv.org/abs/2204.09792",
          "publishedOn": "2022-04-23T00:53:50.203Z",
          "wordCount": 623,
          "title": "Assessing Machine Learning Algorithms for Near-Real Time Bus Ridership Prediction During Extreme Weather. (arXiv:2204.09792v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10242",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sadjadi_S/0/1/0/all/0/1\">Seyed Omid Sadjadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greenberg_C/0/1/0/all/0/1\">Craig Greenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singer_E/0/1/0/all/0/1\">Elliot Singer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mason_L/0/1/0/all/0/1\">Lisa Mason</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reynolds_D/0/1/0/all/0/1\">Douglas Reynolds</a>",
          "description": "The 2021 Speaker Recognition Evaluation (SRE21) was the latest cycle of the\nongoing evaluation series conducted by the U.S. National Institute of Standards\nand Technology (NIST) since 1996. It was the second large-scale multimodal\nspeaker/person recognition evaluation organized by NIST (the first one being\nSRE19). Similar to SRE19, it featured two core evaluation tracks, namely audio\nand audio-visual, as well as an optional visual track. In addition to offering\nfixed and open training conditions, it also introduced new challenges for the\ncommunity, thanks to a new multimodal (i.e., audio, video, and selfie images)\nand multilingual (i.e., with multilingual speakers) corpus, termed WeCanTalk,\ncollected outside North America by the Linguistic Data Consortium (LDC). These\nchallenges included: 1) trials (target and non-target) with enrollment and test\nsegments originating from different domains (i.e., telephony versus video), and\n2) trials (target and non-target) with enrollment and test segments spoken in\ndifferent languages (i.e., cross-lingual trials). This paper presents an\noverview of SRE21 including the tasks, performance metric, data, evaluation\nprotocol, results and system performance analyses. A total of 23 organizations\n(forming 15 teams) from academia and industry participated in SRE21 and\nsubmitted 158 valid system outputs. Evaluation results indicate: audio-visual\nfusion produce substantial gains in performance over audio-only or visual-only\nsystems; top performing speaker and face recognition systems exhibited\ncomparable performance under the matched domain conditions present in this\nevaluation; and, the use of complex neural network architectures (e.g., ResNet)\nalong with angular losses with margin, data augmentation, as well as long\nduration fine-tuning contributed to notable performance improvements for the\naudio-only speaker recognition task.",
          "link": "http://arxiv.org/abs/2204.10242",
          "publishedOn": "2022-04-23T00:53:50.182Z",
          "wordCount": 713,
          "title": "The 2021 NIST Speaker Recognition Evaluation. (arXiv:2204.10242v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08816",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Slijepcevic_I/0/1/0/all/0/1\">Inigo V. Slijepcevic</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Scaife_A/0/1/0/all/0/1\">Anna M. M. Scaife</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Walmsley_M/0/1/0/all/0/1\">Mike Walmsley</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bowles_M/0/1/0/all/0/1\">Micah Bowles</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wong_I/0/1/0/all/0/1\">Ivy Wong</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Shabala_S/0/1/0/all/0/1\">Stanislav S. Shabala</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Tang_H/0/1/0/all/0/1\">Hongming Tang</a>",
          "description": "In this work we examine the classification accuracy and robustness of a\nstate-of-the-art semi-supervised learning (SSL) algorithm applied to the\nmorphological classification of radio galaxies. We test if SSL with fewer\nlabels can achieve test accuracies comparable to the supervised\nstate-of-the-art and whether this holds when incorporating previously unseen\ndata. We find that for the radio galaxy classification problem considered, SSL\nprovides additional regularisation and outperforms the baseline test accuracy.\nHowever, in contrast to model performance metrics reported on computer science\nbenchmarking data-sets, we find that improvement is limited to a narrow range\nof label volumes, with performance falling off rapidly at low label volumes.\nAdditionally, we show that SSL does not improve model calibration, regardless\nof whether classification is improved. Moreover, we find that when different\nunderlying catalogues drawn from the same radio survey are used to provide the\nlabelled and unlabelled data-sets required for SSL, a significant drop in\nclassification performance is observered, highlighting the difficulty of\napplying SSL techniques under dataset shift. We show that a class-imbalanced\nunlabelled data pool negatively affects performance through prior probability\nshift, which we suggest may explain this performance drop, and that using the\nFrechet Distance between labelled and unlabelled data-sets as a measure of\ndata-set shift can provide a prediction of model performance, but that for\ntypical radio galaxy data-sets with labelled sample volumes of O(1000), the\nsample variance associated with this technique is high and the technique is in\ngeneral not sufficiently robust to replace a train-test cycle.",
          "link": "http://arxiv.org/abs/2204.08816",
          "publishedOn": "2022-04-23T00:53:50.175Z",
          "wordCount": 749,
          "title": "Radio Galaxy Zoo: Using semi-supervised learning to leverage large unlabelled data-sets for radio galaxy classification under data-set shift. (arXiv:2204.08816v3 [astro-ph.GA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11758",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Reisinger_C/0/1/0/all/0/1\">Christoph Reisinger</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stockinger_W/0/1/0/all/0/1\">Wolfgang Stockinger</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1\">Yufei Zhang</a>",
          "description": "Despite its popularity in the reinforcement learning community, a provably\nconvergent policy gradient method for general continuous space-time stochastic\ncontrol problems has been elusive. This paper closes the gap by proposing a\nproximal gradient algorithm for feedback controls of finite-time horizon\nstochastic control problems. The state dynamics are continuous time nonlinear\ndiffusions with controlled drift and possibly degenerate noise, and the\nobjectives are nonconvex in the state and nonsmooth in the control. We prove\nunder suitable conditions that the algorithm converges linearly to a stationary\npoint of the control problem, and is stable with respect to policy updates by\napproximate gradient steps. The convergence result justifies the recent\nreinforcement learning heuristics that adding entropy regularization or a\nfictitious discount factor to the optimization objective accelerates the\nconvergence of policy gradient methods. The proof exploits careful regularity\nestimates of backward stochastic differential equations.",
          "link": "http://arxiv.org/abs/2203.11758",
          "publishedOn": "2022-04-23T00:53:50.161Z",
          "wordCount": 625,
          "title": "Linear convergence of a policy gradient method for finite horizon continuous time stochastic control problems. (arXiv:2203.11758v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clarke_R/0/1/0/all/0/1\">Ross M. Clarke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oldewage_E/0/1/0/all/0/1\">Elre T. Oldewage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>",
          "description": "Machine learning training methods depend plentifully and intricately on\nhyperparameters, motivating automated strategies for their optimisation. Many\nexisting algorithms restart training for each new hyperparameter choice, at\nconsiderable computational cost. Some hypergradient-based one-pass methods\nexist, but these either cannot be applied to arbitrary optimiser\nhyperparameters (such as learning rates and momenta) or take several times\nlonger to train than their base models. We extend these existing methods to\ndevelop an approximate hypergradient-based hyperparameter optimiser which is\napplicable to any continuous hyperparameter appearing in a differentiable model\nweight update, yet requires only one training episode, with no restarts. We\nalso provide a motivating argument for convergence to the true hypergradient,\nand perform tractable gradient-based optimisation of independent learning rates\nfor each model parameter. Our method performs competitively from varied random\nhyperparameter initialisations on several UCI datasets and Fashion-MNIST (using\na one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a\nResNet-18), in time only 2-3x greater than vanilla training.",
          "link": "http://arxiv.org/abs/2110.10461",
          "publishedOn": "2022-04-23T00:53:50.130Z",
          "wordCount": null,
          "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation. (arXiv:2110.10461v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11438",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Leoni_M/0/1/0/all/0/1\">Marco Leoni</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ishida_E/0/1/0/all/0/1\">Emille E. O. Ishida</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Peloton_J/0/1/0/all/0/1\">Julien Peloton</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Moller_A/0/1/0/all/0/1\">Anais M&#xf6;ller</a>",
          "description": "We describe how the Fink broker early supernova Ia classifier optimizes its\nML classifications by employing an active learning (AL) strategy. We\ndemonstrate the feasibility of implementation of such strategies in the current\nZwicky Transient Facility (ZTF) public alert data stream. We compare the\nperformance of two AL strategies: uncertainty sampling and random sampling. Our\npipeline consists of 3 stages: feature extraction, classification and learning\nstrategy. Starting from an initial sample of 10 alerts (5 SN Ia and 5 non-Ia),\nwe let the algorithm identify which alert should be added to the training\nsample. The system is allowed to evolve through 300 iterations. Our data set\nconsists of 23 840 alerts from the ZTF with confirmed classification via\ncross-match with SIMBAD database and the Transient name server (TNS), 1 600 of\nwhich were SNe Ia (1 021 unique objects). The data configuration, after the\nlearning cycle was completed, consists of 310 alerts for training and 23 530\nfor testing. Averaging over 100 realizations, the classifier achieved 89%\npurity and 54% efficiency. From 01/November/2020 to 31/October/2021 Fink has\napplied its early supernova Ia module to the ZTF stream and communicated\npromising SN Ia candidates to the TNS. From the 535 spectroscopically\nclassified Fink candidates, 459 (86%) were proven to be SNe Ia. Our results\nconfirm the effectiveness of active learning strategies for guiding the\nconstruction of optimal training samples for astronomical classifiers. It\ndemonstrates in real data that the performance of learning algorithms can be\nhighly improved without the need of extra computational resources or\noverwhelmingly large training samples. This is, to our knowledge, the first\napplication of AL to real alerts data.",
          "link": "http://arxiv.org/abs/2111.11438",
          "publishedOn": "2022-04-23T00:53:50.129Z",
          "wordCount": null,
          "title": "Fink: early supernovae Ia classification using active learning. (arXiv:2111.11438v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00597",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Tsai_S/0/1/0/all/0/1\">Sun-Ting Tsai</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Fields_E/0/1/0/all/0/1\">Eric Fields</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Xu_Y/0/1/0/all/0/1\">Yijia Xu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kuo_E/0/1/0/all/0/1\">En-Jui Kuo</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tiwary_P/0/1/0/all/0/1\">Pratyush Tiwary</a>",
          "description": "Recurrent neural networks have seen widespread use in modeling dynamical\nsystems in varied domains such as weather prediction, text prediction and\nseveral others. Often one wishes to supplement the experimentally observed\ndynamics with prior knowledge or intuition about the system. While the\nrecurrent nature of these networks allows them to model arbitrarily long\nmemories in the time series used in training, it makes it harder to impose\nprior knowledge or intuition through generic constraints. In this work, we\npresent a path sampling approach based on principle of Maximum Caliber that\nallows us to include generic thermodynamic or kinetic constraints into\nrecurrent neural networks. We show the method here for a widely used type of\nrecurrent neural network known as long short-term memory network in the context\nof supplementing time series collected from different application domains.\nThese include classical Molecular Dynamics of a protein and Monte Carlo\nsimulations of an open quantum system continuously losing photons to the\nenvironment and displaying Rabi oscillations. Our method can be easily\ngeneralized to other generative artificial intelligence models and to generic\ntime series in different areas of physical and social sciences, where one\nwishes to supplement limited data with intuition or theory based corrections.",
          "link": "http://arxiv.org/abs/2203.00597",
          "publishedOn": "2022-04-23T00:53:50.129Z",
          "wordCount": null,
          "title": "Path sampling of recurrent neural networks by incorporating known physics. (arXiv:2203.00597v2 [cond-mat.dis-nn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "We study the theory of neural network (NN) from the lens of classical\nnonparametric regression problems with a focus on NN's ability to adaptively\nestimate functions with heterogeneous smoothness -- a property of functions in\nBesov or Bounded Variation (BV) classes. Existing work on this problem requires\ntuning the NN architecture based on the function spaces and sample sizes. We\nconsider a \"Parallel NN\" variant of deep ReLU networks and show that the\nstandard weight decay is equivalent to promoting the $\\ell_p$-sparsity\n($0<p<1$) of the coefficient vector of an end-to-end learned function bases,\ni.e., a dictionary. Using this equivalence, we further establish that by tuning\nonly the weight decay, such Parallel NN achieves an estimation error\narbitrarily close to the minimax rates for both the Besov and BV classes.\nNotably, it gets exponentially closer to minimax optimal as the NN gets deeper.\nOur research sheds new lights on why depth matters and how NNs are more\npowerful than kernel methods.",
          "link": "http://arxiv.org/abs/2204.09664",
          "publishedOn": "2022-04-23T00:53:50.129Z",
          "wordCount": null,
          "title": "Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?. (arXiv:2204.09664v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.13629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1\">Pengfei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xinghua Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_Y/0/1/0/all/0/1\">Yew Soon Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>",
          "description": "Feature-based transfer is one of the most effective methodologies for\ntransfer learning. Existing studies usually assume that the learned new feature\nrepresentation is \\emph{domain-invariant}, and thus train a transfer model\n$\\mathcal{M}$ on the source domain. In this paper, we consider a more realistic\nscenario where the new feature representation is suboptimal and small\ndivergence still exists across domains. We propose a new transfer model called\nRandomized Transferable Machine (RTM) to handle such small divergence of\ndomains. Specifically, we work on the new source and target data learned from\nexisting feature-based transfer methods. The key idea is to enlarge source\ntraining data populations by randomly corrupting the new source data using some\nnoises, and then train a transfer model $\\widetilde{\\mathcal{M}}$ that performs\nwell on all the corrupted source data populations. In principle, the more\ncorruptions are made, the higher the probability of the new target data can be\ncovered by the constructed source data populations, and thus better transfer\nperformance can be achieved by $\\widetilde{\\mathcal{M}}$. An ideal case is with\ninfinite corruptions, which however is infeasible in reality. We develop a\nmarginalized solution that enables to train an $\\widetilde{\\mathcal{M}}$\nwithout conducting any corruption but equivalent to be trained using infinite\nsource noisy data populations. We further propose two instantiations of\n$\\widetilde{\\mathcal{M}}$, which theoretically show the transfer superiority\nover the conventional transfer model $\\mathcal{M}$. More importantly, both\ninstantiations have closed-form solutions, leading to a fast and efficient\ntraining process. Experiments on various real-world transfer tasks show that\nRTM is a promising transfer model.",
          "link": "http://arxiv.org/abs/2011.13629",
          "publishedOn": "2022-04-23T00:53:50.128Z",
          "wordCount": null,
          "title": "An Improved Transfer Model: Randomized Transferable Machine. (arXiv:2011.13629v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.03113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yayong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Weitao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Richard Yi Da Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miao Zhang</a>",
          "description": "Graph convolutional networks (GCNs) and their variants have achieved great\nsuccess in dealing with graph-structured data. Nevertheless, it is well known\nthat deep GCNs suffer from the over-smoothing problem, where node\nrepresentations tend to be indistinguishable as more layers are stacked up. The\ntheoretical research to date on deep GCNs has focused primarily on expressive\npower rather than trainability, an optimization perspective. Compared to\nexpressivity, trainability attempts to address a more fundamental question:\nGiven a sufficiently expressive space of models, can we successfully find a\ngood solution via gradient descent-based optimizers? This work fills this gap\nby exploiting the Graph Neural Tangent Kernel (GNTK), which governs the\noptimization trajectory under gradient descent for wide GCNs. We formulate the\nasymptotic behaviors of GNTK in the large depth, which enables us to reveal the\ndropping trainability of wide and deep GCNs at an exponential rate in the\noptimization process. Additionally, we extend our theoretical framework to\nanalyze residual connection-based techniques, which are found to be merely able\nto mitigate the exponential decay of trainability mildly. Inspired by our\ntheoretical insights on trainability, we propose Critical DropEdge, a\nconnectivity-aware and graph-adaptive sampling method, to alleviate the\nexponential decay problem more fundamentally. Experimental evaluation\nconsistently confirms using our proposed method can achieve better results\ncompared to relevant counterparts with both infinite-width and finite-width.",
          "link": "http://arxiv.org/abs/2103.03113",
          "publishedOn": "2022-04-23T00:53:50.128Z",
          "wordCount": null,
          "title": "Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective. (arXiv:2103.03113v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.06393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tuan Anh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_K/0/1/0/all/0/1\">Katherine M. Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewitt_L/0/1/0/all/0/1\">Luke Hewitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellis_K/0/1/0/all/0/1\">Kevin Ellis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_N/0/1/0/all/0/1\">N. Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1\">Samuel J. Gershman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>",
          "description": "Modeling complex phenomena typically involves the use of both discrete and\ncontinuous variables. Such a setting applies across a wide range of problems,\nfrom identifying trends in time-series data to performing effective\ncompositional scene understanding in images. Here, we propose Hybrid Memoised\nWake-Sleep (HMWS), an algorithm for effective inference in such hybrid\ndiscrete-continuous models. Prior approaches to learning suffer as they need to\nperform repeated expensive inner-loop discrete inference. We build on a recent\napproach, Memoised Wake-Sleep (MWS), which alleviates part of the problem by\nmemoising discrete variables, and extend it to allow for a principled and\neffective way to handle continuous variables by learning a separate recognition\nmodel used for importance-sampling based approximate inference and\nmarginalization. We evaluate HMWS in the GP-kernel learning and 3D scene\nunderstanding domains, and show that it outperforms current state-of-the-art\ninference methods.",
          "link": "http://arxiv.org/abs/2107.06393",
          "publishedOn": "2022-04-23T00:53:50.128Z",
          "wordCount": null,
          "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface. (arXiv:2107.06393v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10268",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1\">Matthias C. Caro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ezzell_N/0/1/0/all/0/1\">Nicholas Ezzell</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gibbs_J/0/1/0/all/0/1\">Joe Gibbs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1\">Andrew T. Sornborger</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Holmes_Z/0/1/0/all/0/1\">Zo&#xeb; Holmes</a>",
          "description": "Generalization bounds are a critical tool to assess the training data\nrequirements of Quantum Machine Learning (QML). Recent work has established\nguarantees for in-distribution generalization of quantum neural networks\n(QNNs), where training and testing data are assumed to be drawn from the same\ndata distribution. However, there are currently no results on\nout-of-distribution generalization in QML, where we require a trained model to\nperform well even on data drawn from a distribution different from the training\ndistribution. In this work, we prove out-of-distribution generalization for the\ntask of learning an unknown unitary using a QNN and for a broad class of\ntraining and testing distributions. In particular, we show that one can learn\nthe action of a unitary on entangled states using only product state training\ndata. We numerically illustrate this by showing that the evolution of a\nHeisenberg spin chain can be learned using only product training states. Since\nproduct states can be prepared using only single-qubit gates, this advances the\nprospects of learning quantum dynamics using near term quantum computers and\nquantum experiments, and further opens up new methods for both the classical\nand quantum compilation of quantum circuits.",
          "link": "http://arxiv.org/abs/2204.10268",
          "publishedOn": "2022-04-23T00:53:50.127Z",
          "wordCount": 656,
          "title": "Out-of-distribution generalization for learning quantum dynamics. (arXiv:2204.10268v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Im_H/0/1/0/all/0/1\">Hyeon-Seong Im</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Si-Hyeon Lee</a>",
          "description": "For multi-band wireless ad hoc networks of multiple users, an anti-jamming\ngame between the users and a jammer is studied. In this game, the users (resp.\njammer) want to maximize (resp. minimize) the expected rewards of the users\ntaking into account various factors such as communication rate, hopping cost,\nand jamming loss. We analyze the arms race of the game and derive an optimal\nfrequency hopping policy at each stage of the arms race based on the Markov\ndecision process (MDP). It is analytically shown that the arms race reaches an\nequilibrium after a few rounds, and a frequency hopping policy and a jamming\nstrategy at the equilibrium are characterized. We propose two kinds of\ncollision avoidance protocols to ensure that at most one user communicates in\neach frequency band, and provide various numerical results that show the\neffects of the reward parameters and collision avoidance protocols on the\noptimal frequency hopping policy and the expected rewards at the equilibrium.\nMoreover, we discuss about equilibria for the case where the jammer adopts some\nunpredictable jamming strategies.",
          "link": "http://arxiv.org/abs/2111.11178",
          "publishedOn": "2022-04-23T00:53:49.552Z",
          "wordCount": null,
          "title": "Anti-Jamming Games in Multi-Band Wireless Ad Hoc Networks. (arXiv:2111.11178v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sroka_P/0/1/0/all/0/1\">Pawe\\{l} Sroka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kliks_A/0/1/0/all/0/1\">Adrian Kliks</a>",
          "description": "Reliable wireless communication between the autonomously driving cars is one\nof the fundamental needs for guaranteeing passenger safety and comfort.\nHowever, when the number of communicating cars increases, the transmission\nquality may be significantly degraded due to too high occupancy radio of the\nused frequency band. In this paper, we concentrate on the autonomous\nvehicle-platooning use-case, where intra-platoon communication is done in the\ndynamically selected frequency band, other than nominally devoted for such\npurposes. The carrier selection is done in a flexible manner with the support\nof the context database located at the roadside unit (edge of wireless\ncommunication infrastructure). However, as the database delivers only context\ninformation to the platoons' leaders, the final decision is made separately by\nthe individual platoons, following the suggestions made by the artificial\nintelligence algorithms. In this work, we concentrate on a lightweight\nQ-learning solution, that could be successfully implemented in each car for\ndynamic channel selection.",
          "link": "http://arxiv.org/abs/2204.10179",
          "publishedOn": "2022-04-23T00:53:49.515Z",
          "wordCount": null,
          "title": "Distributed Learning for Vehicular Dynamic Spectrum Access in Autonomous Driving. (arXiv:2204.10179v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pasen_M/0/1/0/all/0/1\">Martin Pa&#x161;en</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boza_V/0/1/0/all/0/1\">Vladim&#xed;r Bo&#x17e;a</a>",
          "description": "We propose a simple scheme for merging two neural networks trained with\ndifferent starting initialization into a single one with the same size as the\noriginal ones. We do this by carefully selecting channels from each input\nnetwork. Our procedure might be used as a finalization step after one tries\nmultiple starting seeds to avoid an unlucky one. We also show that training two\nnetworks and merging them leads to better performance than training a single\nnetwork for an extended period of time.\n\nAvailability: https://github.com/fmfi-compbio/neural-network-merging",
          "link": "http://arxiv.org/abs/2204.09973",
          "publishedOn": "2022-04-23T00:53:49.503Z",
          "wordCount": null,
          "title": "Merging of neural networks. (arXiv:2204.09973v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.13799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_D/0/1/0/all/0/1\">Donghwee Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Junseok Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hayeong Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_M/0/1/0/all/0/1\">Minjae Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Injung Kim</a>",
          "description": "We propose OUR-GAN, the first one-shot ultra-high-resolution (UHR) image\nsynthesis framework that generates non-repetitive images with 4K or higher\nresolution from a single training image. OUR-GAN generates a visually coherent\nimage at low resolution and then gradually increases the resolution by\nsuper-resolution. Since OUR-GAN learns from a real UHR image, it can synthesize\nlarge-scale shapes with fine details while maintaining long-range coherence,\nwhich is difficult with conventional generative models that generate large\nimages based on the patch distribution learned from relatively small images.\nOUR-GAN applies seamless subregion-wise super-resolution that synthesizes 4k or\nhigher UHR images with limited memory, preventing discontinuity at the\nboundary. Additionally, OUR-GAN improves visual coherence maintaining diversity\nby adding vertical positional embeddings to the feature maps. In experiments on\nthe ST4K and RAISE datasets, OUR-GAN exhibited improved fidelity, visual\ncoherency, and diversity compared with existing methods. The synthesized images\nare presented at https://anonymous-62348.github.io.",
          "link": "http://arxiv.org/abs/2202.13799",
          "publishedOn": "2022-04-23T00:53:49.497Z",
          "wordCount": null,
          "title": "OUR-GAN: One-shot Ultra-high-Resolution Generative Adversarial Networks. (arXiv:2202.13799v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hammar_K/0/1/0/all/0/1\">Kim Hammar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadler_R/0/1/0/all/0/1\">Rolf Stadler</a>",
          "description": "We present a system for interactive examination of learned security policies.\nIt allows a user to traverse episodes of Markov decision processes in a\ncontrolled manner and to track the actions triggered by security policies.\nSimilar to a software debugger, a user can continue or or halt an episode at\nany time step and inspect parameters and probability distributions of interest.\nThe system enables insight into the structure of a given policy and in the\nbehavior of a policy in edge cases. We demonstrate the system with a network\nintrusion use case. We examine the evolution of an IT infrastructure's state\nand the actions prescribed by security policies while an attack occurs. The\npolicies for the demonstration have been obtained through a reinforcement\nlearning approach that includes a simulation system where policies are\nincrementally learned and an emulation system that produces statistics that\ndrive the simulation runs.",
          "link": "http://arxiv.org/abs/2204.01126",
          "publishedOn": "2022-04-23T00:53:49.458Z",
          "wordCount": null,
          "title": "A System for Interactive Examination of Learned Security Policies. (arXiv:2204.01126v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bardou_A/0/1/0/all/0/1\">Anthony Bardou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Begin_T/0/1/0/all/0/1\">Thomas Begin</a>",
          "description": "WLANs, which have overtaken wired networks to become the primary means of\nconnecting devices to the Internet, are prone to performance issues due to the\nscarcity of space in the radio spectrum. As a response, IEEE 802.11ax and\nsubsequent amendments aim at increasing the spatial reuse of a radio channel by\nallowing the dynamic update of two key parameters in wireless transmission: the\ntransmission power (TX_POWER) and the sensitivity threshold (OBSS_PD). In this\npaper, we present INSPIRE, a distributed solution performing local Bayesian\noptimizations based on Gaussian processes to improve the spatial reuse in\nWLANs. INSPIRE makes no explicit assumptions about the topology of WLANs and\nfavors altruistic behaviors of the access points, leading them to find adequate\nconfigurations of their TX_POWER and OBSS_PD parameters for the \"greater good\"\nof the WLANs. We demonstrate the superiority of INSPIRE over other\nstate-of-the-art strategies using the ns-3 simulator and two examples inspired\nby real-life deployments of dense WLANs. Our results show that, in only a few\nseconds, INSPIRE is able to drastically increase the quality of service of\noperational WLANs by improving their fairness and throughput.",
          "link": "http://arxiv.org/abs/2204.10184",
          "publishedOn": "2022-04-23T00:53:49.403Z",
          "wordCount": null,
          "title": "INSPIRE: Distributed Bayesian Optimization for ImproviNg SPatIal REuse in Dense WLANs. (arXiv:2204.10184v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yuexin Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yuchen Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_D/0/1/0/all/0/1\">Ding Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1\">Wei Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tiantian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qingqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenmao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tianqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_K/0/1/0/all/0/1\">Kim-Kwang Raymond Choo</a>",
          "description": "Cryptocurrencies are no longer just the preferred option for cybercriminal\nactivities on darknets, due to the increasing adoption in mainstream\napplications. This is partly due to the transparency associated with the\nunderpinning ledgers, where any individual can access the record of a\ntransaction record on the public ledger. In this paper, we build a dataset\ncomprising Bitcoin transactions between 12 July 2019 and 26 May 2021. This\ndataset (hereafter referred to as BABD-13) contains 13 types of Bitcoin\naddresses, 5 categories of indicators with 148 features, and 544,462 labeled\ndata. We then use our proposed dataset on common machine learning models,\nnamely: k-nearest neighbors algorithm, decision tree, random forest, multilayer\nperceptron, and XGBoost. The results show that the accuracy rates of these\nmachine learning models on our proposed dataset are between 93.24% and 96.71%.\nWe also analyze the proposed features and their relationships from the\nexperiments, and propose a k-hop subgraph generation algorithm to extract a\nk-hop subgraph from the entire Bitcoin transaction graph constructed by the\ndirected heterogeneous multigraph starting from a specific Bitcoin address node\n(e.g., a known transaction associated with a criminal investigation).",
          "link": "http://arxiv.org/abs/2204.05746",
          "publishedOn": "2022-04-23T00:53:49.401Z",
          "wordCount": null,
          "title": "BABD: A Bitcoin Address Behavior Dataset for Address Behavior Pattern Analysis. (arXiv:2204.05746v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.13445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iofinova_E/0/1/0/all/0/1\">Eugenia Iofinova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peste_A/0/1/0/all/0/1\">Alexandra Peste</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtz_M/0/1/0/all/0/1\">Mark Kurtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>",
          "description": "Transfer learning is a classic paradigm by which models pretrained on large\n\"upstream\" datasets are adapted to yield good results on \"downstream\"\nspecialized datasets. Generally, more accurate models on the \"upstream\" dataset\ntend to provide better transfer accuracy \"downstream\". In this work, we perform\nan in-depth investigation of this phenomenon in the context of convolutional\nneural networks (CNNs) trained on the ImageNet dataset, which have been pruned\n- that is, compressed by sparsifying their connections. We consider transfer\nusing unstructured pruned models obtained by applying several state-of-the-art\npruning methods, including magnitude-based, second-order, re-growth,\nlottery-ticket, and regularization approaches, in the context of twelve\nstandard transfer tasks. In a nutshell, our study shows that sparse models can\nmatch or even outperform the transfer performance of dense models, even at high\nsparsities, and, while doing so, can lead to significant inference and even\ntraining speedups. At the same time, we observe and analyze significant\ndifferences in the behaviour of different pruning methods.",
          "link": "http://arxiv.org/abs/2111.13445",
          "publishedOn": "2022-04-23T00:53:49.387Z",
          "wordCount": null,
          "title": "How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v5 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.07295",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saito_Y/0/1/0/all/0/1\">Yuta Saito</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nomura_M/0/1/0/all/0/1\">Masahiro Nomura</a>",
          "description": "We study offline recommender learning from explicit rating feedback in the\npresence of selection bias. A current promising solution for the bias is the\ninverse propensity score (IPS) estimation. However, the performance of existing\npropensity-based methods can suffer significantly from the propensity\nestimation bias. In fact, most of the previous IPS-based methods require some\namount of missing-completely-at-random (MCAR) data to accurately estimate the\npropensity. This leads to a critical self-contradiction; IPS is ineffective\nwithout MCAR data, even though it originally aims to learn recommenders from\nonly missing-not-at-random feedback. To resolve this propensity contradiction,\nwe derive a propensity-independent generalization error bound and propose a\nnovel algorithm to minimize the theoretical bound via adversarial learning. Our\ntheory and algorithm do not require a propensity estimation procedure, thereby\nleading to a well-performing rating predictor without the true propensity\ninformation. Extensive experiments demonstrate that the proposed approach is\nsuperior to a range of existing methods both in rating prediction and ranking\nmetrics in practical settings without MCAR data.",
          "link": "http://arxiv.org/abs/1910.07295",
          "publishedOn": "2022-04-23T00:53:49.376Z",
          "wordCount": 656,
          "title": "Towards Resolving Propensity Contradiction in Offline Recommender Learning. (arXiv:1910.07295v6 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.08973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_Y/0/1/0/all/0/1\">Yoones Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stephen Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosse_D/0/1/0/all/0/1\">Daniel Mosse</a>",
          "description": "Advances in deep vision techniques and ubiquity of smart cameras will drive\nthe next generation of video analytics. However, video analytics applications\nconsume vast amounts of energy as both deep learning techniques and cameras are\npower-hungry. In this paper, we focus on a parking video analytics platform and\npropose RL-CamSleep, a deep reinforcement learning-based technique, to actuate\nthe cameras to reduce the energy footprint while retaining the system's\nutility. Our key insight is that many video-analytics applications do not\nalways need to be operational, and we can design policies to activate video\nanalytics only when necessary. Moreover, our work is complementary to existing\nwork that focuses on improving hardware and software efficiency. We evaluate\nour approach on a city-scale parking dataset having 76 streets spread across\nthe city. Our analysis demonstrates how streets have various parking patterns,\nhighlighting the importance of an adaptive policy. Our approach can learn such\nan adaptive policy that can reduce the average energy consumption by 76.38% and\nachieve an average accuracy of more than 98% in performing video analytics.",
          "link": "http://arxiv.org/abs/2202.08973",
          "publishedOn": "2022-04-23T00:53:49.347Z",
          "wordCount": null,
          "title": "Energy-Efficient Parking Analytics System using Deep Reinforcement Learning. (arXiv:2202.08973v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1\">R&#xf3;bert Csord&#xe1;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1\">Kazuki Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "Despite progress across a broad range of applications, Transformers have\nlimited success in systematic generalization. The situation is especially\nfrustrating in the case of algorithmic tasks, where they often fail to find\nintuitive solutions that route relevant information to the right node/operation\nat the right time in the grid represented by Transformer columns. To facilitate\nthe learning of useful control flow, we propose two modifications to the\nTransformer architecture, copy gate and geometric attention. Our novel Neural\nData Router (NDR) achieves 100% length generalization accuracy on the classic\ncompositional table lookup task, as well as near-perfect accuracy on the simple\narithmetic task and a new variant of ListOps testing for generalization across\ncomputational depths. NDR's attention and gating patterns tend to be\ninterpretable as an intuitive form of neural routing. Our code is public.",
          "link": "http://arxiv.org/abs/2110.07732",
          "publishedOn": "2022-04-23T00:53:49.319Z",
          "wordCount": null,
          "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization. (arXiv:2110.07732v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.10873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuolin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaojun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Recent studies show that deep neural networks (DNN) are vulnerable to\nadversarial examples, which aim to mislead DNNs by adding perturbations with\nsmall magnitude. To defend against such attacks, both empirical and theoretical\ndefense approaches have been extensively studied for a single ML model. In this\nwork, we aim to analyze and provide the certified robustness for ensemble ML\nmodels, together with the sufficient and necessary conditions of robustness for\ndifferent ensemble protocols. Although ensemble models are shown more robust\nthan a single model empirically; surprisingly, we find that in terms of the\ncertified robustness the standard ensemble models only achieve marginal\nimprovement compared to a single model. Thus, to explore the conditions that\nguarantee to provide certifiably robust ensemble ML models, we first prove that\ndiversified gradient and large confidence margin are sufficient and necessary\nconditions for certifiably robust ensemble models under the model-smoothness\nassumption. We then provide the bounded model-smoothness analysis based on the\nproposed Ensemble-before-Smoothing strategy. We also prove that an ensemble\nmodel can always achieve higher certified robustness than a single base model\nunder mild conditions. Inspired by the theoretical findings, we propose the\nlightweight Diversity Regularized Training (DRT) to train certifiably robust\nensemble ML models. Extensive experiments show that our DRT enhanced ensembles\ncan consistently achieve higher certified robustness than existing single and\nensemble ML models, demonstrating the state-of-the-art certified L2-robustness\non MNIST, CIFAR-10, and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2107.10873",
          "publishedOn": "2022-04-23T00:53:49.284Z",
          "wordCount": 733,
          "title": "On the Certified Robustness for Ensemble Models and Beyond. (arXiv:2107.10873v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koblah_D/0/1/0/all/0/1\">David Selasi Koblah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_R/0/1/0/all/0/1\">Rabin Yu Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capecci_D/0/1/0/all/0/1\">Daniel Capecci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dizon_Paradis_O/0/1/0/all/0/1\">Olivia P. Dizon-Paradis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tajik_S/0/1/0/all/0/1\">Shahin Tajik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganji_F/0/1/0/all/0/1\">Fatemeh Ganji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodard_D/0/1/0/all/0/1\">Damon L. Woodard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forte_D/0/1/0/all/0/1\">Domenic Forte</a>",
          "description": "Artificial intelligence (AI) and machine learning (ML) techniques have been\nincreasingly used in several fields to improve performance and the level of\nautomation. In recent years, this use has exponentially increased due to the\nadvancement of high-performance computing and the ever increasing size of data.\nOne of such fields is that of hardware design; specifically the design of\ndigital and analog integrated circuits~(ICs), where AI/ ML techniques have been\nextensively used to address ever-increasing design complexity, aggressive\ntime-to-market, and the growing number of ubiquitous interconnected devices\n(IoT). However, the security concerns and issues related to IC design have been\nhighly overlooked. In this paper, we summarize the state-of-the-art in AL/ML\nfor circuit design/optimization, security and engineering challenges, research\nin security-aware CAD/EDA, and future research directions and needs for using\nAI/ML for security-aware circuit design.",
          "link": "http://arxiv.org/abs/2204.09579",
          "publishedOn": "2022-04-23T00:53:49.218Z",
          "wordCount": 603,
          "title": "A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation. (arXiv:2204.09579v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhaoning Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messikommer_N/0/1/0/all/0/1\">Nico Messikommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrig_D/0/1/0/all/0/1\">Daniel Gehrig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaramuzza_D/0/1/0/all/0/1\">Davide Scaramuzza</a>",
          "description": "Retrieving accurate semantic information in challenging high dynamic range\n(HDR) and high-speed conditions remains an open challenge for image-based\nalgorithms due to severe image degradations. Event cameras promise to address\nthese challenges since they feature a much higher dynamic range and are\nresilient to motion blur. Nonetheless, semantic segmentation with event cameras\nis still in its infancy which is chiefly due to the novelty of the sensor, and\nthe lack of high-quality, labeled datasets. In this work, we introduce ESS,\nwhich tackles this problem by directly transferring the semantic segmentation\ntask from existing labeled image datasets to unlabeled events via unsupervised\ndomain adaptation (UDA). Compared to existing UDA methods, our approach aligns\nrecurrent, motion-invariant event embeddings with image embeddings. For this\nreason, our method neither requires video data nor per-pixel alignment between\nimages and events and, crucially, does not need to hallucinate motion from\nstill images. Additionally, to spur further research in event-based semantic\nsegmentation, we introduce DSEC-Semantic, the first large-scale event-based\ndataset with fine-grained labels. We show that using image labels alone, ESS\noutperforms existing UDA approaches, and when combined with event labels, it\neven outperforms state-of-the-art supervised approaches on both DDD17 and\nDSEC-Semantic. Finally, ESS is general-purpose, which unlocks the vast amount\nof existing labeled image datasets and paves the way for new and exciting\nresearch directions in new fields previously inaccessible for event cameras.",
          "link": "http://arxiv.org/abs/2203.10016",
          "publishedOn": "2022-04-23T00:53:49.205Z",
          "wordCount": 670,
          "title": "ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1811.02117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Sha Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xingxing Wei</a>",
          "description": "An ability to predict the popularity dynamics of individual items within a\ncomplex evolving system has important implications in a wide range of domains.\nHere we propose a deep learning attention mechanism to model the process\nthrough which individual items gain their popularity. We analyze the\ninterpretability of the model with the four key phenomena confirmed\nindependently in the previous studies of long-term popularity dynamics\nquantification, including the intrinsic quality, the aging effect, the recency\neffect and the Matthew effect. We analyze the effectiveness of introducing\nattention model in popularity dynamics prediction. Extensive experiments on a\nreal-large citation data set demonstrate that the designed deep learning\nattention mechanism possesses remarkable power at predicting the long-term\npopularity dynamics. It consistently outperforms the existing methods, and\nachieves a significant performance improvement.",
          "link": "http://arxiv.org/abs/1811.02117",
          "publishedOn": "2022-04-23T00:53:49.198Z",
          "wordCount": 622,
          "title": "Modeling and Predicting Popularity Dynamics via Deep Learning Attention Mechanism. (arXiv:1811.02117v2 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.08044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohamadi_S/0/1/0/all/0/1\">Salman Mohamadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amindavar_H/0/1/0/all/0/1\">Hamidreza Amindavar</a>",
          "description": "Active learning frameworks offer efficient data annotation without remarkable\naccuracy degradation. In other words, active learning starts training the model\nwith a small size of labeled data while exploring the space of unlabeled data\nin order to select most informative samples to be labeled. Generally speaking,\nrepresenting the uncertainty is crucial in any active learning framework,\nhowever, deep learning methods are not capable of either representing or\nmanipulating model uncertainty. On the other hand, from the real world\napplication perspective, uncertainty representation is getting more and more\nattention in the machine learning community. Deep Bayesian active learning\nframeworks and generally any Bayesian active learning settings, provide\npractical consideration in the model which allows training with small data\nwhile representing the model uncertainty for further efficient training. In\nthis paper, we briefly survey recent advances in Bayesian active learning and\nin particular deep Bayesian active learning frameworks.",
          "link": "http://arxiv.org/abs/2012.08044",
          "publishedOn": "2022-04-23T00:53:49.186Z",
          "wordCount": null,
          "title": "Deep Bayesian Active Learning, A Brief Survey on Recent Advances. (arXiv:2012.08044v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haq_A/0/1/0/all/0/1\">Aizaz Ul Haq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_N/0/1/0/all/0/1\">Niranjana Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElSaid_A/0/1/0/all/0/1\">AbdElRahman ElSaid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desell_T/0/1/0/all/0/1\">Travis Desell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krutz_D/0/1/0/all/0/1\">Daniel E. Krutz</a>",
          "description": "Self-adaptive systems frequently use tactics to perform adaptations. Tactic\nexamples include the implementation of additional security measures when an\nintrusion is detected, or activating a cooling mechanism when temperature\nthresholds are surpassed. Tactic volatility occurs in real-world systems and is\ndefined as variable behavior in the attributes of a tactic, such as its latency\nor cost. A system's inability to effectively account for tactic volatility\nadversely impacts its efficiency and resiliency against the dynamics of\nreal-world environments. To enable systems' efficiency against tactic\nvolatility, we propose a Tactic Volatility Aware (TVA-E) process utilizing\nevolved Recurrent Neural Networks (eRNN) to provide accurate tactic\npredictions. TVA-E is also the first known process to take advantage of\nuncertainty reduction tactics to provide additional information to the\ndecision-making process and reduce uncertainty. TVA-E easily integrates into\npopular adaptation processes enabling it to immediately benefit a large number\nof existing self-adaptive systems. Simulations using 52,106 tactic records\ndemonstrate that: I) eRNN is an effective prediction mechanism, II) TVA-E\nrepresents an improvement over existing state-of-the-art processes in\naccounting for tactic volatility, and III) Uncertainty reduction tactics are\nbeneficial in accounting for tactic volatility. The developed dataset and tool\ncan be found at https://tacticvolatility.github.io/",
          "link": "http://arxiv.org/abs/2204.10308",
          "publishedOn": "2022-04-23T00:53:49.181Z",
          "wordCount": null,
          "title": "Addressing Tactic Volatility in Self-Adaptive Systems Using Evolved Recurrent Neural Networks and Uncertainty Reduction Tactics. (arXiv:2204.10308v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.06022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takase_S/0/1/0/all/0/1\">Sho Takase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyono_S/0/1/0/all/0/1\">Shun Kiyono</a>",
          "description": "We propose a parameter sharing method for Transformers (Vaswani et al.,\n2017). The proposed approach relaxes a widely used technique, which shares\nparameters for one layer with all layers such as Universal Transformers\n(Dehghani et al., 2019), to increase the efficiency in the computational time.\nWe propose three strategies: Sequence, Cycle, and Cycle (rev) to assign\nparameters to each layer. Experimental results show that the proposed\nstrategies are efficient in the parameter size and computational time.\nMoreover, we indicate that the proposed strategies are also effective in the\nconfiguration where we use many training data such as the recent WMT\ncompetition.",
          "link": "http://arxiv.org/abs/2104.06022",
          "publishedOn": "2022-04-23T00:53:49.160Z",
          "wordCount": 572,
          "title": "Lessons on Parameter Sharing across Layers in Transformers. (arXiv:2104.06022v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Taoran Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zhiqing Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chunping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiarong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>",
          "description": "Graph Neural Networks (GNNs) are powerful tools for graph representation\nlearning. Despite their rapid development, GNNs also faces some challenges,\nsuch as over-fitting, over-smoothing, and non-robustness. Previous works\nindicate that these problems can be alleviated by random dropping methods,\nwhich integrate noises into models by randomly masking parts of the input.\nHowever, some open-ended problems of random dropping on GNNs remain to solve.\nFirst, it is challenging to find a universal method that are suitable for all\ncases considering the divergence of different datasets and models. Second,\nrandom noises introduced to GNNs cause the incomplete coverage of parameters\nand unstable training process. In this paper, we propose a novel random\ndropping method called DropMessage, which performs dropping operations directly\non the message matrix and can be applied to any message-passing GNNs.\nFurthermore, we elaborate the superiority of DropMessage: it stabilizes the\ntraining process by reducing sample variance; it keeps information diversity\nfrom the perspective of information theory, which makes it a theoretical upper\nbound of other methods. Also, we unify existing random dropping methods into\nour framework and analyze their effects on GNNs. To evaluate our proposed\nmethod, we conduct experiments that aims for multiple tasks on five public\ndatasets and two industrial datasets with various backbone models. The\nexperimental results show that DropMessage has both advantages of effectiveness\nand generalization.",
          "link": "http://arxiv.org/abs/2204.10037",
          "publishedOn": "2022-04-23T00:53:49.136Z",
          "wordCount": 662,
          "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks. (arXiv:2204.10037v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.08414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haitao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guojiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>",
          "description": "Graph-based spatio-temporal neural networks are effective to model the\nspatial dependency among discrete points sampled irregularly from unstructured\ngrids, thanks to the great expressiveness of graph neural networks. However,\nthese models are usually spatially-transductive -- only fitting the signals for\ndiscrete spatial nodes fed in models but unable to generalize to `unseen'\nspatial points with zero-shot. In comparison, for forecasting tasks on\ncontinuous space such as temperature prediction on the earth's surface, the\n\\textit{spatially-inductive} property allows the model to generalize to any\npoint in the spatial domain, demonstrating models' ability to learn the\nunderlying mechanisms or physics laws of the systems, rather than simply fit\nthe signals. Besides, in temporal domains, \\textit{irregularly-sampled} time\nseries, e.g. data with missing values, urge models to be temporally-continuous.\nMotivated by the two issues, we propose a spatio-temporal framework based on\nneural operators for PDEs, which learn the underlying mechanisms governing the\ndynamics of spatially-continuous physical quantities. Experiments show our\nmodel's improved performance on forecasting spatially-continuous physic\nquantities, and its superior generalization to unseen spatial points and\nability to handle temporally-irregular data.",
          "link": "http://arxiv.org/abs/2204.08414",
          "publishedOn": "2022-04-23T00:53:49.111Z",
          "wordCount": 624,
          "title": "STONet: A Neural-Operator-Driven Spatio-temporal Network. (arXiv:2204.08414v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1\">Md Hasibul Amin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elbtity_M/0/1/0/all/0/1\">Mohammed Elbtity</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_M/0/1/0/all/0/1\">Mohammadreza Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zand_R/0/1/0/all/0/1\">Ramtin Zand</a>",
          "description": "We propose an analog implementation of the transcendental activation function\nleveraging two spin-orbit torque magnetoresistive random-access memory\n(SOT-MRAM) devices and a CMOS inverter. The proposed analog neuron circuit\nconsumes 1.8-27x less power, and occupies 2.5-4931x smaller area, compared to\nthe state-of-the-art analog and digital implementations. Moreover, the\ndeveloped neuron can be readily integrated with memristive crossbars without\nrequiring any intermediate signal conversion units. The architecture-level\nanalyses show that a fully-analog in-memory computing (IMC) circuit that use\nour SOT-MRAM neuron along with an SOT-MRAM based crossbar can achieve more than\n1.1x, 12x, and 13.3x reduction in power, latency, and energy, respectively,\ncompared to a mixed-signal implementation with analog memristive crossbars and\ndigital neurons. Finally, through cross-layer analyses, we provide a guide on\nhow varying the device-level parameters in our neuron can affect the accuracy\nof multilayer perceptron (MLP) for MNIST classification.",
          "link": "http://arxiv.org/abs/2204.09918",
          "publishedOn": "2022-04-23T00:53:49.066Z",
          "wordCount": 582,
          "title": "MRAM-based Analog Sigmoid Function for In-memory Computing. (arXiv:2204.09918v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10177",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Morel_R/0/1/0/all/0/1\">Rudy Morel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rochette_G/0/1/0/all/0/1\">Gaspar Rochette</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leonarduzzi_R/0/1/0/all/0/1\">Roberto Leonarduzzi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bouchaud_J/0/1/0/all/0/1\">Jean-Philippe Bouchaud</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mallat_S/0/1/0/all/0/1\">St&#xe9;phane Mallat</a>",
          "description": "We introduce a scattering covariance matrix which provides non-Gaussian\nmodels of time-series having stationary increments. A complex wavelet transform\ncomputes signal variations at each scale. Dependencies across scales are\ncaptured by the joint covariance across time and scales of complex wavelet\ncoefficients and their modulus. This covariance is nearly diagonalized by a\nsecond wavelet transform, which defines the scattering covariance. We show that\nthis set of moments characterizes a wide range of non-Gaussian properties of\nmulti-scale processes. This is analyzed for a variety of processes, including\nfractional Brownian motions, Poisson, multifractal random walks and Hawkes\nprocesses. We prove that self-similar processes have a scattering covariance\nmatrix which is scale invariant. This property can be estimated numerically and\ndefines a class of wide-sense self-similar processes. We build maximum entropy\nmodels conditioned by scattering covariance coefficients, and generate new\ntime-series with a microcanonical sampling algorithm. Applications are shown\nfor highly non-Gaussian financial and turbulence time-series.",
          "link": "http://arxiv.org/abs/2204.10177",
          "publishedOn": "2022-04-23T00:53:49.059Z",
          "wordCount": 622,
          "title": "Scale Dependencies and Self-Similarity Through Wavelet Scattering Covariance. (arXiv:2204.10177v1 [physics.data-an])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patras_P/0/1/0/all/0/1\">Paul Patras</a>",
          "description": "Machine Learning (ML) techniques are increasingly adopted to tackle\never-evolving high-profile network attacks, including DDoS, botnet, and\nransomware, due to their unique ability to extract complex patterns hidden in\ndata streams. These approaches are however routinely validated with data\ncollected in the same environment, and their performance degrades when deployed\nin different network topologies and/or applied on previously unseen traffic, as\nwe uncover. This suggests malicious/benign behaviors are largely learned\nsuperficially and ML-based Network Intrusion Detection System (NIDS) need\nrevisiting, to be effective in practice. In this paper we dive into the\nmechanics of large-scale network attacks, with a view to understanding how to\nuse ML for Network Intrusion Detection (NID) in a principled way. We reveal\nthat, although cyberattacks vary significantly in terms of payloads, vectors\nand targets, their early stages, which are critical to successful attack\noutcomes, share many similarities and exhibit important temporal correlations.\nTherefore, we treat NID as a time-sensitive task and propose NetSentry, perhaps\nthe first of its kind NIDS that builds on Bidirectional Asymmetric LSTM\n(Bi-ALSTM), an original ensemble of sequential neural models, to detect network\nthreats before they spread. We cross-evaluate NetSentry using two practical\ndatasets, training on one and testing on the other, and demonstrate F1 score\ngains above 33% over the state-of-the-art, as well as up to 3 times higher\nrates of detecting attacks such as XSS and web bruteforce. Further, we put\nforward a novel data augmentation technique that boosts the generalization\nabilities of a broad range of supervised deep learning algorithms, leading to\naverage F1 score gains above 35%.",
          "link": "http://arxiv.org/abs/2202.09873",
          "publishedOn": "2022-04-23T00:53:49.051Z",
          "wordCount": 724,
          "title": "NetSentry: A Deep Learning Approach to Detecting Incipient Large-scale Network Attacks. (arXiv:2202.09873v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1\">Anjul Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Pushkar Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Swasti Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_K/0/1/0/all/0/1\">Klaus Mueller</a>",
          "description": "Infographics are an aesthetic visual representation of information following\nspecific design principles of human perception. Designing infographics can be a\ntedious process for non-experts and time-consuming, even for professional\ndesigners. With the help of designers, we propose a semi-automated infographic\nframework for general structured and flow-based infographic design generation.\nFor novice designers, our framework automatically creates and ranks infographic\ndesigns for a user-provided text with no requirement for design input. However,\nexpert designers can still provide custom design inputs to customize the\ninfographics. We will also contribute an individual visual group (VG) designs\ndataset (in SVG), along with a 1k complete infographic image dataset with\nsegmented VGs in this work. Evaluation results confirm that by using our\nframework, designers from all expertise levels can generate generic infographic\ndesigns faster than existing methods while maintaining the same quality as\nhand-designed infographics templates.",
          "link": "http://arxiv.org/abs/2204.09904",
          "publishedOn": "2022-04-23T00:53:49.035Z",
          "wordCount": 616,
          "title": "Infographics Wizard: Flexible Infographics Authoring and Design Exploration. (arXiv:2204.09904v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingxiao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>",
          "description": "Message Passing Neural Networks (MPNNs) are a common type of Graph Neural\nNetwork (GNN), in which each node's representation is computed recursively by\naggregating representations (messages) from its immediate neighbors akin to a\nstar-shaped pattern. MPNNs are appealing for being efficient and scalable,\nhow-ever their expressiveness is upper-bounded by the 1st-order\nWeisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose\nhighly expressive models at the cost of scalability and sometimes\ngeneralization performance. Our work stands between these two regimes: we\nintroduce a general framework to uplift any MPNN to be more expressive, with\nlimited scalability overhead and greatly improved practical performance. We\nachieve this by extending local aggregation in MPNNs from star patterns to\ngeneral subgraph patterns (e.g.,k-egonets):in our framework, each node\nrepresentation is computed as the encoding of a surrounding induced subgraph\nrather than encoding of immediate neighbors only (i.e. a star). We choose the\nsubgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design\na general framework that serves as a wrapper to up-lift any GNN. We call our\nproposed method GNN-AK(GNN As Kernel), as the framework resembles a\nconvolutional neural network by replacing the kernel with GNNs. Theoretically,\nwe show that our framework is strictly more powerful than 1&2-WL, and is not\nless powerful than 3-WL. We also design subgraph sampling strategies which\ngreatly reduce memory footprint and improve speed while maintaining\nperformance. Our method sets new state-of-the-art performance by large margins\nfor several well-known graph ML tasks; specifically, 0.08 MAE on ZINC,74.79%\nand 86.887% accuracy on CIFAR10 and PATTERN respectively.",
          "link": "http://arxiv.org/abs/2110.03753",
          "publishedOn": "2022-04-23T00:53:48.951Z",
          "wordCount": 740,
          "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness. (arXiv:2110.03753v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1\">Nazmul Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_U/0/1/0/all/0/1\">Umar Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1\">Ashkan Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>",
          "description": "The task of continual learning requires careful design of algorithms that can\ntackle catastrophic forgetting. However, the noisy label, which is inevitable\nin a real-world scenario, seems to exacerbate the situation. While very few\nstudies have addressed the issue of continual learning under noisy labels, long\ntraining time and complicated training schemes limit their applications in most\ncases. In contrast, we propose a simple purification technique to effectively\ncleanse the online data stream that is both cost-effective and more accurate.\nAfter purification, we perform fine-tuning in a semi-supervised fashion that\nensures the participation of all available samples. Training in this fashion\nhelps us learn a better representation that results in state-of-the-art (SOTA)\nperformance. Through extensive experimentation on 3 benchmark datasets, MNIST,\nCIFAR10 and CIFAR100, we show the effectiveness of our proposed approach. We\nachieve a 24.8% performance gain for CIFAR10 with 20% noise over previous SOTA\nmethods. Our code is publicly available.",
          "link": "http://arxiv.org/abs/2204.09881",
          "publishedOn": "2022-04-23T00:53:48.170Z",
          "wordCount": 620,
          "title": "CNLL: A Semi-supervised Approach For Continual Noisy Label Learning. (arXiv:2204.09881v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peilun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_F/0/1/0/all/0/1\">Fan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hui Guo</a>",
          "description": "Email threat is a serious issue for enterprise security, which consists of\nvarious malicious scenarios, such as phishing, fraud, blackmail and\nmalvertisement. Traditional anti-spam gateway commonly requires to maintain a\ngreylist to filter out unexpected emails based on suspicious vocabularies\nexisted in the mail subject and content. However, the signature-based approach\ncannot effectively discover novel and unknown suspicious emails that utilize\nvarious hot topics at present, such as COVID-19 and US election. To address the\nproblem, in this paper, we present Holmes, an efficient and lightweight\nsemantic based engine for anomalous email detection. Holmes can convert each\nevent log of email to a sentence through word embedding then extract\ninteresting items among them by novelty detection. Based on our observations,\nwe claim that, in an enterprise environment, there is a stable relation between\nsenders and receivers, but suspicious emails are commonly from unusual sources,\nwhich can be detected through the rareness selection. We evaluate the\nperformance of Holmes in a real-world enterprise environment, in which it sends\nand receives around 5,000 emails each day. As a result, Holmes can achieve a\nhigh detection rate (output around 200 suspicious emails per day) and maintain\na low false alarm rate for anomaly detection.",
          "link": "http://arxiv.org/abs/2104.08044",
          "publishedOn": "2022-04-23T00:53:48.091Z",
          "wordCount": 793,
          "title": "Holmes: An Efficient and Lightweight Semantic Based Anomalous Email Detector. (arXiv:2104.08044v11 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1\">Djallel Bouneffouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1\">Guillermo Cecchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tejwani_R/0/1/0/all/0/1\">Ravi Tejwani</a>",
          "description": "In this work, we compare different neural topic modeling methods in learning\nthe topical propensities of different psychiatric conditions from the\npsychotherapy session transcripts parsed from speech recordings. We also\nincorporate temporal modeling to put this additional interpretability to action\nby parsing out topic similarities as a time series in a turn-level resolution.\nWe believe this topic modeling framework can offer interpretable insights for\nthe therapist to optimally decide his or her strategy and improve the\npsychotherapy effectiveness.",
          "link": "http://arxiv.org/abs/2204.10189",
          "publishedOn": "2022-04-23T00:53:48.060Z",
          "wordCount": 546,
          "title": "Neural Topic Modeling of Psychotherapy Sessions. (arXiv:2204.10189v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.03622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kendrick Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yining Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Self-training algorithms, which train a model to fit pseudolabels predicted\nby another previously-learned model, have been very successful for learning\nwith unlabeled data using neural networks. However, the current theoretical\nunderstanding of self-training only applies to linear models. This work\nprovides a unified theoretical analysis of self-training with deep networks for\nsemi-supervised learning, unsupervised domain adaptation, and unsupervised\nlearning. At the core of our analysis is a simple but realistic \"expansion\"\nassumption, which states that a low probability subset of the data must expand\nto a neighborhood with large probability relative to the subset. We also assume\nthat neighborhoods of examples in different classes have minimal overlap. We\nprove that under these assumptions, the minimizers of population objectives\nbased on self-training and input-consistency regularization will achieve high\naccuracy with respect to ground-truth labels. By using off-the-shelf\ngeneralization bounds, we immediately convert this result to sample complexity\nguarantees for neural nets that are polynomial in the margin and Lipschitzness.\nOur results help explain the empirical successes of recently proposed\nself-training algorithms which use input consistency regularization.",
          "link": "http://arxiv.org/abs/2010.03622",
          "publishedOn": "2022-04-23T00:53:48.046Z",
          "wordCount": 677,
          "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.05094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhaubhadel_S/0/1/0/all/0/1\">Sayera Dhaubhadel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohd_Yusof_J/0/1/0/all/0/1\">Jamaludin Mohd-Yusof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_K/0/1/0/all/0/1\">Kumkum Ganguly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chennupati_G/0/1/0/all/0/1\">Gopinath Chennupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thulasidasan_S/0/1/0/all/0/1\">Sunil Thulasidasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengartner_N/0/1/0/all/0/1\">Nicolas W. Hengartner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mumphrey_B/0/1/0/all/0/1\">Brent J. Mumphrey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durbin_E/0/1/0/all/0/1\">Eric B. Durbin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doherty_J/0/1/0/all/0/1\">Jennifer A. Doherty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemieux_M/0/1/0/all/0/1\">Mireille Lemieux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaefferkoetter_N/0/1/0/all/0/1\">Noah Schaefferkoetter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tourassi_G/0/1/0/all/0/1\">Georgia Tourassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coyle_L/0/1/0/all/0/1\">Linda Coyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Penberthy_L/0/1/0/all/0/1\">Lynne Penberthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMahon_B/0/1/0/all/0/1\">Benjamin H. McMahon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_T/0/1/0/all/0/1\">Tanmoy Bhattacharya</a>",
          "description": "Safe deployment of deep learning systems in critical real world applications\nrequires models to make very few mistakes, and only under predictable\ncircumstances. In this work, we address this problem using an abstaining\nclassifier that is tuned to have $>$95% accuracy, and then identify the\ndeterminants of abstention using LIME. Essentially, we are training our model\nto learn the attributes of pathology reports that are likely to lead to\nincorrect classifications, albeit at the cost of reduced sensitivity. We\ndemonstrate an abstaining classifier in a multitask setting for classifying\ncancer pathology reports from the NCI SEER cancer registries on six tasks of\ninterest. For these tasks, we reduce the classification error rate by factors\nof 2--5 by abstaining on 25--45% of the reports. For the specific task of\nclassifying cancer site, we are able to identify metastasis, reports involving\nlymph nodes, and discussion of multiple cancer sites as responsible for many of\nthe classification mistakes, and observe that the extent and types of mistakes\nvary systematically with cancer site (e.g., breast, lung, and prostate). When\ncombining across three of the tasks, our model classifies 50% of the reports\nwith an accuracy greater than 95% for three of the six tasks\\edit, and greater\nthan 85% for all six tasks on the retained samples. Furthermore, we show that\nLIME provides a better determinant of classification than measures of word\noccurrence alone. By combining a deep abstaining classifier with feature\nidentification using LIME, we are able to identify concepts responsible for\nboth correctness and abstention when classifying cancer sites from pathology\nreports. The improvement of LIME over keyword searches is statistically\nsignificant, presumably because words are assessed in context and have been\nidentified as a local determinant of classification.",
          "link": "http://arxiv.org/abs/2009.05094",
          "publishedOn": "2022-04-23T00:53:48.022Z",
          "wordCount": 823,
          "title": "Why I'm not Answering: Understanding Determinants of Classification of an Abstaining Classifier for Cancer Pathology Reports. (arXiv:2009.05094v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yongjing Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pengpeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_X/0/1/0/all/0/1\">Xuefeng Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guanfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Deqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lei Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanchi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_V/0/1/0/all/0/1\">Victor S. Sheng</a>",
          "description": "Sequential Recommendation aims to predict the next item based on user\nbehaviour. Recently, Self-Supervised Learning (SSL) has been proposed to\nimprove recommendation performance. However, most of existing SSL methods use a\nuniform data augmentation scheme, which loses the sequence correlation of an\noriginal sequence. To this end, in this paper, we propose a Learnable Model\nAugmentation self-supervised learning for sequential Recommendation (LMA4Rec).\nSpecifically, LMA4Rec first takes model augmentation as a supplementary method\nfor data augmentation to generate views. Then, LMA4Rec uses learnable Bernoulli\ndropout to implement model augmentation learnable operations. Next,\nself-supervised learning is used between the contrastive views to extract\nself-supervised signals from an original sequence. Finally, experiments on\nthree public datasets show that the LMA4Rec method effectively improves\nsequential recommendation performance compared with baseline methods.",
          "link": "http://arxiv.org/abs/2204.10128",
          "publishedOn": "2022-04-23T00:53:47.986Z",
          "wordCount": 573,
          "title": "Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation. (arXiv:2204.10128v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haotian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhijian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yujun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>",
          "description": "Deep learning on point clouds has received increased attention thanks to its\nwide applications in AR/VR and autonomous driving. These applications require\nlow latency and high accuracy to provide real-time user experience and ensure\nuser safety. Unlike conventional dense workloads, the sparse and irregular\nnature of point clouds poses severe challenges to running sparse CNNs\nefficiently on the general-purpose hardware. Furthermore, existing sparse\nacceleration techniques for 2D images do not translate to 3D point clouds. In\nthis paper, we introduce TorchSparse, a high-performance point cloud inference\nengine that accelerates the sparse convolution computation on GPUs. TorchSparse\ndirectly optimizes the two bottlenecks of sparse convolution: irregular\ncomputation and data movement. It applies adaptive matrix multiplication\ngrouping to trade computation for better regularity, achieving 1.4-1.5x speedup\nfor matrix multiplication. It also optimizes the data movement by adopting\nvectorized, quantized and fused locality-aware memory access, reducing the\nmemory movement cost by 2.7x. Evaluated on seven representative models across\nthree benchmark datasets, TorchSparse achieves 1.6x and 1.5x measured\nend-to-end speedup over the state-of-the-art MinkowskiEngine and SpConv,\nrespectively.",
          "link": "http://arxiv.org/abs/2204.10319",
          "publishedOn": "2022-04-23T00:53:47.979Z",
          "wordCount": 631,
          "title": "TorchSparse: Efficient Point Cloud Inference Engine. (arXiv:2204.10319v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tonderski_A/0/1/0/all/0/1\">Adam Tonderski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnander_J/0/1/0/all/0/1\">Joakim Johnander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petersson_C/0/1/0/all/0/1\">Christoffer Petersson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+%7B%5CAA%7Dstrom_K/0/1/0/all/0/1\">Kalle &#xc5;str&#xf6;m</a>",
          "description": "We explore future object prediction -- a challenging problem where all\nobjects visible in a future video frame are to be predicted. We propose to\ntackle this problem end-to-end by training a detection transformer to directly\noutput future objects. In order to make accurate predictions about the future,\nit is necessary to capture the dynamics in the scene, both of other objects and\nof the ego-camera. We extend existing detection transformers in two ways to\ncapture the scene dynamics. First, we experiment with three different\nmechanisms that enable the model to spatiotemporally process multiple frames.\nSecond, we feed ego-motion information to the model via cross-attention. We\nshow that both of these cues substantially improve future object prediction\nperformance. Our final approach learns to capture the dynamics and make\npredictions on par with an oracle for 100 ms prediction horizons, and\noutperform baselines for longer prediction horizons.",
          "link": "http://arxiv.org/abs/2204.10321",
          "publishedOn": "2022-04-23T00:53:47.972Z",
          "wordCount": 595,
          "title": "Learning Future Object Prediction with a Spatiotemporal Detection Transformer. (arXiv:2204.10321v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1905.09449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Donghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Zuyuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xinwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jinshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>",
          "description": "The great success of deep neural networks is built upon their\nover-parameterization, which smooths the optimization landscape without\ndegrading the generalization ability. Despite the benefits of\nover-parameterization, a huge amount of parameters makes deep networks\ncumbersome in daily life applications. Though techniques such as pruning and\ndistillation are developed, they are expensive in fully training a dense\nnetwork as backward selection methods, and there is still a void on\nsystematically exploring forward selection methods for learning structural\nsparsity in deep networks. To fill in this gap, this paper proposes a new\napproach based on differential inclusions of inverse scale spaces, which\ngenerate a family of models from simple to complex ones along the dynamics via\ncoupling a pair of parameters, such that over-parameterized deep models and\ntheir structural sparsity can be explored simultaneously. This kind of\ndifferential inclusion scheme has a simple discretization, dubbed Deep\nstructure splitting Linearized Bregman Iteration (DessiLBI), whose global\nconvergence in learning deep networks could be established under the\nKurdyka-Lojasiewicz framework. Experimental evidence shows that our method\nachieves comparable and even better performance than the competitive optimizers\nin exploring the sparse structure of several widely used backbones on the\nbenchmark datasets. Remarkably, with early stopping, our method unveils\n`winning tickets' in early epochs: the effective sparse network structures with\ncomparable test accuracy to fully trained over-parameterized models, that are\nfurther transferable to similar alternative tasks. Furthermore, our method is\nable to grow networks efficiently with adaptive filter configurations,\ndemonstrating a good performance with much less computational cost. Codes and\nmodels can be downloaded at {https://github.com/DessiLBI2020/DessiLBI}.",
          "link": "http://arxiv.org/abs/1905.09449",
          "publishedOn": "2022-04-23T00:53:47.951Z",
          "wordCount": 811,
          "title": "Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces. (arXiv:1905.09449v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sudharsan_B/0/1/0/all/0/1\">Bharath Sudharsan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_D/0/1/0/all/0/1\">Dineshkumar Sundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Pankesh Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breslin_J/0/1/0/all/0/1\">John G. Breslin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Muhammad Intizar Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dustdar_S/0/1/0/all/0/1\">Schahram Dustdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zomaya_A/0/1/0/all/0/1\">Albert Zomaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjan_R/0/1/0/all/0/1\">Rajiv Ranjan</a>",
          "description": "The majority of IoT devices like smartwatches, smart plugs, HVAC controllers,\netc., are powered by hardware with a constrained specification (low memory,\nclock speed and processor) which is insufficient to accommodate and execute\nlarge, high-quality models. On such resource-constrained devices, manufacturers\nstill manage to provide attractive functionalities (to boost sales) by\nfollowing the traditional approach of programming IoT devices/products to\ncollect and transmit data (image, audio, sensor readings, etc.) to their\ncloud-based ML analytics platforms. For decades, this online approach has been\nfacing issues such as compromised data streams, non-real-time analytics due to\nlatency, bandwidth constraints, costly subscriptions, recent privacy issues\nraised by users and the GDPR guidelines, etc. In this paper, to enable\nultra-fast and accurate AI-based offline analytics on resource-constrained IoT\ndevices, we present an end-to-end multi-component model optimization sequence\nand open-source its implementation. Researchers and developers can use our\noptimization sequence to optimize high memory, computation demanding models in\nmultiple aspects in order to produce small size, low latency, low-power\nconsuming models that can comfortably fit and execute on resource-constrained\nhardware. The experimental results show that our optimization components can\nproduce models that are; (i) 12.06 x times compressed; (ii) 0.13% to 0.27% more\naccurate; (iii) Orders of magnitude faster unit inference at 0.06 ms. Our\noptimization sequence is generic and can be applied to any state-of-the-art\nmodels trained for anomaly detection, predictive maintenance, robotics, voice\nrecognition, and machine vision.",
          "link": "http://arxiv.org/abs/2204.10183",
          "publishedOn": "2022-04-23T00:53:47.902Z",
          "wordCount": 689,
          "title": "Multi-Component Optimization and Efficient Deployment of Neural-Networks on Resource-Constrained IoT Hardware. (arXiv:2204.10183v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akpinar_N/0/1/0/all/0/1\">Nil-Jana Akpinar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagireddy_M/0/1/0/all/0/1\">Manish Nagireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stapleton_L/0/1/0/all/0/1\">Logan Stapleton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao-Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Haiyi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Steven Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_H/0/1/0/all/0/1\">Hoda Heidari</a>",
          "description": "Motivated by the growing importance of reducing unfairness in ML predictions,\nFair-ML researchers have presented an extensive suite of algorithmic\n\"fairness-enhancing\" remedies. Most existing algorithms, however, are agnostic\nto the sources of the observed unfairness. As a result, the literature\ncurrently lacks guiding frameworks to specify conditions under which each\nalgorithmic intervention can potentially alleviate the underpinning cause of\nunfairness. To close this gap, we scrutinize the underlying biases (e.g., in\nthe training data or design choices) that cause observational unfairness. We\npresent a bias-injection sandbox tool to investigate fairness consequences of\nvarious biases and assess the effectiveness of algorithmic remedies in the\npresence of specific types of bias. We call this process the\nbias(stress)-testing of algorithmic interventions. Unlike existing toolkits,\nours provides a controlled environment to counterfactually inject biases in the\nML pipeline. This stylized setup offers the distinct capability of testing\nfairness interventions beyond observational data and against an unbiased\nbenchmark. In particular, we can test whether a given remedy can alleviate the\ninjected bias by comparing the predictions resulting after the intervention in\nthe biased setting with true labels in the unbiased regime -- that is, before\nany bias injection. We illustrate the utility of our toolkit via a\nproof-of-concept case study on synthetic data. Our empirical analysis showcases\nthe type of insights that can be obtained through our simulations.",
          "link": "http://arxiv.org/abs/2204.10233",
          "publishedOn": "2022-04-23T00:53:47.893Z",
          "wordCount": 665,
          "title": "A Sandbox Tool to Bias(Stress)-Test Fairness Algorithms. (arXiv:2204.10233v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garland_A/0/1/0/all/0/1\">Anthony Garland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_K/0/1/0/all/0/1\">Kevin Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Matt Smith</a>",
          "description": "Anomaly detection is important for industrial automation and part quality\nassurance, and while humans can easily detect anomalies in components given a\nfew examples, designing a generic automated system that can perform at human or\nabove human capabilities remains a challenge. In this work, we present a simple\nnew anomaly detection algorithm called FADS (feature-based anomaly detection\nsystem) which leverages pretrained convolutional neural networks (CNN) to\ngenerate a statistical model of nominal inputs by observing the activation of\nthe convolutional filters. During inference the system compares the\nconvolutional filter activation of the new input to the statistical model and\nflags activations that are outside the expected range of values and therefore\nlikely an anomaly. By using a pretrained network, FADS demonstrates excellent\nperformance similar to or better than other machine learning approaches to\nanomaly detection while at the same time FADS requires no tuning of the CNN\nweights. We demonstrate FADS ability by detecting process parameter changes on\na custom dataset of additively manufactured lattices. The FADS localization\nalgorithm shows that textural differences that are visible on the surface can\nbe used to detect process parameter changes. In addition, we test FADS on\nbenchmark datasets, such as the MVTec Anomaly Detection dataset, and report\ngood results.",
          "link": "http://arxiv.org/abs/2204.10318",
          "publishedOn": "2022-04-23T00:53:47.834Z",
          "wordCount": 649,
          "title": "Feature anomaly detection system (FADS) for intelligent manufacturing. (arXiv:2204.10318v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamaide_V/0/1/0/all/0/1\">Valentin Hamaide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joassin_D/0/1/0/all/0/1\">Denis Joassin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castin_L/0/1/0/all/0/1\">Lauriane Castin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glineur_F/0/1/0/all/0/1\">Fran&#xe7;ois Glineur</a>",
          "description": "Predicting incoming failures and scheduling maintenance based on sensors\ninformation in industrial machines is increasingly important to avoid downtime\nand machine failure. Different machine learning formulations can be used to\nsolve the predictive maintenance problem. However, many of the approaches\nstudied in the literature are not directly applicable to real-life scenarios.\nIndeed, many of those approaches usually either rely on labelled machine\nmalfunctions in the case of classification and fault detection, or rely on\nfinding a monotonic health indicator on which a prediction can be made in the\ncase of regression and remaining useful life estimation, which is not always\nfeasible. Moreover, the decision-making part of the problem is not always\nstudied in conjunction with the prediction phase. This paper aims to design and\ncompare different formulations for predictive maintenance in a two-level\nframework and design metrics that quantify both the failure detection\nperformance as well as the timing of the maintenance decision. The first level\nis responsible for building a health indicator by aggregating features using a\nlearning algorithm. The second level consists of a decision-making system that\ncan trigger an alarm based on this health indicator. Three degrees of\nrefinements are compared in the first level of the framework, from simple\nthreshold-based univariate predictive technique to supervised learning methods\nbased on the remaining time before failure. We choose to use the Support Vector\nMachine (SVM) and its variations as the common algorithm used in all the\nformulations. We apply and compare the different strategies on a real-world\nrotating machine case study and observe that while a simple model can already\nperform well, more sophisticated refinements enhance the predictions for\nwell-chosen parameters.",
          "link": "http://arxiv.org/abs/2204.10083",
          "publishedOn": "2022-04-23T00:53:47.780Z",
          "wordCount": 718,
          "title": "A two-level machine learning framework for predictive maintenance: comparison of learning formulations. (arXiv:2204.10083v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghazi_M/0/1/0/all/0/1\">Mehdi Mehdipour Ghazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_A/0/1/0/all/0/1\">Amin Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siahi_M/0/1/0/all/0/1\">Mehdi Siahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazi_M/0/1/0/all/0/1\">Mostafa Mehdipour Ghazi</a>",
          "description": "Urban traffic flow prediction using data-driven models can play an important\nrole in route planning and preventing congestion on highways. These methods\nutilize data collected from traffic recording stations at different timestamps\nto predict the future status of traffic. Hence, data collection, transmission,\nstorage, and extraction techniques can have a significant impact on the\nperformance of the traffic flow model. On the other hand, a comprehensive\ndatabase can provide the opportunity for using complex, yet reliable predictive\nmodels such as deep learning methods. However, most of these methods have\ndifficulties in handling missing values and outliers. This study focuses on\nhybrid deep neural networks to predict traffic flow in the California Freeway\nPerformance Measurement System (PeMS) with missing values. The proposed\nnetworks are based on a combination of recurrent neural networks (RNNs) to\nconsider the temporal dependencies in the data recorded in each station and\nconvolutional neural networks (CNNs) to take the spatial correlations in the\nadjacent stations into account. Various architecture configurations with series\nand parallel connections are considered based on RNNs and CNNs, and several\nprevalent data imputation techniques are used to examine the robustness of the\nhybrid networks to missing values. A comprehensive analysis performed on two\ndifferent datasets from PeMS indicates that the proposed series-parallel hybrid\nnetwork with the mean imputation technique achieves the lowest error in\npredicting the traffic flow and is robust to missing values up until 21%\nmissing ratio in both complete and incomplete training data scenarios when\napplied to an incomplete test data.",
          "link": "http://arxiv.org/abs/2204.10222",
          "publishedOn": "2022-04-23T00:53:47.772Z",
          "wordCount": 705,
          "title": "Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks. (arXiv:2204.10222v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juhwan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Gabriel T. R. Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gharaibeh_Y/0/1/0/all/0/1\">Yazan Gharaibeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolluru_C/0/1/0/all/0/1\">Chaitanya Kolluru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimin_V/0/1/0/all/0/1\">Vladislav N. Zimin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dallan_L/0/1/0/all/0/1\">Luis A. P. Dallan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Justin N. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoori_A/0/1/0/all/0/1\">Ammar Hoori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Kindi_S/0/1/0/all/0/1\">Sadeer G. Al-Kindi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guagliumi_G/0/1/0/all/0/1\">Giulio Guagliumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezerra_H/0/1/0/all/0/1\">Hiram G. Bezerra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1\">David L. Wilson</a>",
          "description": "Thin-cap fibroatheroma (TCFA) and plaque rupture have been recognized as the\nmost frequent risk factor for thrombosis and acute coronary syndrome.\nIntravascular optical coherence tomography (IVOCT) can identify TCFA and assess\ncap thickness, which provides an opportunity to assess plaque vulnerability. We\ndeveloped an automated method that can detect lipidous plaque and assess\nfibrous cap thickness in IVOCT images. This study analyzed a total of 4,360\nIVOCT image frames of 77 lesions among 41 patients. To improve segmentation\nperformance, preprocessing included lumen segmentation, pixel-shifting, and\nnoise filtering on the raw polar (r, theta) IVOCT images. We used the\nDeepLab-v3 plus deep learning model to classify lipidous plaque pixels. After\nlipid detection, we automatically detected the outer border of the fibrous cap\nusing a special dynamic programming algorithm and assessed the cap thickness.\nOur method provided excellent discriminability of lipid plaque with a\nsensitivity of 85.8% and A-line Dice coefficient of 0.837. By comparing lipid\nangle measurements between two analysts following editing of our automated\nsoftware, we found good agreement by Bland-Altman analysis (difference 6.7+/-17\ndegree; mean 196 degree). Our method accurately detected the fibrous cap from\nthe detected lipid plaque. Automated analysis required a significant\nmodification for only 5.5% frames. Furthermore, our method showed a good\nagreement of fibrous cap thickness between two analysts with Bland-Altman\nanalysis (4.2+/-14.6 micron; mean 175 micron), indicating little bias between\nusers and good reproducibility of the measurement. We developed a fully\nautomated method for fibrous cap quantification in IVOCT images, resulting in\ngood agreement with determinations by analysts. The method has great potential\nto enable highly automated, repeatable, and comprehensive evaluations of TCFAs.",
          "link": "http://arxiv.org/abs/2204.10162",
          "publishedOn": "2022-04-23T00:53:47.766Z",
          "wordCount": 749,
          "title": "Automated analysis of fibrous cap in intravascular optical coherence tomography images of coronary arteries. (arXiv:2204.10162v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10228",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sadjadi_S/0/1/0/all/0/1\">Seyed Omid Sadjadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greenberg_C/0/1/0/all/0/1\">Craig Greenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singer_E/0/1/0/all/0/1\">Elliot Singer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mason_L/0/1/0/all/0/1\">Lisa Mason</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reynolds_D/0/1/0/all/0/1\">Douglas Reynolds</a>",
          "description": "The US National Institute of Standards and Technology (NIST) has been\nconducting a second iteration of the CTS challenge since August 2020. The\ncurrent iteration of the CTS Challenge is a leaderboard-style speaker\nrecognition evaluation using telephony data extracted from the unexposed\nportions of the Call My Net 2 (CMN2) and Multi-Language Speech (MLS) corpora\ncollected by the LDC. The CTS Challenge is currently organized in a similar\nmanner to the SRE19 CTS Challenge, offering only an open training condition\nusing two evaluation subsets, namely Progress and Test. Unlike in the SRE19\nChallenge, no training or development set was initially released, and NIST has\npublicly released the leaderboards on both subsets for the CTS Challenge. Which\nsubset (i.e., Progress or Test) a trial belongs to is unknown to challenge\nparticipants, and each system submission needs to contain outputs for all of\nthe trials. The CTS Challenge has also served, and will continue to do so, as a\nprerequisite for entrance to the regular SREs (such as SRE21). Since August\n2020, a total of 53 organizations (forming 33 teams) from academia and industry\nhave participated in the CTS Challenge and submitted more than 4400 valid\nsystem outputs. This paper presents an overview of the evaluation and several\nanalyses of system performance for some primary conditions in the CTS\nChallenge. The CTS Challenge results thus far indicate remarkable improvements\nin performance due to 1) speaker embeddings extracted using large-scale and\ncomplex neural network architectures such as ResNets along with angular margin\nlosses for speaker embedding extraction, 2) extensive data augmentation, 3) the\nuse of large amounts of in-house proprietary data from a large number of\nlabeled speakers, 4) long-duration fine-tuning.",
          "link": "http://arxiv.org/abs/2204.10228",
          "publishedOn": "2022-04-23T00:53:47.759Z",
          "wordCount": 729,
          "title": "The NIST CTS Speaker Recognition Challenge. (arXiv:2204.10228v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shahriari_B/0/1/0/all/0/1\">Bobak Shahriari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdolmaleki_A/0/1/0/all/0/1\">Abbas Abdolmaleki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byravan_A/0/1/0/all/0/1\">Arunkumar Byravan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friesen_A/0/1/0/all/0/1\">Abe Friesen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1\">Jost Tobias Springenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_M/0/1/0/all/0/1\">Matt Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>",
          "description": "Actor-critic algorithms that make use of distributional policy evaluation\nhave frequently been shown to outperform their non-distributional counterparts\non many challenging control tasks. Examples of this behavior include the D4PG\nand DMPO algorithms as compared to DDPG and MPO, respectively [Barth-Maron et\nal., 2018; Hoffman et al., 2020]. However, both agents rely on the C51 critic\nfor value estimation.One major drawback of the C51 approach is its requirement\nof prior knowledge about the minimum andmaximum values a policy can attain as\nwell as the number of bins used, which fixes the resolution ofthe\ndistributional estimate. While the DeepMind control suite of tasks utilizes\nstandardized rewards and episode lengths, thus enabling the entire suite to be\nsolved with a single setting of these hyperparameters, this is often not the\ncase. This paper revisits a natural alternative that removes this requirement,\nnamelya mixture of Gaussians, and a simple sample-based loss function to train\nit in an off-policy regime. We empirically evaluate its performance on a broad\nrange of continuous control tasks and demonstrate that it eliminates the need\nfor these distributional hyperparameters and achieves state-of-the-art\nperformance on a variety of challenging tasks (e.g. the humanoid, dog,\nquadruped, and manipulator domains). Finallywe provide an implementation in the\nAcme agent repository.",
          "link": "http://arxiv.org/abs/2204.10256",
          "publishedOn": "2022-04-23T00:53:47.734Z",
          "wordCount": 660,
          "title": "Revisiting Gaussian mixture critic in off-policy reinforcement learning: a sample-based approach. (arXiv:2204.10256v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biradar_S/0/1/0/all/0/1\">Shankar Biradar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saumya_S/0/1/0/all/0/1\">Sunil Saumya</a>",
          "description": "In recent years, there has been a lot of focus on offensive content. The\namount of offensive content generated by social media is increasing at an\nalarming rate. This created a greater need to address this issue than ever\nbefore. To address these issues, the organizers of \"Dravidian-Code Mixed\nHASOC-2020\" have created two challenges. Task 1 involves identifying offensive\ncontent in Malayalam data, whereas Task 2 includes Malayalam and Tamil Code\nMixed Sentences. Our team participated in Task 2. In our suggested model, we\nexperiment with multilingual BERT to extract features, and three different\nclassifiers are used on extracted features. Our model received a weighted F1\nscore of 0.70 for Malayalam data and was ranked fifth; we also received a\nweighted F1 score of 0.573 for Tamil Code Mixed data and were ranked eleventh.",
          "link": "http://arxiv.org/abs/2204.10195",
          "publishedOn": "2022-04-23T00:53:47.727Z",
          "wordCount": 587,
          "title": "IIITDWD-ShankarB@ Dravidian-CodeMixi-HASOC2021: mBERT based model for identification of offensive content in south Indian languages. (arXiv:2204.10195v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tanwar_A/0/1/0/all/0/1\">Ashwani Tanwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ive_J/0/1/0/all/0/1\">Julia Ive</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vibhor Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>",
          "description": "Extracting phenotypes from clinical text has been shown to be useful for a\nvariety of clinical use cases such as identifying patients with rare diseases.\nHowever, reasoning with numerical values remains challenging for phenotyping in\nclinical text, for example, temperature 102F representing Fever. Current\nstate-of-the-art phenotyping models are able to detect general phenotypes, but\nperform poorly when they detect phenotypes requiring numerical reasoning. We\npresent a novel unsupervised methodology leveraging external knowledge and\ncontextualized word embeddings from ClinicalBERT for numerical reasoning in a\nvariety of phenotypic contexts. Comparing against unsupervised benchmarks, it\nshows a substantial performance improvement with absolute gains on generalized\nRecall and F1 scores up to 79% and 71%, respectively. In the supervised\nsetting, it also surpasses the performance of alternative approaches with\nabsolute gains on generalized Recall and F1 scores up to 70% and 44%,\nrespectively.",
          "link": "http://arxiv.org/abs/2204.10202",
          "publishedOn": "2022-04-23T00:53:47.698Z",
          "wordCount": 589,
          "title": "Unsupervised Numerical Reasoning to Extract Phenotypes from Clinical Text by Leveraging External Knowledge. (arXiv:2204.10202v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pavlitskaya_S/0/1/0/all/0/1\">Svetlana Pavlitskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yikmis_S/0/1/0/all/0/1\">&#x15e;iyar Y&#x131;km&#x131;&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1\">J. Marius Z&#xf6;llner</a>",
          "description": "The growing use of deep neural networks (DNNs) in safety- and\nsecurity-critical areas like autonomous driving raises the need for their\nsystematic testing. Coverage-guided testing (CGT) is an approach that applies\nmutation or fuzzing according to a predefined coverage metric to find inputs\nthat cause misbehavior. With the introduction of a neuron coverage metric, CGT\nhas also recently been applied to DNNs. In this work, we apply CGT to the task\nof person detection in crowded scenes. The proposed pipeline uses YOLOv3 for\nperson detection and includes finding DNN bugs via sampling and mutation, and\nsubsequent DNN retraining on the updated training set. To be a bug, we require\na mutated image to cause a significant performance drop compared to a clean\ninput. In accordance with the CGT, we also consider an additional requirement\nof increased coverage in the bug definition. In order to explore several types\nof robustness, our approach includes natural image transformations,\ncorruptions, and adversarial examples generated with the Daedalus attack. The\nproposed framework has uncovered several thousand cases of incorrect DNN\nbehavior. The relative change in mAP performance of the retrained models\nreached on average between 26.21\\% and 64.24\\% for different robustness types.\nHowever, we have found no evidence that the investigated coverage metrics can\nbe advantageously used to improve robustness.",
          "link": "http://arxiv.org/abs/2204.10027",
          "publishedOn": "2022-04-23T00:53:47.691Z",
          "wordCount": 670,
          "title": "Is Neuron Coverage Needed to Make Person Detection More Robust?. (arXiv:2204.10027v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barahona_I/0/1/0/all/0/1\">Igor Barahona</a>",
          "description": "Here I present an investigation on the evolution and use of vocabulary in\ndata science in the last 13 years. Based on a rigorous statistical analysis, a\ndatabase with 12,787 documents containing the words \"data science\" in the\ntitle, abstract or keywords is analyzed. It is proposed to classify the\nevolution of this discipline in three periods: emergence, growth and boom.\nCharacteristic words and pioneering documents are identified for each period.\nBy proposing the distinctive vocabulary and relevant topics of data science and\nclassified in time periods, these results add value to the scientific community\nof this discipline.",
          "link": "http://arxiv.org/abs/2204.10174",
          "publishedOn": "2022-04-23T00:53:47.685Z",
          "wordCount": 550,
          "title": "Evolution and use of data science vocabulary. How much have we changed in 13 years?. (arXiv:2204.10174v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Senrong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Feng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>",
          "description": "Graph neural networks (GNNs) have been widely used in many real applications,\nand recent studies have revealed their vulnerabilities against topology\nattacks. To address this issue, existing efforts have mainly been dedicated to\nimproving the robustness of GNNs, while little attention has been paid to the\ndetection of such attacks. In this work, we study the victim node detection\nproblem under topology attacks against GNNs. Our approach is built upon the key\nobservation rooted in the intrinsic message passing nature of GNNs. That is,\nthe neighborhood of a victim node tends to have two competing group forces,\npushing the node classification results towards the original label and the\ntargeted label, respectively. Based on this observation, we propose to detect\nvictim nodes by deliberately designing an effective measurement of the\nneighborhood variance for each node. Extensive experimental results on four\nreal-world datasets and five existing topology attacks show the effectiveness\nand efficiency of the proposed detection approach.",
          "link": "http://arxiv.org/abs/2204.10072",
          "publishedOn": "2022-04-23T00:53:47.664Z",
          "wordCount": 594,
          "title": "Detecting Topology Attacks against Graph Neural Networks. (arXiv:2204.10072v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Binjie Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Haohao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yueqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1\">Song Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>",
          "description": "Video decomposition is very important to extract moving foreground objects\nfrom complex backgrounds in computer vision, machine learning, and medical\nimaging, e.g., extracting moving contrast-filled vessels from the complex and\nnoisy backgrounds of X-ray coronary angiography (XCA). However, the challenges\ncaused by dynamic backgrounds, overlapping heterogeneous environments and\ncomplex noises still exist in video decomposition. To solve these problems,\nthis study is the first to introduce a flexible visual working memory model in\nvideo decomposition tasks to provide interpretable and high-performance\nhierarchical deep architecture, integrating the transformative representations\nbetween sensory and control layers from the perspective of visual and cognitive\nneuroscience. Specifically, robust PCA unrolling networks acting as a\nstructure-regularized sensor layer decompose XCA into sparse/low-rank\nstructured representations to separate moving contrast-filled vessels from\nnoisy and complex backgrounds. Then, patch recurrent convolutional LSTM\nnetworks with a backprojection module embody unstructured random\nrepresentations of the control layer in working memory, recurrently projecting\nspatiotemporally decomposed nonlocal patches into orthogonal subspaces for\nheterogeneous vessel retrieval and interference suppression. This video\ndecomposition deep architecture effectively restores the heterogeneous profiles\nof intensity and the geometries of moving objects against the complex\nbackground interferences. Experiments show that the proposed method\nsignificantly outperforms state-of-the-art methods in accurate moving\ncontrast-filled vessel extraction with excellent flexibility and computational\nefficiency.",
          "link": "http://arxiv.org/abs/2204.10105",
          "publishedOn": "2022-04-23T00:53:47.640Z",
          "wordCount": 667,
          "title": "Working memory inspired hierarchical video decomposition with transformative representations. (arXiv:2204.10105v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scher_S/0/1/0/all/0/1\">Sebastian Scher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trugler_A/0/1/0/all/0/1\">Andreas Tr&#xfc;gler</a>",
          "description": "Correctly quantifying the robustness of machine learning models is a central\naspect in judging their suitability for specific tasks, and thus, ultimately,\nfor generating trust in the models. We show that the widely used concept of\nadversarial robustness and closely related metrics based on counterfactuals are\nnot necessarily valid metrics for determining the robustness of ML models\nagainst perturbations that occur \"naturally\", outside specific adversarial\nattack scenarios. Additionally, we argue that generic robustness metrics in\nprinciple are insufficient for determining real-world-robustness. Instead we\npropose a flexible approach that models possible perturbations in input data\nindividually for each application. This is then combined with a probabilistic\napproach that computes the likelihood that a real-world perturbation will\nchange a prediction, thus giving quantitative information of the robustness of\nthe trained machine learning model. The method does not require access to the\ninternals of the classifier and thus in principle works for any black-box\nmodel. It is, however, based on Monte-Carlo sampling and thus only suited for\ninput spaces with small dimensions. We illustrate our approach on two dataset,\nas well as on analytically solvable cases. Finally, we discuss ideas on how\nreal-world robustness could be computed or estimated in high-dimensional input\nspaces.",
          "link": "http://arxiv.org/abs/2204.10046",
          "publishedOn": "2022-04-23T00:53:47.625Z",
          "wordCount": 634,
          "title": "Robustness of Machine Learning Models Beyond Adversarial Attacks. (arXiv:2204.10046v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xusheng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_E/0/1/0/all/0/1\">Enguang Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhenzhen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiong Yu</a>",
          "description": "Outlier detection is an important topic in machine learning and has been used\nin a wide range of applications. Outliers are objects that are few in number\nand deviate from the majority of objects. As a result of these two properties,\nwe show that outliers are susceptible to a mechanism called fluctuation. This\narticle proposes a method called fluctuation-based outlier detection (FBOD)\nthat achieves a low linear time complexity and detects outliers purely based on\nthe concept of fluctuation without employing any distance, density or isolation\nmeasure. Fundamentally different from all existing methods. FBOD first converts\nthe Euclidean structure datasets into graphs by using random links, then\npropagates the feature value according to the connection of the graph. Finally,\nby comparing the difference between the fluctuation of an object and its\nneighbors, FBOD determines the object with a larger difference as an outlier.\nThe results of experiments comparing FBOD with seven state-of-the-art\nalgorithms on eight real-world tabular datasets and three video datasets show\nthat FBOD outperforms its competitors in the majority of cases and that FBOD\nhas only 5% of the execution time of the fastest algorithm. The experiment\ncodes are available at:\nhttps://github.com/FluctuationOD/Fluctuation-based-Outlier-Detection.",
          "link": "http://arxiv.org/abs/2204.10007",
          "publishedOn": "2022-04-23T00:53:47.604Z",
          "wordCount": 627,
          "title": "Fluctuation-based Outlier Detection. (arXiv:2204.10007v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09840",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_L/0/1/0/all/0/1\">Lingwei Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1\">Renyuan Zhang</a>",
          "description": "An end-to-end platform assembling multiple tiers is built for precisely\ncognizing brain activities. Being fed massive electroencephalogram (EEG) data,\nthe time-frequency spectrograms are conventionally projected into the\nepisode-wise feature matrices (seen as tier-1). A spiking neural network (SNN)\nbased tier is designed to distill the principle information in terms of\nspike-streams from the rare features, which maintains the temporal implication\nin the nature of EEGs. The proposed tier-3 transposes time- and space-domain of\nspike patterns from the SNN; and feeds the transposed pattern-matrices into an\nartificial neural network (ANN, Transformer specifically) known as tier-4,\nwhere a special spanning topology is proposed to match the two-dimensional\ninput form. In this manner, cognition such as classification is conducted with\nhigh accuracy. For proof-of-concept, the sleep stage scoring problem is\ndemonstrated by introducing multiple EEG datasets with the largest comprising\n42,560 hours recorded from 5,793 subjects. From experiment results, our\nplatform achieves the general cognition overall accuracy of 87% by leveraging\nsole EEG, which is 2% superior to the state-of-the-art. Moreover, our developed\nmulti-tier methodology offers visible and graphical interpretations of the\ntemporal characteristics of EEG by identifying the critical episodes, which is\ndemanded in neurodynamics but hardly appears in conventional cognition\nscenarios.",
          "link": "http://arxiv.org/abs/2204.09840",
          "publishedOn": "2022-04-23T00:53:47.570Z",
          "wordCount": 649,
          "title": "Multi-Tier Platform for Cognizing Massive Electroencephalogram. (arXiv:2204.09840v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tzoumpas_K/0/1/0/all/0/1\">Kostas Tzoumpas</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Estrada_A/0/1/0/all/0/1\">Aaron Estrada</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Miraglio_P/0/1/0/all/0/1\">Pietro Miraglio</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Zambelli_P/0/1/0/all/0/1\">Pietro Zambelli</a> (1) ((1) Eurac Research - Institute for Renewable Energy, Bolzano, Italy (2) Centro Euro-Mediterraneo sui Cambiamenti Climatici, Bologna, Italy)",
          "description": "In the process of collecting data from sensors, several circumstances can\naffect their continuity and validity, resulting in alterations of the data or\nloss of information. Although classical methods of statistics, such as\ninterpolation-like techniques, can be used to approximate the missing data in a\ntime series, the recent developments in Deep Learning (DL) have given impetus\nto innovative and much more accurate forecasting techniques. In the present\npaper, we develop two DL models aimed at filling data gaps, for the specific\ncase of internal temperature time series obtained from monitored apartments\nlocated in Bolzano, Italy. The DL models developed in the present work are\nbased on the combination of Convolutional Neural Networks (CNNs), Long\nShort-Term Memory Neural Networks (LSTMs), and Bidirectional LSTMs (BiLSTMs).\nTwo key features of our models are the use of both pre- and post-gap data, and\nthe exploitation of a correlated time series (the external temperature) in\norder to predict the target one (the internal temperature). Our approach\nmanages to capture the fluctuating nature of the data and shows good accuracy\nin reconstructing the target time series. In addition, our models significantly\nimprove the already good results from another DL architecture that is used as a\nbaseline for the present work.",
          "link": "http://arxiv.org/abs/2204.09994",
          "publishedOn": "2022-04-23T00:53:47.517Z",
          "wordCount": 671,
          "title": "A data filling methodology for time series based on CNN and (Bi)LSTM neural networks. (arXiv:2204.09994v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1\">Tingyun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaofang Zhou</a>",
          "description": "Indexing is an effective way to support efficient query processing in large\ndatabases. Recently the concept of learned index has been explored actively to\nreplace or supplement traditional index structures with machine learning models\nto reduce storage and search costs. However, accurate and efficient similarity\nquery processing in high-dimensional metric spaces remains to be an open\nchallenge. In this paper, a novel indexing approach called LIMS is proposed to\nuse data clustering and pivot-based data transformation techniques to build\nlearned indexes for efficient similarity query processing in metric spaces. The\nunderlying data is partitioned into clusters such that each cluster follows a\nrelatively uniform data distribution. Data redistribution is achieved by\nutilizing a small number of pivots for each cluster. Similar data are mapped\ninto compact regions and the mapped values are totally ordinal. Machine\nlearning models are developed to approximate the position of each data record\non the disk. Efficient algorithms are designed for processing range queries and\nnearest neighbor queries based on LIMS, and for index maintenance with dynamic\nupdates. Extensive experiments on real-world and synthetic datasets demonstrate\nthe superiority of LIMS compared with traditional indexes and state-of-the-art\nlearned indexes.",
          "link": "http://arxiv.org/abs/2204.10028",
          "publishedOn": "2022-04-23T00:53:47.501Z",
          "wordCount": 646,
          "title": "A Learned Index for Exact Similarity Search in Metric Spaces. (arXiv:2204.10028v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tibo_A/0/1/0/all/0/1\">Alessandro Tibo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_T/0/1/0/all/0/1\">Thomas Dyhre Nielsen</a>",
          "description": "Gaussian processes (GPs) are powerful but computationally expensive machine\nlearning models, requiring an estimate of the kernel covariance matrix for\nevery prediction. In large and complex domains, such as graphs, sets, or\nimages, the choice of suitable kernel can also be non-trivial to determine,\nproviding an additional obstacle to the learning task. Over the last decade,\nthese challenges have resulted in significant advances being made in terms of\nscalability and expressivity, exemplified by, e.g., the use of inducing points\nand neural network kernel approximations. In this paper, we propose inducing\nGaussian process networks (IGN), a simple framework for simultaneously learning\nthe feature space as well as the inducing points. The inducing points, in\nparticular, are learned directly in the feature space, enabling a seamless\nrepresentation of complex structured domains while also facilitating scalable\ngradient-based learning methods. We consider both regression and (binary)\nclassification tasks and report on experimental results for real-world data\nsets showing that IGNs provide significant advances over state-of-the-art\nmethods. We also demonstrate how IGNs can be used to effectively model complex\ndomains using neural network architectures.",
          "link": "http://arxiv.org/abs/2204.09889",
          "publishedOn": "2022-04-23T00:53:47.493Z",
          "wordCount": 605,
          "title": "Inducing Gaussian Process Networks. (arXiv:2204.09889v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goswami_S/0/1/0/all/0/1\">Somdatta Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kontolati_K/0/1/0/all/0/1\">Katiana Kontolati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shields_M/0/1/0/all/0/1\">Michael D. Shields</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Traditional machine learning algorithms are designed to learn in isolation,\ni.e. address single tasks. The core idea of transfer learning (TL) is that\nknowledge gained in learning to perform one task (source) can be leveraged to\nimprove learning performance in a related, but different, task (target). TL\nleverages and transfers previously acquired knowledge to address the expense of\ndata acquisition and labeling, potential computational power limitations, and\nthe dataset distribution mismatches. Although significant progress has been\nmade in the fields of image processing, speech recognition, and natural\nlanguage processing (for classification and regression) for TL, little work has\nbeen done in the field of scientific machine learning for functional regression\nand uncertainty quantification in partial differential equations. In this work,\nwe propose a novel TL framework for task-specific learning under conditional\nshift with a deep operator network (DeepONet). Inspired by the conditional\nembedding operator theory, we measure the statistical distance between the\nsource domain and the target feature domain by embedding conditional\ndistributions onto a reproducing kernel Hilbert space. Task-specific operator\nlearning is accomplished by fine-tuning task-specific layers of the target\nDeepONet using a hybrid loss function that allows for the matching of\nindividual target samples while also preserving the global properties of the\nconditional distribution of target data. We demonstrate the advantages of our\napproach for various TL scenarios involving nonlinear PDEs under conditional\nshift. Our results include geometry domain adaptation and show that the\nproposed TL framework enables fast and efficient multi-task operator learning,\ndespite significant differences between the source and target domains.",
          "link": "http://arxiv.org/abs/2204.09810",
          "publishedOn": "2022-04-23T00:53:47.446Z",
          "wordCount": 703,
          "title": "Deep transfer learning for partial differential equations under conditional shift with DeepONet. (arXiv:2204.09810v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yushun Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>",
          "description": "Graph mining algorithms have been playing a significant role in myriad fields\nover the years. However, despite their promising performance on various graph\nanalytical tasks, most of these algorithms lack fairness considerations. As a\nconsequence, they could lead to discrimination towards certain populations when\nexploited in human-centered applications. Recently, algorithmic fairness has\nbeen extensively studied in graph-based applications. In contrast to\nalgorithmic fairness on independent and identically distributed (i.i.d.) data,\nfairness in graph mining has exclusive backgrounds, taxonomies, and fulfilling\ntechniques. In this survey, we provide a comprehensive and up-to-date\nintroduction of existing literature under the context of fair graph mining.\nSpecifically, we propose a novel taxonomy of fairness notions on graphs, which\nsheds light on their connections and differences. We further present an\norganized summary of existing techniques that promote fairness in graph mining.\nFinally, we summarize the widely used datasets in this emerging research field\nand provide insights on current research challenges and open questions, aiming\nat encouraging cross-breeding ideas and further advances.",
          "link": "http://arxiv.org/abs/2204.09888",
          "publishedOn": "2022-04-23T00:53:47.378Z",
          "wordCount": 599,
          "title": "Fairness in Graph Mining: A Survey. (arXiv:2204.09888v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09938",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Janssen_J/0/1/0/all/0/1\">Joseph Janssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guan_V/0/1/0/all/0/1\">Vincent Guan</a>",
          "description": "Scientists frequently prioritize learning from data rather than training the\nbest possible model; however, research in machine learning often prioritizes\nthe latter. The development of marginal feature importance methods, such as\nmarginal contribution feature importance, attempts to break this trend by\nproviding a useful framework for explaining relationships in data in an\ninterpretable fashion. In this work, we generalize the framework of marginal\ncontribution feature importance to improve performance with regards to\ndetecting correlated interactions and reducing runtime. To do so, we consider\n\"information subsets\" of the set of features $F$ and show that our importance\nmetric can be computed directly after applying fair representation learning\nmethods from the AI fairness literature. The methods of optimal transport and\nlinear regression are considered and explored experimentally for removing all\nthe information of our feature of interest $f$ from the feature set $F$. Given\nthese implementations, we show on real and simulated data that ultra marginal\nfeature importance performs at least as well as marginal contribution feature\nimportance, with substantially faster computation time and better performance\nin the presence of correlated interactions and unrelated features.",
          "link": "http://arxiv.org/abs/2204.09938",
          "publishedOn": "2022-04-23T00:53:47.372Z",
          "wordCount": 616,
          "title": "Ultra Marginal Feature Importance. (arXiv:2204.09938v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giulivi_L/0/1/0/all/0/1\">Loris Giulivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carman_M/0/1/0/all/0/1\">Mark James Carman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boracchi_G/0/1/0/all/0/1\">Giacomo Boracchi</a>",
          "description": "Artificial intelligence (AI) systems power the world we live in. Deep neural\nnetworks (DNNs) are able to solve tasks in an ever-expanding landscape of\nscenarios, but our eagerness to apply these powerful models leads us to focus\non their performance and deprioritises our ability to understand them. Current\nresearch in the field of explainable AI tries to bridge this gap by developing\nvarious perturbation or gradient-based explanation techniques. For images,\nthese techniques fail to fully capture and convey the semantic information\nneeded to elucidate why the model makes the predictions it does. In this work,\nwe develop a new form of explanation that is radically different in nature from\ncurrent explanation methods, such as Grad-CAM. Perception visualization\nprovides a visual representation of what the DNN perceives in the input image\nby depicting what visual patterns the latent representation corresponds to.\nVisualizations are obtained through a reconstruction model that inverts the\nencoded features, such that the parameters and predictions of the original\nmodels are not modified. Results of our user study demonstrate that humans can\nbetter understand and predict the system's decisions when perception\nvisualizations are available, thus easing the debugging and deployment of deep\nmodels as trusted systems.",
          "link": "http://arxiv.org/abs/2204.09920",
          "publishedOn": "2022-04-23T00:53:47.335Z",
          "wordCount": 660,
          "title": "Perception Visualization: Seeing Through the Eyes of a DNN. (arXiv:2204.09920v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jintang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1\">Jie Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Ruofan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Changhua Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zibin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiqiang Wang</a>",
          "description": "Recently, graph convolutional networks (GCNs) have shown to be vulnerable to\nsmall adversarial perturbations, which becomes a severe threat and largely\nlimits their applications in security-critical scenarios. To mitigate such a\nthreat, considerable research efforts have been devoted to increasing the\nrobustness of GCNs against adversarial attacks. However, current approaches for\ndefense are typically designed for the whole graph and consider the global\nperformance, posing challenges in protecting important local nodes from\nstronger adversarial targeted attacks. In this work, we present a simple yet\neffective method, named \\textbf{\\underline{G}}raph\n\\textbf{\\underline{U}}niversal\n\\textbf{\\underline{A}}dve\\textbf{\\underline{R}}sarial\n\\textbf{\\underline{D}}efense (GUARD). Unlike previous works, GUARD protects\neach individual node from attacks with a universal defensive patch, which is\ngenerated once and can be applied to any node (node-agnostic) in a graph.\nExtensive experiments on four benchmark datasets demonstrate that our method\nsignificantly improves robustness for several established GCNs against multiple\nadversarial attacks and outperforms existing adversarial defense methods by\nlarge margins. Our code is publicly available at\nhttps://github.com/EdisonLeeeee/GUARD.",
          "link": "http://arxiv.org/abs/2204.09803",
          "publishedOn": "2022-04-23T00:53:47.328Z",
          "wordCount": 612,
          "title": "GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xu Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasha Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hailong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Liantao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junfeng Zhao</a>",
          "description": "In healthcare prediction tasks, it is essential to exploit the correlations\nbetween medical features and learn better patient health representations.\nExisting methods try to estimate feature correlations only from data, or\nincrease the quality of estimation by introducing task-specific medical\nknowledge. However, such methods either are difficult to estimate the feature\ncorrelations due to insufficient training samples, or cannot be generalized to\nother tasks due to reliance on specific knowledge. There are medical research\nrevealing that not all the medical features are strongly correlated. Thus, to\naddress the issues, we expect to group up strongly correlated features and\nlearn feature correlations in a group-wise manner to reduce the learning\ncomplexity without losing generality. In this paper, we propose a general\npatient health representation learning framework MedFACT. We estimate\ncorrelations via measuring similarity between temporal patterns of medical\nfeatures with kernel methods, and cluster features with strong correlations\ninto groups. The feature group is further formulated as a correlation graph,\nand we employ graph convolutional networks to conduct group-wise feature\ninteractions for better representation learning. Experiments on two real-world\ndatasets demonstrate the superiority of MedFACT. The discovered medical\nfindings are also confirmed by literature, providing valuable medical insights\nand explanations.",
          "link": "http://arxiv.org/abs/2204.10011",
          "publishedOn": "2022-04-23T00:53:47.293Z",
          "wordCount": 652,
          "title": "MedFACT: Modeling Medical Feature Correlations in Patient Health Representation Learning via Feature Clustering. (arXiv:2204.10011v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ahsan Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1\">Hemant Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kettimuthu_R/0/1/0/all/0/1\">Rajkumar Kettimuthu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenesei_P/0/1/0/all/0/1\">Peter Kenesei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trujillo_D/0/1/0/all/0/1\">Dennis Trujillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miceli_A/0/1/0/all/0/1\">Antonino Miceli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coffee_R/0/1/0/all/0/1\">Ryan Coffee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thayer_J/0/1/0/all/0/1\">Jana Thayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengchun Liu</a>",
          "description": "Extracting actionable information from data sources such as the Linac\nCoherent Light Source (LCLS-II) and Advanced Photon Source Upgrade (APS-U) is\nbecoming more challenging due to the fast-growing data generation rate. The\nrapid analysis possible with ML methods can enable fast feedback loops that can\nbe used to adjust experimental setups in real-time, for example when errors\noccur or interesting events are detected. However, to avoid degradation in ML\nperformance over time due to changes in an instrument or sample, we need a way\nto update ML models rapidly while an experiment is running. We present here a\ndata service and model service to accelerate deep neural network training with\na focus on ML-based scientific applications. Our proposed data service achieves\n100x speedup in terms of data labeling compare to the current state-of-the-art.\nFurther, our model service achieves up to 200x improvement in training speed.\nOverall, fairDMS achieves up to 92x speedup in terms of end-to-end model\nupdating time.",
          "link": "http://arxiv.org/abs/2204.09805",
          "publishedOn": "2022-04-23T00:53:47.287Z",
          "wordCount": 606,
          "title": "fairDMS: Rapid Model Training by Data and Model Reuse. (arXiv:2204.09805v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1\">Qi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>",
          "description": "Despite the success of reinforcement learning (RL) for Markov decision\nprocesses (MDPs) with function approximation, most RL algorithms easily fail if\nthe agent only has partial observations of the state. Such a setting is often\nmodeled as a partially observable Markov decision process (POMDP). Existing\nsample-efficient algorithms for POMDPs are restricted to the tabular setting\nwhere the state and observation spaces are finite. In this paper, we make the\nfirst attempt at tackling the tension between function approximation and\npartial observability. In specific, we focus on a class of undercomplete POMDPs\nwith linear function approximations, which allows the state and observation\nspaces to be infinite. For such POMDPs, we show that the optimal policy and\nvalue function can be characterized by a sequence of finite-memory Bellman\noperators. We propose an RL algorithm that constructs optimistic estimators of\nthese operators via reproducing kernel Hilbert space (RKHS) embedding.\nMoreover, we theoretically prove that the proposed algorithm finds an\n$\\varepsilon$-optimal policy with $\\tilde O (1/\\varepsilon^2)$ episodes of\nexploration. Also, this sample complexity only depends on the intrinsic\ndimension of the POMDP polynomially and is independent of the size of the state\nand observation spaces. To our best knowledge, we develop the first provably\nsample-efficient algorithm for POMDPs with function approximation.",
          "link": "http://arxiv.org/abs/2204.09787",
          "publishedOn": "2022-04-23T00:53:47.278Z",
          "wordCount": 651,
          "title": "Sample-Efficient Reinforcement Learning for POMDPs with Linear Function Approximations. (arXiv:2204.09787v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ro_J/0/1/0/all/0/1\">Jae Hun Ro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breiner_T/0/1/0/all/0/1\">Theresa Breiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McConnaughey_L/0/1/0/all/0/1\">Lara McConnaughey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ananda Theertha Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathews_R/0/1/0/all/0/1\">Rajiv Mathews</a>",
          "description": "Most studies in cross-device federated learning focus on small models, due to\nthe server-client communication and on-device computation bottlenecks. In this\nwork, we leverage various techniques for mitigating these bottlenecks to train\nlarger language models in cross-device federated learning. With systematic\napplications of partial model training, quantization, efficient transfer\nlearning, and communication-efficient optimizers, we are able to train a $21$M\nparameter Transformer that achieves the same perplexity as that of a similarly\nsized LSTM with $\\sim10\\times$ smaller client-to-server communication cost and\n$11\\%$ lower perplexity than smaller LSTMs commonly studied in literature.",
          "link": "http://arxiv.org/abs/2204.09715",
          "publishedOn": "2022-04-23T00:53:47.272Z",
          "wordCount": 538,
          "title": "Scaling Language Model Size in Cross-Device Federated Learning. (arXiv:2204.09715v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Weichao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenchao Li</a>",
          "description": "A misspecified reward can degrade sample efficiency and induce undesired\nbehaviors in reinforcement learning (RL) problems. We propose symbolic reward\nmachines for incorporating high-level task knowledge when specifying the reward\nsignals. Symbolic reward machines augment existing reward machine formalism by\nallowing transitions to carry predicates and symbolic reward outputs. This\nformalism lends itself well to inverse reinforcement learning, whereby the key\nchallenge is determining appropriate assignments to the symbolic values from a\nfew expert demonstrations. We propose a hierarchical Bayesian approach for\ninferring the most likely assignments such that the concretized reward machine\ncan discriminate expert demonstrated trajectories from other trajectories with\nhigh accuracy. Experimental results show that learned reward machines can\nsignificantly improve training efficiency for complex RL tasks and generalize\nwell across different task environment configurations.",
          "link": "http://arxiv.org/abs/2204.09772",
          "publishedOn": "2022-04-23T00:53:47.263Z",
          "wordCount": 568,
          "title": "A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines. (arXiv:2204.09772v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhixiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_W/0/1/0/all/0/1\">Wenqiang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nallanathan_A/0/1/0/all/0/1\">Arumugam Nallanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Geoffrey Ye Li</a>",
          "description": "The limited communication resources, e.g., bandwidth and energy, and data\nheterogeneity across devices are two of the main bottlenecks for federated\nlearning (FL). To tackle these challenges, we first devise a novel FL framework\nwith partial model aggregation (PMA), which only aggregates the lower layers of\nneural networks responsible for feature extraction while the upper layers\ncorresponding to complex pattern recognition remain at devices for\npersonalization. The proposed PMA-FL is able to address the data heterogeneity\nand reduce the transmitted information in wireless channels. We then obtain a\nconvergence bound of the framework under a non-convex loss function setting.\nWith the aid of this bound, we define a new objective function, named the\nscheduled data sample volume, to transfer the original inexplicit optimization\nproblem into a tractable one for device scheduling, bandwidth allocation,\ncomputation and communication time division. Our analysis reveals that the\noptimal time division is achieved when the communication and computation parts\nof PMA-FL have the same power. We also develop a bisection method to solve the\noptimal bandwidth allocation policy and use the set expansion algorithm to\naddress the optimal device scheduling. Compared with the state-of-the-art\nbenchmarks, the proposed PMA-FL improves 2.72% and 11.6% accuracy on two\ntypical heterogeneous datasets, i.e., MINIST and CIFAR-10, respectively. In\naddition, the proposed joint dynamic device scheduling and resource\noptimization approach achieve slightly higher accuracy than the considered\nbenchmarks, but they provide a satisfactory energy and time reduction: 29%\nenergy or 20% time reduction on the MNIST; and 25% energy or 12.5% time\nreduction on the CIFAR-10.",
          "link": "http://arxiv.org/abs/2204.09746",
          "publishedOn": "2022-04-23T00:53:47.240Z",
          "wordCount": 701,
          "title": "Federated Learning for Energy-limited Wireless Networks: A Partial Model Aggregation Approach. (arXiv:2204.09746v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xingang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Bin Hu</a>",
          "description": "In this paper, we consider the policy evaluation problem in multi-agent\nreinforcement learning (MARL) and derive exact closed-form formulas for the\nfinite-time mean-squared estimation errors of decentralized temporal difference\n(TD) learning with linear function approximation. Our analysis hinges upon the\nfact that the decentralized TD learning method can be viewed as a Markov jump\nlinear system (MJLS). Then standard MJLS theory can be applied to quantify the\nmean and covariance matrix of the estimation error of the decentralized TD\nmethod at every time step. Various implications of our exact formulas on the\nalgorithm performance are also discussed. An interesting finding is that under\na necessary and sufficient stability condition, the mean-squared TD estimation\nerror will converge to an exact limit at a specific exponential rate.",
          "link": "http://arxiv.org/abs/2204.09801",
          "publishedOn": "2022-04-23T00:53:47.233Z",
          "wordCount": 581,
          "title": "Exact Formulas for Finite-Time Estimation Errors of Decentralized Temporal Difference Learning with Linear Function Approximation. (arXiv:2204.09801v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Darapaneni_N/0/1/0/all/0/1\">Narayana Darapaneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhakuni_C/0/1/0/all/0/1\">Chandrashekhar Bhakuni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_U/0/1/0/all/0/1\">Ujjval Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purohit_K/0/1/0/all/0/1\">Khamir Purohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sardna_V/0/1/0/all/0/1\">Vikas Sardna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_P/0/1/0/all/0/1\">Prabir Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paduri_A/0/1/0/all/0/1\">Anwesh Reddy Paduri</a>",
          "description": "Businesses need content. In various forms and formats and for varied\npurposes. In fact, the content marketing industry is set to be worth $412.88\nbillion by the end of 2021. However, according to the Content Marketing\nInstitute, creating engaging content is the #1 challenge that marketers face\ntoday. We under-stand that producing great content requires great writers who\nunderstand the business and can weave their message into reader (and search\nengine) friendly content. In this project, the team has attempted to bridge the\ngap between writers and projects by using AI and ML tools. We used NLP\ntechniques to analyze thou-sands of publicly available business articles\n(corpora) to extract various defining factors for each writing sample. Through\nthis project we aim to automate the highly time-consuming, and often biased\ntask of manually shortlisting the most suitable writer for a given content\nwriting requirement. We believe that a tool like this will have far reaching\npositive implications for both parties - businesses looking for suitable talent\nfor niche writing jobs as well as experienced writers and Subject Matter\nExperts (SMEs) wanting to lend their services to content marketing projects.\nThe business gets the content they need, the content writer/ SME gets a chance\nto leverage his or her talent, while the reader gets authentic content that\nadds real value.",
          "link": "http://arxiv.org/abs/2204.09718",
          "publishedOn": "2022-04-23T00:53:47.176Z",
          "wordCount": 663,
          "title": "Matching Writers to Content Writing Tasks. (arXiv:2204.09718v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>",
          "description": "Biological systems in nature have evolved for millions of years to adapt and\nsurvive the environment. Many features they developed can be inspirational and\nbeneficial for solving technical problems in modern industries. This leads to a\nnovel form of design-by-analogy called bio-inspired design (BID). Although BID\nas a design method has been proven beneficial, the gap between biology and\nengineering continuously hinders designers from effectively applying the\nmethod. Therefore, we explore the recent advance of artificial intelligence\n(AI) for a computational approach to bridge the gap. This paper proposes a\ngenerative design approach based on the pre-trained language model (PLM) to\nautomatically retrieve and map biological analogy and generate BID in the form\nof natural language. The latest generative pre-trained transformer, namely\nGPT-3, is used as the base PLM. Three types of design concept generators are\nidentified and fine-tuned from the PLM according to the looseness of the\nproblem space representation. Machine evaluators are also fine-tuned to assess\nthe correlation between the domains within the generated BID concepts. The\napproach is then tested via a case study in which the fine-tuned models are\napplied to generate and evaluate light-weighted flying car concepts inspired by\nnature. The results show our approach can generate BID concepts with good\nperformance.",
          "link": "http://arxiv.org/abs/2204.09714",
          "publishedOn": "2022-04-23T00:53:47.168Z",
          "wordCount": 655,
          "title": "Generative Pre-Trained Transformers for Biologically Inspired Design. (arXiv:2204.09714v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Magron_P/0/1/0/all/0/1\">Paul Magron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1\">C&#xe9;dric F&#xe9;votte</a>",
          "description": "This paper tackles the problem of decomposing binary data using matrix\nfactorization. We consider the family of mean-parametrized Bernoulli models, a\nclass of generative models that are well suited for modeling binary data and\nenables interpretability of the factors. We factorize the Bernoulli parameter\nand consider an additional Beta prior on one of the factors to further improve\nthe model's expressive power. While similar models have been proposed in the\nliterature, they only exploit the Beta prior as a proxy to ensure a valid\nBernoulli parameter in a Bayesian setting; in practice it reduces to a uniform\nor uninformative prior. Besides, estimation in these models has focused on\ncostly Bayesian inference. In this paper, we propose a simple yet very\nefficient majorization-minimization algorithm for maximum a posteriori\nestimation. Our approach leverages the Beta prior whose parameters can be tuned\nto improve performance in matrix completion tasks. Experiments conducted on\nthree public binary datasets show that our approach offers an excellent\ntrade-off between prediction performance, computational complexity, and\ninterpretability.",
          "link": "http://arxiv.org/abs/2204.09741",
          "publishedOn": "2022-04-23T00:53:47.140Z",
          "wordCount": 603,
          "title": "A majorization-minimization algorithm for nonnegative binary matrix factorization. (arXiv:2204.09741v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Ki-Ung Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shim_D/0/1/0/all/0/1\">Dongseok Shim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kang-wook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae-young Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Younggeun Kim</a>",
          "description": "Super-resolution suffers from an innate ill-posed problem that a single\nlow-resolution (LR) image can be from multiple high-resolution (HR) images.\nRecent studies on the flow-based algorithm solve this ill-posedness by learning\nthe super-resolution space and predicting diverse HR outputs. Unfortunately,\nthe diversity of the super-resolution outputs is still unsatisfactory, and the\noutputs from the flow-based model usually suffer from undesired artifacts which\ncauses low-quality outputs. In this paper, we propose FS-NCSR which produces\ndiverse and high-quality super-resolution outputs using frequency separation\nand noise conditioning compared to the existing flow-based approaches. As the\nsharpness and high-quality detail of the image rely on its high-frequency\ninformation, FS-NCSR only estimates the high-frequency information of the\nhigh-resolution outputs without redundant low-frequency components. Through\nthis, FS-NCSR significantly improves the diversity score without significant\nimage quality degradation compared to the NCSR, the winner of the previous\nNTIRE 2021 challenge.",
          "link": "http://arxiv.org/abs/2204.09679",
          "publishedOn": "2022-04-23T00:53:47.021Z",
          "wordCount": 615,
          "title": "FS-NCSR: Increasing Diversity of the Super-Resolution Space via Frequency Separation and Noise-Conditioned Normalizing Flow. (arXiv:2204.09679v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.08215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_W/0/1/0/all/0/1\">Wasifur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Masum Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md Saiful Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olubajo_T/0/1/0/all/0/1\">Titilayo Olubajo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thaker_J/0/1/0/all/0/1\">Jeet Thaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelkader_A/0/1/0/all/0/1\">Abdelrahman Abdelkader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Phillip Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashizawa_T/0/1/0/all/0/1\">Tetsuo Ashizawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoque_E/0/1/0/all/0/1\">Ehsan Hoque</a>",
          "description": "In this paper, we investigated whether we can 1) detect participants with\nataxia-specific gait characteristics (risk-prediction), and 2) assess severity\nof ataxia from gait (severity-assessment) using computer vision. We created a\ndataset of 155 videos from 89 participants, 24 controls and 65 diagnosed with\n(or are pre-manifest) spinocerebellar ataxias (SCAs), performing the gait task\nof the Scale for the Assessment and Rating of Ataxia (SARA) from 11 medical\nsites located in 8 different states across the United States. We develop a\ncomputer vision pipeline to detect, track, and separate out the participants\nfrom their surroundings and construct several features from their body pose\ncoordinates to capture gait characteristics like step width, step length,\nswing, stability, speed, etc. Our risk-prediction model achieves 83.06%\naccuracy and an 80.23% F1 score. Similarly, our severity-assessment model\nachieves a mean absolute error (MAE) score of 0.6225 and a Pearson's\ncorrelation coefficient score of 0.7268. Our models still performed\ncompetitively when evaluated on data from sites not used during training.\nFurthermore, through feature importance analysis, we found that our models\nassociate wider steps, decreased walking speed, and increased instability with\ngreater ataxia severity, which is consistent with previously established\nclinical knowledge. Our models create possibilities for remote ataxia\nassessment in non-clinical settings in the future, which could significantly\nimprove accessibility of ataxia care. Furthermore, our underlying dataset was\nassembled from a geographically diverse cohort, highlighting its potential to\nfurther increase equity. The code used in this study is open to the public, and\nthe anonymized body pose landmark dataset is also available upon request.",
          "link": "http://arxiv.org/abs/2203.08215",
          "publishedOn": "2022-04-18T00:59:14.071Z",
          "wordCount": null,
          "title": "Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait Task Videos. (arXiv:2203.08215v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungyung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungjin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>",
          "description": "Though deep generative models have gained a lot of attention, most of the\nexisting works are designed for the unimodal generation task. In this paper, we\nexplore a new method for unconditional image-text pair generation. We propose\nMXQ-VAE, a vector quantization method for multimodal image-text representation.\nMXQ-VAE accepts a paired image and text as input, and learns a joint quantized\nrepresentation space, so that the image-text pair can be converted to a\nsequence of unified indices. Then we can use autoregressive generative models\nto model the joint image-text representation, and even perform unconditional\nimage-text pair generation. Extensive experimental results demonstrate that our\napproach effectively generates semantically consistent image-text pair and also\nenhances meaningful alignment between image and text.",
          "link": "http://arxiv.org/abs/2204.07537",
          "publishedOn": "2022-04-18T00:59:14.070Z",
          "wordCount": 571,
          "title": "Unconditional Image-Text Pair Generation with Multimodal Cross Quantizer. (arXiv:2204.07537v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruocheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candan_K/0/1/0/all/0/1\">Kasim Selcuk Candan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "Online review systems are the primary means through which many businesses\nseek to build the brand and spread their messages. Prior research studying the\neffects of online reviews has been mainly focused on a single numerical cause,\ne.g., ratings or sentiment scores. We argue that such notions of causes entail\nthree key limitations: they solely consider the effects of single numerical\ncauses and ignore different effects of multiple aspects -- e.g., Food, Service\n-- embedded in the textual reviews; they assume the absence of hidden\nconfounders in observational studies, e.g., consumers' personal preferences;\nand they overlook the indirect effects of numerical causes that can potentially\ncancel out the effect of textual reviews on business revenue. We thereby\npropose an alternative perspective to this single-cause-based effect estimation\nof online reviews: in the presence of hidden confounders, we consider\nmulti-aspect textual reviews, particularly, their total effects on business\nrevenue and direct effects with the numerical cause -- ratings -- being the\nmediator. We draw on recent advances in machine learning and causal inference\nto together estimate the hidden confounders and causal effects. We present\nempirical evaluations using real-world examples to discuss the importance and\nimplications of differentiating the multi-aspect effects in strategizing\nbusiness operations.",
          "link": "http://arxiv.org/abs/2110.01746",
          "publishedOn": "2022-04-18T00:59:14.063Z",
          "wordCount": 688,
          "title": "Effects of Multi-Aspect Online Reviews with Unobserved Confounders: Estimation and Implication. (arXiv:2110.01746v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14831",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pan_J/0/1/0/all/0/1\">Jiayi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1\">Heye Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1\">Weifei Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_Z/0/1/0/all/0/1\">Zhifan Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1\">Weiwen Wu</a>",
          "description": "Decreasing projection views to lower X-ray radiation dose usually leads to\nsevere streak artifacts. To improve image quality from sparse-view data, a\nMulti-domain Integrative Swin Transformer network (MIST-net) was developed in\nthis article. First, MIST-net incorporated lavish domain features from data,\nresidual-data, image, and residual-image using flexible network architectures,\nwhere residual-data and residual-image sub-network was considered as data\nconsistency module to eliminate interpolation and reconstruction errors.\nSecond, a trainable edge enhancement filter was incorporated to detect and\nprotect image edges. Third, a high-quality reconstruction Swin transformer\n(i.e., Recformer) was designed to capture image global features. The experiment\nresults on numerical and real cardiac clinical datasets with 48-views\ndemonstrated that our proposed MIST-net provided better image quality with more\nsmall features and sharp edges than other competitors.",
          "link": "http://arxiv.org/abs/2111.14831",
          "publishedOn": "2022-04-18T00:59:14.055Z",
          "wordCount": null,
          "title": "Multi-domain Integrative Swin Transformer network for Sparse-View Tomographic Reconstruction. (arXiv:2111.14831v7 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_R/0/1/0/all/0/1\">Rishabh Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_P/0/1/0/all/0/1\">Pradeep Shenoy</a>",
          "description": "Continual learning (CL) aims to develop techniques by which a single model\nadapts to an increasing number of tasks encountered sequentially, thereby\npotentially leveraging learnings across tasks in a resource-efficient manner. A\nmajor challenge for CL systems is catastrophic forgetting, where earlier tasks\nare forgotten while learning a new task. To address this, replay-based CL\napproaches maintain and repeatedly retrain on a small buffer of data selected\nacross encountered tasks. We propose Gradient Coreset Replay (GCR), a novel\nstrategy for replay buffer selection and update using a carefully designed\noptimization criterion. Specifically, we select and maintain a \"coreset\" that\nclosely approximates the gradient of all the data seen so far with respect to\ncurrent model parameters, and discuss key strategies needed for its effective\napplication to the continual learning setting. We show significant gains (2%-4%\nabsolute) over the state-of-the-art in the well-studied offline continual\nlearning setting. Our findings also effectively transfer to online / streaming\nCL settings, showing upto 5% gains over existing approaches. Finally, we\ndemonstrate the value of supervised contrastive loss for continual learning,\nwhich yields a cumulative gain of up to 5% accuracy when combined with our\nsubset selection strategy.",
          "link": "http://arxiv.org/abs/2111.11210",
          "publishedOn": "2022-04-18T00:59:14.054Z",
          "wordCount": null,
          "title": "GCR: Gradient Coreset Based Replay Buffer Selection For Continual Learning. (arXiv:2111.11210v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Hengshuai Yao</a>",
          "description": "Gradient descent is slow to converge for ill-conditioned problems and\nnon-convex problems. An important technique for acceleration is step-size\nadaptation. The first part of this paper contains a detailed review of\nstep-size adaptation methods, including Polyak step-size, L4, LossGrad, Adam,\nIDBD, and Hypergradient descent, and the relation of step-size adaptation to\nmeta-gradient methods. In the second part of this paper, we propose a new class\nof methods of accelerating gradient descent that have some distinctiveness from\nexisting techniques. The new methods, which we call {\\em step-size planning},\nuse the {\\em update experience} to learn an improved way of updating the\nparameters. The methods organize the experience into $K$ steps away from each\nother to facilitate planning. From the past experience, our planning algorithm,\nCsawg, learns a step-size model which is a form of multi-step machine that\npredicts future updates. We extends Csawg to applying step-size planning\nmultiple steps, which leads to further speedup. We discuss and highlight the\nprojection power of the diagonal-matrix step-size for future large scale\napplications. We show for a convex problem, our methods can surpass the\nconvergence rate of Nesterov's accelerated gradient, $1 - \\sqrt{\\mu/L}$, where\n$\\mu, L$ are the strongly convex factor of the loss function $F$ and the\nLipschitz constant of $F'$, which is the theoretical limit for the convergence\nrate of first-order methods. On the well-known non-convex Rosenbrock function,\nour planning methods achieve zero error below 500 gradient evaluations, while\ngradient descent takes about 10000 gradient evaluations to reach a $10^{-3}$\naccuracy. We discuss the connection of step-size planing to planning in\nreinforcement learning, in particular, Dyna architectures.",
          "link": "http://arxiv.org/abs/2204.01705",
          "publishedOn": "2022-04-18T00:59:14.053Z",
          "wordCount": 725,
          "title": "Learning to Accelerate by the Methods of Step-size Planning. (arXiv:2204.01705v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaikumar_P/0/1/0/all/0/1\">Punitha Jaikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandaele_R/0/1/0/all/0/1\">Remy Vandaele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ojha_V/0/1/0/all/0/1\">Varun Ojha</a>",
          "description": "This paper proposes a methodological approach with a transfer learning scheme\nfor plastic waste bottle detection and instance segmentation using the\n\\textit{mask region proposal convolutional neural network} (Mask R-CNN).\nPlastic bottles constitute one of the major pollutants posing a serious threat\nto the environment both in oceans and on land. The automated identification and\nsegregation of bottles can facilitate plastic waste recycling. We prepare a\ncustom-made dataset of 192 bottle images with pixel-by pixel-polygon annotation\nfor the automatic segmentation task. The proposed transfer learning scheme\nmakes use of a Mask R-CNN model pre-trained on the Microsoft COCO dataset. We\npresent a comprehensive scheme for fine-tuning the base pre-trained Mask-RCNN\nmodel on our custom dataset. Our final fine-tuned model has achieved 59.4\n\\textit{mean average precision} (mAP), which corresponds to the MS COCO metric.\nThe results indicate a promising application of deep learning for detecting\nwaste bottles.",
          "link": "http://arxiv.org/abs/2204.07437",
          "publishedOn": "2022-04-18T00:59:14.028Z",
          "wordCount": 614,
          "title": "Transfer Learning for Instance Segmentation of Waste Bottles using Mask R-CNN Algorithm. (arXiv:2204.07437v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mussabayev_R/0/1/0/all/0/1\">Rustam Mussabayev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mladenovic_N/0/1/0/all/0/1\">Nenad Mladenovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_B/0/1/0/all/0/1\">Bassem Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussabayev_R/0/1/0/all/0/1\">Ravil Mussabayev</a>",
          "description": "K-means clustering plays a vital role in data mining. However, its\nperformance drastically drops when applied to huge amounts of data. We propose\na new heuristic that is built on the basis of regular K-means for faster and\nmore accurate big data clustering using the \"less is more\" and MSSC\ndecomposition approaches. The main advantage of the proposed algorithm is that\nit naturally turns the K-means local search into global one through the process\nof decomposition of the MSSC problem. On one hand, decomposition of the MSSC\nproblem into smaller subproblems reduces the computational complexity and\nallows for their parallel processing. On the other hand, the MSSC decomposition\nprovides a new method for the natural data-driven shaking of the incumbent\nsolution while introducing a new neighborhood structure for the solution of the\nMSSC problem. This leads to a new heuristic that improves K-means in big data\nconditions. The scalability of the algorithm to big data can be easily adjusted\nby choosing the appropriate number of subproblems and their size. The proposed\nalgorithm is both scalable and accurate. In our experiments it outperforms all\nrecent state-of-the-art algorithms for the MSSC in terms of time as well as the\nsolution quality.",
          "link": "http://arxiv.org/abs/2204.07485",
          "publishedOn": "2022-04-18T00:59:14.020Z",
          "wordCount": 630,
          "title": "Big-means: Less is More for K-means Clustering. (arXiv:2204.07485v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangdon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiayan Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Accurately detecting and tracking multi-objects is important for\nsafety-critical applications such as autonomous navigation. However, it remains\nchallenging to provide guarantees on the performance of state-of-the-art\ntechniques based on deep learning. We consider a strategy known as conformal\nprediction, which predicts sets of labels instead of a single label; in the\nclassification and regression settings, these algorithms can guarantee that the\ntrue label lies within the prediction set with high probability. Building on\nthese ideas, we propose multi-object detection and tracking algorithms that\ncome with probably approximately correct (PAC) guarantees. They do so by\nconstructing both a prediction set around each object detection as well as\naround the set of edge transitions; given an object, the detection prediction\nset contains its true bounding box with high probability, and the edge\nprediction set contains its true transition across frames with high\nprobability. We empirically demonstrate that our method can detect and track\nobjects with PAC guarantees on the COCO and MOT-17 datasets.",
          "link": "http://arxiv.org/abs/2204.07482",
          "publishedOn": "2022-04-18T00:59:14.012Z",
          "wordCount": null,
          "title": "Towards PAC Multi-Object Detection and Tracking. (arXiv:2204.07482v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.11991",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zeng_S/0/1/0/all/0/1\">Sihan Zeng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kody_A/0/1/0/all/0/1\">Alyssa Kody</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_Y/0/1/0/all/0/1\">Youngdae Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_K/0/1/0/all/0/1\">Kibaek Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Molzahn_D/0/1/0/all/0/1\">Daniel K. Molzahn</a>",
          "description": "With the increasing penetration of distributed energy resources, distributed\noptimization algorithms have attracted significant attention for power systems\napplications due to their potential for superior scalability, privacy, and\nrobustness to a single point-of-failure. The Alternating Direction Method of\nMultipliers (ADMM) is a popular distributed optimization algorithm; however,\nits convergence performance is highly dependent on the selection of penalty\nparameters, which are usually chosen heuristically. In this work, we use\nreinforcement learning (RL) to develop an adaptive penalty parameter selection\npolicy for the AC optimal power flow (ACOPF) problem solved via ADMM with the\ngoal of minimizing the number of iterations until convergence. We train our RL\npolicy using deep Q-learning, and show that this policy can result in\nsignificantly accelerated convergence (up to a 59% reduction in the number of\niterations compared to existing, curvature-informed penalty parameter selection\nmethods). Furthermore, we show that our RL policy demonstrates promise for\ngeneralizability, performing well under unseen loading schemes as well as under\nunseen losses of lines and generators (up to a 50% reduction in iterations).\nThis work thus provides a proof-of-concept for using RL for parameter selection\nin ADMM for power systems applications.",
          "link": "http://arxiv.org/abs/2110.11991",
          "publishedOn": "2022-04-18T00:59:14.012Z",
          "wordCount": null,
          "title": "A Reinforcement Learning Approach to Parameter Selection for Distributed Optimal Power Flow. (arXiv:2110.11991v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.06483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mostafa_H/0/1/0/all/0/1\">Hesham Mostafa</a>",
          "description": "We present the Sequential Aggregation and Rematerialization (SAR) scheme for\ndistributed full-batch training of Graph Neural Networks (GNNs) on large\ngraphs. Large-scale training of GNNs has recently been dominated by\nsampling-based methods and methods based on non-learnable message passing. SAR\non the other hand is a distributed technique that can train any GNN type\ndirectly on an entire large graph. The key innovation in SAR is the distributed\nsequential rematerialization scheme which sequentially re-constructs then frees\npieces of the prohibitively large GNN computational graph during the backward\npass. This results in excellent memory scaling behavior where the memory\nconsumption per worker goes down linearly with the number of workers, even for\ndensely connected graphs. Using SAR, we report the largest applications of\nfull-batch GNN training to-date, and demonstrate large memory savings as the\nnumber of workers increases. We also present a general technique based on\nkernel fusion and attention-matrix rematerialization to optimize both the\nruntime and memory efficiency of attention-based models. We show that, coupled\nwith SAR, our optimized attention kernels lead to significant speedups and\nmemory savings in attention-based GNNs.We made the SAR GNN training library\npublicy available: \\url{https://github.com/IntelLabs/SAR}.",
          "link": "http://arxiv.org/abs/2111.06483",
          "publishedOn": "2022-04-18T00:59:14.011Z",
          "wordCount": null,
          "title": "Sequential Aggregation and Rematerialization: Distributed Full-batch Training of Graph Neural Networks on Large Graphs. (arXiv:2111.06483v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Daeyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Seongsu Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>",
          "description": "Question Answering on Electronic Health Records (EHR-QA) has a significant\nimpact on the healthcare domain, and it is being actively studied. Previous\nresearch on structured EHR-QA focuses on converting natural language queries\ninto query language such as SQL or SPARQL (NLQ2Query), so the problem scope is\nlimited to pre-defined data types by the specific query language. In order to\nexpand the EHR-QA task beyond this limitation to handle multi-modal medical\ndata and solve complex inference in the future, more primitive systemic\nlanguage is needed. In this paper, we design the program-based model\n(NLQ2Program) for EHR-QA as the first step towards the future direction. We\ntackle MIMICSPARQL*, the graph-based EHR-QA dataset, via a program-based\napproach in a semi-supervised manner in order to overcome the absence of gold\nprograms. Without the gold program, our proposed model shows comparable\nperformance to the previous state-of-the-art model, which is an NLQ2Query model\n(0.9% gain). In addition, for a reliable EHR-QA model, we apply the uncertainty\ndecomposition method to measure the ambiguity in the input question. We\nempirically confirmed data uncertainty is most indicative of the ambiguity in\nthe input question.",
          "link": "http://arxiv.org/abs/2203.06918",
          "publishedOn": "2022-04-18T00:59:14.011Z",
          "wordCount": null,
          "title": "Uncertainty-Aware Text-to-Program for Question Answering on Structured Electronic Health Records. (arXiv:2203.06918v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kostovska_A/0/1/0/all/0/1\">Ana Kostovska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vermetten_D/0/1/0/all/0/1\">Diederick Vermetten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dzeroski_S/0/1/0/all/0/1\">Sa&#x161;o D&#x17e;eroski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1\">Carola Doerr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korosec_P/0/1/0/all/0/1\">Peter Koro&#x161;ec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eftimov_T/0/1/0/all/0/1\">Tome Eftimov</a>",
          "description": "Selecting the most suitable algorithm and determining its hyperparameters for\na given optimization problem is a challenging task. Accurately predicting how\nwell a certain algorithm could solve the problem is hence desirable. Recent\nstudies in single-objective numerical optimization show that supervised machine\nlearning methods can predict algorithm performance using landscape features\nextracted from the problem instances.\n\nExisting approaches typically treat the algorithms as black-boxes, without\nconsideration of their characteristics. To investigate in this work if a\nselection of landscape features that depends on algorithms properties could\nfurther improve regression accuracy, we regard the modular CMA-ES framework and\nestimate how much each landscape feature contributes to the best algorithm\nperformance regression models. Exploratory data analysis performed on this data\nindicate that the set of most relevant features does not depend on the\nconfiguration of individual modules, but the influence that these features have\non regression accuracy does. In addition, we have shown that by using\nclassifiers that take the features relevance on the model accuracy, we are able\nto predict the status of individual modules in the CMA-ES configurations.",
          "link": "http://arxiv.org/abs/2204.07431",
          "publishedOn": "2022-04-18T00:59:14.010Z",
          "wordCount": 631,
          "title": "The Importance of Landscape Features for Performance Prediction of Modular CMA-ES Variants. (arXiv:2204.07431v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.10545",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vaiciukynas_E/0/1/0/all/0/1\">Evaldas Vaiciukynas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Danenas_P/0/1/0/all/0/1\">Paulius Danenas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kontrimas_V/0/1/0/all/0/1\">Vilius Kontrimas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Butleris_R/0/1/0/all/0/1\">Rimantas Butleris</a>",
          "description": "Amounts of historical data collected increase and business intelligence\napplicability with automatic forecasting of time series are in high demand.\nWhile no single time series modeling method is universal to all types of\ndynamics, forecasting using an ensemble of several methods is often seen as a\ncompromise. Instead of fixing ensemble diversity and size, we propose to\npredict these aspects adaptively using meta-learning. Meta-learning here\nconsiders two separate random forest regression models, built on 390\ntime-series features, to rank 22 univariate forecasting methods and recommend\nensemble size. The forecasting ensemble is consequently formed from methods\nranked as the best, and forecasts are pooled using either simple or weighted\naverage (with a weight corresponding to reciprocal rank). The proposed approach\nwas tested on 12561 micro-economic time-series (expanded to 38633 for various\nforecasting horizons) of M4 competition where meta-learning outperformed Theta\nand Comb benchmarks by relative forecasting errors for all data types and\nhorizons. Best overall results were achieved by weighted pooling with a\nsymmetric mean absolute percentage error of 9.21% versus 11.05% obtained using\nthe Theta method.",
          "link": "http://arxiv.org/abs/2011.10545",
          "publishedOn": "2022-04-18T00:59:14.002Z",
          "wordCount": 669,
          "title": "Two-Step Meta-Learning for Time-Series Forecasting Ensemble. (arXiv:2011.10545v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.02529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghaffari_S/0/1/0/all/0/1\">Saba Ghaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleh_E/0/1/0/all/0/1\">Ehsan Saleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forsyth_D/0/1/0/all/0/1\">David Forsyth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-xiong Wang</a>",
          "description": "Learning accurate classifiers for novel categories from very few examples,\nknown as few-shot image classification, is a challenging task in statistical\nmachine learning and computer vision. The performance in few-shot\nclassification suffers from the bias in the estimation of classifier\nparameters; however, an effective underlying bias reduction technique that\ncould alleviate this issue in training few-shot classifiers has been\noverlooked. In this work, we demonstrate the effectiveness of Firth bias\nreduction in few-shot classification. Theoretically, Firth bias reduction\nremoves the $O(N^{-1})$ first order term from the small-sample bias of the\nMaximum Likelihood Estimator. Here we show that the general Firth bias\nreduction technique simplifies to encouraging uniform class assignment\nprobabilities for multinomial logistic classification, and almost has the same\neffect in cosine classifiers. We derive an easy-to-implement optimization\nobjective for Firth penalized multinomial logistic and cosine classifiers,\nwhich is equivalent to penalizing the cross-entropy loss with a KL-divergence\nbetween the uniform label distribution and the predictions. Then, we\nempirically evaluate that it is consistently effective across the board for\nfew-shot image classification, regardless of (1) the feature representations\nfrom different backbones, (2) the number of samples per class, and (3) the\nnumber of classes. Finally, we show the robustness of Firth bias reduction, in\nthe case of imbalanced data distribution. Our implementation is available at\nhttps://github.com/ehsansaleh/firth_bias_reduction",
          "link": "http://arxiv.org/abs/2110.02529",
          "publishedOn": "2022-04-18T00:59:13.994Z",
          "wordCount": null,
          "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification. (arXiv:2110.02529v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junhong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khodak_M/0/1/0/all/0/1\">Mikhail Khodak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1\">Ameet Talwalkar</a>",
          "description": "While neural architecture search (NAS) has enabled automated machine learning\n(AutoML) for well-researched areas, its application to tasks beyond computer\nvision is still under-explored. As less-studied domains are precisely those\nwhere we expect AutoML to have the greatest impact, in this work we study NAS\nfor efficiently solving diverse problems. Seeking an approach that is fast,\nsimple, and broadly applicable, we fix a standard convolutional network (CNN)\ntopology and propose to search for the right kernel sizes and dilations its\noperations should take on. This dramatically expands the model's capacity to\nextract features at multiple resolutions for different types of data while only\nrequiring search over the operation space. To overcome the efficiency\nchallenges of naive weight-sharing in this search space, we introduce DASH, a\ndifferentiable NAS algorithm that computes the mixture-of-operations using the\nFourier diagonalization of convolution, achieving both a better asymptotic\ncomplexity and an up-to-10x search time speedup in practice. We evaluate DASH\non NAS-Bench-360, a suite of ten tasks designed for benchmarking NAS in diverse\ndomains. DASH outperforms state-of-the-art methods in aggregate, attaining the\nbest-known automated performance on seven tasks. Meanwhile, on six of the ten\ntasks, the combined search and retraining time is less than 2x slower than\nsimply training a CNN backbone that is far less accurate.",
          "link": "http://arxiv.org/abs/2204.07554",
          "publishedOn": "2022-04-18T00:59:13.993Z",
          "wordCount": null,
          "title": "Efficient Architecture Search for Diverse Tasks. (arXiv:2204.07554v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1\">Quanfu Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yilai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_J/0/1/0/all/0/1\">John Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vos_S/0/1/0/all/0/1\">Seychelle M. Vos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cianfrocco_M/0/1/0/all/0/1\">Michael A. Cianfrocco</a>",
          "description": "Single-particle cryo-electron microscopy (cryo-EM) has become one of the\nmainstream structural biology techniques because of its ability to determine\nhigh-resolution structures of dynamic bio-molecules. However, cryo-EM data\nacquisition remains expensive and labor-intensive, requiring substantial\nexpertise. Structural biologists need a more efficient and objective method to\ncollect the best data in a limited time frame. We formulate the cryo-EM data\ncollection task as an optimization problem in this work. The goal is to\nmaximize the total number of good images taken within a specified period. We\nshow that reinforcement learning offers an effective way to plan cryo-EM data\ncollection, successfully navigating heterogenous cryo-EM grids. The approach we\ndeveloped, cryoRL, demonstrates better performance than average users for data\ncollection under similar settings.",
          "link": "http://arxiv.org/abs/2204.07543",
          "publishedOn": "2022-04-18T00:59:13.992Z",
          "wordCount": null,
          "title": "CryoRL: Reinforcement Learning Enables Efficient Cryo-EM Data Collection. (arXiv:2204.07543v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buthpitiya_S/0/1/0/all/0/1\">Senaka Buthpitiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabrikant_A/0/1/0/all/0/1\">Alex Fabrikant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1\">Donald Metzler</a>",
          "description": "Natural Language Inference (NLI) has been extensively studied by the NLP\ncommunity as a framework for estimating the semantic relation between sentence\npairs. While early work identified certain biases in NLI models, recent\nadvancements in modeling and datasets demonstrated promising performance. In\nthis work, we further explore the direct zero-shot applicability of NLI models\nto real applications, beyond the sentence-pair setting they were trained on.\nFirst, we analyze the robustness of these models to longer and out-of-domain\ninputs. Then, we develop new aggregation methods to allow operating over full\ndocuments, reaching state-of-the-art performance on the ContractNLI dataset.\nInterestingly, we find NLI scores to provide strong retrieval signals, leading\nto more relevant evidence extractions compared to common similarity-based\nmethods. Finally, we go further and investigate whole document clusters to\nidentify both discrepancies and consensus among sources. In a test case, we\nfind real inconsistencies between Wikipedia pages in different languages about\nthe same topic.",
          "link": "http://arxiv.org/abs/2204.07447",
          "publishedOn": "2022-04-18T00:59:13.976Z",
          "wordCount": 600,
          "title": "Stretching Sentence-pair NLI Models to Reason over Long Documents and Clusters. (arXiv:2204.07447v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungjae Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kyungwoo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wanmo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1\">Il-Chul Moon</a>",
          "description": "Recent advances in diffusion models bring the state-of-the art performance on\nimage generation tasks. However, empirical results on previous research in\ndiffusion models imply that there is an inverse correlation on performances for\ndensity estimation and sample generation. This paper analyzes that the inverse\ncorrelation arises because density estimation is mostly contributed from small\ndiffusion time, whereas sample generation mainly depends on large diffusion\ntime. However, training score network on both small and large diffusion time is\ndemanding because of the loss imbalance issue. To successfully train the score\nnetwork on both small and large diffusion time, this paper introduces a\ntraining technique, Soft Truncation, that softens the truncation time for every\nmini-batch update, which is universally applicable to any types of diffusion\nmodels. It turns out that Soft Truncation is equivalent to a diffusion model\nwith a general weight, and we prove the variational bound of the general\nweighted diffusion model. In view of this variational bound, Soft Truncation\nbecomes a natural way to train the score network. In experiments, Soft\nTruncation achieves the state-of-the-art performance on CIFAR-10, CelebA,\nCelebA-HQ $256\\times 256$, and STL-10 datasets.",
          "link": "http://arxiv.org/abs/2106.05527",
          "publishedOn": "2022-04-18T00:59:13.968Z",
          "wordCount": 695,
          "title": "Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation. (arXiv:2106.05527v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stepikin_A/0/1/0/all/0/1\">Alexander Stepikin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romanenkova_E/0/1/0/all/0/1\">Evgenia Romanenkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>",
          "description": "A change points detection aims to catch an abrupt disorder in data\ndistribution. Common approaches assume that there are only two fixed\ndistributions for data: one before and another after a change point. Real-world\ndata are richer than this assumption. There can be multiple different\ndistributions before and after a change. We propose an approach that works in\nthe multiple-distributions scenario. Our approach learn representations for\nsemi-structured data suitable for change point detection, while a common\nclassifiers-based approach fails. Moreover, our model is more robust, when\npredicting change points. The datasets used for benchmarking are sequences of\nimages with and without change points in them.",
          "link": "http://arxiv.org/abs/2204.07403",
          "publishedOn": "2022-04-18T00:59:13.960Z",
          "wordCount": 541,
          "title": "Deep learning model solves change point detection for multiple change types. (arXiv:2204.07403v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07391",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Novelli_P/0/1/0/all/0/1\">Pietro Novelli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bonati_L/0/1/0/all/0/1\">Luigi Bonati</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pontil_M/0/1/0/all/0/1\">Massimiliano Pontil</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Parrinello_M/0/1/0/all/0/1\">Michele Parrinello</a>",
          "description": "Present-day atomistic simulations generate long trajectories of ever more\ncomplex systems. Analyzing these data, discovering metastable states, and\nuncovering their nature is becoming increasingly challenging. In this paper, we\nfirst use the variational approach to conformation dynamics to discover the\nslowest dynamical modes of the simulations. This allows the different\nmetastable states of the system to be located and organized hierarchically. The\nphysical descriptors that characterize metastable states are discovered by\nmeans of a machine learning method. We show in the cases of two proteins,\nChignolin and Bovine Pancreatic Trypsin Inhibitor, how such analysis can be\neffortlessly performed in a matter of seconds. Another strength of our approach\nis that it can be applied to the analysis of both unbiased and biased\nsimulations.",
          "link": "http://arxiv.org/abs/2204.07391",
          "publishedOn": "2022-04-18T00:59:13.953Z",
          "wordCount": 579,
          "title": "Characterizing metastable states with the help of machine learning. (arXiv:2204.07391v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.08604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Galvez_B/0/1/0/all/0/1\">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granqvist_F/0/1/0/all/0/1\">Filip Granqvist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalen_R/0/1/0/all/0/1\">Rogier van Dalen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seigel_M/0/1/0/all/0/1\">Matt Seigel</a>",
          "description": "Federated learning with differential privacy, or private federated learning,\nprovides a strategy to train machine learning models while respecting users'\nprivacy. However, differential privacy can disproportionately degrade the\nperformance of the models on under-represented groups, as these parts of the\ndistribution are difficult to learn in the presence of noise. Existing\napproaches for enforcing fairness in machine learning models have considered\nthe centralized setting, in which the algorithm has access to the users' data.\nThis paper introduces an algorithm to enforce group fairness in private\nfederated learning, where users' data does not leave their devices. First, the\npaper extends the modified method of differential multipliers to empirical risk\nminimization with fairness constraints, thus providing an algorithm to enforce\nfairness in the central setting. Then, this algorithm is extended to the\nprivate federated learning setting. The proposed algorithm, \\texttt{FPFL}, is\ntested on a federated version of the Adult dataset and an \"unfair\" version of\nthe FEMNIST dataset. The experiments on these datasets show how private\nfederated learning accentuates unfairness in the trained models, and how FPFL\nis able to mitigate such unfairness.",
          "link": "http://arxiv.org/abs/2109.08604",
          "publishedOn": "2022-04-18T00:59:13.945Z",
          "wordCount": 677,
          "title": "Enforcing fairness in private federated learning via the modified method of differential multipliers. (arXiv:2109.08604v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1\">Andr&#xe9; Biedenkapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_N/0/1/0/all/0/1\">Nguyen Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krejca_M/0/1/0/all/0/1\">Martin S. Krejca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1\">Carola Doerr</a>",
          "description": "It has long been observed that the performance of evolutionary algorithms and\nother randomized search heuristics can benefit from a non-static choice of the\nparameters that steer their optimization behavior. Mechanisms that identify\nsuitable configurations on the fly (\"parameter control\") or via a dedicated\ntraining process (\"dynamic algorithm configuration\") are therefore an important\ncomponent of modern evolutionary computation frameworks. Several approaches to\naddress the dynamic parameter setting problem exist, but we barely understand\nwhich ones to prefer for which applications. As in classical benchmarking,\nproblem collections with a known ground truth can offer very meaningful\ninsights in this context. Unfortunately, settings with well-understood control\npolicies are very rare.\n\nOne of the few exceptions for which we know which parameter settings minimize\nthe expected runtime is the LeadingOnes problem. We extend this benchmark by\nanalyzing optimal control policies that can select the parameters only from a\ngiven portfolio of possible values. This also allows us to compute optimal\nparameter portfolios of a given size. We demonstrate the usefulness of our\nbenchmarks by analyzing the behavior of the DDQN reinforcement learning\napproach for dynamic algorithm configuration.",
          "link": "http://arxiv.org/abs/2202.03259",
          "publishedOn": "2022-04-18T00:59:13.922Z",
          "wordCount": null,
          "title": "Theory-inspired Parameter Control Benchmarks for Dynamic Algorithm Configuration. (arXiv:2202.03259v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1\">Apoorv Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weihs_L/0/1/0/all/0/1\">Luca Weihs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1\">Aniruddha Kembhavi</a>",
          "description": "Contrastive language image pretraining (CLIP) encoders have been shown to be\nbeneficial for a range of visual tasks from classification and detection to\ncaptioning and image manipulation. We investigate the effectiveness of CLIP\nvisual backbones for Embodied AI tasks. We build incredibly simple baselines,\nnamed EmbCLIP, with no task specific architectures, inductive biases (such as\nthe use of semantic maps), auxiliary tasks during training, or depth maps --\nyet we find that our improved baselines perform very well across a range of\ntasks and simulators. EmbCLIP tops the RoboTHOR ObjectNav leaderboard by a huge\nmargin of 20 pts (Success Rate). It tops the iTHOR 1-Phase Rearrangement\nleaderboard, beating the next best submission, which employs Active Neural\nMapping, and more than doubling the % Fixed Strict metric (0.08 to 0.17). It\nalso beats the winners of the 2021 Habitat ObjectNav Challenge, which employ\nauxiliary tasks, depth maps, and human demonstrations, and those of the 2019\nHabitat PointNav Challenge. We evaluate the ability of CLIP's visual\nrepresentations at capturing semantic information about input observations --\nprimitives that are useful for navigation-heavy embodied tasks -- and find that\nCLIP's representations encode these primitives more effectively than\nImageNet-pretrained backbones. Finally, we extend one of our baselines,\nproducing an agent capable of zero-shot object navigation that can navigate to\nobjects that were not used as targets during training. Our code and models are\navailable at https://github.com/allenai/embodied-clip",
          "link": "http://arxiv.org/abs/2111.09888",
          "publishedOn": "2022-04-18T00:59:13.921Z",
          "wordCount": 709,
          "title": "Simple but Effective: CLIP Embeddings for Embodied AI. (arXiv:2111.09888v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xinyu Zhou</a>",
          "description": "Although nanorobots have been used as clinical prescriptions for work such as\ngastroscopy, and even photoacoustic tomography technology has been proposed to\ncontrol nanorobots to deliver drugs at designated delivery points in real time,\nand there are cases of eliminating \"superbacteria\" in blood through nanorobots,\nmost technologies are immature, either with low efficiency or low accuracy,\nEither it can not be mass produced, so the most effective way to treat cancer\ndiseases at this stage is through chemotherapy and radiotherapy. Patients are\nsuffering and can not be cured. Therefore, this paper proposes an ideal model\nof a treatment method that can completely cure cancer, a cooperative treatment\nmethod based on nano robot queue through team member communication and computer\nvision image classification (target detection).",
          "link": "http://arxiv.org/abs/2111.11236",
          "publishedOn": "2022-04-18T00:59:13.896Z",
          "wordCount": null,
          "title": "Nanorobot queue: Cooperative treatment of cancer based on team member communication and image processing. (arXiv:2111.11236v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2001.11419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gilman_K/0/1/0/all/0/1\">Kyle Gilman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tarzanagh_D/0/1/0/all/0/1\">Davoud Ataee Tarzanagh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Balzano_L/0/1/0/all/0/1\">Laura Balzano</a>",
          "description": "We propose a new fast streaming algorithm for the tensor completion problem\nof imputing missing entries of a low-tubal-rank tensor using the tensor\nsingular value decomposition (t-SVD) algebraic framework. We show the t-SVD is\na specialization of the well-studied block-term decomposition for third-order\ntensors, and we present an algorithm under this model that can track changing\nfree submodules from incomplete streaming 2-D data. The proposed algorithm uses\nprinciples from incremental gradient descent on the Grassmann manifold of\nsubspaces to solve the tensor completion problem with linear complexity and\nconstant memory in the number of time samples. We provide a local expected\nlinear convergence result for our algorithm. Our empirical results are\ncompetitive in accuracy but much faster in compute time than state-of-the-art\ntensor completion algorithms on real applications to recover temporal\nchemo-sensing and MRI data under limited sampling.",
          "link": "http://arxiv.org/abs/2001.11419",
          "publishedOn": "2022-04-18T00:59:13.894Z",
          "wordCount": null,
          "title": "Grassmannian Optimization for Online Tensor Completion and Tracking with the t-SVD. (arXiv:2001.11419v4 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Knyazev_N/0/1/0/all/0/1\">Nick Knyazev</a>",
          "description": "This paper is devoted to a practical method for ferroalloys consumption\nmodeling and optimization. We consider the problem of selecting the optimal\nprocess control parameters based on the analysis of historical data from\nsensors. We developed approach, which predicts results of chemical reactions\nand give ferroalloys consumption recommendation. The main features of our\nmethod are easy interpretation and noise resistance. Our approach is based on\nk-means clustering algorithm, decision trees and linear regression. The main\nidea of the method is to identify situations where processes go similarly. For\nthis, we propose using a k-means based dataset clustering algorithm and a\nclassification algorithm to determine the cluster. This algorithm can be also\napplied to various technological processes, in this article, we demonstrate its\napplication in metallurgy. To test the application of the proposed method, we\nused it to optimize ferroalloys consumption in Basic Oxygen Furnace steelmaking\nwhen finishing steel in a ladle furnace. The minimum required element content\nfor a given steel grade was selected as the predictive model's target variable,\nand the required amount of the element to be added to the melt as the optimized\nvariable. Keywords: Clustering, Machine Learning, Linear Regression,\nSteelmaking, Optimization, Gradient Boosting, Artificial Intelligence, Decision\nTrees, Recommendation services",
          "link": "http://arxiv.org/abs/2204.07421",
          "publishedOn": "2022-04-18T00:59:13.893Z",
          "wordCount": null,
          "title": "An interpretable machine learning approach for ferroalloys consumptions. (arXiv:2204.07421v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1909.04746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khaled_A/0/1/0/all/0/1\">Ahmed Khaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "We provide a new analysis of local SGD, removing unnecessary assumptions and\nelaborating on the difference between two data regimes: identical and\nheterogeneous. In both cases, we improve the existing theory and provide values\nof the optimal stepsize and optimal number of local iterations. Our bounds are\nbased on a new notion of variance that is specific to local SGD methods with\ndifferent data. The tightness of our results is guaranteed by recovering known\nstatements when we plug $H=1$, where $H$ is the number of local steps. The\nempirical evidence further validates the severe impact of data heterogeneity on\nthe performance of local SGD.",
          "link": "http://arxiv.org/abs/1909.04746",
          "publishedOn": "2022-04-18T00:59:13.893Z",
          "wordCount": null,
          "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data. (arXiv:1909.04746v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.07029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Keqian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yifan Hu</a>",
          "description": "We study the problem of user segmentation: given a set of users and one or\nmore predefined groups or segments, assign users to their corresponding\nsegments. As an example, for a segment indicating particular interest in a\ncertain area of sports or entertainment, the task will be to predict whether\neach single user will belong to the segment. However, there may exist numerous\nlong tail prediction tasks that suffer from data availability and may be of\nheterogeneous nature, which make it hard to capture using single off the shelf\nmodel architectures. In this work, we present SuperCone, our unified\npredicative segments system that addresses the above challenges. It builds on\ntop of a flat concept representation that summarizes each user's heterogeneous\ndigital footprints, and uniformly models each of the prediction task using an\napproach called \"super learning \", that is, combining prediction models with\ndiverse architectures or learning method that are not compatible with each\nother. Following this, we provide an end to end approach that learns to\nflexibly attend to best suited heterogeneous experts adaptively, while at the\nsame time incorporating deep representations of the input concepts that\naugments the above experts. Experiments show that SuperCone significantly\noutperform state-of-the-art recommendation and ranking algorithms on a wide\nrange of predicative segment tasks and public structured data learning\nbenchmarks.",
          "link": "http://arxiv.org/abs/2203.07029",
          "publishedOn": "2022-04-18T00:59:13.893Z",
          "wordCount": null,
          "title": "SuperCone: Unified User Segmentation over Heterogeneous Experts via Concept Meta-learning. (arXiv:2203.07029v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Selim_M/0/1/0/all/0/1\">Mahmoud Selim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alanwar_A/0/1/0/all/0/1\">Amr Alanwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kousik_S/0/1/0/all/0/1\">Shreyas Kousik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Grace Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "Reinforcement learning (RL) is capable of sophisticated motion planning and\ncontrol for robots in uncertain environments. However, state-of-the-art deep RL\napproaches typically lack safety guarantees, especially when the robot and\nenvironment models are unknown. To justify widespread deployment, robots must\nrespect safety constraints without sacrificing performance. Thus, we propose a\nBlack-box Reachability-based Safety Layer (BRSL) with three main components:\n(1) data-driven reachability analysis for a black-box robot model, (2) a\ntrajectory rollout planner that predicts future actions and observations using\nan ensemble of neural networks trained online, and (3) a differentiable\npolytope collision check between the reachable set and obstacles that enables\ncorrecting unsafe actions. In simulation, BRSL outperforms other\nstate-of-the-art safe RL methods on a Turtlebot 3, a quadrotor, and a\ntrajectory-tracking point mass with an unsafe set adjacent to the area of\nhighest reward.",
          "link": "http://arxiv.org/abs/2204.07417",
          "publishedOn": "2022-04-18T00:59:13.892Z",
          "wordCount": null,
          "title": "Safe Reinforcement Learning Using Black-Box Reachability Analysis. (arXiv:2204.07417v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07457",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Neskorniuk_V/0/1/0/all/0/1\">Vladislav Neskorniuk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Carnio_A/0/1/0/all/0/1\">Andrea Carnio</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Marsella_D/0/1/0/all/0/1\">Domenico Marsella</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1\">Sergei K. Turitsyn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1\">Jaroslaw E. Prilepsky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aref_V/0/1/0/all/0/1\">Vahid Aref</a>",
          "description": "Autoencoder-based deep learning is applied to jointly optimize geometric and\nprobabilistic constellation shaping for optical coherent communication. The\noptimized constellation shaping outperforms the 256 QAM Maxwell-Boltzmann\nprobabilistic distribution with extra 0.05 bits/4D-symbol mutual information\nfor 64 GBd transmission over 170 km SMF link.",
          "link": "http://arxiv.org/abs/2204.07457",
          "publishedOn": "2022-04-18T00:59:13.892Z",
          "wordCount": null,
          "title": "Model-Based Deep Learning of Joint Probabilistic and Geometric Shaping for Optical Communication. (arXiv:2204.07457v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07492",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chase_R/0/1/0/all/0/1\">Randy J. Chase</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Harrison_D/0/1/0/all/0/1\">David R. Harrison</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Burke_A/0/1/0/all/0/1\">Amanda Burke</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lackmann_G/0/1/0/all/0/1\">Gary M. Lackmann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+McGovern_A/0/1/0/all/0/1\">Amy McGovern</a>",
          "description": "Recently, the use of machine learning in meteorology has increased greatly.\nWhile many machine learning methods are not new, university classes on machine\nlearning are largely unavailable to meteorology students and are not required\nto become a meteorologist. The lack of formal instruction has contributed to\nperception that machine learning methods are 'black boxes' and thus end-users\nare hesitant to apply the machine learning methods in their every day workflow.\nTo reduce the opaqueness of machine learning methods and lower hesitancy\ntowards machine learning in meteorology, this paper provides a survey of some\nof the most common machine learning methods. A familiar meteorological example\nis used to contextualize the machine learning methods while also discussing\nmachine learning topics using plain language. The following machine learning\nmethods are demonstrated: linear regression; logistic regression; decision\ntrees; random forest; gradient boosted decision trees; naive Bayes; and support\nvector machines. Beyond discussing the different methods, the paper also\ncontains discussions on the general machine learning process as well as best\npractices to enable readers to apply machine learning to their own datasets.\nFurthermore, all code (in the form of Jupyter notebooks and Google Colaboratory\nnotebooks) used to make the examples in the paper is provided in an effort to\ncatalyse the use of machine learning in meteorology.",
          "link": "http://arxiv.org/abs/2204.07492",
          "publishedOn": "2022-04-18T00:59:13.892Z",
          "wordCount": null,
          "title": "A Machine Learning Tutorial for Operational Meteorology, Part I: Traditional Machine Learning. (arXiv:2204.07492v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.08966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1\">Fabio Sigrist</a>",
          "description": "Latent Gaussian models and boosting are widely used techniques in statistics\nand machine learning. Tree-boosting shows excellent prediction accuracy on many\ndata sets, but potential drawbacks are that it assumes conditional independence\nof samples, produces discontinuous predictions for, e.g., spatial data, and it\ncan have difficulty with high-cardinality categorical variables. Latent\nGaussian models, such as Gaussian process and grouped random effects models,\nare flexible prior models which explicitly model dependence among samples and\nwhich allow for efficient learning of predictor functions and for making\nprobabilistic predictions. However, existing latent Gaussian models usually\nassume either a zero or a linear prior mean function which can be an\nunrealistic assumption. This article introduces a novel approach that combines\nboosting and latent Gaussian models to remedy the above-mentioned drawbacks and\nto leverage the advantages of both techniques. We obtain increased prediction\naccuracy compared to existing approaches in both simulated and real-world data\nexperiments.",
          "link": "http://arxiv.org/abs/2105.08966",
          "publishedOn": "2022-04-18T00:59:13.891Z",
          "wordCount": null,
          "title": "Latent Gaussian Model Boosting. (arXiv:2105.08966v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07413",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zayats_M/0/1/0/all/0/1\">Mykhaylo Zayats</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zimon_M/0/1/0/all/0/1\">Ma&#x142;gorzata J. Zimo&#x144;</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yeo_K/0/1/0/all/0/1\">Kyongmin Yeo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhuk_S/0/1/0/all/0/1\">Sergiy Zhuk</a>",
          "description": "We propose a new design of a neural network for solving a zero shot super\nresolution problem for turbulent flows. We embed Luenberger-type observer into\nthe network's architecture to inform the network of the physics of the process,\nand to provide error correction and stabilization mechanisms. In addition, to\ncompensate for decrease of observer's performance due to the presence of\nunknown destabilizing forcing, the network is designed to estimate the\ncontribution of the unknown forcing implicitly from the data over the course of\ntraining. By running a set of numerical experiments, we demonstrate that the\nproposed network does recover unknown forcing from data and is capable of\npredicting turbulent flows in high resolution from low resolution noisy\nobservations.",
          "link": "http://arxiv.org/abs/2204.07413",
          "publishedOn": "2022-04-18T00:59:13.890Z",
          "wordCount": 575,
          "title": "Super Resolution for Turbulent Flows in 2D: Stabilized Physics Informed Neural Networks. (arXiv:2204.07413v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoneda_T/0/1/0/all/0/1\">Takuma Yoneda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Ge Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1\">Matthew R. Walter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadie_B/0/1/0/all/0/1\">Bradly Stadie</a>",
          "description": "We introduce a general approach, called Invariance through Inference, for\nimproving the test-time performance of an agent in deployment environments with\nunknown perceptual variations. Instead of producing invariant visual features\nthrough interpolation, invariance through inference turns adaptation at\ndeployment-time into an unsupervised learning problem. This is achieved in\npractice by deploying a straightforward algorithm that tries to match the\ndistribution of latent features to the agent's prior experience, without\nrelying on paired data. Although simple, we show that this idea leads to\nsurprising improvements on a variety of adaptation scenarios without access to\ndeployment-time rewards, including changes in scene content, camera poses, and\nlighting conditions. We present results on challenging domains including\ndistractor control suite and sim-to-real transfer for image-based robot\nmanipulation.",
          "link": "http://arxiv.org/abs/2112.08526",
          "publishedOn": "2022-04-18T00:59:13.882Z",
          "wordCount": null,
          "title": "Invariance Through Inference. (arXiv:2112.08526v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_M/0/1/0/all/0/1\">Minzhou Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Just_H/0/1/0/all/0/1\">Hoang Anh Just</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1\">Lingjuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1\">Meikang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "Backdoor attacks insert malicious data into a training set so that, during\ninference time, it misclassifies inputs that have been patched with a backdoor\ntrigger as the malware specified label. For backdoor attacks to bypass human\ninspection, it is essential that the injected data appear to be correctly\nlabeled. The attacks with such property are often referred to as \"clean-label\nattacks.\" Existing clean-label backdoor attacks require knowledge of the entire\ntraining set to be effective. Obtaining such knowledge is difficult or\nimpossible because training data are often gathered from multiple sources\n(e.g., face images from different users). It remains a question whether\nbackdoor attacks still present a real threat.\n\nThis paper provides an affirmative answer to this question by designing an\nalgorithm to mount clean-label backdoor attacks based only on the knowledge of\nrepresentative examples from the target class. With poisoning equal to or less\nthan 0.5% of the target-class data and 0.05% of the training set, we can train\na model to classify test examples from arbitrary classes into the target class\nwhen the examples are patched with a backdoor trigger. Our attack works well\nacross datasets and models, even when the trigger presents in the physical\nworld.\n\nWe explore the space of defenses and find that, surprisingly, our attack can\nevade the latest state-of-the-art defenses in their vanilla form, or after a\nsimple twist, we can adapt to the downstream defenses. We study the cause of\nthe intriguing effectiveness and find that because the trigger synthesized by\nour attack contains features as persistent as the original semantic features of\nthe target class, any attempt to remove such triggers would inevitably hurt the\nmodel accuracy first.",
          "link": "http://arxiv.org/abs/2204.05255",
          "publishedOn": "2022-04-18T00:59:13.882Z",
          "wordCount": null,
          "title": "Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information. (arXiv:2204.05255v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_R/0/1/0/all/0/1\">Ruibin Mao</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1\">Bo Wen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yahui Zhao</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Arman Kazemi</a> (2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Laguna_A/0/1/0/all/0/1\">Ann Franchesca Laguna</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Neimier_M/0/1/0/all/0/1\">Michael Neimier</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">X. Sharon Hu</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1\">Xia Sheng</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Graves_C/0/1/0/all/0/1\">Catherine E. Graves</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Strachan_J/0/1/0/all/0/1\">John Paul Strachan</a> (4, 5), <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Can Li</a> (1) ((1) The University of Hong Kong, (2) Hewlett Packard Labs, (3) University of Notre Dame, (4) Peter Gr&#xfc;nberg Institut (PGI-14), (5) RWTH Aachen University)",
          "description": "Lifelong on-device learning is a key challenge for machine intelligence, and\nthis requires learning from few, often single, samples. Memory augmented neural\nnetwork has been proposed to achieve the goal, but the memory module has to be\nstored in an off-chip memory due to its size. Therefore the practical use has\nbeen heavily limited. Previous works on emerging memory-based implementation\nhave difficulties in scaling up because different modules with various\nstructures are difficult to integrate on the same chip and the small sense\nmargin of the content addressable memory for the memory module heavily limited\nthe degree of mismatch calculation. In this work, we implement the entire\nmemory augmented neural network architecture in a fully integrated memristive\ncrossbar platform and achieve an accuracy that closely matches standard\nsoftware on digital hardware for the Omniglot dataset. The successful\ndemonstration is supported by implementing new functions in crossbars in\naddition to widely reported matrix multiplications. For example, the\nlocality-sensitive hashing operation is implemented in crossbar arrays by\nexploiting the intrinsic stochasticity of memristor devices. Besides, the\ncontent-addressable memory module is realized in crossbars, which also supports\nthe degree of mismatches. Simulations based on experimentally validated models\nshow such an implementation can be efficiently scaled up for one-shot learning\non the Mini-ImageNet dataset. The successful demonstration paves the way for\npractical on-device lifelong learning and opens possibilities for novel\nattention-based algorithms not possible in conventional hardware.",
          "link": "http://arxiv.org/abs/2204.07429",
          "publishedOn": "2022-04-18T00:59:13.881Z",
          "wordCount": null,
          "title": "Experimentally realized memristive memory augmented neural network. (arXiv:2204.07429v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05205",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Javed_S/0/1/0/all/0/1\">Syed Ashar Javed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Juyal_D/0/1/0/all/0/1\">Dinkar Juyal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shanis_Z/0/1/0/all/0/1\">Zahil Shanis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chakraborty_S/0/1/0/all/0/1\">Shreya Chakraborty</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pokkalla_H/0/1/0/all/0/1\">Harsha Pokkalla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prakash_A/0/1/0/all/0/1\">Aaditya Prakash</a>",
          "description": "Machine Learning has been applied to pathology images in research and\nclinical practice with promising outcomes. However, standard ML models often\nlack the rigorous evaluation required for clinical decisions. Machine learning\ntechniques for natural images are ill-equipped to deal with pathology images\nthat are significantly large and noisy, require expensive labeling, are hard to\ninterpret, and are susceptible to spurious correlations. We propose a set of\npractical guidelines for ML evaluation in pathology that address the above\nconcerns. The paper includes measures for setting up the evaluation framework,\neffectively dealing with variability in labels, and a recommended suite of\ntests to address issues related to domain shift, robustness, and confounding\nvariables. We hope that the proposed framework will bridge the gap between ML\nresearchers and domain experts, leading to wider adoption of ML techniques in\npathology and improving patient outcomes.",
          "link": "http://arxiv.org/abs/2204.05205",
          "publishedOn": "2022-04-18T00:59:13.879Z",
          "wordCount": null,
          "title": "Rethinking Machine Learning Model Evaluation in Pathology. (arXiv:2204.05205v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1\">Hakan Bilen</a>",
          "description": "Remarkable progress has been achieved in synthesizing photo-realistic images\nwith generative adversarial neural networks (GANs). Recently, GANs are utilized\nas the training sample generator when obtaining or storing real training data\nis expensive even infeasible. However, traditional GANs generated images are\nnot as informative as the real training samples when being used to train deep\nneural networks. In this paper, we propose a novel method to synthesize\nInformative Training samples with GAN (IT-GAN). Specifically, we freeze a\npre-trained GAN model and learn the informative latent vectors that corresponds\nto informative training samples. The synthesized images are required to\npreserve information for training deep neural networks rather than visual\nreality or fidelity. Experiments verify that the deep neural networks can learn\nfaster and achieve better performance when being trained with our IT-GAN\ngenerated images. We also show that our method is a promising solution to\ndataset condensation problem.",
          "link": "http://arxiv.org/abs/2204.07513",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Synthesizing Informative Training Samples with GAN. (arXiv:2204.07513v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Ke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>",
          "description": "We propose a streaming non-autoregressive (non-AR) decoding algorithm to\ndeliberate the hypothesis alignment of a streaming RNN-T model. Our algorithm\nfacilitates a simple greedy decoding procedure, and at the same time is capable\nof producing the decoding result at each frame with limited right context, thus\nenjoying both high efficiency and low latency. These advantages are achieved by\nconverting the offline Align-Refine algorithm to be streaming-compatible, with\na novel transformer decoder architecture that performs local self-attentions\nfor both text and audio, and a time-aligned cross-attention at each layer.\nFurthermore, we perform discriminative training of our model with the minimum\nword error rate (MWER) criterion, which has not been done in the non-AR\ndecoding literature. Experiments on voice search datasets and Librispeech show\nthat with reasonable right context, our streaming model performs as well as the\noffline counterpart, and discriminative training leads to further WER gain when\nthe first-pass model has small capacity.",
          "link": "http://arxiv.org/abs/2204.07556",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Streaming Align-Refine for Non-autoregressive Deliberation. (arXiv:2204.07556v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.12426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sandler_A/0/1/0/all/0/1\">Adam Sandler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1\">Diego Klabjan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yuan Luo</a>",
          "description": "We develop methods for reducing the dimensionality of large data sets, common\nin biomedical applications. Learning about patients using genetic data often\nincludes more features than observations, which makes direct supervised\nlearning difficult. One method of reducing the feature space is to use latent\nDirichlet allocation to group genetic variants in an unsupervised manner.\nLatent Dirichlet allocation describes a patient as a mixture of topics\ncorresponding to genetic variants. This can be generalized as a Bayesian tensor\ndecomposition to account for multiple feature variables. Our most significant\ncontributions are with hierarchical topic modeling. We design distinct methods\nof incorporating hierarchical topic modeling, based on nested Chinese\nrestaurant processes and Pachinko Allocation Machine, into Bayesian tensor\ndecomposition. We apply these models to examine patients with one of four\ncommon types of cancer (breast, lung, prostate, and colorectal) and siblings\nwith and without autism spectrum disorder. We linked the genes with their\nbiological pathways and combine this information into a tensor of patients,\ncounts of their genetic variants, and the genes' membership in pathways. We\nfind that our trained models outperform baseline models, with respect to\ncoherence, by up to 40%.",
          "link": "http://arxiv.org/abs/1911.12426",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data Analysis. (arXiv:1911.12426v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.13579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ruo Yu Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francois_Lavet_V/0/1/0/all/0/1\">Vincent Fran&#xe7;ois-Lavet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "We present a new approach for efficient exploration which leverages a\nlow-dimensional encoding of the environment learned with a combination of\nmodel-based and model-free objectives. Our approach uses intrinsic rewards that\nare based on the distance of nearest neighbors in the low dimensional\nrepresentational space to gauge novelty. We then leverage these intrinsic\nrewards for sample-efficient exploration with planning routines in\nrepresentational space for hard exploration tasks with sparse rewards. One key\nelement of our approach is the use of information theoretic principles to shape\nour representations in a way so that our novelty reward goes beyond pixel\nsimilarity. We test our approach on a number of maze tasks, as well as a\ncontrol problem and show that our exploration approach is more sample-efficient\ncompared to strong baselines.",
          "link": "http://arxiv.org/abs/2009.13579",
          "publishedOn": "2022-04-18T00:59:13.876Z",
          "wordCount": null,
          "title": "Novelty Search in Representational Space for Sample Efficient Exploration. (arXiv:2009.13579v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changhun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyungjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunhyeok Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jae-Joon Kim</a>",
          "description": "Binary Neural Networks (BNNs) have emerged as a promising solution for\nreducing the memory footprint and compute costs of deep neural networks. BNNs,\non the other hand, suffer from information loss because binary activations are\nlimited to only two values, resulting in reduced accuracy. To improve the\naccuracy, previous studies have attempted to control the distribution of binary\nactivation by manually shifting the threshold of the activation function or\nmaking the shift amount trainable. During the process, they usually depended on\nstatistical information computed from a batch. We argue that using statistical\ndata from a batch fails to capture the crucial information for each input\ninstance in BNN computations, and the differences between statistical\ninformation computed from each instance need to be considered when determining\nthe binary activation threshold of each instance. Based on the concept, we\npropose the Binary Neural Network with INSTAnce-aware threshold (INSTA-BNN),\nwhich decides the activation threshold value considering the difference between\nstatistical data computed from a batch and each instance. The proposed\nINSTA-BNN outperforms the baseline by 2.5% and 2.3% on the ImageNet\nclassification task with comparable computing cost, achieving 68.0% and 71.7%\ntop-1 accuracy on ResNet-18 and MobileNetV1 based models, respectively.",
          "link": "http://arxiv.org/abs/2204.07439",
          "publishedOn": "2022-04-18T00:59:13.875Z",
          "wordCount": null,
          "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold. (arXiv:2204.07439v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_M/0/1/0/all/0/1\">Meng Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Huiyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "This paper studies node classification in the inductive setting, i.e., aiming\nto learn a model on labeled training graphs and generalize it to infer node\nlabels on unlabeled test graphs. This problem has been extensively studied with\ngraph neural networks (GNNs) by learning effective node representations, as\nwell as traditional structured prediction methods for modeling the structured\noutput of node labels, e.g., conditional random fields (CRFs). In this paper,\nwe present a new approach called the Structured Proxy Network (SPN), which\ncombines the advantages of both worlds. SPN defines flexible potential\nfunctions of CRFs with GNNs. However, learning such a model is nontrivial as it\ninvolves optimizing a maximin game with high-cost inference. Inspired by the\nunderlying connection between joint and marginal distributions defined by\nMarkov networks, we propose to solve an approximate version of the optimization\nproblem as a proxy, which yields a near-optimal solution, making learning more\nefficient. Extensive experiments on two settings show that our approach\noutperforms many competitive baselines.",
          "link": "http://arxiv.org/abs/2204.07524",
          "publishedOn": "2022-04-18T00:59:13.875Z",
          "wordCount": null,
          "title": "Neural Structured Prediction for Inductive Node Classification. (arXiv:2204.07524v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davis_Q/0/1/0/all/0/1\">Q. Tyrell Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bongard_J/0/1/0/all/0/1\">Josh Bongard</a>",
          "description": "Substantial efforts have been applied to engineer CA with desired emergent\nproperties, such as supporting gliders. Recent work in continuous CA has\ngenerated a wide variety of compelling bioreminescent patterns, and the\nexpansion of CA research into continuous numbers, multiple channels, and higher\ndimensions complicates their study. In this work we devise a strategy for\nevolving CA and CA patterns in two steps, based on the simple idea that CA are\nlikely to be complex and computationally capable if they support patterns that\ngrow indefinitely as well as patterns that vanish completely, and are difficult\nto predict the difference in advance. The second part of our strategy evolves\npatterns by selecting for mobility and conservation of mean cell value. We\nvalidate our pattern evolution method by re-discovering gliders in 17 of 17\nLenia CA, and also report 5 new evolved CA that support evolved glider\npatterns, differing from previously reported Lenia patterns. The CA reported\nhere share neighborhood kernels with previously described Lenia CA, but exhibit\na wider range of typical dynamics than their Lenia counterparts. Code for\nevolving continuous CA is made available under an MIT License.",
          "link": "http://arxiv.org/abs/2204.07541",
          "publishedOn": "2022-04-18T00:59:13.875Z",
          "wordCount": null,
          "title": "Selecting Continuous Life-Like Cellular Automata for Halting Unpredictability: Evolving for Abiogenesis. (arXiv:2204.07541v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_S/0/1/0/all/0/1\">Sina Abbasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bedeer_E/0/1/0/all/0/1\">Ebrahim Bedeer</a>",
          "description": "Faster-than-Nyquist (FTN) signaling is a candidate non-orthonormal\ntransmission technique to improve the spectral efficiency (SE) of future\ncommunication systems. However, such improvements of the SE are at the cost of\nadditional computational complexity to remove the intentionally introduced\nintersymbol interference. In this paper, we investigate the use of deep\nlearning (DL) to reduce the detection complexity of FTN signaling. To eliminate\nthe need of having a noise whitening filter at the receiver, we first present\nan equivalent FTN signaling model based on using a set of orthonormal basis\nfunctions and identify its operation region. Second, we propose a DL-based list\nsphere decoding (DL-LSD) algorithm that selects and updates the initial radius\nof the original LSD to guarantee a pre-defined number $N_{\\text{L}}$ of lattice\npoints inside the hypersphere. This is achieved by training a neural network to\noutput an approximate initial radius that includes $N_{\\text{L}}$ lattice\npoints. At the testing phase, if the hypersphere has more than $N_{\\text{L}}$\nlattice points, we keep the $N_{\\text{L}}$ closest points to the point\ncorresponding to the received FTN signal; however, if the hypersphere has less\nthan $N_{\\text{L}}$ points, we increase the approximate initial radius by a\nvalue that depends on the standard deviation of the distribution of the output\nradii from the training phase. Then, the approximate value of the\nlog-likelihood ratio (LLR) is calculated based on the obtained $N_{\\text{L}}$\npoints. Simulation results show that the computational complexity of the\nproposed DL-LSD is lower than its counterpart of the original LSD by orders of\nmagnitude.",
          "link": "http://arxiv.org/abs/2204.07569",
          "publishedOn": "2022-04-18T00:59:13.874Z",
          "wordCount": null,
          "title": "Deep Learning-based List Sphere Decoding for Faster-than-Nyquist (FTN) Signaling Detection. (arXiv:2204.07569v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07532",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tian_H/0/1/0/all/0/1\">Hao Tian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ketkar_R/0/1/0/all/0/1\">Rajas Ketkar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tao_P/0/1/0/all/0/1\">Peng Tao</a>",
          "description": "The absorption, distribution, metabolism, excretion, and toxicity (ADMET)\nproperties are important in drug discovery as they define efficacy and safety.\nHere, we apply an ensemble of features, including fingerprints and descriptors,\nand a tree-based machine learning model, extreme gradient boosting, for\naccurate ADMET prediction. Our model performs well in the Therapeutics Data\nCommons ADMET benchmark group. For 22 tasks, our model is ranked first in 10\ntasks and top 3 in 18 tasks.",
          "link": "http://arxiv.org/abs/2204.07532",
          "publishedOn": "2022-04-18T00:59:13.872Z",
          "wordCount": 504,
          "title": "Accurate ADMET Prediction with XGBoost. (arXiv:2204.07532v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00009",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kocour_M/0/1/0/all/0/1\">Martin Kocour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zmolikova_K/0/1/0/all/0/1\">Kate&#x159;ina &#x17d;mol&#xed;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ondel_L/0/1/0/all/0/1\">Lucas Ondel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Svec_J/0/1/0/all/0/1\">J&#xe1;n &#x160;vec</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Delcroix_M/0/1/0/all/0/1\">Marc Delcroix</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ochiai_T/0/1/0/all/0/1\">Tsubasa Ochiai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burget_L/0/1/0/all/0/1\">Luk&#xe1;&#x161; Burget</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cernocky_J/0/1/0/all/0/1\">Jan &#x10c;ernock&#xfd;</a>",
          "description": "In typical multi-talker speech recognition systems, a neural network-based\nacoustic model predicts senone state posteriors for each speaker. These are\nlater used by a single-talker decoder which is applied on each speaker-specific\noutput stream separately. In this work, we argue that such a scheme is\nsub-optimal and propose a principled solution that decodes all speakers\njointly. We modify the acoustic model to predict joint state posteriors for all\nspeakers, enabling the network to express uncertainty about the attribution of\nparts of the speech signal to the speakers. We employ a joint decoder that can\nmake use of this uncertainty together with higher-level language information.\nFor this, we revisit decoding algorithms used in factorial generative models in\nearly multi-talker speech recognition systems. In contrast with these early\nworks, we replace the GMM acoustic model with DNN, which provides greater\nmodeling power and simplifies part of the inference. We demonstrate the\nadvantage of joint decoding in proof of concept experiments on a mixed-TIDIGITS\ndataset.",
          "link": "http://arxiv.org/abs/2111.00009",
          "publishedOn": "2022-04-18T00:59:13.865Z",
          "wordCount": null,
          "title": "Revisiting joint decoding based multi-talker speech recognition with DNN acoustic model. (arXiv:2111.00009v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nath_U/0/1/0/all/0/1\">Utkarsh Nath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kushagra_S/0/1/0/all/0/1\">Shrinu Kushagra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yingzhen Yang</a>",
          "description": "Compressing deep neural networks while maintaining accuracy is important when\nwe want to deploy large, powerful models in production and/or edge devices. One\ncommon technique used to achieve this goal is knowledge distillation.\nTypically, the output of a static pre-defined teacher (a large base network) is\nused as soft labels to train and transfer information to a student (or smaller)\nnetwork. In this paper, we introduce Adjoined Networks, or AN, a learning\nparadigm that trains both the original base network and the smaller compressed\nnetwork together. In our training approach, the parameters of the smaller\nnetwork are shared across both the base and the compressed networks. Using our\ntraining paradigm, we can simultaneously compress (the student network) and\nregularize (the teacher network) any architecture. In this paper, we focus on\npopular CNN-based architectures used for computer vision tasks. We conduct an\nextensive experimental evaluation of our training paradigm on various\nlarge-scale datasets. Using ResNet-50 as the base network, AN achieves 71.8%\ntop-1 accuracy with only 1.8M parameters and 1.6 GFLOPs on the ImageNet\ndata-set. We further propose Differentiable Adjoined Networks (DAN), a training\nparadigm that augments AN by using neural architecture search to jointly learn\nboth the width and the weights for each layer of the smaller network. DAN\nachieves ResNet-50 level accuracy on ImageNet with $3.8\\times$ fewer parameters\nand $2.2\\times$ fewer FLOPs.",
          "link": "http://arxiv.org/abs/2006.05624",
          "publishedOn": "2022-04-18T00:59:13.864Z",
          "wordCount": 744,
          "title": "Adjoined Networks: A Training Paradigm with Applications to Network Compression. (arXiv:2006.05624v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marmoret_A/0/1/0/all/0/1\">Axel Marmoret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my E. Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bimbot_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Bimbot</a>",
          "description": "Music Structure Analysis (MSA) consists in segmenting a music piece in\nseveral distinct sections. We approach MSA within a compression framework,\nunder the hypothesis that the structure is more easily revealed by a simplified\nrepresentation of the original content of the song. More specifically, under\nthe hypothesis that MSA is correlated with similarities occurring at the bar\nscale, this article introduces the use of linear and non-linear compression\nschemes on barwise audio signals. Compressed representations capture the most\nsalient components of the different bars in the song and are then used to infer\nthe song structure using a dynamic programming algorithm. This work explores\nboth low-rank approximation models such as Principal Component Analysis or\nNonnegative Matrix Factorization and \"piece-specific\" Auto-Encoding Neural\nNetworks, with the objective to learn latent representations specific to a\ngiven song. Such approaches do not rely on supervision nor annotations, which\nare well-known to be tedious to collect and possibly ambiguous in MSA\ndescription. In our experiments, several unsupervised compression schemes\nachieve a level of performance comparable to that of state-of-the-art\nsupervised methods (for 3s tolerance) on the RWC-Pop dataset, showcasing the\nimportance of the barwise compression processing for MSA.",
          "link": "http://arxiv.org/abs/2202.04981",
          "publishedOn": "2022-04-18T00:59:13.855Z",
          "wordCount": 684,
          "title": "Barwise Compression Schemes for Audio-Based Music Structure Analysis. (arXiv:2202.04981v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.07258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hulsebos_M/0/1/0/all/0/1\">Madelon Hulsebos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demiralp_C/0/1/0/all/0/1\">&#xc7;a&#x11f;atay Demiralp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1\">Paul Groth</a>",
          "description": "The success of deep learning has sparked interest in improving relational\ntable tasks, like data preparation and search, with table representation models\ntrained on large table corpora. Existing table corpora primarily contain tables\nextracted from HTML pages, limiting the capability to represent offline\ndatabase tables. To train and evaluate high-capacity models for applications\nbeyond the Web, we need resources with tables that resemble relational database\ntables. Here we introduce GitTables, a corpus of 1M relational tables extracted\nfrom GitHub. Our continuing curation aims at growing the corpus to at least 10M\ntables. Analyses of GitTables show that its structure, content, and topical\ncoverage differ significantly from existing table corpora. We annotate table\ncolumns in GitTables with semantic types, hierarchical relations and\ndescriptions from Schema.org and DBpedia. The evaluation of our annotation\npipeline on the T2Dv2 benchmark illustrates that our approach provides results\non par with human annotations. We present three applications of GitTables,\ndemonstrating its value for learned semantic type detection models, schema\ncompletion methods, and benchmarks for table-to-KG matching, data search, and\npreparation. We make the corpus and code available at\nhttps://gittables.github.io.",
          "link": "http://arxiv.org/abs/2106.07258",
          "publishedOn": "2022-04-18T00:59:13.834Z",
          "wordCount": 662,
          "title": "GitTables: A Large-Scale Corpus of Relational Tables. (arXiv:2106.07258v4 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kenworthy_L/0/1/0/all/0/1\">Luke Kenworthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_S/0/1/0/all/0/1\">Siddharth Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_C/0/1/0/all/0/1\">Christopher Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_H/0/1/0/all/0/1\">Hamsa Balakrishnan</a>",
          "description": "Integer programs provide a powerful abstraction for representing a wide range\nof real-world scheduling problems. Despite their ability to model general\nscheduling problems, solving large-scale integer programs (IP) remains a\ncomputational challenge in practice. The incorporation of more complex\nobjectives such as robustness to disruptions further exacerbates the\ncomputational challenge. We present NICE (Neural network IP Coefficient\nExtraction), a novel technique that combines reinforcement learning and integer\nprogramming to tackle the problem of robust scheduling. More specifically, NICE\nuses reinforcement learning to approximately represent complex objectives in an\ninteger programming formulation. We use NICE to determine assignments of pilots\nto a flight crew schedule so as to reduce the impact of disruptions. We compare\nNICE with (1) a baseline integer programming formulation that produces a\nfeasible crew schedule, and (2) a robust integer programming formulation that\nexplicitly tries to minimize the impact of disruptions. Our experiments show\nthat, across a variety of scenarios, NICE produces schedules resulting in 33%\nto 48% fewer disruptions than the baseline formulation. Moreover, in more\nseverely constrained scheduling scenarios in which the robust integer program\nfails to produce a schedule within 90 minutes, NICE is able to build robust\nschedules in less than 2 seconds on average.",
          "link": "http://arxiv.org/abs/2109.12171",
          "publishedOn": "2022-04-18T00:59:13.825Z",
          "wordCount": 691,
          "title": "NICE: Robust Scheduling through Reinforcement Learning-Guided Integer Programming. (arXiv:2109.12171v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tjanaka_B/0/1/0/all/0/1\">Bryon Tjanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fontaine_M/0/1/0/all/0/1\">Matthew C. Fontaine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolaidis_S/0/1/0/all/0/1\">Stefanos Nikolaidis</a>",
          "description": "Consider the problem of training robustly capable agents. One approach is to\ngenerate a diverse collection of agent polices. Training can then be viewed as\na quality diversity (QD) optimization problem, where we search for a collection\nof performant policies that are diverse with respect to quantified behavior.\nRecent work shows that differentiable quality diversity (DQD) algorithms\ngreatly accelerate QD optimization when exact gradients are available. However,\nagent policies typically assume that the environment is not differentiable. To\napply DQD algorithms to training agent policies, we must approximate gradients\nfor performance and behavior. We propose two variants of the current\nstate-of-the-art DQD algorithm that compute gradients via approximation methods\ncommon in reinforcement learning (RL). We evaluate our approach on four\nsimulated locomotion tasks. One variant achieves results comparable to the\ncurrent state-of-the-art in combining QD and RL, while the other performs\ncomparably in two locomotion tasks. These results provide insight into the\nlimitations of current DQD algorithms in domains where gradients must be\napproximated. Source code is available at https://github.com/icaros-usc/dqd-rl",
          "link": "http://arxiv.org/abs/2202.03666",
          "publishedOn": "2022-04-18T00:59:13.817Z",
          "wordCount": null,
          "title": "Approximating Gradients for Differentiable Quality Diversity in Reinforcement Learning. (arXiv:2202.03666v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshima_T/0/1/0/all/0/1\">Takeshi Teshima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tojo_K/0/1/0/all/0/1\">Koichi Tojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oono_K/0/1/0/all/0/1\">Kenta Oono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Invertible neural networks (INNs) are neural network architectures with\ninvertibility by design. Thanks to their invertibility and the tractability of\nJacobian, INNs have various machine learning applications such as probabilistic\nmodeling, generative modeling, and representation learning. However, their\nattractive properties often come at the cost of restricting the layer designs,\nwhich poses a question on their representation power: can we use these models\nto approximate sufficiently diverse functions? To answer this question, we have\ndeveloped a general theoretical framework to investigate the representation\npower of INNs, building on a structure theorem of differential geometry. The\nframework simplifies the approximation problem of diffeomorphisms, which\nenables us to show the universal approximation properties of INNs. We apply the\nframework to two representative classes of INNs, namely Coupling-Flow-based\nINNs (CF-INNs) and Neural Ordinary Differential Equations (NODEs), and\nelucidate their high representation power despite the restrictions on their\narchitectures.",
          "link": "http://arxiv.org/abs/2204.07415",
          "publishedOn": "2022-04-18T00:59:13.816Z",
          "wordCount": null,
          "title": "Universal approximation property of invertible neural networks. (arXiv:2204.07415v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.00909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lutzeyer_J/0/1/0/all/0/1\">Johannes F. Lutzeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Changmin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>",
          "description": "Message-Passing Neural Networks (MPNNs), the most prominent Graph Neural\nNetwork (GNN) framework, celebrate much success in the analysis of\ngraph-structured data. Concurrently, the sparsification of Neural Network\nmodels attracts a great amount of academic and industrial interest. In this\npaper we conduct a structured, empirical study of the effect of sparsification\non the trainable part of MPNNs known as the Update step. To this end, we design\na series of models to successively sparsify the linear transform in the Update\nstep. Specifically, we propose the ExpanderGNN model with a tuneable\nsparsification rate and the Activation-Only GNN, which has no linear transform\nin the Update step. In agreement with a growing trend in the literature the\nsparsification paradigm is changed by initialising sparse neural network\narchitectures rather than expensively sparsifying already trained\narchitectures. Our novel benchmark models enable a better understanding of the\ninfluence of the Update step on model performance and outperform existing\nsimplified benchmark models such as the Simple Graph Convolution. The\nExpanderGNNs, and in some cases the Activation-Only models, achieve performance\non par with their vanilla counterparts on several downstream tasks, while\ncontaining significantly fewer trainable parameters. Our code is publicly\navailable at: https://github.com/ChangminWu/ExpanderGNN.",
          "link": "http://arxiv.org/abs/2109.00909",
          "publishedOn": "2022-04-18T00:59:13.814Z",
          "wordCount": null,
          "title": "Sparsifying the Update Step in Graph Neural Networks. (arXiv:2109.00909v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sean Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chenjuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jilin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_C/0/1/0/all/0/1\">Christian S. Jensen</a>",
          "description": "In step with the digitalization of transportation, we are witnessing a\ngrowing range of path-based smart-city applications, e.g., travel-time\nestimation and travel path ranking. A temporal path(TP) that includes temporal\ninformation, e.g., departure time, into the path is fundamental to enable such\napplications. In this setting, it is essential to learn generic temporal path\nrepresentations(TPRs) that consider spatial and temporal correlations\nsimultaneously and that can be used in different applications, i.e., downstream\ntasks. Existing methods fail to achieve the goal since (i) supervised methods\nrequire large amounts of task-specific labels when training and thus fail to\ngeneralize the obtained TPRs to other tasks; (ii) through unsupervised methods\ncan learn generic representations, they disregard the temporal aspect, leading\nto sub-optimal results. To contend with the limitations of existing solutions,\nwe propose a Weakly-Supervised Contrastive (WSC) learning model. We first\npropose a temporal path encoder that encodes both the spatial and temporal\ninformation of a temporal path into a TPR. To train the encoder, we introduce\nweak labels that are easy and inexpensive to obtain and are relevant to\ndifferent tasks, e.g., temporal labels indicating peak vs. off-peak hours from\ndeparture times. Based on the weak labels, we construct meaningful positive and\nnegative temporal path samples by considering both spatial and temporal\ninformation, which facilities training the encoder using contrastive learning\nby pulling closer to the positive samples' representations while pushing away\nthe negative samples' representations. To better guide contrastive learning, we\npropose a learning strategy based on Curriculum Learning such that the learning\nperforms from easy to hard training instances. Experiments studies verify the\neffectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2203.16110",
          "publishedOn": "2022-04-18T00:59:13.814Z",
          "wordCount": null,
          "title": "Weakly-supervised Temporal Path Representation Learning with Contrastive Curriculum Learning -- Extended Version. (arXiv:2203.16110v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "In data-rich domains such as vision, language, and speech, deep learning\nprevails to deliver high-performance task-specific models and can even learn\ngeneral task-agnostic representations for efficient finetuning to downstream\ntasks. However, deep learning in resource-limited domains still faces the\nfollowing challenges including (i) limited data, (ii) constrained model\ndevelopment cost, and (iii) lack of adequate pre-trained models for effective\nfinetuning. This paper introduces a new technique called model reprogramming to\nbridge this gap. Model reprogramming enables resource-efficient cross-domain\nmachine learning by repurposing and reusing a well-developed pre-trained model\nfrom a source domain to solve tasks in a target domain without model\nfinetuning, where the source and target domains can be vastly different. In\nmany applications, model reprogramming outperforms transfer learning and\ntraining from scratch. This paper elucidates the methodology of model\nreprogramming, summarizes existing use cases, provides a theoretical\nexplanation on the success of model reprogramming, and concludes with a\ndiscussion on open-ended research questions and opportunities. A list of model\nreprogramming studies is actively maintained and updated at\nhttps://github.com/IBM/model-reprogramming.",
          "link": "http://arxiv.org/abs/2202.10629",
          "publishedOn": "2022-04-18T00:59:13.811Z",
          "wordCount": 627,
          "title": "Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning. (arXiv:2202.10629v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07526",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dudeja_R/0/1/0/all/0/1\">Rishabh Dudeja</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hsu_D/0/1/0/all/0/1\">Daniel Hsu</a>",
          "description": "Tensor PCA is a stylized statistical inference problem introduced by\nMontanari and Richard to study the computational difficulty of estimating an\nunknown parameter from higher-order moment tensors. Unlike its matrix\ncounterpart, Tensor PCA exhibits a statistical-computational gap, i.e., a\nsample size regime where the problem is information-theoretically solvable but\nconjectured to be computationally hard. This paper derives computational lower\nbounds on the run-time of memory bounded algorithms for Tensor PCA using\ncommunication complexity. These lower bounds specify a trade-off among the\nnumber of passes through the data sample, the sample size, and the memory\nrequired by any algorithm that successfully solves Tensor PCA. While the lower\nbounds do not rule out polynomial-time algorithms, they do imply that many\ncommonly-used algorithms, such as gradient descent and power method, must have\na higher iteration count when the sample size is not large enough. Similar\nlower bounds are obtained for Non-Gaussian Component Analysis, a family of\nstatistical estimation problems in which low-order moment tensors carry no\ninformation about the unknown parameter. Finally, stronger lower bounds are\nobtained for an asymmetric variant of Tensor PCA and related statistical\nestimation problems. These results explain why many estimators for these\nproblems use a memory state that is significantly larger than the effective\ndimensionality of the parameter of interest.",
          "link": "http://arxiv.org/abs/2204.07526",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "Statistical-Computational Trade-offs in Tensor PCA and Related Problems via Communication Complexity. (arXiv:2204.07526v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07576",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran A. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassett_D/0/1/0/all/0/1\">Dani S. Bassett</a>",
          "description": "The fruits of science are relationships made comprehensible, often by way of\napproximation. While deep learning is an extremely powerful way to find\nrelationships in data, its use in science has been hindered by the difficulty\nof understanding the learned relationships. The Information Bottleneck (IB) is\nan information theoretic framework for understanding a relationship between an\ninput and an output in terms of a trade-off between the fidelity and complexity\nof approximations to the relationship. Here we show that a crucial modification\n-- distributing bottlenecks across multiple components of the input -- opens\nfundamentally new avenues for interpretable deep learning in science. The\nDistributed Information Bottleneck throttles the downstream complexity of\ninteractions between the components of the input, deconstructing a relationship\ninto meaningful approximations found through deep learning without requiring\ncustom-made datasets or neural network architectures. Applied to a complex\nsystem, the approximations illuminate aspects of the system's nature by\nrestricting -- and monitoring -- the information about different components\nincorporated into the approximation. We demonstrate the Distributed IB's\nexplanatory utility in systems drawn from applied mathematics and condensed\nmatter physics. In the former, we deconstruct a Boolean circuit into\napproximations that isolate the most informative subsets of input components\nwithout requiring exhaustive search. In the latter, we localize information\nabout future plastic rearrangement in the static structure of a sheared glass,\nand find the information to be more or less diffuse depending on the system's\npreparation. By way of a principled scheme of approximations, the Distributed\nIB brings much-needed interpretability to deep learning and enables\nunprecedented analysis of information flow through a system.",
          "link": "http://arxiv.org/abs/2204.07576",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "The Distributed Information Bottleneck reveals the explanatory structure of complex systems. (arXiv:2204.07576v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nystrom_K/0/1/0/all/0/1\">Kaj Nystr&#xf6;m</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vestberg_M/0/1/0/all/0/1\">Matias Vestberg</a>",
          "description": "The Monge-Amp\\`ere equation is a fully nonlinear partial differential\nequation (PDE) of fundamental importance in analysis, geometry and in the\napplied sciences. In this paper we solve the Dirichlet problem associated with\nthe Monge-Amp\\`ere equation using neural networks and we show that an ansatz\nusing deep input convex neural networks can be used to find the unique convex\nsolution. As part of our analysis we study the effect of singularities,\ndiscontinuities and noise in the source function, we consider nontrivial\ndomains, and we investigate how the method performs in higher dimensions. We\nalso compare this method to an alternative approach in which standard\nfeed-forward networks are used together with a loss function which penalizes\nlack of convexity.",
          "link": "http://arxiv.org/abs/2110.03310",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "Solving the Dirichlet problem for the Monge-Amp\\`ere equation using neural networks. (arXiv:2110.03310v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.04629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_L/0/1/0/all/0/1\">Luana Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chamon_L/0/1/0/all/0/1\">Luiz F. O. Chamon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>",
          "description": "Graph neural networks (GNNs) are composed of layers consisting of graph\nconvolutions and pointwise nonlinearities. Due to their invariance and\nstability properties, GNNs are provably successful at learning representations\nfrom data supported on moderate-scale graphs. However, they are difficult to\nlearn on large-scale graphs. In this paper, we study the problem of training\nGNNs on graphs of moderate size and transferring them to large-scale graphs. We\nuse graph limits called graphons to define limit objects for graph filters and\nGNNs -- graphon filters and graphon neural networks (WNNs) -- which we\ninterpret as generative models for graph filters and GNNs. We then show that\ngraphon filters and WNNs can be approximated by graph filters and GNNs sampled\nfrom them on weighted and stochastic graphs. Because the error of these\napproximations can be upper bounded, by a triangle inequality argument we can\nfurther bound the error of transferring a graph filter or a GNN across graphs.\nOur results show that (i) the transference error decreases with the graph size,\nand (ii) that graph filters have a transferability-discriminability tradeoff\nthat in GNNs is alleviated by the scattering behavior of the nonlinearity.\nThese findings are demonstrated empirically in a movie recommendation problem\nand in a decentralized control task.",
          "link": "http://arxiv.org/abs/2112.04629",
          "publishedOn": "2022-04-18T00:59:13.757Z",
          "wordCount": null,
          "title": "Transferability Properties of Graph Neural Networks. (arXiv:2112.04629v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luther_K/0/1/0/all/0/1\">Kyle Luther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seung_H/0/1/0/all/0/1\">H. Sebastian Seung</a>",
          "description": "Recent works have derived neural networks with online correlation-based\nlearning rules to perform \\textit{kernel similarity matching}. These works\napplied existing linear similarity matching algorithms to nonlinear features\ngenerated with random Fourier methods. In this paper attempt to perform kernel\nsimilarity matching by directly learning the nonlinear features. Our algorithm\nproceeds by deriving and then minimizing an upper bound for the sum of squared\nerrors between output and input kernel similarities. The construction of our\nupper bound leads to online correlation-based learning rules which can be\nimplemented with a 1 layer recurrent neural network. In addition to generating\nhigh-dimensional linearly separable representations, we show that our upper\nbound naturally yields representations which are sparse and selective for\nspecific input patterns. We compare the approximation quality of our method to\nneural random Fourier method and variants of the popular but non-biological\n\"Nystr{\\\"o}m\" method for approximating the kernel matrix. Our method appears to\nbe comparable or better than randomly sampled Nystr{\\\"o}m methods when the\noutputs are relatively low dimensional (although still potentially higher\ndimensional than the inputs) but less faithful when the outputs are very high\ndimensional.",
          "link": "http://arxiv.org/abs/2204.07475",
          "publishedOn": "2022-04-18T00:59:13.730Z",
          "wordCount": null,
          "title": "Kernel similarity matching with Hebbian neural networks. (arXiv:2204.07475v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07358",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Musellim_S/0/1/0/all/0/1\">Serkan Musellim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_D/0/1/0/all/0/1\">Dong-Kyun Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jeong_J/0/1/0/all/0/1\">Ji-Hoon Jeong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Brain-computer interface (BCI) is challenging to use in practice due to the\ninter/intra-subject variability of electroencephalography (EEG). The BCI\nsystem, in general, necessitates a calibration technique to obtain\nsubject/session-specific data in order to tune the model each time the system\nis utilized. This issue is acknowledged as a key hindrance to BCI, and a new\nstrategy based on domain generalization has recently evolved to address it. In\nlight of this, we've concentrated on developing an EEG classification framework\nthat can be applied directly to data from unknown domains (i.e. subjects),\nusing only data acquired from separate subjects previously. For this purpose,\nin this paper, we proposed a framework that employs the open-set recognition\ntechnique as an auxiliary task to learn subject-specific style features from\nthe source dataset while helping the shared feature extractor with mapping the\nfeatures of the unseen target dataset as a new unseen domain. Our aim is to\nimpose cross-instance style in-variance in the same domain and reduce the open\nspace risk on the potential unseen subject in order to improve the\ngeneralization ability of the shared feature extractor. Our experiments showed\nthat using the domain information as an auxiliary network increases the\ngeneralization performance.",
          "link": "http://arxiv.org/abs/2204.07358",
          "publishedOn": "2022-04-18T00:59:13.676Z",
          "wordCount": 648,
          "title": "Prototype-based Domain Generalization Framework for Subject-Independent Brain-Computer Interfaces. (arXiv:2204.07358v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Babaiee_Z/0/1/0/all/0/1\">Zahra Babaiee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1\">Lucas Liebenwein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasani_R/0/1/0/all/0/1\">Ramin Hasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosu_R/0/1/0/all/0/1\">Radu Grosu</a>",
          "description": "In this paper, we present a novel sensitivity-based filter pruning algorithm\n(SbF-Pruner) to learn the importance scores of filters of each layer\nend-to-end. Our method learns the scores from the filter weights, enabling it\nto account for the correlations between the filters of each layer. Moreover, by\ntraining the pruning scores of all layers simultaneously our method can account\nfor layer interdependencies, which is essential to find a performant sparse\nsub-network. Our proposed method can train and generate a pruned network from\nscratch in a straightforward, one-stage training process without requiring a\npretrained network. Ultimately, we do not need layer-specific hyperparameters\nand pre-defined layer budgets, since SbF-Pruner can implicitly determine the\nappropriate number of channels in each layer. Our experimental results on\ndifferent network architectures suggest that SbF-Pruner outperforms advanced\npruning methods. Notably, on CIFAR-10, without requiring a pretrained baseline\nnetwork, we obtain 1.02% and 1.19% accuracy gain on ResNet56 and ResNet110,\ncompared to the baseline reported for state-of-the-art pruning algorithms. This\nis while SbF-Pruner reduces parameter-count by 52.3% (for ResNet56) and 54%\n(for ResNet101), which is better than the state-of-the-art pruning algorithms\nwith a high margin of 9.5% and 6.6%.",
          "link": "http://arxiv.org/abs/2204.07412",
          "publishedOn": "2022-04-18T00:59:13.669Z",
          "wordCount": 631,
          "title": "End-to-End Sensitivity-Based Filter Pruning. (arXiv:2204.07412v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zavrak_S/0/1/0/all/0/1\">Sultan Zavrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_S/0/1/0/all/0/1\">Seyhmus Yilmaz</a>",
          "description": "Email is one of the most widely used ways to communicate, with millions of\npeople and businesses relying on it to communicate and share knowledge and\ninformation on a daily basis. Nevertheless, the rise in email users has\noccurred a dramatic increase in spam emails in recent years. Processing and\nmanaging emails properly for individuals and companies are getting increasingly\ndifficult. This article proposes a novel technique for email spam detection\nthat is based on a combination of convolutional neural networks, gated\nrecurrent units, and attention mechanisms. During system training, the network\nis selectively focused on necessary parts of the email text. The usage of\nconvolution layers to extract more meaningful, abstract, and generalizable\nfeatures by hierarchical representation is the major contribution of this\nstudy. Additionally, this contribution incorporates cross-dataset evaluation,\nwhich enables the generation of more independent performance results from the\nmodel's training dataset. According to cross-dataset evaluation results, the\nproposed technique advances the results of the present attention-based\ntechniques by utilizing temporal convolutions, which give us more flexible\nreceptive field sizes are utilized. The suggested technique's findings are\ncompared to those of state-of-the-art models and show that our approach\noutperforms them.",
          "link": "http://arxiv.org/abs/2204.07390",
          "publishedOn": "2022-04-18T00:59:13.661Z",
          "wordCount": 639,
          "title": "Email Spam Detection Using Hierarchical Attention Hybrid Deep Learning Method. (arXiv:2204.07390v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_I/0/1/0/all/0/1\">Itsugun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_R/0/1/0/all/0/1\">Ryota Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1\">Hiroaki Saito</a>",
          "description": "Current works in the generation of personalized dialogue primarily contribute\nto the agent avoiding contradictory persona and driving the response more\ninformative. However, we found that the generated responses from these models\nare mostly self-centered with little care for the other party since they ignore\nthe user's persona. Moreover, we consider high-quality transmission is\nessentially built based on apprehending the persona of the other party.\nMotivated by this, we propose a novel personalized dialogue generator by\ndetecting implicit user persona. Because it's difficult to collect a large\nnumber of personas for each user, we attempt to model the user's potential\npersona and its representation from the dialogue absence of any external\ninformation. Perception variable and fader variable are conceived utilizing\nConditional Variational Inference. The two latent variables simulate the\nprocess of people being aware of the other party's persona and producing the\ncorresponding expression in conversation. Finally, Posterior-discriminated\nRegularization is presented to enhance the training procedure. Empirical\nstudies demonstrate that compared with the state-of-the-art methods, ours is\nmore concerned with the user's persona and outperforms in evaluations.",
          "link": "http://arxiv.org/abs/2204.07372",
          "publishedOn": "2022-04-18T00:59:13.653Z",
          "wordCount": 631,
          "title": "Towards Building a Personalized Dialogue Generator via Implicit User Persona Detection. (arXiv:2204.07372v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07353",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nishida_T/0/1/0/all/0/1\">Tomoya Nishida</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dohi_K/0/1/0/all/0/1\">Kota Dohi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Endo_T/0/1/0/all/0/1\">Takashi Endo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamamoto_M/0/1/0/all/0/1\">Masaaki Yamamoto</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kawaguchi_Y/0/1/0/all/0/1\">Yohei Kawaguchi</a>",
          "description": "We have developed an unsupervised anomalous sound detection method for\nmachine condition monitoring that utilizes an auxiliary task -- detecting when\nthe target machine is active. First, we train a model that detects machine\nactivity by using normal data with machine activity labels and then use the\nactivity-detection error as the anomaly score for a given sound clip if we have\naccess to the ground-truth activity labels in the inference phase. If these\nlabels are not available, the anomaly score is calculated through outlier\ndetection on the embedding vectors obtained by the activity-detection model.\nSolving this auxiliary task enables the model to learn the difference between\nthe target machine sounds and similar background noise, which makes it possible\nto identify small deviations in the target sounds. Experimental results showed\nthat the proposed method improves the anomaly-detection performance of the\nconventional method complementarily by means of an ensemble.",
          "link": "http://arxiv.org/abs/2204.07353",
          "publishedOn": "2022-04-18T00:59:13.632Z",
          "wordCount": 605,
          "title": "Anomalous Sound Detection Based on Machine Activity Detection. (arXiv:2204.07353v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kewei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>",
          "description": "Crowd counting based on density maps is generally regarded as a regression\ntask.Deep learning is used to learn the mapping between image content and crowd\ndensity distribution. Although great success has been achieved, some\npedestrians far away from the camera are difficult to be detected. And the\nnumber of hard examples is often larger. Existing methods with simple Euclidean\ndistance algorithm indiscriminately optimize the hard and easy examples so that\nthe densities of hard examples are usually incorrectly predicted to be lower or\neven zero, which results in large counting errors. To address this problem, we\nare the first to propose the Hard Example Focusing(HEF) algorithm for the\nregression task of crowd counting. The HEF algorithm makes our model rapidly\nfocus on hard examples by attenuating the contribution of easy examples.Then\nhigher importance will be given to the hard examples with wrong estimations.\nMoreover, the scale variations in crowd scenes are large, and the scale\nannotations are labor-intensive and expensive. By proposing a multi-Scale\nSemantic Refining (SSR) strategy, lower layers of our model can break through\nthe limitation of deep learning to capture semantic features of different\nscales to sufficiently deal with the scale variation. We perform extensive\nexperiments on six benchmark datasets to verify the proposed method. Results\nindicate the superiority of our proposed method over the state-of-the-art\nmethods. Moreover, our designed model is smaller and faster.",
          "link": "http://arxiv.org/abs/2204.07406",
          "publishedOn": "2022-04-18T00:59:13.610Z",
          "wordCount": 704,
          "title": "SSR-HEF: Crowd Counting with Multi-Scale Semantic Refining and Hard Example Focusing. (arXiv:2204.07406v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>",
          "description": "Deep learning occupies an undisputed dominance in crowd counting. In this\npaper, we propose a novel convolutional neural network (CNN) architecture\ncalled SegCrowdNet. Despite the complex background in crowd scenes, the\nproposeSegCrowdNet still adaptively highlights the human head region and\nsuppresses the non-head region by segmentation. With the guidance of an\nattention mechanism, the proposed SegCrowdNet pays more attention to the human\nhead region and automatically encodes the highly refined density map. The crowd\ncount can be obtained by integrating the density map. To adapt the variation of\ncrowd counts, SegCrowdNet intelligently classifies the crowd count of each\nimage into several groups. In addition, the multi-scale features are learned\nand extracted in the proposed SegCrowdNet to overcome the scale variations of\nthe crowd. To verify the effectiveness of our proposed method, extensive\nexperiments are conducted on four challenging datasets. The results demonstrate\nthat our proposed SegCrowdNet achieves excellent performance compared with the\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2204.07380",
          "publishedOn": "2022-04-18T00:59:13.602Z",
          "wordCount": 620,
          "title": "Crowd counting with segmentation attention convolutional neural network. (arXiv:2204.07380v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07293",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wenying Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coker_B/0/1/0/all/0/1\">Beau Coker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jeremiah Zhe Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coull_B/0/1/0/all/0/1\">Brent A. Coull</a>",
          "description": "We develop a simple and unified framework for nonlinear variable selection\nthat incorporates model uncertainty and is compatible with a wide range of\nmachine learning models (e.g., tree ensembles, kernel methods and neural\nnetwork). In particular, for a learned nonlinear model $f(\\mathbf{x})$, we\nconsider quantifying the importance of an input variable $\\mathbf{x}^j$ using\nthe integrated gradient measure $\\psi_j = \\Vert \\frac{\\partial}{\\partial\n\\mathbf{x}^j} f(\\mathbf{x})\\Vert^2_2$. We then (1) provide a principled\napproach for quantifying variable selection uncertainty by deriving its\nposterior distribution, and (2) show that the approach is generalizable even to\nnon-differentiable models such as tree ensembles. Rigorous Bayesian\nnonparametric theorems are derived to guarantee the posterior consistency and\nasymptotic uncertainty of the proposed approach. Extensive simulation confirms\nthat the proposed algorithm outperforms existing classic and recent variable\nselection methods.",
          "link": "http://arxiv.org/abs/2204.07293",
          "publishedOn": "2022-04-18T00:59:13.594Z",
          "wordCount": 580,
          "title": "Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Selection with Theoretical Guarantees. (arXiv:2204.07293v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07360",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Meng_H/0/1/0/all/0/1\">Han Meng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_Y/0/1/0/all/0/1\">Yuexing Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Wenbo Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_P/0/1/0/all/0/1\">Peng Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yonghui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiang_W/0/1/0/all/0/1\">Wei Xiang</a>",
          "description": "This paper proposes a knowledge-and-data-driven graph neural network-based\ncollaboration learning model for reliable aircraft recognition in a\nheterogeneous radar network. The aircraft recognizability analysis shows that:\n(1) the semantic feature of an aircraft is motion patterns driven by the\nkinetic characteristics, and (2) the grammatical features contained in the\nradar cross-section (RCS) signals present spatial-temporal-frequency (STF)\ndiversity decided by both the electromagnetic radiation shape and motion\npattern of the aircraft. Then a STF graph attention convolutional network\n(STFGACN) is developed to distill semantic features from the RCS signals\nreceived by the heterogeneous radar network. Extensive experiment results\nverify that the STFGACN outperforms the baseline methods in terms of detection\naccuracy, and ablation experiments are carried out to further show that the\nexpansion of the information dimension can gain considerable benefits to\nperform robustly in the low signal-to-noise ratio region.",
          "link": "http://arxiv.org/abs/2204.07360",
          "publishedOn": "2022-04-18T00:59:13.586Z",
          "wordCount": 599,
          "title": "Spatio-Temporal-Frequency Graph Attention Convolutional Network for Aircraft Recognition Based on Heterogeneous Radar Network. (arXiv:2204.07360v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07312",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Balcan_M/0/1/0/all/0/1\">Maria-Florina Balcan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Prasad_S/0/1/0/all/0/1\">Siddharth Prasad</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sandholm_T/0/1/0/all/0/1\">Tuomas Sandholm</a>, <a href=\"http://arxiv.org/find/math/1/au:+Vitercik_E/0/1/0/all/0/1\">Ellen Vitercik</a>",
          "description": "The incorporation of cutting planes within the branch-and-bound algorithm,\nknown as branch-and-cut, forms the backbone of modern integer programming\nsolvers. These solvers are the foremost method for solving discrete\noptimization problems and thus have a vast array of applications in machine\nlearning, operations research, and many other fields. Choosing cutting planes\neffectively is a major research topic in the theory and practice of integer\nprogramming. We conduct a novel structural analysis of branch-and-cut that pins\ndown how every step of the algorithm is affected by changes in the parameters\ndefining the cutting planes added to the input integer program. Our main\napplication of this analysis is to derive sample complexity guarantees for\nusing machine learning to determine which cutting planes to apply during\nbranch-and-cut. These guarantees apply to infinite families of cutting planes,\nsuch as the family of Gomory mixed integer cuts, which are responsible for the\nmain breakthrough speedups of integer programming solvers. We exploit geometric\nand combinatorial structure of branch-and-cut in our analysis, which provides a\nkey missing piece for the recent generalization theory of branch-and-cut.",
          "link": "http://arxiv.org/abs/2204.07312",
          "publishedOn": "2022-04-18T00:59:13.578Z",
          "wordCount": 630,
          "title": "Structural Analysis of Branch-and-Cut and the Learnability of Gomory Mixed Integer Cuts. (arXiv:2204.07312v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1\">Long Sha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engelbrecht_J/0/1/0/all/0/1\">Jan Engelbrecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1\">Pengyu Hong</a>",
          "description": "Knowledge graph (KG) representation learning aims to encode entities and\nrelations into dense continuous vector spaces such that knowledge contained in\na dataset could be consistently represented. Dense embeddings trained from KG\ndatasets benefit a variety of downstream tasks such as KG completion and link\nprediction. However, existing KG embedding methods fell short to provide a\nsystematic solution for the global consistency of knowledge representation. We\ndeveloped a mathematical language for KG based on an observation of their\ninherent algebraic structure, which we termed as Knowledgebra. By analyzing\nfive distinct algebraic properties, we proved that the semigroup is the most\nreasonable algebraic structure for the relation embedding of a general\nknowledge graph. We implemented an instantiation model, SemE, using simple\nmatrix semigroups, which exhibits state-of-the-art performance on standard\ndatasets. Moreover, we proposed a regularization-based method to integrate\nchain-like logic rules derived from human knowledge into embedding training,\nwhich further demonstrates the power of the developed language. As far as we\nknow, by applying abstract algebra in statistical learning, this work develops\nthe first formal language for general knowledge graphs, and also sheds light on\nthe problem of neural-symbolic integration from an algebraic perspective.",
          "link": "http://arxiv.org/abs/2204.07328",
          "publishedOn": "2022-04-18T00:59:13.546Z",
          "wordCount": 635,
          "title": "Knowledgebra: An Algebraic Learning Framework for Knowledge Graph. (arXiv:2204.07328v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chan-Jan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Transformer-based models are widely used in natural language understanding\n(NLU) tasks, and multimodal transformers have been effective in visual-language\ntasks. This study explores distilling visual information from pretrained\nmultimodal transformers to pretrained language encoders. Our framework is\ninspired by cross-modal encoders' success in visual-language tasks while we\nalter the learning objective to cater to the language-heavy characteristics of\nNLU. After training with a small number of extra adapting steps and finetuned,\nthe proposed XDBERT (cross-modal distilled BERT) outperforms pretrained-BERT in\ngeneral language understanding evaluation (GLUE), situations with adversarial\ngenerations (SWAG) benchmarks, and readability benchmarks. We analyze the\nperformance of XDBERT on GLUE to show that the improvement is likely visually\ngrounded.",
          "link": "http://arxiv.org/abs/2204.07316",
          "publishedOn": "2022-04-18T00:59:13.538Z",
          "wordCount": 564,
          "title": "XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems to Improve Language Understanding. (arXiv:2204.07316v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kuangen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiahong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1\">Yuquan Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_C/0/1/0/all/0/1\">Clarence W. de Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chenglong Fu</a>",
          "description": "Recognizing human locomotion intent and activities is important for\ncontrolling the wearable robots while walking in complex environments. However,\nhuman-robot interface signals are usually user-dependent, which causes that the\nclassifier trained on source subjects performs poorly on new subjects. To\naddress this issue, this paper designs the ensemble diverse hypotheses and\nknowledge distillation (EDHKD) method to realize unsupervised cross-subject\nadaptation. EDH mitigates the divergence between labeled data of source\nsubjects and unlabeled data of target subjects to accurately classify the\nlocomotion modes of target subjects without labeling data. Compared to previous\ndomain adaptation methods based on the single learner, which may only learn a\nsubset of features from input signals, EDH can learn diverse features by\nincorporating multiple diverse feature generators and thus increases the\naccuracy and decreases the variance of classifying target data, but it\nsacrifices the efficiency. To solve this problem, EDHKD (student) distills the\nknowledge from the EDH (teacher) to a single network to remain efficient and\naccurate. The performance of the EDHKD is theoretically proved and\nexperimentally validated on a 2D moon dataset and two public human locomotion\ndatasets. Experimental results show that the EDHKD outperforms all other\nmethods. The EDHKD can classify target data with 96.9%, 94.4%, and 97.4%\naverage accuracy on the above three datasets with a short computing time (1\nms). Compared to a benchmark (BM) method, the EDHKD increases 1.3% and 7.1%\naverage accuracy for classifying the locomotion modes of target subjects. The\nEDHKD also stabilizes the learning curves. Therefore, the EDHKD is significant\nfor increasing the generalization ability and efficiency of the human intent\nprediction and human activity recognition system, which will improve\nhuman-robot interactions.",
          "link": "http://arxiv.org/abs/2204.07308",
          "publishedOn": "2022-04-18T00:59:13.530Z",
          "wordCount": 741,
          "title": "Ensemble diverse hypotheses and knowledge distillation for unsupervised cross-subject adaptation. (arXiv:2204.07308v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahir/0/1/0/all/0/1\">Sahir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilhan_E/0/1/0/all/0/1\">Erc&#xfc;ment &#x130;lhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Srijita Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1\">Matthew E. Taylor</a>",
          "description": "Reinforcement learning (RL) has shown great success in solving many\nchallenging tasks via use of deep neural networks. Although using deep learning\nfor RL brings immense representational power, it also causes a well-known\nsample-inefficiency problem. This means that the algorithms are data-hungry and\nrequire millions of training samples to converge to an adequate policy. One way\nto combat this issue is to use action advising in a teacher-student framework,\nwhere a knowledgeable teacher provides action advice to help the student. This\nwork considers how to better leverage uncertainties about when a student should\nask for advice and if the student can model the teacher to ask for less advice.\nThe student could decide to ask for advice when it is uncertain or when both it\nand its model of the teacher are uncertain. In addition to this investigation,\nthis paper introduces a new method to compute uncertainty for a deep RL agent\nusing a secondary neural network. Our empirical results show that using dual\nuncertainties to drive advice collection and reuse may improve learning\nperformance across several Atari games.",
          "link": "http://arxiv.org/abs/2204.07254",
          "publishedOn": "2022-04-18T00:59:13.521Z",
          "wordCount": 636,
          "title": "Methodical Advice Collection and Reuse in Deep Reinforcement Learning. (arXiv:2204.07254v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07352",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balelli_I/0/1/0/all/0/1\">Irene Balelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_S/0/1/0/all/0/1\">Santiago Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzi_M/0/1/0/all/0/1\">Marco Lorenzi</a>",
          "description": "We propose a novel federated learning paradigm to model data variability\namong heterogeneous clients in multi-centric studies. Our method is expressed\nthrough a hierarchical Bayesian latent variable model, where client-specific\nparameters are assumed to be realization from a global distribution at the\nmaster level, which is in turn estimated to account for data bias and\nvariability across clients. We show that our framework can be effectively\noptimized through expectation maximization (EM) over latent master's\ndistribution and clients' parameters. We also introduce formal differential\nprivacy (DP) guarantees compatibly with our EM optimization scheme. We tested\nour method on the analysis of multi-modal medical imaging data and clinical\nscores from distributed clinical datasets of patients affected by Alzheimer's\ndisease. We demonstrate that our method is robust when data is distributed\neither in iid and non-iid manners, even when local parameters perturbation is\nincluded to provide DP guarantees. Moreover, the variability of data, views and\ncenters can be quantified in an interpretable manner, while guaranteeing\nhigh-quality data reconstruction as compared to state-of-the-art autoencoding\nmodels and federated learning schemes. The code is available at\nhttps://gitlab.inria.fr/epione/federated-multi-views-ppca.",
          "link": "http://arxiv.org/abs/2204.07352",
          "publishedOn": "2022-04-18T00:59:13.498Z",
          "wordCount": 664,
          "title": "A Differentially Private Probabilistic Framework for Modeling the Variability Across Federated Datasets of Heterogeneous Multi-View Observations. (arXiv:2204.07352v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07347",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zengfu Wang</a>",
          "description": "Crowd counting is a challenging problem due to the scene complexity and scale\nvariation. Although deep learning has achieved great improvement in crowd\ncounting, scene complexity affects the judgement of these methods and they\nusually regard some objects as people mistakenly; causing potentially enormous\nerrors in the crowd counting result. To address the problem, we propose a novel\nend-to-end model called Crowd Attention Convolutional Neural Network (CAT-CNN).\nOur CAT-CNN can adaptively assess the importance of a human head at each pixel\nlocation by automatically encoding a confidence map. With the guidance of the\nconfidence map, the position of human head in estimated density map gets more\nattention to encode the final density map, which can avoid enormous\nmisjudgements effectively. The crowd count can be obtained by integrating the\nfinal density map. To encode a highly refined density map, the total crowd\ncount of each image is classified in a designed classification task and we\nfirst explicitly map the prior of the population-level category to feature\nmaps. To verify the efficiency of our proposed method, extensive experiments\nare conducted on three highly challenging datasets. Results establish the\nsuperiority of our method over many state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2204.07347",
          "publishedOn": "2022-04-18T00:59:13.489Z",
          "wordCount": 664,
          "title": "Crowd counting with crowd attention convolutional neural network. (arXiv:2204.07347v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1\">Yibing Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenbin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Graph neural networks have emerged as a leading architecture for many\ngraph-level tasks such as graph classification and graph generation with a\nnotable improvement. Among these tasks, graph pooling is an essential component\nof graph neural network architectures for obtaining a holistic graph-level\nrepresentation of the entire graph. Although a great variety of methods have\nbeen proposed in this promising and fast-developing research field, to the best\nof our knowledge, little effort has been made to systematically summarize these\nmethods. To set the stage for the development of future works, in this paper,\nwe attempt to fill this gap by providing a broad review of recent methods on\ngraph pooling. Specifically, 1) we first propose a taxonomy of existing graph\npooling methods and provide a mathematical summary for each category; 2) next,\nwe provide an overview of the libraries related to graph pooling, including the\ncommonly used datasets, model architectures for downstream tasks, and\nopen-source implementations; 3) then, we further outline in brief the\napplications that incorporate the idea of graph pooling in a number of domains;\n4) and finally, we discuss some critical challenges faced by the current\nstudies and share our insights on potential directions for improving graph\npooling in the future.",
          "link": "http://arxiv.org/abs/2204.07321",
          "publishedOn": "2022-04-18T00:59:13.480Z",
          "wordCount": 654,
          "title": "Graph Pooling for Graph Neural Networks: Progress, Challenges, and Opportunities. (arXiv:2204.07321v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lechner_M/0/1/0/all/0/1\">Mathias Lechner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Alexander Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henzinger_T/0/1/0/all/0/1\">Thomas A. Henzinger</a>",
          "description": "Adversarial training (i.e., training on adversarially perturbed input data)\nis a well-studied method for making neural networks robust to potential\nadversarial attacks during inference. However, the improved robustness does not\ncome for free but rather is accompanied by a decrease in overall model accuracy\nand performance. Recent work has shown that, in practical robot learning\napplications, the effects of adversarial training do not pose a fair trade-off\nbut inflict a net loss when measured in holistic robot performance. This work\nrevisits the robustness-accuracy trade-off in robot learning by systematically\nanalyzing if recent advances in robust training methods and theory in\nconjunction with adversarial robot learning can make adversarial training\nsuitable for real-world robot applications. We evaluate a wide variety of robot\nlearning tasks ranging from autonomous driving in a high-fidelity environment\namenable to sim-to-real deployment, to mobile robot gesture recognition. Our\nresults demonstrate that, while these techniques make incremental improvements\non the trade-off on a relative scale, the negative side-effects caused by\nadversarial training still outweigh the improvements by an order of magnitude.\nWe conclude that more substantial advances in robust learning methods are\nnecessary before they can benefit robot learning tasks in practice.",
          "link": "http://arxiv.org/abs/2204.07373",
          "publishedOn": "2022-04-18T00:59:13.456Z",
          "wordCount": 636,
          "title": "Revisiting the Adversarial Robustness-Accuracy Tradeoff in Robot Learning. (arXiv:2204.07373v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shell Xu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuhmer_J/0/1/0/all/0/1\">Jan St&#xfc;hmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy M. Hospedales</a>",
          "description": "Few-shot learning (FSL) is an important and topical problem in computer\nvision that has motivated extensive research into numerous methods spanning\nfrom sophisticated meta-learning methods to simple transfer learning baselines.\nWe seek to push the limits of a simple-but-effective pipeline for more\nrealistic and practical settings of few-shot image classification. To this end,\nwe explore few-shot learning from the perspective of neural network\narchitecture, as well as a three stage pipeline of network updates under\ndifferent data supplies, where unsupervised external data is considered for\npre-training, base categories are used to simulate few-shot tasks for\nmeta-training, and the scarcely labelled data of an novel task is taken for\nfine-tuning. We investigate questions such as: (1) How pre-training on external\ndata benefits FSL? (2) How state-of-the-art transformer architectures can be\nexploited? and (3) How fine-tuning mitigates domain shift? Ultimately, we show\nthat a simple transformer-based pipeline yields surprisingly good performance\non standard benchmarks such as Mini-ImageNet, CIFAR-FS, CDFSL and Meta-Dataset.\nOur code and demo are available at https://hushell.github.io/pmf.",
          "link": "http://arxiv.org/abs/2204.07305",
          "publishedOn": "2022-04-18T00:59:13.446Z",
          "wordCount": 635,
          "title": "Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference. (arXiv:2204.07305v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potosnak_W/0/1/0/all/0/1\">Willa Potosnak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "Applications of machine learning in healthcare often require working with\ntime-to-event prediction tasks including prognostication of an adverse event,\nre-hospitalization or death. Such outcomes are typically subject to censoring\ndue to loss of follow up. Standard machine learning methods cannot be applied\nin a straightforward manner to datasets with censored outcomes. In this paper,\nwe present auton-survival, an open-source repository of tools to streamline\nworking with censored time-to-event or survival data. auton-survival includes\ntools for survival regression, adjustment in the presence of domain shift,\ncounterfactual estimation, phenotyping for risk stratification, evaluation, as\nwell as estimation of treatment effects. Through real world case studies\nemploying a large subset of the SEER oncology incidence data, we demonstrate\nthe ability of auton-survival to rapidly support data scientists in answering\ncomplex health and epidemiological questions.",
          "link": "http://arxiv.org/abs/2204.07276",
          "publishedOn": "2022-04-18T00:59:13.421Z",
          "wordCount": 585,
          "title": "auton-survival: an Open-Source Package for Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data. (arXiv:2204.07276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_A/0/1/0/all/0/1\">Alan D. Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greene_J/0/1/0/all/0/1\">John D. Greene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_V/0/1/0/all/0/1\">Vincent X. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_P/0/1/0/all/0/1\">Priyadip Ray</a>",
          "description": "We develop an unsupervised probabilistic model for heterogeneous Electronic\nHealth Record (EHR) data. Utilizing a mixture model formulation, our approach\ndirectly models sequences of arbitrary length, such as medications and\nlaboratory results. This allows for subgrouping and incorporation of the\ndynamics underlying heterogeneous data types. The model consists of a layered\nset of latent variables that encode underlying structure in the data. These\nvariables represent subject subgroups at the top layer, and unobserved states\nfor sequences in the second layer. We train this model on episodic data from\nsubjects receiving medical care in the Kaiser Permanente Northern California\nintegrated healthcare delivery system. The resulting properties of the trained\nmodel generate novel insight from these complex and multifaceted data. In\naddition, we show how the model can be used to analyze sequences that\ncontribute to assessment of mortality likelihood.",
          "link": "http://arxiv.org/abs/2204.07292",
          "publishedOn": "2022-04-18T00:59:08.559Z",
          "wordCount": 579,
          "title": "Unsupervised Probabilistic Models for Sequential Electronic Health Records. (arXiv:2204.07292v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melnychuk_V/0/1/0/all/0/1\">Valentyn Melnychuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frauen_D/0/1/0/all/0/1\">Dennis Frauen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Estimating counterfactual outcomes over time from observational data is\nrelevant for many applications (e.g., personalized medicine). Yet,\nstate-of-the-art methods build upon simple long short-term memory (LSTM)\nnetworks, thus rendering inferences for complex, long-range dependencies\nchallenging. In this paper, we develop a novel Causal Transformer for\nestimating counterfactual outcomes over time. Our model is specifically\ndesigned to capture complex, long-range dependencies among time-varying\nconfounders. For this, we combine three transformer subnetworks with separate\ninputs for time-varying covariates, previous treatments, and previous outcomes\ninto a joint network with in-between cross-attentions. We further develop a\ncustom, end-to-end training procedure for our Causal Transformer. Specifically,\nwe propose a novel counterfactual domain confusion loss to address confounding\nbias: it aims to learn adversarial balanced representations, so that they are\npredictive of the next outcome but non-predictive of the current treatment\nassignment. We evaluate our Causal Transformer based on synthetic and\nreal-world datasets, where it achieves superior performance over current\nbaselines. To the best of our knowledge, this is the first work proposing\ntransformer-based architecture for estimating counterfactual outcomes from\nlongitudinal data.",
          "link": "http://arxiv.org/abs/2204.07258",
          "publishedOn": "2022-04-18T00:59:08.543Z",
          "wordCount": 608,
          "title": "Causal Transformer for Estimating Counterfactual Outcomes. (arXiv:2204.07258v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ang_P/0/1/0/all/0/1\">Phyllis Ang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wills_L/0/1/0/all/0/1\">Lisa Wu Wills</a>",
          "description": "With many real-world applications of Natural Language Processing (NLP)\ncomprising of long texts, there has been a rise in NLP benchmarks that measure\nthe accuracy of models that can handle longer input sequences. However, these\nbenchmarks do not consider the trade-offs between accuracy, speed, and power\nconsumption as input sizes or model sizes are varied. In this work, we perform\na systematic study of this accuracy vs. efficiency trade-off on two widely used\nlong-sequence models - Longformer-Encoder-Decoder (LED) and Big Bird - during\nfine-tuning and inference on four datasets from the SCROLLS benchmark. To study\nhow this trade-off differs across hyperparameter settings, we compare the\nmodels across four sequence lengths (1024, 2048, 3072, 4096) and two model\nsizes (base and large) under a fixed resource budget. We find that LED\nconsistently achieves better accuracy at lower energy costs than Big Bird. For\nsummarization, we find that increasing model size is more energy efficient than\nincreasing sequence length for higher accuracy. However, this comes at the cost\nof a large drop in inference speed. For question answering, we find that\nsmaller models are both more efficient and more accurate due to the larger\ntraining batch sizes possible under a fixed resource budget.",
          "link": "http://arxiv.org/abs/2204.07288",
          "publishedOn": "2022-04-18T00:59:08.524Z",
          "wordCount": 655,
          "title": "Characterizing the Efficiency vs. Accuracy Trade-off for Long-Context NLP Models. (arXiv:2204.07288v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bemporad_A/0/1/0/all/0/1\">Alberto Bemporad</a>",
          "description": "This paper proposes an active learning algorithm for solving regression and\nclassification problems based on inverse-distance weighting functions for\nselecting the feature vectors to query. The algorithm has the following\nfeatures: (i) supports both pool-based and population-based sampling; (ii) is\nindependent of the type of predictor used; (iii) can handle known and unknown\nconstraints on the queryable feature vectors; and (iv) can run either\nsequentially, or in batch mode, depending on how often the predictor is\nretrained. The method's potential is shown in numerical tests on illustrative\nsynthetic problems and real-world regression and classification datasets from\nthe UCI repository. A Python implementation of the algorithm that we call IDEAL\n(Inverse-Distance based Exploration for Active Learning), is available at\n\\url{this http URL}.",
          "link": "http://arxiv.org/abs/2204.07177",
          "publishedOn": "2022-04-18T00:59:08.513Z",
          "wordCount": 560,
          "title": "Active Learning for Regression and Classification by Inverse Distance Weighting. (arXiv:2204.07177v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07207",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wundervald_B/0/1/0/all/0/1\">Bruna Wundervald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Parnell_A/0/1/0/all/0/1\">Andrew Parnell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Domijan_K/0/1/0/all/0/1\">Katarina Domijan</a>",
          "description": "We propose a simple yet powerful extension of Bayesian Additive Regression\nTrees which we name Hierarchical Embedded BART (HE-BART). The model allows for\nrandom effects to be included at the terminal node level of a set of regression\ntrees, making HE-BART a non-parametric alternative to mixed effects models\nwhich avoids the need for the user to specify the structure of the random\neffects in the model, whilst maintaining the prediction and uncertainty\ncalibration properties of standard BART. Using simulated and real-world\nexamples, we demonstrate that this new extension yields superior predictions\nfor many of the standard mixed effects models' example data sets, and yet still\nprovides consistent estimates of the random effect variances. In a future\nversion of this paper, we outline its use in larger, more advanced data sets\nand structures.",
          "link": "http://arxiv.org/abs/2204.07207",
          "publishedOn": "2022-04-18T00:59:08.505Z",
          "wordCount": 560,
          "title": "Hierarchical Embedded Bayesian Additive Regression Trees. (arXiv:2204.07207v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07162",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Delvigne_V/0/1/0/all/0/1\">Victor Delvigne</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wannous_H/0/1/0/all/0/1\">Hazem Wannous</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Vandeborre_J/0/1/0/all/0/1\">Jean-Philippe Vandeborre</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ris_L/0/1/0/all/0/1\">Laurence Ris</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dutoit_T/0/1/0/all/0/1\">Thierry Dutoit</a>",
          "description": "For many years now, understanding the brain mechanism has been a great\nresearch subject in many different fields. Brain signal processing and\nespecially electroencephalogram (EEG) has recently known a growing interest\nboth in academia and industry. One of the main examples is the increasing\nnumber of Brain-Computer Interfaces (BCI) aiming to link brains and computers.\nIn this paper, we present a novel framework allowing us to retrieve the\nattention state, i.e degree of attention given to a specific task, from EEG\nsignals. While previous methods often consider the spatial relationship in EEG\nthrough electrodes and process them in recurrent or convolutional based\narchitecture, we propose here to also exploit the spatial and temporal\ninformation with a transformer-based network that has already shown its\nsupremacy in many machine-learning (ML) related studies, e.g. machine\ntranslation. In addition to this novel architecture, an extensive study on the\nfeature extraction methods, frequential bands and temporal windows length has\nalso been carried out. The proposed network has been trained and validated on\ntwo public datasets and achieves higher results compared to state-of-the-art\nmodels. As well as proposing better results, the framework could be used in\nreal applications, e.g. Attention Deficit Hyperactivity Disorder (ADHD)\nsymptoms or vigilance during a driving assessment.",
          "link": "http://arxiv.org/abs/2204.07162",
          "publishedOn": "2022-04-18T00:59:08.481Z",
          "wordCount": 662,
          "title": "Spatio-Temporal Analysis of Transformer based Architecture for Attention Estimation from EEG. (arXiv:2204.07162v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rubinfeld_R/0/1/0/all/0/1\">Ronitt Rubinfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilyan_A/0/1/0/all/0/1\">Arsen Vasilyan</a>",
          "description": "There are many important high dimensional function classes that have fast\nagnostic learning algorithms when strong assumptions on the distribution of\nexamples can be made, such as Gaussianity or uniformity over the domain. But\nhow can one be sufficiently confident that the data indeed satisfies the\ndistributional assumption, so that one can trust in the output quality of the\nagnostic learning algorithm? We propose a model by which to systematically\nstudy the design of tester-learner pairs $(\\mathcal{A},\\mathcal{T})$, such that\nif the distribution on examples in the data passes the tester $\\mathcal{T}$\nthen one can safely trust the output of the agnostic learner $\\mathcal{A}$ on\nthe data.\n\nTo demonstrate the power of the model, we apply it to the classical problem\nof agnostically learning halfspaces under the standard Gaussian distribution\nand present a tester-learner pair with a combined run-time of\n$n^{\\tilde{O}(1/\\epsilon^4)}$. This qualitatively matches that of the best\nknown ordinary agnostic learning algorithms for this task. In contrast, finite\nsample Gaussian distribution testers do not exist for the $L_1$ and EMD\ndistance measures. A key step in the analysis is a novel characterization of\nconcentration and anti-concentration properties of a distribution whose\nlow-degree moments approximately match those of a Gaussian. We also use tools\nfrom polynomial approximation theory.\n\nIn contrast, we show strong lower bounds on the combined run-times of\ntester-learner pairs for the problems of agnostically learning convex sets\nunder the Gaussian distribution and for monotone Boolean functions under the\nuniform distribution over $\\{0,1\\}^n$. Through these lower bounds we exhibit\nnatural problems where there is a dramatic gap between standard agnostic\nlearning run-time and the run-time of the best tester-learner pair.",
          "link": "http://arxiv.org/abs/2204.07196",
          "publishedOn": "2022-04-18T00:59:08.447Z",
          "wordCount": 706,
          "title": "Testing distributional assumptions of learning algorithms. (arXiv:2204.07196v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1\">Paras Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruocheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candan_K/0/1/0/all/0/1\">K. Sel&#xe7;uk Candan</a>",
          "description": "Recommender systems aim to recommend new items to users by learning user and\nitem representations. In practice, these representations are highly entangled\nas they consist of information about multiple factors, including user's\ninterests, item attributes along with confounding factors such as user\nconformity, and item popularity. Considering these entangled representations\nfor inferring user preference may lead to biased recommendations (e.g., when\nthe recommender model recommends popular items even if they do not align with\nthe user's interests).\n\nRecent research proposes to debias by modeling a recommender system from a\ncausal perspective. The exposure and the ratings are analogous to the treatment\nand the outcome in the causal inference framework, respectively. The critical\nchallenge in this setting is accounting for the hidden confounders. These\nconfounders are unobserved, making it hard to measure them. On the other hand,\nsince these confounders affect both the exposure and the ratings, it is\nessential to account for them in generating debiased recommendations. To better\napproximate hidden confounders, we propose to leverage network information\n(i.e., user-social and user-item networks), which are shown to influence how\nusers discover and interact with an item. Aside from the user conformity,\naspects of confounding such as item popularity present in the network\ninformation is also captured in our method with the aid of \\textit{causal\ndisentanglement} which unravels the learned representations into independent\nfactors that are responsible for (a) modeling the exposure of an item to the\nuser, (b) predicting the ratings, and (c) controlling the hidden confounders.\nExperiments on real-world datasets validate the effectiveness of the proposed\nmodel for debiasing recommender systems.",
          "link": "http://arxiv.org/abs/2204.07221",
          "publishedOn": "2022-04-18T00:59:08.439Z",
          "wordCount": 706,
          "title": "Causal Disentanglement with Network Information for Debiased Recommendations. (arXiv:2204.07221v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bird_J/0/1/0/all/0/1\">Jordan J. Bird</a>",
          "description": "This study explores how robots and generative approaches can be used to mount\nsuccessful false-acceptance adversarial attacks on signature verification\nsystems. Initially, a convolutional neural network topology and data\naugmentation strategy are explored and tuned, producing an 87.12% accurate\nmodel for the verification of 2,640 human signatures. Two robots are then\ntasked with forging 50 signatures, where 25 are used for the verification\nattack, and the remaining 25 are used for tuning of the model to defend against\nthem. Adversarial attacks on the system show that there exists an information\nsecurity risk; the Line-us robotic arm can fool the system 24% of the time and\nthe iDraw 2.0 robot 32% of the time. A conditional GAN finds similar success,\nwith around 30% forged signatures misclassified as genuine. Following fine-tune\ntransfer learning of robotic and generative data, adversarial attacks are\nreduced below the model threshold by both robots and the GAN. It is observed\nthat tuning the model reduces the risk of attack by robots to 8% and 12%, and\nthat conditional generative adversarial attacks can be reduced to 4% when 25\nimages are presented and 5% when 1000 images are presented.",
          "link": "http://arxiv.org/abs/2204.07246",
          "publishedOn": "2022-04-18T00:59:08.419Z",
          "wordCount": 632,
          "title": "Robotic and Generative Adversarial Attacks in Offline Writer-independent Signature Verification. (arXiv:2204.07246v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07291",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Nakazato_K/0/1/0/all/0/1\">Kenichi Nakazato</a>",
          "description": "Deep neural network is the widely applied technology in this decade. In spite\nof the fruitful applications, the mechanism behind that is still to be\nelucidated. We study the learning process with a very simple supervised\nlearning encoding problem. As a result, we found a simple law, in the training\nresponse, which describes neural tangent kernel. The response consists of a\npower law like decay multiplied by a simple response kernel. We can construct a\nsimple mean-field dynamical model with the law, which explains how the network\nlearns. In the learning, the input space is split into sub-spaces along\ncompetition between the kernels. With the iterated splits and the aging, the\nnetwork gets more complexity, but finally loses its plasticity.",
          "link": "http://arxiv.org/abs/2204.07291",
          "publishedOn": "2022-04-18T00:59:08.412Z",
          "wordCount": 563,
          "title": "The training response law explains how deep neural networks learn. (arXiv:2204.07291v1 [cond-mat.dis-nn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cont_R/0/1/0/all/0/1\">Rama Cont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossier_A/0/1/0/all/0/1\">Alain Rossier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">RenYuan Xu</a>",
          "description": "We prove linear convergence of gradient descent to a global minimum for the\ntraining of deep residual networks with constant layer width and smooth\nactivation function. We further show that the trained weights, as a function of\nthe layer index, admits a scaling limit which is H\\\"older continuous as the\ndepth of the network tends to infinity. The proofs are based on non-asymptotic\nestimates of the loss function and of norms of the network weights along the\ngradient descent path. We illustrate the relevance of our theoretical results\nto practical settings using detailed numerical experiments on supervised\nlearning problems.",
          "link": "http://arxiv.org/abs/2204.07261",
          "publishedOn": "2022-04-18T00:59:08.404Z",
          "wordCount": 549,
          "title": "Convergence and Implicit Regularization Properties of Gradient Descent for Deep Residual Networks. (arXiv:2204.07261v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07230",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Oommen_V/0/1/0/all/0/1\">Vivek Oommen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Shukla_K/0/1/0/all/0/1\">Khemraj Shukla</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Goswami_S/0/1/0/all/0/1\">Somdatta Goswami</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Dingreville_R/0/1/0/all/0/1\">Remi Dingreville</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Phase-field modeling is an effective mesoscale method for capturing the\nevolution dynamics of materials, e.g., in spinodal decomposition of a two-phase\nmixture. However, the accuracy of high-fidelity phase field models comes at a\nsubstantial computational cost. Hence, fast and generalizable surrogate models\nare needed to alleviate the cost in computationally taxing processes such as in\noptimization and design of materials. The intrinsic discontinuous nature of the\nphysical phenomena incurred by the presence of sharp phase boundaries makes the\ntraining of the surrogate model cumbersome. We develop a new framework that\nintegrates a convolutional autoencoder architecture with a deep neural operator\n(DeepONet) to learn the dynamic evolution of a two-phase mixture. We utilize\nthe convolutional autoencoder to provide a compact representation of the\nmicrostructure data in a low-dimensional latent space. DeepONet, which consists\nof two sub-networks, one for encoding the input function at a fixed number of\nsensors locations (branch net) and another for encoding the locations for the\noutput functions (trunk net), learns the mesoscale dynamics of the\nmicrostructure evolution in the latent space. The decoder part of the\nconvolutional autoencoder can then reconstruct the time-evolved microstructure\nfrom the DeepONet predictions. The result is an efficient and accurate\naccelerated phase-field framework that outperforms other neural-network-based\napproaches while at the same time being robust to noisy inputs.",
          "link": "http://arxiv.org/abs/2204.07230",
          "publishedOn": "2022-04-18T00:59:08.397Z",
          "wordCount": 665,
          "title": "Learning two-phase microstructure evolution using neural operators and autoencoder architectures. (arXiv:2204.07230v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meulemans_A/0/1/0/all/0/1\">Alexander Meulemans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farinha_M/0/1/0/all/0/1\">Matilde Tristany Farinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cervera_M/0/1/0/all/0/1\">Maria R. Cervera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sacramento_J/0/1/0/all/0/1\">Jo&#xe3;o Sacramento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1\">Benjamin F. Grewe</a>",
          "description": "The success of deep learning attracted interest in whether the brain learns\nhierarchical representations using gradient-based learning. However, current\nbiologically plausible methods for gradient-based credit assignment in deep\nneural networks need infinitesimally small feedback signals, which is\nproblematic in biologically realistic noisy environments and at odds with\nexperimental evidence in neuroscience showing that top-down feedback can\nsignificantly influence neural activity. Building upon deep feedback control\n(DFC), a recently proposed credit assignment method, we combine strong feedback\ninfluences on neural activity with gradient-based learning and show that this\nnaturally leads to a novel view on neural network optimization. Instead of\ngradually changing the network weights towards configurations with low output\nloss, weight updates gradually minimize the amount of feedback required from a\ncontroller that drives the network to the supervised output label. Moreover, we\nshow that the use of strong feedback in DFC allows learning forward and\nfeedback connections simultaneously, using a learning rule fully local in space\nand time. We complement our theoretical results with experiments on standard\ncomputer-vision benchmarks, showing competitive performance to backpropagation\nas well as robustness to noise. Overall, our work presents a fundamentally\nnovel view of learning as control minimization, while sidestepping biologically\nunrealistic assumptions.",
          "link": "http://arxiv.org/abs/2204.07249",
          "publishedOn": "2022-04-18T00:59:08.387Z",
          "wordCount": 655,
          "title": "Minimizing Control for Credit Assignment with Strong Feedback. (arXiv:2204.07249v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_R/0/1/0/all/0/1\">Raphael Souza de Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1\">Erick Giovani Sperandio Nascimento</a>",
          "description": "Recent advances in Artificial intelligence (AI) have leveraged promising\nresults in solving complex problems in the area of Natural Language Processing\n(NLP), being an important tool to help in the expeditious resolution of\njudicial proceedings in the legal area. In this context, this work targets the\nproblem of detecting the degree of similarity between judicial documents that\ncan be achieved in the inference group, by applying six NLP techniques based on\ntransformers, namely BERT, GPT-2 and RoBERTa pre-trained in the Brazilian\nPortuguese language and the same specialized using 210,000 legal proceedings.\nDocuments were pre-processed and had their content transformed into a vector\nrepresentation using these NLP techniques. Unsupervised learning was used to\ncluster the lawsuits, calculating the quality of the model based on the cosine\nof the distance between the elements of the group to its centroid. We noticed\nthat models based on transformers present better performance when compared to\nprevious research, highlighting the RoBERTa model specialized in the Brazilian\nPortuguese language, making it possible to advance in the current state of the\nart in the area of NLP applied to the legal sector.",
          "link": "http://arxiv.org/abs/2204.07182",
          "publishedOn": "2022-04-18T00:59:08.353Z",
          "wordCount": 639,
          "title": "Brazilian Court Documents Clustered by Similarity Together Using Natural Language Processing Approaches with Transformers. (arXiv:2204.07182v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ouderaa_T/0/1/0/all/0/1\">Tycho F.A. van der Ouderaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_D/0/1/0/all/0/1\">David W. Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>",
          "description": "Equivariances provide useful inductive biases in neural network modeling,\nwith the translation equivariance of convolutional neural networks being a\ncanonical example. Equivariances can be embedded in architectures through\nweight-sharing and place symmetry constraints on the functions a neural network\ncan represent. The type of symmetry is typically fixed and has to be chosen in\nadvance. Although some tasks are inherently equivariant, many tasks do not\nstrictly follow such symmetries. In such cases, equivariance constraints can be\noverly restrictive. In this work, we propose a parameter-efficient relaxation\nof equivariance that can effectively interpolate between a (i) non-equivariant\nlinear product, (ii) a strict-equivariant convolution, and (iii) a\nstrictly-invariant mapping. The proposed parameterization can be thought of as\na building block to allow adjustable symmetry structure in neural networks.\nCompared to non-equivariant or strict-equivariant baselines, we experimentally\nverify that soft equivariance leads to improved performance in terms of test\naccuracy on CIFAR-10 and CIFAR-100 image classification tasks.",
          "link": "http://arxiv.org/abs/2204.07178",
          "publishedOn": "2022-04-18T00:59:08.337Z",
          "wordCount": 591,
          "title": "Relaxing Equivariance Constraints with Non-stationary Continuous Filters. (arXiv:2204.07178v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1\">Navjot Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solomonik_E/0/1/0/all/0/1\">Edgar Solomonik</a>",
          "description": "CP decomposition (CPD) is prevalent in chemometrics, signal processing, data\nmining and many more fields. While many algorithms have been proposed to\ncompute the CPD, alternating least squares (ALS) remains one of the most widely\nused algorithm for computing the decomposition. Recent works have introduced\nthe notion of eigenvalues and singular values of a tensor and explored\napplications of eigenvectors and singular vectors in areas like signal\nprocessing, data analytics and in various other fields. We introduce a new\nformulation for deriving singular values and vectors of a tensor by considering\nthe critical points of a function different from what is used in the previous\nwork. Computing these critical points in an alternating manner motivates an\nalternating optimization algorithm which corresponds to alternating least\nsquares algorithm in the matrix case. However, for tensors with order greater\nthan equal to $3$, it minimizes an objective function which is different from\nthe commonly used least squares loss. Alternating optimization of this new\nobjective leads to simple updates to the factor matrices with the same\nasymptotic computational cost as ALS. We show that a subsweep of this algorithm\ncan achieve a superlinear convergence rate for exact CPD with known rank and\nverify it experimentally. We then view the algorithm as optimizing a\nMahalanobis distance with respect to each factor with ground metric dependent\non the other factors. This perspective allows us to generalize our approach to\ninterpolate between updates corresponding to the ALS and the new algorithm to\nmanage the tradeoff between stability and fitness of the decomposition. Our\nexperimental results show that for approximating synthetic and real-world\ntensors, this algorithm and its variants converge to a better conditioned\ndecomposition with comparable and sometimes better fitness as compared to the\nALS algorithm.",
          "link": "http://arxiv.org/abs/2204.07208",
          "publishedOn": "2022-04-18T00:59:08.330Z",
          "wordCount": 728,
          "title": "Alternating Mahalanobis Distance Minimization for Stable and Accurate CP Decomposition. (arXiv:2204.07208v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07235",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Filipov_E/0/1/0/all/0/1\">Evgueni T. Filipov</a>",
          "description": "Engineering design of origami systems is challenging because comparing\ndifferent origami patterns requires using categorical features and evaluating\nmulti-physics behavior targets introduces multi-objective problems. This work\nshows that a decision tree machine learning method is particularly suitable for\nthe inverse design of origami. This interpretable machine learning method can\nreveal complex interactions between categorical features and continuous\nfeatures for comparing different origami patterns, can tackle multi-objective\nproblems for designing active origami with multi-physics performance targets,\nand can extend existing origami shape fitting algorithms to further consider\nnon-geometrical performances of origami systems. The proposed framework shows a\nholistic way of designing active origami systems for various applications such\nas metamaterials, deployable structures, soft robots, biomedical devices, and\nmany more.",
          "link": "http://arxiv.org/abs/2204.07235",
          "publishedOn": "2022-04-18T00:59:08.295Z",
          "wordCount": 564,
          "title": "Harnessing Interpretable Machine Learning for Origami Feature Design and Pattern Selection. (arXiv:2204.07235v1 [cond-mat.soft])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07234",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Nguyen_P/0/1/0/all/0/1\">Phong C.H. Nguyen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Choi_J/0/1/0/all/0/1\">Joseph B. Choi</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Nguyen_Y/0/1/0/all/0/1\">Yen-Thi Nguyen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Seshadri_P/0/1/0/all/0/1\">Pradeep K. Seshadri</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Udaykumar_H/0/1/0/all/0/1\">H.S. Udaykumar</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Baek_S/0/1/0/all/0/1\">Stephen Baek</a>",
          "description": "The thermomechanical properties of energetic materials (EM) are known to be a\nfunction of their microscopic structures, i.e., morphological configurations of\ncrystals and pores. This microstructural dependency has motivated vigorous\nresearch in the EM community, seeking to engineer material microstructures with\ntargeted properties and performance under the materials-by-design paradigm.\nHowever, establishing the complex structure-property-performance (SPP)\nrelationships of EMs demands extensive experimental and simulation efforts, and\nassimilating and encapsulating these relationships in usable models is a\nchallenge. Here, we present a novel deep learning method, Physics-Aware\nRecurrent Convolutional (PARC) Neural Network, that can \"learn\" the mesoscale\nthermo-mechanics of EM microstructures during the shock-to-detonation\ntransition (SDT). We show that this new approach can produce accurate\nhigh-fidelity predictions of time-evolving temperature and pressure fields of\nthe same quality as the state-of-the-art direct numerical simulations (DNS),\ndespite the dramatic reduction of computing time, from hours and days on a\nhigh-performance computing cluster (HPC) to a little more than a second on a\ncommodity laptop. We also demonstrate that PARC can provide physical insights,\ni.e., the artificial neurons can illuminate the underlying physics by\nidentifying which microstructural features led to critical hotspots and what\nare the characteristics of \"critical\" versus \"non-critical\" microstructures.\nThis new knowledge generated alongside the capacity to conduct high-throughput\nexperiments will broaden our theoretical understanding of the initiation\nmechanisms of EM detonation, as a step towards engineering EMs with specific\nproperties.",
          "link": "http://arxiv.org/abs/2204.07234",
          "publishedOn": "2022-04-18T00:59:08.286Z",
          "wordCount": 684,
          "title": "Physics-Aware Recurrent Convolutional (PARC) Neural Networks to Assimilate Meso-scale Reactive Mechanics of Energetic Materials. (arXiv:2204.07234v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07172",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1\">Gabriel Loaiza-Ganem</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ross_B/0/1/0/all/0/1\">Brendan Leigh Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caterini_A/0/1/0/all/0/1\">Anthony L. Caterini</a>",
          "description": "Likelihood-based, or explicit, deep generative models use neural networks to\nconstruct flexible high-dimensional densities. This formulation directly\ncontradicts the manifold hypothesis, which states that observed data lies on a\nlow-dimensional manifold embedded in high-dimensional ambient space. In this\npaper we investigate the pathologies of maximum-likelihood training in the\npresence of this dimensionality mismatch. We formally prove that degenerate\noptima are achieved wherein the manifold itself is learned but not the\ndistribution on it, a phenomenon we call manifold overfitting. We propose a\nclass of two-step procedures consisting of a dimensionality reduction step\nfollowed by maximum-likelihood density estimation, and prove that they recover\nthe data-generating distribution in the nonparametric regime, thus avoiding\nmanifold overfitting. We also show that these procedures enable density\nestimation on the manifolds learned by implicit models, such as generative\nadversarial networks, hence addressing a major shortcoming of these models.\nSeveral recently proposed methods are instances of our two-step procedures; we\nthus unify, extend, and theoretically justify a large class of models.",
          "link": "http://arxiv.org/abs/2204.07172",
          "publishedOn": "2022-04-18T00:59:08.277Z",
          "wordCount": 613,
          "title": "Diagnosing and Fixing Manifold Overfitting in Deep Generative Models. (arXiv:2204.07172v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelli_K/0/1/0/all/0/1\">Khouloud Abdelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Joo Yeon Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azendorf_F/0/1/0/all/0/1\">Florian Azendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesser_H/0/1/0/all/0/1\">Helmut Griesser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tropschug_C/0/1/0/all/0/1\">Carsten Tropschug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pachnicke_S/0/1/0/all/0/1\">Stephan Pachnicke</a>",
          "description": "Secure and reliable data communication in optical networks is critical for\nhigh-speed Internet. However, optical fibers, serving as the data transmission\nmedium providing connectivity to billons of users worldwide, are prone to a\nvariety of anomalies resulting from hard failures (e.g., fiber cuts) and\nmalicious physical attacks (e.g., optical eavesdropping (fiber tapping)) etc.\nSuch anomalies may cause network disruption and thereby inducing huge financial\nand data losses, or compromise the confidentiality of optical networks by\ngaining unauthorized access to the carried data, or gradually degrade the\nnetwork operations. Therefore, it is highly required to implement efficient\nanomaly detection, diagnosis, and localization schemes for enhancing the\navailability and reliability of optical networks. In this paper, we propose a\ndata driven approach to accurately and quickly detect, diagnose, and localize\nfiber anomalies including fiber cuts, and optical eavesdropping attacks. The\nproposed method combines an autoencoder-based anomaly detection and an\nattention-based bidirectional gated recurrent unit algorithm, whereby the\nformer is used for fault detection and the latter is adopted for fault\ndiagnosis and localization once an anomaly is detected by the autoencoder. We\nverify the efficiency of our proposed approach by experiments under various\nanomaly scenarios using real operational data. The experimental results\ndemonstrate that: (i) the autoencoder detects any fiber fault or anomaly with\nan F1 score of 96.86%; and (ii) the attention-based bidirectional gated\nrecurrent unit algorithm identifies the the detected anomalies with an average\naccuracy of 98.2%, and localizes the faults with an average root mean square\nerror of 0.19 m.",
          "link": "http://arxiv.org/abs/2204.07059",
          "publishedOn": "2022-04-16T00:51:47.045Z",
          "wordCount": 731,
          "title": "Machine Learning-based Anomaly Detection in Optical Fiber Monitoring. (arXiv:2204.07059v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goktas_D/0/1/0/all/0/1\">Denizalp Goktas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiayi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenwald_A/0/1/0/all/0/1\">Amy Greenwald</a>",
          "description": "The behavior of no-regret learning algorithms is well understood in\ntwo-player min-max (i.e, zero-sum) games. In this paper, we investigate the\nbehavior of no-regret learning in min-max games with dependent strategy sets,\nwhere the strategy of the first player constrains the behavior of the second.\nSuch games are best understood as sequential, i.e., min-max Stackelberg, games.\nWe consider two settings, one in which only the first player chooses their\nactions using a no-regret algorithm while the second player best responds, and\none in which both players use no-regret algorithms. For the former case, we\nshow that no-regret dynamics converge to a Stackelberg equilibrium. For the\nlatter case, we introduce a new type of regret, which we call Lagrangian\nregret, and show that if both players minimize their Lagrangian regrets, then\nplay converges to a Stackelberg equilibrium. We then observe that online mirror\ndescent (OMD) dynamics in these two settings correspond respectively to a known\nnested (i.e., sequential) gradient descent-ascent (GDA) algorithm and a new\nsimultaneous GDA-like algorithm, thereby establishing convergence of these\nalgorithms to Stackelberg equilibrium. Finally, we analyze the robustness of\nOMD dynamics to perturbations by investigating online min-max Stackelberg\ngames. We prove that OMD dynamics are robust for a large class of online\nmin-max games with independent strategy sets. In the dependent case, we\ndemonstrate the robustness of OMD dynamics experimentally by simulating them in\nonline Fisher markets, a canonical example of a min-max Stackelberg game with\ndependent strategy sets.",
          "link": "http://arxiv.org/abs/2203.14126",
          "publishedOn": "2022-04-16T00:51:46.878Z",
          "wordCount": 721,
          "title": "Robust No-Regret Learning in Min-Max Stackelberg Games. (arXiv:2203.14126v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaze_S/0/1/0/all/0/1\">Sagar Vaze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1\">Andrea Vedaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "The ability to identify whether or not a test sample belongs to one of the\nsemantic classes in a classifier's training set is critical to practical\ndeployment of the model. This task is termed open-set recognition (OSR) and has\nreceived significant attention in recent years. In this paper, we first\ndemonstrate that the ability of a classifier to make the 'none-of-above'\ndecision is highly correlated with its accuracy on the closed-set classes. We\nfind that this relationship holds across loss objectives and architectures, and\nfurther demonstrate the trend both on the standard OSR benchmarks as well as on\na large-scale ImageNet evaluation. Second, we use this correlation to boost the\nperformance of a maximum logit score OSR 'baseline' by improving its closed-set\naccuracy, and with this strong baseline achieve state-of-the-art on a number of\nOSR benchmarks. Similarly, we boost the performance of the existing\nstate-of-the-art method by improving its closed-set accuracy, but the resulting\ndiscrepancy with the strong baseline is marginal. Our third contribution is to\npresent the 'Semantic Shift Benchmark' (SSB), which better respects the task of\ndetecting semantic novelty, in contrast to other forms of distribution shift\nalso considered in related sub-fields, such as out-of-distribution detection.\nOn this new evaluation, we again demonstrate that there is negligible\ndifference between the strong baseline and the existing state-of-the-art.\nProject Page: https://www.robots.ox.ac.uk/~vgg/research/osr/",
          "link": "http://arxiv.org/abs/2110.06207",
          "publishedOn": "2022-04-16T00:51:46.866Z",
          "wordCount": 708,
          "title": "Open-Set Recognition: a Good Closed-Set Classifier is All You Need?. (arXiv:2110.06207v2 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Butler_A/0/1/0/all/0/1\">Andrew Butler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_R/0/1/0/all/0/1\">Roy H. Kwon</a>",
          "description": "Many problems in engineering and statistics involve both predictive\nforecasting and decision-based optimization. Traditionally, predictive models\nare optimized independently from the final decision-based optimization problem.\nIn contrast, a `smart, predict then optimize' (SPO) framework optimizes\nprediction models to explicitly minimize the final downstream decision loss. In\nthis paper we present dboost, a gradient boosting algorithm for training\nprediction model ensembles to minimize decision regret. The dboost framework\nsupports any convex optimization program that can be cast as convex quadratic\ncone program and gradient boosting is performed by implicit differentiation of\na custom fixed-point mapping. To our knowledge, the dboost framework is the\nfirst general purpose implementation of gradient boosting to predict and\noptimize problems. Experimental results comparing with state-of-the-art SPO\nmethods show that dboost can further reduce out-of-sample decision regret.",
          "link": "http://arxiv.org/abs/2204.06895",
          "publishedOn": "2022-04-16T00:51:45.646Z",
          "wordCount": 573,
          "title": "Gradient boosting for convex cone predict and optimize problems. (arXiv:2204.06895v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06806",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maji_D/0/1/0/all/0/1\">Debapriya Maji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagori_S/0/1/0/all/0/1\">Soyeb Nagori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathew_M/0/1/0/all/0/1\">Manu Mathew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poddar_D/0/1/0/all/0/1\">Deepak Poddar</a>",
          "description": "We introduce YOLO-pose, a novel heatmap-free approach for joint detection,\nand 2D multi-person pose estimation in an image based on the popular YOLO\nobject detection framework. Existing heatmap based two-stage approaches are\nsub-optimal as they are not end-to-end trainable and training relies on a\nsurrogate L1 loss that is not equivalent to maximizing the evaluation metric,\ni.e. Object Keypoint Similarity (OKS). Our framework allows us to train the\nmodel end-to-end and optimize the OKS metric itself. The proposed model learns\nto jointly detect bounding boxes for multiple persons and their corresponding\n2D poses in a single forward pass and thus bringing in the best of both\ntop-down and bottom-up approaches. Proposed approach doesn't require the\npostprocessing of bottom-up approaches to group detected keypoints into a\nskeleton as each bounding box has an associated pose, resulting in an inherent\ngrouping of the keypoints. Unlike top-down approaches, multiple forward passes\nare done away with since all persons are localized along with their pose in a\nsingle inference. YOLO-pose achieves new state-of-the-art results on COCO\nvalidation (90.2% AP50) and test-dev set (90.3% AP50), surpassing all existing\nbottom-up approaches in a single forward pass without flip test, multi-scale\ntesting, or any other test time augmentation. All experiments and results\nreported in this paper are without any test time augmentation, unlike\ntraditional approaches that use flip-test and multi-scale testing to boost\nperformance. Our training codes will be made publicly available at\nhttps://github.com/TexasInstruments/edgeai-yolov5 and\nhttps://github.com/TexasInstruments/edgeai-yolox",
          "link": "http://arxiv.org/abs/2204.06806",
          "publishedOn": "2022-04-16T00:51:44.991Z",
          "wordCount": 698,
          "title": "YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss. (arXiv:2204.06806v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianxi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1\">Feng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_A/0/1/0/all/0/1\">Anlong Ming</a>",
          "description": "For the 2D laser-based tasks, e.g., people detection and people tracking, leg\ndetection is usually the first step. Thus, it carries great weight in\ndetermining the performance of people detection and people tracking. However,\nmany leg detectors ignore the inevitable noise and the multiscale\ncharacteristics of the laser scan, which makes them sensitive to the unreliable\nfeatures of point cloud and further degrades the performance of the leg\ndetector. In this paper, we propose a multiscale adaptive-switch Random Forest\n(MARF) to overcome these two challenges. Firstly, the adaptive-switch decision\ntree is designed to use noisesensitive features to conduct weighted\nclassification and noiseinvariant features to conduct binary classification,\nwhich makes our detector perform more robust to noise. Secondly, considering\nthe multiscale property that the sparsity of the 2D point cloud is proportional\nto the length of laser beams, we design a multiscale random forest structure to\ndetect legs at different distances. Moreover, the proposed approach allows us\nto discover a sparser human leg from point clouds than others. Consequently,\nour method shows an improved performance compared to other state-of-the-art leg\ndetectors on the challenging Moving Legs dataset and retains the whole pipeline\nat a speed of 60+ FPS on lowcomputational laptops. Moreover, we further apply\nthe proposed MARF to the people detection and tracking system, achieving a\nconsiderable gain in all metrics.",
          "link": "http://arxiv.org/abs/2204.06833",
          "publishedOn": "2022-04-16T00:51:44.983Z",
          "wordCount": 671,
          "title": "MARF: Multiscale Adaptive-switch Random Forest for Leg Detection with 2D Laser Scanners. (arXiv:2204.06833v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Youwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_C/0/1/0/all/0/1\">Chongjian Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1\">Zhan Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yibing Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengtao Xie</a>",
          "description": "Vision Transformers (ViTs) take all the image patches as tokens and construct\nmulti-head self-attention (MHSA) among them. Complete leverage of these image\ntokens brings redundant computations since not all the tokens are attentive in\nMHSA. Examples include that tokens containing semantically meaningless or\ndistractive image backgrounds do not positively contribute to the ViT\npredictions. In this work, we propose to reorganize image tokens during the\nfeed-forward process of ViT models, which is integrated into ViT during\ntraining. For each forward inference, we identify the attentive image tokens\nbetween MHSA and FFN (i.e., feed-forward network) modules, which is guided by\nthe corresponding class token attention. Then, we reorganize image tokens by\npreserving attentive image tokens and fusing inattentive ones to expedite\nsubsequent MHSA and FFN computations. To this end, our method EViT improves\nViTs from two perspectives. First, under the same amount of input image tokens,\nour method reduces MHSA and FFN computation for efficient inference. For\ninstance, the inference speed of DeiT-S is increased by 50% while its\nrecognition accuracy is decreased by only 0.3% for ImageNet classification.\nSecond, by maintaining the same computational cost, our method empowers ViTs to\ntake more image tokens as input for recognition accuracy improvement, where the\nimage tokens are from higher resolution images. An example is that we improve\nthe recognition accuracy of DeiT-S by 1% for ImageNet classification at the\nsame computational cost of a vanilla DeiT-S. Meanwhile, our method does not\nintroduce more parameters to ViTs. Experiments on the standard benchmarks show\nthe effectiveness of our method. The code is available at\nhttps://github.com/youweiliang/evit",
          "link": "http://arxiv.org/abs/2202.07800",
          "publishedOn": "2022-04-16T00:51:44.888Z",
          "wordCount": 741,
          "title": "Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations. (arXiv:2202.07800v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruohong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yize Chen</a>",
          "description": "We consider the problem of learning the energy disaggregation signals for\nresidential load data. Such task is referred as non-intrusive load monitoring\n(NILM), and in order to find individual devices' power consumption profiles\nbased on aggregated meter measurements, a machine learning model is usually\ntrained based on large amount of training data coming from a number of\nresidential homes. Yet collecting such residential load datasets require both\nhuge efforts and customers' approval on sharing metering data, while load data\ncoming from different regions or electricity users may exhibit heterogeneous\nusage patterns. Both practical concerns make training a single, centralized\nNILM model challenging. In this paper, we propose a decentralized and\ntask-adaptive learning scheme for NILM tasks, where nested meta learning and\nfederated learning steps are designed for learning task-specific models\ncollectively. Simulation results on benchmark dataset validate proposed\nalgorithm's performance on efficiently inferring appliance-level consumption\nfor a variety of homes and appliances.",
          "link": "http://arxiv.org/abs/2204.06767",
          "publishedOn": "2022-04-16T00:51:44.878Z",
          "wordCount": 585,
          "title": "Learning Task-Aware Energy Disaggregation: a Federated Approach. (arXiv:2204.06767v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jenul_A/0/1/0/all/0/1\">Anna Jenul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schrunner_S/0/1/0/all/0/1\">Stefan Schrunner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_B/0/1/0/all/0/1\">Bao Ngoc Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helin_R/0/1/0/all/0/1\">Runar Helin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futsaether_C/0/1/0/all/0/1\">Cecilia Marie Futs&#xe6;ther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liland_K/0/1/0/all/0/1\">Kristian Hovde Liland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomic_O/0/1/0/all/0/1\">Oliver Tomic</a>",
          "description": "In artificial neural networks, understanding the contributions of input\nfeatures on the prediction fosters model explainability and delivers relevant\ninformation about the dataset. While typical setups for feature importance\nranking assess input features individually, in this study, we go one step\nfurther and rank the importance of groups of features, denoted as\nfeature-blocks. A feature-block can contain features of a specific type or\nfeatures derived from a particular source, which are presented to the neural\nnetwork in separate input branches (multiblock ANNs). This work presents three\nmethods pursuing distinct strategies to rank features in multiblock ANNs by\ntheir importance: (1) a composite strategy building on individual feature\nimportance rankings, (2) a knock-in, and (3) a knock-out strategy. While the\ncomposite strategy builds on state-of-the-art feature importance rankings,\nknock-in and knock-out strategies evaluate the block as a whole via a mutual\ninformation criterion. Our experiments consist of a simulation study validating\nall three approaches, followed by a case study on two distinct real-world\ndatasets to compare the strategies. We conclude that each strategy has its\nmerits for specific application scenarios.",
          "link": "http://arxiv.org/abs/2109.10279",
          "publishedOn": "2022-04-16T00:51:44.870Z",
          "wordCount": 650,
          "title": "Ranking Feature-Block Importance in Artificial Multiblock Neural Networks. (arXiv:2109.10279v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yufei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Ting Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stringhini_G/0/1/0/all/0/1\">Gianluca Stringhini</a>",
          "description": "Previous security research efforts orbiting around graphs have been\nexclusively focusing on either (de-)anonymizing the graphs or understanding the\nsecurity and privacy issues of graph neural networks. Little attention has been\npaid to understand the privacy risks of integrating the output from graph\nembedding models (e.g., node embeddings) with complex downstream machine\nlearning pipelines. In this paper, we fill this gap and propose a novel\nmodel-agnostic graph recovery attack that exploits the implicit graph\nstructural information preserved in the embeddings of graph nodes. We show that\nan adversary can recover edges with decent accuracy by only gaining access to\nthe node embedding matrix of the original graph without interactions with the\nnode embedding models. We demonstrate the effectiveness and applicability of\nour graph recovery attack through extensive experiments.",
          "link": "http://arxiv.org/abs/2204.06963",
          "publishedOn": "2022-04-16T00:51:44.862Z",
          "wordCount": 594,
          "title": "Finding MNEMON: Reviving Memories of Node Embeddings. (arXiv:2204.06963v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekhar_A/0/1/0/all/0/1\">Aaditya Chandrasekhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhara_S/0/1/0/all/0/1\">Saketh Sridhara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_K/0/1/0/all/0/1\">Krishnan Suresh</a>",
          "description": "Multiscale topology optimization (M-TO) entails generating an optimal global\ntopology, and an optimal set of microstructures at a smaller scale, for a\nphysics-constrained problem. With the advent of additive manufacturing, M-TO\nhas gained significant prominence. However, generating optimal microstructures\nat various locations can be computationally very expensive. As an alternate,\ngraded multiscale topology optimization (GM-TO) has been proposed where one or\nmore pre-selected and graded (parameterized) microstructural topologies are\nused to fill the domain optimally. This leads to a significant reduction in\ncomputation while retaining many of the benefits of M-TO.\n\nA successful GM-TO framework must: (1) be capable of efficiently handling\nnumerous pre-selected microstructures, (2) be able to continuously switch\nbetween these microstructures during optimization, (3) ensure that the\npartition of unity is satisfied, and (4) discourage microstructure mixing at\ntermination.\n\nIn this paper, we propose to meet these requirements by exploiting the unique\nclassification capacity of neural networks. Specifically, we propose a graded\nmultiscale topology optimization using neural-network (GM-TOuNN) framework with\nthe following features: (1) the number of design variables is only weakly\ndependent on the number of pre-selected microstructures, (2) it guarantees\npartition of unity while discouraging microstructure mixing, and (3) it\nsupports automatic differentiation, thereby eliminating manual sensitivity\nanalysis. The proposed framework is illustrated through several examples.",
          "link": "http://arxiv.org/abs/2204.06682",
          "publishedOn": "2022-04-16T00:51:44.853Z",
          "wordCount": 658,
          "title": "GM-TOuNN: Graded Multiscale Topology Optimization using Neural Networks. (arXiv:2204.06682v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07004",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thiery_A/0/1/0/all/0/1\">Alexandre H. Thiery</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Braeu_F/0/1/0/all/0/1\">Fabian Braeu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tun_T/0/1/0/all/0/1\">Tin A. Tun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aung_T/0/1/0/all/0/1\">Tin Aung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Girard_M/0/1/0/all/0/1\">Michael J.A. Girard</a>",
          "description": "Purpose: (1) To assess the performance of geometric deep learning (PointNet)\nin diagnosing glaucoma from a single optical coherence tomography (OCT) 3D scan\nof the optic nerve head (ONH); (2) To compare its performance to that obtained\nwith a standard 3D convolutional neural network (CNN), and with a gold-standard\nglaucoma parameter, i.e. retinal nerve fiber layer (RNFL) thickness.\n\nMethods: 3D raster scans of the ONH were acquired with Spectralis OCT for 477\nglaucoma and 2,296 non-glaucoma subjects at the Singapore National Eye Centre.\nAll volumes were automatically segmented using deep learning to identify 7\nmajor neural and connective tissues including the RNFL, the prelamina, and the\nlamina cribrosa (LC). Each ONH was then represented as a 3D point cloud with\n1,000 points chosen randomly from all tissue boundaries. To simplify the\nproblem, all ONH point clouds were aligned with respect to the plane and center\nof Bruch's membrane opening. Geometric deep learning (PointNet) was then used\nto provide a glaucoma diagnosis from a single OCT point cloud. The performance\nof our approach was compared to that obtained with a 3D CNN, and with RNFL\nthickness.\n\nResults: PointNet was able to provide a robust glaucoma diagnosis solely from\nthe ONH represented as a 3D point cloud (AUC=95%). The performance of PointNet\nwas superior to that obtained with a standard 3D CNN (AUC=87%) and with that\nobtained from RNFL thickness alone (AUC=80%).\n\nDiscussion: We provide a proof-of-principle for the application of geometric\ndeep learning in the field of glaucoma. Our technique requires significantly\nless information as input to perform better than a 3D CNN, and with an AUC\nsuperior to that obtained from RNFL thickness alone. Geometric deep learning\nmay have wide applicability in the field of Ophthalmology.",
          "link": "http://arxiv.org/abs/2204.07004",
          "publishedOn": "2022-04-16T00:51:44.827Z",
          "wordCount": 748,
          "title": "Medical Application of Geometric Deep Learning for the Diagnosis of Glaucoma. (arXiv:2204.07004v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06664",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Niss_L/0/1/0/all/0/1\">Laura Niss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yuekai Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "Sampling biases in training data are a major source of algorithmic biases in\nmachine learning systems. Although there are many methods that attempt to\nmitigate such algorithmic biases during training, the most direct and obvious\nway is simply collecting more representative training data. In this paper, we\nconsider the task of assembling a training dataset in which minority groups are\nadequately represented from a given set of data sources. In essence, this is an\nadaptive sampling problem to determine if a given point lies in the convex hull\nof the means from a set of unknown distributions. We present adaptive sampling\nmethods to determine, with high confidence, whether it is possible to assemble\na representative dataset from the given data sources. We also demonstrate the\nefficacy of our policies in simulations in the Bernoulli and a multinomial\nsetting.",
          "link": "http://arxiv.org/abs/2204.06664",
          "publishedOn": "2022-04-16T00:51:44.820Z",
          "wordCount": 575,
          "title": "Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms. (arXiv:2204.06664v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_H/0/1/0/all/0/1\">Hosein Rezaei</a>",
          "description": "Word embedding systems such as Word2Vec and GloVe are well-known in deep\nlearning approaches to NLP. This is largely due to their ability to capture\nsemantic relationships between words. In this work we investigated their\nusefulness in capturing rhythmic similarity of words instead. The results show\nthat vectors these embeddings assign to rhyming words are more similar to each\nother, compared to the other words. It is also revealed that GloVe performs\nrelatively better than Word2Vec in this regard. We also proposed a first of its\nkind metric for quantifying rhythmic similarity of a pair of words.",
          "link": "http://arxiv.org/abs/2204.04833",
          "publishedOn": "2022-04-16T00:51:44.812Z",
          "wordCount": 550,
          "title": "Word Embeddings Are Capable of Capturing Rhythmic Similarity of Words. (arXiv:2204.04833v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07054",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Cui_H/0/1/0/all/0/1\">Hejie Cui</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dai_W/0/1/0/all/0/1\">Wei Dai</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kan_X/0/1/0/all/0/1\">Xuan Kan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gu_A/0/1/0/all/0/1\">Antonio Aodong Chen Gu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lukemire_J/0/1/0/all/0/1\">Joshua Lukemire</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhan_L/0/1/0/all/0/1\">Liang Zhan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Guo_Y/0/1/0/all/0/1\">Ying Guo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>",
          "description": "Mapping the connectome of the human brain using structural or functional\nconnectivity has become one of the most pervasive paradigms for neuroimaging\nanalysis. Recently, Graph Neural Networks (GNNs) motivated from geometric deep\nlearning have attracted broad interest due to their established power for\nmodeling complex networked data. Despite their established performance in other\nfields, there has not yet been a systematic study of how to design effective\nGNNs for brain network analysis. To bridge this gap, we present BrainGB, a\nbenchmark for brain network analysis with GNNs. BrainGB standardizes the\nprocess by 1) summarizing brain network construction pipelines for both\nfunctional and structural neuroimaging modalities and 2) modularizing the\nimplementation of GNN designs. We conduct extensive experiments on datasets\nacross cohorts and modalities and recommend a set of general recipes for\neffective GNN designs on brain networks. To support open and reproducible\nresearch on GNN-based brain network analysis, we also host the BrainGB website\nat https:// brainnet.us/ with models, tutorials, examples, as well as an\nout-of-box Python package. We hope that this work will provide useful empirical\nevidence and offer insights for future research in this novel and promising\ndirection.",
          "link": "http://arxiv.org/abs/2204.07054",
          "publishedOn": "2022-04-16T00:51:44.804Z",
          "wordCount": 667,
          "title": "BrainGB: A Benchmark for Brain Network Analysis with Graph Neural Networks. (arXiv:2204.07054v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makoviychuk_V/0/1/0/all/0/1\">Viktor Makoviychuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_Y/0/1/0/all/0/1\">Yashraj Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1\">Fabio Ramos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1\">Wojciech Matusik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Animesh Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macklin_M/0/1/0/all/0/1\">Miles Macklin</a>",
          "description": "Deep reinforcement learning can generate complex control policies, but\nrequires large amounts of training data to work effectively. Recent work has\nattempted to address this issue by leveraging differentiable simulators.\nHowever, inherent problems such as local minima and exploding/vanishing\nnumerical gradients prevent these methods from being generally applied to\ncontrol tasks with complex contact-rich dynamics, such as humanoid locomotion\nin classical RL benchmarks. In this work we present a high-performance\ndifferentiable simulator and a new policy learning algorithm (SHAC) that can\neffectively leverage simulation gradients, even in the presence of\nnon-smoothness. Our learning algorithm alleviates problems with local minima\nthrough a smooth critic function, avoids vanishing/exploding gradients through\na truncated learning window, and allows many physical environments to be run in\nparallel. We evaluate our method on classical RL control tasks, and show\nsubstantial improvements in sample efficiency and wall-clock time over\nstate-of-the-art RL and differentiable simulation-based algorithms. In\naddition, we demonstrate the scalability of our method by applying it to the\nchallenging high-dimensional problem of muscle-actuated locomotion with a large\naction space, achieving a greater than 17x reduction in training time over the\nbest-performing established RL algorithm.",
          "link": "http://arxiv.org/abs/2204.07137",
          "publishedOn": "2022-04-16T00:51:44.796Z",
          "wordCount": 641,
          "title": "Accelerated Policy Learning with Parallel Differentiable Simulation. (arXiv:2204.07137v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08928",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_K/0/1/0/all/0/1\">Kan Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_X/0/1/0/all/0/1\">Xuanyi Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Unstructured text provides decision-makers with a rich data source in many\ndomains, ranging from product reviews in retailing to nursing notes in\nhealthcare. To leverage this information, words are typically translated into\nword embeddings -- vectors that encode the semantic relationships between words\n-- through unsupervised learning algorithms such as matrix factorization.\nHowever, learning word embeddings from new domains with limited training data\ncan be challenging, because the meaning/usage may be different in the new\ndomain, e.g., the word \"positive\" typically has positive sentiment, but often\nhas negative sentiment in medical notes since it may imply that a patient is\ntested positive for a disease. Intuitively, we expect that only a small number\nof domain-specific words may have new meanings/usages. We propose an intuitive\ntwo-stage estimator that exploits this structure via a group-sparse penalty to\nefficiently transfer learn domain-specific word embeddings by combining\nlarge-scale text corpora (such as Wikipedia) with limited domain-specific text\ndata. We bound the generalization error of our estimator, proving that it can\nachieve the same accuracy (compared to not transfer learning) with\nsubstantially less domain-specific data when only a small number of embeddings\nare altered between domains. Our results provide the first bounds on\ngroup-sparse matrix factorization, which may be of independent interest. We\nempirically evaluate the effectiveness of our approach compared to\nstate-of-the-art fine-tuning heuristics from natural language processing.",
          "link": "http://arxiv.org/abs/2104.08928",
          "publishedOn": "2022-04-16T00:51:44.773Z",
          "wordCount": 685,
          "title": "Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings. (arXiv:2104.08928v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forouhesh_M/0/1/0/all/0/1\">Mohammad Forouhesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansouri_A/0/1/0/all/0/1\">Arash Mansouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fani_H/0/1/0/all/0/1\">Hossein Fani</a>",
          "description": "Within the context of review analytics, aspects are the features of products\nand services at which customers target their opinions and sentiments. Aspect\ndetection helps product owners and service providers to identify shortcomings\nand prioritize customers' needs, and hence, maintain revenues and mitigate\ncustomer churn. Existing methods focus on detecting the surface form of an\naspect by training supervised learning methods that fall short when aspects are\nlatent in reviews. In this paper, we propose an unsupervised method to extract\nlatent occurrences of aspects. Specifically, we assume that a customer\nundergoes a two-stage hypothetical generative process when writing a review:\n(1) deciding on an aspect amongst the set of aspects available for the product\nor service, and (2) writing the opinion words that are more interrelated to the\nchosen aspect from the set of all words available in a language. We employ\nlatent Dirichlet allocation to learn the latent aspects distributions for\ngenerating the reviews. Experimental results on benchmark datasets show that\nour proposed method is able to improve the state of the art when the aspects\nare latent with no surface form in reviews.",
          "link": "http://arxiv.org/abs/2204.06964",
          "publishedOn": "2022-04-16T00:51:44.765Z",
          "wordCount": 638,
          "title": "Latent Aspect Detection from Online Unsolicited Customer Reviews. (arXiv:2204.06964v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassani_A/0/1/0/all/0/1\">Ali Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walton_S/0/1/0/all/0/1\">Steven Walton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Humphrey Shi</a>",
          "description": "We present Neighborhood Attention Transformer (NAT), an efficient, accurate\nand scalable hierarchical transformer that works well on both image\nclassification and downstream vision tasks. It is built upon Neighborhood\nAttention (NA), a simple and flexible attention mechanism that localizes the\nreceptive field for each query to its nearest neighboring pixels. NA is a\nlocalization of self-attention, and approaches it as the receptive field size\nincreases. It is also equivalent in FLOPs and memory usage to Swin\nTransformer's shifted window attention given the same receptive field size,\nwhile being less constrained. Furthermore, NA includes local inductive biases,\nwhich eliminate the need for extra operations such as pixel shifts.\nExperimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1\naccuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on\nMS-COCO and 48.4% mIoU on ADE20k. We will open-source our checkpoints, training\nscript, configurations, and our CUDA kernel at:\nhttps://github.com/SHI-Labs/Neighborhood-Attention-Transformer .",
          "link": "http://arxiv.org/abs/2204.07143",
          "publishedOn": "2022-04-16T00:51:44.742Z",
          "wordCount": 592,
          "title": "Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06643",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yaojie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingjian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pike_L/0/1/0/all/0/1\">Lee Pike</a>",
          "description": "We introduce NSEdit (neural-symbolic edit), a novel Transformer-based code\nrepair method. Given only the source code that contains bugs, NSEdit predicts\nan editing sequence that can fix the bugs. The edit grammar is formulated as a\nregular language, and the Transformer uses it as a neural-symbolic scripting\ninterface to generate editing programs. We modify the Transformer and add a\npointer network to select the edit locations. An ensemble of rerankers are\ntrained to re-rank the editing sequences generated by beam search. We fine-tune\nthe rerankers on the validation set to reduce over-fitting. NSEdit is evaluated\non various code repair datasets and achieved a new state-of-the-art accuracy\n($24.04\\%$) on the Tufano small dataset of the CodeXGLUE benchmark. NSEdit\nperforms robustly when programs vary from packages to packages and when buggy\nprograms are concrete. We conduct detailed analysis on our methods and\ndemonstrate the effectiveness of each component.",
          "link": "http://arxiv.org/abs/2204.06643",
          "publishedOn": "2022-04-16T00:51:44.733Z",
          "wordCount": 600,
          "title": "Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar. (arXiv:2204.06643v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelli_K/0/1/0/all/0/1\">Khouloud Abdelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesser_H/0/1/0/all/0/1\">Helmut Griesser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ehrle_P/0/1/0/all/0/1\">Peter Ehrle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tropschug_C/0/1/0/all/0/1\">Carsten Tropschug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pachnicke_S/0/1/0/all/0/1\">Stephan Pachnicke</a>",
          "description": "To reduce operation-and-maintenance expenses (OPEX) and to ensure optical\nnetwork survivability, optical network operators need to detect and diagnose\nfaults in a timely manner and with high accuracy. With the rapid advancement of\ntelemetry technology and data analysis techniques, data-driven approaches\nleveraging telemetry data to tackle the fault diagnosis problem have been\ngaining popularity due to their quick implementation and deployment. In this\npaper, we propose a novel multi-task learning model based on long short-term\nmemory (LSTM) to detect, locate, and estimate the reflectance of fiber\nreflective faults (events) including the connectors and the mechanical splices\nby extracting insights from monitored data obtained by the optical time domain\nreflectometry (OTDR) principle commonly used for troubleshooting of fiber optic\ncables or links. The experimental results prove that the proposed method: (i)\nachieves a good detection capability and high localization accuracy within\nshort measurement time even for low SNR values; and (ii) outperforms\nconventionally employed techniques.",
          "link": "http://arxiv.org/abs/2204.07058",
          "publishedOn": "2022-04-16T00:51:44.726Z",
          "wordCount": null,
          "title": "Reflective Fiber Faults Detection and Characterization Using Long-Short-Term Memory. (arXiv:2204.07058v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1802.03308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1\">Frieder Stolzenburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litz_S/0/1/0/all/0/1\">Sandra Litz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_O/0/1/0/all/0/1\">Olivia Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Obst_O/0/1/0/all/0/1\">Oliver Obst</a>",
          "description": "Recurrent neural networks are a powerful means to cope with time series. We\nshow how linear, i.e., linearly activated recurrent neural networks (LRNNs) can\napproximate any time-dependent function f(t) given by a number of function\nvalues. The approximation can effectively be learned by simply solving a linear\nequation system; no backpropagation or similar methods are needed. Furthermore,\nthe size of an LRNN can be reduced significantly in one step, after inspecting\nthe eigenvalues of the network transition matrix, by taking only the most\nrelevant components. Therefore, in contrast to others, we do not only learn\nnetwork weights but also the network architecture. LRNNs have interesting\nproperties: They end up in ellipse trajectories in the long run and allow the\nprediction of further values and compact representations of functions. We\ndemonstrate this by several experiments, among them multiple superimposed\noscillators (MSO), robotic soccer, and predicting stock prices. LRNNs\noutperform the previous state-of-the-art for the MSO task with a minimal number\nof units.",
          "link": "http://arxiv.org/abs/1802.03308",
          "publishedOn": "2022-04-16T00:51:44.702Z",
          "wordCount": 677,
          "title": "The Power of Linear Recurrent Neural Networks. (arXiv:1802.03308v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07136",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pozdnyakov_S/0/1/0/all/0/1\">Sergey N. Pozdnyakov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ceriotti_M/0/1/0/all/0/1\">Michele Ceriotti</a>",
          "description": "Graph neural networks (GNN) are very popular methods in machine learning and\nhave been applied very successfully to the prediction of the properties of\nmolecules and materials. First-order GNNs are well known to be incomplete,\ni.e., there exist graphs that are distinct but appear identical when seen\nthrough the lens of the GNN. More complicated schemes have thus been designed\nto increase their resolving power. Applications to molecules (and more\ngenerally, point clouds), however, add a geometric dimension to the problem.\nThe most straightforward and prevalent approach to construct graph\nrepresentation for molecules regards atoms as vertices in a graph and draws a\nbond between each pair of atoms within a chosen cutoff. Bonds can be decorated\nwith the distance between atoms, and the resulting \"distance graph NNs\" (dGNN)\nhave empirically demonstrated excellent resolving power and are widely used in\nchemical ML, with all known indistinguishable graphs being resolved in the\nfully-connected limit. Here we show that even for the restricted case of\nfully-connected graphs induced by 3D atom clouds dGNNs are not complete. We\nconstruct pairs of distinct point clouds that generate graphs that, for any\ncutoff radius, are equivalent based on a first-order Weisfeiler-Lehman test.\nThis class of degenerate structures includes chemically-plausible\nconfigurations, setting an ultimate limit to the expressive power of some of\nthe well-established GNN architectures for atomistic machine learning. Models\nthat explicitly use angular or directional information in the description of\natomic environments can resolve these degeneracies.",
          "link": "http://arxiv.org/abs/2201.07136",
          "publishedOn": "2022-04-16T00:51:44.678Z",
          "wordCount": 706,
          "title": "Incompleteness of graph convolutional neural networks for points clouds in three dimensions. (arXiv:2201.07136v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thibeau_Sutre_E/0/1/0/all/0/1\">Elina Thibeau-Sutre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collin_S/0/1/0/all/0/1\">Sasha Collin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burgos_N/0/1/0/all/0/1\">Ninon Burgos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colliot_O/0/1/0/all/0/1\">Olivier Colliot</a>",
          "description": "Deep learning methods have become very popular for the processing of natural\nimages, and were then successfully adapted to the neuroimaging field. As these\nmethods are non-transparent, interpretability methods are needed to validate\nthem and ensure their reliability. Indeed, it has been shown that deep learning\nmodels may obtain high performance even when using irrelevant features, by\nexploiting biases in the training set. Such undesirable situations can\npotentially be detected by using interpretability methods. Recently, many\nmethods have been proposed to interpret neural networks. However, this domain\nis not mature yet. Machine learning users face two major issues when aiming to\ninterpret their models: which method to choose, and how to assess its\nreliability? Here, we aim at providing answers to these questions by presenting\nthe most common interpretability methods and metrics developed to assess their\nreliability, as well as their applications and benchmarks in the neuroimaging\ncontext. Note that this is not an exhaustive survey: we aimed to focus on the\nstudies which we found to be the most representative and relevant.",
          "link": "http://arxiv.org/abs/2204.07005",
          "publishedOn": "2022-04-16T00:51:44.637Z",
          "wordCount": 637,
          "title": "Interpretability of Machine Learning Methods Applied to Neuroimaging. (arXiv:2204.07005v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05839",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Benny J. Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qiqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_M/0/1/0/all/0/1\">Matthew L. Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frey_N/0/1/0/all/0/1\">Nathan Frey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1\">Joseph McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bestor_D/0/1/0/all/0/1\">David Bestor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yee_C/0/1/0/all/0/1\">Charles Yee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcand_W/0/1/0/all/0/1\">William Arcand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byun_C/0/1/0/all/0/1\">Chansup Byun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edelman_D/0/1/0/all/0/1\">Daniel Edelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubbell_M/0/1/0/all/0/1\">Matthew Hubbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1\">Michael Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kepner_J/0/1/0/all/0/1\">Jeremy Kepner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_A/0/1/0/all/0/1\">Anna Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaleas_A/0/1/0/all/0/1\">Adam Michaleas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaleas_P/0/1/0/all/0/1\">Peter Michaleas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milechin_L/0/1/0/all/0/1\">Lauren Milechin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullen_J/0/1/0/all/0/1\">Julia Mullen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prout_A/0/1/0/all/0/1\">Andrew Prout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuther_A/0/1/0/all/0/1\">Albert Reuther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosa_A/0/1/0/all/0/1\">Antonio Rosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowne_A/0/1/0/all/0/1\">Andrew Bowne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McEvoy_L/0/1/0/all/0/1\">Lindsey McEvoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baolin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_D/0/1/0/all/0/1\">Devesh Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadepally_V/0/1/0/all/0/1\">Vijay Gadepally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samsi_S/0/1/0/all/0/1\">Siddharth Samsi</a>",
          "description": "High-Performance Computing (HPC) centers and cloud providers support an\nincreasingly diverse set of applications on heterogenous hardware. As\nArtificial Intelligence (AI) and Machine Learning (ML) workloads have become an\nincreasingly larger share of the compute workloads, new approaches to optimized\nresource usage, allocation, and deployment of new AI frameworks are needed. By\nidentifying compute workloads and their utilization characteristics, HPC\nsystems may be able to better match available resources with the application\ndemand. By leveraging datacenter instrumentation, it may be possible to develop\nAI-based approaches that can identify workloads and provide feedback to\nresearchers and datacenter operators for improving operational efficiency. To\nenable this research, we released the MIT Supercloud Dataset, which provides\ndetailed monitoring logs from the MIT Supercloud cluster. This dataset includes\nCPU and GPU usage by jobs, memory usage, and file system logs. In this paper,\nwe present a workload classification challenge based on this dataset. We\nintroduce a labelled dataset that can be used to develop new approaches to\nworkload classification and present initial results based on existing\napproaches. The goal of this challenge is to foster algorithmic innovations in\nthe analysis of compute workloads that can achieve higher accuracy than\nexisting methods. Data and code will be made publicly available via the\nDatacenter Challenge website : https://dcc.mit.edu.",
          "link": "http://arxiv.org/abs/2204.05839",
          "publishedOn": "2022-04-16T00:51:44.629Z",
          "wordCount": 715,
          "title": "The MIT Supercloud Workload Classification Challenge. (arXiv:2204.05839v2 [cs.DC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadok_S/0/1/0/all/0/1\">Samir Sadok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leglaive_S/0/1/0/all/0/1\">Simon Leglaive</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girin_L/0/1/0/all/0/1\">Laurent Girin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1\">Xavier Alameda-Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seguier_R/0/1/0/all/0/1\">Renaud S&#xe9;guier</a>",
          "description": "Understanding and controlling latent representations in deep generative\nmodels is a challenging yet important problem for analyzing, transforming and\ngenerating various types of data. In speech processing, inspiring from the\nanatomical mechanisms of phonation, the source-filter model considers that\nspeech signals are produced from a few independent and physically meaningful\ncontinuous latent factors, among which the fundamental frequency $f_0$ and the\nformants are of primary importance. In this work, we show that the\nsource-filter model of speech production naturally arises in the latent space\nof a variational autoencoder (VAE) trained in an unsupervised manner on a\ndataset of natural speech signals. Using only a few seconds of labeled speech\nsignals generated with an artificial speech synthesizer, we experimentally\nillustrate that $f_0$ and the formant frequencies are encoded in orthogonal\nsubspaces of the VAE latent space and we develop a weakly-supervised method to\naccurately and independently control these speech factors of variation within\nthe learned latent subspaces. Without requiring additional information such as\ntext or human-labeled data, this results in a deep generative model of speech\nspectrograms that is conditioned on $f_0$ and the formant frequencies, and\nwhich is applied to the transformation of speech signals.",
          "link": "http://arxiv.org/abs/2204.07075",
          "publishedOn": "2022-04-16T00:51:44.607Z",
          "wordCount": 657,
          "title": "Learning and controlling the source-filter representation of speech with a variational autoencoder. (arXiv:2204.07075v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07000",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bottcher_L/0/1/0/all/0/1\">Luis B&#xf6;ttcher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_H/0/1/0/all/0/1\">Hinrikus Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_B/0/1/0/all/0/1\">Bastian Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutat_P/0/1/0/all/0/1\">Philipp Lutat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trageser_M/0/1/0/all/0/1\">Marc Trageser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pohl_O/0/1/0/all/0/1\">Oliver Pohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulbig_A/0/1/0/all/0/1\">Andreas Ulbig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1\">Martin Grohe</a>",
          "description": "In this paper we propose a graph neural network architecture solving the AC\npower flow problem under realistic constraints. While the energy transition is\nchanging the energy industry to a digitalized and decentralized energy system,\nthe challenges are increasingly shifting to the distribution grid level to\nintegrate new loads and generation technologies. To ensure a save and resilient\noperation of distribution grids, AC power flow calculations are the means of\nchoice to determine grid operating limits or analyze grid asset utilization in\nplanning procedures. In our approach we demonstrate the development of a\nframework which makes use of graph neural networks to learn the physical\nconstraints of the power flow. We present our model architecture on which we\nperform unsupervised training to learn a general solution of the AC power flow\nformulation that is independent of the specific topologies and supply tasks\nused for training. Finally, we demonstrate, validate and discuss our results on\nmedium voltage benchmark grids.",
          "link": "http://arxiv.org/abs/2204.07000",
          "publishedOn": "2022-04-16T00:51:44.597Z",
          "wordCount": 605,
          "title": "Solving AC Power Flow with Graph Neural Networks under Realistic Constraints. (arXiv:2204.07000v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07110",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Sgarbossa_D/0/1/0/all/0/1\">Damiano Sgarbossa</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lupo_U/0/1/0/all/0/1\">Umberto Lupo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bitbol_A/0/1/0/all/0/1\">Anne-Florence Bitbol</a>",
          "description": "Computational models starting from large ensembles of evolutionarily related\nprotein sequences capture a representation of protein families and learn\nconstraints associated to protein structure and function. They thus open the\npossibility for generating novel sequences belonging to protein families.\nProtein language models trained on multiple sequence alignments, such as MSA\nTransformer, are highly attractive candidates to this end. We propose and test\nan iterative method that directly uses the masked language modeling objective\nto generate sequences using MSA Transformer. We demonstrate that the resulting\nsequences generally score better than those generated by Potts models, and even\nthan natural sequences, for homology, coevolution and structure-based measures.\nMoreover, MSA Transformer better reproduces the higher-order statistics and the\ndistribution of sequences in sequence space of natural data than Potts models,\nalthough Potts models better reproduce first- and second-order statistics. MSA\nTransformer is thus a strong candidate for protein sequence generation and\nprotein design.",
          "link": "http://arxiv.org/abs/2204.07110",
          "publishedOn": "2022-04-16T00:51:44.577Z",
          "wordCount": null,
          "title": "Generative power of a protein language model trained on multiple sequence alignments. (arXiv:2204.07110v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramazanli_I/0/1/0/all/0/1\">Ilqar Ramazanli</a>",
          "description": "The matrix completion problem has been studied broadly under many underlying\nconditions. The problem has been explored under adaptive or non-adaptive, exact\nor estimation, single-phase or multi-phase, and many other categories. In most\nof these cases, the observation cost of each entry is uniform and has the same\ncost across the columns. However, in many real-life scenarios, we could expect\nelements from distinct columns or distinct positions to have a different cost.\nIn this paper, we explore this generalization under adaptive conditions. We\napproach the problem under two different cost models. The first one is that\nentries from different columns have different observation costs, but, within\nthe same column, each entry has a uniform cost. The second one is any two entry\nhas different observation cost, despite being the same or different columns. We\nprovide complexity analysis of our algorithms and provide tightness guarantees.",
          "link": "http://arxiv.org/abs/2203.12120",
          "publishedOn": "2022-04-16T00:51:44.576Z",
          "wordCount": null,
          "title": "Matrix Completion with Heterogonous Cost. (arXiv:2203.12120v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haoran Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marmoret_A/0/1/0/all/0/1\">Axel Marmoret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my E. Cohen</a>",
          "description": "Automatic Music Transcription, which consists in transforming an audio\nrecording of a musical performance into symbolic format, remains a difficult\nMusic Information Retrieval task. In this work, which focuses on piano\ntranscription, we propose a semi-supervised approach using low-rank matrix\nfactorization techniques, in particular Convolutive Nonnegative Matrix\nFactorization. In the semi-supervised setting, only a single recording of each\nindividual notes is required. We show on the MAPS dataset that the proposed\nsemi-supervised CNMF method performs better than state-of-the-art low-rank\nfactorization techniques and a little worse than supervised deep learning\nstate-of-the-art methods, while however suffering from generalization issues.",
          "link": "http://arxiv.org/abs/2202.04989",
          "publishedOn": "2022-04-16T00:51:44.570Z",
          "wordCount": null,
          "title": "Semi-Supervised Convolutive NMF for Automatic Piano Transcription. (arXiv:2202.04989v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh-Duong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Min Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1\">Quoc-Viet Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Dinh Thai Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Diep N. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1\">Won-Joo Hwang</a>",
          "description": "Federated learning (FL) is a new artificial intelligence concept that enables\nInternet-of-Things (IoT) devices to learn a collaborative model without sending\nthe raw data to centralized nodes for processing. Despite numerous advantages,\nlow computing resources at IoT devices and high communication costs for\nexchanging model parameters make applications of FL in massive IoT networks\nvery limited. In this work, we develop a novel compression scheme for FL,\ncalled high-compression federated learning (HCFL), for very large scale IoT\nnetworks. HCFL can reduce the data load for FL processes without changing their\nstructure and hyperparameters. In this way, we not only can significantly\nreduce communication costs, but also make intensive learning processes more\nadaptable on low-computing resource IoT devices. Furthermore, we investigate a\nrelationship between the number of IoT devices and the convergence level of the\nFL model and thereby better assess the quality of the FL process. We\ndemonstrate our HCFL scheme in both simulations and mathematical analyses. Our\nproposed theoretical research can be used as a minimum level of satisfaction,\nproving that the FL process can achieve good performance when a determined\nconfiguration is met. Therefore, we show that HCFL is applicable in any\nFL-integrated networks with numerous IoT devices.",
          "link": "http://arxiv.org/abs/2204.06760",
          "publishedOn": "2022-04-16T00:51:44.567Z",
          "wordCount": null,
          "title": "HCFL: A High Compression Approach for Communication-Efficient Federated Learning in Very Large Scale IoT Networks. (arXiv:2204.06760v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07134",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Brini_A/0/1/0/all/0/1\">Alessio Brini</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Tedeschi_G/0/1/0/all/0/1\">Gabriele Tedeschi</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Tantari_D/0/1/0/all/0/1\">Daniele Tantari</a>",
          "description": "In this paper we analyze the effect of a policy recommendation on the\nperformances of an artificial interbank market. Financial institutions\nstipulate lending agreements following a public recommendation and their\nindividual information. The former, modeled by a reinforcement learning optimal\npolicy trying to maximize the long term fitness of the system, gathers\ninformation on the economic environment and directs economic actors to create\ncredit relationships based on the optimal choice between a low interest rate or\nhigh liquidity supply. The latter, based on the agents' balance sheet, allows\nto determine the liquidity supply and interest rate that the banks optimally\noffer on the market. Based on the combination between the public and the\nprivate signal, financial institutions create or cut their credit connections\nover time via a preferential attachment evolving procedure able to generate a\ndynamic network. Our results show that the emergence of a core-periphery\ninterbank network, combined with a certain level of homogeneity on the size of\nlenders and borrowers, are essential features to ensure the resilience of the\nsystem. Moreover, the reinforcement learning optimal policy recommendation\nplays a crucial role in mitigating systemic risk with respect to alternative\npolicy instruments.",
          "link": "http://arxiv.org/abs/2204.07134",
          "publishedOn": "2022-04-16T00:51:44.565Z",
          "wordCount": null,
          "title": "Reinforcement Learning Policy Recommendation for Interbank Network Stability. (arXiv:2204.07134v1 [econ.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.10610",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gao_L/0/1/0/all/0/1\">Long Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arefan_D/0/1/0/all/0/1\">Dooman Arefan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Panigrahy_A/0/1/0/all/0/1\">Ashok Panigrahy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_S/0/1/0/all/0/1\">Shandong Wu</a>",
          "description": "Medical image data are usually imbalanced across different classes. One-class\nclassification has attracted increasing attention to address the data imbalance\nproblem by distinguishing the samples of the minority class from the majority\nclass. Previous methods generally aim to either learn a new feature space to\nmap training samples together or to fit training samples by autoencoder-like\nmodels. These methods mainly focus on capturing either compact or descriptive\nfeatures, where the information of the samples of a given one class is not\nsufficiently utilized. In this paper, we propose a novel deep learning-based\nmethod to learn compact features by adding constraints on the bottleneck\nfeatures, and to preserve descriptive features by training an autoencoder at\nthe same time. Through jointly optimizing the constraining loss and the\nautoencoder's reconstruction loss, our method can learn more relevant features\nassociated with the given class, making the majority and minority samples more\ndistinguishable. Experimental results on three clinical datasets (including the\nMRI breast images, FFDM breast images and chest X-ray images) obtains\nstate-of-art performance compared to previous methods.",
          "link": "http://arxiv.org/abs/2111.10610",
          "publishedOn": "2022-04-16T00:51:44.564Z",
          "wordCount": null,
          "title": "Constrained Deep One-Class Feature Learning For Classifying Imbalanced Medical Images. (arXiv:2111.10610v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clinkinbeard_N/0/1/0/all/0/1\">Nicholus R. Clinkinbeard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_P/0/1/0/all/0/1\">Prof. Nicole N. Hashemi</a>",
          "description": "To improve predictive models for STEM applications, supplemental\nphysics-based features computed from input parameters are introduced into\nsingle and multiple layers of a deep neural network (DNN). While many studies\nfocus on informing DNNs with physics through differential equations or\nnumerical simulation, much may be gained through integration of simplified\nrelationships. To evaluate this hypothesis, a number of thin rectangular plates\nsimply-supported on all edges are simulated for five materials. With plate\ndimensions and material properties as input features and fundamental natural\nfrequency as the sole output, predictive performance of a purely data-driven\nDNN-based model is compared with models using additional inputs computed from\nsimplified physical relationships among baseline parameters, namely plate\nweight, modulus of rigidity, and shear modulus. To better understand the\nbenefit to model accuracy, these additional features are injected into various\nsingle and multiple DNN layers, and trained with four different dataset sizes.\nWhen these physics-enhanced models are evaluated against independent data of\nthe same materials and similar dimensions to the training sets, supplementation\nwith simplified physics-based parameters provides little reduction in\nprediction error over the baseline for models trained with dataset sizes of 60\nand greater, although small improvement from 19.3% to 16.1% occurs when trained\nwith a sparse size of 30. Conversely, notable accuracy gains occur when the\nindependent test data is of material and dimensions not conforming to the\ntraining set. Specifically, when physics-enhanced data is injected into\nmultiple DNN layers, reductions in error from 33.2% to 19.6%, 34.9% to 19.9%,\n35.8% to 22.4%, and 43.0% to 28.4% are achieved for training dataset sizes of\n261, 117, 60, and 30, respectively, demonstrating attainment of a degree of\ngeneralizability.",
          "link": "http://arxiv.org/abs/2204.06764",
          "publishedOn": "2022-04-16T00:51:44.563Z",
          "wordCount": null,
          "title": "Supplementation of deep neural networks with simplified physics-based features to increase model prediction accuracy. (arXiv:2204.06764v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sajnani_R/0/1/0/all/0/1\">Rahul Sajnani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulenard_A/0/1/0/all/0/1\">Adrien Poulenard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_J/0/1/0/all/0/1\">Jivitesh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dua_R/0/1/0/all/0/1\">Radhika Dua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas J. Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_S/0/1/0/all/0/1\">Srinath Sridhar</a>",
          "description": "Progress in 3D object understanding has relied on manually canonicalized\nshape datasets that contain instances with consistent position and orientation\n(3D pose). This has made it hard to generalize these methods to in-the-wild\nshapes, eg., from internet model collections or depth sensors. ConDor is a\nself-supervised method that learns to Canonicalize the 3D orientation and\nposition for full and partial 3D point clouds. We build on top of Tensor Field\nNetworks (TFNs), a class of permutation- and rotation-equivariant, and\ntranslation-invariant 3D networks. During inference, our method takes an unseen\nfull or partial 3D point cloud at an arbitrary pose and outputs an equivariant\ncanonical pose. During training, this network uses self-supervision losses to\nlearn the canonical pose from an un-canonicalized collection of full and\npartial 3D point clouds. ConDor can also learn to consistently co-segment\nobject parts without any supervision. Extensive quantitative results on four\nnew metrics show that our approach outperforms existing methods while enabling\nnew applications such as operation on depth images and annotation transfer.",
          "link": "http://arxiv.org/abs/2201.07788",
          "publishedOn": "2022-04-16T00:51:44.561Z",
          "wordCount": null,
          "title": "ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes. (arXiv:2201.07788v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06935",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zhijun Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaeffer_H/0/1/0/all/0/1\">Hayden Schaeffer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1\">Rachel Ward</a>",
          "description": "The spectra of random feature matrices provide essential information on the\nconditioning of the linear system used in random feature regression problems\nand are thus connected to the consistency and generalization of random feature\nmodels. Random feature matrices are asymmetric rectangular nonlinear matrices\ndepending on two input variables, the data and the weights, which can make\ntheir characterization challenging. We consider two settings for the two input\nvariables, either both are random variables or one is a random variable and the\nother is well-separated, i.e. there is a minimum distance between points. With\nconditions on the dimension, the complexity ratio, and the sampling variance,\nwe show that the singular values of these matrices concentrate near their full\nexpectation and near one with high-probability. In particular, since the\ndimension depends only on the logarithm of the number of random weights or the\nnumber of data points, our complexity bounds can be achieved even in moderate\ndimensions for many practical setting. The theoretical results are verified\nwith numerical experiments.",
          "link": "http://arxiv.org/abs/2204.06935",
          "publishedOn": "2022-04-16T00:51:44.559Z",
          "wordCount": null,
          "title": "Concentration of Random Feature Matrices in High-Dimensions. (arXiv:2204.06935v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Glushkovsky_A/0/1/0/all/0/1\">Alex Glushkovsky</a>",
          "description": "The research paper addresses linear decomposition of time series of\nnon-additive metrics that allows for the identification and interpretation of\ncontributing factors (input features) of variance. Non-additive metrics, such\nas ratios, are widely used in a variety of domains. It commonly requires\npreceding aggregations of underlying variables that are used to calculate the\nmetric of interest. The latest poses a dimensionality challenge when the input\nfeatures and underlying variables are formed as two-dimensional arrays along\nelements, such as account or customer identifications, and time points. It\nrules out direct modeling of the time series of a non-additive metric as a\nfunction of input features. The article discusses a five-step approach: (1)\nsegmentations of input features and the underlying variables of the metric that\nare supported by unsupervised autoencoders, (2) univariate or joint fittings of\nthe metric by the aggregated input features on the segmented domains, (3)\ntransformations of pre-screened input features according to the fitted models,\n(4) aggregation of the transformed features as time series, and (5) modelling\nof the metric time series as a sum of constrained linear effects of the\naggregated features. Alternatively, approximation by numerical differentiation\nhas been considered to linearize the metric. It allows for element level\nunivariate or joint modeling of step (2). The process of these analytical steps\nallows for a backward-looking explanatory decomposition of the metric as a sum\nof time series of the survived input features. The paper includes a synthetic\nexample that studies loss-to-balance monthly rates of a hypothetical retail\ncredit portfolio. To validate that no latent factors other than the survived\ninput features have significant impacts on the metric, Statistical Process\nControl has been introduced for the residual time series.",
          "link": "http://arxiv.org/abs/2204.06688",
          "publishedOn": "2022-04-16T00:51:44.558Z",
          "wordCount": null,
          "title": "Time Series of Non-Additive Metrics: Identification and Interpretation of Contributing Factors of Variance by Linear Decomposition. (arXiv:2204.06688v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01681",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Qasim_S/0/1/0/all/0/1\">Shah Rukh Qasim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chernyavskaya_N/0/1/0/all/0/1\">Nadezda Chernyavskaya</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kieseler_J/0/1/0/all/0/1\">Jan Kieseler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Long_K/0/1/0/all/0/1\">Kenneth Long</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Viazlo_O/0/1/0/all/0/1\">Oleksandr Viazlo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pierini_M/0/1/0/all/0/1\">Maurizio Pierini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nawaz_R/0/1/0/all/0/1\">Raheel Nawaz</a>",
          "description": "We present an end-to-end reconstruction algorithm to build particle\ncandidates from detector hits in next-generation granular calorimeters similar\nto that foreseen for the high-luminosity upgrade of the CMS detector. The\nalgorithm exploits a distance-weighted graph neural network, trained with\nobject condensation, a graph segmentation technique. Through a single-shot\napproach, the reconstruction task is paired with energy regression. We describe\nthe reconstruction performance in terms of efficiency as well as in terms of\nenergy resolution. In addition, we show the jet reconstruction performance of\nour method and discuss its inference computational cost. To our knowledge, this\nwork is the first-ever example of single-shot calorimetric reconstruction of\n${\\cal O}(1000)$ particles in high-luminosity conditions with 200 pileup.",
          "link": "http://arxiv.org/abs/2204.01681",
          "publishedOn": "2022-04-16T00:51:44.558Z",
          "wordCount": null,
          "title": "End-to-end multi-particle reconstruction in high occupancy imaging calorimeters with graph neural networks. (arXiv:2204.01681v2 [physics.ins-det] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Steinbach_P/0/1/0/all/0/1\">Peter Steinbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gernhardt_F/0/1/0/all/0/1\">Felicita Gernhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanveer_M/0/1/0/all/0/1\">Mahnoor Tanveer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmerler_S/0/1/0/all/0/1\">Steve Schmerler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Starke_S/0/1/0/all/0/1\">Sebastian Starke</a>",
          "description": "With the availability of data, hardware, software ecosystem and relevant\nskill sets, the machine learning community is undergoing a rapid development\nwith new architectures and approaches appearing at high frequency every year.\nIn this article, we conduct an exemplary image classification study in order to\ndemonstrate how confidence intervals around accuracy measurements can greatly\nenhance the communication of research results as well as impact the reviewing\nprocess. In addition, we explore the hallmarks and limitations of this\napproximation. We discuss the relevance of this approach reflecting on a\nspotlight publication of ICLR22. A reproducible workflow is made available as\nan open-source adjoint to this publication. Based on our discussion, we make\nsuggestions for improving the authoring and reviewing process of machine\nlearning articles.",
          "link": "http://arxiv.org/abs/2204.05173",
          "publishedOn": "2022-04-16T00:51:44.558Z",
          "wordCount": null,
          "title": "Machine Learning State-of-the-Art with Uncertainties. (arXiv:2204.05173v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.03386",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_B/0/1/0/all/0/1\">Bashir Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehdashtian_S/0/1/0/all/0/1\">Sepehr Dehdashtian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeti_V/0/1/0/all/0/1\">Vishnu Boddeti</a>",
          "description": "Many applications of representation learning, such as privacy-preservation,\nalgorithmic fairness, and domain adaptation, desire explicit control over\nsemantic information being discarded. This goal is formulated as satisfying two\nobjectives: maximizing utility for predicting a target attribute while\nsimultaneously being independent or invariant with respect to a known semantic\nattribute. Solutions to such problems lead to trade-offs between the two\nobjectives when they are competing with each other. While existing works study\nbounds on these trade-offs, three questions still remain outstanding:\n\\emph{What are the exact fundamental trade-offs between utility and\ninvariance?}, 2) \\emph{What is the optimal dimensionality of the\nrepresentation?}, and 3) \\emph{What are the encoders (mapping data to a\nrepresentation) that achieve the exact fundamental trade-offs and how can we\nestimate them from data?} This paper addresses these questions. We adopt a\nfunctional analysis perspective and derive closed-form solutions for the global\noptima of the underlying optimization problems under mild assumptions, which in\nturn yields closed formulae for the exact trade-offs, optimal representation\ndimensionality, and the corresponding encoders. We also numerically quantify\nthe trade-offs on representative problems and compare them to those achieved by\nbaseline invariant representation learning algorithms.",
          "link": "http://arxiv.org/abs/2109.03386",
          "publishedOn": "2022-04-16T00:51:44.557Z",
          "wordCount": null,
          "title": "Characterizing the Fundamental Trade-offs in Learning Invariant Representations. (arXiv:2109.03386v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skorokhodov_I/0/1/0/all/0/1\">Ivan Skorokhodov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1\">Sergey Tulyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhoseiny_M/0/1/0/all/0/1\">Mohamed Elhoseiny</a>",
          "description": "Videos show continuous events, yet most $-$ if not all $-$ video synthesis\nframeworks treat them discretely in time. In this work, we think of videos of\nwhat they should be $-$ time-continuous signals, and extend the paradigm of\nneural representations to build a continuous-time video generator. For this, we\nfirst design continuous motion representations through the lens of positional\nembeddings. Then, we explore the question of training on very sparse videos and\ndemonstrate that a good generator can be learned by using as few as 2 frames\nper clip. After that, we rethink the traditional image + video discriminators\npair and design a holistic discriminator that aggregates temporal information\nby simply concatenating frames' features. This decreases the training cost and\nprovides richer learning signal to the generator, making it possible to train\ndirectly on 1024$^2$ videos for the first time. We build our model on top of\nStyleGAN2 and it is just ${\\approx}5\\%$ more expensive to train at the same\nresolution while achieving almost the same image quality. Moreover, our latent\nspace features similar properties, enabling spatial manipulations that our\nmethod can propagate in time. We can generate arbitrarily long videos at\narbitrary high frame rate, while prior work struggles to generate even 64\nframes at a fixed rate. Our model is tested on four modern 256$^2$ and one\n1024$^2$-resolution video synthesis benchmarks. In terms of sheer metrics, it\nperforms on average ${\\approx}30\\%$ better than the closest runner-up. Project\nwebsite: https://universome.github.io.",
          "link": "http://arxiv.org/abs/2112.14683",
          "publishedOn": "2022-04-16T00:51:44.556Z",
          "wordCount": null,
          "title": "StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.05842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dwivedi_R/0/1/0/all/0/1\">Raaz Dwivedi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "We introduce kernel thinning, a new procedure for compressing a distribution\n$\\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given\na suitable reproducing kernel $\\mathbf{k}$ and $\\mathcal{O}(n^2)$ time, kernel\nthinning compresses an $n$-point approximation to $\\mathbb{P}$ into a\n$\\sqrt{n}$-point approximation with comparable worst-case integration error\nacross the associated reproducing kernel Hilbert space. With high probability,\nthe maximum discrepancy in integration error is\n$\\mathcal{O}_d(n^{-1/2}\\sqrt{\\log n})$ for compactly supported $\\mathbb{P}$ and\n$\\mathcal{O}_d(n^{-\\frac{1}{2}} (\\log n)^{(d+1)/2}\\sqrt{\\log\\log n})$ for\nsub-exponential $\\mathbb{P}$ on $\\mathbb{R}^d$. In contrast, an equal-sized\ni.i.d. sample from $\\mathbb{P}$ suffers $\\Omega(n^{-1/4})$ integration error.\nOur sub-exponential guarantees resemble the classical quasi-Monte Carlo error\nrates for uniform $\\mathbb{P}$ on $[0,1]^d$ but apply to general distributions\non $\\mathbb{R}^d$ and a wide range of common kernels. We use our results to\nderive explicit non-asymptotic maximum mean discrepancy bounds for Gaussian,\nMat\\'ern, and B-spline kernels and present two vignettes illustrating the\npractical benefits of kernel thinning over i.i.d. sampling and standard Markov\nchain Monte Carlo thinning, in dimensions $d=2$ through $100$.",
          "link": "http://arxiv.org/abs/2105.05842",
          "publishedOn": "2022-04-16T00:51:44.554Z",
          "wordCount": null,
          "title": "Kernel Thinning. (arXiv:2105.05842v7 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07034",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Leal_T/0/1/0/all/0/1\">Tiago Leal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopes_F/0/1/0/all/0/1\">Fabio Lopes</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Teixeira_C/0/1/0/all/0/1\">Cesar Teixeira</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dourado_A/0/1/0/all/0/1\">Antonio Dourado</a>",
          "description": "Refractory epileptic patients can suffer a seizure at any moment. Seizure\nprediction would substantially improve their lives. In this work, based on\nscalp EEG and its transformation into images, the likelihood of an epileptic\nseizure occurring at any moment is computed using an average of the softmax\nlayer output (the likelihood) of a CNN, instead of the output of the\nclassification layer. Results show that by analyzing the likelihood and\nthresholding it, prediction has higher sensitivity or a lower FPR/h. The best\nthreshold for the likelihood was higher than 50% for 5 patients, and was lower\nfor the remaining 36. However, more testing is needed, especially in new\nseizures, to better assess the real performance of this method. This work is a\nproof of concept with a positive outlook.",
          "link": "http://arxiv.org/abs/2204.07034",
          "publishedOn": "2022-04-16T00:51:44.543Z",
          "wordCount": null,
          "title": "Epileptic Seizure Risk Assessment by Multi-Channel Imaging of the EEG. (arXiv:2204.07034v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.00514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moschella_L/0/1/0/all/0/1\">Luca Moschella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melzi_S/0/1/0/all/0/1\">Simone Melzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cosmo_L/0/1/0/all/0/1\">Luca Cosmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maggioli_F/0/1/0/all/0/1\">Filippo Maggioli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litany_O/0/1/0/all/0/1\">Or Litany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1\">Maks Ovsjanikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodola_E/0/1/0/all/0/1\">Emanuele Rodol&#xe0;</a>",
          "description": "Spectral geometric methods have brought revolutionary changes to the field of\ngeometry processing. Of particular interest is the study of the Laplacian\nspectrum as a compact, isometry and permutation-invariant representation of a\nshape. Some recent works show how the intrinsic geometry of a full shape can be\nrecovered from its spectrum, but there are approaches that consider the more\nchallenging problem of recovering the geometry from the spectral information of\npartial shapes. In this paper, we propose a possible way to fill this gap. We\nintroduce a learning-based method to estimate the Laplacian spectrum of the\nunion of partial non-rigid 3D shapes, without actually computing the 3D\ngeometry of the union or any correspondence between those partial shapes. We do\nso by operating purely in the spectral domain and by defining the union\noperation between short sequences of eigenvalues. We show that the approximated\nunion spectrum can be used as-is to reconstruct the complete geometry [MRC*19],\nperform region localization on a template [RTO*19] and retrieve shapes from a\ndatabase, generalizing ShapeDNA [RWP06] to work with partialities. Working with\neigenvalues allows us to deal with unknown correspondence, different sampling,\nand different discretizations (point clouds and meshes alike), making this\noperation especially robust and general. Our approach is data-driven and can\ngeneralize to isometric and non-isometric deformations of the surface, as long\nas these stay within the same semantic class (e.g., human bodies or horses), as\nwell as to partiality artifacts not seen at training time.",
          "link": "http://arxiv.org/abs/2104.00514",
          "publishedOn": "2022-04-16T00:51:44.543Z",
          "wordCount": null,
          "title": "Learning Spectral Unions of Partial Deformable 3D Shapes. (arXiv:2104.00514v2 [cs.GR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04517",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_Z/0/1/0/all/0/1\">Zohaib Amjad Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beghdadi_A/0/1/0/all/0/1\">Azeddine Beghdadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kaaniche_M/0/1/0/all/0/1\">Mounir Kaaniche</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheikh_F/0/1/0/all/0/1\">Faouzi Alaya Cheikh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharbi_O/0/1/0/all/0/1\">Osama Gharbi</a>",
          "description": "Video quality assessment is a challenging problem having a critical\nsignificance in the context of medical imaging. For instance, in laparoscopic\nsurgery, the acquired video data suffers from different kinds of distortion\nthat not only hinder surgery performance but also affect the execution of\nsubsequent tasks in surgical navigation and robotic surgeries. For this reason,\nwe propose in this paper neural network-based approaches for distortion\nclassification as well as quality prediction. More precisely, a Residual\nNetwork (ResNet) based approach is firstly developed for simultaneous ranking\nand classification task. Then, this architecture is extended to make it\nappropriate for the quality prediction task by using an additional Fully\nConnected Neural Network (FCNN). To train the overall architecture (ResNet and\nFCNN models), transfer learning and end-to-end learning approaches are\ninvestigated. Experimental results, carried out on a new laparoscopic video\nquality database, have shown the efficiency of the proposed methods compared to\nrecent conventional and deep learning based approaches.",
          "link": "http://arxiv.org/abs/2202.04517",
          "publishedOn": "2022-04-16T00:51:44.542Z",
          "wordCount": null,
          "title": "A Neural Network based Framework for Effective Laparoscopic Video Quality Assessment. (arXiv:2202.04517v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blau_A/0/1/0/all/0/1\">Ari Blau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gebhardt_C/0/1/0/all/0/1\">Christoph Gebhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendesky_A/0/1/0/all/0/1\">Andres Bendesky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paninski_L/0/1/0/all/0/1\">Liam Paninski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Anqi Wu</a>",
          "description": "Multi-animal pose estimation is essential for studying animals' social\nbehaviors in neuroscience and neuroethology. Advanced approaches have been\nproposed to support multi-animal estimation and achieve state-of-the-art\nperformance. However, these models rarely exploit unlabeled data during\ntraining even though real world applications have exponentially more unlabeled\nframes than labeled frames. Manually adding dense annotations for a large\nnumber of images or videos is costly and labor-intensive, especially for\nmultiple instances. Given these deficiencies, we propose a novel\nsemi-supervised architecture for multi-animal pose estimation, leveraging the\nabundant structures pervasive in unlabeled frames in behavior videos to enhance\ntraining, which is critical for sparsely-labeled problems. The resulting\nalgorithm will provide superior multi-animal pose estimation results on three\nanimal experiments compared to the state-of-the-art baseline and exhibits more\npredictive power in sparsely-labeled data regimes.",
          "link": "http://arxiv.org/abs/2204.07072",
          "publishedOn": "2022-04-16T00:51:44.541Z",
          "wordCount": null,
          "title": "SemiMultiPose: A Semi-supervised Multi-animal Pose Estimation Framework. (arXiv:2204.07072v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wysocki_O/0/1/0/all/0/1\">Oskar Wysocki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zili Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ORegan_P/0/1/0/all/0/1\">Paul O&#x27;Regan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_D/0/1/0/all/0/1\">Deborah Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wysocka_M/0/1/0/all/0/1\">Magdalena Wysocka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">D&#xf3;nal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andr&#xe9; Freitas</a>",
          "description": "BioBERT and BioMegatron are Transformers models adapted for the biomedical\ndomain based on publicly available biomedical corpora. As such, they have the\npotential to encode large-scale biological knowledge. We investigate the\nencoding and representation of biological knowledge in these models, and its\npotential utility to support inference in cancer precision medicine - namely,\nthe interpretation of the clinical significance of genomic alterations. We\ncompare the performance of different transformer baselines; we use probing to\ndetermine the consistency of encodings for distinct entities; and we use\nclustering methods to compare and contrast the internal properties of the\nembeddings for genes, variants, drugs and diseases. We show that these models\ndo indeed encode biological knowledge, although some of this is lost in\nfine-tuning for specific tasks. Finally, we analyse how the models behave with\nregard to biases and imbalances in the dataset.",
          "link": "http://arxiv.org/abs/2202.02432",
          "publishedOn": "2022-04-16T00:51:44.530Z",
          "wordCount": null,
          "title": "Transformers and the representation of biomedical background knowledge. (arXiv:2202.02432v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_M/0/1/0/all/0/1\">Madan Ravi Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sekeh_S/0/1/0/all/0/1\">Salimeh Yasaei Sekeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corso_J/0/1/0/all/0/1\">Jason J. Corso</a>",
          "description": "Raw deep neural network (DNN) performance is not enough; in real-world\nsettings, computational load, training efficiency and adversarial security are\njust as or even more important. We propose to simultaneously tackle\nPerformance, Efficiency, and Robustness, using our proposed algorithm Q-TART,\nQuickly Train for Adversarial Robustness and in-Transferability. Q-TART follows\nthe intuition that samples highly susceptible to noise strongly affect the\ndecision boundaries learned by DNNs, which in turn degrades their performance\nand adversarial susceptibility. By identifying and removing such samples, we\ndemonstrate improved performance and adversarial robustness while using only a\nsubset of the training data. Through our experiments we highlight Q-TART's high\nperformance across multiple Dataset-DNN combinations, including ImageNet, and\nprovide insights into the complementary behavior of Q-TART alongside existing\nadversarial training approaches to increase robustness by over 1.3% while using\nup to 17.9% less training time.",
          "link": "http://arxiv.org/abs/2204.07024",
          "publishedOn": "2022-04-16T00:51:44.527Z",
          "wordCount": null,
          "title": "Q-TART: Quickly Training for Adversarial Robustness and in-Transferability. (arXiv:2204.07024v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jikuan Qian</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rui Li</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mingyuan Luo</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zehui Lin</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Hong_W/0/1/0/all/0/1\">Wenhui Hong</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruobing Huang</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Haining Fan</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a> (1,2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jun Cheng</a> (1,2 and 3) ((1) aNational-Regional Key Technology Engineering Laboratory for Medical Ultrasound, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China, (2) Medical Ultrasound Image Computing (MUSIC) Laboratory, Shenzhen University, Shenzhen, China, (3) Marshall Laboratory of Biomedical Engineering, Shenzhen University, Shenzhen, China, (4) Qinghai University Affiliated Hospital, Xining, Qinghai, China)",
          "description": "Different from handcrafted features, deep neural networks can automatically\nlearn task-specific features from data. Due to this data-driven nature, they\nhave achieved remarkable success in various areas. However, manual design and\nselection of suitable network architectures are time-consuming and require\nsubstantial effort of human experts. To address this problem, researchers have\nproposed neural architecture search (NAS) algorithms which can automatically\ngenerate network architectures but suffer from heavy computational cost and\ninstability if searching from scratch. In this paper, we propose a hybrid NAS\nframework for ultrasound (US) image classification and segmentation. The hybrid\nframework consists of a pre-trained backbone and several searched cells (i.e.,\nnetwork building blocks), which takes advantage of the strengths of both NAS\nand the expert knowledge from existing convolutional neural networks.\nSpecifically, two effective and lightweight operations, a mixed depth-wise\nconvolution operator and a squeeze-and-excitation block, are introduced into\nthe candidate operations to enhance the variety and capacity of the searched\ncells. These two operations not only decrease model parameters but also boost\nnetwork performance. Moreover, we propose a re-aggregation strategy for the\nsearched cells, aiming to further improve the performance for different vision\ntasks. We tested our method on two large US image datasets, including a 9-class\nechinococcosis dataset containing 9566 images for classification and an ovary\ndataset containing 3204 images for segmentation. Ablation experiments and\ncomparison with other handcrafted or automatically searched architectures\ndemonstrate that our method can generate more powerful and lightweight models\nfor the above US image classification and segmentation tasks.",
          "link": "http://arxiv.org/abs/2204.06697",
          "publishedOn": "2022-04-16T00:51:44.490Z",
          "wordCount": null,
          "title": "HASA: Hybrid Architecture Search with Aggregation Strategy for Echinococcosis Classification and Ovary Segmentation in Ultrasound Images. (arXiv:2204.06697v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caillon_A/0/1/0/all/0/1\">Antoine Caillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esling_P/0/1/0/all/0/1\">Philippe Esling</a>",
          "description": "Deep learning models are mostly used in an offline inference fashion.\nHowever, this strongly limits the use of these models inside audio generation\nsetups, as most creative workflows are based on real-time digital signal\nprocessing. Although approaches based on recurrent networks can be naturally\nadapted to this buffer-based computation, the use of convolutions still poses\nsome serious challenges. To tackle this issue, the use of causal streaming\nconvolutions have been proposed. However, this requires specific complexified\ntraining and can impact the resulting audio quality.\n\nIn this paper, we introduce a new method allowing to produce non-causal\nstreaming models. This allows to make any convolutional model compatible with\nreal-time buffer-based processing. As our method is based on a post-training\nreconfiguration of the model, we show that it is able to transform models\ntrained without causal constraints into a streaming model. We show how our\nmethod can be adapted to fit complex architectures with parallel branches. To\nevaluate our method, we apply it on the recent RAVE model, which provides\nhigh-quality real-time audio synthesis. We test our approach on multiple music\nand speech datasets and show that it is faster than overlap-add methods, while\nhaving no impact on the generation quality. Finally, we introduce two\nopen-source implementation of our work as Max/MSP and PureData externals, and\nas a VST audio plugin. This allows to endow traditional digital audio\nworkstation with real-time neural audio synthesis on a laptop CPU.",
          "link": "http://arxiv.org/abs/2204.07064",
          "publishedOn": "2022-04-16T00:51:44.489Z",
          "wordCount": null,
          "title": "Streamable Neural Audio Synthesis With Non-Causal Convolutions. (arXiv:2204.07064v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06931",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Braeu_F/0/1/0/all/0/1\">Fabian A. Braeu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thiery_A/0/1/0/all/0/1\">Alexandre H. Thi&#xe9;ry</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tun_T/0/1/0/all/0/1\">Tin A. Tun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kadziauskiene_A/0/1/0/all/0/1\">Aiste Kadziauskiene</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barbastathis_G/0/1/0/all/0/1\">George Barbastathis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aung_T/0/1/0/all/0/1\">Tin Aung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Girard_M/0/1/0/all/0/1\">Micha&#xeb;l J.A. Girard</a>",
          "description": "Purpose: The optic nerve head (ONH) undergoes complex and deep 3D\nmorphological changes during the development and progression of glaucoma.\nOptical coherence tomography (OCT) is the current gold standard to visualize\nand quantify these changes, however the resulting 3D deep-tissue information\nhas not yet been fully exploited for the diagnosis and prognosis of glaucoma.\nTo this end, we aimed: (1) To compare the performance of two relatively recent\ngeometric deep learning techniques in diagnosing glaucoma from a single OCT\nscan of the ONH; and (2) To identify the 3D structural features of the ONH that\nare critical for the diagnosis of glaucoma.\n\nMethods: In this study, we included a total of 2,247 non-glaucoma and 2,259\nglaucoma scans from 1,725 subjects. All subjects had their ONHs imaged in 3D\nwith Spectralis OCT. All OCT scans were automatically segmented using deep\nlearning to identify major neural and connective tissues. Each ONH was then\nrepresented as a 3D point cloud. We used PointNet and dynamic graph\nconvolutional neural network (DGCNN) to diagnose glaucoma from such 3D ONH\npoint clouds and to identify the critical 3D structural features of the ONH for\nglaucoma diagnosis.\n\nResults: Both the DGCNN (AUC: 0.97$\\pm$0.01) and PointNet (AUC:\n0.95$\\pm$0.02) were able to accurately detect glaucoma from 3D ONH point\nclouds. The critical points formed an hourglass pattern with most of them\nlocated in the inferior and superior quadrant of the ONH.\n\nDiscussion: The diagnostic accuracy of both geometric deep learning\napproaches was excellent. Moreover, we were able to identify the critical 3D\nstructural features of the ONH for glaucoma diagnosis that tremendously\nimproved the transparency and interpretability of our method. Consequently, our\napproach may have strong potential to be used in clinical applications for the\ndiagnosis and prognosis of a wide range of ophthalmic disorders.",
          "link": "http://arxiv.org/abs/2204.06931",
          "publishedOn": "2022-04-16T00:51:44.422Z",
          "wordCount": null,
          "title": "Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis. (arXiv:2204.06931v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guodao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Band_S/0/1/0/all/0/1\">Shahab S. Band</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ardabili_S/0/1/0/all/0/1\">Sina Ardabili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_K/0/1/0/all/0/1\">Kwok-Wing Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosavi_A/0/1/0/all/0/1\">Amir Mosavi</a>",
          "description": "In this research, dew point temperature (DPT) is simulated using the\ndata-driven approach. Adaptive Neuro-Fuzzy Inference System (ANFIS) is utilized\nas a data-driven technique to forecast this parameter at Tabriz in East\nAzerbaijan. Various input patterns, namely T min, T max, and T mean, are\nutilized for training the architecture whilst DPT is the model's output. The\nfindings indicate that, in general, ANFIS method is capable of identifying data\npatterns with a high degree of accuracy. However, the approach demonstrates\nthat processing time and computer resources may substantially increase by\nadding additional functions. Based on the results, the number of iterations and\ncomputing resources might change dramatically if new functionalities are\nincluded. As a result, tuning parameters have to be optimized inside the method\nframework. The findings demonstrate a high agreement between results by the\ndata-driven technique (machine learning method) and the observed data. Using\nthis prediction toolkit, DPT can be adequately forecasted solely based on the\ntemperature distribution of Tabriz. This kind of modeling is extremely\npromising for predicting DPT at various sites. Besides, this study thoroughly\ncompares the Bilayered Neural Network (BNN) and ANFIS models on various scales.\nWhilst the ANFIS model is extremely stable for almost all numbers of membership\nfunctions, the BNN model is highly sensitive to this scale factor to predict\nDPT.",
          "link": "http://arxiv.org/abs/2202.12256",
          "publishedOn": "2022-04-16T00:51:44.422Z",
          "wordCount": null,
          "title": "Integration of neural network and fuzzy logic decision making compared with bilayered neural network in the simulation of daily dew point temperature. (arXiv:2202.12256v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_G/0/1/0/all/0/1\">Geunseob Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1\">Rahul Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hidey_C/0/1/0/all/0/1\">Chris Hidey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1\">Shachi Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Aditya Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_P/0/1/0/all/0/1\">Pararth Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rushin Shah</a>",
          "description": "Semantic parsing (SP) is a core component of modern virtual assistants like\nGoogle Assistant and Amazon Alexa. While sequence-to-sequence-based\nauto-regressive (AR) approaches are common for conversational semantic parsing,\nrecent studies employ non-autoregressive (NAR) decoders and reduce inference\nlatency while maintaining competitive parsing quality. However, a major\ndrawback of NAR decoders is the difficulty of generating top-k (i.e., k-best)\noutputs with approaches such as beam search. To address this challenge, we\npropose a novel NAR semantic parser that introduces intent conditioning on the\ndecoder. Inspired by the traditional intent and slot tagging parsers, we\ndecouple the top-level intent prediction from the rest of a parse. As the\ntop-level intent largely governs the syntax and semantics of a parse, the\nintent conditioning allows the model to better control beam search and improves\nthe quality and diversity of top-k outputs. We introduce a hybrid\nteacher-forcing approach to avoid training and inference mismatch. We evaluate\nthe proposed NAR on conversational SP datasets, TOP & TOPv2. Like the existing\nNAR models, we maintain the O(1) decoding time complexity while generating more\ndiverse outputs and improving the top-3 exact match (EM) by 2.4 points. In\ncomparison with AR models, our model speeds up beam search inference by 6.7\ntimes on CPU with competitive top-k EM.",
          "link": "http://arxiv.org/abs/2204.06748",
          "publishedOn": "2022-04-16T00:51:44.421Z",
          "wordCount": null,
          "title": "Improving Top-K Decoding for Non-Autoregressive Semantic Parsing via Intent Conditioning. (arXiv:2204.06748v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seiler_M/0/1/0/all/0/1\">Moritz Vinzent Seiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prager_R/0/1/0/all/0/1\">Raphael Patrick Prager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerschke_P/0/1/0/all/0/1\">Pascal Kerschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trautmann_H/0/1/0/all/0/1\">Heike Trautmann</a>",
          "description": "Exploratory Landscape Analysis is a powerful technique for numerically\ncharacterizing landscapes of single-objective continuous optimization problems.\nLandscape insights are crucial both for problem understanding as well as for\nassessing benchmark set diversity and composition. Despite the irrefutable\nusefulness of these features, they suffer from their own ailments and\ndownsides. Hence, in this work we provide a collection of different approaches\nto characterize optimization landscapes. Similar to conventional landscape\nfeatures, we require a small initial sample. However, instead of computing\nfeatures based on that sample, we develop alternative representations of the\noriginal sample. These range from point clouds to 2D images and, therefore, are\nentirely feature-free. We demonstrate and validate our devised methods on the\nBBOB testbed and predict, with the help of Deep Learning, the high-level,\nexpert-based landscape properties such as the degree of multimodality and the\nexistence of funnel structures. The quality of our approaches is on par with\nmethods relying on the traditional landscape features. Thereby, we provide an\nexciting new perspective on every research area which utilizes problem\ninformation such as problem understanding and algorithm design as well as\nautomated algorithm configuration and selection.",
          "link": "http://arxiv.org/abs/2204.05752",
          "publishedOn": "2022-04-16T00:51:44.417Z",
          "wordCount": null,
          "title": "A Collection of Deep Learning-based Feature-Free Approaches for Characterizing Single-Objective Continuous Fitness Landscapes. (arXiv:2204.05752v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01142",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Darling_R/0/1/0/all/0/1\">R. W. R. Darling</a>, <a href=\"http://arxiv.org/find/math/1/au:+Emanuello_J/0/1/0/all/0/1\">John A. Emanuello</a>, <a href=\"http://arxiv.org/find/math/1/au:+Purvine_E/0/1/0/all/0/1\">Emilie Purvine</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ridley_A/0/1/0/all/0/1\">Ahmad Ridley</a>",
          "description": "Topological Data Analysis (TDA) is a rigorous framework that borrows\ntechniques from geometric and algebraic topology, category theory, and\ncombinatorics in order to study the \"shape\" of such complex high-dimensional\ndata. Research in this area has grown significantly over the last several years\nbringing a deeply rooted theory to bear on practical applications in areas such\nas genomics, natural language processing, medicine, cybersecurity, energy, and\nclimate change. Within some of these areas, TDA has also been used to augment\nAI and ML techniques.\n\nWe believe there is further utility to be gained in this space that can be\nfacilitated by a workshop bringing together experts (both theorists and\npractitioners) and non-experts. Currently there is an active community of pure\nmathematicians with research interests in developing and exploring the\ntheoretical and computational aspects of TDA. Applied mathematicians and other\npractitioners are also present in community but do not represent a majority.\nThis speaks to the primary aim of this workshop which is to grow a wider\ncommunity of interest in TDA. By fostering meaningful exchanges between these\ngroups, from across the government, academia, and industry, we hope to create\nnew synergies that can only come through building a mutual comprehensive\nawareness of the problem and solution spaces.",
          "link": "http://arxiv.org/abs/2204.01142",
          "publishedOn": "2022-04-16T00:51:44.416Z",
          "wordCount": null,
          "title": "Proceedings of TDA: Applications of Topological Data Analysis to Data Science, Artificial Intelligence, and Machine Learning Workshop at SDM 2022. (arXiv:2204.01142v2 [math.AT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sedova_A/0/1/0/all/0/1\">Anastasiia Sedova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1\">Benjamin Roth</a>",
          "description": "A way to overcome expensive and time-consuming manual data labeling is weak\nsupervision - automatic annotation of data samples via a predefined set of\nlabeling functions (LFs), rule-based mechanisms that generate potentially\nerroneous labels. In this work, we investigate noise reduction techniques for\nweak supervision based on the principle of k-fold cross-validation. In\nparticular, we extend two frameworks for detecting the erroneous samples in\nmanually annotated data to the weakly supervised setting. Our methods profit\nfrom leveraging the information about matching LFs and detect noisy samples\nmore accurately. We also introduce a new algorithm for denoising the weakly\nannotated data called ULF, that refines the allocation of LFs to classes by\nestimating the reliable LFs-to-classes joint matrix. Evaluation on several\ndatasets shows that ULF successfully improves weakly supervised learning\nwithout using any manually labeled data.",
          "link": "http://arxiv.org/abs/2204.06863",
          "publishedOn": "2022-04-16T00:51:44.414Z",
          "wordCount": null,
          "title": "ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision. (arXiv:2204.06863v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06546",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Choi_S/0/1/0/all/0/1\">Soonbeom Choi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nam_J/0/1/0/all/0/1\">Juhan Nam</a>",
          "description": "Recent studies in singing voice synthesis have achieved high-quality results\nleveraging advances in text-to-speech models based on deep neural networks. One\nof the main issues in training singing voice synthesis models is that they\nrequire melody and lyric labels to be temporally aligned with audio data. The\ntemporal alignment is a time-exhausting manual work in preparing for the\ntraining data. To address the issue, we propose a melody-unsupervision model\nthat requires only audio-and-lyrics pairs without temporal alignment in\ntraining time but generates singing voice audio given a melody and lyrics input\nin inference time. The proposed model is composed of a phoneme classifier and a\nsinging voice generator jointly trained in an end-to-end manner. The model can\nbe fine-tuned by adjusting the amount of supervision with temporally aligned\nmelody labels. Through experiments in melody-unsupervision and semi-supervision\nsettings, we compare the audio quality of synthesized singing voice. We also\nshow that the proposed model is capable of being trained with speech audio and\ntext labels but can generate singing voice in inference time.",
          "link": "http://arxiv.org/abs/2110.06546",
          "publishedOn": "2022-04-16T00:51:44.414Z",
          "wordCount": null,
          "title": "A Melody-Unsupervision Model for Singing Voice Synthesis. (arXiv:2110.06546v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.01511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Honari_S/0/1/0/all/0/1\">Sina Honari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constantin_V/0/1/0/all/0/1\">Victor Constantin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhodin_H/0/1/0/all/0/1\">Helge Rhodin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1\">Mathieu Salzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "In this paper we propose an unsupervised learning method to extract temporal\ninformation on monocular videos, where we detect and encode subject of interest\nin each frame and leverage contrastive self-supervised (CSS) learning to\nextract rich latent vectors. Instead of simply treating the latent features of\nnearby frames as positive pairs and those of temporally-distant ones as\nnegative pairs as in other CSS approaches, we explicitly disentangle each\nlatent vector into a time-variant component and a time-invariant one. We then\nshow that applying CSS only to the time-variant features and encouraging a\ngradual transition on them between nearby and away frames while also\nreconstructing the input, extract rich temporal features into the time-variant\ncomponent, well-suited for human pose estimation. Our approach reduces error by\nabout 50\\% compared to the standard CSS strategies, outperforms other\nunsupervised single-view methods and matches the performance of multi-view\ntechniques.",
          "link": "http://arxiv.org/abs/2012.01511",
          "publishedOn": "2022-04-16T00:51:44.412Z",
          "wordCount": null,
          "title": "Unsupervised Temporal Learning on Monocular Videos for 3D Human Pose Estimation. (arXiv:2012.01511v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1\">Haewon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "We investigate the fairness concerns of training a machine learning model\nusing data with missing values. Even though there are a number of fairness\nintervention methods in the literature, most of them require a complete\ntraining set as input. In practice, data can have missing values, and data\nmissing patterns can depend on group attributes (e.g. gender or race). Simply\napplying off-the-shelf fair learning algorithms to an imputed dataset may lead\nto an unfair model. In this paper, we first theoretically analyze different\nsources of discrimination risks when training with an imputed dataset. Then, we\npropose an integrated approach based on decision trees that does not require a\nseparate process of imputation and learning. Instead, we train a tree with\nmissing incorporated as attribute (MIA), which does not require explicit\nimputation, and we optimize a fairness-regularized objective function. We\ndemonstrate that our approach outperforms existing fairness intervention\nmethods applied to an imputed dataset, through several experiments on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2109.10431",
          "publishedOn": "2022-04-16T00:51:44.410Z",
          "wordCount": null,
          "title": "Fairness without Imputation: A Decision Tree Approach for Fair Prediction with Missing Values. (arXiv:2109.10431v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05745",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lew_T/0/1/0/all/0/1\">Thomas Lew</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Janson_L/0/1/0/all/0/1\">Lucas Janson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bonalli_R/0/1/0/all/0/1\">Riccardo Bonalli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "In this work, we analyze an efficient sampling-based algorithm for\ngeneral-purpose reachability analysis, which remains a notoriously challenging\nproblem with applications ranging from neural network verification to safety\nanalysis of dynamical systems. By sampling inputs, evaluating their images in\nthe true reachable set, and taking their $\\epsilon$-padded convex hull as a set\nestimator, this algorithm applies to general problem settings and is simple to\nimplement. Our main contribution is the derivation of asymptotic and\nfinite-sample accuracy guarantees using random set theory. This analysis\ninforms algorithmic design to obtain an $\\epsilon$-close reachable set\napproximation with high probability, provides insights into which reachability\nproblems are most challenging, and motivates safety-critical applications of\nthe technique. On a neural network verification task, we show that this\napproach is more accurate and significantly faster than prior work. Informed by\nour analysis, we also design a robust model predictive controller that we\ndemonstrate in hardware experiments.",
          "link": "http://arxiv.org/abs/2112.05745",
          "publishedOn": "2022-04-16T00:51:44.410Z",
          "wordCount": null,
          "title": "A Simple and Efficient Sampling-based Algorithm for General Reachability Analysis. (arXiv:2112.05745v3 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trummer_I/0/1/0/all/0/1\">Immanuel Trummer</a>",
          "description": "In black-box optimization problems, we aim to maximize an unknown objective\nfunction, where the function is only accessible through feedbacks of an\nevaluation or simulation oracle. In real-life, the feedbacks of such oracles\nare often noisy and available after some unknown delay that may depend on the\ncomputation time of the oracle. Additionally, if the exact evaluations are\nexpensive but coarse approximations are available at a lower cost, the\nfeedbacks can have multi-fidelity. In order to address this problem, we propose\na generic extension of hierarchical optimistic tree search (HOO), called\nProCrastinated Tree Search (PCTS), that flexibly accommodates a delay and\nnoise-tolerant bandit algorithm. We provide a generic proof technique to\nquantify regret of PCTS under delayed, noisy, and multi-fidelity feedbacks.\nSpecifically, we derive regret bounds of PCTS enabled with delayed-UCB1 (DUCB1)\nand delayed-UCB-V (DUCBV) algorithms. Given a horizon $T$, PCTS retains the\nregret bound of non-delayed HOO for expected delay of $O(\\log T)$ and worsens\nby $O(T^{\\frac{1-\\alpha}{d+2}})$ for expected delays of $O(T^{1-\\alpha})$ for\n$\\alpha \\in (0,1]$. We experimentally validate on multiple synthetic functions\nand hyperparameter tuning problems that PCTS outperforms the state-of-the-art\nblack-box optimization methods for feedbacks with different noise levels,\ndelays, and fidelity.",
          "link": "http://arxiv.org/abs/2110.07232",
          "publishedOn": "2022-04-16T00:51:44.409Z",
          "wordCount": null,
          "title": "Procrastinated Tree Search: Black-box Optimization with Delayed, Noisy, and Multi-Fidelity Feedback. (arXiv:2110.07232v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huaulme_A/0/1/0/all/0/1\">Arnaud Huaulm&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harada_K/0/1/0/all/0/1\">Kanako Harada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quang-Minh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Bogyu Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Seungbum Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Min-Kook Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peven_M/0/1/0/all/0/1\">Michael Peven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunshuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yonghao Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Satyadwyoom Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalithkumar_S/0/1/0/all/0/1\">Seenivasan Lalithkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hongliang_R/0/1/0/all/0/1\">Ren Hongliang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuzaki_H/0/1/0/all/0/1\">Hiroki Matsuzaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_Y/0/1/0/all/0/1\">Yuto Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harai_Y/0/1/0/all/0/1\">Yuriko Harai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondo_S/0/1/0/all/0/1\">Satoshi Kondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsuishi_M/0/1/0/all/0/1\">Mamoru Mitsuishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannin_P/0/1/0/all/0/1\">Pierre Jannin</a>",
          "description": "This paper presents the design and results of the \"PEg TRAnsfert Workflow\nrecognition\" (PETRAW) challenge whose objective was to develop surgical\nworkflow recognition methods based on one or several modalities, among video,\nkinematic, and segmentation data, in order to study their added value. The\nPETRAW challenge provided a data set of 150 peg transfer sequences performed on\na virtual simulator. This data set was composed of videos, kinematics, semantic\nsegmentation, and workflow annotations which described the sequences at three\ndifferent granularity levels: phase, step, and activity. Five tasks were\nproposed to the participants: three of them were related to the recognition of\nall granularities with one of the available modalities, while the others\naddressed the recognition with a combination of modalities. Average\napplication-dependent balanced accuracy (AD-Accuracy) was used as evaluation\nmetric to take unbalanced classes into account and because it is more\nclinically relevant than a frame-by-frame score. Seven teams participated in at\nleast one task and four of them in all tasks. Best results are obtained with\nthe use of the video and the kinematics data with an AD-Accuracy between 93%\nand 90% for the four teams who participated in all tasks. The improvement\nbetween video/kinematic-based methods and the uni-modality ones was significant\nfor all of the teams. However, the difference in testing execution time between\nthe video/kinematic-based and the kinematic-based methods has to be taken into\nconsideration. Is it relevant to spend 20 to 200 times more computing time for\nless than 3% of improvement? The PETRAW data set is publicly available at\nwww.synapse.org/PETRAW to encourage further research in surgical workflow\nrecognition.",
          "link": "http://arxiv.org/abs/2202.05821",
          "publishedOn": "2022-04-16T00:51:44.407Z",
          "wordCount": null,
          "title": "PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?. (arXiv:2202.05821v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bruinsma_W/0/1/0/all/0/1\">Wessel P. Bruinsma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tegner_M/0/1/0/all/0/1\">Martin Tegn&#xe9;r</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The Gaussian Process Convolution Model (GPCM; Tobar et al., 2015a) is a model\nfor signals with complex spectral structure. A significant limitation of the\nGPCM is that it assumes a rapidly decaying spectrum: it can only model smooth\nsignals. Moreover, inference in the GPCM currently requires (1) a mean-field\nassumption, resulting in poorly calibrated uncertainties, and (2) a tedious\nvariational optimisation of large covariance matrices. We redesign the GPCM\nmodel to induce a richer distribution over the spectrum with relaxed\nassumptions about smoothness: the Causal Gaussian Process Convolution Model\n(CGPCM) introduces a causality assumption into the GPCM, and the Rough Gaussian\nProcess Convolution Model (RGPCM) can be interpreted as a Bayesian\nnonparametric generalisation of the fractional Ornstein-Uhlenbeck process. We\nalso propose a more effective variational inference scheme, going beyond the\nmean-field assumption: we design a Gibbs sampler which directly samples from\nthe optimal variational solution, circumventing any variational optimisation\nentirely. The proposed variations of the GPCM are validated in experiments on\nsynthetic and real-world data, showing promising results.",
          "link": "http://arxiv.org/abs/2203.06997",
          "publishedOn": "2022-04-16T00:51:44.404Z",
          "wordCount": null,
          "title": "Modelling Non-Smooth Signals with Complex Spectral Structure. (arXiv:2203.06997v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.02889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Ruixuan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1\">Qi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "Previous studies demonstrate DNNs' vulnerability to adversarial examples and\nadversarial training can establish a defense to adversarial examples. In\naddition, recent studies show that deep neural networks also exhibit\nvulnerability to parameter corruptions. The vulnerability of model parameters\nis of crucial value to the study of model robustness and generalization. In\nthis work, we introduce the concept of parameter corruption and propose to\nleverage the loss change indicators for measuring the flatness of the loss\nbasin and the parameter robustness of neural network parameters. On such basis,\nwe analyze parameter corruptions and propose the multi-step adversarial\ncorruption algorithm. To enhance neural networks, we propose the adversarial\nparameter defense algorithm that minimizes the average risk of multiple\nadversarial parameter corruptions. Experimental results show that the proposed\nalgorithm can improve both the parameter robustness and accuracy of neural\nnetworks.",
          "link": "http://arxiv.org/abs/2109.02889",
          "publishedOn": "2022-04-16T00:51:43.895Z",
          "wordCount": null,
          "title": "Adversarial Parameter Defense by Multi-Step Risk Minimization. (arXiv:2109.02889v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.07140",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Weiss_M/0/1/0/all/0/1\">Matthew L. Weiss</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Frey_N/0/1/0/all/0/1\">Nathan C. Frey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Samsi_S/0/1/0/all/0/1\">Siddharth Samsi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Paffenroth_R/0/1/0/all/0/1\">Randy C. Paffenroth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gadepally_V/0/1/0/all/0/1\">Vijay Gadepally</a>",
          "description": "Traditional frequency based projection filters, or projection operators (PO),\nseparate signal and noise through a series of transformations which remove\nfrequencies where noise is present. However, this technique relies on a priori\nknowledge of what frequencies contain signal and noise and that these\nfrequencies do not overlap, which is difficult to achieve in practice. To\naddress these issues, we introduce a PO-neural network hybrid model, the Pseudo\nProjection Operator (PPO), which leverages a neural network to perform\nfrequency selection. We compare the filtering capabilities of a PPO, PO, and\ndenoising autoencoder (DAE) on the University of Rochester Multi-Modal Music\nPerformance Dataset with a variety of added noise types. In the majority of\nexperiments, the PPO outperforms both the PO and DAE. Based upon these results,\nwe suggest future application of the PPO to filtering problems in the physical\nand biological sciences.",
          "link": "http://arxiv.org/abs/2111.07140",
          "publishedOn": "2022-04-16T00:51:43.894Z",
          "wordCount": null,
          "title": "The Pseudo Projection Operator: Applications of Deep Learning to Projection Based Filtering in Non-Trivial Frequency Regimes. (arXiv:2111.07140v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_S/0/1/0/all/0/1\">Shafi Goldwasser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Michael P. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaikuntanathan_V/0/1/0/all/0/1\">Vinod Vaikuntanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamir_O/0/1/0/all/0/1\">Or Zamir</a>",
          "description": "Given the computational cost and technical expertise required to train\nmachine learning models, users may delegate the task of learning to a service\nprovider. We show how a malicious learner can plant an undetectable backdoor\ninto a classifier. On the surface, such a backdoored classifier behaves\nnormally, but in reality, the learner maintains a mechanism for changing the\nclassification of any input, with only a slight perturbation. Importantly,\nwithout the appropriate \"backdoor key\", the mechanism is hidden and cannot be\ndetected by any computationally-bounded observer. We demonstrate two frameworks\nfor planting undetectable backdoors, with incomparable guarantees.\n\nFirst, we show how to plant a backdoor in any model, using digital signature\nschemes. The construction guarantees that given black-box access to the\noriginal model and the backdoored version, it is computationally infeasible to\nfind even a single input where they differ. This property implies that the\nbackdoored model has generalization error comparable with the original model.\nSecond, we demonstrate how to insert undetectable backdoors in models trained\nusing the Random Fourier Features (RFF) learning paradigm or in Random ReLU\nnetworks. In this construction, undetectability holds against powerful\nwhite-box distinguishers: given a complete description of the network and the\ntraining data, no efficient distinguisher can guess whether the model is\n\"clean\" or contains a backdoor.\n\nOur construction of undetectable backdoors also sheds light on the related\nissue of robustness to adversarial examples. In particular, our construction\ncan produce a classifier that is indistinguishable from an \"adversarially\nrobust\" classifier, but where every input has an adversarial example! In\nsummary, the existence of undetectable backdoors represent a significant\ntheoretical roadblock to certifying adversarial robustness.",
          "link": "http://arxiv.org/abs/2204.06974",
          "publishedOn": "2022-04-16T00:51:43.878Z",
          "wordCount": null,
          "title": "Planting Undetectable Backdoors in Machine Learning Models. (arXiv:2204.06974v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.01250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baldini_I/0/1/0/all/0/1\">Ioana Baldini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dennis Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramamurthy_K/0/1/0/all/0/1\">Karthikeyan Natesan Ramamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurochkin_M/0/1/0/all/0/1\">Mikhail Yurochkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Moninder Singh</a>",
          "description": "The popularity of pretrained language models in natural language processing\nsystems calls for a careful evaluation of such models in down-stream tasks,\nwhich have a higher potential for societal impact. The evaluation of such\nsystems usually focuses on accuracy measures. Our findings in this paper call\nfor attention to be paid to fairness measures as well. Through the analysis of\nmore than a dozen pretrained language models of varying sizes on two toxic text\nclassification tasks (English), we demonstrate that focusing on accuracy\nmeasures alone can lead to models with wide variation in fairness\ncharacteristics. Specifically, we observe that fairness can vary even more than\naccuracy with increasing training data size and different random\ninitializations. At the same time, we find that little of the fairness\nvariation is explained by model size, despite claims in the literature. To\nimprove model fairness without retraining, we show that two post-processing\nmethods developed for structured, tabular data can be successfully applied to a\nrange of pretrained language models. Warning: This paper contains samples of\noffensive text.",
          "link": "http://arxiv.org/abs/2108.01250",
          "publishedOn": "2022-04-16T00:51:43.878Z",
          "wordCount": null,
          "title": "Your fairness may vary: Pretrained language model fairness in toxic text classification. (arXiv:2108.01250v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.06047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Federated learning is an emerging research paradigm enabling collaborative\ntraining of machine learning models among different organizations while keeping\ndata private at each institution. Despite recent progress, there remain\nfundamental challenges such as the lack of convergence and the potential for\ncatastrophic forgetting across real-world heterogeneous devices. In this paper,\nwe demonstrate that self-attention-based architectures (e.g., Transformers) are\nmore robust to distribution shifts and hence improve federated learning over\nheterogeneous data. Concretely, we conduct the first rigorous empirical\ninvestigation of different neural architectures across a range of federated\nalgorithms, real-world benchmarks, and heterogeneous data splits. Our\nexperiments show that simply replacing convolutional networks with Transformers\ncan greatly reduce catastrophic forgetting of previous devices, accelerate\nconvergence, and reach a better global model, especially when dealing with\nheterogeneous data. We release our code and pretrained models at\nhttps://github.com/Liangqiong/ViT-FL-main to encourage future exploration in\nrobust architectures as an alternative to current research efforts on the\noptimization front.",
          "link": "http://arxiv.org/abs/2106.06047",
          "publishedOn": "2022-04-16T00:51:43.877Z",
          "wordCount": null,
          "title": "Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07037",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Toit_J/0/1/0/all/0/1\">J du Toit</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Preez_J/0/1/0/all/0/1\">J du Preez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wolhuter_R/0/1/0/all/0/1\">R Wolhuter</a>",
          "description": "We present a sequential Bayesian learning method for tracking non-stationary\nsignal-to-noise ratios in LDPC codes using probabilistic graphical models. We\nrepresent the LDPC code as a cluster graph using a general purpose cluster\ngraph construction algorithm called the layered trees running intersection\nproperty (LTRIP) algorithm. The channel noise estimator is a global Gamma\ncluster, which we extend to allow for Bayesian tracking of non-stationary noise\nvariation. We evaluate our proposed model on real-world 5G drive test data. Our\nresults show that our model is capable of tracking non-stationary channel\nnoise, which outperforms an LDPC code with a fixed knowledge of the actual\naverage channel noise.",
          "link": "http://arxiv.org/abs/2204.07037",
          "publishedOn": "2022-04-16T00:51:43.875Z",
          "wordCount": null,
          "title": "LDPC codes: tracking non-stationary channel noise using sequential variational Bayesian estimates. (arXiv:2204.07037v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhe Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bikel_D/0/1/0/all/0/1\">Dan Bikel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfonseca_E/0/1/0/all/0/1\">Enrique Alfonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1\">Chen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitouni_I/0/1/0/all/0/1\">Imed Zitouni</a>",
          "description": "Dual encoders have been used for question-answering (QA) and information\nretrieval (IR) tasks with good results. There are two major types of dual\nencoders, Siamese Dual Encoders (SDE), with parameters shared across two\nencoders, and Asymmetric Dual Encoder (ADE), with two distinctly parameterized\nencoders. In this work, we explore the dual encoder architectures for QA\nretrieval tasks. By evaluating on MS MARCO and the MultiReQA benchmark, we show\nthat SDE performs significantly better than ADE. We further propose three\ndifferent improved versions of ADEs. Based on the evaluation of QA retrieval\ntasks and direct analysis of the embeddings, we demonstrate that sharing\nparameters in projection layers would enable ADEs to perform competitively with\nSDEs.",
          "link": "http://arxiv.org/abs/2204.07120",
          "publishedOn": "2022-04-16T00:51:43.875Z",
          "wordCount": null,
          "title": "Exploring Dual Encoder Architectures for Question Answering. (arXiv:2204.07120v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ardeshir_S/0/1/0/all/0/1\">Shervin Ardeshir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_N/0/1/0/all/0/1\">Nagendra Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taghavi_H/0/1/0/all/0/1\">Hossein Taghavi</a>",
          "description": "We explore retrieving character-focused video frames as candidates for being\nvideo thumbnails. To evaluate each frame of the video based on the character(s)\npresent in it, characters (faces) are evaluated in two aspects:\nFacial-expression: We train a CNN model to measure whether a face has an\nacceptable facial expression for being in a video thumbnail. This model is\ntrained to distinguish faces extracted from artworks/thumbnails, from faces\nextracted from random frames of videos. Prominence and interactions:\nCharacter(s) in the thumbnail should be important character(s) in the video, to\nprevent the algorithm from suggesting non-representative frames as candidates.\nWe use face clustering to identify the characters in the video, and form a\ngraph in which the prominence (frequency of appearance) of the character(s),\nand their interactions (co-occurrence) are captured. We use this graph to infer\nthe relevance of the characters present in each candidate frame. Once every\nface is scored based on the two criteria above, we infer frame level scores by\ncombining the scores for all the faces within a frame.",
          "link": "http://arxiv.org/abs/2204.06563",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "Character-focused Video Thumbnail Retrieval. (arXiv:2204.06563v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "Model ensemble is a popular approach to produce a low-variance and\nwell-generalized model. However, it induces large memory and inference costs,\nwhich are often not affordable for real-world deployment. Existing work has\nresorted to sharing weights among models. However, when increasing the\nproportion of the shared weights, the resulting models tend to be similar, and\nthe benefits of using model ensemble diminish. To retain ensemble benefits\nwhile maintaining a low memory cost, we propose a consistency-regularized\nensemble learning approach based on perturbed models, named CAMERO.\nSpecifically, we share the weights of bottom layers across all models and apply\ndifferent perturbations to the hidden representations for different models,\nwhich can effectively promote the model diversity. Meanwhile, we apply a\nprediction consistency regularizer across the perturbed models to control the\nvariance due to the model diversity. Our experiments using large language\nmodels demonstrate that CAMERO significantly improves the generalization\nperformance of the ensemble model. Specifically, CAMERO outperforms the\nstandard ensemble of 8 BERT-base models on the GLUE benchmark by 0.7 with a\nsignificantly smaller model size (114.2M vs. 880.6M).",
          "link": "http://arxiv.org/abs/2204.06625",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "CAMERO: Consistency Regularized Ensemble of Perturbed Language Models with Weight Sharing. (arXiv:2204.06625v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1\">Kaan Gokcesu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1\">Hakan Gokcesu</a>",
          "description": "We study the problem of expert advice under partial bandit feedback setting\nand create a sequential minimax optimal algorithm. Our algorithm works with a\nmore general partial monitoring setting, where, in contrast to the classical\nbandit feedback, the losses can be revealed in an adversarial manner. Our\nalgorithm adopts a universal prediction perspective, whose performance is\nanalyzed with regret against a general expert selection sequence. The regret we\nstudy is against a general competition class that covers many settings (such as\nthe switching or contextual experts settings) and the expert selection\nsequences in the competition class are determined by the application at hand.\nOur regret bounds are second order bounds in terms of the sum of squared losses\nand the normalized regret of our algorithm is invariant under arbitrary affine\ntransforms of the loss sequence. Our algorithm is truly online and does not use\nany preliminary information about the loss sequences.",
          "link": "http://arxiv.org/abs/2204.06660",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "Second Order Regret Bounds Against Generalized Expert Sequences under Partial Bandit Feedback. (arXiv:2204.06660v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07071",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xing Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maranzatto_T/0/1/0/all/0/1\">Thomas Maranzatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reyzin_L/0/1/0/all/0/1\">Lev Reyzin</a>",
          "description": "In this paper we investigate the problem of learning evolving concepts over a\ncombinatorial structure. Previous work by Emamjomeh-Zadeh et al. [2020]\nintroduced dynamics into interactive learning as a way to model non-static user\npreferences in clustering problems or recommender systems. We provide many\nuseful contributions to this problem. First, we give a framework that captures\nboth of the models analyzed by [Emamjomeh-Zadeh et al., 2020], which allows us\nto study any type of concept evolution and matches the same query complexity\nbounds and running time guarantees of the previous models. Using this general\nmodel we solve the open problem of closing the gap between the upper and lower\nbounds on query complexity. Finally, we study an efficient algorithm where the\nlearner simply follows the feedback at each round, and we provide mistake\nbounds for low diameter graphs such as cliques, stars, and general o(log n)\ndiameter graphs by using a Markov Chain model.",
          "link": "http://arxiv.org/abs/2204.07071",
          "publishedOn": "2022-04-16T00:51:43.869Z",
          "wordCount": null,
          "title": "A Unified Analysis of Dynamic Interactive Learning. (arXiv:2204.07071v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ren_T/0/1/0/all/0/1\">Tongzheng Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhuo_J/0/1/0/all/0/1\">Jiacheng Zhuo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>",
          "description": "It is known that when the statistical models are singular, i.e., the Fisher\ninformation matrix at the true parameter is degenerate, the fixed step-size\ngradient descent algorithm takes polynomial number of steps in terms of the\nsample size $n$ to converge to a final statistical radius around the true\nparameter, which can be unsatisfactory for the application. To further improve\nthat computational complexity, we consider the utilization of the second-order\ninformation in the design of optimization algorithms. Specifically, we study\nthe normalized gradient descent (NormGD) algorithm for solving parameter\nestimation in parametric statistical models, which is a variant of gradient\ndescent algorithm whose step size is scaled by the maximum eigenvalue of the\nHessian matrix of the empirical loss function of statistical models. When the\npopulation loss function, i.e., the limit of the empirical loss function when\n$n$ goes to infinity, is homogeneous in all directions, we demonstrate that the\nNormGD iterates reach a final statistical radius around the true parameter\nafter a logarithmic number of iterations in terms of $n$. Therefore, for fixed\ndimension $d$, the NormGD algorithm achieves the optimal overall computational\ncomplexity $\\mathcal{O}(n)$ to reach the final statistical radius. This\ncomputational complexity is cheaper than that of the fixed step-size gradient\ndescent algorithm, which is of the order $\\mathcal{O}(n^{\\tau})$ for some $\\tau\n> 1$, to reach the same statistical radius. We illustrate our general theory\nunder two statistical models: generalized linear models and mixture models, and\nexperimental results support our prediction with general theory.",
          "link": "http://arxiv.org/abs/2202.04219",
          "publishedOn": "2022-04-16T00:51:43.867Z",
          "wordCount": null,
          "title": "Improving Computational Complexity in Statistical Models with Second-Order Information. (arXiv:2202.04219v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kacham_P/0/1/0/all/0/1\">Praneeth Kacham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We give a sketching-based iterative algorithm that computes $1+\\varepsilon$\napproximate solutions for the ridge regression problem $\\min_x \\|{Ax-b}\\|_2^2\n+\\lambda\\|{x}\\|_2^2$ where $A \\in \\mathbb{R}^{n \\times d}$ with $d \\ge n$. Our\nalgorithm, for a constant number of iterations (requiring a constant number of\npasses over the input), improves upon earlier work of Chowdhury et al., by\nrequiring that the sketching matrix only has a weaker Approximate Matrix\nMultiplication (AMM) guarantee that depends on $\\epsilon$, along with a\nconstant subspace embedding guarantee. The earlier work instead requires that\nthe sketching matrix have a subspace embedding guarantee that depends on\n$\\epsilon$. For example, to produce a $1+\\varepsilon$ approximate solution in\n$1$ iteration, which requires $2$ passes over the input, our algorithm requires\nthe OSNAP embedding to have $m= O(n\\sigma^2/\\lambda\\varepsilon)$ rows with a\nsparsity parameter $s = O(\\log(n))$, whereas the earlier algorithm of Chowdhury\net al., with the same number of rows of OSNAP requires a sparsity $s =\nO(\\sqrt{\\sigma^2/\\lambda\\varepsilon} \\cdot \\log(n))$, where $\\sigma =\n\\|{A}\\|_2$ is the spectral norm of the matrix $A$. We also show that this\nalgorithm can be used to give faster algorithms for kernel ridge regression.\nFinally, we show that the sketch size required for our algorithm is essentially\noptimal for a natural framework of algorithms for ridge regression by proving\nlower bounds on oblivious sketching matrices for AMM. The sketch size lower\nbounds for AMM may be of independent interest.",
          "link": "http://arxiv.org/abs/2204.06653",
          "publishedOn": "2022-04-16T00:51:43.865Z",
          "wordCount": null,
          "title": "Sketching Algorithms and Lower Bounds for Ridge Regression. (arXiv:2204.06653v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1\">Samar Khanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Bram Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bala_K/0/1/0/all/0/1\">Kavita Bala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1\">Bharath Hariharan</a>",
          "description": "Geographic variance in satellite imagery impacts the ability of machine\nlearning models to generalise to new regions. In this paper, we model\ngeographic generalisation in medium resolution Landsat-8 satellite imagery as a\ncontinuous domain adaptation problem, demonstrating how models generalise\nbetter with appropriate domain knowledge. We develop a dataset spatially\ndistributed across the entire continental United States, providing macroscopic\ninsight into the effects of geography on crop classification in multi-spectral\nand temporally distributed satellite imagery. Our method demonstrates improved\ngeneralisability from 1) passing geographically correlated climate variables\nalong with the satellite data to a Transformer model and 2) regressing on the\nmodel features to reconstruct these domain variables. Combined, we provide a\nnovel perspective on geographic generalisation in satellite imagery and a\nsimple-yet-effective approach to leverage domain knowledge. Code is available\nat: \\url{https://github.com/samar-khanna/cropmap}",
          "link": "http://arxiv.org/abs/2204.07030",
          "publishedOn": "2022-04-16T00:51:43.865Z",
          "wordCount": null,
          "title": "Activation Regression for Continuous Domain Generalization with Applications to Crop Classification. (arXiv:2204.07030v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1\">Lucy Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gharbi_M/0/1/0/all/0/1\">Michael Gharbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shechtman_E/0/1/0/all/0/1\">Eli Shechtman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Richard Zhang</a>",
          "description": "Generative models operate at fixed resolution, even though natural images\ncome in a variety of sizes. As high-resolution details are downsampled away,\nand low-resolution images are discarded altogether, precious supervision is\nlost. We argue that every pixel matters and create datasets with variable-size\nimages, collected at their native resolutions. Taking advantage of this data is\nchallenging; high-resolution processing is costly, and current architectures\ncan only process fixed-resolution data. We introduce continuous-scale training,\na process that samples patches at random scales to train a new generator with\nvariable output resolutions. First, conditioning the generator on a target\nscale allows us to generate higher resolutions images than previously possible,\nwithout adding layers to the model. Second, by conditioning on continuous\ncoordinates, we can sample patches that still obey a consistent global layout,\nwhich also allows for scalable training at higher resolutions. Controlled FFHQ\nexperiments show our method takes advantage of the multi-resolution training\ndata better than discrete multi-scale approaches, achieving better FID scores\nand cleaner high-frequency details. We also train on other natural image\ndomains including churches, mountains, and birds, and demonstrate arbitrary\nscale synthesis with both coherent global layouts and realistic local details,\ngoing beyond 2K resolution in our experiments. Our project page is available\nat: https://chail.github.io/anyres-gan/.",
          "link": "http://arxiv.org/abs/2204.07156",
          "publishedOn": "2022-04-16T00:51:43.864Z",
          "wordCount": null,
          "title": "Any-resolution Training for High-resolution Image Synthesis. (arXiv:2204.07156v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.07467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sitaula_C/0/1/0/all/0/1\">Chiranjibi Sitaula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jinyuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadarshi_A/0/1/0/all/0/1\">Archana Priyadarshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tracy_M/0/1/0/all/0/1\">Mark Tracy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kavehei_O/0/1/0/all/0/1\">Omid Kavehei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinder_M/0/1/0/all/0/1\">Murray Hinder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Withana_A/0/1/0/all/0/1\">Anusha Withana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McEwan_A/0/1/0/all/0/1\">Alistair McEwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzbanrad_F/0/1/0/all/0/1\">Faezeh Marzbanrad</a>",
          "description": "Abdominal auscultation is a convenient, safe and inexpensive method to assess\nbowel conditions, which is essential in neonatal care. It helps early detection\nof neonatal bowel dysfunctions and allows timely intervention. This paper\npresents a neonatal bowel sound detection method to assist the auscultation.\nSpecifically, a Convolutional Neural Network (CNN) is proposed to classify\nperistalsis and non-peristalsis sounds. The classification is then optimized\nusing a Laplace Hidden Semi-Markov Model (HSMM). The proposed method is\nvalidated on abdominal sounds from 49 newborn infants admitted to our tertiary\nNeonatal Intensive Care Unit (NICU). The results show that the method can\neffectively detect bowel sounds with accuracy and area under curve (AUC) score\nbeing 89.81% and 83.96% respectively, outperforming 13 baseline methods.\nFurthermore, the proposed Laplace HSMM refinement strategy is proven capable to\nenhance other bowel sound detection models. The outcomes of this work have the\npotential to facilitate future telehealth applications for neonatal care. The\nsource code of our work can be found at:\nhttps://bitbucket.org/chirudeakin/neonatal-bowel-sound-classification/",
          "link": "http://arxiv.org/abs/2108.07467",
          "publishedOn": "2022-04-16T00:51:43.864Z",
          "wordCount": null,
          "title": "Neonatal Bowel Sound Detection Using Convolutional Neural Network and Laplace Hidden Semi-Markov Model. (arXiv:2108.07467v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.04109",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nabi_R/0/1/0/all/0/1\">Razieh Nabi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malinsky_D/0/1/0/all/0/1\">Daniel Malinsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shpitser_I/0/1/0/all/0/1\">Ilya Shpitser</a>",
          "description": "Recently there has been sustained interest in modifying prediction algorithms\nto satisfy fairness constraints. These constraints are typically complex\nnonlinear functionals of the observed data distribution. Focusing on the\npath-specific causal constraints proposed by Nabi and Shpitser (2018), we\nintroduce new theoretical results and optimization techniques to make model\ntraining easier and more accurate. Specifically, we show how to reparameterize\nthe observed data likelihood such that fairness constraints correspond directly\nto parameters that appear in the likelihood, transforming a complex constrained\noptimization objective into a simple optimization problem with box constraints.\nWe also exploit methods from empirical likelihood theory in statistics to\nimprove predictive performance by constraining baseline covariates, without\nrequiring parametric models. We combine the merits of both proposals to\noptimize a hybrid reparameterized likelihood. The techniques presented here\nshould be applicable more broadly to fair prediction proposals that impose\nconstraints on predictive models.",
          "link": "http://arxiv.org/abs/1910.04109",
          "publishedOn": "2022-04-16T00:51:43.863Z",
          "wordCount": null,
          "title": "Optimal Training of Fair Predictive Models. (arXiv:1910.04109v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assran_M/0/1/0/all/0/1\">Mahmoud Assran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1\">Mathilde Caron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1\">Piotr Bojanowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bordes_F/0/1/0/all/0/1\">Florian Bordes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1\">Pascal Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1\">Armand Joulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1\">Nicolas Ballas</a>",
          "description": "We propose Masked Siamese Networks (MSN), a self-supervised learning\nframework for learning image representations. Our approach matches the\nrepresentation of an image view containing randomly masked patches to the\nrepresentation of the original unmasked image. This self-supervised\npre-training strategy is particularly scalable when applied to Vision\nTransformers since only the unmasked patches are processed by the network. As a\nresult, MSNs improve the scalability of joint-embedding architectures, while\nproducing representations of a high semantic level that perform competitively\non low-shot image classification. For instance, on ImageNet-1K, with only 5,000\nannotated images, our base MSN model achieves 72.4% top-1 accuracy, and with 1%\nof ImageNet-1K labels, we achieve 75.7% top-1 accuracy, setting a new\nstate-of-the-art for self-supervised learning on this benchmark. Our code is\npublicly available.",
          "link": "http://arxiv.org/abs/2204.07141",
          "publishedOn": "2022-04-16T00:51:43.862Z",
          "wordCount": null,
          "title": "Masked Siamese Networks for Label-Efficient Learning. (arXiv:2204.07141v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.13500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Hong Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Minghao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Chupeng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zongmin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">Xinhui Xue</a>",
          "description": "Model compression becomes a recent trend due to the requirement of deploying\nneural networks on embedded and mobile devices. Hence, both accuracy and\nefficiency are of critical importance. To explore a balance between them, a\nknowledge distillation strategy is proposed for general visual representation\nlearning. It utilizes our well-designed activation map adaptive module to\nreplace some blocks of the teacher network, exploring the most appropriate\nsupervisory features adaptively during the training process. Using the\nteacher's hidden layer output to prompt the student network to train so as to\ntransfer effective semantic information.To verify the effectiveness of our\nstrategy, this paper applied our method to cifar-10 dataset. Results\ndemonstrate that the method can boost the accuracy of the student network by\n0.6% with 6.5% loss reduction, and significantly improve its training speed.",
          "link": "http://arxiv.org/abs/2010.13500",
          "publishedOn": "2022-04-16T00:51:43.862Z",
          "wordCount": null,
          "title": "Activation Map Adaptation for Effective Knowledge Distillation. (arXiv:2010.13500v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Youngjin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_E/0/1/0/all/0/1\">Eugene Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yongjae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungwon Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1\">Jin-Woo Chung</a>",
          "description": "The hidden nature and the limited accessibility of the Dark Web, combined\nwith the lack of public datasets in this domain, make it difficult to study its\ninherent characteristics such as linguistic properties. Previous works on text\nclassification of Dark Web domain have suggested that the use of deep neural\nmodels may be ineffective, potentially due to the linguistic differences\nbetween the Dark and Surface Webs. However, not much work has been done to\nuncover the linguistic characteristics of the Dark Web. This paper introduces\nCoDA, a publicly available Dark Web dataset consisting of 10000 web documents\ntailored towards text-based Dark Web analysis. By leveraging CoDA, we conduct a\nthorough linguistic analysis of the Dark Web and examine the textual\ndifferences between the Dark Web and the Surface Web. We also assess the\nperformance of various methods of Dark Web page classification. Finally, we\ncompare CoDA with an existing public Dark Web dataset and evaluate their\nsuitability for various use cases.",
          "link": "http://arxiv.org/abs/2204.06885",
          "publishedOn": "2022-04-16T00:51:43.861Z",
          "wordCount": null,
          "title": "Shedding New Light on the Language of the Dark Web. (arXiv:2204.06885v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ardeshir_S/0/1/0/all/0/1\">Shervin Ardeshir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segalin_C/0/1/0/all/0/1\">Cristina Segalin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kallus_N/0/1/0/all/0/1\">Nathan Kallus</a>",
          "description": "In machine learning, disparity metrics are often defined by measuring the\ndifference in the performance or outcome of a model, across different\nsub-populations (groups) of datapoints. Thus, the inputs to disparity\nquantification consist of a model's predictions $\\hat{y}$, the ground-truth\nlabels for the predictions $y$, and group labels $g$ for the data points.\nPerformance of the model for each group is calculated by comparing $\\hat{y}$\nand $y$ for the datapoints within a specific group, and as a result, disparity\nof performance across the different groups can be calculated. In many real\nworld scenarios however, group labels ($g$) may not be available at scale\nduring training and validation time, or collecting them might not be feasible\nor desirable as they could often be sensitive information. As a result,\nevaluating disparity metrics across categorical groups would not be feasible.\nOn the other hand, in many scenarios noisy groupings may be obtainable using\nsome form of a proxy, which would allow measuring disparity metrics across\nsub-populations. Here we explore performing such analysis on computer vision\nmodels trained on human faces, and on tasks such as face attribute prediction\nand affect estimation. Our experiments indicate that embeddings resulting from\nan off-the-shelf face recognition model, could meaningfully serve as a proxy\nfor such estimation.",
          "link": "http://arxiv.org/abs/2204.06562",
          "publishedOn": "2022-04-16T00:51:43.859Z",
          "wordCount": null,
          "title": "Estimating Structural Disparities for Face Models. (arXiv:2204.06562v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.01299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kariyappa_S/0/1/0/all/0/1\">Sanjay Kariyappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qureshi_M/0/1/0/all/0/1\">Moinuddin K Qureshi</a>",
          "description": "Split learning is a popular technique used for vertical federated learning\n(VFL), where the goal is to jointly train a model on the private input and\nlabel data held by two parties. This technique uses a split-model, trained\nend-to-end, by exchanging the intermediate representations (IR) of the inputs\nand gradients of the IR between the two parties. We propose ExPLoit - a\nlabel-leakage attack that allows an adversarial input-owner to extract the\nprivate labels of the label-owner during split-learning. ExPLoit frames the\nattack as a supervised learning problem by using a novel loss function that\ncombines gradient-matching and several regularization terms developed using key\nproperties of the dataset and models. Our evaluations show that ExPLoit can\nuncover the private labels with near-perfect accuracy of up to 99.96%. Our\nfindings underscore the need for better training techniques for VFL.",
          "link": "http://arxiv.org/abs/2112.01299",
          "publishedOn": "2022-04-16T00:51:43.859Z",
          "wordCount": null,
          "title": "ExPLoit: Extracting Private Labels in Split Learning. (arXiv:2112.01299v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tien_J/0/1/0/all/0/1\">Jeremy Tien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jerry Zhi-Yang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erickson_Z/0/1/0/all/0/1\">Zackory Erickson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel Brown</a>",
          "description": "Learning robot policies via preference-based reward learning is an\nincreasingly popular method for customizing robot behavior. However, in recent\nyears, there has been a growing body of anecdotal evidence that learning reward\nfunctions from preferences is prone to spurious correlations and reward gaming\nor hacking behaviors. While there is much anecdotal, empirical, and theoretical\nanalysis of causal confusion and reward gaming behaviors both in reinforcement\nlearning and imitation learning approaches that directly map from states to\nactions, we provide the first systematic study of causal confusion in the\ncontext of learning reward functions from preferences. To facilitate this\nstudy, we identify a set of three preference learning benchmark domains where\nwe observe causal confusion when learning from offline datasets of pairwise\ntrajectory preferences: a simple reacher domain, an assistive feeding domain,\nand an itch-scratching domain. To gain insight into this observed causal\nconfusion, we present a sensitivity analysis that explores the effect of\ndifferent factors--including the type of training data, reward model capacity,\nand feature dimensionality--on the robustness of rewards learned from\npreferences. We find evidence that learning rewards from pairwise trajectory\npreferences is highly sensitive and non-robust to spurious features and\nincreasing model capacity, but not as sensitive to the type of training data.\nVideos, code, and supplemental results are available at\nhttps://sites.google.com/view/causal-reward-confusion.",
          "link": "http://arxiv.org/abs/2204.06601",
          "publishedOn": "2022-04-16T00:51:43.858Z",
          "wordCount": null,
          "title": "A Study of Causal Confusion in Preference-Based Reward Learning. (arXiv:2204.06601v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardmeier_C/0/1/0/all/0/1\">Christian Hardmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1\">Jes Frellsen</a>",
          "description": "A lot of Machine Learning (ML) and Deep Learning (DL) research is of an\nempirical nature. Nevertheless, statistical significance testing (SST) is still\nnot widely used. This endangers true progress, as seeming improvements over a\nbaseline might be statistical flukes, leading follow-up research astray while\nwasting human and computational resources. Here, we provide an easy-to-use\npackage containing different significance tests and utility functions\nspecifically tailored towards research needs and usability.",
          "link": "http://arxiv.org/abs/2204.06815",
          "publishedOn": "2022-04-16T00:51:43.814Z",
          "wordCount": null,
          "title": "deep-significance - Easy and Meaningful Statistical Significance Testing in the Age of Neural Networks. (arXiv:2204.06815v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.04788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1\">Hsiang Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1\">Mario Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "Disparate treatment occurs when a machine learning model yields different\ndecisions for individuals based on a sensitive attribute (e.g., age, sex). In\ndomains where prediction accuracy is paramount, it could potentially be\nacceptable to fit a model which exhibits disparate treatment. To evaluate the\neffect of disparate treatment, we compare the performance of split classifiers\n(i.e., classifiers trained and deployed separately on each group) with\ngroup-blind classifiers (i.e., classifiers which do not use a sensitive\nattribute). We introduce the benefit-of-splitting for quantifying the\nperformance improvement by splitting classifiers. Computing the\nbenefit-of-splitting directly from its definition could be intractable since it\ninvolves solving optimization problems over an infinite-dimensional functional\nspace. Under different performance measures, we (i) prove an equivalent\nexpression for the benefit-of-splitting which can be efficiently computed by\nsolving small-scale convex programs; (ii) provide sharp upper and lower bounds\nfor the benefit-of-splitting which reveal precise conditions where a\ngroup-blind classifier will always suffer from a non-trivial performance gap\nfrom the split classifiers. In the finite sample regime, splitting is not\nnecessarily beneficial and we provide data-dependent bounds to understand this\neffect. Finally, we validate our theoretical results through numerical\nexperiments on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2002.04788",
          "publishedOn": "2022-04-16T00:51:43.813Z",
          "wordCount": null,
          "title": "To Split or Not to Split: The Impact of Disparate Treatment in Classification. (arXiv:2002.04788v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.07963",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gassner_A/0/1/0/all/0/1\">Arthur Gassner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Musat_C/0/1/0/all/0/1\">Claudiu Musat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rusu_A/0/1/0/all/0/1\">Alexandru Rusu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burg_A/0/1/0/all/0/1\">Andreas Burg</a>",
          "description": "Many applications require accurate indoor localization. Fingerprint-based\nlocalization methods propose a solution to this problem, but rely on a radio\nmap that is effort-intensive to acquire. We automate the radio map acquisition\nphase using a software-defined radio (SDR) and a wheeled robot. Furthermore, we\nopen-source a radio map acquired with our automated tool for a 3GPP Long-Term\nEvolution (LTE) wireless link. To the best of our knowledge, this is the first\npublicly available radio map containing channel state information (CSI).\nFinally, we describe first localization experiments on this radio map using a\nconvolutional neural network to regress for location coordinates.",
          "link": "http://arxiv.org/abs/2104.07963",
          "publishedOn": "2022-04-16T00:51:43.811Z",
          "wordCount": null,
          "title": "OpenCSI: An Open-Source Dataset for Indoor Localization Using CSI-Based Fingerprinting. (arXiv:2104.07963v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07155",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_B/0/1/0/all/0/1\">Brice Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>",
          "description": "We consider the problem of quantum state certification, where we are given\nthe description of a mixed state $\\sigma \\in \\mathbb{C}^{d \\times d}$, $n$\ncopies of a mixed state $\\rho \\in \\mathbb{C}^{d \\times d}$, and $\\varepsilon >\n0$, and we are asked to determine whether $\\rho = \\sigma$ or whether $\\| \\rho -\n\\sigma \\|_1 > \\varepsilon$. When $\\sigma$ is the maximally mixed state\n$\\frac{1}{d} I_d$, this is known as mixedness testing. We focus on algorithms\nwhich use incoherent measurements, i.e. which only measure one copy of $\\rho$\nat a time. Unlike those that use entangled, multi-copy measurements, these can\nbe implemented without persistent quantum memory and thus represent a large\nclass of protocols that can be run on current or near-term devices.\n\nFor mixedness testing, there is a folklore algorithm which uses incoherent\nmeasurements and only needs $O(d^{3/2} / \\varepsilon^2)$ copies. The algorithm\nis non-adaptive, that is, its measurements are fixed ahead of time, and is\nknown to be optimal for non-adaptive algorithms. However, when the algorithm\ncan make arbitrary incoherent measurements, the best known lower bound is only\n$\\Omega (d^{4/3} / \\varepsilon^2)$ [Bubeck-Chen-Li '20], and it has been an\noutstanding open problem to close this polynomial gap. In this work, 1) we\nsettle the copy complexity of mixedness testing with incoherent measurements\nand show that $\\Omega (d^{3/2} / \\varepsilon^2)$ copies are necessary, and 2)\nwe show the instance-optimal bounds for state certification to general $\\sigma$\nfirst derived by [Chen-Li-O'Donnell '21] for non-adaptive measurements also\nhold for arbitrary incoherent measurements.\n\nQualitatively, our results say that adaptivity does not help at all for these\nproblems. Our results are based on new techniques that allow us to reduce the\nproblem to understanding certain matrix martingales, which we believe may be of\nindependent interest.",
          "link": "http://arxiv.org/abs/2204.07155",
          "publishedOn": "2022-04-16T00:51:43.809Z",
          "wordCount": null,
          "title": "Tight Bounds for Quantum State Certification with Incoherent Measurements. (arXiv:2204.07155v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Menon_R/0/1/0/all/0/1\">Rakesh R Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sayan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shashank Srivastava</a>",
          "description": "Supervised learning has traditionally focused on inductive learning by\nobserving labeled examples of a task. In contrast, humans have the ability to\nlearn new concepts from language. Here, we explore training zero-shot\nclassifiers for structured data purely from language. For this, we introduce\nCLUES, a benchmark for Classifier Learning Using natural language ExplanationS,\nconsisting of a range of classification tasks over structured data along with\nnatural language supervision in the form of explanations. CLUES consists of 36\nreal-world and 144 synthetic classification tasks. It contains crowdsourced\nexplanations describing real-world tasks from multiple teachers and\nprogrammatically generated explanations for the synthetic tasks. To model the\ninfluence of explanations in classifying an example, we develop ExEnt, an\nentailment-based model that learns classifiers using explanations. ExEnt\ngeneralizes up to 18% better (relative) on novel tasks than a baseline that\ndoes not use explanations. We delineate key challenges for automated learning\nfrom explanations, addressing which can lead to progress on CLUES in the\nfuture. Code and datasets are available at: https://clues-benchmark.github.io.",
          "link": "http://arxiv.org/abs/2204.07142",
          "publishedOn": "2022-04-16T00:51:43.808Z",
          "wordCount": null,
          "title": "CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations. (arXiv:2204.07142v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.07259",
          "author": "<a href=\"http://arxiv.org/find/nlin/1/au:+Barfuss_W/0/1/0/all/0/1\">Wolfram Barfuss</a>, <a href=\"http://arxiv.org/find/nlin/1/au:+Mann_R/0/1/0/all/0/1\">Richard P. Mann</a>",
          "description": "Assessing the systemic effects of uncertainty that arises from agents'\npartial observation of the true states of the world is critical for\nunderstanding a wide range of scenarios. Yet, previous modeling work on agent\nlearning and decision-making either lacks a systematic way to describe this\nsource of uncertainty or puts the focus on obtaining optimal policies using\ncomplex models of the world that would impose an unrealistically high cognitive\ndemand on real agents. In this work we aim to efficiently describe the emergent\nbehavior of biologically plausible and parsimonious learning agents faced with\npartially observable worlds. Therefore we derive and present deterministic\nreinforcement learning dynamics where the agents observe the true state of the\nenvironment only partially. We showcase the broad applicability of our dynamics\nacross different classes of partially observable agent-environment systems. We\nfind that partial observability creates unintuitive benefits in a number of\nspecific contexts, pointing the way to further research on a general\nunderstanding of such effects. For instance, partially observant agents can\nlearn better outcomes faster, in a more stable way and even overcome social\ndilemmas. Furthermore, our method allows the application of dynamical systems\ntheory to partially observable multiagent leaning. In this regard we find the\nemergence of catastrophic limit cycles, a critical slowing down of the learning\nprocesses between reward regimes and the separation of the learning dynamics\ninto fast and slow directions, all caused by partial observability. Therefore,\nthe presented dynamics have the potential to become a formal, yet practical,\nlightweight and robust tool for researchers in biology, social science and\nmachine learning to systematically investigate the effects of interacting\npartially observant agents.",
          "link": "http://arxiv.org/abs/2109.07259",
          "publishedOn": "2022-04-16T00:51:43.808Z",
          "wordCount": null,
          "title": "Modeling the effects of environmental and perceptual uncertainty using deterministic reinforcement learning dynamics with partial observability. (arXiv:2109.07259v2 [nlin.AO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tariq_A/0/1/0/all/0/1\">Amara Tariq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunnmon_J/0/1/0/all/0/1\">Jared Dunnmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_U/0/1/0/all/0/1\">Umesh Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elugunti_P/0/1/0/all/0/1\">Praneetha Elugunti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_B/0/1/0/all/0/1\">Bhavik N. Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_I/0/1/0/all/0/1\">Imon Banerjee</a>",
          "description": "Measures to predict 30-day readmission are considered an important quality\nfactor for hospitals as accurate predictions can reduce the overall cost of\ncare by identifying high risk patients before they are discharged. While recent\ndeep learning-based studies have shown promising empirical results on\nreadmission prediction, several limitations exist that may hinder widespread\nclinical utility, such as (a) only patients with certain conditions are\nconsidered, (b) existing approaches do not leverage data temporality, (c)\nindividual admissions are assumed independent of each other, which is\nunrealistic, (d) prior studies are usually limited to single source of data and\nsingle center data. To address these limitations, we propose a multimodal,\nmodality-agnostic spatiotemporal graph neural network (MM-STGNN) for prediction\nof 30-day all-cause hospital readmission that fuses multimodal in-patient\nlongitudinal data. By training and evaluating our methods using longitudinal\nchest radiographs and electronic health records from two independent centers,\nwe demonstrate that MM-STGNN achieves AUROC of 0.79 on both primary and\nexternal datasets. Furthermore, MM-STGNN significantly outperforms the current\nclinical reference standard, LACE+ score (AUROC=0.61), on the primary dataset.\nFor subset populations of patients with heart and vascular disease, our model\nalso outperforms baselines on predicting 30-day readmission (e.g., 3.7 point\nimprovement in AUROC in patients with heart disease). Lastly, qualitative model\ninterpretability analysis indicates that while patients' primary diagnoses were\nnot explicitly used to train the model, node features crucial for model\nprediction directly reflect patients' primary diagnoses. Importantly, our\nMM-STGNN is agnostic to node feature modalities and could be utilized to\nintegrate multimodal data for triaging patients in various downstream resource\nallocation tasks.",
          "link": "http://arxiv.org/abs/2204.06766",
          "publishedOn": "2022-04-16T00:51:43.807Z",
          "wordCount": null,
          "title": "Multimodal spatiotemporal graph neural networks for improved prediction of 30-day all-cause hospital readmission. (arXiv:2204.06766v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moyer_E/0/1/0/all/0/1\">Ethan Jacob Moyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augustin_A/0/1/0/all/0/1\">Alisha Isabelle Augustin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Satvik Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dholakia_A/0/1/0/all/0/1\">Ansh Aashish Dholakia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Andy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isozaki_I/0/1/0/all/0/1\">Isamu Mclean Isozaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_D/0/1/0/all/0/1\">Daniel Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Edward Kim</a>",
          "description": "In this work, we highlight our novel evolutionary sparse time-series\nforecasting algorithm also known as EvoSTS. The algorithm attempts to\nevolutionary prioritize weights of Long Short-Term Memory (LSTM) Network that\nbest minimize the reconstruction loss of a predicted signal using a learned\nsparse coded dictionary. In each generation of our evolutionary algorithm, a\nset number of children with the same initial weights are spawned. Each child\nundergoes a training step and adjusts their weights on the same data. Due to\nstochastic back-propagation, the set of children has a variety of weights with\ndifferent levels of performance. The weights that best minimize the\nreconstruction loss with a given signal dictionary are passed to the next\ngeneration. The predictions from the best-performing weights of the first and\nlast generation are compared. We found improvements while comparing the weights\nof these two generations. However, due to several confounding parameters and\nhyperparameter limitations, some of the weights had negligible improvements. To\nthe best of our knowledge, this is the first attempt to use sparse coding in\nthis way to optimize time series forecasting model weights, such as those of an\nLSTM network.",
          "link": "http://arxiv.org/abs/2204.07066",
          "publishedOn": "2022-04-16T00:51:43.807Z",
          "wordCount": null,
          "title": "EvoSTS Forecasting: Evolutionary Sparse Time-Series Forecasting. (arXiv:2204.07066v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pedemonte_S/0/1/0/all/0/1\">Stefano Pedemonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsue_T/0/1/0/all/0/1\">Trevor Tsue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mombourquette_B/0/1/0/all/0/1\">Brent Mombourquette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_Y/0/1/0/all/0/1\">Yen Nhi Truong Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthews_T/0/1/0/all/0/1\">Thomas Matthews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoil_R/0/1/0/all/0/1\">Rodrigo Morales Hoil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Meet Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghare_N/0/1/0/all/0/1\">Nikita Ghare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zingman_Daniels_N/0/1/0/all/0/1\">Naomi Zingman-Daniels</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holley_S/0/1/0/all/0/1\">Susan Holley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appleton_C/0/1/0/all/0/1\">Catherine M. Appleton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jason Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wahl_R/0/1/0/all/0/1\">Richard L. Wahl</a>",
          "description": "Screening mammography improves breast cancer outcomes by enabling early\ndetection and treatment. However, false positive callbacks for additional\nimaging from screening exams cause unnecessary procedures, patient anxiety, and\nfinancial burden. This work demonstrates an AI algorithm that reduces false\npositives by identifying mammograms not suspicious for breast cancer. We\ntrained the algorithm to determine the absence of cancer using 123,248 2D\ndigital mammograms (6,161 cancers) and performed a retrospective study on\n14,831 screening exams (1,026 cancers) from 15 US and 3 UK sites. Retrospective\nevaluation of the algorithm on the largest of the US sites (11,592 mammograms,\n101 cancers) a) left the cancer detection rate unaffected (p=0.02,\nnon-inferiority margin 0.25 cancers per 1000 exams), b) reduced callbacks for\ndiagnostic exams by 31.1% compared to standard clinical readings, c) reduced\nbenign needle biopsies by 7.4%, and d) reduced screening exams requiring\nradiologist interpretation by 41.6% in the simulated clinical workflow. This\nwork lays the foundation for semi-autonomous breast cancer screening systems\nthat could benefit patients and healthcare systems by reducing false positives,\nunnecessary procedures, patient anxiety, and expenses.",
          "link": "http://arxiv.org/abs/2204.06671",
          "publishedOn": "2022-04-16T00:51:43.806Z",
          "wordCount": null,
          "title": "A deep learning algorithm for reducing false positives in screening mammography. (arXiv:2204.06671v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mak_T/0/1/0/all/0/1\">Tiffany T.W. Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaopu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ip_N/0/1/0/all/0/1\">Nancy Y. Ip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Self-supervised pre-training methods have brought remarkable breakthroughs in\nthe understanding of text, image, and speech. Recent developments in genomics\nhas also adopted these pre-training methods for genome understanding. However,\nthey focus only on understanding haploid sequences, which hinders their\napplicability towards understanding genetic variations, also known as single\nnucleotide polymorphisms (SNPs), which is crucial for genome-wide association\nstudy. In this paper, we introduce SNP2Vec, a scalable self-supervised\npre-training approach for understanding SNP. We apply SNP2Vec to perform\nlong-sequence genomics modeling, and we evaluate the effectiveness of our\napproach on predicting Alzheimer's disease risk in a Chinese cohort. Our\napproach significantly outperforms existing polygenic risk score methods and\nall other baselines, including the model that is trained entirely with haploid\nsequences. We release our code and dataset on\nhttps://github.com/HLTCHKUST/snp2vec.",
          "link": "http://arxiv.org/abs/2204.06699",
          "publishedOn": "2022-04-16T00:51:43.806Z",
          "wordCount": null,
          "title": "SNP2Vec: Scalable Self-Supervised Pre-Training for Genome-Wide Association Study. (arXiv:2204.06699v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1903.09668",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yuexi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Polson_N/0/1/0/all/0/1\">Nicholas G. Polson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolov_V/0/1/0/all/0/1\">Vadim O. Sokolov</a>",
          "description": "Deep Learning (DL) methods have emerged as one of the most powerful tools for\nfunctional approximation and prediction. While the representation properties of\nDL have been well studied, uncertainty quantification remains challenging and\nlargely unexplored. Data augmentation techniques are a natural approach to\nprovide uncertainty quantification and to incorporate stochastic Monte Carlo\nsearch into stochastic gradient descent (SGD) methods. The purpose of our paper\nis to show that training DL architectures with data augmentation leads to\nefficiency gains. We use the theory of scale mixtures of normals to derive data\naugmentation strategies for deep learning. This allows variants of the\nexpectation-maximization and MCMC algorithms to be brought to bear on these\nhigh dimensional nonlinear deep learning models. To demonstrate our\nmethodology, we develop data augmentation algorithms for a variety of commonly\nused activation functions: logit, ReLU, leaky ReLU and SVM. Our methodology is\ncompared to traditional stochastic gradient descent with back-propagation. Our\noptimization procedure leads to a version of iteratively re-weighted least\nsquares and can be implemented at scale with accelerated linear algebra methods\nproviding substantial improvement in speed. We illustrate our methodology on a\nnumber of standard datasets. Finally, we conclude with directions for future\nresearch.",
          "link": "http://arxiv.org/abs/1903.09668",
          "publishedOn": "2022-04-16T00:51:43.805Z",
          "wordCount": null,
          "title": "Data Augmentation for Bayesian Deep Learning. (arXiv:1903.09668v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.08988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1\">Tunazzina Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_D/0/1/0/all/0/1\">Dan Goldwasser</a>",
          "description": "Social media platforms provide convenient means for users to participate in\nmultiple online activities on various contents and create fast widespread\ninteractions. However, this rapidly growing access has also increased the\ndiverse information, and characterizing user types to understand people's\nlifestyle decisions shared in social media is challenging. In this paper, we\npropose a weakly supervised graph embedding based framework for understanding\nuser types. We evaluate the user embedding learned using weak supervision over\nwell-being related tweets from Twitter, focusing on 'Yoga', 'Keto diet'.\nExperiments on real-world datasets demonstrate that the proposed framework\noutperforms the baselines for detecting user types. Finally, we illustrate data\nanalysis on different types of users (e.g., practitioner vs. promotional) from\nour dataset. While we focus on lifestyle-related tweets (i.e., yoga, keto), our\nmethod for constructing user representation readily generalizes to other\ndomains.",
          "link": "http://arxiv.org/abs/2108.08988",
          "publishedOn": "2022-04-16T00:51:43.805Z",
          "wordCount": null,
          "title": "Twitter User Representation Using Weakly Supervised Graph Embedding. (arXiv:2108.08988v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Doumanidis_C/0/1/0/all/0/1\">Constantine Doumanidis</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Rajput_P/0/1/0/all/0/1\">Prashant Hari Narayan Rajput</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Maniatakos_M/0/1/0/all/0/1\">Michail Maniatakos</a> (1) ((1) New York University Abu Dhabi, (2) NYU Tandon School of Engineering)",
          "description": "Industrial Control Systems (ICS) have played a catalytic role in enabling the\n4th Industrial Revolution. ICS devices like Programmable Logic Controllers\n(PLCs), automate, monitor, and control critical processes in industrial,\nenergy, and commercial environments. The convergence of traditional Operational\nTechnology (OT) with Information Technology (IT) has opened a new and unique\nthreat landscape. This has inspired defense research that focuses heavily on\nMachine Learning (ML) based anomaly detection methods that run on external IT\nhardware, which means an increase in costs and the further expansion of the\nthreat landscape. To remove this requirement, we introduce the ICS machine\nlearning inference framework (ICSML) which enables the execution of ML model\ninference natively on the PLC. ICSML is implemented in IEC 61131-3 code and\nprovides several optimizations to bypass the limitations imposed by the\ndomain-specific languages. Therefore, it works \\emph{on every PLC without the\nneed for vendor support}. ICSML provides a complete set of components for the\ncreation of full ML models similarly to established ML frameworks. We run a\nseries of benchmarks studying memory and performance and compare our solution\nto the TFLite inference framework. At the same time, we develop domain-specific\nmodel optimizations to improve the efficiency of ICSML. To demonstrate the\nabilities of ICSML, we evaluate a case study of a real defense for\nprocess-aware attacks targeting a desalination plant.",
          "link": "http://arxiv.org/abs/2202.10075",
          "publishedOn": "2022-04-16T00:51:43.804Z",
          "wordCount": null,
          "title": "ICSML: Industrial Control Systems Machine Learning Inference Framework natively executing on IEC 61131-3 compliant devices. (arXiv:2202.10075v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindstaahl_S/0/1/0/all/0/1\">Simon Lindst&#xe5;hl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Proutiere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1\">Andreas Jonsson</a>",
          "description": "In sliced networks, the shared tenancy of slices requires adaptive admission\ncontrol of data flows, based on measurements of network resources. In this\npaper, we investigate the design of measurement-based admission control\nschemes, deciding whether a new data flow can be admitted and in this case, on\nwhich slice. The objective is to devise a joint measurement and decision\nstrategy that returns a correct decision (e.g., the least loaded slice) with a\ncertain level of confidence while minimizing the measurement cost (the number\nof measurements made before committing to the decision). We study the design of\nsuch strategies for several natural admission criteria specifying what a\ncorrect decision is. For each of these criteria, using tools from best arm\nidentification in bandits, we first derive an explicit information-theoretical\nlower bound on the cost of any algorithm returning the correct decision with\nfixed confidence. We then devise a joint measurement and decision strategy\nachieving this theoretical limit. We compare empirically the measurement costs\nof these strategies, and compare them both to the lower bounds as well as a\nnaive measurement scheme. We find that our algorithm significantly outperforms\nthe naive scheme (by a factor $2-8$).",
          "link": "http://arxiv.org/abs/2204.06910",
          "publishedOn": "2022-04-16T00:51:43.799Z",
          "wordCount": null,
          "title": "Measurement-based Admission Control in Sliced Networks: A Best Arm Identification Approach. (arXiv:2204.06910v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wedler_M/0/1/0/all/0/1\">Mathies Wedler</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Stender_M/0/1/0/all/0/1\">Merten Stender</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Klein_M/0/1/0/all/0/1\">Marco Klein</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ehlers_S/0/1/0/all/0/1\">Svenja Ehlers</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_N/0/1/0/all/0/1\">Norbert Hoffmann</a> (1 and 2) ((1) Hamburg University of Technology, (2) Imperial College London)",
          "description": "Supervised machine learning approaches require the formulation of a loss\nfunctional to be minimized in the training phase. Sequential data are\nubiquitous across many fields of research, and are often treated with Euclidean\ndistance-based loss functions that were designed for tabular data. For smooth\noscillatory data, those conventional approaches lack the ability to penalize\namplitude, frequency and phase prediction errors at the same time, and tend to\nbe biased towards amplitude errors. We introduce the surface similarity\nparameter (SSP) as a novel loss function that is especially useful for training\nmachine learning models on smooth oscillatory sequences. Our extensive\nexperiments on chaotic spatio-temporal dynamical systems indicate that the SSP\nis beneficial for shaping gradients, thereby accelerating the training process,\nreducing the final prediction error, and implementing a stronger regularization\neffect compared to using classical loss functions. The results indicate the\npotential of the novel loss metric particularly for highly complex and chaotic\ndata, such as data stemming from the nonlinear two-dimensional\nKuramoto-Sivashinsky equation and the linear propagation of dispersive surface\ngravity waves in fluids.",
          "link": "http://arxiv.org/abs/2204.06843",
          "publishedOn": "2022-04-16T00:51:43.796Z",
          "wordCount": null,
          "title": "Surface Similarity Parameter: A New Machine Learning Loss Metric for Oscillatory Spatio-Temporal Data. (arXiv:2204.06843v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Sheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qingxiang Liu</a>",
          "description": "Federated learning (FL) is a distributed machine learning paradigm in which\nthe server periodically aggregates local model parameters from clients without\nassembling their private data. User-constrained communication bandwidth and the\nrequirement for personalized models pose severe challenges to FL. Federated\ndistillation (FD) is proposed to simultaneously address the two problems, which\nexchanges knowledge between the server and clients, supporting heterogeneous\nlocal models while significantly reducing communication overhead. However, most\nexisting FD methods require a proxy dataset, which is often unavailable.\nProxy-data-free FD approaches eliminate the need for additional public data\nbeyond clients' private data, but suffer from remarkable discrepancy among\nlocal knowledge due to model heterogeneity, leading to ambiguous representation\non the server and inevitable accuracy degradation. To tackle this issue, we\npropose a proxy-data-free FD algorithm based on distributed knowledge\ncongruence (FedDKC). FedDKC leverages well-designed refinement strategies to\nnarrow local knowledge differences into an acceptable upper bound to mitigate\nthe negative effects of knowledge incongruence. Specifically, from perspectives\nof peak probability and Shannon entropy of local knowledge, we design\nkernel-based knowledge refinement (KKR) and searching-based knowledge\nrefinement (SKR) respectively, and theoretically guarantee the refined-local\nknowledge can satisfy an approximately-similar distribution and be regarded as\ncongruent. Extensive experiments conducted on three common datasets demonstrate\nthat our proposed FedDKC method outperforms the state-of-the-art in 93.33% of\ncomparisons, and achieves faster convergence without increasing communication\noverhead.",
          "link": "http://arxiv.org/abs/2204.07028",
          "publishedOn": "2022-04-16T00:51:43.796Z",
          "wordCount": null,
          "title": "Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation. (arXiv:2204.07028v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wysocki_O/0/1/0/all/0/1\">Oskar Wysocki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davies_J/0/1/0/all/0/1\">Jessica Katharine Davies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vigo_M/0/1/0/all/0/1\">Markel Vigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armstrong_A/0/1/0/all/0/1\">Anne Caroline Armstrong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">D&#xf3;nal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Rebecca Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andr&#xe9; Freitas</a>",
          "description": "This paper contributes with a pragmatic evaluation framework for explainable\nMachine Learning (ML) models for clinical decision support. The study revealed\na more nuanced role for ML explanation models, when these are pragmatically\nembedded in the clinical context. Despite the general positive attitude of\nhealthcare professionals (HCPs) towards explanations as a safety and trust\nmechanism, for a significant set of participants there were negative effects\nassociated with confirmation bias, accentuating model over-reliance and\nincreased effort to interact with the model. Also, contradicting one of its\nmain intended functions, standard explanatory models showed limited ability to\nsupport a critical understanding of the limitations of the model. However, we\nfound new significant positive effects which repositions the role of\nexplanations within a clinical context: these include reduction of automation\nbias, addressing ambiguous clinical cases (cases where HCPs were not certain\nabout their decision) and support of less experienced HCPs in the acquisition\nof new domain knowledge.",
          "link": "http://arxiv.org/abs/2204.05030",
          "publishedOn": "2022-04-16T00:51:43.795Z",
          "wordCount": null,
          "title": "Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making. (arXiv:2204.05030v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skenderi_G/0/1/0/all/0/1\">Geri Skenderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joppi_C/0/1/0/all/0/1\">Christian Joppi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denitto_M/0/1/0/all/0/1\">Matteo Denitto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarpa_B/0/1/0/all/0/1\">Berniero Scarpa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cristani_M/0/1/0/all/0/1\">Marco Cristani</a>",
          "description": "We present Visuelle 2.0, the first dataset useful for facing diverse\nprediction problems that a fast-fashion company has to manage routinely.\nFurthermore, we demonstrate how the use of computer vision is substantial in\nthis scenario. Visuelle 2.0 contains data for 6 seasons / 5355 clothing\nproducts of Nuna Lie, a famous Italian company with hundreds of shops located\nin different areas within the country. In particular, we focus on a specific\nprediction problem, namely short-observation new product sale forecasting\n(SO-fore). SO-fore assumes that the season has started and a set of new\nproducts is on the shelves of the different stores. The goal is to forecast the\nsales for a particular horizon, given a short, available past (few weeks),\nsince no earlier statistics are available. To be successful, SO-fore approaches\nshould capture this short past and exploit other modalities or exogenous data.\nTo these aims, Visuelle 2.0 is equipped with disaggregated data at the\nitem-shop level and multi-modal information for each clothing item, allowing\ncomputer vision approaches to come into play. The main message that we deliver\nis that the use of image data with deep networks boosts performances obtained\nwhen using the time series in long-term forecasting scenarios, ameliorating the\nWAPE by 8.2% and the MAE by 7.7%. The dataset is available at:\nhttps://humaticslab.github.io/forecasting/visuelle.",
          "link": "http://arxiv.org/abs/2204.06972",
          "publishedOn": "2022-04-16T00:51:43.772Z",
          "wordCount": null,
          "title": "The multi-modal universe of fast-fashion: the Visuelle 2.0 benchmark. (arXiv:2204.06972v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.13669",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herrera_C/0/1/0/all/0/1\">Calypso Herrera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krach_F/0/1/0/all/0/1\">Florian Krach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruyssen_P/0/1/0/all/0/1\">Pierre Ruyssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1\">Josef Teichmann</a>",
          "description": "This paper presents new machine learning approaches to approximate the\nsolutions of optimal stopping problems. The key idea of these methods is to use\nneural networks, where the parameters of the hidden layers are generated\nrandomly and only the last layer is trained, in order to approximate the\ncontinuation value. Our approaches are applicable to high dimensional problems\nwhere the existing approaches become increasingly impractical. In addition,\nsince our approaches can be optimized using simple linear regression, they are\neasy to implement and theoretical guarantees are provided. Our randomized\nreinforcement learning approach and randomized recurrent neural network\napproach outperform the state-of-the-art and other relevant machine learning\napproaches in Markovian and non-Markovian examples, respectively. In\nparticular, we test our approaches on Black-Scholes, Heston, rough Heston and\nfractional Brownian motion. Moreover, we show that they can also be used to\nefficiently compute Greeks of American options.",
          "link": "http://arxiv.org/abs/2104.13669",
          "publishedOn": "2022-04-16T00:51:43.772Z",
          "wordCount": null,
          "title": "Optimal Stopping via Randomized Neural Networks. (arXiv:2104.13669v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.06663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1\">Vinod Kumar Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sukhdeep Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Anuj Sharma</a>",
          "description": "Despite being studied extensively for a few decades, handwritten character\nrecognition (HCR) is considered a challenging learning problem in pattern\nrecognition and there is very limited research on script independent models.\nThis is mainly because of diversity of scripts, focus of the conventional\nresearch on handcrafted feature extraction techniques, and unavailability of\npublic datasets and codes to reproduce the results. On the other hand, deep\nlearning has witnessed huge success in different areas of pattern recognition,\nincluding HCR, and provides end-to-end learning but it has been studied for\nspecific scripts only. In this paper, we have proposed a novel deep learning\narchitecture which exploits transfer learning and image-augmentation for\nend-to-end learning for script independent handwritten character recognition,\ncalled HCR-Net. HCR-Net is based on a novel transfer learning approach for HCR,\nwhere some of lower layers of a pre-trained network are utilized. Due to\ntransfer learning and image-augmentation, HCR-Net provides faster training,\nbetter performance and better generalizations, and can achieve up to 99\\%\nresults of its final accuracy in just first epoch. The experimental results on\npublicly available datasets of Bangla, Punjabi, Hindi, English, Swedish, Urdu,\nFarsi, Tibetan, Kannada, Malayalam, Telugu, Marathi, Nepali and Arabic\nlanguages prove the efficacy of HCR-Net and establishes several new benchmarks.\nFor reproducibility of the results and for the advancements of the HCR\nresearch, complete code is publicly released at\nhttps://github.com/jmdvinodjmd/HCR-Net.",
          "link": "http://arxiv.org/abs/2108.06663",
          "publishedOn": "2022-04-16T00:51:43.771Z",
          "wordCount": null,
          "title": "HCR-Net: A deep learning based script independent handwritten character recognition network. (arXiv:2108.06663v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03894",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yen_H/0/1/0/all/0/1\">Hao Yen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ku_P/0/1/0/all/0/1\">Pin-Jui Ku</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_H/0/1/0/all/0/1\">Hu Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Siniscalchi_S/0/1/0/all/0/1\">Sabato Marco Siniscalchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "In this study, we propose a novel adversarial reprogramming (AR) approach for\nlow-resource spoken command recognition (SCR), and build an AR-SCR system. The\nAR procedure aims to modify the acoustic signals (from the target domain) to\nrepurpose a pretrained SCR model (from the source domain). To solve the label\nmismatches between source and target domains, and further improve the stability\nof AR, we propose a novel similarity-based label mapping technique to align\nclasses. In addition, the transfer learning (TL) technique is combined with the\noriginal AR process to improve the model adaptation capability. We evaluate the\nproposed AR-SCR system on three low-resource SCR datasets, including Arabic,\nLithuanian, and dysarthric Mandarin speech. Experimental results show that with\na pretrained AM trained on a large-scale English dataset, the proposed AR-SCR\nsystem outperforms the current state-of-the-art results on Arabic and\nLithuanian speech commands datasets, with only a limited amount of training\ndata.",
          "link": "http://arxiv.org/abs/2110.03894",
          "publishedOn": "2022-04-16T00:51:43.771Z",
          "wordCount": null,
          "title": "A Study of Low-Resource Speech Commands Recognition based on Adversarial Reprogramming. (arXiv:2110.03894v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.06246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "Making an informed decision -- for example, when choosing a career or housing\n-- requires knowledge about the available options. Such knowledge is generally\nacquired through costly trial and error, but this learning process can be\ndisrupted by competition. In this work, we study how competition affects the\nlong-term outcomes of individuals as they learn. We build on a line of work\nthat models this setting as a two-sided matching market with bandit learners. A\nrecent result in this area states that it is impossible to simultaneously\nguarantee two natural desiderata: stability and low optimal regret for all\nagents. Resource-allocating platforms can point to this result as a\njustification for assigning good long-term outcomes to some agents and poor\nones to others. We show that this impossibility need not hold true. In\nparticular, by modeling two additional components of competition -- namely,\ncosts and transfers -- we prove that it is possible to simultaneously guarantee\nfour desiderata: stability, low optimal regret, fairness in the distribution of\nregret, and high social welfare.",
          "link": "http://arxiv.org/abs/2102.06246",
          "publishedOn": "2022-04-16T00:51:43.751Z",
          "wordCount": null,
          "title": "Regret, stability & fairness in matching markets with bandit learners. (arXiv:2102.06246v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.08746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tekgul_B/0/1/0/all/0/1\">Buse G. A. Tekgul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shelly Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchal_S/0/1/0/all/0/1\">Samuel Marchal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asokan_N/0/1/0/all/0/1\">N. Asokan</a>",
          "description": "Recent work has shown that deep reinforcement learning (DRL) policies are\nvulnerable to adversarial perturbations. Adversaries can mislead policies of\nDRL agents by perturbing the state of the environment observed by the agents.\nExisting attacks are feasible in principle but face challenges in practice,\neither by being too slow to fool DRL policies in real time or by modifying past\nobservations stored in the agent's memory. We show that using the Universal\nAdversarial Perturbation (UAP) method to compute perturbations, independent of\nthe individual inputs to which they are applied to, can fool DRL policies\neffectively and in real time. We describe three such attack variants. Via an\nextensive evaluation using three Atari 2600 games, we show that our attacks are\neffective, as they fully degrade the performance of three different DRL agents\n(up to 100%, even when the $l_\\infty$ bound on the perturbation is as small as\n0.01). It is faster compared to the response time (0.6ms on average) of\ndifferent DRL policies, and considerably faster than prior attacks using\nadversarial perturbations (1.8ms on average). We also show that our attack\ntechnique is efficient, incurring an online computational cost of 0.027ms on\naverage. Using two further tasks involving robotic movement, we confirm that\nour results generalize to more complex DRL tasks. Furthermore, we demonstrate\nthat the effectiveness of known defenses diminishes against universal\nperturbations. We propose an effective technique that detects all known\nadversarial perturbations against DRL policies, including all the universal\nperturbations presented in this paper.",
          "link": "http://arxiv.org/abs/2106.08746",
          "publishedOn": "2022-04-16T00:51:43.737Z",
          "wordCount": null,
          "title": "Real-time Adversarial Perturbations against Deep Reinforcement Learning Policies: Attacks and Defenses. (arXiv:2106.08746v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsilivis_N/0/1/0/all/0/1\">Nikolaos Tsilivis</a>",
          "description": "One way to interpret the behavior of a blackbox recurrent neural network\n(RNN) is to extract from it a more interpretable discrete computational model,\nlike a finite state machine, that captures its behavior. In this work, we\npropose a new method for extracting finite automata from RNNs inspired by the\nstate merging paradigm from grammatical inference. We demonstrate the\neffectiveness of our method on the Tomita languages benchmark, where we find\nthat it is able to extract faithful automata from RNNs trained on all languages\nin the benchmark. We find that extraction performance is aided by the number of\ndata provided during the extraction process, as well as, curiously, whether the\nRNN model is trained for additional epochs after perfectly learning its target\nlanguage. We use our method to analyze this phenomenon, finding that training\nbeyond convergence is useful because it leads to compression of the internal\nstate space of the RNN. This finding demonstrates how our method can be used\nfor interpretability and analysis of trained RNN models.",
          "link": "http://arxiv.org/abs/2201.12451",
          "publishedOn": "2022-04-16T00:51:43.737Z",
          "wordCount": null,
          "title": "Extracting Finite Automata from RNNs Using State Merging. (arXiv:2201.12451v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.03312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_D/0/1/0/all/0/1\">Duyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Cong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuangzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>",
          "description": "Prevailing deep models are single-purpose and overspecialize at individual\ntasks. However, when being extended to new tasks, they typically forget\npreviously learned skills and learn from scratch. We address this issue by\nintroducing SkillNet, a general-purpose model that stitches together existing\nskills to learn new tasks more effectively. The key feature of our approach is\nthat it is sparsely activated guided by predefined skills. Different from\ntraditional dense models that always activate all the model parameters,\nSkillNet only activates parts of the model parameters whose skills are relevant\nto the target task. When learning for a new task, our approach precisely\nactivates required skills and also provides an option to add new skills. We\nevaluate on natural language understandings tasks and have the following\nfindings. First, with only one model checkpoint, SkillNet performs better than\ntask-specific fine-tuning and two multi-task learning baselines (i.e., dense\nmodel and Mixture-of-Experts model) on six tasks. Second, sparsely activated\npre-training further improves the overall performance. Third, SkillNet\nsignificantly outperforms baseline systems when being extended to new tasks.",
          "link": "http://arxiv.org/abs/2203.03312",
          "publishedOn": "2022-04-16T00:51:43.736Z",
          "wordCount": null,
          "title": "SkillNet: A Sparsely Activated Model for General-Purpose Natural Language Understanding. (arXiv:2203.03312v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_P/0/1/0/all/0/1\">Pengyue Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_D/0/1/0/all/0/1\">Dandan Lyu</a>",
          "description": "Predicting the number of infections in the anti-epidemic process is extremely\nbeneficial to the government in developing anti-epidemic strategies, especially\nin fine-grained geographic units. Previous works focus on low spatial\nresolution prediction, e.g., county-level, and preprocess data to the same\ngeographic level, which loses some useful information. In this paper, we\npropose a fine-grained population mobility data-based model (FGC-COVID)\nutilizing data of two geographic levels for community-level COVID-19\nprediction. We use the population mobility data between Census Block Groups\n(CBGs), which is a finer-grained geographic level than community, to build the\ngraph and capture the dependencies between CBGs using graph neural networks\n(GNNs). To mine as finer-grained patterns as possible for prediction, a spatial\nweighted aggregation module is introduced to aggregate the embeddings of CBGs\nto community level based on their geographic affiliation and spatial\nautocorrelation. Extensive experiments on 300 days LA city COVID-19 data\nindicate our model outperforms existing forecasting models on community-level\nCOVID-19 prediction.",
          "link": "http://arxiv.org/abs/2202.06257",
          "publishedOn": "2022-04-16T00:51:43.731Z",
          "wordCount": null,
          "title": "Fine-Grained Population Mobility Data-Based Community-Level COVID-19 Prediction Model. (arXiv:2202.06257v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.11234",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Diethe_T/0/1/0/all/0/1\">Tom Diethe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flach_P/0/1/0/all/0/1\">Peter Flach</a>",
          "description": "The use of episodic memory in continual learning has demonstrated\neffectiveness for alleviating catastrophic forgetting. In recent studies,\ngradient-based approaches have been developed to make more efficient use of\ncompact episodic memory. Such approaches refine the gradients resulting from\nnew samples by those from memorized samples, aiming to reduce the diversity of\ngradients from different tasks. In this paper, we clarify the relation between\ndiversity of gradients and discriminativeness of representations, showing\nshared as well as conflicting interests between Deep Metric Learning and\ncontinual learning, thus demonstrating pros and cons of learning discriminative\nrepresentations in continual learning. Based on these findings, we propose a\nsimple method -- Semi-Discriminative Representation Loss (SDRL) -- for\ncontinual learning. In comparison with state-of-the-art methods, SDRL shows\nbetter performance with low computational cost on multiple benchmark tasks in\nthe setting of online continual learning.",
          "link": "http://arxiv.org/abs/2006.11234",
          "publishedOn": "2022-04-16T00:51:43.712Z",
          "wordCount": null,
          "title": "Semi-Discriminative Representation Loss for Online Continual Learning. (arXiv:2006.11234v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14798",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Fang_L/0/1/0/all/0/1\">Lidong Fang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ge_P/0/1/0/all/0/1\">Pei Ge</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+E_W/0/1/0/all/0/1\">Weinan E</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lei_H/0/1/0/all/0/1\">Huan Lei</a>",
          "description": "A long standing problem in the modeling of non-Newtonian hydrodynamics of\npolymeric flows is the availability of reliable and interpretable hydrodynamic\nmodels that faithfully encode the underlying micro-scale polymer dynamics. The\nmain complication arises from the long polymer relaxation time, the complex\nmolecular structure and heterogeneous interaction. DeePN$^2$, a deep\nlearning-based non-Newtonian hydrodynamic model, has been proposed and has\nshown some success in systematically passing the micro-scale structural\nmechanics information to the macro-scale hydrodynamics for suspensions with\nsimple polymer conformation and bond potential. The model retains a\nmulti-scaled nature by mapping the polymer configurations into a set of\nsymmetry-preserving macro-scale features. The extended constitutive laws for\nthese macro-scale features can be directly learned from the kinetics of their\nmicro-scale counterparts. In this paper, we develop DeePN$^2$ using more\ncomplex micro-structural models. We show that DeePN$^2$ can faithfully capture\nthe broadly overlooked viscoelastic differences arising from the specific\nmolecular structural mechanics without human intervention.",
          "link": "http://arxiv.org/abs/2112.14798",
          "publishedOn": "2022-04-16T00:51:43.711Z",
          "wordCount": null,
          "title": "DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v3 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellani_A/0/1/0/all/0/1\">Andrea Castellani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1\">Sebastian Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1\">Barbara Hammer</a>",
          "description": "Data stream classification is an important problem in the field of machine\nlearning. Due to the non-stationary nature of the data where the underlying\ndistribution changes over time (concept drift), the model needs to continuously\nadapt to new data statistics. Stream-based Active Learning (AL) approaches\naddress this problem by interactively querying a human expert to provide new\ndata labels for the most recent samples, within a limited budget. Existing AL\nstrategies assume that labels are immediately available, while in a real-world\nscenario the expert requires time to provide a queried label (verification\nlatency), and by the time the requested labels arrive they may not be relevant\nanymore. In this article, we investigate the influence of finite,\ntime-variable, and unknown verification delay, in the presence of concept drift\non AL approaches. We propose PRopagate (PR), a latency independent utility\nestimator which also predicts the requested, but not yet known, labels.\nFurthermore, we propose a drift-dependent dynamic budget strategy, which uses a\nvariable distribution of the labelling budget over time, after a detected\ndrift. Thorough experimental evaluation, with both synthetic and real-world\nnon-stationary datasets, and different settings of verification latency and\nbudget are conducted and analyzed. We empirically show that the proposed method\nconsistently outperforms the state-of-the-art. Additionally, we demonstrate\nthat with variable budget allocation in time, it is possible to boost the\nperformance of AL strategies, without increasing the overall labeling budget.",
          "link": "http://arxiv.org/abs/2204.06822",
          "publishedOn": "2022-04-16T00:51:43.708Z",
          "wordCount": null,
          "title": "Stream-based Active Learning with Verification Latency in Non-stationary Environments. (arXiv:2204.06822v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06955",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sitnik_D/0/1/0/all/0/1\">Dario Sitnik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kopriva_I/0/1/0/all/0/1\">Ivica Kopriva</a>",
          "description": "Accurate segmentation of medical images is essential for diagnosis and\ntreatment of diseases. These problems are solved by highly complex models, such\nas deep networks (DN), requiring a large amount of labeled data for training.\nThereby, many DNs possess task- or imaging modality specific architectures with\na decision-making process that is often hard to explain and interpret. Here, we\npropose a framework that embeds existing DNs into a low-dimensional subspace\ninduced by the learnable explicit feature map (LEFM) layer. Compared to the\nexisting DN, the framework adds one hyperparameter and only modestly increase\nthe number of learnable parameters. The method is aimed at, but not limited to,\nsegmentation of low-dimensional medical images, such as color histopathological\nimages of stained frozen sections. Since features in the LEFM layer are\npolynomial functions of the original features, proposed LEFM-Nets contribute to\nthe interpretability of network decisions. In this work, we combined LEFM with\nthe known networks: DeepLabv3+, UNet, UNet++ and MA-net. New LEFM-Nets are\napplied to the segmentation of adenocarcinoma of a colon in a liver from images\nof hematoxylin and eosin (H&E) stained frozen sections. LEFM-Nets are also\ntested on nuclei segmentation from images of H&E stained frozen sections of ten\nhuman organs. On the first problem, LEFM-Nets achieved statistically\nsignificant performance improvement in terms of micro balanced accuracy and\n$F_1$ score than original networks. LEFM-Nets achieved only better performance\nin comparison with the original networks on the second problem. The source code\nis available at https://github.com/dsitnik/lefm.",
          "link": "http://arxiv.org/abs/2204.06955",
          "publishedOn": "2022-04-16T00:51:43.708Z",
          "wordCount": null,
          "title": "LEFM-Nets: Learnable Explicit Feature Map Deep Networks for Segmentation of Histopathological Images of Frozen Sections. (arXiv:2204.06955v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mehta_I/0/1/0/all/0/1\">Ishit Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandraker_M/0/1/0/all/0/1\">Manmohan Chandraker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramamoorthi_R/0/1/0/all/0/1\">Ravi Ramamoorthi</a>",
          "description": "Coordinate-based neural networks parameterizing implicit surfaces have\nemerged as efficient representations of geometry. They effectively act as\nparametric level sets with the zero-level set defining the surface of interest.\nWe present a framework that allows applying deformation operations defined for\ntriangle meshes onto such implicit surfaces. Several of these operations can be\nviewed as energy-minimization problems that induce an instantaneous flow field\non the explicit surface. Our method uses the flow field to deform parametric\nimplicit surfaces by extending the classical theory of level sets. We also\nderive a consolidated view for existing methods on differentiable surface\nextraction and rendering, by formalizing connections to the level-set theory.\nWe show that these methods drift from the theory and that our approach exhibits\nimprovements for applications like surface smoothing, mean-curvature flow,\ninverse rendering and user-defined editing on implicit geometry.",
          "link": "http://arxiv.org/abs/2204.07159",
          "publishedOn": "2022-04-16T00:51:43.708Z",
          "wordCount": null,
          "title": "A Level Set Theory for Neural Implicit Evolution under Explicit Flows. (arXiv:2204.07159v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorinova_M/0/1/0/all/0/1\">Maria I. Gorinova</a>",
          "description": "Probabilistic programming is a growing area that strives to make statistical\nanalysis more accessible, by separating probabilistic modelling from\nprobabilistic inference. In practice this decoupling is difficult. No single\ninference algorithm can be used as a probabilistic programming back-end that is\nsimultaneously reliable, efficient, black-box, and general. Probabilistic\nprogramming languages often choose a single algorithm to apply to a given\nproblem, thus inheriting its limitations. While substantial work has been done\nboth to formalise probabilistic programming and to improve efficiency of\ninference, there has been little work that makes use of the available program\nstructure, by formally analysing it, to better utilise the underlying inference\nalgorithm.\n\nThis dissertation presents three novel techniques (both static and dynamic),\nwhich aim to improve probabilistic programming using program analysis. The\ntechniques analyse a probabilistic program and adapt it to make inference more\nefficient, sometimes in a way that would have been tedious or impossible to do\nby hand.",
          "link": "http://arxiv.org/abs/2204.06868",
          "publishedOn": "2022-04-16T00:51:43.700Z",
          "wordCount": null,
          "title": "Program Analysis of Probabilistic Programs. (arXiv:2204.06868v1 [cs.PL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ley_D/0/1/0/all/0/1\">Dan Ley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Saumitra Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>",
          "description": "Counterfactual explanations have been widely studied in explainability, with\na range of application dependent methods emerging in fairness, recourse and\nmodel understanding. However, the major shortcoming associated with these\nmethods is their inability to provide explanations beyond the local or\ninstance-level. While some works touch upon the notion of a global explanation,\ntypically suggesting to aggregate masses of local explanations in the hope of\nascertaining global properties, few provide frameworks that are either reliable\nor computationally tractable. Meanwhile, practitioners are requesting more\nefficient and interactive explainability tools. We take this opportunity to\ninvestigate existing global methods, with a focus on implementing and improving\nActionable Recourse Summaries (AReS), the only known global counterfactual\nexplanation framework for recourse.",
          "link": "http://arxiv.org/abs/2204.06917",
          "publishedOn": "2022-04-16T00:51:43.700Z",
          "wordCount": null,
          "title": "Global Counterfactual Explanations: Investigations, Implementations and Improvements. (arXiv:2204.06917v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1\">Guolin Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwary_S/0/1/0/all/0/1\">Saurabh Tiwary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "We present an efficient method of pretraining large-scale autoencoding\nlanguage models using training signals generated by an auxiliary model.\nOriginated in ELECTRA, this training strategy has demonstrated\nsample-efficiency to pretrain models at the scale of hundreds of millions of\nparameters. In this work, we conduct a comprehensive empirical study, and\npropose a recipe, namely \"Model generated dEnoising TRaining Objective\"\n(METRO), which incorporates some of the best modeling techniques developed\nrecently to speed up, stabilize, and enhance pretrained language models without\ncompromising model effectiveness. The resultant models, METRO-LM, consisting of\nup to 5.4 billion parameters, achieve new state-of-the-art on the GLUE,\nSuperGLUE, and SQuAD benchmarks. More importantly, METRO-LM are efficient in\nthat they often outperform previous large models with significantly smaller\nmodel sizes and lower pretraining cost.",
          "link": "http://arxiv.org/abs/2204.06644",
          "publishedOn": "2022-04-16T00:51:43.699Z",
          "wordCount": null,
          "title": "METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals. (arXiv:2204.06644v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muench_S/0/1/0/all/0/1\">Stefan Muench</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_D/0/1/0/all/0/1\">Darshankumar Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heindel_L/0/1/0/all/0/1\">Leonhard Heindel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hantschke_P/0/1/0/all/0/1\">Peter Hantschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roellig_M/0/1/0/all/0/1\">Mike Roellig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaestner_M/0/1/0/all/0/1\">Markus Kaestner</a>",
          "description": "This paper proposes a computationally efficient methodology to predict the\ndamage progression in solder contacts of electronic components using\ntemperature-time curves. For this purpose, two machine learning algorithms, a\nMultilayer Perceptron and a Long Short-Term Memory network, are trained and\ncompared with respect to their prediction accuracy and the required amount of\ntraining data. The training is performed using synthetic, normally distributed\ndata that is realistic for automotive applications. A finite element model of a\nsimple bipolar chip resistor in surface mount technology configuration is used\nto numerically compute the synthetic data. As a result, both machine learning\nalgorithms show a relevant accuracy for the prediction of accumulated creep\nstrains. With a training data length of 350 hours (12.5% of the available\ntraining data), both models show a constantly good fitting performance of $R^2$\nof 0.72 for the Multilayer Perceptron and $R^2$ of 0.87 for the Long Short-Term\nMemory network. The prediction errors of the accumulated creep strains are less\nthan 10% with an amount of 350 hours training data and decreases to less than 5\n% when using further data. Therefore, both approaches are promising for the\nlifetime prediction directly on the electronic device.",
          "link": "http://arxiv.org/abs/2204.06627",
          "publishedOn": "2022-04-16T00:51:43.698Z",
          "wordCount": null,
          "title": "Performance Assessment of different Machine Learning Algorithm for Life-Time Prediction of Solder Joints based on Synthetic Data. (arXiv:2204.06627v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamm_K/0/1/0/all/0/1\">Keaton Hamm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henscheid_N/0/1/0/all/0/1\">Nick Henscheid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Shujie Kang</a>",
          "description": "In this paper, we propose Wasserstein Isometric Mapping (Wassmap), a\nparameter-free nonlinear dimensionality reduction technique that provides\nsolutions to some drawbacks in existing global nonlinear dimensionality\nreduction algorithms in imaging applications. Wassmap represents images via\nprobability measures in Wasserstein space, then uses pairwise quadratic\nWasserstein distances between the associated measures to produce a\nlow-dimensional, approximately isometric embedding. We show that the algorithm\nis able to exactly recover parameters of some image manifolds including those\ngenerated by translations or dilations of a fixed generating measure.\nAdditionally, we show that a discrete version of the algorithm retrieves\nparameters from manifolds generated from discrete measures by providing a\ntheoretical bridge to transfer recovery results from functional data to\ndiscrete data. Testing of the proposed algorithms on various image data\nmanifolds show that Wassmap yields good embeddings compared with other global\ntechniques.",
          "link": "http://arxiv.org/abs/2204.06645",
          "publishedOn": "2022-04-16T00:51:43.697Z",
          "wordCount": null,
          "title": "Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning. (arXiv:2204.06645v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raposo_G/0/1/0/all/0/1\">Gon&#xe7;alo Raposo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_R/0/1/0/all/0/1\">Rui Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_B/0/1/0/all/0/1\">Bruno Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coheur_L/0/1/0/all/0/1\">Lu&#xed;sa Coheur</a>",
          "description": "In conversational question answering, systems must correctly interpret the\ninterconnected interactions and generate knowledgeable answers, which may\nrequire the retrieval of relevant information from a background repository.\nRecent approaches to this problem leverage neural language models, although\ndifferent alternatives can be considered in terms of modules for (a)\nrepresenting user questions in context, (b) retrieving the relevant background\ninformation, and (c) generating the answer. This work presents a conversational\nquestion answering system designed specifically for the Search-Oriented\nConversational AI (SCAI) shared task, and reports on a detailed analysis of its\nquestion rewriting module. In particular, we considered different variations of\nthe question rewriting module to evaluate the influence on the subsequent\ncomponents, and performed a careful analysis of the results obtained with the\nbest system configuration. Our system achieved the best performance in the\nshared task and our analysis emphasizes the importance of the conversation\ncontext representation for the overall system performance.",
          "link": "http://arxiv.org/abs/2201.09146",
          "publishedOn": "2022-04-16T00:51:43.697Z",
          "wordCount": null,
          "title": "Question rewriting? Assessing its importance for conversational question answering. (arXiv:2201.09146v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_T/0/1/0/all/0/1\">Thang Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1\">Yasin Abbasi-Yadkori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vernade_C/0/1/0/all/0/1\">Claire Vernade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study a sequential decision problem where the learner faces a sequence of\n$K$-armed stochastic bandit tasks. The tasks may be designed by an adversary,\nbut the adversary is constrained to choose the optimal arm of each task in a\nsmaller (but unknown) subset of $M$ arms. The task boundaries might be known\n(the bandit meta-learning setting), or unknown (the non-stationary bandit\nsetting), and the number of tasks $N$ as well as the total number of rounds $T$\nare known ($N$ could be unknown in the meta-learning setting). We design an\nalgorithm based on a reduction to bandit submodular maximization, and show that\nits regret in both settings is smaller than the simple baseline of\n$\\tilde{O}(\\sqrt{KNT})$ that can be obtained by using standard algorithms\ndesigned for non-stationary bandit problems. For the bandit meta-learning\nproblem with fixed task length $\\tau$, we show that the regret of the algorithm\nis bounded as $\\tilde{O}(N\\sqrt{M \\tau}+N^{2/3})$. Under additional assumptions\non the identifiability of the optimal arms in each task, we show a bandit\nmeta-learning algorithm with an improved $\\tilde{O}(N\\sqrt{M \\tau}+N^{1/2})$\nregret.",
          "link": "http://arxiv.org/abs/2202.13001",
          "publishedOn": "2022-04-16T00:51:43.696Z",
          "wordCount": null,
          "title": "Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yuanyuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_Jaccard_J/0/1/0/all/0/1\">Julian Jang-Jaccard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabrina_F/0/1/0/all/0/1\">Fariza Sabrina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camtepe_S/0/1/0/all/0/1\">Seyit Camtepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulic_M/0/1/0/all/0/1\">Mikael Boulic</a>",
          "description": "Anomaly detection for indoor air quality (IAQ) data has become an important\narea of research as the quality of air is closely related to human health and\nwell-being. However, traditional statistics and shallow machine learning-based\napproaches in anomaly detection in the IAQ area could not detect anomalies\ninvolving the observation of correlations across several data points (i.e.,\noften referred to as long-term dependences). We propose a hybrid deep learning\nmodel that combines LSTM with Autoencoder for anomaly detection tasks in IAQ to\naddress this issue. In our approach, the LSTM network is comprised of multiple\nLSTM cells that work with each other to learn the long-term dependences of the\ndata in a time-series sequence. Autoencoder identifies the optimal threshold\nbased on the reconstruction loss rates evaluated on every data across all\ntime-series sequences. Our experimental results, based on the Dunedin CO2\ntime-series dataset obtained through a real-world deployment of the schools in\nNew Zealand, demonstrate a very high and robust accuracy rate (99.50%) that\noutperforms other similar models.",
          "link": "http://arxiv.org/abs/2204.06701",
          "publishedOn": "2022-04-16T00:51:43.629Z",
          "wordCount": null,
          "title": "LSTM-Autoencoder based Anomaly Detection for Indoor Air Quality Time Series Data. (arXiv:2204.06701v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsubara_Y/0/1/0/all/0/1\">Yoshitomo Matsubara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callegaro_D/0/1/0/all/0/1\">Davide Callegaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levorato_M/0/1/0/all/0/1\">Marco Levorato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Restuccia_F/0/1/0/all/0/1\">Francesco Restuccia</a>",
          "description": "Although mission-critical applications require the use of deep neural\nnetworks (DNNs), their continuous execution at mobile devices results in a\nsignificant increase in energy consumption. While edge offloading can decrease\nenergy consumption, erratic patterns in channel quality, network and edge\nserver load can lead to severe disruption of the system's key operations. An\nalternative approach, called split computing, generates compressed\nrepresentations within the model (called \"bottlenecks\"), to reduce bandwidth\nusage and energy consumption. Prior work has proposed approaches that introduce\nadditional layers, to the detriment of energy consumption and latency. For this\nreason, we propose a new framework called BottleFit, which, in addition to\ntargeted DNN architecture modifications, includes a novel training strategy to\nachieve high accuracy even with strong compression rates. We apply BottleFit on\ncutting-edge DNN models in image classification, and show that BottleFit\nachieves 77.1% data compression with up to 0.6% accuracy loss on ImageNet\ndataset, while state of the art such as SPINN loses up to 6% in accuracy. We\nexperimentally measure the power consumption and latency of an image\nclassification application running on an NVIDIA Jetson Nano board (GPU-based)\nand a Raspberry PI board (GPU-less). We show that BottleFit decreases power\nconsumption and latency respectively by up to 49% and 89% with respect to\n(w.r.t.) local computing and by 37% and 55% w.r.t. edge offloading. We also\ncompare BottleFit with state-of-the-art autoencoders-based approaches, and show\nthat (i) BottleFit reduces power consumption and execution time respectively by\nup to 54% and 44% on the Jetson and 40% and 62% on Raspberry PI; (ii) the size\nof the head model executed on the mobile device is 83 times smaller. We publish\nthe code repository for reproducibility of the results in this study.",
          "link": "http://arxiv.org/abs/2201.02693",
          "publishedOn": "2022-04-16T00:51:43.629Z",
          "wordCount": null,
          "title": "BottleFit: Learning Compressed Representations in Deep Neural Networks for Effective and Efficient Split Computing. (arXiv:2201.02693v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahabandu_D/0/1/0/all/0/1\">Dinuka Sahabandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mertoguno_S/0/1/0/all/0/1\">Sukarno Mertoguno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poovendran_R/0/1/0/all/0/1\">Radha Poovendran</a>",
          "description": "Binary analysis of software is a critical step in cyber forensics\napplications such as program vulnerability assessment and malware detection.\nThis involves interpreting instructions executed by software and often\nnecessitates converting the software's binary file data to assembly language.\nThe conversion process requires information about the binary file's target\ninstruction set architecture (ISA). However, ISA information might not be\nincluded in binary files due to compilation errors, partial downloads, or\nadversarial corruption of file metadata. Machine learning (ML) is a promising\nmethodology that can be used to identify the target ISA using binary data in\nthe object code section of binary files. In this paper we propose a binary code\nfeature extraction model to improve the accuracy and scalability of ML-based\nISA identification methods. Our feature extraction model can be used in the\nabsence of domain knowledge about the ISAs. Specifically, we adapt models from\nnatural language processing (NLP) to i) identify successive byte patterns\ncommonly observed in binary codes, ii) estimate the significance of each byte\npattern to a binary file, and iii) estimate the relevance of each byte pattern\nin distinguishing between ISAs. We introduce character-level features of\nencoded binaries to identify fine-grained bit patterns inherent to each ISA. We\nuse a dataset with binaries from 12 different ISAs to evaluate our approach.\nEmpirical evaluations show that using our byte-level features in ML-based ISA\nidentification results in an 8% higher accuracy than the state-of-the-art\nfeatures based on byte-histograms and byte pattern signatures. We observe that\ncharacter-level features allow reducing the size of the feature set by up to\n16x while maintaining accuracy above 97%.",
          "link": "http://arxiv.org/abs/2204.06624",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "A Natural Language Processing Approach for Instruction Set Architecture Identification. (arXiv:2204.06624v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feijie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shiqi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Song Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Z/0/1/0/all/0/1\">Zhihao Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1\">Weihua Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>",
          "description": "Traditional one-bit compressed stochastic gradient descent can not be\ndirectly employed in multi-hop all-reduce, a widely adopted distributed\ntraining paradigm in network-intensive high-performance computing systems such\nas public clouds. According to our theoretical findings, due to the cascading\ncompression, the training process has considerable deterioration on the\nconvergence performance. To overcome this limitation, we implement a sign-bit\ncompression-based learning synchronization framework, Marsit. It prevents\ncascading compression via an elaborate bit-wise operation for unbiased sign\naggregation and its specific global compensation mechanism for mitigating\ncompression deviation. The proposed framework retains the same theoretical\nconvergence rate as non-compression mechanisms. Experimental results\ndemonstrate that Marsit reduces up to 35% training time while preserving the\nsame accuracy as training without compression.",
          "link": "http://arxiv.org/abs/2204.06787",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "Sign Bit is Enough: A Learning Synchronization Framework for Multi-hop All-reduce with Ultimate Compression. (arXiv:2204.06787v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06904",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_Q/0/1/0/all/0/1\">Qiuhao Chen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Du_Y/0/1/0/all/0/1\">Yuxuan Du</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhao_Q/0/1/0/all/0/1\">Qi Zhao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jiao_Y/0/1/0/all/0/1\">Yuling Jiao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lu_X/0/1/0/all/0/1\">Xiliang Lu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1\">Xingyao Wu</a>",
          "description": "Efficient quantum compiling tactics greatly enhance the capability of quantum\ncomputers to execute complicated quantum algorithms. Due to its fundamental\nimportance, a plethora of quantum compilers has been designed in past years.\nHowever, there are several caveats to current protocols, which are low\noptimality, high inference time, limited scalability, and lack of universality.\nTo compensate for these defects, here we devise an efficient and practical\nquantum compiler assisted by advanced deep reinforcement learning (RL)\ntechniques, i.e., data generation, deep Q-learning, and AQ* search. In this\nway, our protocol is compatible with various quantum machines and can be used\nto compile multi-qubit operators. We systematically evaluate the performance of\nour proposal in compiling quantum operators with both inverse-closed and\ninverse-free universal basis sets. In the task of single-qubit operator\ncompiling, our proposal outperforms other RL-based quantum compilers in the\nmeasure of compiling sequence length and inference time. Meanwhile, the output\nsolution is near-optimal, guaranteed by the Solovay-Kitaev theorem. Notably,\nfor the inverse-free universal basis set, the achieved sequence length\ncomplexity is comparable with the inverse-based setting and dramatically\nadvances previous methods. These empirical results contribute to improving the\ninverse-free Solovay-Kitaev theorem. In addition, for the first time, we\ndemonstrate how to leverage RL-based quantum compilers to accomplish two-qubit\noperator compiling. The achieved results open an avenue for integrating RL with\nquantum compiling to unify efficiency and practicality and thus facilitate the\nexploration of quantum advantages.",
          "link": "http://arxiv.org/abs/2204.06904",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "Efficient and practical quantum compiler towards multi-qubit systems with deep reinforcement learning. (arXiv:2204.06904v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07122",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Arvinte_M/0/1/0/all/0/1\">Marius Arvinte</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tamir_J/0/1/0/all/0/1\">Jonathan I Tamir</a>",
          "description": "Channel estimation is a critical task in multiple-input multiple-output\ndigital communications that has effects on end-to-end system performance. In\nthis work, we introduce a novel approach for channel estimation using deep\nscore-based generative models. These models are trained to estimate the\ngradient of the log-prior distribution, and can be used to iteratively refine\nestimates, given observed measurements of a signal. We introduce a framework\nfor training score-based generative models for wireless channels, as well as\nperforming channel estimation using posterior sampling at test time. We derive\ntheoretical robustness guarantees of channel estimation with posterior sampling\nin single-input single-output scenarios, and show that the observations\nregarding estimation performance are verified experimentally in MIMO channels.\nOur results in simulated clustered delay line channels show competitive\nin-distribution performance without error floors in the high signal-to-noise\nratio regime, and robust out-of-distribution performance, outperforming\ncompeting deep learning methods by up to 5 dB in end-to-end communication\nperformance, while the complexity analysis reveals how model architecture can\nefficiently trade performance for estimation latency.",
          "link": "http://arxiv.org/abs/2204.07122",
          "publishedOn": "2022-04-16T00:51:43.628Z",
          "wordCount": null,
          "title": "MIMO Channel Estimation using Score-Based Generative Models. (arXiv:2204.07122v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1\">Arun Babu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiatao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>",
          "description": "While the general idea of self-supervised learning is identical across\nmodalities, the actual algorithms and objectives differ widely because they\nwere developed with a single modality in mind. To get us closer to general\nself-supervised learning, we present data2vec, a framework that uses the same\nlearning method for either speech, NLP or computer vision. The core idea is to\npredict latent representations of the full input data based on a masked view of\nthe input in a self-distillation setup using a standard Transformer\narchitecture. Instead of predicting modality-specific targets such as words,\nvisual tokens or units of human speech which are local in nature, data2vec\npredicts contextualized latent representations that contain information from\nthe entire input. Experiments on the major benchmarks of speech recognition,\nimage classification, and natural language understanding demonstrate a new\nstate of the art or competitive performance to predominant approaches.",
          "link": "http://arxiv.org/abs/2202.03555",
          "publishedOn": "2022-04-16T00:51:43.627Z",
          "wordCount": null,
          "title": "data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language. (arXiv:2202.03555v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Esmaeilpour_M/0/1/0/all/0/1\">Mohammad Esmaeilpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardinal_P/0/1/0/all/0/1\">Patrick Cardinal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koerich_A/0/1/0/all/0/1\">Alessandro Lameiras Koerich</a>",
          "description": "This paper investigates the impact of different standard environmental sound\nrepresentations (spectrograms) on the recognition performance and adversarial\nattack robustness of a victim residual convolutional neural network, namely\nResNet-18. Our main motivation for focusing on such a front-end classifier\nrather than other complex architectures is balancing recognition accuracy and\nthe total number of training parameters. Herein, we measure the impact of\ndifferent settings required for generating more informative Mel-frequency\ncepstral coefficient (MFCC), short-time Fourier transform (STFT), and discrete\nwavelet transform (DWT) representations on our front-end model. This\nmeasurement involves comparing the classification performance over the\nadversarial robustness. We demonstrate an inverse relationship between\nrecognition accuracy and model robustness against six benchmarking attack\nalgorithms on the balance of average budgets allocated by the adversary and the\nattack cost. Moreover, our experimental results have shown that while the\nResNet-18 model trained on DWT spectrograms achieves a high recognition\naccuracy, attacking this model is relatively more costly for the adversary than\nother 2D representations. We also report some results on different\nconvolutional neural network architectures such as ResNet-34, ResNet-56,\nAlexNet, and GoogLeNet, SB-CNN, and LSTM-based.",
          "link": "http://arxiv.org/abs/2204.07018",
          "publishedOn": "2022-04-16T00:51:43.560Z",
          "wordCount": 664,
          "title": "From Environmental Sound Representation to Robustness of 2D CNN Models Against Adversarial Attacks. (arXiv:2204.07018v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Hengyue Pan</a>",
          "description": "Convolutional neural network (CNN) achieves impressive success in the field\nof computer vision during the past few decades. As the core of CNNs, image\nconvolution operation helps CNNs to achieve good performance on image-related\ntasks. However, image convolution is hard to be implemented and parallelized.\nIn this paper, we propose a novel neural network model, namely CEMNet, that can\nbe trained in frequency domain. The most important motivation of this research\nis that we can use the very simple element-wise multiplication operation to\nreplace the image convolution in frequency domain based on Cross-Correlation\nTheorem. We further introduce Weight Fixation Mechanism to alleviate\nover-fitting, and analyze the working behavior of Batch Normalization, Leaky\nReLU and Dropout in frequency domain to design their counterparts for CEMNet.\nAlso, to deal with complex inputs brought by DFT, we design two branch network\nstructure for CEMNet. Experimental results imply that CEMNet works well in\nfrequency domain, and achieve good performance on MNIST and CIFAR-10 databases.\nTo our knowledge, CEMNet is the first model trained in Fourier Domain that\nachieves more than 70\\% validation accuracy on CIFAR-10 database.",
          "link": "http://arxiv.org/abs/2204.06718",
          "publishedOn": "2022-04-16T00:51:43.226Z",
          "wordCount": 621,
          "title": "Learning Convolutional Neural Networks in Frequency Domain. (arXiv:2204.06718v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07124",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blumlein_T/0/1/0/all/0/1\">Theresa Bl&#xfc;mlein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Persson_J/0/1/0/all/0/1\">Joel Persson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Dynamic treatment regimes (DTRs) are used in medicine to tailor sequential\ntreatment decisions to patients by considering patient heterogeneity. Common\nmethods for learning optimal DTRs, however, have shortcomings: they are\ntypically based on outcome prediction and not treatment effect estimation, or\nthey use linear models that are restrictive for patient data from modern\nelectronic health records. To address these shortcomings, we develop two novel\nmethods for learning optimal DTRs that effectively handle complex patient data.\nWe call our methods DTR-CT and DTR-CF. Our methods are based on a data-driven\nestimation of heterogeneous treatment effects using causal tree methods,\nspecifically causal trees and causal forests, that learn non-linear\nrelationships, control for time-varying confounding, are doubly robust, and\nexplainable. To the best of our knowledge, our paper is the first that adapts\ncausal tree methods for learning optimal DTRs. We evaluate our proposed methods\nusing synthetic data and then apply them to real-world data from intensive care\nunits. Our methods outperform state-of-the-art baselines in terms of cumulative\nregret and percentage of optimal decisions by a considerable margin. Our work\nimproves treatment recommendations from electronic health record and is thus of\ndirect relevance for personalized medicine.",
          "link": "http://arxiv.org/abs/2204.07124",
          "publishedOn": "2022-04-16T00:51:43.078Z",
          "wordCount": 644,
          "title": "Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine. (arXiv:2204.07124v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanlin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Ting He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_V/0/1/0/all/0/1\">Vijay Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kevin S. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasteris_S/0/1/0/all/0/1\">Stephen Pasteris</a>",
          "description": "Coresets are small, weighted summaries of larger datasets, aiming at\nproviding provable error bounds for machine learning (ML) tasks while\nsignificantly reducing the communication and computation costs. To achieve a\nbetter trade-off between ML error bounds and costs, we propose the first\nframework to incorporate quantization techniques into the process of coreset\nconstruction. Specifically, we theoretically analyze the ML error bounds caused\nby a combination of coreset construction and quantization. Based on that, we\nformulate an optimization problem to minimize the ML error under a fixed budget\nof communication cost. To improve the scalability for large datasets, we\nidentify two proxies of the original objective function, for which efficient\nalgorithms are developed. For the case of data on multiple nodes, we further\ndesign a novel algorithm to allocate the communication budget to the nodes\nwhile minimizing the overall ML error. Through extensive experiments on\nmultiple real-world datasets, we demonstrate the effectiveness and efficiency\nof our proposed algorithms for a variety of ML tasks. In particular, our\nalgorithms have achieved more than 90% data reduction with less than 10%\ndegradation in ML performance in most cases.",
          "link": "http://arxiv.org/abs/2204.06652",
          "publishedOn": "2022-04-16T00:51:43.069Z",
          "wordCount": 627,
          "title": "Joint Coreset Construction and Quantization for Distributed Machine Learning. (arXiv:2204.06652v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richards_S/0/1/0/all/0/1\">Spencer M. Richards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizan_N/0/1/0/all/0/1\">Navid Azizan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slotine_J/0/1/0/all/0/1\">Jean-Jacques Slotine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "Real-time adaptation is imperative to the control of robots operating in\ncomplex, dynamic environments. Adaptive control laws can endow even nonlinear\nsystems with good trajectory tracking performance, provided that any uncertain\ndynamics terms are linearly parameterizable with known nonlinear features.\nHowever, it is often difficult to specify such features a priori, such as for\naerodynamic disturbances on rotorcraft or interaction forces between a\nmanipulator arm and various objects. In this paper, we turn to data-driven\nmodeling with neural networks to learn, offline from past data, an adaptive\ncontroller with an internal parametric model of these nonlinear features. Our\nkey insight is that we can better prepare the controller for deployment with\ncontrol-oriented meta-learning of features in closed-loop simulation, rather\nthan regression-oriented meta-learning of features to fit input-output data.\nSpecifically, we meta-learn the adaptive controller with closed-loop tracking\nsimulation as the base-learner and the average tracking error as the\nmeta-objective. With both fully-actuated and underactuated nonlinear planar\nrotorcraft subject to wind, we demonstrate that our adaptive controller\noutperforms other controllers trained with regression-oriented meta-learning\nwhen deployed in closed-loop for trajectory tracking control.",
          "link": "http://arxiv.org/abs/2204.06716",
          "publishedOn": "2022-04-16T00:51:43.046Z",
          "wordCount": 649,
          "title": "Control-oriented meta-learning. (arXiv:2204.06716v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06698",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_A/0/1/0/all/0/1\">Angelica Tiemi Mizuno Nakamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_D/0/1/0/all/0/1\">Denis Fernando Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grassi_V/0/1/0/all/0/1\">Valdir Grassi Jr</a>",
          "description": "Multi-Task Learning is a learning paradigm that uses correlated tasks to\nimprove performance generalization. A common way to learn multiple tasks is\nthrough the hard parameter sharing approach, in which a single architecture is\nused to share the same subset of parameters, creating an inductive bias between\nthem during the training process. Due to its simplicity, potential to improve\ngeneralization, and reduce computational cost, it has gained the attention of\nthe scientific and industrial communities. However, tasks often conflict with\neach other, which makes it challenging to define how the gradients of multiple\ntasks should be combined to allow simultaneous learning. To address this\nproblem, we use the idea of multi-objective optimization to propose a method\nthat takes into account temporal behaviour of the gradients to create a dynamic\nbias that adjust the importance of each task during the backpropagation. The\nresult of this method is to give more attention to the tasks that are diverging\nor that are not being benefited during the last iterations, allowing to ensure\nthat the simultaneous learning is heading to the performance maximization of\nall tasks. As a result, we empirically show that the proposed method\noutperforms the state-of-art approaches on learning conflicting tasks. Unlike\nthe adopted baselines, our method ensures that all tasks reach good\ngeneralization performances.",
          "link": "http://arxiv.org/abs/2204.06698",
          "publishedOn": "2022-04-16T00:51:43.009Z",
          "wordCount": 658,
          "title": "Leveraging convergence behavior to balance conflicting tasks in multi-task learning. (arXiv:2204.06698v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06684",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lu_L/0/1/0/all/0/1\">Lu Lu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pestourie_R/0/1/0/all/0/1\">Raphael Pestourie</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Johnson_S/0/1/0/all/0/1\">Steven G. Johnson</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Romano_G/0/1/0/all/0/1\">Giuseppe Romano</a>",
          "description": "Deep neural operators can learn operators mapping between\ninfinite-dimensional function spaces via deep neural networks and have become\nan emerging paradigm of scientific machine learning. However, training neural\noperators usually requires a large amount of high-fidelity data, which is often\ndifficult to obtain in real engineering problems. Here, we address this\nchallenge by using multifidelity learning, i.e., learning from multifidelity\ndatasets. We develop a multifidelity neural operator based on a deep operator\nnetwork (DeepONet). A multifidelity DeepONet includes two standard DeepONets\ncoupled by residual learning and input augmentation. Multifidelity DeepONet\nsignificantly reduces the required amount of high-fidelity data and achieves\none order of magnitude smaller error when using the same amount of\nhigh-fidelity data. We apply a multifidelity DeepONet to learn the phonon\nBoltzmann transport equation (BTE), a framework to compute nanoscale heat\ntransport. By combining a trained multifidelity DeepONet with genetic algorithm\nor topology optimization, we demonstrate a fast solver for the inverse design\nof BTE problems.",
          "link": "http://arxiv.org/abs/2204.06684",
          "publishedOn": "2022-04-16T00:51:43.000Z",
          "wordCount": 621,
          "title": "Multifidelity deep neural operators for efficient learning of partial differential equations with application to fast inverse design of nanoscale heat transport. (arXiv:2204.06684v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Ankita Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thirunarayan_K/0/1/0/all/0/1\">Krishnaprasad Thirunarayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romine_W/0/1/0/all/0/1\">William L. Romine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alambo_A/0/1/0/all/0/1\">Amanuel Alambo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cajita_M/0/1/0/all/0/1\">Mia Cajita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1\">Tanvi Banerjee</a>",
          "description": "Heart failure occurs when the heart is not able to pump blood and oxygen to\nsupport other organs in the body as it should. Treatments include medications\nand sometimes hospitalization. Patients with heart failure can have both\ncardiovascular as well as non-cardiovascular comorbidities. Clinical notes of\npatients with heart failure can be analyzed to gain insight into the topics\ndiscussed in these notes and the major comorbidities in these patients. In this\nregard, we apply machine learning techniques, such as topic modeling, to\nidentify the major themes found in the clinical notes specific to the\nprocedures performed on 1,200 patients admitted for heart failure at the\nUniversity of Illinois Hospital and Health Sciences System (UI Health). Topic\nmodeling revealed five hidden themes in these clinical notes, including one\nrelated to heart disease comorbidities.",
          "link": "http://arxiv.org/abs/2204.07074",
          "publishedOn": "2022-04-16T00:51:42.949Z",
          "wordCount": 605,
          "title": "Leveraging Natural Learning Processing to Uncover Themes in Clinical Notes of Patients Admitted for Heart Failure. (arXiv:2204.07074v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weyns_D/0/1/0/all/0/1\">Danny Weyns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baeck_T/0/1/0/all/0/1\">Thomas Baeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Rene Vidal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belbachir_A/0/1/0/all/0/1\">Ahmed Nabil Belbachir</a>",
          "description": "Computing systems are omnipresent; their sustainability has become crucial\nfor our society. A key aspect of this sustainability is the ability of\ncomputing systems to cope with the continuous change they face, ranging from\ndynamic operating conditions, to changing goals, and technological progress.\nWhile we are able to engineer smart computing systems that autonomously deal\nwith various types of changes, handling unanticipated changes requires system\nevolution, which remains in essence a human-centered process. This will\neventually become unmanageable. To break through the status quo, we put forward\nan arguable opinion for the vision of self-evolving computing systems that are\nequipped with an evolutionary engine enabling them to evolve autonomously.\nSpecifically, when a self-evolving computing system detects conditions outside\nits operational domain, such as an anomaly or a new goal, it activates an\nevolutionary engine that runs online experiments to determine how the system\nneeds to evolve to deal with the changes, thereby evolving its architecture.\nDuring this process the engine can integrate new computing elements that are\nprovided by computing warehouses. These computing elements provide\nspecifications and procedures enabling their automatic integration. We motivate\nthe need for self-evolving computing systems in light of the state of the art,\noutline a conceptual architecture of self-evolving computing systems, and\nillustrate the architecture for a future smart city mobility system that needs\nto evolve continuously with changing conditions. To conclude, we highlight key\nresearch challenges to realize the vision of self-evolving computing systems.",
          "link": "http://arxiv.org/abs/2204.06825",
          "publishedOn": "2022-04-16T00:51:42.941Z",
          "wordCount": 678,
          "title": "The Vision of Self-Evolving Computing Systems. (arXiv:2204.06825v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Rui Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1\">Stephen James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yichuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yun-Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>",
          "description": "In this paper, we propose an iterative self-training framework for\nsim-to-real 6D object pose estimation to facilitate cost-effective robotic\ngrasping. Given a bin-picking scenario, we establish a photo-realistic\nsimulator to synthesize abundant virtual data, and use this to train an initial\npose estimation network. This network then takes the role of a teacher model,\nwhich generates pose predictions for unlabeled real data. With these\npredictions, we further design a comprehensive adaptive selection scheme to\ndistinguish reliable results, and leverage them as pseudo labels to update a\nstudent model for pose estimation on real data. To continuously improve the\nquality of pseudo labels, we iterate the above steps by taking the trained\nstudent model as a new teacher and re-label real data using the refined teacher\nmodel. We evaluate our method on a public benchmark and our newly-released\ndataset, achieving an ADD(-S) improvement of 11.49% and 22.62% respectively.\nOur method is also able to improve robotic bin-picking success by 19.54%,\ndemonstrating the potential of iterative sim-to-real solutions for robotic\napplications.",
          "link": "http://arxiv.org/abs/2204.07049",
          "publishedOn": "2022-04-16T00:51:42.899Z",
          "wordCount": 637,
          "title": "Sim-to-Real 6D Object Pose Estimation via Iterative Self-training for Robotic Bin-picking. (arXiv:2204.07049v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.11442",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chen_D/0/1/0/all/0/1\">Dicheng Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hu_W/0/1/0/all/0/1\">Wanqi Hu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_H/0/1/0/all/0/1\">Huiting Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhou_Y/0/1/0/all/0/1\">Yirong Zhou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Qiu_T/0/1/0/all/0/1\">Tianyu Qiu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huang_Y/0/1/0/all/0/1\">Yihui Huang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_J/0/1/0/all/0/1\">Jiazheng Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lin_L/0/1/0/all/0/1\">Liangjie Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_Z/0/1/0/all/0/1\">Zhigang Wu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yan_G/0/1/0/all/0/1\">Gen Yan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guo_D/0/1/0/all/0/1\">Di Guo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lin_J/0/1/0/all/0/1\">Jianzhong Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Qu_X/0/1/0/all/0/1\">Xiaobo Qu</a>",
          "description": "Magnetic Resonance Spectroscopy (MRS) is a noninvasive tool to reveal\nmetabolic information. One challenge of 1H-MRS is the low Signal-Noise Ratio\n(SNR). To improve the SNR, a typical approach is to perform Signal Averaging\n(SA) with M repeated samples. The data acquisition time, however, is increased\nby M times accordingly, and a complete clinical MRS scan takes approximately 10\nminutes at a common setting M=128. Recently, deep learning has been introduced\nto improve the SNR but most of them use the simulated data as the training set.\nThis may hinder the MRS applications since some potential differences, such as\nacquisition system imperfections, and physiological and psychologic conditions\nmay exist between the simulated and in vivo data. Here, we proposed a new\nscheme that purely used the repeated samples of realistic data. A deep learning\nmodel, Refusion Long Short-Term Memory (ReLSTM), was designed to learn the\nmapping from the low SNR time-domain data (24 SA) to the high SNR one (128 SA).\nExperiments on the in vivo brain spectra of 7 healthy subjects, 2 brain tumor\npatients and 1 cerebral infarction patient showed that only using 20% repeated\nsamples, the denoised spectra by ReLSTM could provide comparable estimated\nconcentrations of metabolites to 128 SA. Compared with the state-of-the-art\nlow-rank denoising method, the ReLSTM achieved the lower relative error and the\nCram\\'er-Rao lower bounds in quantifying some important biomarkers. In summary,\nReLSTM can perform high-fidelity denoising of the spectra under fast\nacquisition (24 SA), which would be valuable to MRS clinical studies.",
          "link": "http://arxiv.org/abs/2101.11442",
          "publishedOn": "2022-04-16T00:51:42.878Z",
          "wordCount": 740,
          "title": "Magnetic Resonance Spectroscopy Deep Learning Denoising Using Few In Vivo Data. (arXiv:2101.11442v2 [physics.med-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yiding Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angluin_D/0/1/0/all/0/1\">Dana Angluin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_R/0/1/0/all/0/1\">Robert Frank</a>",
          "description": "This paper analyzes three formal models of Transformer encoders that differ\nin the form of their self-attention mechanism: unique hard attention (UHAT);\ngeneralized unique hard attention (GUHAT), which generalizes UHAT; and\naveraging hard attention (AHAT). We show that UHAT and GUHAT Transformers,\nviewed as string acceptors, can only recognize formal languages in the\ncomplexity class AC$^0$, the class of languages recognizable by families of\nBoolean circuits of constant depth and polynomial size. This upper bound\nsubsumes Hahn's (2020) results that GUHAT cannot recognize the DYCK languages\nor the PARITY language, since those languages are outside AC$^0$ (Furst et al.,\n1984). In contrast, the non-AC$^0$ languages MAJORITY and DYCK-1 are\nrecognizable by AHAT networks, implying that AHAT can recognize languages that\nUHAT and GUHAT cannot.",
          "link": "http://arxiv.org/abs/2204.06618",
          "publishedOn": "2022-04-16T00:51:42.870Z",
          "wordCount": 593,
          "title": "Formal Language Recognition by Hard Attention Transformers: Perspectives from Circuit Complexity. (arXiv:2204.06618v1 [cs.CC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+G_R/0/1/0/all/0/1\">Renith G</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warrier_H/0/1/0/all/0/1\">Harikrishna Warrier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_Y/0/1/0/all/0/1\">Yogesh Gupta</a>",
          "description": "Content based providers transmits real time complex signal such as video data\nfrom one region to another. During this transmission process, the signals\nusually end up distorted or degraded where the actual information present in\nthe video is lost. This normally happens in the streaming video services\napplications. Hence there is a need to know the level of degradation that\nhappened in the receiver side. This video degradation can be estimated by\nnetwork state parameters like data rate and packet loss values. Our proposed\nsolution vQoS GAN (video Quality of Service Generative Adversarial Network) can\nestimate the network state parameters from the degraded received video data\nusing a deep learning approach of semi supervised generative adversarial\nnetwork algorithm. A robust and unique design of deep learning network model\nhas been trained with the video data along with data rate and packet loss class\nlabels and achieves over 95 percent of training accuracy. The proposed semi\nsupervised generative adversarial network can additionally reconstruct the\ndegraded video data to its original form for a better end user experience.",
          "link": "http://arxiv.org/abs/2204.07062",
          "publishedOn": "2022-04-16T00:51:42.825Z",
          "wordCount": 629,
          "title": "Network state Estimation using Raw Video Analysis: vQoS-GAN based non-intrusive Deep Learning Approach. (arXiv:2204.07062v1 [cs.MM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06638",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liang_D/0/1/0/all/0/1\">Daniel Liang</a>",
          "description": "Given a dataset of input states, measurements, and probabilities, is it\npossible to efficiently predict the measurement probabilities associated with a\nquantum circuit? Recent work of Caro and Datta (2020) studied the problem of\nPAC learning quantum circuits in an information theoretic sense, leaving open\nquestions of computational efficiency. In particular, one candidate class of\ncircuits for which an efficient learner might have been possible was that of\nClifford circuits, since the corresponding set of states generated by such\ncircuits, called stabilizer states, are known to be efficiently PAC learnable\n(Rocchetto 2018). Here we provide a negative result, showing that proper\nlearning of CNOT circuits is hard for classical learners unless $\\textsf{RP} =\n\\textsf{NP}$. As the classical analogue and subset of Clifford circuits, this\nnaturally leads to a hardness result for Clifford circuits as well.\nAdditionally, we show that if $\\textsf{RP} = \\textsf{NP}$ then there would\nexist efficient proper learning algorithms for CNOT and Clifford circuits. By\nsimilar arguments, we also find that an efficient proper quantum learner for\nsuch circuits exists if and only if $\\textsf{NP} \\subseteq \\textsf{RQP}$.",
          "link": "http://arxiv.org/abs/2204.06638",
          "publishedOn": "2022-04-16T00:51:42.752Z",
          "wordCount": 625,
          "title": "Clifford Circuits can be Properly PAC Learned if and only if $\\textsf{RP}=\\textsf{NP}$. (arXiv:2204.06638v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salami_A/0/1/0/all/0/1\">Abbas Salami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreu_Perez_J/0/1/0/all/0/1\">Javier Andreu-Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillmeister_H/0/1/0/all/0/1\">Helge Gillmeister</a>",
          "description": "In recent years, neural networks and especially deep architectures have\nreceived substantial attention for EEG signal analysis in the field of\nbrain-computer interfaces (BCIs). In this ongoing research area, the end-to-end\nmodels are more favoured than traditional approaches requiring signal\ntransformation pre-classification. They can eliminate the need for prior\ninformation from experts and the extraction of handcrafted features. However,\nalthough several deep learning algorithms have been already proposed in the\nliterature, achieving high accuracies for classifying motor movements or mental\ntasks, they often face a lack of interpretability and therefore are not quite\nfavoured by the neuroscience community. The reasons behind this issue can be\nthe high number of parameters and the sensitivity of deep neural networks to\ncapture tiny yet unrelated discriminative features. We propose an end-to-end\ndeep learning architecture called EEG-ITNet and a more comprehensible method to\nvisualise the network learned patterns. Using inception modules and causal\nconvolutions with dilation, our model can extract rich spectral, spatial, and\ntemporal information from multi-channel EEG signals with less complexity (in\nterms of the number of trainable parameters) than other existing end-to-end\narchitectures, such as EEG-Inception and EEG-TCNet. By an exhaustive evaluation\non dataset 2a from BCI competition IV and OpenBMI motor imagery dataset,\nEEG-ITNet shows up to 5.9\\% improvement in the classification accuracy in\ndifferent scenarios with statistical significance compared to its competitors.\nWe also comprehensively explain and support the validity of network\nillustration from a neuroscientific perspective. We have also made our code\nopen at https://github.com/AbbasSalami/EEG-ITNet",
          "link": "http://arxiv.org/abs/2204.06947",
          "publishedOn": "2022-04-16T00:51:42.725Z",
          "wordCount": 712,
          "title": "EEG-ITNet: An Explainable Inception Temporal Convolutional Network for Motor Imagery Classification. (arXiv:2204.06947v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06929",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_J/0/1/0/all/0/1\">Jiamin Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">Haoming Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_S/0/1/0/all/0/1\">Shuangchi He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_X/0/1/0/all/0/1\">Xindi Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zejian Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_W/0/1/0/all/0/1\">Wufeng Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_J/0/1/0/all/0/1\">Jun Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a>",
          "description": "Ultrasound (US) imaging is widely used for anatomical structure inspection in\nclinical diagnosis. The training of new sonographers and deep learning based\nalgorithms for US image analysis usually requires a large amount of data.\nHowever, obtaining and labeling large-scale US imaging data are not easy tasks,\nespecially for diseases with low incidence. Realistic US image synthesis can\nalleviate this problem to a great extent. In this paper, we propose a\ngenerative adversarial network (GAN) based image synthesis framework. Our main\ncontributions include: 1) we present the first work that can synthesize\nrealistic B-mode US images with high-resolution and customized texture editing\nfeatures; 2) to enhance structural details of generated images, we propose to\nintroduce auxiliary sketch guidance into a conditional GAN. We superpose the\nedge sketch onto the object mask and use the composite mask as the network\ninput; 3) to generate high-resolution US images, we adopt a progressive\ntraining strategy to gradually generate high-resolution images from\nlow-resolution images. In addition, a feature loss is proposed to minimize the\ndifference of high-level features between the generated and real images, which\nfurther improves the quality of generated images; 4) the proposed US image\nsynthesis method is quite universal and can also be generalized to the US\nimages of other anatomical structures besides the three ones tested in our\nstudy (lung, hip joint, and ovary); 5) extensive experiments on three large US\nimage datasets are conducted to validate our method. Ablation studies,\ncustomized texture editing, user studies, and segmentation tests demonstrate\npromising results of our method in synthesizing realistic US images.",
          "link": "http://arxiv.org/abs/2204.06929",
          "publishedOn": "2022-04-16T00:51:42.686Z",
          "wordCount": 743,
          "title": "Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dulberg_Z/0/1/0/all/0/1\">Zack Dulberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_R/0/1/0/all/0/1\">Rachit Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berwian_I/0/1/0/all/0/1\">Isabel M. Berwian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Jonathan D. Cohen</a>",
          "description": "The problem of balancing conflicting needs is fundamental to intelligence.\nStandard reinforcement learning algorithms maximize a scalar reward, which\nrequires combining different objective-specific rewards into a single number.\nAlternatively, different objectives could also be combined at the level of\naction value, such that specialist modules responsible for different objectives\nsubmit different action suggestions to a decision process, each based on\nrewards that are independent of one another. In this work, we explore the\npotential benefits of this alternative strategy. We investigate a biologically\nrelevant multi-objective problem, the continual homeostasis of a set of\nvariables, and compare a monolithic deep Q-network to a modular network with a\ndedicated Q-learner for each variable. We find that the modular agent: a)\nrequires minimal exogenously determined exploration; b) has improved sample\nefficiency; and c) is more robust to out-of-domain perturbation.",
          "link": "http://arxiv.org/abs/2204.06608",
          "publishedOn": "2022-04-16T00:51:42.629Z",
          "wordCount": 589,
          "title": "Modularity benefits reinforcement learning agents with competing homeostatic drives. (arXiv:2204.06608v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nesterov_V/0/1/0/all/0/1\">Vitali Nesterov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torres_F/0/1/0/all/0/1\">Fabricio Arend Torres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagy_Huber_M/0/1/0/all/0/1\">Monika Nagy-Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samarin_M/0/1/0/all/0/1\">Maxim Samarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_V/0/1/0/all/0/1\">Volker Roth</a>",
          "description": "Considering smooth mappings from input vectors to continuous targets, our\ngoal is to characterise subspaces of the input domain, which are invariant\nunder such mappings. Thus, we want to characterise manifolds implicitly defined\nby level sets. Specifically, this characterisation should be of a global\nparametric form, which is especially useful for different informed data\nexploration tasks, such as building grid-based approximations, sampling points\nalong the level curves, or finding trajectories on the manifold. However,\nglobal parameterisations can only exist if the level sets are connected. For\nthis purpose, we introduce a novel and flexible class of neural networks that\ngeneralise input-convex networks. These networks represent functions that are\nguaranteed to have connected level sets forming smooth manifolds on the input\nspace. We further show that global parameterisations of these level sets can be\nalways found efficiently. Lastly, we demonstrate that our novel technique for\ncharacterising invariances is a powerful generative data exploration tool in\nreal-world applications, such as computational chemistry.",
          "link": "http://arxiv.org/abs/2204.07009",
          "publishedOn": "2022-04-16T00:51:42.621Z",
          "wordCount": 593,
          "title": "Learning Invariances with Generalised Input-Convex Neural Networks. (arXiv:2204.07009v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kachuee_M/0/1/0/all/0/1\">Mohammad Kachuee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nam_J/0/1/0/all/0/1\">Jinseok Nam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_S/0/1/0/all/0/1\">Sarthak Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Won_J/0/1/0/all/0/1\">Jin-Myung Won</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>",
          "description": "Skill routing is an important component in large-scale conversational\nsystems. In contrast to traditional rule-based skill routing, state-of-the-art\nsystems use a model-based approach to enable natural conversations. To provide\nsupervision signal required to train such models, ideas such as human\nannotation, replication of a rule-based system, relabeling based on user\nparaphrases, and bandit-based learning were suggested. However, these\napproaches: (a) do not scale in terms of the number of skills and skill\non-boarding, (b) require a very costly expert annotation/rule-design, (c)\nintroduce risks in the user experience with each model update. In this paper,\nwe present a scalable self-learning approach to explore routing alternatives\nwithout causing abrupt policy changes that break the user experience, learn\nfrom the user interaction, and incrementally improve the routing via frequent\nmodel refreshes. To enable such robust frequent model updates, we suggest a\nsimple and effective approach that ensures controlled policy updates for\nindividual domains, followed by an off-policy evaluation for making deployment\ndecisions without any need for lengthy A/B experimentation. We conduct various\noffline and online A/B experiments on a commercial large-scale conversational\nsystem to demonstrate the effectiveness of the proposed method in real-world\nproduction settings.",
          "link": "http://arxiv.org/abs/2204.07135",
          "publishedOn": "2022-04-16T00:51:42.512Z",
          "wordCount": null,
          "title": "Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational AI Systems. (arXiv:2204.07135v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.06252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md Jahidul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruobing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattar_J/0/1/0/all/0/1\">Junaed Sattar</a>",
          "description": "This paper presents a holistic approach to saliency-guided visual attention\nmodeling (SVAM) for use by autonomous underwater robots. Our proposed model,\nnamed SVAM-Net, integrates deep visual features at various scales and semantics\nfor effective salient object detection (SOD) in natural underwater images. The\nSVAM-Net architecture is configured in a unique way to jointly accommodate\nbottom-up and top-down learning within two separate branches of the network\nwhile sharing the same encoding layers. We design dedicated spatial attention\nmodules (SAMs) along these learning pathways to exploit the coarse-level and\nfine-level semantic features for SOD at four stages of abstractions. The\nbottom-up branch performs a rough yet reasonably accurate saliency estimation\nat a fast rate, whereas the deeper top-down branch incorporates a residual\nrefinement module (RRM) that provides fine-grained localization of the salient\nobjects. Extensive performance evaluation of SVAM-Net on benchmark datasets\nclearly demonstrates its effectiveness for underwater SOD. We also validate its\ngeneralization performance by several ocean trials' data that include test\nimages of diverse underwater scenes and waterbodies, and also images with\nunseen natural objects. Moreover, we analyze its computational feasibility for\nrobotic deployments and demonstrate its utility in several important use cases\nof visual attention modeling.",
          "link": "http://arxiv.org/abs/2011.06252",
          "publishedOn": "2022-04-16T00:51:42.448Z",
          "wordCount": null,
          "title": "SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater Robots. (arXiv:2011.06252v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07043",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Borovac_A/0/1/0/all/0/1\">Ana Borovac</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gudmundsson_S/0/1/0/all/0/1\">Steinn Gudmundsson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thorvardsson_G/0/1/0/all/0/1\">Gardar Thorvardsson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moghadam_S/0/1/0/all/0/1\">Saeed M. Moghadam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nevalainen_P/0/1/0/all/0/1\">P&#xe4;ivi Nevalainen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stevenson_N/0/1/0/all/0/1\">Nathan Stevenson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vanhatalo_S/0/1/0/all/0/1\">Sampsa Vanhatalo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Runarsson_T/0/1/0/all/0/1\">Thomas P. Runarsson</a>",
          "description": "Sharing medical data between institutions is difficult in practice due to\ndata protection laws and official procedures within institutions. Therefore,\nmost existing algorithms are trained on relatively small electroencephalogram\n(EEG) data sets which is likely to be detrimental to prediction accuracy. In\nthis work, we simulate a case when the data can not be shared by splitting the\npublicly available data set into disjoint sets representing data in individual\ninstitutions. We propose to train a (local) detector in each institution and\naggregate their individual predictions into one final prediction. Four\naggregation schemes are compared, namely, the majority vote, the mean, the\nweighted mean and the Dawid-Skene method. The approach allows different\ndetector architectures amongst the institutions. The method was validated on an\nindependent data set using only a subset of EEG channels. The ensemble reaches\naccuracy comparable to a single detector trained on all the data when\nsufficient amount of data is available in each institution. The weighted mean\naggregation scheme showed best overall performance, it was only marginally\noutperformed by the Dawid-Skene method when local detectors approach\nperformance of a single detector trained on all available data.",
          "link": "http://arxiv.org/abs/2204.07043",
          "publishedOn": "2022-04-16T00:51:42.371Z",
          "wordCount": null,
          "title": "Ensemble learning using individual neonatal data for seizure detection. (arXiv:2204.07043v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.09777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zela_A/0/1/0/all/0/1\">Arber Zela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siems_J/0/1/0/all/0/1\">Julien Siems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_L/0/1/0/all/0/1\">Lucas Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasik_J/0/1/0/all/0/1\">Jovita Lukasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1\">Margret Keuper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>",
          "description": "The most significant barrier to the advancement of Neural Architecture Search\n(NAS) is its demand for large computational resources, which hinders\nscientifically sound empirical evaluations of NAS methods. Tabular NAS\nbenchmarks have alleviated this problem substantially, making it possible to\nproperly evaluate NAS methods in seconds on commodity machines. However, an\nunintended consequence of tabular NAS benchmarks has been a focus on extremely\nsmall architectural search spaces since their construction relies on exhaustive\nevaluations of the space. This leads to unrealistic results that do not\ntransfer to larger spaces. To overcome this fundamental limitation, we propose\na methodology to create cheap NAS surrogate benchmarks for arbitrary search\nspaces. We exemplify this approach by creating surrogate NAS benchmarks on the\nexisting tabular NAS-Bench-101 and on two widely used NAS search spaces with up\nto $10^{21}$ architectures ($10^{13}$ times larger than any previous tabular\nNAS benchmark). We show that surrogate NAS benchmarks can model the true\nperformance of architectures better than tabular benchmarks (at a small\nfraction of the cost), that they lead to faithful estimates of how well\ndifferent NAS methods work on the original non-surrogate benchmark, and that\nthey can generate new scientific insight. We open-source all our code and\nbelieve that surrogate NAS benchmarks are an indispensable tool to extend\nscientifically sound work on NAS to large and exciting search spaces.",
          "link": "http://arxiv.org/abs/2008.09777",
          "publishedOn": "2022-04-16T00:51:42.371Z",
          "wordCount": null,
          "title": "Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks. (arXiv:2008.09777v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preuss_M/0/1/0/all/0/1\">Mike Preuss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>",
          "description": "Go-Explore achieved breakthrough performance on challenging reinforcement\nlearning (RL) tasks with sparse rewards. The key insight of Go-Explore was that\nsuccessful exploration requires an agent to first return to an interesting\nstate ('Go'), and only then explore into unknown terrain ('Explore'). We refer\nto such exploration after a goal is reached as 'post-exploration'. In this\npaper we present a systematic study of post-exploration, answering open\nquestions that the Go-Explore paper did not answer yet. First, we study the\nisolated potential of post-exploration, by turning it on and off within the\nsame algorithm. Subsequently, we introduce new methodology to adaptively decide\nwhen to post-explore and for how long to post-explore. Experiments on a range\nof MiniGrid environments show that post-exploration indeed boosts performance\n(with a bigger impact than tuning regular exploration parameters), and this\neffect is further enhanced by adaptively deciding when and for how long to\npost-explore. In short, our work identifies adaptive post-exploration as a\npromising direction for RL exploration research.",
          "link": "http://arxiv.org/abs/2203.16311",
          "publishedOn": "2022-04-14T00:58:52.151Z",
          "wordCount": null,
          "title": "When to Go, and When to Explore: The Benefit of Post-Exploration in Intrinsic Motivation. (arXiv:2203.16311v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12363",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saad_F/0/1/0/all/0/1\">Feras A. Saad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cusumano_Towner_M/0/1/0/all/0/1\">Marco Cusumano-Towner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mansinghka_V/0/1/0/all/0/1\">Vikash K. Mansinghka</a>",
          "description": "Estimating information-theoretic quantities such as entropy and mutual\ninformation is central to many problems in statistics and machine learning, but\nchallenging in high dimensions. This paper presents estimators of entropy via\ninference (EEVI), which deliver upper and lower bounds on many information\nquantities for arbitrary variables in a probabilistic generative model. These\nestimators use importance sampling with proposal distribution families that\ninclude amortized variational inference and sequential Monte Carlo, which can\nbe tailored to the target model and used to squeeze true information values\nwith high accuracy. We present several theoretical properties of EEVI and\ndemonstrate scalability and efficacy on two problems from the medical domain:\n(i) in an expert system for diagnosing liver disorders, we rank medical tests\naccording to how informative they are about latent diseases, given a pattern of\nobserved symptoms and patient attributes; and (ii) in a differential equation\nmodel of carbohydrate metabolism, we find optimal times to take blood glucose\nmeasurements that maximize information about a diabetic patient's insulin\nsensitivity, given their meal and medication schedule.",
          "link": "http://arxiv.org/abs/2202.12363",
          "publishedOn": "2022-04-14T00:58:52.150Z",
          "wordCount": null,
          "title": "Estimators of Entropy and Information via Inference in Probabilistic Models. (arXiv:2202.12363v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.01818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garttner_S/0/1/0/all/0/1\">Stephan G&#xe4;rttner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alpak_F/0/1/0/all/0/1\">Faruk O. Alpak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meier_A/0/1/0/all/0/1\">Andreas Meier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_N/0/1/0/all/0/1\">Nadja Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_F/0/1/0/all/0/1\">Florian Frank</a>",
          "description": "In recent years, convolutional neural networks (CNNs) have experienced an\nincreasing interest in their ability to perform a fast approximation of\neffective hydrodynamic parameters in porous media research and applications.\nThis paper presents a novel methodology for permeability prediction from\nmicro-CT scans of geological rock samples. The training data set for CNNs\ndedicated to permeability prediction consists of permeability labels that are\ntypically generated by classical lattice Boltzmann methods (LBM) that simulate\nthe flow through the pore space of the segmented image data. We instead perform\ndirect numerical simulation (DNS) by solving the stationary Stokes equation in\nan efficient and distributed-parallel manner. As such, we circumvent the\nconvergence issues of LBM that frequently are observed on complex pore\ngeometries, and therefore, improve the generality and accuracy of our training\ndata set. Using the DNS-computed permeabilities, a physics-informed CNN PhyCNN)\nis trained by additionally providing a tailored characteristic quantity of the\npore space. More precisely, by exploiting the connection to flow problems on a\ngraph representation of the pore space, additional information about confined\nstructures is provided to the network in terms of the maximum flow value, which\nis the key innovative component of our workflow. The robustness of this\napproach is reflected by very high prediction accuracy, which is observed for a\nvariety of sandstone samples from archetypal rock formations.",
          "link": "http://arxiv.org/abs/2109.01818",
          "publishedOn": "2022-04-14T00:58:52.138Z",
          "wordCount": null,
          "title": "Estimating permeability of 3D micro-CT images by physics-informed CNNs based on DNS. (arXiv:2109.01818v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aminpour_M/0/1/0/all/0/1\">Mohammad Aminpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaie_R/0/1/0/all/0/1\">Reza Alaie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kardani_N/0/1/0/all/0/1\">Navid Kardani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moridpour_S/0/1/0/all/0/1\">Sara Moridpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazem_M/0/1/0/all/0/1\">Majidreza Nazem</a>",
          "description": "Machine Learning (ML) algorithms are increasingly used as surrogate models to\nincrease the efficiency of stochastic reliability analyses in geotechnical\nengineering. This paper presents a highly efficient ML aided reliability\ntechnique that is able to accurately predict the results of a Monte Carlo (MC)\nreliability study, and yet performs 500 times faster. A complete MC reliability\nanalysis on anisotropic heterogeneous slopes consisting of 120,000 simulated\nsamples is conducted in parallel to the proposed ML aided stochastic technique.\nComparing the results of the complete MC study and the proposed ML aided\ntechnique, the expected errors of the proposed method are realistically\nexamined. Circumventing the time-consuming computation of factors of safety for\nthe training datasets, the proposed technique is more efficient than previous\nmethods. Different ML models, including Random Forest (RF), Support Vector\nMachine (SVM) and Artificial Neural Networks (ANN) are presented, optimised and\ncompared. The effects of the size and type of training and testing datasets are\ndiscussed. The expected errors of the ML predicted probability of failure are\ncharacterised by different levels of soil heterogeneity and anisotropy. Using\nonly 1% of MC samples to train ML surrogate models, the proposed technique can\naccurately predict the probability of failure with mean errors limited to 0.7%.\nThe proposed technique reduces the computational time required for our study\nfrom 306 days to only 14 hours, providing 500 times higher efficiency.",
          "link": "http://arxiv.org/abs/2204.06098",
          "publishedOn": "2022-04-14T00:58:52.137Z",
          "wordCount": null,
          "title": "Highly efficient reliability analysis of anisotropic heterogeneous slopes: Machine Learning aided Monte Carlo method. (arXiv:2204.06098v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11147",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cheng_S/0/1/0/all/0/1\">Siyuan Cheng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hong_H/0/1/0/all/0/1\">Haosen Hong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lian_J/0/1/0/all/0/1\">Jiazhang Lian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiang Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Self-supervised protein language models have proved their effectiveness in\nlearning the proteins representations. With the increasing computational power,\ncurrent protein language models pre-trained with millions of diverse sequences\ncan advance the parameter scale from million-level to billion-level and achieve\nremarkable improvement. However, those prevailing approaches rarely consider\nincorporating knowledge graphs (KGs), which can provide rich structured\nknowledge facts for better protein representations. We argue that informative\nbiology knowledge in KGs can enhance protein representation with external\nknowledge. In this work, we propose OntoProtein, the first general framework\nthat makes use of structure in GO (Gene Ontology) into protein pre-training\nmodels. We construct a novel large-scale knowledge graph that consists of GO\nand its related proteins, and gene annotation texts or protein sequences\ndescribe all nodes in the graph. We propose novel contrastive learning with\nknowledge-aware negative sampling to jointly optimize the knowledge graph and\nprotein embedding during pre-training. Experimental results show that\nOntoProtein can surpass state-of-the-art methods with pre-trained protein\nlanguage models in TAPE benchmark and yield better performance compared with\nbaselines in protein-protein interaction and protein function prediction. Code\nand datasets are available in https://github.com/zjunlp/OntoProtein.",
          "link": "http://arxiv.org/abs/2201.11147",
          "publishedOn": "2022-04-14T00:58:52.137Z",
          "wordCount": null,
          "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding. (arXiv:2201.11147v3 [q-bio.BM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.02552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Truong_D/0/1/0/all/0/1\">Dung Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_M/0/1/0/all/0/1\">Manisha Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkataraju_K/0/1/0/all/0/1\">Kannan Umadevi Venkataraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milham_M/0/1/0/all/0/1\">Michael Milham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delorme_A/0/1/0/all/0/1\">Arnaud Delorme</a>",
          "description": "Deep Learning has revolutionized various fields, including Computer Vision,\nNatural Language Processing, as well as Biomedical research. Within the field\nof neuroscience, specifically in electrophysiological neuroimaging, researchers\nare starting to explore leveraging deep learning to make predictions on their\ndata without extensive feature engineering. The availability of large-scale\ndatasets is a crucial aspect of allowing the experimentation of Deep Learning\nmodels. We are publishing the first large-scale clinical EEG dataset that\nsimplifies data access and management for Deep Learning. This dataset contains\neyes-closed EEG data prepared from a collection of 1,574 juvenile participants\nfrom the Healthy Brain Network. We demonstrate a use case integrating this\nframework, and discuss why providing such neuroinformatics infrastructure to\nthe community is critical for future scientific discoveries.",
          "link": "http://arxiv.org/abs/2203.02552",
          "publishedOn": "2022-04-14T00:58:52.137Z",
          "wordCount": null,
          "title": "A streamable large-scale clinical EEG dataset for Deep Learning. (arXiv:2203.02552v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yingxia Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>",
          "description": "In the era of big data, intellectual property-oriented scientific and\ntechnological resources show the trend of large data scale, high information\ndensity and low value density, which brings severe challenges to the effective\nuse of intellectual property resources, and the demand for mining hidden\ninformation in intellectual property is increasing. This makes intellectual\nproperty-oriented science and technology resource portraits and analysis of\nevolution become the current research hotspot. This paper sorts out the\nconstruction method of intellectual property resource intellectual portrait and\nits pre-work property entity extraction and entity completion from the aspects\nof algorithm classification and general process, and directions for improvement\nof future methods.",
          "link": "http://arxiv.org/abs/2204.06221",
          "publishedOn": "2022-04-14T00:58:52.136Z",
          "wordCount": null,
          "title": "Research on Intellectual Property Resource Profile and Evolution Law. (arXiv:2204.06221v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianren Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shangqi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tian Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaolin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>",
          "description": "Goal-conditioned Hierarchical Reinforcement Learning (HRL) is a promising\napproach for scaling up reinforcement learning (RL) techniques. However, it\noften suffers from training inefficiency as the action space of the high-level,\ni.e., the goal space, is large. Searching in a large goal space poses\ndifficulty for both high-level subgoal generation and low-level policy\nlearning. In this paper, we show that this problem can be effectively\nalleviated by restricting the high-level action space from the whole goal space\nto a $k$-step adjacent region of the current state using an adjacency\nconstraint. We theoretically prove that in a deterministic Markov Decision\nProcess (MDP), the proposed adjacency constraint preserves the optimal\nhierarchical policy, while in a stochastic MDP the adjacency constraint induces\na bounded state-value suboptimality determined by the MDP's transition\nstructure. We further show that this constraint can be practically implemented\nby training an adjacency network that can discriminate between adjacent and\nnon-adjacent subgoals. Experimental results on discrete and continuous control\ntasks including challenging simulated robot locomotion and manipulation tasks\nshow that incorporating the adjacency constraint significantly boosts the\nperformance of state-of-the-art goal-conditioned HRL approaches.",
          "link": "http://arxiv.org/abs/2111.00213",
          "publishedOn": "2022-04-14T00:58:52.136Z",
          "wordCount": null,
          "title": "Adjacency constraint for efficient hierarchical reinforcement learning. (arXiv:2111.00213v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krahenbuhl_P/0/1/0/all/0/1\">Philipp Kr&#xe4;henb&#xfc;hl</a>",
          "description": "In this paper, we present a system to train driving policies from experiences\ncollected not just from the ego-vehicle, but all vehicles that it observes.\nThis system uses the behaviors of other agents to create more diverse driving\nscenarios without collecting additional data. The main difficulty in learning\nfrom other vehicles is that there is no sensor information. We use a set of\nsupervisory tasks to learn an intermediate representation that is invariant to\nthe viewpoint of the controlling vehicle. This not only provides a richer\nsignal at training time but also allows more complex reasoning during\ninference. Learning how all vehicles drive helps predict their behavior at test\ntime and can avoid collisions. We evaluate this system in closed-loop driving\nsimulations. Our system outperforms all prior methods on the public CARLA\nLeaderboard by a wide margin, improving driving score by 25 and route\ncompletion rate by 24 points. Our method won the 2021 CARLA Autonomous Driving\nchallenge. Code and data are available at https://github.com/dotchen/LAV.",
          "link": "http://arxiv.org/abs/2203.11934",
          "publishedOn": "2022-04-14T00:58:52.135Z",
          "wordCount": null,
          "title": "Learning from All Vehicles. (arXiv:2203.11934v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahloujifar_S/0/1/0/all/0/1\">Saeed Mahloujifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sablayrolles_A/0/1/0/all/0/1\">Alexandre Sablayrolles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1\">Graham Cormode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>",
          "description": "Given a trained model and a data sample, membership-inference (MI) attacks\npredict whether the sample was in the model's training set. A common\ncountermeasure against MI attacks is to utilize differential privacy (DP)\nduring model training to mask the presence of individual examples. While this\nuse of DP is a principled approach to limit the efficacy of MI attacks, there\nis a gap between the bounds provided by DP and the empirical performance of MI\nattacks. In this paper, we derive bounds for the \\textit{advantage} of an\nadversary mounting a MI attack, and demonstrate tightness for the widely-used\nGaussian mechanism. We further show bounds on the \\textit{confidence} of MI\nattacks. Our bounds are much stronger than those obtained by DP analysis. For\nexample, analyzing a setting of DP-SGD with $\\epsilon=4$ would obtain an upper\nbound on the advantage of $\\approx0.36$ based on our analyses, while getting\nbound of $\\approx 0.97$ using the analysis of previous work that convert\n$\\epsilon$ to membership inference bounds.\n\nFinally, using our analysis, we provide MI metrics for models trained on\nCIFAR10 dataset. To the best of our knowledge, our analysis provides the\nstate-of-the-art membership inference bounds for the privacy.",
          "link": "http://arxiv.org/abs/2204.06106",
          "publishedOn": "2022-04-14T00:58:52.134Z",
          "wordCount": null,
          "title": "Optimal Membership Inference Bounds for Adaptive Composition of Sampled Gaussian Mechanisms. (arXiv:2204.06106v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toit_J/0/1/0/all/0/1\">J du Toit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preez_J/0/1/0/all/0/1\">J du Preez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolhuter_R/0/1/0/all/0/1\">R Wolhuter</a>",
          "description": "We present a comparison study between a cluster and factor graph\nrepresentation of LDPC codes. In probabilistic graphical models, cluster graphs\nretain useful dependence between random variables during inference, which are\nadvantageous in terms of computational cost, convergence speed, and accuracy of\nmarginal probabilities. This study investigates these benefits in the context\nof LDPC codes and shows that a cluster graph representation outperforms the\ntraditional factor graph representation.",
          "link": "http://arxiv.org/abs/2204.06350",
          "publishedOn": "2022-04-14T00:58:52.134Z",
          "wordCount": null,
          "title": "LDPC codes: comparing cluster graphs to factor graphs. (arXiv:2204.06350v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06310",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wodzinski_M/0/1/0/all/0/1\">Marek Wodzinski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Daniol_M/0/1/0/all/0/1\">Mateusz Daniol</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Socha_M/0/1/0/all/0/1\">Miroslaw Socha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hemmerling_D/0/1/0/all/0/1\">Daria Hemmerling</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stanuch_M/0/1/0/all/0/1\">Maciej Stanuch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Skalski_A/0/1/0/all/0/1\">Andrzej Skalski</a>",
          "description": "The goal of this work is to propose a robust, fast, and fully automatic\nmethod for personalized cranial defect reconstruction and implant modeling.\n\nWe propose a two-step deep learning-based method using a modified U-Net\narchitecture to perform the defect reconstruction, and a dedicated iterative\nprocedure to improve the implant geometry, followed by automatic generation of\nmodels ready for 3-D printing. We propose a cross-case augmentation based on\nimperfect image registration combining cases from different datasets. We\nperform ablation studies regarding different augmentation strategies and\ncompare them to other state-of-the-art methods.\n\nWe evaluate the method on three datasets introduced during the AutoImplant\n2021 challenge, organized jointly with the MICCAI conference. We perform the\nquantitative evaluation using the Dice and boundary Dice coefficients, and the\nHausdorff distance. The average Dice coefficient, boundary Dice coefficient,\nand the 95th percentile of Hausdorff distance are 0.91, 0.94, and 1.53 mm\nrespectively. We perform an additional qualitative evaluation by 3-D printing\nand visualization in mixed reality to confirm the implant's usefulness.\n\nWe propose a complete pipeline that enables one to create the cranial implant\nmodel ready for 3-D printing. The described method is a greatly extended\nversion of the method that scored 1st place in all AutoImplant 2021 challenge\ntasks. We freely release the source code, that together with the open datasets,\nmakes the results fully reproducible. The automatic reconstruction of cranial\ndefects may enable manufacturing personalized implants in a significantly\nshorter time, possibly allowing one to perform the 3-D printing process\ndirectly during a given intervention. Moreover, we show the usability of the\ndefect reconstruction in mixed reality that may further reduce the surgery\ntime.",
          "link": "http://arxiv.org/abs/2204.06310",
          "publishedOn": "2022-04-14T00:58:52.121Z",
          "wordCount": null,
          "title": "Deep Learning-based Framework for Automatic Cranial Defect Reconstruction and Implant Modeling. (arXiv:2204.06310v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michel_P/0/1/0/all/0/1\">Paul Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>",
          "description": "As machine learning models are deployed ever more broadly, it becomes\nincreasingly important that they are not only able to perform well on their\ntraining distribution, but also yield accurate predictions when confronted with\ndistribution shift. The Distributionally Robust Optimization (DRO) framework\nproposes to address this issue by training models to minimize their expected\nrisk under a collection of distributions, to imitate test-time shifts. This is\nmost commonly achieved by instance-level re-weighting of the training objective\nto emulate the likelihood ratio with possible test distributions, which allows\nfor estimating their empirical risk via importance sampling (assuming that they\nare subpopulations of the training distribution). However, re-weighting schemes\nin the literature are usually limited due to the difficulty of keeping the\noptimization problem tractable and the complexity of enforcing normalization\nconstraints. In this paper, we show that three simple ideas -- mini-batch level\nnormalization, a KL penalty and simultaneous gradient updates -- allow us to\ntrain models with DRO using a broader class of parametric likelihood ratios. In\na series of experiments on both image and text classification benchmarks, we\nfind that models trained with the resulting parametric adversaries are\nconsistently more robust to subpopulation shifts when compared to other DRO\napproaches, and that the method performs reliably well with little\nhyper-parameter tuning. Code to reproduce our experiments can be found at\nhttps://github.com/pmichel31415/P-DRO.",
          "link": "http://arxiv.org/abs/2204.06340",
          "publishedOn": "2022-04-14T00:58:52.121Z",
          "wordCount": null,
          "title": "Distributionally Robust Models with Parametric Likelihood Ratios. (arXiv:2204.06340v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wallin_E/0/1/0/all/0/1\">Erik Wallin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiberg_V/0/1/0/all/0/1\">Viktor Wiberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vesterlund_F/0/1/0/all/0/1\">Folke Vesterlund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmgren_J/0/1/0/all/0/1\">Johan Holmgren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Persson_H/0/1/0/all/0/1\">Henrik Persson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Servin_M/0/1/0/all/0/1\">Martin Servin</a>",
          "description": "We present a method that uses high-resolution topography data of rough\nterrain, and ground vehicle simulation, to predict traversability.\nTraversability is expressed as three independent measures: the ability to\ntraverse the terrain at a target speed, energy consumption, and acceleration.\nThe measures are continuous and reflect different objectives for planning that\ngo beyond binary classification. A deep neural network is trained to predict\nthe traversability measures from the local heightmap and target speed. To\nproduce training data, we use an articulated vehicle with wheeled bogie\nsuspensions and procedurally generated terrains. We evaluate the model on\nlaser-scanned forest terrains, previously unseen by the model. The model\npredicts traversability with an accuracy of 90%. Predictions rely on features\nfrom the high-dimensional terrain data that surpass local roughness and slope\nrelative to the heading. Correlations show that the three traversability\nmeasures are complementary to each other. With an inference speed 3000 times\nfaster than the ground truth simulation and trivially parallelizable, the model\nis well suited for traversability analysis and optimal path planning over large\nareas.",
          "link": "http://arxiv.org/abs/2203.16354",
          "publishedOn": "2022-04-14T00:58:52.121Z",
          "wordCount": null,
          "title": "Learning multiobjective rough terrain traversability. (arXiv:2203.16354v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaoli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jun Han</a>",
          "description": "Since 2016, we have witnessed the tremendous growth of artificial\nintelligence+visualization (AI+VIS) research. However, existing survey papers\non AI+VIS focus on visual analytics and information visualization, not\nscientific visualization (SciVis). In this paper, we survey related deep\nlearning (DL) works in SciVis, specifically in the direction of DL4SciVis:\ndesigning DL solutions for solving SciVis problems. To stay focused, we\nprimarily consider works that handle scalar and vector field data but exclude\nmesh data. We classify and discuss these works along six dimensions: domain\nsetting, research task, learning type, network architecture, loss function, and\nevaluation metric. The paper concludes with a discussion of the remaining gaps\nto fill along the discussed dimensions and the grand challenges we need to\ntackle as a community. This state-of-the-art survey guides SciVis researchers\nin gaining an overview of this emerging topic and points out future directions\nto grow this research.",
          "link": "http://arxiv.org/abs/2204.06504",
          "publishedOn": "2022-04-14T00:58:52.118Z",
          "wordCount": null,
          "title": "DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific Visualization. (arXiv:2204.06504v1 [cs.GR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Joanna Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlin_K/0/1/0/all/0/1\">Kuba Perlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamalakara_S/0/1/0/all/0/1\">Siddhartha Rao Kamalakara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araujo_J/0/1/0/all/0/1\">Jo&#xe3;o G.M. Ara&#xfa;jo</a>",
          "description": "Modern large language models require distributed training strategies due to\ntheir size. The challenges of efficiently and robustly training them are met\nwith rapid developments on both software and hardware frontiers. In this\ntechnical report, we explore challenges and design decisions associated with\ndeveloping a scalable training framework, and present a quantitative analysis\nof efficiency improvements coming from adopting new software and hardware\nsolutions.",
          "link": "http://arxiv.org/abs/2204.06514",
          "publishedOn": "2022-04-14T00:58:52.118Z",
          "wordCount": null,
          "title": "Scalable Training of Language Models using JAX pjit and TPUv4. (arXiv:2204.06514v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gangwar_A/0/1/0/all/0/1\">Amisha Gangwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_T/0/1/0/all/0/1\">Tanvi Mehta</a>",
          "description": "Sentiment Analysis is a vital research topic in the field of Computer\nScience. With the accelerated development of Information Technology and social\nnetworks, a massive amount of data related to comment texts has been generated\non web applications or social media platforms like Twitter. Due to this, people\nhave actively started proliferating general information and the information\nrelated to political opinions, which becomes an important reason for analyzing\npublic reactions. Most researchers have used social media specifics or contents\nto analyze and predict public opinion concerning political events. This\nresearch proposes an analytical study using Israeli political Twitter data to\ninterpret public opinion towards the Palestinian-Israeli conflict. The\nattitudes of ethnic groups and opinion leaders in the form of tweets are\nanalyzed using Machine Learning algorithms like Support Vector Classifier\n(SVC), Decision Tree (DT), and Naive Bayes (NB). Finally, a comparative\nanalysis is done based on experimental results from different models.",
          "link": "http://arxiv.org/abs/2204.06515",
          "publishedOn": "2022-04-14T00:58:52.118Z",
          "wordCount": null,
          "title": "Sentiment Analysis of Political Tweets for Israel using Machine Learning. (arXiv:2204.06515v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changjun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaomo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofang Wang</a>",
          "description": "The demand of probabilistic time series forecasting has been recently raised\nin various dynamic system scenarios, for example, system identification and\nprognostic and health management of machines. To this end, we combine the\nadvances in both deep generative models and state space model (SSM) to come up\nwith a novel, data-driven deep probabilistic sequence model. Specifically, we\nfollow the popular encoder-decoder generative structure to build the recurrent\nneural networks (RNN) assisted variational sequence model on an augmented\nrecurrent input space, which could induce rich stochastic sequence dependency.\nBesides, in order to alleviate the inconsistency issue of the posterior between\ntraining and predicting as well as improving the mining of dynamic patterns, we\n(i) propose using a lagged hybrid output as input for the posterior at next\ntime step, which brings training and predicting into alignment; and (ii)\nfurther devise a generalized auto-regressive strategy that encodes all the\nhistorical dependencies for the posterior. Thereafter, we first investigate the\nmethodological characteristics of the proposed deep probabilistic sequence\nmodel on toy cases, and then comprehensively demonstrate the superiority of our\nmodel against existing deep probabilistic SSM models through extensive\nnumerical experiments on eight system identification benchmarks from various\ndynamic systems. Finally, we apply our sequence model to a real-world\ncentrifugal compressor forecasting problem, and again verify its outstanding\nperformance by quantifying the time series predictive distribution.",
          "link": "http://arxiv.org/abs/2106.05848",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems. (arXiv:2106.05848v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bentley_P/0/1/0/all/0/1\">Peter J Bentley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Soo Ling Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaier_A/0/1/0/all/0/1\">Adam Gaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_L/0/1/0/all/0/1\">Linh Tran</a>",
          "description": "Constrained optimization problems can be difficult because their search\nspaces have properties not conducive to search, e.g., multimodality,\ndiscontinuities, or deception. To address such difficulties, considerable\nresearch has been performed on creating novel evolutionary algorithms or\nspecialized genetic operators. However, if the representation that defined the\nsearch space could be altered such that it only permitted valid solutions that\nsatisfied the constraints, the task of finding the optimal would be made more\nfeasible without any need for specialized optimization algorithms. We propose\nConstrained Optimization in Latent Space (COIL), which uses a VAE to generate a\nlearned latent representation from a dataset comprising samples from the valid\nregion of the search space according to a constraint, thus enabling the\noptimizer to find the objective in the new space defined by the learned\nrepresentation. Preliminary experiments show promise: compared to an identical\nGA using a standard representation that cannot meet the constraints or find fit\nsolutions, COIL with its learned latent representation can perfectly satisfy\ndifferent types of constraints while finding high-fitness solutions.",
          "link": "http://arxiv.org/abs/2202.02163",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "COIL: Constrained Optimization in Learned Latent Space -- Learning Representations for Valid Solutions. (arXiv:2202.02163v3 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.02194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yibo Zhou</a>",
          "description": "In some scenarios, classifier requires detecting out-of-distribution samples\nfar from its training data. With desirable characteristics, reconstruction\nautoencoder-based methods deal with this problem by using input reconstruction\nerror as a metric of novelty vs. normality. We formulate the essence of such\napproach as a quadruplet domain translation with an intrinsic bias to only\nquery for a proxy of conditional data uncertainty. Accordingly, an improvement\ndirection is formalized as maximumly compressing the autoencoder's latent space\nwhile ensuring its reconstructive power for acting as a described domain\ntranslator. From it, strategies are introduced including semantic\nreconstruction, data certainty decomposition and normalized L2 distance to\nsubstantially improve original methods, which together establish\nstate-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of\nCIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method\nworks without any additional data, hard-to-implement structure, time-consuming\npipeline, and even harming the classification accuracy of known classes.",
          "link": "http://arxiv.org/abs/2203.02194",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection. (arXiv:2203.02194v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.11011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1\">Jibing Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuewen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Wenzheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Massive open online courses (MOOCs), which provide a large-scale interactive\nparticipation and open access via the web, are becoming a modish way for online\nand distance education. To help users have a better study experience, many MOOC\nplatforms have provided the services of recommending courses to users. However,\nwe argue that directly recommending a course to users will ignore the expertise\nlevels of different users. To fill this gap, this paper studies the problem of\nconcept recommendation in a more fine-grained view. We propose a novel\nHeterogeneous Information Networks based Concept Recommender with Reinforcement\nLearning (HinCRec-RL) incorporated for concept recommendation in MOOCs.\nSpecifically, we first formulate the concept recommendation in MOOCs as a\nreinforcement learning problem to better model the dynamic interaction among\nusers and knowledge concepts. In addition, to mitigate the data sparsity issue\nwhich also exists in many other recommendation tasks, we consider a\nheterogeneous information network (HIN) among users, courses, videos and\nconcepts, to better learn the semantic representation of users. In particular,\nwe use the meta-paths on HIN to guide the propagation of users' preferences and\npropose a heterogeneous graph attention network to represent the meta-paths. To\nvalidate the effectiveness of our proposed approach, we conduct comprehensive\nexperiments on a real-world dataset from XuetangX, a popular MOOC platform from\nChina. The promising results show that our proposed approach can outperform\nother baselines.",
          "link": "http://arxiv.org/abs/2203.11011",
          "publishedOn": "2022-04-14T00:58:52.117Z",
          "wordCount": null,
          "title": "Reinforced MOOCs Concept Recommendation in Heterogeneous Information Networks. (arXiv:2203.11011v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06164",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ding_S/0/1/0/all/0/1\">Shaojin Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Weiran Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+David_R/0/1/0/all/0/1\">Robert David</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Botros_R/0/1/0/all/0/1\">Rami Botros</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Panigrahy_R/0/1/0/all/0/1\">Rina Panigrahy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_D/0/1/0/all/0/1\">Dongseong Hwang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1\">Ian McGraw</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prabhavalkar_R/0/1/0/all/0/1\">Rohit Prabhavalkar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>",
          "description": "In this paper, we propose a dynamic cascaded encoder Automatic Speech\nRecognition (ASR) model, which unifies models for different deployment\nscenarios. Moreover, the model can significantly reduce model size and power\nconsumption without loss of quality. Namely, with the dynamic cascaded encoder\nmodel, we explore three techniques to maximally boost the performance of each\nmodel size: 1) Use separate decoders for each sub-model while sharing the\nencoders; 2) Use funnel-pooling to improve the encoder efficiency; 3) Balance\nthe size of causal and non-causal encoders to improve quality and fit\ndeployment constraints. Overall, the proposed large-medium model has 30%\nsmaller size and reduces power consumption by 33%, compared to the baseline\ncascaded encoder model. The triple-size model that unifies the large, medium,\nand small models achieves 37% total size reduction with minimal quality loss,\nwhile substantially reducing the engineering efforts of having separate models.",
          "link": "http://arxiv.org/abs/2204.06164",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes. (arXiv:2204.06164v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.13695",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fonseca_E/0/1/0/all/0/1\">Erika Fonseca</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Galkin_B/0/1/0/all/0/1\">Boris Galkin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Amer_R/0/1/0/all/0/1\">Ramy Amer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+DaSilva_L/0/1/0/all/0/1\">Luiz A. DaSilva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dusparic_I/0/1/0/all/0/1\">Ivana Dusparic</a>",
          "description": "Providing reliable connectivity to cellular-connected UAV can be very\nchallenging; their performance highly depends on the nature of the surrounding\nenvironment, such as density and heights of the ground BSs. On the other hand,\ntall buildings might block undesired interference signals from ground BSs,\nthereby improving the connectivity between the UAVs and their serving BSs. To\naddress the connectivity of UAVs in such environments, this paper proposes a RL\nalgorithm to dynamically optimise the height of a UAV as it moves through the\nenvironment, with the goal of increasing the throughput or spectrum efficiency\nthat it experiences. The proposed solution is evaluated in two settings: using\na series of generated environments where we vary the number of BS and building\ndensities, and in a scenario using real-world data obtained from an experiment\nin Dublin, Ireland. Results show that our proposed RL-based solution improves\nUAVs QoS by 6% to 41%, depending on the scenario. We also conclude that, when\nflying at heights higher than the buildings, building density variation has no\nimpact on UAV QoS. On the other hand, BS density can negatively impact UAV QoS,\nwith higher numbers of BSs generating more interference and deteriorating UAV\nperformance.",
          "link": "http://arxiv.org/abs/2007.13695",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "Adaptive Height Optimisation for Cellular-Connected UAVs using Reinforcement Learning. (arXiv:2007.13695v3 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.14181",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Roychowdhury_S/0/1/0/all/0/1\">Sohini Roychowdhury</a>",
          "description": "Automated segmentation of pathological regions of interest aids medical image\ndiagnostics and follow-up care. However, accurate pathological segmentations\nrequire high quality of annotated data that can be both cost and time intensive\nto generate. In this work, we propose an automated two-step method that detects\na minimal image subset required to train segmentation models by evaluating the\nquality of medical images from 3D image stacks using a U-net++ model. These\nimages that represent a lack of quality training can then be annotated and used\nto fully train a U-net-based segmentation model. The proposed QU-net++ model\ndetects this lack of quality training based on the disagreement in\nsegmentations produced from the final two output layers. The proposed model\nisolates around 10% of the slices per 3D image stack and can scale across\nimaging modalities to segment cysts in OCT images and ground glass opacity\n(GGO) in lung CT images with Dice scores in the range 0.56-0.72. Thus, the\nproposed method can be applied for cost effective multi-modal pathology\nsegmentation tasks.",
          "link": "http://arxiv.org/abs/2110.14181",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "QU-net++: Image Quality Detection Framework for Segmentation of Medical 3D Image Stacks. (arXiv:2110.14181v4 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.13858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenhua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1\">Dong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haozhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fanglin Liu</a>",
          "description": "Deep learning oriented named entity recognition (DNER) has gradually become\nthe paradigm of knowledge discovery, which greatly promotes domain\nintelligence. However, the current activation function of DNER fails to treat\ngradient vanishing, no negative output or non-differentiable existence, which\nmay impede knowledge exploration caused by the omission and incomplete\nrepresentation of latent semantics. To break through the dilemma, we present a\nnovel activation function termed KDAC. Detailly, KDAC is an aggregation\nfunction with multiple conversion modes. The backbone of the activation region\nis the interaction between exponent and linearity, and the both ends extend\nthrough adaptive linear divergence, which surmounts the obstacle of gradient\nvanishing and no negative output. Crucially, the non-differentiable points are\nalerted and eliminated by an approximate smoothing algorithm. KDAC has a series\nof brilliant properties, including nonlinear, stable near-linear transformation\nand derivative, as well as dynamic style, etc. We perform experiments based on\nBERT-BiLSTM-CNN-CRF model on six benchmark datasets containing different domain\nknowledge, such as Weibo, Clinical, E-commerce, Resume, HAZOP and People's\ndaily. The evaluation results show that KDAC is advanced and effective, and can\nprovide more generalized activation to stimulate the performance of DNER. We\nhope that KDAC can be exploited as a promising activation function to devote\nitself to the construction of knowledge.",
          "link": "http://arxiv.org/abs/2111.13858",
          "publishedOn": "2022-04-14T00:58:52.116Z",
          "wordCount": null,
          "title": "Why KDAC? A general activation function for knowledge discovery. (arXiv:2111.13858v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhat_A/0/1/0/all/0/1\">Avinash Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coursey_A/0/1/0/all/0/1\">Austin Coursey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1\">Grace Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sixian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahar_N/0/1/0/all/0/1\">Nadia Nahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shurui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kastner_C/0/1/0/all/0/1\">Christian K&#xe4;stner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jin L.C. Guo</a>",
          "description": "Machine learning models have been widely developed, released, and adopted in\nnumerous applications. Meanwhile, the documentation practice for machine\nlearning models often falls short of established practices for traditional\nsoftware components, which impedes model accountability, inadvertently abets\ninappropriate or misuse of models, and may trigger negative social impact.\nRecently, model cards, a template for documenting machine learning models, have\nattracted notable attention, but their impact on the practice of model\ndocumentation is unclear. In this work, we examine publicly available model\ncards and other similar documentation. Our analysis reveals a substantial gap\nbetween the suggestions made in the original model card work and the content in\nactual documentation. Motivated by this observation and literature on fields\nsuch as software documentation, interaction design, and traceability, we\nfurther propose a set of design guidelines that aim to support the\ndocumentation practice for machine learning models including (1) the\ncollocation of documentation environment with the coding environment, (2)\nnudging the consideration of model card sections during model development, and\n(3) documentation derived from and traced to the source. We designed a\nprototype tool named DocML following those guidelines to support model\ndevelopment in computational notebooks. A lab study reveals the benefit of our\ntool to shift the behavior of data scientists towards documentation quality and\naccountability.",
          "link": "http://arxiv.org/abs/2204.06425",
          "publishedOn": "2022-04-14T00:58:52.115Z",
          "wordCount": null,
          "title": "Aspirations and Practice of Model Documentation: Moving the Needle with Nudging and Traceability. (arXiv:2204.06425v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Le Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tongyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bowen Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_W/0/1/0/all/0/1\">Weifeng Lv</a>",
          "description": "Given a sequence of sets, where each set is associated with a timestamp and\ncontains an arbitrary number of elements, the task of temporal sets prediction\naims to predict the elements in the subsequent set. Previous studies for\ntemporal sets prediction mainly capture each user's evolutionary preference by\nlearning from his/her own sequence. Although insightful, we argue that: 1) the\ncollaborative signals latent in different users' sequences are essential but\nhave not been exploited; 2) users also tend to show stationary preferences\nwhile existing methods fail to consider. To this end, we propose an integrated\nlearning framework to model both the evolutionary and the stationary\npreferences of users for temporal sets prediction, which first constructs a\nuniversal sequence by chronologically arranging all the user-set interactions,\nand then learns on each user-set interaction. In particular, for each user-set\ninteraction, we first design an evolutionary user preference modelling\ncomponent to track the user's time-evolving preference and exploit the latent\ncollaborative signals among different users. This component maintains a memory\nbank to store memories of the related user and elements, and continuously\nupdates their memories based on the currently encoded messages and the past\nmemories. Then, we devise a stationary user preference modelling module to\ndiscover each user's personalized characteristics according to the historical\nsequence, which adaptively aggregates the previously interacted elements from\ndual perspectives with the guidance of the user's and elements' embeddings.\nFinally, we develop a set-batch algorithm to improve the model efficiency,\nwhich can create time-consistent batches in advance and achieve 3.5x training\nspeedups on average. Experiments on real-world datasets demonstrate the\neffectiveness and good interpretability of our approach.",
          "link": "http://arxiv.org/abs/2204.05490",
          "publishedOn": "2022-04-14T00:58:52.115Z",
          "wordCount": null,
          "title": "Modelling Evolutionary and Stationary User Preferences for Temporal Sets Prediction. (arXiv:2204.05490v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1\">Hyunjin Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seungwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chanyoung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>",
          "description": "Hypergraphs (i.e., sets of hyperedges) naturally represent group relations\n(e.g., researchers co-authoring a paper and ingredients used together in a\nrecipe), each of which corresponds to a hyperedge (i.e., a subset of nodes).\nPredicting future or missing hyperedges bears significant implication for many\napplications (e.g., collaboration and recipe recommendation). What makes\nhyperedge prediction particularly challenging is the vast number of\nnon-hyperedge subsets, which grows exponentially with the number of nodes.\nSince it is prohibitive to use all of them as negative examples for model\ntraining, it is inevitable to sample a very small portion of them, and to this\nend, heuristic sampling schemes have been employed. However, trained models\nsuffer from poor generalization capability for examples of different natures.\nIn this paper, we propose AHP, an adversarial training-based\nhyperedge-prediction method. It learns to sample negative examples without\nrelying on any heuristic schemes. Using six real hypergraphs, we show that AHP\ngeneralizes better to negative examples of various natures. It yields up to\n28.2% higher AUROC than best existing methods and often even outperforms its\nvariants with sampling schemes tailored to test sets.",
          "link": "http://arxiv.org/abs/2204.06353",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "AHP: Learning to Negative Sample for Hyperedge Prediction. (arXiv:2204.06353v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Solmaz_G/0/1/0/all/0/1\">G&#xfc;rkan Solmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cirillo_F/0/1/0/all/0/1\">Flavio Cirillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maresca_F/0/1/0/all/0/1\">Fabio Maresca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Anagha Gode Anil Kumar</a>",
          "description": "Weak supervision (WS) is an alternative to the traditional supervised\nlearning to address the need for ground truth. Data programming is a practical\nWS approach that allows programmatic labeling data samples using labeling\nfunctions (LFs) instead of hand-labeling each data point. However, the existing\napproach fails to fully exploit the domain knowledge encoded into LFs,\nespecially when the LFs' coverage is low. This is due to the common data\nprogramming pipeline that neglects to utilize data features during the\ngenerative process. This paper proposes a new approach called reinforced\nlabeling (RL). Given an unlabeled dataset and a set of LFs, RL augments the\nLFs' outputs to cases not covered by LFs based on similarities among samples.\nThus, RL can lead to higher labeling coverage for training an end classifier.\nThe experiments on several domains (classification of YouTube comments, wine\nquality, and weather prediction) result in considerable gains. The new approach\nproduces significant performance improvement, leading up to +21 points in\naccuracy and +61 points in F1 scores compared to the state-of-the-art data\nprogramming approach.",
          "link": "http://arxiv.org/abs/2204.06436",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "Label Augmentation with Reinforced Labeling for Weak Supervision. (arXiv:2204.06436v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srinivasa_R/0/1/0/all/0/1\">Rakshith S Srinivasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Cheng Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_B/0/1/0/all/0/1\">Brandon Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spaeder_J/0/1/0/all/0/1\">Jeffrey Spaeder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Cao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_L/0/1/0/all/0/1\">Lucas Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "The ongoing pandemic has highlighted the importance of reliable and efficient\nclinical trials in healthcare. Trial sites, where the trials are conducted, are\nchosen mainly based on feasibility in terms of medical expertise and access to\na large group of patients. More recently, the issue of diversity and inclusion\nin clinical trials is gaining importance. Different patient groups may\nexperience the effects of a medical drug/ treatment differently and hence need\nto be included in the clinical trials. These groups could be based on\nethnicity, co-morbidities, age, or economic factors. Thus, designing a method\nfor trial site selection that accounts for both feasibility and diversity is a\ncrucial and urgent goal. In this paper, we formulate this problem as a ranking\nproblem with fairness constraints. Using principles of fairness in machine\nlearning, we learn a model that maps a clinical trial description to a ranked\nlist of potential trial sites. Unlike existing fairness frameworks, the group\nmembership of each trial site is non-binary: each trial site may have access to\npatients from multiple groups. We propose fairness criteria based on\ndemographic parity to address such a multi-group membership scenario. We test\nour method on 480 real-world clinical trials and show that our model results in\na list of potential trial sites that provides access to a diverse set of\npatients while also ensuing a high number of enrolled patients.",
          "link": "http://arxiv.org/abs/2204.06501",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "Clinical trial site matching with improved diversity using fair policy learning. (arXiv:2204.06501v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.12650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avram_A/0/1/0/all/0/1\">Andrei-Marius Avram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catrina_D/0/1/0/all/0/1\">Darius Catrina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cercel_D/0/1/0/all/0/1\">Dumitru-Clementin Cercel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dascalu_M/0/1/0/all/0/1\">Mihai Dasc&#x103;lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rebedea_T/0/1/0/all/0/1\">Traian Rebedea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pais_V/0/1/0/all/0/1\">Vasile P&#x103;i&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tufis_D/0/1/0/all/0/1\">Dan Tufi&#x15f;</a>",
          "description": "Running large-scale pre-trained language models in computationally\nconstrained environments remains a challenging problem yet to be addressed,\nwhile transfer learning from these models has become prevalent in Natural\nLanguage Processing tasks. Several solutions, including knowledge distillation,\nnetwork quantization, or network pruning have been previously proposed;\nhowever, these approaches focus mostly on the English language, thus widening\nthe gap when considering low-resource languages. In this work, we introduce\nthree light and fast versions of distilled BERT models for the Romanian\nlanguage: Distil-BERT-base-ro, Distil-RoBERT-base, and\nDistilMulti-BERT-base-ro. The first two models resulted from the individual\ndistillation of knowledge from two base versions of Romanian BERTs available in\nliterature, while the last one was obtained by distilling their ensemble. To\nour knowledge, this is the first attempt to create publicly available Romanian\ndistilled BERT models, which were thoroughly evaluated on five tasks:\npart-of-speech tagging, named entity recognition, sentiment analysis, semantic\ntextual similarity, and dialect identification. Our experimental results argue\nthat the three distilled models offer performance comparable to their teachers,\nwhile being twice as fast on a GPU and ~35% smaller. In addition, we further\ntest the similarity between the predictions of our students versus their\nteachers by measuring their label and probability loyalty, together with\nregression loyalty - a new metric introduced in this work.",
          "link": "http://arxiv.org/abs/2112.12650",
          "publishedOn": "2022-04-14T00:58:52.114Z",
          "wordCount": null,
          "title": "Distilling the Knowledge of Romanian BERTs Using Multiple Teachers. (arXiv:2112.12650v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06301",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Li_X/0/1/0/all/0/1\">Xiangru Li</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wang_Z/0/1/0/all/0/1\">Zhu Wang</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zeng_S/0/1/0/all/0/1\">Si Zeng</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Liao_C/0/1/0/all/0/1\">Caixiu Liao</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Du_B/0/1/0/all/0/1\">Bing Du</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kong_X/0/1/0/all/0/1\">X. Kong</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Li_H/0/1/0/all/0/1\">Haining Li</a>",
          "description": "The accuracy of the estimated stellar atmospheric parameter decreases\nevidently with the decreasing of spectral signal-to-noise ratio (SNR) and there\nare a huge amount of this kind observations, especially in case of SNR$<$30.\nTherefore, it is helpful to improve the parameter estimation performance for\nthese spectra and this work studied the ($T_\\texttt{eff}, \\log~g$, [Fe/H])\nestimation problem for LAMOST DR8 low-resolution spectra with 20$\\leq$SNR$<$30.\nWe proposed a data-driven method based on machine learning techniques. Firstly,\nthis scheme detected stellar atmospheric parameter-sensitive features from\nspectra by the Least Absolute Shrinkage and Selection Operator (LASSO),\nrejected ineffective data components and irrelevant data. Secondly, a\nMulti-layer Perceptron (MLP) method was used to estimate stellar atmospheric\nparameters from the LASSO features. Finally, the performance of the LASSO-MLP\nwas evaluated by computing and analyzing the consistency between its estimation\nand the reference from the APOGEE (Apache Point Observatory Galactic Evolution\nExperiment) high-resolution spectra. Experiments show that the Mean Absolute\nErrors (MAE) of $T_\\texttt{eff}, \\log~g$, [Fe/H] are reduced from the LASP\n(137.6 K, 0.195 dex, 0.091 dex) to LASSO-MLP (84.32 K, 0.137 dex, 0.063 dex),\nwhich indicate evident improvements on stellar atmospheric parameter\nestimation. In addition, this work estimated the stellar atmospheric parameters\nfor 1,162,760 low-resolution spectra with 20$\\leq$SNR$<$30 from LAMOST DR8\nusing LASSO-MLP, and released the estimation catalog, learned model,\nexperimental code, trained model, training data and test data for scientific\nexploration and algorithm study.",
          "link": "http://arxiv.org/abs/2204.06301",
          "publishedOn": "2022-04-14T00:58:52.113Z",
          "wordCount": null,
          "title": "Estimation of stellar atmospheric parameters from LAMOST DR8 low-resolution spectra with 20$\\leq$SNR$<$30. (arXiv:2204.06301v1 [astro-ph.GA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachdeva_R/0/1/0/all/0/1\">Ragav Sachdeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammond_R/0/1/0/all/0/1\">Ravi Hammond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bockman_J/0/1/0/all/0/1\">James Bockman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arthur_A/0/1/0/all/0/1\">Alec Arthur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smart_B/0/1/0/all/0/1\">Brandon Smart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Craggs_D/0/1/0/all/0/1\">Dustin Craggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doan_A/0/1/0/all/0/1\">Anh-Dzung Doan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rowntree_T/0/1/0/all/0/1\">Thomas Rowntree</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutz_E/0/1/0/all/0/1\">Elijah Schutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orenstein_A/0/1/0/all/0/1\">Adrian Orenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Andy Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_T/0/1/0/all/0/1\">Tat-Jun Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1\">Ian Reid</a>",
          "description": "Future Moon bases will likely be constructed using resources mined from the\nsurface of the Moon. The difficulty of maintaining a human workforce on the\nMoon and communications lag with Earth means that mining will need to be\nconducted using collaborative robots with a high degree of autonomy. In this\npaper, we describe our solution for Phase 2 of the NASA Space Robotics\nChallenge, which provided a simulated lunar environment in which teams were\ntasked to develop software systems to achieve autonomous collaborative robots\nfor mining on the Moon. Our 3rd place and innovation award winning solution\nshows how machine learning-enabled vision could alleviate major challenges\nposed by the lunar environment towards autonomous space mining, chiefly the\nlack of satellite positioning systems, hazardous terrain, and delicate robot\ninteractions. A robust multi-robot coordinator was also developed to achieve\nlong-term operation and effective collaboration between robots.",
          "link": "http://arxiv.org/abs/2109.12109",
          "publishedOn": "2022-04-14T00:58:52.113Z",
          "wordCount": null,
          "title": "Autonomy and Perception for Space Mining. (arXiv:2109.12109v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Siviero_E/0/1/0/all/0/1\">Emilia Siviero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chautru_E/0/1/0/all/0/1\">Emilie Chautru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1\">Stephan Cl&#xe9;men&#xe7;on</a>",
          "description": "In the Big Data era, with the ubiquity of geolocation sensors in particular,\nmassive datasets exhibiting a possibly complex spatial dependence structure are\nbecoming increasingly available. In this context, the standard probabilistic\ntheory of statistical learning does not apply directly and guarantees of the\ngeneralization capacity of predictive rules learned from such data are left to\nestablish. We analyze here the simple Kriging task, the flagship problem in\nGeostatistics: the values of a square integrable random field $X=\\{X_s\\}_{s\\in\nS}$, $S\\subset \\mathbb{R}^2$, with unknown covariance structure are to be\npredicted with minimum quadratic risk, based upon observing a single\nrealization of the spatial process at a finite number of locations $s_1,\\;\n\\ldots,\\; s_n$ in $S$. Despite the connection of this minimization problem with\nkernel ridge regression, establishing the generalization capacity of empirical\nrisk minimizers is far from straightforward, due to the non i.i.d. nature of\nthe spatial data $X_{s_1},\\; \\ldots,\\; X_{s_n}$ involved. In this article,\nnonasymptotic bounds of order $O_{\\mathbb{P}}(1/n)$ are proved for the excess\nrisk of a plug-in predictive rule mimicking the true minimizer in the case of\nisotropic stationary Gaussian processes observed at locations forming a regular\ngrid. These theoretical results, as well as the role played by the technical\nconditions required to establish them, are illustrated by various numerical\nexperiments and hopefully pave the way for further developments in statistical\nlearning based on spatial data.",
          "link": "http://arxiv.org/abs/2202.07365",
          "publishedOn": "2022-04-14T00:58:52.113Z",
          "wordCount": null,
          "title": "A Statistical Learning View of Simple Kriging. (arXiv:2202.07365v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06264",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Levy_T/0/1/0/all/0/1\">Tomer Levy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Abramovich_F/0/1/0/all/0/1\">Felix Abramovich</a>",
          "description": "We consider high-dimensional multiclass classification by sparse multinomial\nlogistic regression. Unlike binary classification, in the multiclass setup one\ncan think about an entire spectrum of possible notions of sparsity associated\nwith different structural assumptions on the regression coefficients matrix. We\npropose a computationally feasible feature selection procedure based on\npenalized maximum likelihood with convex penalties capturing a specific type of\nsparsity at hand. In particular, we consider global sparsity, double row-wise\nsparsity, and low-rank sparsity, and show that with the properly chosen tuning\nparameters the derived plug-in classifiers attain the minimax generalization\nerror bounds (in terms of misclassification excess risk) within the\ncorresponding classes of multiclass sparse linear classifiers. The developed\napproach is general and can be adapted to other types of sparsity as well.",
          "link": "http://arxiv.org/abs/2204.06264",
          "publishedOn": "2022-04-14T00:58:52.112Z",
          "wordCount": null,
          "title": "Generalization Error Bounds for Multiclass Sparse Linear Classifiers. (arXiv:2204.06264v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_J/0/1/0/all/0/1\">Jaehoon Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiyagalingam_J/0/1/0/all/0/1\">Jeyan Thiyagalingam</a>",
          "description": "Noting the importance of factorizing (or disentangling) the latent space, we\npropose a novel, non-probabilistic disentangling framework for autoencoders,\nbased on the principles of symmetry transformations in group-theory. To the\nbest of our knowledge, this is the first deterministic model that is aiming to\nachieve disentanglement based on autoencoders without regularizers. The\nproposed model is compared to seven state-of-the-art generative models based on\nautoencoders and evaluated based on five supervised disentanglement metrics.\nThe experimental results show that the proposed model can have better\ndisentanglement when variances of each features are different. We believe that\nthis model leads to a new field for disentanglement learning based on\nautoencoders without regularizers.",
          "link": "http://arxiv.org/abs/2202.09926",
          "publishedOn": "2022-04-14T00:58:52.112Z",
          "wordCount": null,
          "title": "Disentangling Autoencoders (DAE). (arXiv:2202.09926v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mingshuo_N/0/1/0/all/0/1\">Nie Mingshuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dongming_C/0/1/0/all/0/1\">Chen Dongming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dongqi_W/0/1/0/all/0/1\">Wang Dongqi</a>",
          "description": "Graph mining tasks arise from many different application domains, ranging\nfrom social networks, transportation, E-commerce, etc., which have been\nreceiving great attention from the theoretical and algorithm design communities\nin recent years, and there has been some pioneering work using the hotly\nresearched reinforcement learning (RL) techniques to address graph data mining\ntasks. However, these graph mining algorithms and RL models are dispersed in\ndifferent research areas, which makes it hard to compare different algorithms\nwith each other. In this survey, we provide a comprehensive overview of RL\nmodels and graph mining and generalize these algorithms to Graph Reinforcement\nLearning (GRL) as a unified formulation. We further discuss the applications of\nGRL methods across various domains and summarize the method description,\nopen-source codes, and benchmark datasets of GRL methods. Finally, we propose\npossible important directions and challenges to be solved in the future. This\nis the latest work on a comprehensive survey of GRL literature, and this work\nprovides a global view for researchers as well as a learning resource for\nresearchers outside the domain. In addition, we create an online open-source\nfor both interested researchers who want to enter this rapidly developing\ndomain and experts who would like to compare GRL methods.",
          "link": "http://arxiv.org/abs/2204.06127",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "Reinforcement Learning on Graph: A Survey. (arXiv:2204.06127v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06322",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hard_A/0/1/0/all/0/1\">Andrew Hard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Partridge_K/0/1/0/all/0/1\">Kurt Partridge</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_N/0/1/0/all/0/1\">Neng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Augenstein_S/0/1/0/all/0/1\">Sean Augenstein</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shah_A/0/1/0/all/0/1\">Aishanee Shah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Park_H/0/1/0/all/0/1\">Hyun Jin Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Park_A/0/1/0/all/0/1\">Alex Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ng_S/0/1/0/all/0/1\">Sara Ng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nguyen_J/0/1/0/all/0/1\">Jessica Nguyen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moreno_I/0/1/0/all/0/1\">Ignacio Lopez Moreno</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mathews_R/0/1/0/all/0/1\">Rajiv Mathews</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beaufays_F/0/1/0/all/0/1\">Fran&#xe7;oise Beaufays</a>",
          "description": "We trained a keyword spotting model using federated learning on real user\ndevices and observed significant improvements when the model was deployed for\ninference on phones. To compensate for data domains that are missing from\non-device training caches, we employed joint federated-centralized training.\nAnd to learn in the absence of curated labels on-device, we formulated a\nconfidence filtering strategy based on user-feedback signals for federated\ndistillation. These techniques created models that significantly improved\nquality metrics in offline evaluations and user-experience metrics in live A/B\nexperiments.",
          "link": "http://arxiv.org/abs/2204.06322",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "Production federated keyword spotting via distillation, filtering, and joint federated-centralized training. (arXiv:2204.06322v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chun-Hung Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Di-Chun Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gau_R/0/1/0/all/0/1\">Rung-Hung Gau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lu Wei</a>",
          "description": "Federated learning (FL) is a promising distributed learning technique\nparticularly suitable for wireless learning scenarios since it can accomplish a\nlearning task without raw data transportation so as to preserve data privacy\nand lower network resource consumption. However, current works on FL over\nwireless networks do not profoundly study the fundamental performance of FL\nover wireless networks that suffers from communication outage due to channel\nimpairment and network interference. To accurately exploit the performance of\nFL over wireless networks, this paper proposes a novel intermittent FL model\nover a cellular-connected unmanned aerial vehicle (UAV) network, which\ncharacterizes communication outage from UAV (clients) to their server and data\nheterogeneity among the datasets at UAVs. We propose an analytically tractable\nframework to derive the uplink outage probability and use it to devise a\nsimulation-based approach so as to evaluate the performance of the proposed\nintermittent FL model. Our findings reveal how the intermittent FL model is\nimpacted by uplink communication outage and UAV deployment. Extensive numerical\nsimulations are provided to show the consistency between the simulated and\nanalytical performances of the proposed intermittent FL model.",
          "link": "http://arxiv.org/abs/2110.07077",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "Modeling and Analysis of Intermittent Federated Learning Over Cellular-Connected UAV Networks. (arXiv:2110.07077v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_W/0/1/0/all/0/1\">Weirui Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuexiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1\">Liuyi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>",
          "description": "The incredible development of federated learning (FL) has benefited various\ntasks in the domains of computer vision and natural language processing, and\nthe existing frameworks such as TFF and FATE has made the deployment easy in\nreal-world applications. However, federated graph learning (FGL), even though\ngraph data are prevalent, has not been well supported due to its unique\ncharacteristics and requirements. The lack of FGL-related framework increases\nthe efforts for accomplishing reproducible research and deploying in real-world\napplications. Motivated by such strong demand, in this paper, we first discuss\nthe challenges in creating an easy-to-use FGL package and accordingly present\nour implemented package FederatedScope-GNN (FS-G), which provides (1) a unified\nview for modularizing and expressing FGL algorithms; (2) comprehensive DataZoo\nand ModelZoo for out-of-the-box FGL capability; (3) an efficient model\nauto-tuning component; and (4) off-the-shelf privacy attack and defense\nabilities. We validate the effectiveness of FS-G by conducting extensive\nexperiments, which simultaneously gains many valuable insights about FGL for\nthe community. Moreover, we employ FS-G to serve the FGL application in\nreal-world E-commerce scenarios, where the attained improvements indicate great\npotential business benefits. We publicly release FS-G, as submodules of\nFederatedScope, at https://github.com/alibaba/FederatedScope to promote FGL's\nresearch and enable broad applications that would otherwise be infeasible due\nto the lack of a dedicated package.",
          "link": "http://arxiv.org/abs/2204.05562",
          "publishedOn": "2022-04-14T00:58:52.109Z",
          "wordCount": null,
          "title": "FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning. (arXiv:2204.05562v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lerma_M/0/1/0/all/0/1\">Miguel Lerma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_M/0/1/0/all/0/1\">Mirtha Lucas</a>",
          "description": "We discuss a way to find a well behaved baseline for attribution methods that\nwork by feeding a neural network with a sequence of interpolated inputs between\ntwo given inputs. Then, we test it with our novel Riemann-Stieltjes Integrated\nGradient-weighted Class Activation Mapping (RSI-Grad-CAM) attribution method.",
          "link": "http://arxiv.org/abs/2204.06120",
          "publishedOn": "2022-04-14T00:58:52.108Z",
          "wordCount": null,
          "title": "Baseline Computation for Attribution Methods Based on Interpolated Inputs. (arXiv:2204.06120v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06242",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qoku_A/0/1/0/all/0/1\">Arber Qoku</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buettner_F/0/1/0/all/0/1\">Florian Buettner</a>",
          "description": "Many real-world systems are described not only by data from a single source\nbut via multiple data views. For example, in genomic medicine, a patient can be\ndescribed by data from different molecular layers. This raises the need for\nmulti-view models that are able to disentangle variation within and across data\nviews in an interpretable manner. Latent variable models with structured\nsparsity are a commonly used tool to address this modeling task but\ninterpretability is cumbersome since it requires a direct inspection and\ninterpretation of each factor via a specialized domain expert. Here, we propose\nMuVI, a novel approach for domain-informed multi-view latent variable models,\nfacilitating the analysis of multi-view data in an inherently explainable\nmanner. We demonstrate that our model (i) is able to integrate noisy domain\nexpertise in form of feature sets, (ii) is robust to noise in the encoded\ndomain knowledge, (iii) results in identifiable factors and (iv) is able to\ninfer interpretable and biologically meaningful axes of variation in a\nreal-world multi-view dataset of cancer patients.",
          "link": "http://arxiv.org/abs/2204.06242",
          "publishedOn": "2022-04-14T00:58:52.108Z",
          "wordCount": null,
          "title": "Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity. (arXiv:2204.06242v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06150",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Horowitz_H/0/1/0/all/0/1\">Haim Horowitz</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rao_P/0/1/0/all/0/1\">Pooja Rao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Radha_S/0/1/0/all/0/1\">Santosh Kumar Radha</a>",
          "description": "Synthetic data generation has proven to be a promising solution for\naddressing data availability issues in various domains. Even more challenging\nis the generation of synthetic time series data, where one has to preserve\ntemporal dynamics, i.e., the generated time series must respect the original\nrelationships between variables across time. Recently proposed techniques such\nas generative adversarial networks (GANs) and quantum-GANs lack the ability to\nattend to the time series specific temporal correlations adequately. We propose\nusing the inherent nature of quantum computers to simulate quantum dynamics as\na technique to encode such features. We start by assuming that a given time\nseries can be generated by a quantum process, after which we proceed to learn\nthat quantum process using quantum machine learning. We then use the learned\nmodel to generate out-of-sample time series and show that it captures unique\nand complex features of the learned time series. We also study the class of\ntime series that can be modeled using this technique. Finally, we\nexperimentally demonstrate the proposed algorithm on an 11-qubit trapped-ion\nquantum machine.",
          "link": "http://arxiv.org/abs/2204.06150",
          "publishedOn": "2022-04-14T00:58:52.104Z",
          "wordCount": null,
          "title": "A quantum generative model for multi-dimensional time series using Hamiltonian learning. (arXiv:2204.06150v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.01852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kojima_H/0/1/0/all/0/1\">Hiroki Kojima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikegami_T/0/1/0/all/0/1\">Takashi Ikegami</a>",
          "description": "We present a novel artificial cognitive mapping system using generative deep\nneural networks, called variational autoencoder/generative adversarial network\n(VAE/GAN), which can map input images to latent vectors and generate temporal\nsequences internally. The results show that the distance of the predicted image\nis reflected in the distance of the corresponding latent vector after training.\nThis indicates that the latent space is self-organized to reflect the proximity\nstructure of the dataset and may provide a mechanism through which many aspects\nof cognition are spatially represented. The present study allows the network to\ninternally generate temporal sequences that are analogous to the hippocampal\nreplay/pre-play ability, where VAE produces only near-accurate replays of past\nexperiences, but by introducing GANs, the generated sequences are coupled with\ninstability and novelty.",
          "link": "http://arxiv.org/abs/2102.01852",
          "publishedOn": "2022-04-14T00:58:52.104Z",
          "wordCount": null,
          "title": "Organization of a Latent Space structure in VAE/GAN trained by navigation data. (arXiv:2102.01852v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_L/0/1/0/all/0/1\">Leonardo F. R. Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengwen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreyer_M/0/1/0/all/0/1\">Markus Dreyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Despite recent improvements in abstractive summarization, most current\napproaches generate summaries that are not factually consistent with the source\ndocument, severely restricting their trust and usage in real-world\napplications. Recent works have shown promising improvements in factuality\nerror identification using text or dependency arc entailments; however, they do\nnot consider the entire semantic graph simultaneously. To this end, we propose\nFactGraph, a method that decomposes the document and the summary into\nstructured meaning representations (MR), which are more suitable for factuality\nevaluation. MRs describe core semantic concepts and their relations,\naggregating the main content in both document and summary in a canonical form,\nand reducing data sparsity. FactGraph encodes such graphs using a graph encoder\naugmented with structure-aware adapters to capture interactions among the\nconcepts based on the graph connectivity, along with text representations using\nan adapter-based text encoder. Experiments on different benchmarks for\nevaluating factuality show that FactGraph outperforms previous approaches by up\nto 15%. Furthermore, FactGraph improves performance on identifying content\nverifiability errors and better captures subsentence-level factual\ninconsistencies.",
          "link": "http://arxiv.org/abs/2204.06508",
          "publishedOn": "2022-04-14T00:58:52.093Z",
          "wordCount": null,
          "title": "FactGraph: Evaluating Factuality in Summarization with Semantic Graph Representations. (arXiv:2204.06508v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaeri_M/0/1/0/all/0/1\">MohammadAli Shaeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afzal_A/0/1/0/all/0/1\">Arshia Afzal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoaran_M/0/1/0/all/0/1\">Mahsa Shoaran</a>",
          "description": "Neuroscience and neurotechnology are currently being revolutionized by\nartificial intelligence (AI) and machine learning. AI is widely used to study\nand interpret neural signals (analytical applications), assist people with\ndisabilities (prosthetic applications), and treat underlying neurological\nsymptoms (therapeutic applications). In this brief, we will review the emerging\nopportunities of on-chip AI for the next-generation implantable brain-machine\ninterfaces (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major\ntechnological challenges for the effectiveness of AI models will be discussed.\nFinally, we will present algorithmic and IC design solutions to enable a new\ngeneration of AI-enhanced and high-channel-count BMIs.",
          "link": "http://arxiv.org/abs/2204.02362",
          "publishedOn": "2022-04-14T00:58:52.093Z",
          "wordCount": null,
          "title": "Challenges and Opportunities of Edge AI for Next-Generation Implantable BMIs. (arXiv:2204.02362v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Munoz_Cancino_R/0/1/0/all/0/1\">Ricardo Mu&#xf1;oz-Cancino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1\">Cristi&#xe1;n Bravo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_S/0/1/0/all/0/1\">Sebasti&#xe1;n A. R&#xed;os</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grana_M/0/1/0/all/0/1\">Manuel Gra&#xf1;a</a>",
          "description": "For more than a half-century, credit risk management has used credit scoring\nmodels in each of its well-defined stages to manage credit risk. Application\nscoring is used to decide whether to grant a credit or not, while behavioral\nscoring is used mainly for portfolio management and to take preventive actions\nin case of default signals. In both cases, network data has recently been shown\nto be valuable to increase the predictive power of these models, especially\nwhen the borrower's historical data is scarce or not available. This study aims\nto understand the creditworthiness assessment performance dynamics and how it\nis influenced by the credit history, repayment behavior, and social network\nfeatures. To accomplish this, we introduced a machine learning classification\nframework to analyze 97.000 individuals and companies from the moment they\nobtained their first loan to 12 months afterward. Our novel and massive dataset\nallow us to characterize each borrower according to their credit behavior, and\nsocial and economic relationships. Our research shows that borrowers' history\nincreases performance at a decreasing rate during the first six months and then\nstabilizes. The most notable effect on perfomance of social networks features\noccurs at loan application; in personal scoring, this effect prevails a few\nmonths, while in business scoring adds value throughout the study period. These\nfindings are of great value to improve credit risk management and optimize the\nuse of traditional information and alternative data sources.",
          "link": "http://arxiv.org/abs/2204.06122",
          "publishedOn": "2022-04-14T00:58:52.092Z",
          "wordCount": null,
          "title": "On the dynamics of credit history and social interaction features, and their impact on creditworthiness assessment performance. (arXiv:2204.06122v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravenscroft_W/0/1/0/all/0/1\">William Ravenscroft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goetze_S/0/1/0/all/0/1\">Stefan Goetze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>",
          "description": "Speech dereverberation is often an important requirement in robust speech\nprocessing tasks. Supervised deep learning (DL) models give state-of-the-art\nperformance for single-channel speech dereverberation. Temporal convolutional\nnetworks (TCNs) are commonly used for sequence modelling in speech enhancement\ntasks. A feature of TCNs is that they have a receptive field (RF) dependant on\nthe specific model configuration which determines the number of input frames\nthat can be observed to produce an individual output frame. It has been shown\nthat TCNs are capable of performing dereverberation of simulated speech data,\nhowever a thorough analysis, especially with focus on the RF is yet lacking in\nthe literature. This paper analyses dereverberation performance depending on\nthe model size and the RF of TCNs. Experiments using the WHAMR corpus which is\nextended to include room impulse responses (RIRs) with larger T60 values\ndemonstrate that a larger RF can have significant improvement in performance\nwhen training smaller TCN models. It is also demonstrated that TCNs benefit\nfrom a wider RF when dereverberating RIRs with larger RT60 values.",
          "link": "http://arxiv.org/abs/2204.06439",
          "publishedOn": "2022-04-14T00:58:52.092Z",
          "wordCount": null,
          "title": "Receptive Field Analysis of Temporal Convolutional Networks for Monaural Speech Dereverberation. (arXiv:2204.06439v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.07084",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Osa_T/0/1/0/all/0/1\">Takayuki Osa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tangkaratt_V/0/1/0/all/0/1\">Voot Tangkaratt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Reinforcement learning algorithms are typically limited to learning a single\nsolution for a specified task, even though diverse solutions often exist.\nRecent studies showed that learning a set of diverse solutions is beneficial\nbecause diversity enables robust few-shot adaptation. Although existing methods\nlearn diverse solutions by using the mutual information as unsupervised\nrewards, such an approach often suffers from the bias of the gradient estimator\ninduced by value function approximation. In this study, we propose a novel\nmethod that can learn diverse solutions without suffering the bias problem. In\nour method, a policy conditioned on a continuous or discrete latent variable is\ntrained by directly maximizing the variational lower bound of the mutual\ninformation, instead of using the mutual information as unsupervised rewards as\nin previous studies. Through extensive experiments on robot locomotion tasks,\nwe demonstrate that the proposed method successfully learns an infinite set of\ndiverse solutions by learning continuous latent variables, which is more\nchallenging than learning a finite number of solutions. Subsequently, we show\nthat our method enables more effective few-shot adaptation compared with\nexisting methods.",
          "link": "http://arxiv.org/abs/2103.07084",
          "publishedOn": "2022-04-14T00:58:52.091Z",
          "wordCount": null,
          "title": "Discovering Diverse Solutions in Deep Reinforcement Learning by Maximizing State-Action-Based Mutual Information. (arXiv:2103.07084v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Occhipinti_A/0/1/0/all/0/1\">Annalisa Occhipinti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_L/0/1/0/all/0/1\">Louis Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angione_C/0/1/0/all/0/1\">Claudio Angione</a>",
          "description": "Text-based communication is highly favoured as a communication method,\nespecially in business environments. As a result, it is often abused by sending\nmalicious messages, e.g., spam emails, to deceive users into relaying personal\ninformation, including online accounts credentials or banking details. For this\nreason, many machine learning methods for text classification have been\nproposed and incorporated into the services of most email providers. However,\noptimising text classification algorithms and finding the right tradeoff on\ntheir aggressiveness is still a major research problem.\n\nWe present an updated survey of 12 machine learning text classifiers applied\nto a public spam corpus. A new pipeline is proposed to optimise hyperparameter\nselection and improve the models' performance by applying specific methods\n(based on natural language processing) in the preprocessing stage.\n\nOur study aims to provide a new methodology to investigate and optimise the\neffect of different feature sizes and hyperparameters in machine learning\nclassifiers that are widely used in text classification problems. The\nclassifiers are tested and evaluated on different metrics including F-score\n(accuracy), precision, recall, and run time. By analysing all these aspects, we\nshow how the proposed pipeline can be used to achieve a good accuracy towards\nspam filtering on the Enron dataset, a widely used public email corpus.\nStatistical tests and explainability techniques are applied to provide a robust\nanalysis of the proposed pipeline and interpret the classification outcomes of\nthe 12 machine learning models, also identifying words that drive the\nclassification results. Our analysis shows that it is possible to identify an\neffective machine learning model to classify the Enron dataset with an F-score\nof 94%.",
          "link": "http://arxiv.org/abs/2204.06518",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "A pipeline and comparative study of 12 machine learning models for text classification. (arXiv:2204.06518v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.10102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Renjue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pengfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Cheng-Chao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Youcheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Bai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>",
          "description": "To analyse local robustness properties of deep neural networks (DNNs), we\npresent a practical framework from a model learning perspective. Based on\nblack-box model learning with scenario optimisation, we abstract the local\nbehaviour of a DNN via an affine model with the probably approximately correct\n(PAC) guarantee. From the learned model, we can infer the corresponding\nPAC-model robustness property. The innovation of our work is the integration of\nmodel learning into PAC robustness analysis: that is, we construct a PAC\nguarantee on the model level instead of sample distribution, which induces a\nmore faithful and accurate robustness evaluation. This is in contrast to\nexisting statistical methods without model learning. We implement our method in\na prototypical tool named DeepPAC. As a black-box method, DeepPAC is scalable\nand efficient, especially when DNNs have complex structures or high-dimensional\ninputs. We extensively evaluate DeepPAC, with 4 baselines (using formal\nverification, statistical methods, testing and adversarial attack) and 20 DNN\nmodels across 3 datasets, including MNIST, CIFAR-10, and ImageNet. It is shown\nthat DeepPAC outperforms the state-of-the-art statistical method PROVERO, and\nit achieves more practical robustness analysis than the formal verification\ntool ERAN. Also, its results are consistent with existing DNN testing work like\nDeepGini.",
          "link": "http://arxiv.org/abs/2101.10102",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning. (arXiv:2101.10102v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.05955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vicente_Sola_A/0/1/0/all/0/1\">Alex Vicente-Sola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manna_D/0/1/0/all/0/1\">Davide L. Manna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirkland_P/0/1/0/all/0/1\">Paul Kirkland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caterina_G/0/1/0/all/0/1\">Gaetano Di Caterina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bihl_T/0/1/0/all/0/1\">Trevor Bihl</a>",
          "description": "Spiking neural networks (SNNs) have become an interesting alternative to\nconventional artificial neural networks (ANN) thanks to their temporal\nprocessing capabilities and energy efficient implementations in neuromorphic\nhardware. However the challenges involved in training SNNs have limited their\nperformance in terms of accuracy and thus their applications. Improving\nlearning algorithms and neural architectures for a more accurate feature\nextraction is therefore one of the current priorities in SNN research. In this\npaper we present a study on the key components of modern spiking architectures.\nWe empirically compare different techniques in image classification datasets\ntaken from the best performing networks. We design a spiking version of the\nsuccessful residual network architecture and provide an in-depth study on the\npossible implementations of spiking residual connections. Our results provide a\nstate of the art guide to SNN design, which allows to make informed choices\nwhen trying to build the optimal visual feature extractor. Finally, our network\noutperforms previous SNN architectures in CIFAR-10 (94.14%) and CIFAR-100\n(74.65%) datasets and matches the state of the art in DVS-CIFAR10 (72.98%),\nwith less parameters than the previous state of the art and without the need\nfor ANN-SNN conversion. Code available at\nhttps://github.com/VicenteAlex/Spiking_ResNet",
          "link": "http://arxiv.org/abs/2111.05955",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "Keys to Accurate Feature Extraction Using Residual Spiking Neural Networks. (arXiv:2111.05955v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_W/0/1/0/all/0/1\">Wai Weng Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Layeghy_S/0/1/0/all/0/1\">Siamak Layeghy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portmann_M/0/1/0/all/0/1\">Marius Portmann</a>",
          "description": "Criminals have become increasingly experienced in using cryptocurrencies,\nsuch as Bitcoin, for money laundering. The use of cryptocurrencies can hide\ncriminal identities and transfer hundreds of millions of dollars of dirty funds\nthrough their criminal digital wallets. However, this is considered a paradox\nbecause cryptocurrencies are gold mines for open-source intelligence, allowing\nlaw enforcement agencies to have more power in conducting forensic analyses.\nThis paper proposed Inspection-L, a graph neural network (GNN) framework based\non self-supervised Deep Graph Infomax (DGI), with supervised learning\nalgorithms, namely Random Forest (RF) to detect illicit transactions for AML.\nTo the best of our knowledge, our proposal is the first of applying\nself-supervised GNNs to the problem of AML in Bitcoin. The proposed method has\nbeen evaluated on the Elliptic dataset and shows that our approach outperforms\nthe baseline in terms of key classification metrics, which demonstrates the\npotential of self-supervised GNN in cryptocurrency illicit transaction\ndetection.",
          "link": "http://arxiv.org/abs/2203.10465",
          "publishedOn": "2022-04-14T00:58:52.090Z",
          "wordCount": null,
          "title": "Inspection-L: A Self-Supervised GNN-Based Money Laundering Detection System for Bitcoin. (arXiv:2203.10465v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06348",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Poelking_C/0/1/0/all/0/1\">Carl Poelking</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chessari_G/0/1/0/all/0/1\">Gianni Chessari</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Murray_C/0/1/0/all/0/1\">Christopher W. Murray</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hall_R/0/1/0/all/0/1\">Richard J. Hall</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Colwell_L/0/1/0/all/0/1\">Lucy Colwell</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Verdonk_M/0/1/0/all/0/1\">Marcel Verdonk</a>",
          "description": "Machine learning (ML) is widely used in drug discovery to train models that\npredict protein-ligand binding. These models are of great value to medicinal\nchemists, in particular if they provide case-specific insight into the physical\ninteractions that drive the binding process. In this study we derive ML models\nfrom over 50 fragment-screening campaigns to introduce two important elements\nthat we believe are absent in most -- if not all -- ML studies of this type\nreported to date: First, alongside the observed hits we use to train our\nmodels, we incorporate true misses and show that these experimentally validated\nnegative data are of significant importance to the quality of the derived\nmodels. Second, we provide a physically interpretable and verifiable\nrepresentation of what the ML model considers important for successful binding.\nThis representation is derived from a straightforward attribution procedure\nthat explains the prediction in terms of the (inter-)action of chemical\nenvironments. Critically, we validate the attribution outcome on a large scale\nagainst prior annotations made independently by expert molecular modellers. We\nfind good agreement between the key molecular substructures proposed by the ML\nmodel and those assigned manually, even when the model's performance in\ndiscriminating hits from misses is far from perfect. By projecting the\nattribution onto predefined interaction prototypes (pharmacophores), we show\nthat ML allows us to formulate simple rules for what drives fragment binding\nagainst a target automatically from screening data.",
          "link": "http://arxiv.org/abs/2204.06348",
          "publishedOn": "2022-04-14T00:58:52.089Z",
          "wordCount": null,
          "title": "Meaningful machine learning models and machine-learned pharmacophores from fragment screening campaigns. (arXiv:2204.06348v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06375",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blanke_M/0/1/0/all/0/1\">Matthieu Blanke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lelarge_M/0/1/0/all/0/1\">Marc Lelarge</a>",
          "description": "This work addresses the problem of exploration in an unknown environment. For\nlinear dynamical systems, we use an experimental design framework and introduce\nan online greedy policy where the control maximizes the information of the next\nstep. In a setting with a limited number of experimental trials, our algorithm\nhas low complexity and shows experimentally competitive performances compared\nto more elaborate gradient-based methods.",
          "link": "http://arxiv.org/abs/2204.06375",
          "publishedOn": "2022-04-14T00:58:52.089Z",
          "wordCount": null,
          "title": "Online greedy identification of linear dynamical systems. (arXiv:2204.06375v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goktas_D/0/1/0/all/0/1\">Denizalp Goktas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenwald_A/0/1/0/all/0/1\">Amy Greenwald</a>",
          "description": "Min-max optimization problems (i.e., min-max games) have been attracting a\ngreat deal of attention because of their applicability to a wide range of\nmachine learning problems. Although significant progress has been made\nrecently, the literature to date has focused on games with independent strategy\nsets; little is known about solving games with dependent strategy sets, which\ncan be characterized as min-max Stackelberg games. We introduce two first-order\nmethods that solve a large class of convex-concave min-max Stackelberg games,\nand show that our methods converge in polynomial time. Min-max Stackelberg\ngames were first studied by Wald, under the posthumous name of Wald's maximin\nmodel, a variant of which is the main paradigm used in robust optimization,\nwhich means that our methods can likewise solve many convex robust optimization\nproblems. We observe that the computation of competitive equilibria in Fisher\nmarkets also comprises a min-max Stackelberg game. Further, we demonstrate the\nefficacy and efficiency of our algorithms in practice by computing competitive\nequilibria in Fisher markets with varying utility structures. Our experiments\nsuggest potential ways to extend our theoretical results, by demonstrating how\ndifferent smoothness properties can affect the convergence rate of our\nalgorithms.",
          "link": "http://arxiv.org/abs/2110.05192",
          "publishedOn": "2022-04-14T00:58:52.089Z",
          "wordCount": null,
          "title": "Convex-Concave Min-Max Stackelberg Games. (arXiv:2110.05192v4 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Imbiriba_T/0/1/0/all/0/1\">Tales Imbiriba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demirkaya_A/0/1/0/all/0/1\">Ahmet Demirkaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunik_J/0/1/0/all/0/1\">Jind&#x159;ich Dun&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Straka_O/0/1/0/all/0/1\">Ond&#x159;ej Straka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogmus_D/0/1/0/all/0/1\">Deniz Erdo&#x11f;mu&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Closas_P/0/1/0/all/0/1\">Pau Closas</a>",
          "description": "In this paper we present a hybrid neural network augmented physics-based\nmodeling (APBM) framework for Bayesian nonlinear latent space estimation. The\nproposed APBM strategy allows for model adaptation when new operation\nconditions come into play or the physics-based model is insufficient (or\nincomplete) to properly describe the latent phenomenon. One advantage of the\nAPBMs and our estimation procedure is the capability of maintaining the\nphysical interpretability of estimated states. Furthermore, we propose a\nconstraint filtering approach to control the neural network contributions to\nthe overall model. We also exploit assumed density filtering techniques and\ncubature integration rules to present a flexible estimation strategy that can\neasily deal with nonlinear models and high-dimensional latent spaces. Finally,\nwe demonstrate the efficacy of our methodology by leveraging a target tracking\nscenario with nonlinear and incomplete measurement and acceleration models,\nrespectively.",
          "link": "http://arxiv.org/abs/2204.06471",
          "publishedOn": "2022-04-14T00:58:52.041Z",
          "wordCount": null,
          "title": "Hybrid Neural Network Augmented Physics-based Models for Nonlinear Filtering. (arXiv:2204.06471v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ant&#xf4;nio H. Ribeiro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>",
          "description": "As machine learning models start to be used in critical applications, their\nvulnerabilities and brittleness become a pressing concern. Adversarial attacks\nare a popular framework for studying these vulnerabilities. In this work, we\nstudy the error of linear regression in the face of adversarial attacks. We\nprovide bounds of the error in terms of the traditional risk and the parameter\nnorm and show how these bounds can be leveraged and make it possible to use\nanalysis from non-adversarial setups to study the adversarial risk. The\nusefulness of these results is illustrated by shedding light on whether or not\noverparameterized linear models can be adversarially robust. We show that\nadding features to linear models might be either a source of additional\nrobustness or brittleness. We show that these differences appear due to scaling\nand how the $\\ell_1$ and $\\ell_2$ norms of random projections concentrate. We\nalso show how the reformulation we propose allows for solving adversarial\ntraining as a convex optimization problem. This is then used as a tool to study\nhow adversarial training and other regularization methods might affect the\nrobustness of the estimated models.",
          "link": "http://arxiv.org/abs/2204.06274",
          "publishedOn": "2022-04-14T00:58:52.039Z",
          "wordCount": null,
          "title": "Overparameterized Linear Regression under Adversarial Attacks. (arXiv:2204.06274v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lecerf_U/0/1/0/all/0/1\">Ugo Lecerf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yemdji_Tchassi_C/0/1/0/all/0/1\">Christelle Yemdji-Tchassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michiardi_P/0/1/0/all/0/1\">Pietro Michiardi</a>",
          "description": "When learning to act in a stochastic, partially observable environment, an\nintelligent agent should be prepared to anticipate a change in its belief of\nthe environment state, and be capable of adapting its actions on-the-fly to\nchanging conditions. As humans, we are able to form contingency plans when\nlearning a task with the explicit aim of being able to correct errors in the\ninitial control, and hence prove useful if ever there is a sudden change in our\nperception of the environment which requires immediate corrective action. This\nis especially the case for autonomous vehicles (AVs) navigating real-world\nsituations where safety is paramount, and a strong ability to react to a\nchanging belief about the environment is truly needed.\n\nIn this paper we explore an end-to-end approach, from training to execution,\nfor learning robust contingency plans and combining them with a hierarchical\nplanner to obtain a robust agent policy in an autonomous navigation task where\nother vehicles' behaviours are unknown, and the agent's belief about these\nbehaviours is subject to sudden, last-second change. We show that our approach\nresults in robust, safe behaviour in a partially observable, stochastic\nenvironment, generalizing well over environment dynamics not seen during\ntraining.",
          "link": "http://arxiv.org/abs/2204.06509",
          "publishedOn": "2022-04-14T00:58:52.037Z",
          "wordCount": null,
          "title": "Safer Autonomous Driving in a Stochastic, Partially-Observable Environment by Hierarchical Contingency Planning. (arXiv:2204.06509v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06064",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dreifuerst_R/0/1/0/all/0/1\">Ryan M. Dreifuerst</a>, <a href=\"http://arxiv.org/find/eess/1/au:+jr%2E_R/0/1/0/all/0/1\">Robert W. Heath jr.</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yazdan_A/0/1/0/all/0/1\">Ali Yazdan</a>",
          "description": "Beam codebooks are a new feature of massive multiple-input multiple-output\n(M-MIMO) in 5G new radio (NR). Codebooks comprised of beamforming vectors are\nused to transmit reference signals and obtain limited channel state information\n(CSI) from receivers via the codeword index. This enables large arrays that\ncannot otherwise obtain sufficient CSI. The performance, however, is limited by\nthe codebook design. In this paper, we show that machine learning can be used\nto train site-specific codebooks for initial access. We design a neural network\nbased on an autoencoder architecture that uses a beamspace observation in\ncombination with RF environment characteristics to improve the synchronization\nsignal (SS) burst codebook. We test our algorithm using a flexible dataset of\nchannels generated from QuaDRiGa. The results show that our model outperforms\nthe industry standard (DFT beams) and approaches the optimal performance\n(perfect CSI and singular value decomposition (SVD)-based beamforming), using\nonly a few bits of feedback.",
          "link": "http://arxiv.org/abs/2204.06064",
          "publishedOn": "2022-04-14T00:58:52.035Z",
          "wordCount": null,
          "title": "Massive MIMO Beam Management in Sub-6 GHz 5G NR. (arXiv:2204.06064v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dandi_Y/0/1/0/all/0/1\">Yatin Dandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koloskova_A/0/1/0/all/0/1\">Anastasia Koloskova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U. Stich</a>",
          "description": "Decentralized learning provides an effective framework to train machine\nlearning models with data distributed over arbitrary communication graphs.\nHowever, most existing approaches toward decentralized learning disregard the\ninteraction between data heterogeneity and graph topology. In this paper, we\ncharacterize the dependence of convergence on the relationship between the\nmixing weights of the graph and the data heterogeneity across nodes. We propose\na metric that quantifies the ability of a graph to mix the current gradients.\nWe further prove that the metric controls the convergence rate, particularly in\nsettings where the heterogeneity across nodes dominates the stochasticity\nbetween updates for a given node. Motivated by our analysis, we propose an\napproach that periodically and efficiently optimizes the metric using standard\nconvex constrained optimization and sketching techniques. Through comprehensive\nexperiments on standard computer vision and NLP benchmarks, we show that our\napproach leads to improvement in test performance for a wide range of tasks.",
          "link": "http://arxiv.org/abs/2204.06477",
          "publishedOn": "2022-04-14T00:58:52.035Z",
          "wordCount": null,
          "title": "Data-heterogeneity-aware Mixing for Decentralized Learning. (arXiv:2204.06477v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neumayer_S/0/1/0/all/0/1\">Sebastian Neumayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goujon_A/0/1/0/all/0/1\">Alexis Goujon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohra_P/0/1/0/all/0/1\">Pakshal Bohra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unser_M/0/1/0/all/0/1\">Michael Unser</a>",
          "description": "Lipschitz-constrained neural networks have many applications in machine\nlearning. Since designing and training expressive Lipschitz-constrained\nnetworks is very challenging, there is a need for improved methods and a better\ntheoretical understanding. Unfortunately, it turns out that ReLU networks have\nprovable disadvantages in this setting. Hence, we propose to use learnable\nspline activation functions with at least 3 linear regions instead. We prove\nthat this choice is optimal among all component-wise $1$-Lipschitz activation\nfunctions in the sense that no other weight constrained architecture can\napproximate a larger class of functions. Additionally, this choice is at least\nas expressive as the recently introduced non component-wise Groupsort\nactivation function for spectral-norm-constrained weights. Previously published\nnumerical results support our theoretical findings.",
          "link": "http://arxiv.org/abs/2204.06233",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "Approximation of Lipschitz Functions using Deep Spline Neural Networks. (arXiv:2204.06233v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yiyou Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yifei Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaojin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixuan Li</a>",
          "description": "Out-of-distribution (OOD) detection is a critical task for deploying machine\nlearning models in the open world. Distance-based methods have demonstrated\npromise, where testing samples are detected as OOD if they are relatively far\naway from in-distribution (ID) data. However, prior methods impose a strong\ndistributional assumption of the underlying feature space, which may not always\nhold. In this paper, we explore the efficacy of non-parametric nearest-neighbor\ndistance for OOD detection, which has been largely overlooked in the\nliterature. Unlike prior works, our method does not impose any distributional\nassumption, hence providing stronger flexibility and generality. We demonstrate\nthe effectiveness of nearest-neighbor-based OOD detection on several benchmarks\nand establish superior performance. Under the same model trained on\nImageNet-1k, our method substantially reduces the false positive rate\n(FPR@TPR95) by 24.77% compared to a strong baseline SSD+, which uses a\nparametric approach Mahalanobis distance in detection.",
          "link": "http://arxiv.org/abs/2204.06507",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "Out-of-distribution Detection with Deep Nearest Neighbors. (arXiv:2204.06507v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannan_H/0/1/0/all/0/1\">Harish Kannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1\">Alexander Cloninger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1\">Rayan Saab</a>",
          "description": "We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.",
          "link": "http://arxiv.org/abs/2106.02614",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for Random Fourier Features. (arXiv:2106.02614v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuli_S/0/1/0/all/0/1\">Shreshth Tuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casale_G/0/1/0/all/0/1\">Giuliano Casale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jennings_N/0/1/0/all/0/1\">Nicholas R. Jennings</a>",
          "description": "Efficient anomaly detection and diagnosis in multivariate time-series data is\nof great importance for modern industrial applications. However, building a\nsystem that is able to quickly and accurately pinpoint anomalous observations\nis a challenging problem. This is due to the lack of anomaly labels, high data\nvolatility and the demands of ultra-low inference times in modern applications.\nDespite the recent developments of deep learning approaches for anomaly\ndetection, only a few of them can address all of these challenges. In this\npaper, we propose TranAD, a deep transformer network based anomaly detection\nand diagnosis model which uses attention-based sequence encoders to swiftly\nperform inference with the knowledge of the broader temporal trends in the\ndata. TranAD uses focus score-based self-conditioning to enable robust\nmulti-modal feature extraction and adversarial training to gain stability.\nAdditionally, model-agnostic meta learning (MAML) allows us to train the model\nusing limited data. Extensive empirical studies on six publicly available\ndatasets demonstrate that TranAD can outperform state-of-the-art baseline\nmethods in detection and diagnosis performance with data and time-efficient\ntraining. Specifically, TranAD increases F1 scores by up to 17%, reducing\ntraining times by up to 99% compared to the baselines.",
          "link": "http://arxiv.org/abs/2201.07284",
          "publishedOn": "2022-04-14T00:58:52.034Z",
          "wordCount": null,
          "title": "TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data. (arXiv:2201.07284v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.04301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhewei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenwen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Linyue Zhou</a>",
          "description": "Intrusion detection has been a key topic in the field of cyber security, and\nthe common network threats nowadays have the characteristics of varieties and\nvariation. Considering the serious imbalance of intrusion detection datasets\nwill result in low classification performance on attack behaviors of small\nsample size and difficulty to detect network attacks accurately and\nefficiently, using Adaptive Synthetic Sampling (ADASYN) method to balance\ndatasets was proposed in this paper. In addition, Random Forest algorithm was\nused to train intrusion detection classifiers. Through the comparative\nexperiment of Intrusion detection on CICIDS 2017 dataset, it is found that\nADASYN with Random Forest performs better. Based on the experimental results,\nthe improvement of precision, recall, F1 scores and AUC values after ADASYN is\nthen analyzed. Experiments show that the proposed method can be applied to\nintrusion detection with large data, and can effectively improve the\nclassification accuracy of network attack behaviors. Compared with traditional\nmachine learning models, it has better performance, generalization ability and\nrobustness.",
          "link": "http://arxiv.org/abs/2105.04301",
          "publishedOn": "2022-04-14T00:58:52.033Z",
          "wordCount": null,
          "title": "ADASYN-Random Forest Based Intrusion Detection Model. (arXiv:2105.04301v5 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.06054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingfei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1\">Sam Devlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "Sample efficiency is crucial for imitation learning methods to be applicable\nin real-world applications. Many studies improve sample efficiency by extending\nadversarial imitation to be off-policy regardless of the fact that these\noff-policy extensions could either change the original objective or involve\ncomplicated optimization. We revisit the foundation of adversarial imitation\nand propose an off-policy sample efficient approach that requires no\nadversarial training or min-max optimization. Our formulation capitalizes on\ntwo key insights: (1) the similarity between the Bellman equation and the\nstationary state-action distribution equation allows us to derive a novel\ntemporal difference (TD) learning approach; and (2) the use of a deterministic\npolicy simplifies the TD learning. Combined, these insights yield a practical\nalgorithm, Deterministic and Discriminative Imitation (D2-Imitation), which\noperates by first partitioning samples into two replay buffers and then\nlearning a deterministic policy via off-policy reinforcement learning. Our\nempirical results show that D2-Imitation is effective in achieving good sample\nefficiency, outperforming several off-policy extension approaches of\nadversarial imitation on many control tasks.",
          "link": "http://arxiv.org/abs/2112.06054",
          "publishedOn": "2022-04-14T00:58:52.033Z",
          "wordCount": null,
          "title": "Deterministic and Discriminative Imitation (D2-Imitation): Revisiting Adversarial Imitation for Sample Efficiency. (arXiv:2112.06054v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Visani_G/0/1/0/all/0/1\">Giorgio Visani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graffi_G/0/1/0/all/0/1\">Giacomo Graffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfero_M/0/1/0/all/0/1\">Mattia Alfero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagli_E/0/1/0/all/0/1\">Enrico Bagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capuzzo_D/0/1/0/all/0/1\">Davide Capuzzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chesani_F/0/1/0/all/0/1\">Federico Chesani</a>",
          "description": "The switch from a Model-Centric to a Data-Centric mindset is putting emphasis\non data and its quality rather than algorithms, bringing forward new\nchallenges. In particular, the sensitive nature of the information in highly\nregulated scenarios needs to be accounted for. Specific approaches to address\nthe privacy issue have been developed, as Privacy Enhancing Technologies.\nHowever, they frequently cause loss of information, putting forward a crucial\ntrade-off among data quality and privacy. A clever way to bypass such a\nconundrum relies on Synthetic Data: data obtained from a generative process,\nlearning the real data properties. Both Academia and Industry realized the\nimportance of evaluating synthetic data quality: without all-round reliable\nmetrics, the innovative data generation task has no proper objective function\nto maximize. Despite that, the topic remains under-explored. For this reason,\nwe systematically catalog the important traits of synthetic data quality and\nprivacy, and devise a specific methodology to test them. The result is DAISYnt\n(aDoption of Artificial Intelligence SYnthesis): a comprehensive suite of\nadvanced tests, which sets a de facto standard for synthetic data evaluation.\nAs a practical use-case, a variety of generative algorithms have been trained\non real-world Credit Bureau Data. The best model has been assessed, using\nDAISYnt on the different synthetic replicas. Further potential uses, among\nothers, entail auditing and fine-tuning of generative models or ensuring high\nquality of a given synthetic dataset. From a prescriptive viewpoint,\neventually, DAISYnt may pave the way to synthetic data adoption in highly\nregulated domains, ranging from Finance to Healthcare, through Insurance and\nEducation.",
          "link": "http://arxiv.org/abs/2204.06297",
          "publishedOn": "2022-04-14T00:58:52.029Z",
          "wordCount": null,
          "title": "Enabling Synthetic Data adoption in regulated domains. (arXiv:2204.06297v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_H/0/1/0/all/0/1\">Haoyu Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1\">Nianzu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_D/0/1/0/all/0/1\">Daiyue Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jianping Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>",
          "description": "User interests are usually dynamic in the real world, which poses both\ntheoretical and practical challenges for learning accurate preferences from\nrich behavior data. Among existing user behavior modeling solutions, attention\nnetworks are widely adopted for its effectiveness and relative simplicity.\nDespite being extensively studied, existing attentions still suffer from two\nlimitations: i) conventional attentions mainly take into account the spatial\ncorrelation between user behaviors, regardless the distance between those\nbehaviors in the continuous time space; and ii) these attentions mostly provide\na dense and undistinguished distribution over all past behaviors then\nattentively encode them into the output latent representations. This is however\nnot suitable in practical scenarios where a user's future actions are relevant\nto a small subset of her/his historical behaviors. In this paper, we propose a\nnovel attention network, named self-modulating attention, that models the\ncomplex and non-linearly evolving dynamic user preferences. We empirically\ndemonstrate the effectiveness of our method on top-N sequential recommendation\ntasks, and the results on three large-scale real-world datasets show that our\nmodel can achieve state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2204.06517",
          "publishedOn": "2022-04-14T00:58:52.023Z",
          "wordCount": null,
          "title": "Learning Self-Modulating Attention in Continuous Time Space with Applications to Sequential Recommendation. (arXiv:2204.06517v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunha_B/0/1/0/all/0/1\">Barbara Cunha</a> (LTDS), <a href=\"http://arxiv.org/find/cs/1/au:+Droz_C/0/1/0/all/0/1\">Christophe Droz</a> (I4S), <a href=\"http://arxiv.org/find/cs/1/au:+Zine_A/0/1/0/all/0/1\">Abdelmalek Zine</a> (ICJ), <a href=\"http://arxiv.org/find/cs/1/au:+Foulard_S/0/1/0/all/0/1\">St&#xe9;phane Foulard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichchou_M/0/1/0/all/0/1\">Mohamed Ichchou</a> (LTDS)",
          "description": "The use of Machine Learning (ML) has rapidly spread across several fields,\nhaving encountered many applications in Structural Dynamics and Vibroacoustic\n(SD\\&V). The increasing capabilities of ML to unveil insights from data, driven\nby unprecedented data availability, algorithms advances and computational\npower, enhance decision making, uncertainty handling, patterns recognition and\nreal-time assessments. Three main applications in SD\\&V have taken advantage of\nthese benefits. In Structural Health Monitoring, ML detection and prognosis\nlead to safe operation and optimized maintenance schedules. System\nidentification and control design are leveraged by ML techniques in Active\nNoise Control and Active Vibration Control. Finally, the so-called ML-based\nsurrogate models provide fast alternatives to costly simulations, enabling\nrobust and optimized product design. Despite the many works in the area, they\nhave not been reviewed and analyzed. Therefore, to keep track and understand\nthis ongoing integration of fields, this paper presents a survey of ML\napplications in SD\\&V analyses, shedding light on the current state of\nimplementation and emerging opportunities. The main methodologies, advantages,\nlimitations, and recommendations based on scientific knowledge were identified\nfor each of the three applications. Moreover, the paper considers the role of\nDigital Twins and Physics Guided ML to overcome current challenges and power\nfuture research progress. As a result, the survey provides a broad overview of\nthe present landscape of ML applied in SD\\&V and guides the reader to an\nadvanced understanding of progress and prospects in the field.",
          "link": "http://arxiv.org/abs/2204.06362",
          "publishedOn": "2022-04-14T00:58:52.021Z",
          "wordCount": null,
          "title": "A Review of Machine Learning Methods Applied to Structural Dynamics and Vibroacoustic. (arXiv:2204.06362v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06062",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Grigsby_J/0/1/0/all/0/1\">J. Elisenda Grigsby</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lindsey_K/0/1/0/all/0/1\">Kathryn Lindsey</a>, <a href=\"http://arxiv.org/find/math/1/au:+Masden_M/0/1/0/all/0/1\">Marissa Masden</a>",
          "description": "We apply a generalized piecewise-linear (PL) version of Morse theory due to\nGrunert-Kuhnel-Rote to define and study new local and global notions of\ntopological complexity for fully-connected feedforward ReLU neural network\nfunctions, F: R^n -> R. Along the way, we show how to construct, for each such\nF, a canonical polytopal complex K(F) and a deformation retract of the domain\nonto K(F), yielding a convenient compact model for performing calculations. We\nalso give a combinatorial description of local complexity for depth 2 networks,\nand a construction showing that local complexity can be arbitrarily high.",
          "link": "http://arxiv.org/abs/2204.06062",
          "publishedOn": "2022-04-14T00:58:52.020Z",
          "wordCount": null,
          "title": "Local and global topological complexity measures OF ReLU neural network functions. (arXiv:2204.06062v1 [math.AT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tailor_S/0/1/0/all/0/1\">Shyam A. Tailor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opolka_F/0/1/0/all/0/1\">Felix L. Opolka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>",
          "description": "Common wisdom in the graph neural network (GNN) community dictates that\nanisotropic models -- in which messages sent between nodes are a function of\nboth the source and target node -- are required to achieve state-of-the-art\nperformance. Benchmarks to date have demonstrated that these models perform\nbetter than comparable isotropic models -- where messages are a function of the\nsource node only. In this work we provide empirical evidence challenging this\nnarrative: we propose an isotropic GNN, which we call Efficient Graph\nConvolution (EGC), that consistently outperforms comparable anisotropic models,\nincluding the popular GAT or PNA architectures by using spatially-varying\nadaptive filters. In addition to raising important questions for the GNN\ncommunity, our work has significant real-world implications for efficiency. EGC\nachieves higher model accuracy, with lower memory consumption and latency,\nalong with characteristics suited to accelerator implementation, while being a\ndrop-in replacement for existing architectures. As an isotropic model, it\nrequires memory proportional to the number of vertices in the graph\n($\\mathcal{O}(V)$); in contrast, anisotropic models require memory proportional\nto the number of edges ($\\mathcal{O}(E)$). We demonstrate that EGC outperforms\nexisting approaches across 6 large and diverse benchmark datasets, and conclude\nby discussing questions that our work raise for the community going forward.\nCode and pretrained models for our experiments are provided at\nhttps://github.com/shyam196/egc.",
          "link": "http://arxiv.org/abs/2104.01481",
          "publishedOn": "2022-04-14T00:58:51.988Z",
          "wordCount": null,
          "title": "Do We Need Anisotropic Graph Neural Networks?. (arXiv:2104.01481v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aminpour_M/0/1/0/all/0/1\">Mohammad Aminpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaie_R/0/1/0/all/0/1\">Reza Alaie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kardani_N/0/1/0/all/0/1\">Navid Kardani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moridpour_S/0/1/0/all/0/1\">Sara Moridpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazem_M/0/1/0/all/0/1\">Majidreza Nazem</a>",
          "description": "Random field Monte Carlo (MC) reliability analysis is a robust stochastic\nmethod to determine the probability of failure. This method, however, requires\na large number of numerical simulations demanding high computational costs.\nThis paper explores the efficiency of different machine learning (ML)\nalgorithms used as surrogate models trained on a limited number of random field\nslope stability simulations in predicting the results of large datasets. The MC\ndata in this paper require only the examination of failure or non-failure,\ncircumventing the time-consuming calculation of factors of safety. An extensive\ndataset is generated, consisting of 120,000 finite difference MC slope\nstability simulations incorporating different levels of soil heterogeneity and\nanisotropy. The Bagging Ensemble, Random Forest and Support Vector classifiers\nare found to be the superior models for this problem amongst 9 different models\nand ensemble classifiers. Trained only on 0.47% of data (500 samples), the ML\nmodel can classify the entire 120,000 samples with an accuracy of %85 and AUC\nscore of %91. The performance of ML methods in classifying the random field\nslope stability results generally reduces with higher anisotropy and\nheterogeneity of soil. The ML assisted MC reliability analysis proves a robust\nstochastic method where errors in the predicted probability of failure using %5\nof MC data is only %0.46 in average. The approach reduced the computational\ntime from 306 days to less than 6 hours.",
          "link": "http://arxiv.org/abs/2204.06097",
          "publishedOn": "2022-04-14T00:58:51.987Z",
          "wordCount": null,
          "title": "Slope stability predictions on spatially variable random fields using machine learning surrogate models. (arXiv:2204.06097v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.03349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wirth_E/0/1/0/all/0/1\">E. Wirth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokutta_S/0/1/0/all/0/1\">S. Pokutta</a>",
          "description": "The vanishing ideal of a set of points $X\\subseteq \\mathbb{R}^n$ is the set\nof polynomials that evaluate to $0$ over all points $\\mathbf{x} \\in X$ and\nadmits an efficient representation by a finite set of polynomials called\ngenerators. To accommodate the noise in the data set, we introduce the\nConditional Gradients Approximately Vanishing Ideal algorithm (CGAVI) for the\nconstruction of the set of generators of the approximately vanishing ideal. The\nconstructed set of generators captures polynomial structures in data and gives\nrise to a feature map that can, for example, be used in combination with a\nlinear classifier for supervised learning. In CGAVI, we construct the set of\ngenerators by solving specific instances of (constrained) convex optimization\nproblems with the Pairwise Frank-Wolfe algorithm (PFW). Among other things, the\nconstructed generators inherit the LASSO generalization bound and not only\nvanish on the training but also on out-sample data. Moreover, CGAVI admits a\ncompact representation of the approximately vanishing ideal by constructing few\ngenerators with sparse coefficient vectors.",
          "link": "http://arxiv.org/abs/2202.03349",
          "publishedOn": "2022-04-14T00:58:51.986Z",
          "wordCount": null,
          "title": "Conditional Gradients for the Approximately Vanishing Ideal. (arXiv:2202.03349v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05522",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cecchi_G/0/1/0/all/0/1\">Guillermo Cecchi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bouneffouf_D/0/1/0/all/0/1\">Djallel Bouneffouf</a>",
          "description": "The therapeutic working alliance is an important predictor of the outcome of\nthe psychotherapy treatment. In practice, the working alliance is estimated\nfrom a set of scoring questionnaires in an inventory that both the patient and\nthe therapists fill out. In this work, we propose an analytical framework of\ndirectly inferring the therapeutic working alliance from the natural language\nwithin the psychotherapy sessions in a turn-level resolution with deep\nembeddings such as the Doc2Vec and SentenceBERT models. The transcript of each\npsychotherapy session can be transcribed and generated in real-time from the\nsession speech recordings, and these embedded dialogues are compared with the\ndistributed representations of the statements in the working alliance\ninventory. We demonstrate, in a real-world dataset with over 950 sessions of\npsychotherapy treatments in anxiety, depression, schizophrenia and suicidal\npatients, the effectiveness of this method in mapping out trajectories of\npatient-therapist alignment and the interpretability that can offer insights in\nclinical psychiatry. We believe such a framework can be provide timely feedback\nto the therapist regarding the quality of the conversation in interview\nsessions.",
          "link": "http://arxiv.org/abs/2204.05522",
          "publishedOn": "2022-04-14T00:58:51.986Z",
          "wordCount": null,
          "title": "Deep Annotation of Therapeutic Working Alliance in Psychotherapy. (arXiv:2204.05522v1 [q-bio.NC] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Peiyan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1\">Qi Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bingguang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shiqi Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rongchan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhi-Ming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Stochastic partial differential equations (SPDEs) are significant tools for\nmodeling dynamics in many areas including atmospheric sciences and physics.\nNeural Operators, generations of neural networks with capability of learning\nmaps between infinite-dimensional spaces, are strong tools for solving\nparametric PDEs. However, they lack the ability to modeling SPDEs which usually\nhave poor regularity due to the driving noise. As the theory of regularity\nstructure has achieved great successes in analyzing SPDEs and provides the\nconcept model feature vectors that well-approximate SPDEs' solutions, we\npropose the Neural Operator with Regularity Structure (NORS) which incorporates\nthe feature vectors for modeling dynamics driven by SPDEs. We conduct\nexperiments on various of SPDEs including the dynamic Phi41 model and the 2d\nstochastic Navier-Stokes equation, and the results demonstrate that the NORS is\nresolution-invariant, efficient, and achieves one order of magnitude lower\nerror with a modest amount of data.",
          "link": "http://arxiv.org/abs/2204.06255",
          "publishedOn": "2022-04-14T00:58:51.985Z",
          "wordCount": null,
          "title": "Neural Operator with Regularity Structure for Modeling Dynamics Driven by SPDEs. (arXiv:2204.06255v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06445",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1\">Haibao Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhai_H/0/1/0/all/0/1\">Hongzhi Zhai</a>",
          "description": "Multi-label learning is often used to mine the correlation between variables\nand multiple labels, and its research focuses on fully extracting the\ninformation between variables and labels. The $\\ell_{2,1}$ regularization is\noften used to get a sparse coefficient matrix, but the problem of\nmulticollinearity among variables cannot be effectively solved. In this paper,\nthe proposed model can choose the most relevant variables by solving a joint\nconstraint optimization problem using the $\\ell_{2,1}$ regularization and\nFrobenius regularization. In manifold regularization, we carry out a random\nwalk strategy based on the joint structure to construct a neighborhood graph,\nwhich is highly robust to outliers. In addition, we give an iterative algorithm\nof the proposed method and proved the convergence of this algorithm. The\nexperiments on the real-world data sets also show that the comprehensive\nperformance of our method is consistently better than the classical method.",
          "link": "http://arxiv.org/abs/2204.06445",
          "publishedOn": "2022-04-14T00:58:51.943Z",
          "wordCount": null,
          "title": "Random Graph Embedding and Joint Sparse Regularization for Multi-label Feature Selection. (arXiv:2204.06445v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arasteh_S/0/1/0/all/0/1\">Soroosh Tayebi Arasteh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weise_T/0/1/0/all/0/1\">Tobias Weise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_M/0/1/0/all/0/1\">Maria Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noth_E/0/1/0/all/0/1\">Elmar N&#xf6;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Seung Hee Yang</a>",
          "description": "With the advancements in deep learning (DL) and an increasing interest in\ndata-driven speech processing methods, a major challenge for speech data\nscientists in the healthcare domain is the anonymization of pathological\nspeech, which is a required step to be able to make them accessible as a public\ntraining resource. In this paper, we investigate pathological speech data and\ncompare their speaker verifiability with that of healthy individuals. We\nutilize a large pathological speech corpus of more than 2,000 test subjects\nwith various speech and voice disorders from different ages and apply DL-based\nautomatic speaker verification (ASV) techniques. As a result, we obtained a\nmean equal error rate (EER) of 0.86% with a standard deviation of 0.16%, which\nis a factor of three lower than comparable healthy speech databases. We further\nperform detailed analyses of external influencing factors on ASV such as age,\npathology, recording environment, and utterance length, to explore their\nrespective effect. Our findings indicate that speech pathology is a potential\nbiomarker in ASV. This is potentially of high interest for the anonymization of\npathological speech data.",
          "link": "http://arxiv.org/abs/2204.06450",
          "publishedOn": "2022-04-14T00:58:51.943Z",
          "wordCount": null,
          "title": "Is Speech Pathology a Biomarker in Automatic Speaker Verification?. (arXiv:2204.06450v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06407",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_F/0/1/0/all/0/1\">Fu-Chieh Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_Y/0/1/0/all/0/1\">Yu-Wei Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Ya-Wen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Ssu-Rui Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cioba_A/0/1/0/all/0/1\">Alexandru Cioba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_I/0/1/0/all/0/1\">I-Lun Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_J/0/1/0/all/0/1\">Jhih-Wei Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng-Yuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chien-Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ren-Chu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yao-Wen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tai-Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tung-Chieh Chen</a>",
          "description": "Recently, successful applications of reinforcement learning to chip placement\nhave emerged. Pretrained models are necessary to improve efficiency and\neffectiveness. Currently, the weights of objective metrics (e.g., wirelength,\ncongestion, and timing) are fixed during pretraining. However, fixed-weighed\nmodels cannot generate the diversity of placements required for engineers to\naccommodate changing requirements as they arise. This paper proposes flexible\nmultiple-objective reinforcement learning (MORL) to support objective functions\nwith inference-time variable weights using just a single pretrained model. Our\nmacro placement results show that MORL can generate the Pareto frontier of\nmultiple objectives effectively.",
          "link": "http://arxiv.org/abs/2204.06407",
          "publishedOn": "2022-04-14T00:58:51.942Z",
          "wordCount": null,
          "title": "Flexible Multiple-Objective Reinforcement Learning for Chip Placement. (arXiv:2204.06407v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.08924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asghari_S/0/1/0/all/0/1\">Seyed Mohammad Asghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwaracherla_V/0/1/0/all/0/1\">Vikranth Dwaracherla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahimi_M/0/1/0/all/0/1\">Morteza Ibrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Effective decision, exploration, and adaptation often require an agent to\nknow what it knows and, also, what it does not know. This capability relies on\nthe quality of \\textit{joint} predictions of labels assigned to multiple\ninputs. Conventional neural networks lack this capability and, since most\nresearch has focused on marginal predictions, this shortcoming has been largely\noverlooked. By assessing the quality of joint predictions it is possible to\ndetermine whether a neural network effectively distinguishes between epistemic\nuncertainty (that due to lack of knowledge) and aleatoric uncertainty (that due\nto chance). We introduce the \\textit{epistemic neural network} (ENN) as a\ngeneral interface for uncertainty modeling in deep learning. While prior\napproaches to uncertainty modeling can be viewed as ENNs, the new interface\nfacilitates comparison of joint predictions, and the design of novel\narchitectures and algorithms. In particular, we introduce the \\textit{epinet}:\nan architecture that can supplement any existing neural network, including\npretrained models, and trained with modest incremental computation to represent\nuncertainty. With an epinet, conventional neural networks outperform very large\nensembles, consisting of hundreds or more particles, with orders of magnitude\nless computation. We demonstrate this efficacy across synthetic data, ImageNet,\nand sequential decision problems. As part of this effort we open-source\nexperiment code.",
          "link": "http://arxiv.org/abs/2107.08924",
          "publishedOn": "2022-04-14T00:58:51.921Z",
          "wordCount": 676,
          "title": "Epistemic Neural Networks. (arXiv:2107.08924v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zangwei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Pengtai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xuan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_D/0/1/0/all/0/1\">Da Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_C/0/1/0/all/0/1\">Chenguang Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_L/0/1/0/all/0/1\">Leqi Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Ming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiangzhuo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1\">Fuzhao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1\">Ziheng Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Youlong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "The click-through rate (CTR) prediction task is to predict whether a user\nwill click on the recommended item. As mind-boggling amounts of data are\nproduced online daily, accelerating CTR prediction model training is critical\nto ensuring an up-to-date model and reducing the training cost. One approach to\nincrease the training speed is to apply large batch training. However, as shown\nin computer vision and natural language processing tasks, training with a large\nbatch easily suffers from the loss of accuracy. Our experiments show that\nprevious scaling rules fail in the training of CTR prediction neural networks.\nTo tackle this problem, we first theoretically show that different frequencies\nof ids make it challenging to scale hyperparameters when scaling the batch\nsize. To stabilize the training process in a large batch size setting, we\ndevelop the adaptive Column-wise Clipping (CowClip). It enables an easy and\neffective scaling rule for the embeddings, which keeps the learning rate\nunchanged and scales the L2 loss. We conduct extensive experiments with four\nCTR prediction networks on two real-world datasets and successfully scaled 128\ntimes the original batch size without accuracy loss. In particular, for CTR\nprediction model DeepFM training on the Criteo dataset, our optimization\nframework enlarges the batch size from 1K to 128K with over 0.1% AUC\nimprovement and reduces training time from 12 hours to 10 minutes on a single\nV100 GPU. Our code locates at https://github.com/zhengzangw/LargeBatchCTR.",
          "link": "http://arxiv.org/abs/2204.06240",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "CowClip: Reducing CTR Prediction Model Training Time from 12 hours to 10 minutes on 1 GPU. (arXiv:2204.06240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunegatti_E/0/1/0/all/0/1\">Elia Cunegatti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iacca_G/0/1/0/all/0/1\">Giovanni Iacca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucur_D/0/1/0/all/0/1\">Doina Bucur</a>",
          "description": "Finding the most influential nodes in a network is a computationally hard\nproblem with several possible applications in various kinds of network-based\nproblems. While several methods have been proposed for tackling the influence\nmaximisation (IM) problem, their runtime typically scales poorly when the\nnetwork size increases. Here, we propose an original method, based on network\ndownscaling, that allows a multi-objective evolutionary algorithm (MOEA) to\nsolve the IM problem on a reduced scale network, while preserving the relevant\nproperties of the original network. The downscaled solution is then upscaled to\nthe original network, using a mechanism based on centrality metrics such as\nPageRank. Our results on eight large networks (including two with $\\sim$50k\nnodes) demonstrate the effectiveness of the proposed method with a more than\n10-fold runtime gain compared to the time needed on the original network, and\nan up to $82\\%$ time reduction compared to CELF.",
          "link": "http://arxiv.org/abs/2204.06250",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "Large-scale multi-objective influence maximisation with network downscaling. (arXiv:2204.06250v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rakka_M/0/1/0/all/0/1\">Mariam Rakka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fouda_M/0/1/0/all/0/1\">Mohammed E. Fouda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanj_R/0/1/0/all/0/1\">Rouwaida Kanj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurdahi_F/0/1/0/all/0/1\">Fadi Kurdahi</a>",
          "description": "Decision trees are considered one of the most powerful tools for data\nclassification. Accelerating the decision tree search is crucial for\non-the-edge applications that have limited power and latency budget. In this\npaper, we propose a Content Addressable Memory (CAM) Compiler for Decision Tree\n(DT) inference acceleration. We propose a novel \"adaptive-precision\" scheme\nthat results in a compact implementation and enables an efficient bijective\nmapping to Ternary Content Addressable Memories while maintaining high\ninference accuracies. In addition, a Resistive-CAM (ReCAM) functional\nsynthesizer is developed for mapping the decision tree to the ReCAM and\nperforming functional simulations for energy, latency, and accuracy\nevaluations. We study the decision tree accuracy under hardware non-idealities\nincluding device defects, manufacturing variability, and input encoding noise.\nWe test our framework on various DT datasets including \\textit{Give Me Some\nCredit}, \\textit{Titanic}, and \\textit{COVID-19}. Our results reveal up to\n{42.4\\%} energy savings and up to 17.8x better energy-delay-area product\ncompared to the state-of-art hardware accelerators, and up to 333 million\ndecisions per sec for the pipelined implementation.",
          "link": "http://arxiv.org/abs/2204.06114",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "DT2CAM: A Decision Tree to Content Addressable Memory Framework. (arXiv:2204.06114v1 [cs.AR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.06666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Runiu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shu-Tao Xia</a>",
          "description": "Hypergraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph-structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-range relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-and-play module for improving the representational power of\nHGCNNs.Specifically, HERALD adaptively optimizes the adjacency relationship\nbetween vertices and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.",
          "link": "http://arxiv.org/abs/2106.06666",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.06666v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1\">Armen Aghajanyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jessy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sida Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_F/0/1/0/all/0/1\">Freda Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1\">Ruiqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>",
          "description": "Code is seldom written in a single left-to-right pass and is instead\nrepeatedly edited and refined. We introduce InCoder, a unified generative model\nthat can perform program synthesis (via left-to-right generation) as well as\nediting (via infilling). InCoder is trained to generate code files from a large\ncorpus of permissively licensed code, where regions of code have been randomly\nmasked and moved to the end of each file, allowing code infilling with\nbidirectional context. Our model is the first generative model that is able to\ndirectly perform zero-shot code infilling, which we evaluate on challenging\ntasks such as type inference, comment generation, and variable re-naming. We\nfind that the ability to condition on bidirectional context substantially\nimproves performance on these tasks, while still performing comparably on\nstandard program synthesis benchmarks in comparison to left-to-right only\nmodels pretrained at similar scale. The InCoder models and code are publicly\nreleased. https://sites.google.com/view/incoder-code-models",
          "link": "http://arxiv.org/abs/2204.05999",
          "publishedOn": "2022-04-14T00:58:51.899Z",
          "wordCount": null,
          "title": "InCoder: A Generative Model for Code Infilling and Synthesis. (arXiv:2204.05999v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muller_D/0/1/0/all/0/1\">Dominik M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_Rey_I/0/1/0/all/0/1\">I&#xf1;aki Soto-Rey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramer_F/0/1/0/all/0/1\">Frank Kramer</a>",
          "description": "Novel and high-performance medical image classification pipelines are heavily\nutilizing ensemble learning strategies. The idea of ensemble learning is to\nassemble diverse models or multiple predictions and, thus, boost prediction\nperformance. However, it is still an open question to what extent as well as\nwhich ensemble learning strategies are beneficial in deep learning based\nmedical image classification pipelines. In this work, we proposed a\nreproducible medical image classification pipeline for analyzing the\nperformance impact of the following ensemble learning techniques: Augmenting,\nStacking, and Bagging. The pipeline consists of state-of-the-art preprocessing\nand image augmentation methods as well as 9 deep convolution neural network\narchitectures. It was applied on four popular medical imaging datasets with\nvarying complexity. Furthermore, 12 pooling functions for combining multiple\npredictions were analyzed, ranging from simple statistical functions like\nunweighted averaging up to more complex learning-based functions like support\nvector machines. Our results revealed that Stacking achieved the largest\nperformance gain of up to 13% F1-score increase. Augmenting showed consistent\nimprovement capabilities by up to 4% and is also applicable to single model\nbased pipelines. Cross-validation based Bagging demonstrated significant\nperformance gain close to Stacking, which resulted in an F1-score increase up\nto +11%. Furthermore, we demonstrated that simple statistical pooling functions\nare equal or often even better than more complex pooling functions. We\nconcluded that the integration of ensemble learning techniques is a powerful\nmethod for any medical image classification pipeline to improve robustness and\nboost performance.",
          "link": "http://arxiv.org/abs/2201.11440",
          "publishedOn": "2022-04-14T00:58:51.897Z",
          "wordCount": null,
          "title": "An Analysis on Ensemble Learning optimized Medical Image Classification with Deep Convolutional Neural Networks. (arXiv:2201.11440v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1\">Jing Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_N/0/1/0/all/0/1\">Nguyen Quoc Viet Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>",
          "description": "Next Point-of-Interest (POI) recommendation has become an indispensable\nfunctionality in Location-based Social Networks (LBSNs) due to its\neffectiveness in helping people decide the next POI to visit. However, accurate\nrecommendation requires a vast amount of historical check-in data, thus\nthreatening user privacy as the location-sensitive data needs to be handled by\ncloud servers. Although there have been several on-device frameworks for\nprivacy-preserving POI recommendations, they are still resource-intensive when\nit comes to storage and computation, and show limited robustness to the high\nsparsity of user-POI interactions. On this basis, we propose a novel\ndecentralized collaborative learning framework for POI recommendation (DCLR),\nwhich allows users to train their personalized models locally in a\ncollaborative manner. DCLR significantly reduces the local models' dependence\non the cloud for training, and can be used to expand arbitrary centralized\nrecommendation models. To counteract the sparsity of on-device user data when\nlearning each local model, we design two self-supervision signals to pretrain\nthe POI representations on the server with geographical and categorical\ncorrelations of POIs. To facilitate collaborative learning, we innovatively\npropose to incorporate knowledge from either geographically or semantically\nsimilar users into each local model with attentive aggregation and mutual\ninformation maximization. The collaborative learning process makes use of\ncommunications between devices while requiring only minor engagement from the\ncentral server for identifying user groups, and is compatible with common\nprivacy preservation mechanisms like differential privacy.",
          "link": "http://arxiv.org/abs/2204.06516",
          "publishedOn": "2022-04-14T00:58:51.893Z",
          "wordCount": 668,
          "title": "Decentralized Collaborative Learning Framework for Next POI Recommendation. (arXiv:2204.06516v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bang Wang</a>",
          "description": "How to effectively sample high-quality negative instances is important for\nwell training a recommendation model. We argue that a high-quality negative\nshould be both \\textit{informativeness} and \\textit{unbiasedness}. Although\nprevious studies have proposed some approaches to address the informativeness\nin negative sampling, few has been done to discriminating false negative from\ntrue negative for unbiased negative sampling, not to mention taking both into\nconsideration. This paper first adopts a parameter learning perspective to\nanalyze negative informativeness and unbiasedness in loss gradient-based model\ntraining. We argue that both negative sampling and collaborative filtering\ninclude an implicit task of negative classification, from which we report an\ninsightful yet beneficial finding about the order relation in predicted\nnegatives' scores. Based on our finding and by regarding negatives as random\nvariables, we next derive the class condition density of true negatives and\nthat of false negatives. We also design a Bayesian classifier for negative\nclassification, from which we define a quantitative unbiasedness measure for\nnegatives. Finally, we propose to use a harmonic mean of informativeness and\nunbiasedness to sample high-quality negatives. Experimental studies validate\nthe superiority of our negative sampling algorithm over the peers in terms of\nbetter sampling quality and better recommendation performance.",
          "link": "http://arxiv.org/abs/2204.06520",
          "publishedOn": "2022-04-14T00:58:51.867Z",
          "wordCount": 624,
          "title": "Negative Sampling for Recommendation. (arXiv:2204.06520v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seongmin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie J. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1\">Judy Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>",
          "description": "CNN image classifiers are widely used, thanks to their efficiency and\naccuracy. However, they can suffer from biases that impede their practical\napplications. Most existing bias investigation techniques are either\ninapplicable to general image classification tasks or require significant user\nefforts in perusing all data subgroups to manually specify which data\nattributes to inspect. We present VisCUIT, an interactive visualization system\nthat reveals how and why a CNN classifier is biased. VisCUIT visually\nsummarizes the subgroups on which the classifier underperforms and helps users\ndiscover and characterize the cause of the underperformances by revealing image\nconcepts responsible for activating neurons that contribute to\nmisclassifications. VisCUIT runs in modern browsers and is open-source,\nallowing people to easily access and extend the tool to other model\narchitectures and datasets. VisCUIT is available at the following public demo\nlink: https://poloclub.github.io/VisCUIT. A video demo is available at\nhttps://youtu.be/eNDbSyM4R_4.",
          "link": "http://arxiv.org/abs/2204.05899",
          "publishedOn": "2022-04-14T00:58:51.860Z",
          "wordCount": 611,
          "title": "VisCUIT: Visual Auditor for Bias in CNN Image Classifier. (arXiv:2204.05899v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_W/0/1/0/all/0/1\">Wenqiang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agapitos_A/0/1/0/all/0/1\">Alexandros Agapitos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanwei Liu</a>",
          "description": "Coverage and capacity are the important metrics for performance evaluation in\nwireless networks, while the coverage and capacity have several conflicting\nrelationships, e.g. high transmit power contributes to large coverage but high\ninter-cell interference reduces the capacity performance. Therefore, in order\nto strike a balance between the coverage and capacity, a novel model is\nproposed for the coverage and capacity optimization of simultaneously\ntransmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs)\nassisted networks. To solve the coverage and capacity optimization (CCO)\nproblem, a machine learning-based multi-objective optimization algorithm, i.e.,\nthe multi-objective proximal policy optimization (MO-PPO) algorithm, is\nproposed. In this algorithm, a loss function-based update strategy is the core\npoint, which is able to calculate weights for both loss functions of coverage\nand capacity by a min-norm solver at each update. The numerical results\ndemonstrate that the investigated update strategy outperforms the fixed\nweight-based MO algorithms.",
          "link": "http://arxiv.org/abs/2204.06390",
          "publishedOn": "2022-04-14T00:58:51.850Z",
          "wordCount": 600,
          "title": "Coverage and Capacity Optimization in STAR-RISs Assisted Networks: A Machine Learning Approach. (arXiv:2204.06390v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1\">Martin Josifoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_N/0/1/0/all/0/1\">Nicola De Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petroni_F/0/1/0/all/0/1\">Fabio Petroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>",
          "description": "Structured and grounded representation of text is typically formalized by\nclosed information extraction, the problem of extracting an exhaustive set of\n(subject, relation, object) triplets that are consistent with a predefined set\nof entities and relations from a knowledge base schema. Most existing works are\npipelines prone to error accumulation, and all approaches are only applicable\nto unrealistically small numbers of entities and relations. We introduce GenIE\n(generative information extraction), the first end-to-end autoregressive\nformulation of closed information extraction. GenIE naturally exploits the\nlanguage knowledge from the pre-trained transformer by autoregressively\ngenerating relations and entities in textual form. Thanks to a new bi-level\nconstrained generation strategy, only triplets consistent with the predefined\nknowledge base schema are produced. Our experiments show that GenIE is\nstate-of-the-art on closed information extraction, generalizes from fewer\ntraining data points than baselines, and scales to a previously unmanageable\nnumber of entities and relations. With this work, closed information extraction\nbecomes practical in realistic scenarios, providing new opportunities for\ndownstream tasks. Finally, this work paves the way towards a unified end-to-end\napproach to the core tasks of information extraction. Code, data and models\navailable at https://github.com/epfl-dlab/GenIE.",
          "link": "http://arxiv.org/abs/2112.08340",
          "publishedOn": "2022-04-14T00:58:51.840Z",
          "wordCount": 674,
          "title": "GenIE: Generative Information Extraction. (arXiv:2112.08340v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1810.03730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1\">Christian Walder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lexing Xie</a>",
          "description": "In this paper, we develop an efficient nonparametric Bayesian estimation of\nthe kernel function of Hawkes processes. The non-parametric Bayesian approach\nis important because it provides flexible Hawkes kernels and quantifies their\nuncertainty. Our method is based on the cluster representation of Hawkes\nprocesses. Utilizing the finite support assumption of the Hawkes process, we\nefficiently sample random branching structures and thus, we split the Hawkes\nprocess into clusters of Poisson processes. We derive two algorithms -- a block\nGibbs sampler and a maximum a posteriori estimator based on expectation\nmaximization -- and we show that our methods have a linear time complexity,\nboth theoretically and empirically. On synthetic data, we show our methods to\nbe able to infer flexible Hawkes triggering kernels. On two large-scale Twitter\ndiffusion datasets, we show that our methods outperform the current\nstate-of-the-art in goodness-of-fit and that the time complexity is linear in\nthe size of the dataset. We also observe that on diffusions related to online\nvideos, the learned kernels reflect the perceived longevity for different\ncontent types such as music or pets videos.",
          "link": "http://arxiv.org/abs/1810.03730",
          "publishedOn": "2022-04-14T00:58:51.831Z",
          "wordCount": 671,
          "title": "Efficient Non-parametric Bayesian Hawkes Processes. (arXiv:1810.03730v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "Prompt-based learning (i.e., prompting) is an emerging paradigm for\nexploiting knowledge learned by a pretrained language model. In this paper, we\npropose Automatic Multi-Label Prompting (AMuLaP), a simple yet effective method\nto automatically select label mappings for few-shot text classification with\nprompting. Our method exploits one-to-many label mappings and a\nstatistics-based algorithm to select label mappings given a prompt template.\nOur experiments demonstrate that AMuLaP achieves competitive performance on the\nGLUE benchmark without human effort or external resources.",
          "link": "http://arxiv.org/abs/2204.06305",
          "publishedOn": "2022-04-14T00:58:51.800Z",
          "wordCount": 515,
          "title": "Automatic Multi-Label Prompting: Simple and Interpretable Few-Shot Classification. (arXiv:2204.06305v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1\">Kangning Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plemmons_R/0/1/0/all/0/1\">Robert J. Plemmons</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Hyperspectral images encode rich structure that can be exploited for material\ndiscrimination by machine learning algorithms. This article introduces the\nActive Diffusion and VCA-Assisted Image Segmentation (ADVIS) for active\nmaterial discrimination. ADVIS selects high-purity, high-density pixels that\nare far in diffusion distance (a data-dependent metric) from other high-purity,\nhigh-density pixels in the hyperspectral image. The ground truth labels of\nthese pixels are queried and propagated to the rest of the image. The ADVIS\nactive learning algorithm is shown to strongly outperform its fully\nunsupervised clustering algorithm counterpart, suggesting that the\nincorporation of a very small number of carefully-selected ground truth labels\ncan result in substantially superior material discrimination in hyperspectral\nimages.",
          "link": "http://arxiv.org/abs/2204.06298",
          "publishedOn": "2022-04-14T00:58:51.793Z",
          "wordCount": 566,
          "title": "Active Diffusion and VCA-Assisted Image Segmentation of Hyperspectral Images. (arXiv:2204.06298v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suteu_M/0/1/0/all/0/1\">Mihai Suteu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>",
          "description": "Structured pruning efficiently compresses networks by identifying and\nremoving unimportant neurons. While this can be elegantly achieved by applying\nsparsity-inducing regularisation on BatchNorm parameters, an L1 penalty would\nshrink all scaling factors rather than just those of superfluous neurons. To\ntackle this issue, we introduce a simple BatchNorm variation with bounded\nscaling parameters, based on which we design a novel regularisation term that\nsuppresses only neurons with low importance. Under our method, the weights of\nunnecessary neurons effectively recede, producing a polarised bimodal\ndistribution of importances. We show that neural networks trained this way can\nbe pruned to a larger extent and with less deterioration. We one-shot prune VGG\nand ResNet architectures at different ratios on CIFAR and ImagenNet datasets.\nIn the case of VGG-style networks, our method significantly outperforms\nexisting approaches particularly under a severe pruning regime.",
          "link": "http://arxiv.org/abs/2204.06404",
          "publishedOn": "2022-04-14T00:58:51.785Z",
          "wordCount": 561,
          "title": "Receding Neuron Importances for Structured Pruning. (arXiv:2204.06404v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.15646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Floto_G/0/1/0/all/0/1\">Griffin Floto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kremer_S/0/1/0/all/0/1\">Stefan Kremer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nica_M/0/1/0/all/0/1\">Mihai Nica</a>",
          "description": "An important property for deep neural networks is the ability to perform\nrobust out-of-distribution detection on previously unseen data. This property\nis essential for safety purposes when deploying models for real world\napplications. Recent studies show that probabilistic generative models can\nperform poorly on this task, which is surprising given that they seek to\nestimate the likelihood of training data. To alleviate this issue, we propose\nthe exponentially tilted Gaussian prior distribution for the Variational\nAutoencoder (VAE) which pulls points onto the surface of a hyper-sphere in\nlatent space. This achieves state-of-the art results on the area under the\ncurve-receiver operator characteristics metric using just the log-likelihood\nthat the VAE naturally assigns. Because this prior is a simple modification of\nthe traditional VAE prior, it is faster and easier to implement than\ncompetitive methods.",
          "link": "http://arxiv.org/abs/2111.15646",
          "publishedOn": "2022-04-14T00:58:51.775Z",
          "wordCount": 611,
          "title": "The Exponentially Tilted Gaussian Prior for Variational Autoencoders. (arXiv:2111.15646v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patil_P/0/1/0/all/0/1\">Parth Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranade_A/0/1/0/all/0/1\">Aparna Ranade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabane_M/0/1/0/all/0/1\">Maithili Sabane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litake_O/0/1/0/all/0/1\">Onkar Litake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>",
          "description": "Named Entity Recognition (NER) is a basic NLP task and finds major\napplications in conversational and search systems. It helps us identify key\nentities in a sentence used for the downstream application. NER or similar slot\nfilling systems for popular languages have been heavily used in commercial\napplications. In this work, we focus on Marathi, an Indian language, spoken\nprominently by the people of Maharashtra state. Marathi is a low resource\nlanguage and still lacks useful NER resources. We present L3Cube-MahaNER, the\nfirst major gold standard named entity recognition dataset in Marathi. We also\ndescribe the manual annotation guidelines followed during the process. In the\nend, we benchmark the dataset on different CNN, LSTM, and Transformer based\nmodels like mBERT, XLM-RoBERTa, IndicBERT, MahaBERT, etc. The MahaBERT provides\nthe best performance among all the models. The data and models are available at\nhttps://github.com/l3cube-pune/MarathiNLP .",
          "link": "http://arxiv.org/abs/2204.06029",
          "publishedOn": "2022-04-14T00:58:51.659Z",
          "wordCount": null,
          "title": "L3Cube-MahaNER: A Marathi Named Entity Recognition Dataset and BERT models. (arXiv:2204.06029v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06109",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Baran_S/0/1/0/all/0/1\">Sebastian Baran</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Rola_P/0/1/0/all/0/1\">Przemys&#x142;aw Rola</a>",
          "description": "The insurance industry, with its large datasets, is a natural place to use\nbig data solutions. However it must be stressed, that significant number of\napplications for machine learning in insurance industry, like fraud detection\nor claim prediction, deals with the problem of machine learning on an\nimbalanced data set. This is due to the fact that frauds or claims are rare\nevents when compared with the entire population of drivers. The problem of\nimbalanced learning is often hard to overcome. Therefore, the main goal of this\nwork is to present and apply various methods of dealing with an imbalanced\ndataset in the context of claim occurrence prediction in car insurance. In\naddition, the above techniques are used to compare the results of machine\nlearning algorithms in the context of claim occurrence prediction in car\ninsurance. Our study covers the following techniques: logistic-regression,\ndecision tree, random forest, xgBoost, feed-forward network. The problem is the\nclassification one.",
          "link": "http://arxiv.org/abs/2204.06109",
          "publishedOn": "2022-04-14T00:58:51.659Z",
          "wordCount": null,
          "title": "Prediction of motor insurance claims occurrence as an imbalanced machine learning problem. (arXiv:2204.06109v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06214",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mandal_R/0/1/0/all/0/1\">Ranju Mandal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azam_B/0/1/0/all/0/1\">Basim Azam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_B/0/1/0/all/0/1\">Brijesh Verma</a>",
          "description": "Deep learning models have been efficient lately on image parsing tasks.\nHowever, deep learning models are not fully capable of exploiting visual and\ncontextual information simultaneously. The proposed three-layer context-based\ndeep architecture is capable of integrating context explicitly with visual\ninformation. The novel idea here is to have a visual layer to learn visual\ncharacteristics from binary class-based learners, a contextual layer to learn\ncontext, and then an integration layer to learn from both via genetic\nalgorithm-based optimal fusion to produce a final decision. The experimental\noutcomes when evaluated on benchmark datasets are promising. Further analysis\nshows that optimized network weights can improve performance and make stable\npredictions.",
          "link": "http://arxiv.org/abs/2204.06214",
          "publishedOn": "2022-04-14T00:58:51.629Z",
          "wordCount": null,
          "title": "Context-based Deep Learning Architecture with Optimal Integration Layer for Image Parsing. (arXiv:2204.06214v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weyns_D/0/1/0/all/0/1\">Danny Weyns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gheibi_O/0/1/0/all/0/1\">Omid Gheibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quin_F/0/1/0/all/0/1\">Federico Quin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donckt_J/0/1/0/all/0/1\">Jeroen Van Der Donckt</a>",
          "description": "Many software systems today face uncertain operating conditions, such as\nsudden changes in the availability of resources or unexpected user behavior.\nWithout proper mitigation these uncertainties can jeopardize the system goals.\nSelf-adaptation is a common approach to tackle such uncertainties. When the\nsystem goals may be compromised, the self-adaptive system has to select the\nbest adaptation option to reconfigure by analyzing the possible adaptation\noptions, i.e., the adaptation space. Yet, analyzing large adaptation spaces\nusing rigorous methods can be resource- and time-consuming, or even be\ninfeasible. One approach to tackle this problem is by using online machine\nlearning to reduce adaptation spaces. However, existing approaches require\ndomain expertise to perform feature engineering to define the learner, and\nsupport online adaptation space reduction only for specific goals. To tackle\nthese limitations, we present 'Deep Learning for Adaptation Space Reduction\nPlus' -- DLASeR+ in short. DLASeR+ offers an extendable learning framework for\nonline adaptation space reduction that does not require feature engineering,\nwhile supporting three common types of adaptation goals: threshold,\noptimization, and set-point goals. We evaluate DLASeR+ on two instances of an\nInternet-of-Things application with increasing sizes of adaptation spaces for\ndifferent combinations of adaptation goals. We compare DLASeR+ with a baseline\nthat applies exhaustive analysis and two state-of-the-art approaches for\nadaptation space reduction that rely on learning. Results show that DLASeR+ is\neffective with a negligible effect on the realization of the adaptation goals\ncompared to an exhaustive analysis approach, and supports three common types of\nadaptation goals beyond the state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2204.06254",
          "publishedOn": "2022-04-14T00:58:51.629Z",
          "wordCount": null,
          "title": "Deep Learning for Effective and Efficient Reduction of Large Adaptation Spaces in Self-Adaptive Systems. (arXiv:2204.06254v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassignana_E/0/1/0/all/0/1\">Elisa Bassignana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Eberstein_M/0/1/0/all/0/1\">Max M&#xfc;ller-Eberstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varab_D/0/1/0/all/0/1\">Daniel Varab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mike Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardmeier_C/0/1/0/all/0/1\">Christian Hardmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>",
          "description": "The field of Deep Learning (DL) has undergone explosive growth during the\nlast decade, with a substantial impact on Natural Language Processing (NLP) as\nwell. Yet, as with other fields employing DL techniques, there has been a lack\nof common experimental standards compared to more established disciplines.\nStarting from fundamental scientific principles, we distill ongoing discussions\non experimental standards in DL into a single, widely-applicable methodology.\nFollowing these best practices is crucial to strengthening experimental\nevidence, improve reproducibility and enable scientific progress. These\nstandards are further collected in a public repository to help them\ntransparently adapt to future needs.",
          "link": "http://arxiv.org/abs/2204.06251",
          "publishedOn": "2022-04-14T00:58:51.628Z",
          "wordCount": null,
          "title": "Experimental Standards for Deep Learning Research: A Natural Language Processing Perspective. (arXiv:2204.06251v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.05097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Manh Tuan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1\">Noseong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>",
          "description": "Graph neural networks (GNNs) have received massive attention in the field of\nmachine learning on graphs. Inspired by the success of neural networks, a line\nof research has been conducted to train GNNs to deal with various tasks, such\nas node classification, graph classification, and link prediction. In this\nwork, our task of interest is graph classification. Several GNN models have\nbeen proposed and shown great accuracy in this task. However, the question is\nwhether usual training methods fully realize the capacity of the GNN models.\n\nIn this work, we propose a two-stage training framework based on triplet\nloss. In the first stage, GNN is trained to map each graph to a Euclidean-space\nvector so that graphs of the same class are close while those of different\nclasses are mapped far apart. Once graphs are well-separated based on labels, a\nclassifier is trained to distinguish between different classes. This method is\ngeneric in the sense that it is compatible with any GNN model. By adapting five\nGNN models to our method, we demonstrate the consistent improvement in accuracy\nand utilization of each GNN's allocated capacity over the original training\nmethod of each model up to 5.4\\% points in 12 datasets.",
          "link": "http://arxiv.org/abs/2011.05097",
          "publishedOn": "2022-04-11T00:52:29.155Z",
          "wordCount": 684,
          "title": "Two-stage Training of Graph Neural Networks for Graph Classification. (arXiv:2011.05097v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.02445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1\">Kirill Shevkunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1\">Liudmila Prokhorenkova</a>",
          "description": "Various non-trivial spaces are becoming popular for embedding structured data\nsuch as graphs, texts, or images. Following spherical and hyperbolic spaces,\nmore general product spaces have been proposed. However, searching for the best\nconfiguration of product space is a resource-intensive procedure, which reduces\nthe practical applicability of the idea. We generalize the concept of product\nspace and introduce an overlapping space that does not have the configuration\nsearch problem. The main idea is to allow subsets of coordinates to be shared\nbetween spaces of different types (Euclidean, hyperbolic, spherical). As a\nresult, parameter optimization automatically learns the optimal configuration.\nAdditionally, overlapping spaces allow for more compact representations since\ntheir geometry is more complex. Our experiments confirm that overlapping spaces\noutperform the competitors in graph embedding tasks. Here, we consider both\ndistortion setup, where the aim is to preserve distances, and ranking setup,\nwhere the relative order should be preserved. The proposed method effectively\nsolves the problem and outperforms the competitors in both settings. We also\nperform an empirical analysis in a realistic information retrieval task, where\nwe compare all spaces by incorporating them into DSSM. In this case, the\nproposed overlapping space consistently achieves nearly optimal results without\nany configuration tuning. This allows for reducing training time, which can be\nsignificant in large-scale applications.",
          "link": "http://arxiv.org/abs/2007.02445",
          "publishedOn": "2022-04-11T00:52:29.147Z",
          "wordCount": 697,
          "title": "Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mahdi S. Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jia Shu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_A/0/1/0/all/0/1\">Andre Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jingxuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuli_M/0/1/0/all/0/1\">Mathieu Tuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1\">Sepehr Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadakia_A/0/1/0/all/0/1\">Arsh Kadakia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1\">Konstantinos N. Plataniotis</a>",
          "description": "Neural Architecture Search (NAS) has shifted network design from using human\nintuition to leveraging search algorithms guided by evaluation metrics. We\nstudy channel size optimization in convolutional neural networks (CNN) and\nidentify the role it plays in model accuracy and complexity. Current channel\nsize selection methods are generally limited by discrete sample spaces while\nsuffering from manual iteration and simple heuristics. To solve this, we\nintroduce an efficient dynamic scaling algorithm -- CONet -- that automatically\noptimizes channel sizes across network layers for a given CNN. Two metrics --\n\"\\textit{Rank}\" and \"\\textit{Rank Average Slope}\" -- are introduced to identify\nthe information accumulated in training. The algorithm dynamically scales\nchannel sizes up or down over a fixed searching phase. We conduct experiments\non CIFAR10/100 and ImageNet datasets and show that CONet can find efficient and\naccurate architectures searched in ResNet, DARTS, and DARTS+ spaces that\noutperform their baseline models.\n\nThis document supersedes previously published paper in ICCV2021-NeurArch\nworkshop. An additional section is included on manual scaling of channel size\nin CNNs to numerically validate of the metrics used in searching optimum\nchannel configurations in CNNs.",
          "link": "http://arxiv.org/abs/2108.06822",
          "publishedOn": "2022-04-11T00:52:29.140Z",
          "wordCount": 677,
          "title": "CONet: Channel Optimization for Convolutional Neural Networks. (arXiv:2108.06822v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.10439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_A/0/1/0/all/0/1\">Alexander Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_A/0/1/0/all/0/1\">Andrew H. Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1\">Berkin Bilgic</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ba_D/0/1/0/all/0/1\">Demba Ba</a>",
          "description": "Sparse Bayesian learning (SBL) is a powerful framework for tackling the\nsparse coding problem while also providing uncertainty quantification. The most\npopular inference algorithms for SBL exhibit prohibitively large computational\ncosts for high-dimensional problems due to the need to maintain a large\ncovariance matrix. To resolve this issue, we introduce a new method for\naccelerating SBL inference -- named covariance-free expectation maximization\n(CoFEM) -- that avoids explicit computation of the covariance matrix. CoFEM\nsolves multiple linear systems to obtain unbiased estimates of the posterior\nstatistics needed by SBL. This is accomplished by exploiting innovations from\nnumerical linear algebra such as preconditioned conjugate gradient and a\nlittle-known diagonal estimation rule. For a large class of compressed sensing\nmatrices, we provide theoretical justifications for why our method scales well\nin high-dimensional settings. Through simulations, we show that CoFEM can be up\nto thousands of times faster than existing baselines without sacrificing coding\naccuracy. Through applications to calcium imaging deconvolution and\nmulti-contrast MRI reconstruction, we show that CoFEM enables SBL to tractably\ntackle high-dimensional sparse coding problems of practical interest.",
          "link": "http://arxiv.org/abs/2105.10439",
          "publishedOn": "2022-04-11T00:52:29.133Z",
          "wordCount": 635,
          "title": "Covariance-Free Sparse Bayesian Learning. (arXiv:2105.10439v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.01808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isacchini_G/0/1/0/all/0/1\">Giulio Isacchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spisak_N/0/1/0/all/0/1\">Natanael Spisak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourmohammad_A/0/1/0/all/0/1\">Armita Nourmohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mora_T/0/1/0/all/0/1\">Thierry Mora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walczak_A/0/1/0/all/0/1\">Aleksandra M. Walczak</a>",
          "description": "Simulation-based inference enables learning the parameters of a model even\nwhen its likelihood cannot be computed in practice. One class of methods uses\ndata simulated with different parameters to infer models of the\nlikelihood-to-evidence ratio, or equivalently the posterior function. Here we\nframe the inference task as an estimation of an energy function parametrized\nwith an artificial neural network. We present an intuitive approach where the\noptimal model of the likelihood-to-evidence ratio is found by maximizing the\nlikelihood of simulated data. Within this framework, the connection between the\ntask of simulation-based inference and mutual information maximization is\nclear, and we show how several known methods of posterior estimation relate to\nalternative lower bounds to mutual information. These distinct objective\nfunctions aim at the same optimal energy form and therefore can be directly\nbenchmarked. We compare their accuracy in the inference of model parameters,\nfocusing on four dynamical systems that encompass common challenges in time\nseries analysis: dynamics driven by multiplicative noise, nonlinear\ninteractions, chaotic behavior, and high-dimensional parameter space.",
          "link": "http://arxiv.org/abs/2106.01808",
          "publishedOn": "2022-04-11T00:52:29.125Z",
          "wordCount": 653,
          "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories. (arXiv:2106.01808v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Anru R. Zhang</a>",
          "description": "We consider the problem of learning high dimensional polynomial\ntransformations of Gaussians. Given samples of the form $p(x)$, where $x\\sim\nN(0, \\mathrm{Id}_r)$ is hidden and $p: \\mathbb{R}^r \\to \\mathbb{R}^d$ is a\nfunction where every output coordinate is a low-degree polynomial, the goal is\nto learn the distribution over $p(x)$. This problem is natural in its own\nright, but is also an important special case of learning deep generative\nmodels, namely pushforwards of Gaussians under two-layer neural networks with\npolynomial activations. Understanding the learnability of such generative\nmodels is crucial to understanding why they perform so well in practice.\n\nOur first main result is a polynomial-time algorithm for learning quadratic\ntransformations of Gaussians in a smoothed setting. Our second main result is a\npolynomial-time algorithm for learning constant-degree polynomial\ntransformations of Gaussian in a smoothed setting, when the rank of the\nassociated tensors is small. In fact our results extend to any\nrotation-invariant input distribution, not just Gaussian. These are the first\nend-to-end guarantees for learning a pushforward under a neural network with\nmore than one layer.\n\nAlong the way, we also give the first polynomial-time algorithms with\nprovable guarantees for tensor ring decomposition, a popular generalization of\ntensor decomposition that is used in practice to implicitly store large\ntensors.",
          "link": "http://arxiv.org/abs/2204.04209",
          "publishedOn": "2022-04-11T00:52:29.101Z",
          "wordCount": 641,
          "title": "Learning Polynomial Transformations. (arXiv:2204.04209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Turri_V/0/1/0/all/0/1\">Violet Turri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dzombak_R/0/1/0/all/0/1\">Rachel Dzombak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heim_E/0/1/0/all/0/1\">Eric Heim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+VanHoudnos_N/0/1/0/all/0/1\">Nathan VanHoudnos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palat_J/0/1/0/all/0/1\">Jay Palat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Anusha Sinha</a>",
          "description": "Current test and evaluation (T&E) methods for assessing machine learning (ML)\nsystem performance often rely on incomplete metrics. Testing is additionally\noften siloed from the other phases of the ML system lifecycle. Research\ninvestigating cross-domain approaches to ML T&E is needed to drive the state of\nthe art forward and to build an Artificial Intelligence (AI) engineering\ndiscipline. This paper advocates for a robust, integrated approach to testing\nby outlining six key questions for guiding a holistic T&E strategy.",
          "link": "http://arxiv.org/abs/2204.04211",
          "publishedOn": "2022-04-11T00:52:29.094Z",
          "wordCount": 528,
          "title": "Measuring AI Systems Beyond Accuracy. (arXiv:2204.04211v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khazraei_A/0/1/0/all/0/1\">Amir Khazraei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hallyburton_S/0/1/0/all/0/1\">Spencer Hallyburton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qitong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1\">Miroslav Pajic</a>",
          "description": "This work focuses on the use of deep learning for vulnerability analysis of\ncyber-physical systems (CPS). Specifically, we consider a control architecture\nwidely used in CPS (e.g., robotics), where the low-level control is based on\ne.g., the extended Kalman filter (EKF) and an anomaly detector. To facilitate\nanalyzing the impact potential sensing attacks could have, our objective is to\ndevelop learning-enabled attack generators capable of designing stealthy\nattacks that maximally degrade system operation. We show how such problem can\nbe cast within a learning-based grey-box framework where parts of the runtime\ninformation are known to the attacker, and introduce two models based on\nfeed-forward neural networks (FNN); both models are trained offline, using a\ncost function that combines the attack effects on the estimation error and the\nresidual signal used for anomaly detection, so that the trained models are\ncapable of recursively generating such effective sensor attacks in real-time.\nThe effectiveness of the proposed methods is illustrated on several case\nstudies.",
          "link": "http://arxiv.org/abs/2103.06271",
          "publishedOn": "2022-04-11T00:52:29.087Z",
          "wordCount": 641,
          "title": "Learning-Based Vulnerability Analysis of Cyber-Physical Systems. (arXiv:2103.06271v3 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04187",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Saar_L/0/1/0/all/0/1\">Logan Saar</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Liang_H/0/1/0/all/0/1\">Haotong Liang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Wang_A/0/1/0/all/0/1\">Alex Wang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+McDannald_A/0/1/0/all/0/1\">Austin McDannald</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Rodriguez_E/0/1/0/all/0/1\">Efrain Rodriguez</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kusne_A/0/1/0/all/0/1\">A. Gilad Kusne</a>",
          "description": "The next generation of physical science involves robot scientists -\nautonomous physical science systems capable of experimental design, execution,\nand analysis in a closed loop. Such systems have shown real-world success for\nscientific exploration and discovery, including the first discovery of a\nbest-in-class material. To build and use these systems, the next generation\nworkforce requires expertise in diverse areas including ML, control systems,\nmeasurement science, materials synthesis, decision theory, among others.\nHowever, education is lagging. Educators need a low-cost, easy-to-use platform\nto teach the required skills. Industry can also use such a platform for\ndeveloping and evaluating autonomous physical science methodologies. We present\nthe next generation in science education, a kit for building a low-cost\nautonomous scientist. The kit was used during two courses at the University of\nMaryland to teach undergraduate and graduate students autonomous physical\nscience. We discuss its use in the course and its greater capability to teach\nthe dual tasks of autonomous model exploration, optimization, and\ndetermination, with an example of autonomous experimental \"discovery\" of the\nHenderson-Hasselbalch equation.",
          "link": "http://arxiv.org/abs/2204.04187",
          "publishedOn": "2022-04-11T00:52:29.079Z",
          "wordCount": 625,
          "title": "A Low-Cost Robot Science Kit for Education with Symbolic Regression for Hypothesis Discovery and Validation. (arXiv:2204.04187v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.09907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agibetov_A/0/1/0/all/0/1\">Asan Agibetov</a>",
          "description": "Learning good quality neural graph embeddings has long been achieved by\nminimzing the pointwise mutual information (PMI) for co-occuring nodes in\nsimulated random walks. This design choice has been mostly popularized by the\ndirect application of the highly-successful word embedding algorithm word2vec\nto predicting the formation of new links in social, co-citation, and biological\nnetworks. However, such a skeumorphic design of graph embedding methods entails\na truncation of information coming from pairs of nodes with low PMI. To\ncircumvent this issue, we propose an improved approach to learning low-rank\nfactorization embeddings that incorporate information from such unlikely pairs\nof nodes and show that it can improve the link prediction performance of\nbaseline methods from 1.2% to 24.2%. Based on our results and observations we\noutline further steps that could improve the design of next graph embedding\nalgorithms that are based on matrix factorizaion.",
          "link": "http://arxiv.org/abs/2011.09907",
          "publishedOn": "2022-04-11T00:52:29.060Z",
          "wordCount": 626,
          "title": "Neural graph embeddings via matrix factorization for link prediction: smoothing or truncating negatives?. (arXiv:2011.09907v2 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1\">Salah Zaiem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a>",
          "description": "Contrastive learning enables learning useful audio and speech representations\nwithout ground-truth labels by maximizing the similarity between latent\nrepresentations of similar signal segments. In this framework various data\naugmentation techniques are usually exploited to help enforce desired\ninvariances within the learned representations, improving performance on\nvarious audio tasks thanks to more robust embeddings. Now, selecting the most\nrelevant augmentations has proven crucial for better downstream performances.\nThus, this work introduces a conditional independance-based method which allows\nfor automatically selecting a suitable distribution on the choice of\naugmentations and their parametrization from a set of predefined ones, for\ncontrastive self-supervised pre-training. This is performed with respect to a\ndownstream task of interest, hence saving a costly hyper-parameter search.\nExperiments performed on two different downstream tasks validate the proposed\napproach showing better results than experimenting without augmentation or with\nbaseline augmentations. We furthermore conduct a qualitative analysis of the\nautomatically selected augmentations and their variation according to the\nconsidered final downstream dataset.",
          "link": "http://arxiv.org/abs/2204.04170",
          "publishedOn": "2022-04-11T00:52:29.052Z",
          "wordCount": 614,
          "title": "Automatic Data Augmentation Selection and Parametrization in Contrastive Self-Supervised Speech Representation Learning. (arXiv:2204.04170v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.05185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ross_A/0/1/0/all/0/1\">Andrew Slavin Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "In representation learning, there has been recent interest in developing\nalgorithms to disentangle the ground-truth generative factors behind a dataset,\nand metrics to quantify how fully this occurs. However, these algorithms and\nmetrics often assume that both representations and ground-truth factors are\nflat, continuous, and factorized, whereas many real-world generative processes\ninvolve rich hierarchical structure, mixtures of discrete and continuous\nvariables with dependence between them, and even varying intrinsic\ndimensionality. In this work, we develop benchmarks, algorithms, and metrics\nfor learning such hierarchical representations.",
          "link": "http://arxiv.org/abs/2102.05185",
          "publishedOn": "2022-04-11T00:52:29.045Z",
          "wordCount": 569,
          "title": "Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement. (arXiv:2102.05185v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.11397",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Duan_J/0/1/0/all/0/1\">Jingliang Duan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyu Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shengbo Eben Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_Q/0/1/0/all/0/1\">Qi Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_Z/0/1/0/all/0/1\">Zhenzhong Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>",
          "description": "This paper presents a constrained adaptive dynamic programming (CADP)\nalgorithm to solve general nonlinear nonaffine optimal control problems with\nknown dynamics. Unlike previous ADP algorithms, it can directly deal with\nproblems with state constraints. Firstly, a constrained generalized policy\niteration (CGPI) framework is developed to handle state constraints by\ntransforming the traditional policy improvement process into a constrained\npolicy optimization problem. Next, we propose an actor-critic variant of CGPI,\ncalled CADP, in which both policy and value functions are approximated by\nmulti-layer neural networks to directly map the system states to control inputs\nand value function, respectively. CADP linearizes the constrained optimization\nproblem locally into a quadratically constrained linear programming problem,\nand then obtains the optimal update of the policy network by solving its dual\nproblem. A trust region constraint is added to prevent excessive policy update,\nthus ensuring linearization accuracy. We determine the feasibility of the\npolicy optimization problem by calculating the minimum trust region boundary\nand update the policy using two recovery rules when infeasible. The vehicle\ncontrol problem in the path-tracking task is used to demonstrate the\neffectiveness of this proposed method.",
          "link": "http://arxiv.org/abs/1911.11397",
          "publishedOn": "2022-04-11T00:52:29.037Z",
          "wordCount": 692,
          "title": "Adaptive dynamic programming for nonaffine nonlinear optimal control problem with state constraints. (arXiv:1911.11397v3 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.09040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kensen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bieber_D/0/1/0/all/0/1\">David Bieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>",
          "description": "The success and popularity of deep learning is on the rise, partially due to\npowerful deep learning frameworks such as TensorFlow and PyTorch that make it\neasier to develop deep learning models. However, these libraries also come with\nsteep learning curves, since programming in these frameworks is quite different\nfrom traditional imperative programming with explicit loops and conditionals.\nIn this work, we present a tool called TF-Coder for programming by example in\nTensorFlow. TF-Coder uses a bottom-up weighted enumerative search, with\nvalue-based pruning of equivalent expressions and flexible type- and\nvalue-based filtering to ensure that expressions adhere to various requirements\nimposed by the TensorFlow library. We train models to predict TensorFlow\noperations from features of the input and output tensors and natural language\ndescriptions of tasks, to prioritize relevant operations during search.\nTF-Coder solves 63 of 70 real-world tasks within 5 minutes, sometimes finding\nsimpler solutions in less time compared to experienced human programmers.",
          "link": "http://arxiv.org/abs/2003.09040",
          "publishedOn": "2022-04-11T00:52:29.028Z",
          "wordCount": 664,
          "title": "TF-Coder: Program Synthesis for Tensor Manipulations. (arXiv:2003.09040v4 [cs.PL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04127",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kakoulidis_P/0/1/0/all/0/1\">Panos Kakoulidis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vamvoukakis_G/0/1/0/all/0/1\">Georgios Vamvoukakis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Markopoulos_K/0/1/0/all/0/1\">Konstantinos Markopoulos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>",
          "description": "Existing singing voice synthesis models (SVS) are usually trained on singing\ndata and depend on either error-prone time-alignment and duration features or\nexplicit music score information. In this paper, we propose Karaoker, a\nmultispeaker Tacotron-based model conditioned on voice characteristic features\nthat is trained exclusively on spoken data without requiring time-alignments.\nKaraoker synthesizes singing voice following a multi-dimensional template\nextracted from a source waveform of an unseen speaker/singer. The model is\njointly conditioned with a single deep convolutional encoder on continuous data\nincluding pitch, intensity, harmonicity, formants, cepstral peak prominence and\noctaves. We extend the text-to-speech training objective with feature\nreconstruction, classification and speaker identification tasks that guide the\nmodel to an accurate result. Except for multi-tasking, we also employ a\nWasserstein GAN training scheme as well as new losses on the acoustic model's\noutput to further refine the quality of the model.",
          "link": "http://arxiv.org/abs/2204.04127",
          "publishedOn": "2022-04-11T00:52:29.008Z",
          "wordCount": 598,
          "title": "Karaoker: Alignment-free singing voice synthesis with speech training data. (arXiv:2204.04127v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00464",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1\">Chris Junchi Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1\">Nicolas Loizou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We study the stochastic bilinear minimax optimization problem, presenting an\nanalysis of the same-sample Stochastic ExtraGradient (SEG) method with constant\nstep size, and presenting variations of the method that yield favorable\nconvergence. In sharp contrasts with the basic SEG method whose last iterate\nonly contracts to a fixed neighborhood of the Nash equilibrium, SEG augmented\nwith iteration averaging provably converges to the Nash equilibrium under the\nsame standard settings, and such a rate is further improved by incorporating a\nscheduled restarting procedure. In the interpolation setting where noise\nvanishes at the Nash equilibrium, we achieve an optimal convergence rate up to\ntight constants. We present numerical experiments that validate our theoretical\nfindings and demonstrate the effectiveness of the SEG method when equipped with\niteration averaging and restarting.",
          "link": "http://arxiv.org/abs/2107.00464",
          "publishedOn": "2022-04-11T00:52:28.995Z",
          "wordCount": 647,
          "title": "On the Convergence of Stochastic Extragradient for Bilinear Games using Restarted Iteration Averaging. (arXiv:2107.00464v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04054",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Blank_J/0/1/0/all/0/1\">Julian Blank</a>, <a href=\"http://arxiv.org/find/math/1/au:+Deb_K/0/1/0/all/0/1\">Kalyanmoy Deb</a>",
          "description": "Significant effort has been made to solve computationally expensive\noptimization problems in the past two decades, and various optimization methods\nincorporating surrogates into optimization have been proposed. Most research\nfocuses on either exploiting the surrogate by defining a utility optimization\nproblem or customizing an existing optimization method to use one or multiple\napproximation models. However, only a little attention has been paid to generic\nconcepts applicable to different types of algorithms and optimization problems\nsimultaneously. Thus this paper proposes a generalized probabilistic\nsurrogate-assisted framework (GPSAF), applicable to a broad category of\nunconstrained and constrained, single- and multi-objective optimization\nalgorithms. The idea is based on a surrogate assisting an existing optimization\nmethod. The assistance is based on two distinct phases, one facilitating\nexploration and another exploiting the surrogates. The exploration and\nexploitation of surrogates are automatically balanced by performing a\nprobabilistic knockout tournament among different clusters of solutions. A\nstudy of multiple well-known population-based optimization algorithms is\nconducted with and without the proposed surrogate assistance on single- and\nmulti-objective optimization problems with a maximum solution evaluation budget\nof 300 or less. The results indicate the effectiveness of applying GPSAF to an\noptimization algorithm and the competitiveness with other surrogate-assisted\nalgorithms.",
          "link": "http://arxiv.org/abs/2204.04054",
          "publishedOn": "2022-04-11T00:52:28.988Z",
          "wordCount": 645,
          "title": "GPSAF: A Generalized Probabilistic Surrogate-Assisted Framework for Constrained Single- and Multi-objective Optimization. (arXiv:2204.04054v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Araujo_P/0/1/0/all/0/1\">Pedro Henrique Luz de Araujo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1\">Benjamin Roth</a>",
          "description": "Behavioural testing -- verifying system capabilities by validating\nhuman-designed input-output pairs -- is an alternative evaluation method of\nnatural language processing systems proposed to address the shortcomings of the\nstandard approach: computing metrics on held-out data. While behavioural tests\ncapture human prior knowledge and insights, there has been little exploration\non how to leverage them for model training and development. With this in mind,\nwe explore behaviour-aware learning by examining several fine-tuning schemes\nusing HateCheck, a suite of functional tests for hate speech detection systems.\nTo address potential pitfalls of training on data originally intended for\nevaluation, we train and evaluate models on different configurations of\nHateCheck by holding out categories of test cases, which enables us to estimate\nperformance on potentially overlooked system properties. The fine-tuning\nprocedure led to improvements in the classification accuracy of held-out\nfunctionalities and identity groups, suggesting that models can potentially\ngeneralise to overlooked functionalities. However, performance on held-out\nfunctionality classes and i.i.d. hate speech detection data decreased, which\nindicates that generalisation occurs mostly across functionalities from the\nsame class and that the procedure led to overfitting to the HateCheck data\ndistribution.",
          "link": "http://arxiv.org/abs/2204.04042",
          "publishedOn": "2022-04-11T00:52:28.970Z",
          "wordCount": 643,
          "title": "Checking HateCheck: a cross-functional analysis of behaviour-aware learning for hate speech detection. (arXiv:2204.04042v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.00632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pauli_P/0/1/0/all/0/1\">Patricia Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funcke_N/0/1/0/all/0/1\">Niklas Funcke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gramlich_D/0/1/0/all/0/1\">Dennis Gramlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Msalmi_M/0/1/0/all/0/1\">Mohamed Amine Msalmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allgower_F/0/1/0/all/0/1\">Frank Allg&#xf6;wer</a>",
          "description": "This paper is concerned with the training of neural networks (NNs) under\nsemidefinite constraints, which allows for NN training with robustness and\nstability guarantees. In particular, we set up an efficient and scalable\ntraining scheme for NN training problems of this kind based on interior point\nmethods, while we also exploit the structure of the underlying matrix\nconstraint. We apply our training scheme to several relevant examples that have\nbeen studied in the literature and newly present the application of the method\nto the training of Wasserstein generative adversarial networks (WGANs). In\nnumerical examples, we show the superiority of our method and its applicability\nto WGAN training.",
          "link": "http://arxiv.org/abs/2201.00632",
          "publishedOn": "2022-04-11T00:52:28.958Z",
          "wordCount": null,
          "title": "Neural network training under semidefinite constraints. (arXiv:2201.00632v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.09962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pegoraro_M/0/1/0/all/0/1\">Marco Pegoraro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uysal_M/0/1/0/all/0/1\">Merih Seran Uysal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgi_D/0/1/0/all/0/1\">David Benedikt Georgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aalst_W/0/1/0/all/0/1\">Wil M.P. van der Aalst</a>",
          "description": "The real-time prediction of business processes using historical event data is\nan important capability of modern business process monitoring systems. Existing\nprocess prediction methods are able to also exploit the data perspective of\nrecorded events, in addition to the control-flow perspective. However, while\nwell-structured numerical or categorical attributes are considered in many\nprediction techniques, almost no technique is able to utilize text documents\nwritten in natural language, which can hold information critical to the\nprediction task. In this paper, we illustrate the design, implementation, and\nevaluation of a novel text-aware process prediction model based on Long\nShort-Term Memory (LSTM) neural networks and natural language models. The\nproposed model can take categorical, numerical and textual attributes in event\ndata into account to predict the activity and timestamp of the next event, the\noutcome, and the cycle time of a running process instance. Experiments show\nthat the text-aware model is able to outperform state-of-the-art process\nprediction methods on simulated and real-world event logs containing textual\ndata.",
          "link": "http://arxiv.org/abs/2104.09962",
          "publishedOn": "2022-04-11T00:52:28.957Z",
          "wordCount": null,
          "title": "Text-Aware Predictive Monitoring of Business Processes. (arXiv:2104.09962v2 [cs.AI] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_D/0/1/0/all/0/1\">Dmitry Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiselev_M/0/1/0/all/0/1\">Mikhail Kiselev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larionov_D/0/1/0/all/0/1\">Denis Larionov</a>",
          "description": "This article proposes a sparse computation-based method for optimizing neural\nnetworks for reinforcement learning (RL) tasks. This method combines two ideas:\nneural network pruning and taking into account input data correlations; it\nmakes it possible to update neuron states only when changes in them exceed a\ncertain threshold. It significantly reduces the number of multiplications when\nrunning neural networks. We tested different RL tasks and achieved 20-150x\nreduction in the number of multiplications. There were no substantial\nperformance losses; sometimes the performance even improved.",
          "link": "http://arxiv.org/abs/2201.02571",
          "publishedOn": "2022-04-11T00:52:28.956Z",
          "wordCount": null,
          "title": "Neural Network Optimization for Reinforcement Learning Tasks Using Sparse Computations. (arXiv:2201.02571v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaoling Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_M/0/1/0/all/0/1\">Mayank Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1\">Dimitris Metaxas</a>",
          "description": "The adversarial risk of a machine learning model has been widely studied.\nMost previous works assume that the data lies in the whole ambient space. We\npropose to take a new angle and take the manifold assumption into\nconsideration. Assuming data lies in a manifold, we investigate two new types\nof adversarial risk, the normal adversarial risk due to perturbation along\nnormal direction, and the in-manifold adversarial risk due to perturbation\nwithin the manifold. We prove that the classic adversarial risk can be bounded\nfrom both sides using the normal and in-manifold adversarial risks. We also\nshow with a surprisingly pessimistic case that the standard adversarial risk\ncan be nonzero even when both normal and in-manifold risks are zero. We\nfinalize the paper with empirical studies supporting our theoretical results.\nOur results suggest the possibility of improving the robustness of a classifier\nby only focusing on the normal adversarial risk.",
          "link": "http://arxiv.org/abs/2203.13277",
          "publishedOn": "2022-04-11T00:52:28.956Z",
          "wordCount": null,
          "title": "A Manifold View of Adversarial Risk. (arXiv:2203.13277v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.00604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rabadan_M/0/1/0/all/0/1\">Miquel Mart&#xed; i Rabad&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bujwid_S/0/1/0/all/0/1\">Sebastian Bujwid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pieropan_A/0/1/0/all/0/1\">Alessandro Pieropan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1\">Hossein Azizpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maki_A/0/1/0/all/0/1\">Atsuto Maki</a>",
          "description": "Most semi-supervised learning methods over-sample labeled data when\nconstructing training mini-batches. This paper studies whether this common\npractice improves learning and how. We compare it to an alternative setting\nwhere each mini-batch is uniformly sampled from all the training data, labeled\nor not, which greatly reduces direct supervision from true labels in typical\nlow-label regimes. However, this simpler setting can also be seen as more\ngeneral and even necessary in multi-task problems where over-sampling labeled\ndata would become intractable. Our experiments on semi-supervised CIFAR-10\nimage classification using FixMatch show a performance drop when using the\nuniform sampling approach which diminishes when the amount of labeled data or\nthe training time increases. Further, we analyse the training dynamics to\nunderstand how over-sampling of labeled data compares to uniform sampling. Our\nmain finding is that over-sampling is especially beneficial early in training\nbut gets less important in the later stages when more pseudo-labels become\ncorrect. Nevertheless, we also find that keeping some true labels remains\nimportant to avoid the accumulation of confirmation errors from incorrect\npseudo-labels.",
          "link": "http://arxiv.org/abs/2201.00604",
          "publishedOn": "2022-04-11T00:52:28.955Z",
          "wordCount": null,
          "title": "An analysis of over-sampling labeled data in semi-supervised learning with FixMatch. (arXiv:2201.00604v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigaud_O/0/1/0/all/0/1\">Olivier Sigaud</a>",
          "description": "Deep neuroevolution and deep Reinforcement Learning have received a lot of\nattention in the last years. Some works have compared them, highlighting theirs\npros and cons, but an emerging trend consists in combining them so as to\nbenefit from the best of both worlds. In this paper, we provide a survey of\nthis emerging trend by organizing the literature into related groups of works\nand casting all the existing combinations in each group into a generic\nframework. We systematically cover all easily available papers irrespective of\ntheir publication status, focusing on the combination mechanisms rather than on\nthe experimental results. In total, we cover 45 algorithms more recent than\n2017. We hope this effort will favor the growth of the domain by facilitating\nthe understanding of the relationships between the methods, leading to deeper\nanalyses, outlining missing useful comparisons and suggesting new combinations\nof mechanisms.",
          "link": "http://arxiv.org/abs/2203.14009",
          "publishedOn": "2022-04-11T00:52:28.954Z",
          "wordCount": null,
          "title": "Combining Evolution and Deep Reinforcement Learning for Policy Search: a Survey. (arXiv:2203.14009v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu-Rong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1\">Sheng Yen Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shan-Hung Wu</a>",
          "description": "The recent development of Generative adversarial networks (GANs) has driven\nmany computer vision applications. Despite the great synthesis quality,\ntraining GANs often confronts several issues, including non-convergence, mode\ncollapse, and gradient vanishing. There exist several workarounds, for example,\nregularizing Lipschitz continuity and adopting Wasserstein distance. Although\nthese methods can partially solve the problems, we argue that the problems are\nresult from modeling the discriminator with deep neural networks. In this\npaper, we base on newly derived deep neural network theories called Neural\nTangent Kernel (NTK) and propose a new generative algorithm called generative\nadversarial NTK (GA-NTK). The GA-NTK models the discriminator as a Gaussian\nProcess (GP). With the help of the NTK theories, the training dynamics of\nGA-NTK can be described with a closed-form formula. To synthesize data with the\nclosed-form formula, the objectives can be simplified into a single-level\nadversarial optimization problem. We conduct extensive experiments on\nreal-world datasets, and the results show that GA-NTK can generate images\ncomparable to those by GANs but is much easier to train under various\nconditions. We also study the current limitations of GA-NTK and propose some\nworkarounds to make GA-NTK more practical.",
          "link": "http://arxiv.org/abs/2204.04090",
          "publishedOn": "2022-04-11T00:52:28.943Z",
          "wordCount": 613,
          "title": "Generative Adversarial Method Based On Neural Tangent Kernels. (arXiv:2204.04090v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guangyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatti_N/0/1/0/all/0/1\">Nikolaj Tatti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gionis_A/0/1/0/all/0/1\">Aristides Gionis</a>",
          "description": "Submodular maximization has been the backbone of many important\nmachine-learning problems, and has applications to viral marketing,\ndiversification, sensor placement, and more. However, the study of maximizing\nsubmodular functions has mainly been restricted in the context of selecting a\nset of items. On the other hand, many real-world applications require a\nsolution that is a ranking over a set of items. The problem of ranking in the\ncontext of submodular function maximization has been considered before, but to\na much lesser extent than item-selection formulations. In this paper, we\nexplore a novel formulation for ranking items with submodular valuations and\nbudget constraints. We refer to this problem as max-submodular ranking (MSR).\nIn more detail, given a set of items and a set of non-decreasing submodular\nfunctions, where each function is associated with a budget, we aim to find a\nranking of the set of items that maximizes the sum of values achieved by all\nfunctions under the budget constraints. For the MSR problem with cardinality-\nand knapsack-type budget constraints we propose practical algorithms with\napproximation guarantees. In addition, we perform an empirical evaluation,\nwhich demonstrates the superior performance of the proposed algorithms against\nstrong baselines.",
          "link": "http://arxiv.org/abs/2204.04168",
          "publishedOn": "2022-04-11T00:52:28.935Z",
          "wordCount": 624,
          "title": "Ranking with submodular functions on a budget. (arXiv:2204.04168v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hong Jun Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Deep learning has proven effective across a range of data sets. In light of\nthis, a natural inquiry is: \"for what data generating processes can deep\nlearning succeed?\" In this work, we study the sample complexity of learning\nmultilayer data generating processes of a sort for which deep neural networks\nseem to be suited. We develop general and elegant information-theoretic tools\nthat accommodate analysis of any data generating process -- shallow or deep,\nparametric or nonparametric, noiseless or noisy. We then use these tools to\ncharacterize the dependence of sample complexity on the depth of multilayer\nprocesses. Our results indicate roughly linear dependence on depth. This is in\ncontrast to previous results that suggest exponential or high-order polynomial\ndependence.",
          "link": "http://arxiv.org/abs/2203.00246",
          "publishedOn": "2022-04-11T00:52:28.927Z",
          "wordCount": null,
          "title": "Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bagdasaryan_E/0/1/0/all/0/1\">Eugene Bagdasaryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmatikov_V/0/1/0/all/0/1\">Vitaly Shmatikov</a>",
          "description": "We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to \"spin\" their outputs so as to\nsupport an adversary-chosen sentiment or point of view -- but only when the\ninput contains adversary-chosen trigger words. For example, a spinned\nsummarization model outputs positive summaries of any text that mentions the\nname of some individual or organization.\n\nModel spinning introduces a \"meta-backdoor\" into a model. Whereas\nconventional backdoors cause models to produce incorrect outputs on inputs with\nthe trigger, outputs of spinned models preserve context and maintain standard\naccuracy metrics, yet also satisfy a meta-task chosen by the adversary.\n\nModel spinning enables propaganda-as-a-service, where propaganda is defined\nas biased speech. An adversary can create customized language models that\nproduce desired spins for chosen triggers, then deploy these models to generate\ndisinformation (a platform attack), or else inject them into ML training\npipelines (a supply-chain attack), transferring malicious functionality to\ndownstream models trained by victims.\n\nTo demonstrate the feasibility of model spinning, we develop a new\nbackdooring technique. It stacks an adversarial meta-task onto a seq2seq model,\nbackpropagates the desired meta-task output to points in the word-embedding\nspace we call \"pseudo-words,\" and uses pseudo-words to shift the entire output\ndistribution of the seq2seq model. We evaluate this attack on language\ngeneration, summarization, and translation models with different triggers and\nmeta-tasks such as sentiment, toxicity, and entailment. Spinned models largely\nmaintain their accuracy metrics (ROUGE and BLEU) while shifting their outputs\nto satisfy the adversary's meta-task. We also show that, in the case of a\nsupply-chain attack, the spin functionality transfers to downstream models.",
          "link": "http://arxiv.org/abs/2112.05224",
          "publishedOn": "2022-04-11T00:52:28.924Z",
          "wordCount": null,
          "title": "Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures. (arXiv:2112.05224v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.00734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1\">Xin Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>",
          "description": "There is a growing interest in applying machine learning techniques for\nhealthcare. Recently, federated machine learning (FL) is gaining popularity\nsince it allows researchers to train powerful models without compromising data\nprivacy and security. However, the performance of existing FL approaches often\ndeteriorates when encountering non-iid situations where there exist\ndistribution gaps among clients, and few previous efforts focus on\npersonalization in healthcare. In this article, we propose AdaFed to tackle\ndomain shifts and obtain personalized models for local clients. AdaFed learns\nthe similarity between clients via the statistics of the batch normalization\nlayers while preserving the specificity of each client with different local\nbatch normalization. Comprehensive experiments on five healthcare benchmarks\ndemonstrate that AdaFed achieves better accuracy compared to state-of-the-art\nmethods (e.g., \\textbf{10}\\%+ accuracy improvement for PAMAP2) with faster\nconvergence speed.",
          "link": "http://arxiv.org/abs/2112.00734",
          "publishedOn": "2022-04-11T00:52:28.917Z",
          "wordCount": null,
          "title": "Federated Learning with Adaptive Batchnorm for Personalized Healthcare. (arXiv:2112.00734v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.09120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_M/0/1/0/all/0/1\">Mohit Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1\">Sahil Modi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_R/0/1/0/all/0/1\">Rishabh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Saurabh Gupta</a>",
          "description": "Interactive object understanding, or what we can do to objects and how is a\nlong-standing goal of computer vision. In this paper, we tackle this problem\nthrough observation of human hands in in-the-wild egocentric videos. We\ndemonstrate that observation of what human hands interact with and how can\nprovide both the relevant data and the necessary supervision. Attending to\nhands, readily localizes and stabilizes active objects for learning and reveals\nplaces where interactions with objects occur. Analyzing the hands shows what we\ncan do to objects and how. We apply these basic principles on the EPIC-KITCHENS\ndataset, and successfully learn state-sensitive features, and object\naffordances (regions of interaction and afforded grasps), purely by observing\nhands in egocentric videos.",
          "link": "http://arxiv.org/abs/2112.09120",
          "publishedOn": "2022-04-11T00:52:28.917Z",
          "wordCount": null,
          "title": "Human Hands as Probes for Interactive Object Understanding. (arXiv:2112.09120v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Han_T/0/1/0/all/0/1\">Tianyu Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kather_J/0/1/0/all/0/1\">Jakob Nikolas Kather</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedersoli_F/0/1/0/all/0/1\">Federico Pedersoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zimmermann_M/0/1/0/all/0/1\">Markus Zimmermann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keil_S/0/1/0/all/0/1\">Sebastian Keil</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schulze_Hagen_M/0/1/0/all/0/1\">Maximilian Schulze-Hagen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Terwoelbeck_M/0/1/0/all/0/1\">Marc Terwoelbeck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Isfort_P/0/1/0/all/0/1\">Peter Isfort</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Haarburger_C/0/1/0/all/0/1\">Christoph Haarburger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiessling_F/0/1/0/all/0/1\">Fabian Kiessling</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schulz_V/0/1/0/all/0/1\">Volkmar Schulz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuhl_C/0/1/0/all/0/1\">Christiane Kuhl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nebelung_S/0/1/0/all/0/1\">Sven Nebelung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Truhn_D/0/1/0/all/0/1\">Daniel Truhn</a>",
          "description": "Disease-modifying management aims to prevent deterioration and progression of\nthe disease, not just relieve symptoms. Unfortunately, the development of\nnecessary therapies is often hampered by the failure to recognize the\npresymptomatic disease and limited understanding of disease development. We\npresent a generic solution for this problem by a methodology that allows the\nprediction of progression risk and morphology in individuals using a latent\nextrapolation optimization approach. To this end, we combined a regularized\ngenerative adversarial network (GAN) and a latent nearest neighbor algorithm\nfor joint optimization to generate plausible images of future time points. We\nevaluated our method on osteoarthritis (OA) data from a multi-center\nlongitudinal study (the Osteoarthritis Initiative, OAI). With presymptomatic\nbaseline data, our model is generative and significantly outperforms the\nend-to-end learning model in discriminating the progressive cohort. Two\nexperiments were performed with seven experienced radiologists. When no\nsynthetic follow-up radiographs were provided, our model performed better than\nall seven radiologists. In cases where the synthetic follow-ups generated by\nour model were available, the specificity and sensitivity of all readers in\ndiscriminating progressors increased from $72.3\\%$ to $88.6\\%$ and from\n$42.1\\%$ to $51.6\\%$, respectively. Our results open up a new possibility of\nusing model-based morphology and risk prediction to make predictions about\nfuture disease occurrence, as demonstrated in the example of OA.",
          "link": "http://arxiv.org/abs/2111.11439",
          "publishedOn": "2022-04-11T00:52:28.915Z",
          "wordCount": null,
          "title": "Image prediction of disease progression by style-based manifold extrapolation. (arXiv:2111.11439v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05267",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yuchen Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_N/0/1/0/all/0/1\">Nana Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chng_E/0/1/0/all/0/1\">Eng Siong Chng</a>",
          "description": "Speech enhancement (SE) aims to suppress the additive noise from a noisy\nspeech signal to improve the speech's perceptual quality and intelligibility.\nHowever, the over-suppression phenomenon in the enhanced speech might degrade\nthe performance of downstream automatic speech recognition (ASR) task due to\nthe missing latent information. To alleviate such problem, we propose an\ninteractive feature fusion network (IFF-Net) for noise-robust speech\nrecognition to learn complementary information from the enhanced feature and\noriginal noisy feature. Experimental results show that the proposed method\nachieves absolute word error rate (WER) reduction of 4.1% over the best\nbaseline on RATS Channel-A corpus. Our further analysis indicates that the\nproposed IFF-Net can complement some missing information in the over-suppressed\nenhanced feature.",
          "link": "http://arxiv.org/abs/2110.05267",
          "publishedOn": "2022-04-11T00:52:28.912Z",
          "wordCount": null,
          "title": "Interactive Feature Fusion for End-to-End Noise-Robust Speech Recognition. (arXiv:2110.05267v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.04888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Christopher Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1\">Taisuke Yasuda</a>",
          "description": "We study active sampling algorithms for linear regression, which aim to query\nonly a few entries of a target vector $b\\in\\mathbb R^n$ and output a near\nminimizer to $\\min_{x\\in\\mathbb R^d} \\|Ax-b\\|$, for a design matrix\n$A\\in\\mathbb R^{n \\times d}$ and loss $\\|\\cdot\\|$.\n\nFor $p$ norm regression for any $0<p<\\infty$, we give an algorithm based on\nLewis weight sampling outputting a $(1+\\epsilon)$-approximate solution using\njust $\\tilde O(d/\\epsilon^2)$ queries to $b$ for $p\\in(0,1)$,\n$\\tilde{O}(d/\\epsilon)$ queries for $1<p<2$, and\n$\\tilde{O}(d^{p/2}/\\epsilon^p)$ queries for $2<p<\\infty$. For $0<p<2$, our\nbounds are optimal up to log factors, settling the query complexity for this\nrange. For $2<p<\\infty$, our dependence on $d$ is optimal, while our dependence\non $\\epsilon$ is off by at most $\\epsilon$, up to log factors. Our result\nresolves an open question of [CD21], who gave near optimal bounds for the $1$\nnorm, but required $d^2/\\epsilon^2$ samples for $\\ell_p$ regression with\n$1<p<2$, and gave no bounds for $2<p<\\infty$ or $0<p<1$.\n\nWe also give the first total sensitivity bound of\n$O(d^{\\max\\{1,p/2\\}}\\log^2n)$ for loss functions of degree $p$ polynomial\ngrowth, improving a result of [TMF20]. By combining this with our techniques\nfor $\\ell_p$ regression, we obtain an active regression algorithm making\n$\\tilde O(d^{1+\\max\\{1,p/2\\}}/\\mathrm{poly}(\\epsilon))$ queries for such loss\nfunctions, including the Tukey and Huber losses, answering another question of\n[CD21]. For the Huber loss, we further improve our bound to $\\tilde\nO(d^{4-2\\sqrt2}/\\mathrm{poly}(\\epsilon))$ samples. Our sensitivity bounds also\nhave many applications, including Orlicz norm subspace embeddings, robust\nsubspace approximation, and dimension reduction for smoothed $p$-norms.\n\nFinally, our active sampling results give the first sublinear time algorithms\nfor Kronecker product regression under every $p$ norm.",
          "link": "http://arxiv.org/abs/2111.04888",
          "publishedOn": "2022-04-11T00:52:28.908Z",
          "wordCount": null,
          "title": "Active Linear Regression for $\\ell_p$ Norms and Beyond. (arXiv:2111.04888v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1\">Gaurav Kumar Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawal_R/0/1/0/all/0/1\">Ruchit Rawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1\">Anirban Chakraborty</a>",
          "description": "Deep models are highly susceptible to adversarial attacks. Such attacks are\ncarefully crafted imperceptible noises that can fool the network and can cause\nsevere consequences when deployed. To encounter them, the model requires\ntraining data for adversarial training or explicit regularization-based\ntechniques. However, privacy has become an important concern, restricting\naccess to only trained models but not the training data (e.g. biometric data).\nAlso, data curation is expensive and companies may have proprietary rights over\nit. To handle such situations, we propose a completely novel problem of\n'test-time adversarial defense in absence of training data and even their\nstatistics'. We solve it in two stages: a) detection and b) correction of\nadversarial samples. Our adversarial sample detection framework is initially\ntrained on arbitrary data and is subsequently adapted to the unlabelled test\ndata through unsupervised domain adaptation. We further correct the predictions\non detected adversarial samples by transforming them in Fourier domain and\nobtaining their low frequency component at our proposed suitable radius for\nmodel prediction. We demonstrate the efficacy of our proposed technique via\nextensive experiments against several adversarial attacks and for different\nmodel architectures and datasets. For a non-robust Resnet-18 model pre-trained\non CIFAR-10, our detection method correctly identifies 91.42% adversaries.\nAlso, we significantly improve the adversarial accuracy from 0% to 37.37% with\na minimal drop of 0.02% in clean accuracy on state-of-the-art 'Auto Attack'\nwithout having to retrain the model.",
          "link": "http://arxiv.org/abs/2204.01568",
          "publishedOn": "2022-04-11T00:52:28.908Z",
          "wordCount": null,
          "title": "DAD: Data-free Adversarial Defense at Test Time. (arXiv:2204.01568v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sichen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1\">Jeffrey Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>",
          "description": "Disentangled representation learning offers useful properties such as\ndimension reduction and interpretability, which are essential to modern deep\nlearning approaches. Although deep learning techniques have been widely applied\nto spatio-temporal data mining, there has been little attention to further\ndisentangle the latent features and understanding their contribution to the\nmodel performance, particularly their mutual information and correlation across\nfeatures. In this study, we adopt two state-of-the-art disentangled\nrepresentation learning methods and apply them to three large-scale public\nspatio-temporal datasets. To evaluate their performance, we propose an internal\nevaluation metric focusing on the degree of correlations among latent variables\nof the learned representations and the prediction performance of the downstream\ntasks. Empirical results show that our modified method can learn disentangled\nrepresentations that achieve the same level of performance as existing\nstate-of-the-art ST deep learning methods in a spatio-temporal sequence\nforecasting problem. Additionally, we find that our methods can be used to\ndiscover real-world spatial-temporal semantics to describe the variables in the\nlearned representation.",
          "link": "http://arxiv.org/abs/2202.04821",
          "publishedOn": "2022-04-11T00:52:28.906Z",
          "wordCount": null,
          "title": "Measuring disentangled generative spatio-temporal representation. (arXiv:2202.04821v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "The noise transition matrix plays a central role in the problem of learning\nfrom noisy labels. Among many other reasons, a significant number of existing\nsolutions rely on access to it. Estimating the transition matrix without using\nground truth labels is a critical and challenging task. When label noise\ntransition depends on each instance, the problem of identifying the\ninstance-dependent noise transition matrix becomes substantially more\nchallenging. Despite recent works proposing solutions for learning from\ninstance-dependent noisy labels, we lack a unified understanding of when such a\nproblem remains identifiable, and therefore learnable. This paper seeks to\nprovide answers to a sequence of related questions: What are the primary\nfactors that contribute to the identifiability of a noise transition matrix?\nCan we explain the observed empirical successes? When a problem is not\nidentifiable, what can we do to make it so? We will relate our theoretical\nfindings to the literature and hope to provide guidelines for developing\neffective solutions for battling instance-dependent label noise.",
          "link": "http://arxiv.org/abs/2202.02016",
          "publishedOn": "2022-04-11T00:52:28.905Z",
          "wordCount": null,
          "title": "Identifiability of Label Noise Transition Matrix. (arXiv:2202.02016v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.12505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_D/0/1/0/all/0/1\">Dong Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenguang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gang Wang</a>",
          "description": "Ride-hailing service is becoming a leading part in urban transportation. To\nimprove the efficiency of ride-hailing service, accurate prediction of\ntransportation demand is a fundamental challenge. In this paper, we tackle this\nproblem from both aspects of network structure and data-set formulation. For\nnetwork design, we propose a spatial-temporal attention multi-graph convolution\nnetwork (STA-MGCN). A spatial-temporal layer in STA-MGCN is developed to\ncapture the temporal correlations by temporal attention mechanism and temporal\ngate convolution, and the spatial correlations by multigraph convolution. A\nfeature cluster layer is introduced to learn latent regional functions and to\nreduce the computation burden. For the data-set formulation, we develop a novel\napproach which considers the transportation feature of periodicity with offset.\nInstead of only using history data during the same time period, the history\norder demand in forward and backward neighboring time periods from yesterday\nand last week are also included. Extensive experiments on the three real-world\ndatasets of New-York, Chicago and Chengdu show that the proposed algorithm\nachieves the state-of-the-art performance for ride-hailing demand prediction.",
          "link": "http://arxiv.org/abs/2203.12505",
          "publishedOn": "2022-04-11T00:52:28.905Z",
          "wordCount": null,
          "title": "A Spatial-Temporal Attention Multi-Graph Convolution Network for Ride-Hailing Demand Prediction Based on Periodicity with Offset. (arXiv:2203.12505v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.13005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Siddharth Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatele_A/0/1/0/all/0/1\">Abhinav Bhatele</a>",
          "description": "In the last few years, the memory requirements to train state-of-the-art\nneural networks have far exceeded the DRAM capacities of modern hardware\naccelerators. This has necessitated the development of efficient algorithms to\ntrain these neural networks in parallel on large-scale GPU-based clusters.\nSince computation is relatively inexpensive on modern GPUs, designing and\nimplementing extremely efficient communication in these parallel training\nalgorithms is critical for extracting the maximum performance. This paper\npresents AxoNN, a parallel deep learning framework that exploits asynchrony and\nmessage-driven execution to schedule neural network operations on each GPU,\nthereby reducing GPU idle time and maximizing hardware efficiency. By using the\nCPU memory as a scratch space for offloading data periodically during training,\nAxoNN is able to reduce GPU memory consumption by four times. This allows us to\nincrease the number of parameters per GPU by four times, thus reducing the\namount of communication and increasing performance by over 13%. When tested\nagainst large transformer models with 12-100 billion parameters on 48-384\nNVIDIA Tesla V100 GPUs, AxoNN achieves a per-GPU throughput of 49.4-54.78% of\ntheoretical peak and reduces the training time by 22-37 days (15-25% speedup)\nas compared to the state-of-the-art.",
          "link": "http://arxiv.org/abs/2110.13005",
          "publishedOn": "2022-04-11T00:52:28.892Z",
          "wordCount": null,
          "title": "AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning. (arXiv:2110.13005v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.11732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1\">Ruoxuan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koenecke_A/0/1/0/all/0/1\">Allison Koenecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powell_M/0/1/0/all/0/1\">Michael Powell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Analyzing observational data from multiple sources can be useful for\nincreasing statistical power to detect a treatment effect; however, practical\nconstraints such as privacy considerations may restrict individual-level\ninformation sharing across data sets. This paper develops federated methods\nthat only utilize summary-level information from heterogeneous data sets. Our\nfederated methods provide doubly-robust point estimates of treatment effects as\nwell as variance estimates. We derive the asymptotic distributions of our\nfederated estimators, which are shown to be asymptotically equivalent to the\ncorresponding estimators from the combined, individual-level data. We show that\nto achieve these properties, federated methods should be adjusted based on\nconditions such as whether models are correctly specified and stable across\nheterogeneous data sets.",
          "link": "http://arxiv.org/abs/2107.11732",
          "publishedOn": "2022-04-11T00:52:28.882Z",
          "wordCount": null,
          "title": "Federated Causal Inference in Heterogeneous Observational Data. (arXiv:2107.11732v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.06329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gerhard_Young_G/0/1/0/all/0/1\">Greyson Gerhard-Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anantha_R/0/1/0/all/0/1\">Raviteja Anantha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chappidi_S/0/1/0/all/0/1\">Srinivas Chappidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmeister_B/0/1/0/all/0/1\">Bj&#xf6;rn Hoffmeister</a>",
          "description": "Recent work building open-domain chatbots has demonstrated that increasing\nmodel size improves performance. On the other hand, latency and connectivity\nconsiderations dictate the move of digital assistants on the device. Giving a\ndigital assistant like Siri, Alexa, or Google Assistant the ability to discuss\njust about anything leads to the need for reducing the chatbot model size such\nthat it fits on the user's device. We demonstrate that low parameter models can\nsimultaneously retain their general knowledge conversational abilities while\nimproving in a specific domain. Additionally, we propose a generic framework\nthat accounts for variety in question types, tracks reference throughout\nmulti-turn conversations, and removes inconsistent and potentially toxic\nresponses. Our framework seamlessly transitions between chatting and performing\ntransactional tasks, which will ultimately make interactions with digital\nassistants more human-like. We evaluate our framework on 1 internal and 4\npublic benchmark datasets using both automatic (Perplexity) and human (SSA -\nSensibleness and Specificity Average) evaluation metrics and establish\ncomparable performance while reducing model parameters by 90%.",
          "link": "http://arxiv.org/abs/2108.06329",
          "publishedOn": "2022-04-11T00:52:28.881Z",
          "wordCount": null,
          "title": "Low-Resource Adaptation of Open-Domain Generative Chatbots. (arXiv:2108.06329v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.04298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sowmen Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md. Saiful Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1\">Md. Ruhul Amin</a>",
          "description": "Forensic analysis of manipulated pixels requires the identification of\nvarious hidden and subtle features from images. Conventional image recognition\nmodels generally fail at this task because they are biased and more attentive\ntoward the dominant local and spatial features. In this paper, we propose a\nnovel Gated Context Attention Network (GCA-Net) that utilizes non-local\nattention in conjunction with a gating mechanism in order to capture the finer\nimage discrepancies and better identify forged regions. The proposed framework\nuses high dimensional embeddings to filter and aggregate the relevant context\nfrom coarse feature maps at various stages of the decoding process. This\nimproves the network's understanding of global differences and reduces\nfalse-positive localizations. Our evaluation on standard image forensic\nbenchmarks shows that GCA-Net can both compete against and improve over\nstate-of-the-art networks by an average of 4.7% AUC. Additional ablation\nstudies also demonstrate the method's robustness against attributions and\nresilience to false-positive predictions.",
          "link": "http://arxiv.org/abs/2112.04298",
          "publishedOn": "2022-04-11T00:52:28.881Z",
          "wordCount": null,
          "title": "GCA-Net : Utilizing Gated Context Attention for Improving Image Forgery Localization and Detection. (arXiv:2112.04298v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.03097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1\">Cuiling Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1\">Yidong Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>",
          "description": "Machine learning systems generally assume that the training and testing\ndistributions are the same. To this end, a key requirement is to develop models\nthat can generalize to unseen distributions. Domain generalization (DG), i.e.,\nout-of-distribution generalization, has attracted increasing interests in\nrecent years. Domain generalization deals with a challenging setting where one\nor several different but related domain(s) are given, and the goal is to learn\na model that can generalize to an unseen test domain. Great progress has been\nmade in the area of domain generalization for years. This paper presents the\nfirst review of recent advances in this area. First, we provide a formal\ndefinition of domain generalization and discuss several related fields. We then\nthoroughly review the theories related to domain generalization and carefully\nanalyze the theory behind generalization. We categorize recent algorithms into\nthree classes: data manipulation, representation learning, and learning\nstrategy, and present several popular algorithms in detail for each category.\nThird, we introduce the commonly used datasets, applications, and our\nopen-sourced codebase for fair evaluation. Finally, we summarize existing\nliterature and present some potential research topics for the future.",
          "link": "http://arxiv.org/abs/2103.03097",
          "publishedOn": "2022-04-11T00:52:28.873Z",
          "wordCount": null,
          "title": "Generalizing to Unseen Domains: A Survey on Domain Generalization. (arXiv:2103.03097v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.09151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiuniu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wenjia Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingzhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Antoni B. Chan</a>",
          "description": "Describing images using natural language is widely known as image captioning,\nwhich has made consistent progress due to the development of computer vision\nand natural language generation techniques. Though conventional captioning\nmodels achieve high accuracy based on popular metrics, i.e., BLEU, CIDEr, and\nSPICE, the ability of captions to distinguish the target image from other\nsimilar images is under-explored. To generate distinctive captions, a few\npioneers employ contrastive learning or re-weighted the ground-truth captions,\nwhich focuses on one single input image. However, the relationships between\nobjects in a similar image group (e.g., items or properties within the same\nalbum or fine-grained events) are neglected. In this paper, we improve the\ndistinctiveness of image captions using a Group-based Distinctive Captioning\nModel (GdisCap), which compares each image with other images in one similar\ngroup and highlights the uniqueness of each image. In particular, we propose a\ngroup-based memory attention (GMA) module, which stores object features that\nare unique among the image group (i.e., with low similarity to objects in other\nimages). These unique object features are highlighted when generating captions,\nresulting in more distinctive captions. Furthermore, the distinctive words in\nthe ground-truth captions are selected to supervise the language decoder and\nGMA. Finally, we propose a new evaluation metric, distinctive word rate\n(DisWordRate) to measure the distinctiveness of captions. Quantitative results\nindicate that the proposed method significantly improves the distinctiveness of\nseveral baseline models, and achieves the state-of-the-art performance on both\naccuracy and distinctiveness. Results of a user study agree with the\nquantitative evaluation and demonstrate the rationality of the new metric\nDisWordRate.",
          "link": "http://arxiv.org/abs/2108.09151",
          "publishedOn": "2022-04-11T00:52:28.873Z",
          "wordCount": null,
          "title": "Group-based Distinctive Image Captioning with Memory Attention. (arXiv:2108.09151v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00594",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1\">Salah Zaiem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heba_A/0/1/0/all/0/1\">Abdel Heba</a>",
          "description": "Through solving pretext tasks, self-supervised learning leverages unlabeled\ndata to extract useful latent representations replacing traditional input\nfeatures in the downstream task. In audio/speech signal processing, a wide\nrange of features where engineered through decades of research efforts. As it\nturns out, learning to predict such features (a.k.a pseudo-labels) has proven\nto be a particularly relevant pretext task, leading to useful self-supervised\nrepresentations which prove to be effective for downstream tasks. However,\nmethods and common practices for combining such pretext tasks for better\nperformance on the downstream task have not been explored and understood\nproperly. In fact, the process relies almost exclusively on a computationally\nheavy experimental procedure, which becomes intractable with the increase of\nthe number of pretext tasks. This paper introduces a method to select a group\nof pretext tasks among a set of candidates. The method we propose estimates\ncalibrated weights for the partial losses corresponding to the considered\npretext tasks during the self-supervised training process. The experiments\nconducted on automatic speech recognition, speaker and emotion recognition\nvalidate our approach, as the groups selected and weighted with our method\nperform better than classic baselines, thus facilitating the selection and\ncombination of relevant pseudo-labels for self-supervised representation\nlearning.",
          "link": "http://arxiv.org/abs/2107.00594",
          "publishedOn": "2022-04-11T00:52:28.872Z",
          "wordCount": null,
          "title": "Pretext Tasks selection for multitask self-supervised speech representation learning. (arXiv:2107.00594v4 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07510",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhangjie Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jinghan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>",
          "description": "Learning a generalizable deep model from a few examples in a short time\nremains a major challenge of machine learning, which has impeded its wide\ndeployment to many scenarios. Recent advances reveal that a properly\npre-trained model endows an important property: transferability. A higher\ntransferability of the learned representations indicates a better\ngeneralizability across domains of different distributions (domain\ntransferability), or across tasks of different semantics (task\ntransferability). Transferability has become the key to enable data-efficient\ndeep learning, however, existing pre-training methods focus only on domain\ntransferability while meta-training methods only on task transferability. This\nrestricts their data-efficiency in downstream scenarios of diverging domains\nand tasks. A finding of this paper is that even a tight combination of\npre-training and meta-training cannot achieve both kinds of transferability.\nThis motivates the proposed Omni-Training framework towards data-efficient deep\nlearning. Our first contribution is Omni-Net, a tri-flow architecture. Besides\nthe joint representation flow, Omni-Net introduces two new parallel flows for\npre-training and meta-training, respectively responsible for learning\nrepresentations of domain transferability and task transferability. Omni-Net\ncoordinates the parallel flows by routing them via the joint-flow, making each\ngain the other kind of transferability. Our second contribution is Omni-Loss,\nin which a self-distillation regularization is imposed to enable knowledge\ntransfer across the training process. Omni-Training is a general framework that\naccommodates many existing pre-training and meta-training algorithms. A\nthorough evaluation on cross-task and cross-domain datasets in classification,\nregression and reinforcement learning problems shows that Omni-Training\nconsistently outperforms the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2110.07510",
          "publishedOn": "2022-04-11T00:52:28.872Z",
          "wordCount": null,
          "title": "Omni-Training for Data-Efficient Deep Learning. (arXiv:2110.07510v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.09003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianyuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiangyu Zhu</a>",
          "description": "We study the problem of safe offline reinforcement learning (RL), the goal is\nto learn a policy that maximizes long-term reward while satisfying safety\nconstraints given only offline data, without further interaction with the\nenvironment. This problem is more appealing for real world RL applications, in\nwhich data collection is costly or dangerous. Enforcing constraint satisfaction\nis non-trivial, especially in offline settings, as there is a potential large\ndiscrepancy between the policy distribution and the data distribution, causing\nerrors in estimating the value of safety constraints. We show that na\\\"ive\napproaches that combine techniques from safe RL and offline RL can only learn\nsub-optimal solutions. We thus develop a simple yet effective algorithm,\nConstraints Penalized Q-Learning (CPQ), to solve the problem. Our method admits\nthe use of data generated by mixed behavior policies. We present a theoretical\nanalysis and demonstrate empirically that our approach can learn robustly\nacross a variety of benchmark control tasks, outperforming several baselines.",
          "link": "http://arxiv.org/abs/2107.09003",
          "publishedOn": "2022-04-11T00:52:28.871Z",
          "wordCount": null,
          "title": "Constraints Penalized Q-learning for Safe Offline Reinforcement Learning. (arXiv:2107.09003v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.08463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cioba_A/0/1/0/all/0/1\">Alexandru Cioba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bromberg_M/0/1/0/all/0/1\">Michael Bromberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niyogi_R/0/1/0/all/0/1\">Ritwik Niyogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1\">Georgios Batzolis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1\">Jezabel Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernacchia_A/0/1/0/all/0/1\">Alberto Bernacchia</a>",
          "description": "Meta-learning models transfer the knowledge acquired from previous tasks to\nquickly learn new ones. They are trained on benchmarks with a fixed number of\ndata points per task. This number is usually arbitrary and it is unknown how it\naffects performance at testing. Since labelling of data is expensive, finding\nthe optimal allocation of labels across training tasks may reduce costs. Given\na fixed budget of labels, should we use a small number of highly labelled\ntasks, or many tasks with few labels each? Should we allocate more labels to\nsome tasks and less to others? We show that: 1) If tasks are homogeneous, there\nis a uniform optimal allocation, whereby all tasks get the same amount of data;\n2) At fixed budget, there is a trade-off between number of tasks and number of\ndata points per task, with a unique solution for the optimum; 3) When trained\nseparately, harder task should get more data, at the cost of a smaller number\nof tasks; 4) When training on a mixture of easy and hard tasks, more data\nshould be allocated to easy tasks. Interestingly, Neuroscience experiments have\nshown that human visual skills also transfer better from easy tasks. We prove\nthese results mathematically on mixed linear regression, and we show\nempirically that the same results hold for few-shot image classification on\nCIFAR-FS and mini-ImageNet. Our results provide guidance for allocating labels\nacross tasks when collecting data for meta-learning.",
          "link": "http://arxiv.org/abs/2103.08463",
          "publishedOn": "2022-04-11T00:52:28.781Z",
          "wordCount": null,
          "title": "How to distribute data across tasks for meta-learning?. (arXiv:2103.08463v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04017",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Mensa_S/0/1/0/all/0/1\">Stefano Mensa</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sahin_E/0/1/0/all/0/1\">Emre Sahin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1\">Francesco Tacchino</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Barkoutsos_P/0/1/0/all/0/1\">Panagiotis Kl. Barkoutsos</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tavernelli_I/0/1/0/all/0/1\">Ivano Tavernelli</a>",
          "description": "Machine Learning (ML) for Ligand Based Virtual Screening (LB-VS) is an\nimportant in-silico tool for discovering new drugs in a faster and\ncost-effective manner, especially for emerging diseases such as COVID-19. In\nthis paper, we propose a general-purpose framework combining a classical\nSupport Vector Classifier (SVC) algorithm with quantum kernel estimation for\nLB-VS on real-world databases, and we argue in favor of its prospective quantum\nadvantage. Indeed, we heuristically prove that our quantum integrated workflow\ncan, at least in some relevant instances, provide a tangible advantage compared\nto state-of-art classical algorithms operating on the same datasets, showing\nstrong dependence on target and features selection method. Finally, we test our\nalgorithm on IBM Quantum processors using ADRB2 and COVID-19 datasets, showing\nthat hardware simulations provide results in line with the predicted\nperformances and can surpass classical equivalents.",
          "link": "http://arxiv.org/abs/2204.04017",
          "publishedOn": "2022-04-11T00:52:28.779Z",
          "wordCount": null,
          "title": "Quantum Machine Learning Framework for Virtual Screening in Drug Discovery: a Prospective Quantum Advantage. (arXiv:2204.04017v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenqian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shangbin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zilong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1\">Zhenyu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Minnan Luo</a>",
          "description": "Political perspective detection has become an increasingly important task\nthat can help combat echo chambers and political polarization. Previous\napproaches generally focus on leveraging textual content to identify stances,\nwhile they fail to reason with background knowledge or leverage the rich\nsemantic and syntactic textual labels in news articles. In light of these\nlimitations, we propose KCD, a political perspective detection approach to\nenable multi-hop knowledge reasoning and incorporate textual cues as\nparagraph-level labels. Specifically, we firstly generate random walks on\nexternal knowledge graphs and infuse them with news text representations. We\nthen construct a heterogeneous information network to jointly model news\ncontent as well as semantic, syntactic and entity cues in news articles.\nFinally, we adopt relational graph neural networks for graph-level\nrepresentation learning and conduct political perspective detection. Extensive\nexperiments demonstrate that our approach outperforms state-of-the-art methods\non two benchmark datasets. We further examine the effect of knowledge walks and\ntextual cues and how they contribute to our approach's data efficiency.",
          "link": "http://arxiv.org/abs/2204.04046",
          "publishedOn": "2022-04-11T00:52:28.778Z",
          "wordCount": null,
          "title": "KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media. (arXiv:2204.04046v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_D/0/1/0/all/0/1\">Deqing Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiuju Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiao Feng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanbing Zhang</a>",
          "description": "Given the trend of digitization and increasing number of maritime transport,\nprediction of vessel berth stay has been triggered for requirements of\noperation research and scheduling optimization problem in the era of maritime\nbig data, which takes a significant part in port efficiency and maritime\nlogistics enhancement. This study proposes a systematic and dynamic approach of\npredicting berth stay for tanker terminals. The approach covers three\ninnovative aspects: 1) Data source employed is multi-faceted, including cargo\noperation data from tanker terminals, time-series data from automatic\nidentification system (AIS), etc. 2) The process of berth stay is decomposed\ninto multiple blocks according to data analysis and information extraction\ninnovatively, and practical operation scenarios are also developed accordingly.\n3) The predictive models of berth stay are developed on the basis of prior data\nanalysis and information extraction under two methods, including regression and\ndecomposed distribution. The models are evaluated under four dynamic scenarios\nwith certain designated cargoes among two different terminals. The evaluation\nresults show that the proposed approach can predict berth stay with the\naccuracy up to 98.81% validated by historical baselines, and also demonstrate\nthe proposed approach has dynamic capability of predicting berth stay among the\nscenarios. The model may be potentially applied for short-term pilot-booking or\nscheduling optimizations within a reasonable time frame for advancement of port\nintelligence and logistics efficiency.",
          "link": "http://arxiv.org/abs/2204.04085",
          "publishedOn": "2022-04-11T00:52:28.778Z",
          "wordCount": null,
          "title": "Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qilong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1\">Shibei Xue</a>",
          "description": "Federated learning protects data privacy and security by exchanging models\ninstead of data. However, unbalanced data distributions among participating\nclients compromise the accuracy and convergence speed of federated learning\nalgorithms. To alleviate this problem, unlike previous studies that limit the\ndistance of updates for local models, we propose global-update-guided federated\nlearning (FedGG), which introduces a model-cosine loss into local objective\nfunctions, so that local models can fit local data distributions under the\nguidance of update directions of global models. Furthermore, considering that\nthe update direction of a global model is informative in the early stage of\ntraining, we propose adaptive loss weights based on the update distances of\nlocal models. Numerical simulations show that, compared with other advanced\nalgorithms, FedGG has a significant improvement on model convergence accuracies\nand speeds. Additionally, compared with traditional fixed loss weights,\nadaptive loss weights enable our algorithm to be more stable and easier to\nimplement in practice.",
          "link": "http://arxiv.org/abs/2204.03920",
          "publishedOn": "2022-04-11T00:52:28.774Z",
          "wordCount": null,
          "title": "Global Update Guided Federated Learning. (arXiv:2204.03920v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Portisch_J/0/1/0/all/0/1\">Jan Portisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_G/0/1/0/all/0/1\">Guilherme Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefani_K/0/1/0/all/0/1\">Karolin Stefani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreplin_K/0/1/0/all/0/1\">Katharina Kreplin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hladik_M/0/1/0/all/0/1\">Michael Hladik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1\">Heiko Paulheim</a>",
          "description": "Ontology matching is a core task when creating interoperable and linked open\ndatasets. In this paper, we explore a novel structure-based mapping approach\nwhich is based on knowledge graph embeddings: The ontologies to be matched are\nembedded, and an approach known as absolute orientation is used to align the\ntwo embedding spaces. Next to the approach, the paper presents a first,\npreliminary evaluation using synthetic and real-world datasets. We find in\nexperiments with synthetic data, that the approach works very well on similarly\nstructured graphs; it handles alignment noise better than size and structural\ndifferences in the ontologies.",
          "link": "http://arxiv.org/abs/2204.04040",
          "publishedOn": "2022-04-11T00:52:28.770Z",
          "wordCount": null,
          "title": "Ontology Matching Through Absolute Orientation of Embedding Spaces. (arXiv:2204.04040v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dissen_Y/0/1/0/all/0/1\">Yehoshua Dissen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>",
          "description": "Over the last few years, deep learning has grown in popularity for speaker\nverification, identification, and diarization. Inarguably, a significant part\nof this success is due to the demonstrated effectiveness of their speaker\nrepresentations. These, however, are heavily dependent on large amounts of\nannotated data and can be sensitive to new domains. This study proposes an\nentirely unsupervised deep-learning model for speaker diarization.\nSpecifically, the study focuses on generating high-quality neural speaker\nrepresentations without any annotated data, as well as on estimating secondary\nhyperparameters of the model without annotations.\n\nThe speaker embeddings are represented by an encoder trained in a\nself-supervised fashion using pairs of adjacent segments assumed to be of the\nsame speaker. The trained encoder model is then used to self-generate\npseudo-labels to subsequently train a similarity score between different\nsegments of the same call using probabilistic linear discriminant analysis\n(PLDA) and further to learn a clustering stopping threshold. We compared our\nmodel to state-of-the-art unsupervised as well as supervised baselines on the\nCallHome benchmarks. According to empirical results, our approach outperforms\nunsupervised methods when only two speakers are present in the call, and is\nonly slightly worse than recent supervised models.",
          "link": "http://arxiv.org/abs/2204.04166",
          "publishedOn": "2022-04-11T00:52:28.770Z",
          "wordCount": null,
          "title": "Self-supervised Speaker Diarization. (arXiv:2204.04166v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yukai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiaro_R/0/1/0/all/0/1\">Roberta Chiaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poncino_M/0/1/0/all/0/1\">Massimo Poncino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliari_D/0/1/0/all/0/1\">Daniele Jahier Pagliari</a>",
          "description": "Collaborative Inference (CI) optimizes the latency and energy consumption of\ndeep learning inference through the inter-operation of edge and cloud devices.\nAlbeit beneficial for other tasks, CI has never been applied to the sequence-\nto-sequence mapping problem at the heart of Neural Machine Translation (NMT).\nIn this work, we address the specific issues of collaborative NMT, such as\nestimating the latency required to generate the (unknown) output sequence, and\nshow how existing CI methods can be adapted to these applications. Our\nexperiments show that CI can reduce the latency of NMT by up to 44% compared to\na non-collaborative approach.",
          "link": "http://arxiv.org/abs/2204.04043",
          "publishedOn": "2022-04-11T00:52:28.767Z",
          "wordCount": null,
          "title": "C-NMT: A Collaborative Inference Framework for Neural Machine Translation. (arXiv:2204.04043v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuhao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Saizhuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shouling Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuhong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenguang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alex X. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyah_R/0/1/0/all/0/1\">Raheem Beyah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Ting Wang</a>",
          "description": "One intriguing property of adversarial attacks is their \"transferability\" --\nan adversarial example crafted with respect to one deep neural network (DNN)\nmodel is often found effective against other DNNs as well. Intensive research\nhas been conducted on this phenomenon under simplistic controlled conditions.\nYet, thus far, there is still a lack of comprehensive understanding about\ntransferability-based attacks (\"transfer attacks\") in real-world environments.\n\nTo bridge this critical gap, we conduct the first large-scale systematic\nempirical study of transfer attacks against major cloud-based MLaaS platforms,\ntaking the components of a real transfer attack into account. The study leads\nto a number of interesting findings which are inconsistent to the existing\nones, including: (1) Simple surrogates do not necessarily improve real transfer\nattacks. (2) No dominant surrogate architecture is found in real transfer\nattacks. (3) It is the gap between posterior (output of the softmax layer)\nrather than the gap between logit (so-called $\\kappa$ value) that increases\ntransferability. Moreover, by comparing with prior works, we demonstrate that\ntransfer attacks possess many previously unknown properties in real-world\nenvironments, such as (1) Model similarity is not a well-defined concept. (2)\n$L_2$ norm of perturbation can generate high transferability without usage of\ngradient and is a more powerful source than $L_\\infty$ norm. We believe this\nwork sheds light on the vulnerabilities of popular MLaaS platforms and points\nto a few promising research directions.",
          "link": "http://arxiv.org/abs/2204.04063",
          "publishedOn": "2022-04-11T00:52:28.767Z",
          "wordCount": null,
          "title": "Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings. (arXiv:2204.04063v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maurya_V/0/1/0/all/0/1\">Vikas Maurya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1\">Rachit Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Saurabh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1\">Sandeep Kumar Shukla</a>",
          "description": "Due to the importance of Critical Infrastructure (CI) in a nation's economy,\nthey have been lucrative targets for cyber attackers. These critical\ninfrastructures are usually Cyber-Physical Systems (CPS) such as power grids,\nwater, and sewage treatment facilities, oil and gas pipelines, etc. In recent\ntimes, these systems have suffered from cyber attacks numerous times.\nResearchers have been developing cyber security solutions for CIs to avoid\nlasting damages. According to standard frameworks, cyber security based on\nidentification, protection, detection, response, and recovery are at the core\nof these research. Detection of an ongoing attack that escapes standard\nprotection such as firewall, anti-virus, and host/network intrusion detection\nhas gained importance as such attacks eventually affect the physical dynamics\nof the system. Therefore, anomaly detection in physical dynamics proves an\neffective means to implement defense-in-depth. PASAD is one example of anomaly\ndetection in the sensor/actuator data, representing such systems' physical\ndynamics. We present EPASAD, which improves the detection technique used in\nPASAD to detect these micro-stealthy attacks, as our experiments show that\nPASAD's spherical boundary-based detection fails to detect. Our method EPASAD\novercomes this by using Ellipsoid boundaries, thereby tightening the boundaries\nin various dimensions, whereas a spherical boundary treats all dimensions\nequally. We validate EPASAD using the dataset produced by the TE-process\nsimulator and the C-town datasets. The results show that EPASAD improves\nPASAD's average recall by 5.8% and 9.5% for the two datasets, respectively.",
          "link": "http://arxiv.org/abs/2204.04154",
          "publishedOn": "2022-04-11T00:52:28.734Z",
          "wordCount": null,
          "title": "EPASAD: Ellipsoid decision boundary based Process-Aware Stealthy Attack Detector. (arXiv:2204.04154v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_D/0/1/0/all/0/1\">Deqing Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiuju Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiao Feng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanbing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Ning Li</a>",
          "description": "In this study, a novel coordinative scheduling optimization approach is\nproposed to enhance port efficiency by reducing weighted average turnaround\ntime. The proposed approach is developed as a heuristic algorithm applied and\ninvestigated through different observation windows with weekly rolling horizon\nparadigm method. The experimental results show that the proposed approach is\neffective and promising on mitigating the turnaround time of vessels. The\nresults demonstrate that largest potential savings of turnaround time (weighted\naverage) are around 17 hours (28%) reduction on baseline of 1-week observation,\n45 hours (37%) reduction on baseline of 2-week observation and 70 hours (40%)\nreduction on baseline of 3-week observation. Even though the experimental\nresults are based on historical datasets, the results potentially present\nsignificant benefits if real-time applications were applied under a quadratic\ncomputational complexity.",
          "link": "http://arxiv.org/abs/2204.03955",
          "publishedOn": "2022-04-11T00:52:28.710Z",
          "wordCount": null,
          "title": "Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 2. (arXiv:2204.03955v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuejun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1\">Qiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordy_M/0/1/0/all/0/1\">Maxime Cordy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xiaofei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadakis_M/0/1/0/all/0/1\">Mike Papadakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Traon_Y/0/1/0/all/0/1\">Yves Le Traon</a>",
          "description": "Various deep neural networks (DNNs) are developed and reported for their\ntremendous success in multiple domains. Given a specific task, developers can\ncollect massive DNNs from public sources for efficient reusing and avoid\nredundant work from scratch. However, testing the performance (e.g., accuracy\nand robustness) of multiple DNNs and giving a reasonable recommendation that\nwhich model should be used is challenging regarding the scarcity of labeled\ndata and demand of domain expertise. Existing testing approaches are mainly\nselection-based where after sampling, a few of the test data are labeled to\ndiscriminate DNNs. Therefore, due to the randomness of sampling, the\nperformance ranking is not deterministic. In this paper, we propose a\nlabeling-free comparison testing approach to overcome the limitations of\nlabeling effort and sampling randomness. The main idea is to learn a Bayesian\nmodel to infer the models' specialty only based on predicted labels. To\nevaluate the effectiveness of our approach, we undertook exhaustive experiments\non 9 benchmark datasets spanning in the domains of image, text, and source\ncode, and 165 DNNs. In addition to accuracy, we consider the robustness against\nsynthetic and natural distribution shifts. The experimental results demonstrate\nthat the performance of existing approaches degrades under distribution shifts.\nOur approach outperforms the baseline methods by up to 0.74 and 0.53 on\nSpearman's correlation and Kendall's $\\tau$, respectively, regardless of the\ndataset and distribution shift. Additionally, we investigated the impact of\nmodel quality (accuracy and robustness) and diversity (standard deviation of\nthe quality) on the testing effectiveness and observe that there is a higher\nchance of a good result when the quality is over 50\\% and the diversity is\nlarger than 18\\%.",
          "link": "http://arxiv.org/abs/2204.03994",
          "publishedOn": "2022-04-11T00:52:28.681Z",
          "wordCount": 711,
          "title": "Labeling-Free Comparison Testing of Deep Learning Models. (arXiv:2204.03994v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melzi_P/0/1/0/all/0/1\">Pietro Melzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1\">Ruben Tolosana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1\">Ruben Vera-Rodriguez</a>",
          "description": "Electrocardiograms (ECGs) have shown unique patterns to distinguish between\ndifferent subjects and present important advantages compared to other biometric\ntraits, such as difficulty to counterfeit, liveness detection, and ubiquity.\nAlso, with the success of Deep Learning technologies, ECG biometric recognition\nhas received increasing interest in recent years. However, it is not easy to\nevaluate the improvements of novel ECG proposed methods, mainly due to the lack\nof public data and standard experimental protocols. In this study, we perform\nextensive analysis and comparison of different scenarios in ECG biometric\nrecognition. Both verification and identification tasks are investigated, as\nwell as single- and multi-session scenarios. Finally, we also perform single-\nand multi-lead ECG experiments, considering traditional scenarios using\nelectrodes in the chest and limbs and current user-friendly wearable devices.\n\nIn addition, we present ECGXtractor, a robust Deep Learning technology\ntrained with an in-house large-scale database and able to operate successfully\nacross various scenarios and multiple databases. We introduce our proposed\nfeature extractor, trained with multiple sinus-rhythm heartbeats belonging to\n55,967 subjects, and provide a general public benchmark evaluation with\ndetailed experimental protocol. We evaluate the system performance over four\ndifferent databases: i) our in-house database, ii) PTB, iii) ECG-ID, and iv)\nCYBHi. With the widely used PTB database, we achieve Equal Error Rates of 0.14%\nand 2.06% in verification, and accuracies of 100% and 96.46% in identification,\nrespectively in single- and multi-session analysis. We release the source code,\nexperimental protocol details, and pre-trained models in GitHub to advance in\nthe field.",
          "link": "http://arxiv.org/abs/2204.03992",
          "publishedOn": "2022-04-11T00:52:28.658Z",
          "wordCount": 681,
          "title": "ECG Biometric Recognition: Review, System Proposal, and Benchmark Evaluation. (arXiv:2204.03992v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamada_Y/0/1/0/all/0/1\">Yutaro Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otani_M/0/1/0/all/0/1\">Mayu Otani</a>",
          "description": "As clean ImageNet accuracy nears its ceiling, the research community is\nincreasingly more concerned about robust accuracy under distributional shifts.\nWhile a variety of methods have been proposed to robustify neural networks,\nthese techniques often target models trained on ImageNet classification. At the\nsame time, it is a common practice to use ImageNet pretrained backbones for\ndownstream tasks such as object detection, semantic segmentation, and image\nclassification from different domains. This raises a question: Can these robust\nimage classifiers transfer robustness to downstream tasks? For object detection\nand semantic segmentation, we find that a vanilla Swin Transformer, a variant\nof Vision Transformer tailored for dense prediction tasks, transfers robustness\nbetter than Convolutional Neural Networks that are trained to be robust to the\ncorrupted version of ImageNet. For CIFAR10 classification, we find that models\nthat are robustified for ImageNet do not retain robustness when fully\nfine-tuned. These findings suggest that current robustification techniques tend\nto emphasize ImageNet evaluations. Moreover, network architecture is a strong\nsource of robustness when we consider transfer learning.",
          "link": "http://arxiv.org/abs/2204.03934",
          "publishedOn": "2022-04-11T00:52:28.647Z",
          "wordCount": 604,
          "title": "Does Robustness on ImageNet Transfer to Downstream Tasks?. (arXiv:2204.03934v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_N/0/1/0/all/0/1\">Narges Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azmi_R/0/1/0/all/0/1\">Reza Azmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moghadam_S/0/1/0/all/0/1\">Sara Saberi Tehrani Moghadam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zarvani_M/0/1/0/all/0/1\">Maral Zarvani</a>",
          "description": "Fashion is now among the largest industries worldwide, for it represents\nhuman history and helps tell the worlds story. As a result of the Fourth\nIndustrial Revolution, the Internet has become an increasingly important source\nof fashion information. However, with a growing number of web pages and social\ndata, it is nearly impossible for humans to manually catch up with the ongoing\nevolution and the continuously variable content in this domain. The proper\nmanagement and exploitation of big data can pave the way for the substantial\ngrowth of the global economy as well as citizen satisfaction. Therefore,\ncomputer scientists have found it challenging to handle e-commerce fashion\nwebsites by using big data and machine learning technologies. This paper first\nproposes a scalable focused Web Crawler engine based on the distributed\ncomputing platforms to extract and process fashion data on e-commerce websites.\nThe role of the proposed platform is then described in developing a\ndisentangled feature extraction method by employing deep convolutional\ngenerative adversarial networks (DCGANs) for content-based image indexing and\nretrieval. Finally, the state-of-the-art solutions are compared, and the\nresults of the proposed approach are analyzed on a standard dataset. For the\nreal-life implementation of the proposed solution, a Web-based application is\ndeveloped on Apache Storm, Kafka, Solr, and Milvus platforms to create a\nfashion search engine called SnapMode.",
          "link": "http://arxiv.org/abs/2204.03998",
          "publishedOn": "2022-04-11T00:52:28.640Z",
          "wordCount": 689,
          "title": "SnapMode: An Intelligent and Distributed Large-Scale Fashion Image Retrieval Platform Based On Big Data and Deep Generative Adversarial Network Technologies. (arXiv:2204.03998v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ijaz Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seokjoo Shin</a>",
          "description": "The traditional communication model based on chain of multiple independent\nprocessing blocks is constraint to efficiency and introduces artificial\nbarriers. Thus, each individually optimized block does not guarantee end-to-end\nperformance of the system. Recently, end-to-end learning of communications\nsystems through machine learning (ML) have been proposed to optimize the system\nmetrics jointly over all components. These methods show performance\nimprovements but has a limitation that it requires a differentiable channel\nmodel. In this study, we have summarized the existing approaches that\nalleviates this problem. We believe that this study will provide better\nunderstanding of the topic and an insight into future research in this field.",
          "link": "http://arxiv.org/abs/2204.03944",
          "publishedOn": "2022-04-11T00:52:28.632Z",
          "wordCount": 547,
          "title": "Channel model for end-to-end learning of communications systems: A survey. (arXiv:2204.03944v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bulatovic_N/0/1/0/all/0/1\">Nikola Bulatovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djukanovic_S/0/1/0/all/0/1\">Slobodan Djukanovic</a>",
          "description": "The paper addresses acoustic vehicle detection and speed estimation from\nsingle sensor measurements. We predict the vehicle's pass-by instant by\nminimizing clipped vehicle-to-microphone distance, which is predicted from the\nmel-spectrogram of input audio, in a supervised learning approach. In addition,\nmel-spectrogram-based features are used directly for vehicle speed estimation,\nwithout introducing any intermediate features. The results show that the\nproposed features can be used for accurate vehicle detection and speed\nestimation, with an average error of 7.87 km/h. If we formulate speed\nestimation as a classification problem, with a 10 km/h discretization interval,\nthe proposed method attains the average accuracy of 48.7% for correct class\nprediction and 91.0% when an offset of one class is allowed. The proposed\nmethod is evaluated on a dataset of 304 urban-environment on-field recordings\nof ten different vehicles.",
          "link": "http://arxiv.org/abs/2204.04013",
          "publishedOn": "2022-04-11T00:52:28.625Z",
          "wordCount": 588,
          "title": "Mel-spectrogram features for acoustic vehicle detection and speed estimation. (arXiv:2204.04013v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golowich_N/0/1/0/all/0/1\">Noah Golowich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>",
          "description": "We show that computing approximate stationary Markov coarse correlated\nequilibria (CCE) in general-sum stochastic games is computationally\nintractable, even when there are two players, the game is turn-based, the\ndiscount factor is an absolute constant, and the approximation is an absolute\nconstant. Our intractability results stand in sharp contrast to normal-form\ngames where exact CCEs are efficiently computable. A fortiori, our results\nimply that there are no efficient algorithms for learning stationary Markov CCE\npolicies in multi-agent reinforcement learning (MARL), even when the\ninteraction is two-player and turn-based, and both the discount factor and the\ndesired approximation of the learned policies is an absolute constant. In turn,\nthese results stand in sharp contrast to single-agent reinforcement learning\n(RL) where near-optimal stationary Markov policies can be efficiently learned.\nComplementing our intractability results for stationary Markov CCEs, we provide\na decentralized algorithm (assuming shared randomness among players) for\nlearning a nonstationary Markov CCE policy with polynomial time and sample\ncomplexity in all problem parameters. Previous work for learning Markov CCE\npolicies all required exponential time and sample complexity in the number of\nplayers.",
          "link": "http://arxiv.org/abs/2204.03991",
          "publishedOn": "2022-04-11T00:52:28.606Z",
          "wordCount": 614,
          "title": "The Complexity of Markov Equilibrium in Stochastic Games. (arXiv:2204.03991v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahanor_I/0/1/0/all/0/1\">Izuwa Ahanor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medal_H/0/1/0/all/0/1\">Hugh Medal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trapp_A/0/1/0/all/0/1\">Andrew C. Trapp</a>",
          "description": "While most methods for solving mixed-integer optimization problems seek a\nsingle optimal solution, finding a diverse set of near-optimal solutions can\noften be more useful. State of the art methods for generating diverse\nnear-optimal solutions usually take a two-phase approach, first finding a set\nof near-optimal solutions and then finding a diverse subset. In contrast, we\npresent a method of finding a set of diverse solutions by emphasizing diversity\nwithin the search for near-optimal solutions. Specifically, within a\nbranch-and-bound framework, we investigate parameterized node selection rules\nthat explicitly consider diversity. Our results indicate that our approach\nsignificantly increases diversity of the final solution set. When compared with\nexisting methods for finding diverse near-optimal sets, our method runs with\nsimilar run-time as regular node selection methods and gives a diversity\nimprovement of up to 140%. In contrast, popular node selection rules such as\nbest-first search gives an improvement of no more than 40%. Further, we find\nthat our method is most effective when diversity is emphasized more in node\nselection when deeper in the tree and when the solution set has grown large\nenough.",
          "link": "http://arxiv.org/abs/2204.03822",
          "publishedOn": "2022-04-11T00:52:28.599Z",
          "wordCount": 637,
          "title": "DiversiTree: Computing Diverse Sets of Near-Optimal Solutions to Mixed-Integer Optimization Problems. (arXiv:2204.03822v1 [cs.DM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_D/0/1/0/all/0/1\">Deqing Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiuju Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiao Feng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanbing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Ning Li</a>",
          "description": "In this study, a novel coordinative scheduling optimization approach is\nproposed to enhance port efficiency by reducing average wait time and\nturnaround time. The proposed approach consists of enhanced particle swarm\noptimization (ePSO) as kernel and augmented firefly algorithm (AFA) as global\noptimal search. Two paradigm methods of the proposed approach are investigated,\nwhich are batch method and rolling horizon method. The experimental results\nshow that both paradigm methods of proposed approach can effectively enhance\nport efficiency. The average wait time could be significantly reduced by 86.0%\n- 95.5%, and the average turnaround time could eventually save 38.2% - 42.4%\nwith respect to historical benchmarks. Moreover, the paradigm method of rolling\nhorizon could reduce to 20 mins on running time over 3-month datasets, rather\nthan 4 hrs on batch method at corresponding maximum performance.",
          "link": "http://arxiv.org/abs/2204.03899",
          "publishedOn": "2022-04-11T00:52:28.591Z",
          "wordCount": null,
          "title": "Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 1. (arXiv:2204.03899v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liew_S/0/1/0/all/0/1\">Seng Pei Liew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_T/0/1/0/all/0/1\">Tsubasa Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takagi_S/0/1/0/all/0/1\">Shun Takagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kato_F/0/1/0/all/0/1\">Fumiyuki Kato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_M/0/1/0/all/0/1\">Masatoshi Yoshikawa</a>",
          "description": "Recently, it is shown that shuffling can amplify the central differential\nprivacy guarantees of data randomized with local differential privacy. Within\nthis setup, a centralized, trusted shuffler is responsible for shuffling by\nkeeping the identities of data anonymous, which subsequently leads to stronger\nprivacy guarantees for systems. However, introducing a centralized entity to\nthe originally local privacy model loses some appeals of not having any\ncentralized entity as in local differential privacy. Moreover, implementing a\nshuffler in a reliable way is not trivial due to known security issues and/or\nrequirements of advanced hardware or secure computation technology.\n\nMotivated by these practical considerations, we rethink the shuffle model to\nrelax the assumption of requiring a centralized, trusted shuffler. We introduce\nnetwork shuffling, a decentralized mechanism where users exchange data in a\nrandom-walk fashion on a network/graph, as an alternative of achieving privacy\namplification via anonymity. We analyze the threat model under such a setting,\nand propose distributed protocols of network shuffling that is straightforward\nto implement in practice. Furthermore, we show that the privacy amplification\nrate is similar to other privacy amplification techniques such as uniform\nshuffling. To our best knowledge, among the recently studied intermediate trust\nmodels that leverage privacy amplification techniques, our work is the first\nthat is not relying on any centralized entity to achieve privacy amplification.",
          "link": "http://arxiv.org/abs/2204.03919",
          "publishedOn": "2022-04-11T00:52:28.590Z",
          "wordCount": 663,
          "title": "Network Shuffling: Privacy Amplification via Random Walks. (arXiv:2204.03919v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faundez_Zanuy_M/0/1/0/all/0/1\">Marcos Faundez-Zanuy</a>",
          "description": "This Paper studies different committees of neural networks for biometric\npattern recognition. We use the neural nets as classifiers for identification\nand verification purposes. We show that a committee of nets can improve the\nrecognition rates when compared with a multi-start initialization algo-rithm\nthat just picks up the neural net which offers the best performance. On the\nother hand, we found that there is no strong correlation between\nidentifi-cation and verification applications using the same classifier.",
          "link": "http://arxiv.org/abs/2204.03935",
          "publishedOn": "2022-04-11T00:52:28.583Z",
          "wordCount": 562,
          "title": "Study of a committee of neural networks for biometric hand-geometry recognition. (arXiv:2204.03935v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Subhrajit Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mincu_D/0/1/0/all/0/1\">Diana Mincu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proleev_L/0/1/0/all/0/1\">Lev Proleev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostamzadeh_N/0/1/0/all/0/1\">Negar Rostamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghate_C/0/1/0/all/0/1\">Chintan Ghate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harris_N/0/1/0/all/0/1\">Natalie Harris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Christina Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schrouff_J/0/1/0/all/0/1\">Jessica Schrouff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomasev_N/0/1/0/all/0/1\">Nenad Tomasev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartsell_F/0/1/0/all/0/1\">Fletcher Lee Hartsell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1\">Katherine Heller</a>",
          "description": "Literature on machine learning for multiple sclerosis has primarily focused\non the use of neuroimaging data such as magnetic resonance imaging and clinical\nlaboratory tests for disease identification. However, studies have shown that\nthese modalities are not consistent with disease activity such as symptoms or\ndisease progression. Furthermore, the cost of collecting data from these\nmodalities is high, leading to scarce evaluations. In this work, we used\nmulti-dimensional, affordable, physical and smartphone-based performance\noutcome measures (POM) in conjunction with demographic data to predict multiple\nsclerosis disease progression. We performed a rigorous benchmarking exercise on\ntwo datasets and present results across 13 clinically actionable prediction\nendpoints and 6 machine learning models. To the best of our knowledge, our\nresults are the first to show that it is possible to predict disease\nprogression using POMs and demographic data in the context of both clinical\ntrials and smartphone-base studies by using two datasets. Moreover, we\ninvestigate our models to understand the impact of different POMs and\ndemographics on model performance through feature ablation studies. We also\nshow that model performance is similar across different demographic subgroups\n(based on age and sex). To enable this work, we developed an end-to-end\nreusable pre-processing and machine learning framework which allows quicker\nexperimentation over disparate MS datasets.",
          "link": "http://arxiv.org/abs/2204.03969",
          "publishedOn": "2022-04-11T00:52:28.574Z",
          "wordCount": 656,
          "title": "Disability prediction in multiple sclerosis using performance outcome measures and demographic data. (arXiv:2204.03969v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Md Faisal Mahbub Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_M/0/1/0/all/0/1\">Michael Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1\">Gaetano Rossiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1\">Nandana Mihindukulasooriya</a>",
          "description": "In a recent work, we presented a novel state-of-the-art approach to zero-shot\nslot filling that extends dense passage retrieval with hard negatives and\nrobust training procedures for retrieval augmented generation models. In this\npaper, we propose a system based on an enhanced version of this approach where\nwe train task specific models for other knowledge intensive language tasks,\nsuch as open domain question answering (QA), dialogue and fact checking. Our\nsystem achieves results comparable to the best models in the KILT leaderboards.\nMoreover, given a user query, we show how the output from these different\nmodels can be combined to cross-examine each other. Particularly, we show how\naccuracy in dialogue can be improved using the QA model. A short video\ndemonstrating the system is available here -\n\\url{https://ibm.box.com/v/kgi-interactive-demo} .",
          "link": "http://arxiv.org/abs/2204.03985",
          "publishedOn": "2022-04-11T00:52:28.556Z",
          "wordCount": 572,
          "title": "KGI: An Integrated Framework for Knowledge Intensive Language Tasks. (arXiv:2204.03985v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Seongwook Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaehyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1\">Heejeong Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sull_S/0/1/0/all/0/1\">Sanghoon Sull</a>",
          "description": "Due to the cost or interference of measurement, we need to control\nmeasurement system. Assuming that each variable can be measured sequentially,\nthere exists optimal policy choosing next measurement for the former\nobservations. Though optimal measurement policy is actually dependent on the\ngoal of measurement, we mainly focus on retrieving complete data, so called as\nimputation. Also, we adapt the imputation method to missingness varying with\nmeasurement policy. However, learning measurement policy and imputation\nrequires complete data which is impossible to be observed, unfortunately. To\ntackle this problem, we propose a data generation method and joint learning\nalgorithm. The main idea is that 1) the data generation method is inherited by\nimputation method, and 2) the adaptation of imputation encourages measurement\npolicy to learn more than individual learning. We implemented some variations\nof proposed algorithm for two different datasets and various missing rates.\nFrom the experimental results, we demonstrate that our algorithm is generally\napplicable and outperforms baseline methods.",
          "link": "http://arxiv.org/abs/2204.03872",
          "publishedOn": "2022-04-11T00:52:28.548Z",
          "wordCount": 595,
          "title": "Controllable Missingness from Uncontrollable Missingness: Joint Learning Measurement Policy and Imputation. (arXiv:2204.03872v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yiqing Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lequan Yu</a>",
          "description": "Federated learning (FL) is a distributed learning paradigm that enables\nmultiple clients to collaboratively learn a shared global model. Despite the\nrecent progress, it remains challenging to deal with heterogeneous data\nclients, as the discrepant data distributions usually prevent the global model\nfrom delivering good generalization ability on each participating client. In\nthis paper, we propose CD^2-pFed, a novel Cyclic Distillation-guided Channel\nDecoupling framework, to personalize the global model in FL, under various\nsettings of data heterogeneity. Different from previous works which establish\nlayer-wise personalization to overcome the non-IID data across different\nclients, we make the first attempt at channel-wise assignment for model\npersonalization, referred to as channel decoupling. To further facilitate the\ncollaboration between private and shared weights, we propose a novel cyclic\ndistillation scheme to impose a consistent regularization between the local and\nglobal model representations during the federation. Guided by the cyclical\ndistillation, our channel decoupling framework can deliver more accurate and\ngeneralized results for different kinds of heterogeneity, such as feature skew,\nlabel distribution skew, and concept shift. Comprehensive experiments on four\nbenchmarks, including natural image and medical image analysis tasks,\ndemonstrate the consistent effectiveness of our method on both local and\nexternal validations.",
          "link": "http://arxiv.org/abs/2204.03880",
          "publishedOn": "2022-04-11T00:52:28.541Z",
          "wordCount": 640,
          "title": "CD$^2$-pFed: Cyclic Distillation-guided Channel Decoupling for Model Personalization in Federated Learning. (arXiv:2204.03880v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04016",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Weise_T/0/1/0/all/0/1\">Tobias Weise</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klumpp_P/0/1/0/all/0/1\">Philipp Klumpp</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Noeth_E/0/1/0/all/0/1\">Elmar Noeth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heismann_B/0/1/0/all/0/1\">Bjoern Heismann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schuster_M/0/1/0/all/0/1\">Maria Schuster</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1\">Seung Hee Yang</a>",
          "description": "Speech intelligibility assessment plays an important role in the therapy of\npatients suffering from pathological speech disorders. Automatic and objective\nmeasures are desirable to assist therapists in their traditionally subjective\nand labor-intensive assessments. In this work, we investigate a novel approach\nfor obtaining such a measure using the divergence in disentangled latent speech\nrepresentations of a parallel utterance pair, obtained from a healthy reference\nand a pathological speaker. Experiments on an English database of Cerebral\nPalsy patients, using all available utterances per speaker, show high and\nsignificant correlation values (R = -0.9) with subjective intelligibility\nmeasures, while having only minimal deviation (+-0.01) across four different\nreference speaker pairs. We also demonstrate the robustness of the proposed\nmethod (R = -0.89 deviating +-0.02 over 1000 iterations) by considering a\nsignificantly smaller amount of utterances per speaker. Our results are among\nthe first to show that disentangled speech representations can be used for\nautomatic pathological speech intelligibility assessment, resulting in a\nreference speaker pair invariant method, applicable in scenarios with only few\nutterances available.",
          "link": "http://arxiv.org/abs/2204.04016",
          "publishedOn": "2022-04-11T00:52:28.534Z",
          "wordCount": 633,
          "title": "Disentangled Latent Speech Representation for Automatic Pathological Intelligibility Assessment. (arXiv:2204.04016v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03812",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Cheung_K/0/1/0/all/0/1\">Kingman Cheung</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Chung_Y/0/1/0/all/0/1\">Yi-Lun Chung</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Hsu_S/0/1/0/all/0/1\">Shih-Chieh Hsu</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Nachman_B/0/1/0/all/0/1\">Benjamin Nachman</a>",
          "description": "The modeling of jet substructure significantly differs between Parton Shower\nMonte Carlo (PSMC) programs. Despite this, we observe that machine learning\nclassifiers trained on different PSMCs learn nearly the same function. This\nmeans that when these classifiers are applied to the same PSMC for testing,\nthey result in nearly the same performance. This classifier universality\nindicates that a machine learning model trained on one simulation and tested on\nanother simulation (or data) will likely be optimal. Our observations are based\non detailed studies of shallow and deep neural networks applied to simulated\nLorentz boosted Higgs jet tagging at the LHC.",
          "link": "http://arxiv.org/abs/2204.03812",
          "publishedOn": "2022-04-11T00:52:28.526Z",
          "wordCount": 544,
          "title": "Exploring the Universality of Hadronic Jet Classification. (arXiv:2204.03812v1 [hep-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1\">Stephen Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taehyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>",
          "description": "Deep Neural Networks (DNN) have made significant progress in a wide range of\nvisual recognition tasks such as image classification, object detection, and\nsemantic segmentation. The evolution of convolutional architectures has led to\nbetter performance by incurring expensive computational costs. In addition,\nnetwork design has become a difficult task, which is labor-intensive and\nrequires a high level of domain knowledge. To mitigate such issues, there have\nbeen studies for a variety of neural architecture search methods that\nautomatically search for optimal architectures, achieving models with\nimpressive performance that outperform human-designed counterparts. This survey\naims to provide an overview of existing works in this field of research and\nspecifically focus on the supernet optimization that builds a neural network\nthat assembles all the architectures as its sub models by using weight sharing.\nWe aim to accomplish that by categorizing supernet optimization by proposing\nthem as solutions to the common challenges found in the literature: data-side\noptimization, poor rank correlation alleviation, and transferable NAS for a\nnumber of deployment scenarios.",
          "link": "http://arxiv.org/abs/2204.03916",
          "publishedOn": "2022-04-11T00:52:28.509Z",
          "wordCount": 601,
          "title": "SuperNet in Neural Architecture Search: A Taxonomic Survey. (arXiv:2204.03916v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1\">Rajat Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_D/0/1/0/all/0/1\">Debojyoti Dutta</a>",
          "description": "Training action space selection for reinforcement learning (RL) is\nconflict-prone due to complex state-action relationships. To address this\nchallenge, this paper proposes a Shapley-inspired methodology for training\naction space categorization and ranking. To reduce exponential-time shapley\ncomputations, the methodology includes a Monte Carlo simulation to avoid\nunnecessary explorations. The effectiveness of the methodology is illustrated\nusing a cloud infrastructure resource tuning case study. It reduces the search\nspace by 80\\% and categorizes the training action sets into dispensable and\nindispensable groups. Additionally, it ranks different training actions to\nfacilitate high-performance yet cost-efficient RL model design. The proposed\ndata-driven methodology is extensible to different domains, use cases, and\nreinforcement learning algorithms.",
          "link": "http://arxiv.org/abs/2204.03840",
          "publishedOn": "2022-04-11T00:52:28.500Z",
          "wordCount": 535,
          "title": "Data-Driven Evaluation of Training Action Space for Reinforcement Learning. (arXiv:2204.03840v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Copur_O/0/1/0/all/0/1\">Onur Copur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakip_M/0/1/0/all/0/1\">Mert Nak&#x131;p</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1\">Simone Scardapane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slowack_J/0/1/0/all/0/1\">J&#xfc;rgen Slowack</a>",
          "description": "Recognition of user interaction, in particular engagement detection, became\nhighly crucial for online working and learning environments, especially during\nthe COVID-19 outbreak. Such recognition and detection systems significantly\nimprove the user experience and efficiency by providing valuable feedback. In\nthis paper, we propose a novel Engagement Detection with Multi-Task Training\n(ED-MTT) system which minimizes mean squared error and triplet loss together to\ndetermine the engagement level of students in an e-learning environment. The\nperformance of this system is evaluated and compared against the\nstate-of-the-art on a publicly available dataset as well as videos collected\nfrom real-life scenarios. The results show that ED-MTT achieves 6% lower MSE\nthan the best state-of-the-art performance with highly acceptable training time\nand lightweight feature extraction.",
          "link": "http://arxiv.org/abs/2204.04020",
          "publishedOn": "2022-04-11T00:52:28.493Z",
          "wordCount": null,
          "title": "Engagement Detection with Multi-Task Training in E-Learning Environments. (arXiv:2204.04020v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anjomshoaa_A/0/1/0/all/0/1\">Amin Anjomshoaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Curry_E/0/1/0/all/0/1\">Edward Curry</a>",
          "description": "The knowledge, embodied in machine learning models for intelligent systems,\nis commonly associated with time-consuming and costly processes such as\nlarge-scale data collection, data labelling, network training, and fine-tuning\nof models. Sharing and reuse of these elaborated models between intelligent\nsystems deployed in a different environment, which is known as transfer\nlearning, would facilitate the adoption of services for the users and\naccelerates the uptake of intelligent systems in environments such as smart\nbuilding and smart city applications. In this context, the communication and\nknowledge exchange between AI-enabled environments depend on a complicated\nnetworks of systems, system of systems, digital assets, and their chain of\ndependencies that hardly follows the centralized schema of traditional\ninformation systems. Rather, it requires an adaptive decentralized system\narchitecture that is empowered by features such as data provenance, workflow\ntransparency, and validation of process participants. In this research, we\npropose a decentralized and adaptive software framework based on blockchain and\nknowledge graph technologies that supports the knowledge exchange and\ninteroperability between IoT-enabled environments, in a transparent and\ntrustworthy way.",
          "link": "http://arxiv.org/abs/2204.03959",
          "publishedOn": "2022-04-11T00:52:28.489Z",
          "wordCount": 601,
          "title": "Blockchain as an Enabler for Transfer Learning in Smart Environments. (arXiv:2204.03959v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>",
          "description": "The field of bibliometrics, studying citations and behavior, is critical to\nthe discussion of reproducibility. Citations are one of the primary incentive\nand reward systems for academic work, and so we desire to know if this\nincentive rewards reproducible work. Yet to the best of our knowledge, only one\nwork has attempted to look at this combined space, concluding that\nnon-reproducible work is more highly cited. We show that answering this\nquestion is more challenging than first proposed, and subtle issues can inhibit\na robust conclusion. To make inferences with more robust behavior, we propose a\nhierarchical Bayesian model that incorporates the citation rate over time,\nrather than the total number of citations after a fixed amount of time. In\ndoing so we show that, under current evidence the answer is more likely that\ncertain fields of study such as Medicine and Machine Learning (ML) do correlate\nreproducible works with more citations, but other fields appear to have no\nrelationship. Further, we find that making code available and thoroughly\nreferencing prior works appear to also positively correlate with increased\ncitations. Our code and data can be found at\nhttps://github.com/EdwardRaff/ReproducibleCitations .",
          "link": "http://arxiv.org/abs/2204.03829",
          "publishedOn": "2022-04-11T00:52:28.478Z",
          "wordCount": 631,
          "title": "Does the Market of Citations Reward Reproducible Work?. (arXiv:2204.03829v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03911",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Frezat_H/0/1/0/all/0/1\">Hugo Frezat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sommer_J/0/1/0/all/0/1\">Julien Le Sommer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fablet_R/0/1/0/all/0/1\">Ronan Fablet</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Balarac_G/0/1/0/all/0/1\">Guillaume Balarac</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lguensat_R/0/1/0/all/0/1\">Redouane Lguensat</a>",
          "description": "The use of machine learning to build subgrid parametrizations for climate\nmodels is receiving growing attention. State-of-the-art strategies address the\nproblem as a supervised learning task and optimize algorithms that predict\nsubgrid fluxes based on information from coarse resolution models. In practice,\ntraining data are generated from higher resolution numerical simulations\ntransformed in order to mimic coarse resolution simulations. By essence, these\nstrategies optimize subgrid parametrizations to meet so-called $\\textit{a\npriori}$ criteria. But the actual purpose of a subgrid parametrization is to\nobtain good performance in terms of $\\textit{a posteriori}$ metrics which imply\ncomputing entire model trajectories. In this paper, we focus on the\nrepresentation of energy backscatter in two dimensional quasi-geostrophic\nturbulence and compare parametrizations obtained with different learning\nstrategies at fixed computational complexity. We show that strategies based on\n$\\textit{a priori}$ criteria yield parametrizations that tend to be unstable in\ndirect simulations and describe how subgrid parametrizations can alternatively\nbe trained end-to-end in order to meet $\\textit{a posteriori}$ criteria. We\nillustrate that end-to-end learning strategies yield parametrizations that\noutperform known empirical and data-driven schemes in terms of performance,\nstability and ability to apply to different flow configurations. These results\nsupport the relevance of differentiable programming paradigms for climate\nmodels in the future.",
          "link": "http://arxiv.org/abs/2204.03911",
          "publishedOn": "2022-04-11T00:52:27.840Z",
          "wordCount": 653,
          "title": "A posteriori learning for quasi-geostrophic turbulence parametrization. (arXiv:2204.03911v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1\">Kshitiz Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Lin Xiao</a>",
          "description": "We consider two federated learning algorithms for training partially\npersonalized models, where the shared and personal parameters are updated\neither simultaneously or alternately on the devices. Both algorithms have been\nproposed in the literature, but their convergence properties are not fully\nunderstood, especially for the alternating variant. We provide convergence\nanalyses of both algorithms in the general nonconvex setting with partial\nparticipation and delineate the regime where one dominates the other. Our\nexperiments on real-world image, text, and speech datasets demonstrate that (a)\npartial personalization can obtain most of the benefits of full model\npersonalization with a small fraction of personal parameters, and, (b) the\nalternating update algorithm often outperforms the simultaneous update\nalgorithm.",
          "link": "http://arxiv.org/abs/2204.03809",
          "publishedOn": "2022-04-11T00:52:27.816Z",
          "wordCount": 551,
          "title": "Federated Learning with Partial Model Personalization. (arXiv:2204.03809v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_C/0/1/0/all/0/1\">Congyu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Ning Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xin Geng</a>",
          "description": "Partial label learning (PLL) is a typical weakly supervised learning problem,\nwhere each training example is associated with a set of candidate labels among\nwhich only one is true. Most existing PLL approaches assume that the incorrect\nlabels in each training example are randomly picked as the candidate labels and\nmodel the generation process of the candidate labels in a simple way. However,\nthese approaches usually do not perform as well as expected due to the fact\nthat the generation process of the candidate labels is always\ninstance-dependent. Therefore, it deserves to be modeled in a refined way. In\nthis paper, we consider instance-dependent PLL and assume that the generation\nprocess of the candidate labels could decompose into two sequential parts,\nwhere the correct label emerges first in the mind of the annotator but then the\nincorrect labels related to the feature are also selected with the correct\nlabel as candidate labels due to uncertainty of labeling. Motivated by this\nconsideration, we propose a novel PLL method that performs Maximum A\nPosterior(MAP) based on an explicitly modeled generation process of candidate\nlabels via decomposed probability distribution models. Experiments on benchmark\nand real-world datasets validate the effectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2204.03845",
          "publishedOn": "2022-04-11T00:52:27.805Z",
          "wordCount": 622,
          "title": "Decomposition-based Generation Process for Instance-Dependent Partial Label Learning. (arXiv:2204.03845v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03771",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Min_J/0/1/0/all/0/1\">Joosung Min</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elliott_L/0/1/0/all/0/1\">Lloyd T. Elliott</a>",
          "description": "$Q$-learning is the most fundamental model-free reinforcement learning\nalgorithm. Deployment of $Q$-learning requires approximation of the\nstate-action value function (also known as the $Q$-function). In this work, we\nprovide online random forests as $Q$-function approximators and propose a novel\nmethod wherein the random forest is grown as learning proceeds (through\nexpanding forests). We demonstrate improved performance of our methods over\nstate-of-the-art Deep $Q$-Networks in two OpenAI gyms (`blackjack' and\n`inverted pendulum') but not in the `lunar lander' gym. We suspect that the\nresilience to overfitting enjoyed by random forests recommends our method for\ncommon tasks that do not require a strong representation of the problem domain.\nWe show that expanding forests (in which the number of trees increases as data\ncomes in) improve performance, suggesting that expanding forests are viable for\nother applications of online random forests beyond the reinforcement learning\nsetting.",
          "link": "http://arxiv.org/abs/2204.03771",
          "publishedOn": "2022-04-11T00:52:27.790Z",
          "wordCount": 563,
          "title": "Q-learning with online random forests. (arXiv:2204.03771v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03761",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Quezada_L/0/1/0/all/0/1\">L.F. Quezada</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sun_G/0/1/0/all/0/1\">Guo-Hua Sun</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Dong_S/0/1/0/all/0/1\">Shi-Hai Dong</a>",
          "description": "In this work we introduce a quantum sorting algorithm with adaptable\nrequirements of memory and circuit depth, and then use it to develop a new\nquantum version of the classical machine learning algorithm known as k-nearest\nneighbors (k-NN). Both the efficiency and performance of this new quantum\nversion of the k-NN algorithm are compared to those of the classical k-NN and\nanother quantum version proposed by Schuld et al. \\cite{Int13}. Results show\nthat the efficiency of both quantum algorithms is similar to each other and\nsuperior to that of the classical algorithm. On the other hand, the performance\nof our proposed quantum k-NN algorithm is superior to the one proposed by\nSchuld et al. and similar to that of the classical k-NN.",
          "link": "http://arxiv.org/abs/2204.03761",
          "publishedOn": "2022-04-11T00:52:27.782Z",
          "wordCount": 570,
          "title": "Quantum version of the k-NN classifier based on a quantum sorting algorithm. (arXiv:2204.03761v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03793",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ding_S/0/1/0/all/0/1\">Shaojin Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rikhye_R/0/1/0/all/0/1\">Rajeev Rikhye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayanan_A/0/1/0/all/0/1\">Arun Narayanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OMalley_T/0/1/0/all/0/1\">Tom O&#x27;Malley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1\">Ian McGraw</a>",
          "description": "Personalization of on-device speech recognition (ASR) has seen explosive\ngrowth in recent years, largely due to the increasing popularity of personal\nassistant features on mobile devices and smart home speakers. In this work, we\npresent Personal VAD 2.0, a personalized voice activity detector that detects\nthe voice activity of a target speaker, as part of a streaming on-device ASR\nsystem. Although previous proof-of-concept studies have validated the\neffectiveness of Personal VAD, there are still several critical challenges to\naddress before this model can be used in production: first, the quality must be\nsatisfactory in both enrollment and enrollment-less scenarios; second, it\nshould operate in a streaming fashion; and finally, the model size should be\nsmall enough to fit a limited latency and CPU/Memory budget. To meet the\nmulti-faceted requirements, we propose a series of novel designs: 1) advanced\nspeaker embedding modulation methods; 2) a new training paradigm to generalize\nto enrollment-less conditions; 3) architecture and runtime optimizations for\nlatency and resource restrictions. Extensive experiments on a realistic speech\nrecognition system demonstrated the state-of-the-art performance of our\nproposed method.",
          "link": "http://arxiv.org/abs/2204.03793",
          "publishedOn": "2022-04-11T00:52:27.702Z",
          "wordCount": 638,
          "title": "Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition. (arXiv:2204.03793v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03784",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takahashi_C/0/1/0/all/0/1\">Chako Takahashi</a>",
          "description": "The evaluation of the free energy of a stochastic model is considered to be a\nsignificant issue in various fields of physics and machine learning. However,\nthe exact free energy evaluation is computationally infeasible because it\nincludes an intractable partition function. Annealed importance sampling (AIS)\nis a type of importance sampling based on the Markov chain Monte Carlo method,\nwhich is similar to a simulated annealing, and can effectively approximate the\nfree energy. This study proposes a new AIS-based approach, referred to as\nmarginalized AIS (mAIS). The statistical efficiency of mAIS is investigated in\ndetail based on a theoretical and numerical perspectives. Based on the\ninvestigation, it has been proved that mAIS is more effective than AIS under a\ncertain condition.",
          "link": "http://arxiv.org/abs/2204.03784",
          "publishedOn": "2022-04-11T00:52:27.666Z",
          "wordCount": 564,
          "title": "Free Energy Evaluation Using Marginalized Annealed Importance Sampling. (arXiv:2204.03784v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03804",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bian_W/0/1/0/all/0/1\">Wanyu Bian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingchao Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_X/0/1/0/all/0/1\">Xiaojing Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmei Chen</a>",
          "description": "Generating multi-contrasts/modal MRI of the same anatomy enriches diagnostic\ninformation but is limited in practice due to excessive data acquisition time.\nIn this paper, we propose a novel deep-learning model for joint reconstruction\nand synthesis of multi-modal MRI using incomplete k-space data of several\nsource modalities as inputs. The output of our model includes reconstructed\nimages of the source modalities and high-quality image synthesized in the\ntarget modality. Our proposed model is formulated as a variational problem that\nleverages several learnable modality-specific feature extractors and a\nmultimodal synthesis module. We propose a learnable optimization algorithm to\nsolve this model, which induces a multi-phase network whose parameters can be\ntrained using multi-modal MRI data. Moreover, a bilevel-optimization framework\nis employed for robust parameter training. We demonstrate the effectiveness of\nour approach using extensive numerical experiments.",
          "link": "http://arxiv.org/abs/2204.03804",
          "publishedOn": "2022-04-11T00:52:27.658Z",
          "wordCount": 591,
          "title": "A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis. (arXiv:2204.03804v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aguiar_G/0/1/0/all/0/1\">Gabriel Aguiar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krawczyk_B/0/1/0/all/0/1\">Bartosz Krawczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cano_A/0/1/0/all/0/1\">Alberto Cano</a>",
          "description": "Class imbalance poses new challenges when it comes to classifying data\nstreams. Many algorithms recently proposed in the literature tackle this\nproblem using a variety of data-level, algorithm-level, and ensemble\napproaches. However, there is a lack of standardized and agreed-upon procedures\non how to evaluate these algorithms. This work presents a taxonomy of\nalgorithms for imbalanced data streams and proposes a standardized, exhaustive,\nand informative experimental testbed to evaluate algorithms in a collection of\ndiverse and challenging imbalanced data stream scenarios. The experimental\nstudy evaluates 24 state-of-the-art data streams algorithms on 515 imbalanced\ndata streams that combine static and dynamic class imbalance ratios,\ninstance-level difficulties, concept drift, real-world and semi-synthetic\ndatasets in binary and multi-class scenarios. This leads to the largest\nexperimental study conducted so far in the data stream mining domain. We\ndiscuss the advantages and disadvantages of state-of-the-art classifiers in\neach of these scenarios and we provide general recommendations to end-users for\nselecting the best algorithms for imbalanced data streams. Additionally, we\nformulate open challenges and future directions for this domain. Our\nexperimental testbed is fully reproducible and easy to extend with new methods.\nThis way we propose the first standardized approach to conducting experiments\nin imbalanced data streams that can be used by other researchers to create\ntrustworthy and fair evaluation of newly proposed methods. Our experimental\nframework can be downloaded from\nhttps://github.com/canoalberto/imbalanced-streams.",
          "link": "http://arxiv.org/abs/2204.03719",
          "publishedOn": "2022-04-11T00:52:27.650Z",
          "wordCount": 665,
          "title": "A survey on learning from imbalanced data streams: taxonomy, challenges, empirical study, and reproducible experimental framework. (arXiv:2204.03719v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zehtabi_S/0/1/0/all/0/1\">Shahryar Zehtabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1\">Seyyedali Hosseinalipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher G. Brinton</a>",
          "description": "A recent emphasis of distributed learning research has been on federated\nlearning (FL), in which model training is conducted by the data-collecting\ndevices. Existing research on FL has mostly focused on a star topology learning\narchitecture with synchronized (time-triggered) model training rounds, where\nthe local models of the devices are periodically aggregated by a centralized\ncoordinating node. However, in many settings, such a coordinating node may not\nexist, motivating efforts to fully decentralize FL. In this work, we propose a\nnovel methodology for distributed model aggregations via asynchronous,\nevent-triggered consensus iterations over the network graph topology. We\nconsider heterogeneous communication event thresholds at each device that weigh\nthe change in local model parameters against the available local resources in\ndeciding the benefit of aggregations at each iteration. Through theoretical\nanalysis, we demonstrate that our methodology achieves asymptotic convergence\nto the globally optimal learning model under standard assumptions in\ndistributed learning and graph consensus literature, and without restrictive\nconnectivity requirements on the underlying topology. Subsequent numerical\nresults demonstrate that our methodology obtains substantial improvements in\ncommunication requirements compared with FL baselines.",
          "link": "http://arxiv.org/abs/2204.03726",
          "publishedOn": "2022-04-11T00:52:27.631Z",
          "wordCount": 606,
          "title": "Decentralized Event-Triggered Federated Learning with Heterogeneous Communication Thresholds. (arXiv:2204.03726v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zahid_M/0/1/0/all/0/1\">Muhammad Uzair Zahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiranyaz_S/0/1/0/all/0/1\">Serkan Kiranyaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Objective: Global (inter-patient) ECG classification for arrhythmia detection\nover Electrocardiogram (ECG) signal is a challenging task for both humans and\nmachines. The main reason is the significant variations of both normal and\narrhythmic ECG patterns among patients. Automating this process with utmost\naccuracy is, therefore, highly desirable due to the advent of wearable ECG\nsensors. However, even with numerous deep learning approaches proposed\nrecently, there is still a notable gap in the performance of global and\npatient-specific ECG classification performances. This study proposes a novel\napproach to narrow this gap and propose a real-time solution with shallow and\ncompact 1D Self-Organized Operational Neural Networks (Self-ONNs). Methods: In\nthis study, we propose a novel approach for inter-patient ECG classification\nusing a compact 1D Self-ONN by exploiting morphological and timing information\nin heart cycles. We used 1D Self-ONN layers to automatically learn\nmorphological representations from ECG data, enabling us to capture the shape\nof the ECG waveform around the R peaks. We further inject temporal features\nbased on RR interval for timing characterization. The classification layers can\nthus benefit from both temporal and learned features for the final arrhythmia\nclassification. Results: Using the MIT-BIH arrhythmia benchmark database, the\nproposed method achieves the highest classification performance ever achieved,\ni.e., 99.21% precision, 99.10% recall, and 99.15% F1-score for normal (N)\nsegments; 82.19% precision, 82.50% recall, and 82.34% F1-score for the\nsupra-ventricular ectopic beat (SVEBs); and finally, 94.41% precision, 96.10%\nrecall, and 95.2% F1-score for the ventricular-ectopic beats (VEBs).",
          "link": "http://arxiv.org/abs/2204.03768",
          "publishedOn": "2022-04-11T00:52:27.624Z",
          "wordCount": 670,
          "title": "Global ECG Classification by Self-Operational Neural Networks with Feature Injection. (arXiv:2204.03768v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olague_G/0/1/0/all/0/1\">Gustavo Olague</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menendez_Clavijo_J/0/1/0/all/0/1\">Jose Armando Menendez-Clavijo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olague_M/0/1/0/all/0/1\">Matthieu Olague</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ocampo_A/0/1/0/all/0/1\">Arturo Ocampo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibarra_Vazquez_G/0/1/0/all/0/1\">Gerardo Ibarra-Vazquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochoa_R/0/1/0/all/0/1\">Rocio Ochoa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineda_R/0/1/0/all/0/1\">Roberto Pineda</a>",
          "description": "Despite recent improvements in computer vision, artificial visual systems'\ndesign is still daunting since an explanation of visual computing algorithms\nremains elusive. Salient object detection is one problem that is still open due\nto the difficulty of understanding the brain's inner workings. Progress on this\nresearch area follows the traditional path of hand-made designs using\nneuroscience knowledge. In recent years two different approaches based on\ngenetic programming appear to enhance their technique. One follows the idea of\ncombining previous hand-made methods through genetic programming and fuzzy\nlogic. The other approach consists of improving the inner computational\nstructures of basic hand-made models through artificial evolution. This\nresearch work proposes expanding the artificial dorsal stream using a recent\nproposal to solve salient object detection problems. This approach uses the\nbenefits of the two main aspects of this research area: fixation prediction and\ndetection of salient objects. We decided to apply the fusion of visual saliency\nand image segmentation algorithms as a template. The proposed methodology\ndiscovers several critical structures in the template through artificial\nevolution. We present results on a benchmark designed by experts with\noutstanding results in comparison with the state-of-the-art.",
          "link": "http://arxiv.org/abs/2204.03722",
          "publishedOn": "2022-04-11T00:52:27.617Z",
          "wordCount": 650,
          "title": "Automated Design of Salient Object Detection Algorithms with Brain Programming. (arXiv:2204.03722v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kensen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Joey Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Pengcheng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_C/0/1/0/all/0/1\">Charles Sutton</a>",
          "description": "When writing programs, people have the ability to tackle a new complex task\nby decomposing it into smaller and more familiar subtasks. While it is\ndifficult to measure whether neural program synthesis methods have similar\ncapabilities, what we can measure is whether they compositionally generalize,\nthat is, whether a model that has been trained on the simpler subtasks is\nsubsequently able to solve more complex tasks. In this paper, we focus on\nmeasuring the ability of learned program synthesizers to compositionally\ngeneralize. We first characterize several different axes along which program\nsynthesis methods would be desired to generalize, e.g., length generalization,\nor the ability to combine known subroutines in new ways that do not occur in\nthe training data. Based on this characterization, we introduce a benchmark\nsuite of tasks to assess these abilities based on two popular existing\ndatasets, SCAN and RobustFill. Finally, we make first attempts to improve the\ncompositional generalization ability of Transformer models along these axes\nthrough novel attention mechanisms that draw inspiration from a human-like\ndecomposition strategy. Empirically, we find our modified Transformer models\ngenerally perform better than natural baselines, but the tasks remain\nchallenging.",
          "link": "http://arxiv.org/abs/2204.03758",
          "publishedOn": "2022-04-11T00:52:27.601Z",
          "wordCount": 633,
          "title": "Compositional Generalization and Decomposition in Neural Program Synthesis. (arXiv:2204.03758v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03703",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_Z/0/1/0/all/0/1\">Zhen Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_J/0/1/0/all/0/1\">Jung Ki Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barbastathis_G/0/1/0/all/0/1\">George Barbastathis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Glinsky_M/0/1/0/all/0/1\">Michael E. Glinsky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vaughan_C/0/1/0/all/0/1\">Courtenay T. Vaughan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Larson_K/0/1/0/all/0/1\">Kurt W. Larson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alpert_B/0/1/0/all/0/1\">Bradley K. Alpert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Levine_Z/0/1/0/all/0/1\">Zachary H. Levine</a>",
          "description": "X-ray tomography is capable of imaging the interior of objects in three\ndimensions non-invasively, with applications in biomedical imaging, materials\nscience, electronic inspection, and other fields. The reconstruction process\ncan be an ill-conditioned inverse problem, requiring regularization to obtain\nsatisfactory reconstructions. Recently, deep learning has been adopted for\ntomographic reconstruction. Unlike iterative algorithms which require a\ndistribution that is known a priori, deep reconstruction networks can learn a\nprior distribution through sampling the training distributions. In this work,\nwe develop a Physics-assisted Generative Adversarial Network (PGAN), a two-step\nalgorithm for tomographic reconstruction. In contrast to previous efforts, our\nPGAN utilizes maximum-likelihood estimates derived from the measurements to\nregularize the reconstruction with both known physics and the learned prior.\nSynthetic objects with spatial correlations are integrated circuits (IC) from a\nproposed model CircuitFaker. Compared with maximum-likelihood estimation, PGAN\ncan reduce the photon requirement with limited projection angles to achieve a\ngiven error rate. We further attribute the improvement to the learned prior by\nreconstructing objects created without spatial correlations. The advantages of\nusing a prior from deep learning in X-ray tomography may further enable\nlow-photon nanoscale imaging.",
          "link": "http://arxiv.org/abs/2204.03703",
          "publishedOn": "2022-04-11T00:52:27.584Z",
          "wordCount": 645,
          "title": "Physics-assisted Generative Adversarial Network for X-Ray Tomography. (arXiv:2204.03703v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1\">Siddhartha Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollnig_K/0/1/0/all/0/1\">Konrad Kollnig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shadbolt_N/0/1/0/all/0/1\">Nigel Shadbolt</a>",
          "description": "Digital harms can manifest across any interface. Key problems in addressing\nthese harms include the high individuality of harms and the fast-changing\nnature of digital systems. As a result, we still lack a systematic approach to\nstudy harms and produce interventions for end-users. We put forward\nGreaseVision, a new framework that enables end-users to collaboratively develop\ninterventions against harms in software using a no-code approach and recent\nadvances in few-shot machine learning. The contribution of the framework and\ntool allow individual end-users to study their usage history and create\npersonalized interventions. Our contribution also enables researchers to study\nthe distribution of harms and interventions at scale.",
          "link": "http://arxiv.org/abs/2204.03731",
          "publishedOn": "2022-04-11T00:52:27.576Z",
          "wordCount": 529,
          "title": "GreaseVision: Rewriting the Rules of the Interface. (arXiv:2204.03731v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03737",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1\">Xinjie Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuangzhi Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1\">Dongwei Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1\">Huaji Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_S/0/1/0/all/0/1\">Shanqing Yu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_S/0/1/0/all/0/1\">Shilian Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xuan_Q/0/1/0/all/0/1\">Qi Xuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoniu Yang</a>",
          "description": "With the rapid development of deep learning, automatic modulation recognition\n(AMR), as an important task in cognitive radio, has gradually transformed from\ntraditional feature extraction and classification to automatic classification\nby deep learning technology. However, deep learning models are data-driven\nmethods, which often require a large amount of data as the training support.\nData augmentation, as the strategy of expanding dataset, can improve the\ngeneralization of the deep learning models and thus improve the accuracy of the\nmodels to a certain extent. In this paper, for AMR of radio signals, we propose\na data augmentation strategy based on mixing signals and consider four specific\nmethods (Random Mixing, Maximum-Similarity-Mixing, $\\theta-$Similarity Mixing\nand n-times Random Mixing) to achieve data augmentation. Experiments show that\nour proposed method can improve the classification accuracy of deep learning\nbased AMR models in the full public dataset RML2016.10a. In particular, for the\ncase of a single signal-to-noise ratio signal set, the classification accuracy\ncan be significantly improved, which verifies the effectiveness of the methods.",
          "link": "http://arxiv.org/abs/2204.03737",
          "publishedOn": "2022-04-11T00:52:27.569Z",
          "wordCount": 612,
          "title": "Mixing Signals: Data Augmentation Approach for Deep Learning Based Modulation Recognition. (arXiv:2204.03737v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ng_P/0/1/0/all/0/1\">Pai Chet Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spachos_P/0/1/0/all/0/1\">Petros Spachos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+She_J/0/1/0/all/0/1\">James She</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1\">Konstantinos N. Plataniotis</a>",
          "description": "This paper presents a nonlinear location estimation to infer the position of\na user holding a smartphone. We consider a large location with $M$ number of\ngrid points, each grid point is labeled with a unique fingerprint consisting of\nthe received signal strength (RSS) values measured from $N$ number of Bluetooth\nLow Energy (BLE) beacons. Given the fingerprint observed by the smartphone, the\nuser's current location can be estimated by finding the top-k similar\nfingerprints from the list of fingerprints registered in the database. Besides\nthe environmental factors, the dynamicity in holding the smartphone is another\nsource to the variation in fingerprint measurements, yet there are not many\nstudies addressing the fingerprint variability due to dynamic smartphone\npositions held by human hands during online detection. To this end, we propose\na nonlinear location estimation using the kernel method. Specifically, our\nproposed method comprises of two steps: 1) a beacon selection strategy to\nselect a subset of beacons that is insensitive to the subtle change of holding\npositions, and 2) a kernel method to compute the similarity between this subset\nof observed signals and all the fingerprints registered in the database. The\nexperimental results based on large-scale data collected in a complex building\nindicate a substantial performance gain of our proposed approach in comparison\nto state-of-the-art methods. The dataset consisting of the signal information\ncollected from the beacons is available online.",
          "link": "http://arxiv.org/abs/2204.03724",
          "publishedOn": "2022-04-11T00:52:27.561Z",
          "wordCount": 672,
          "title": "A Kernel Method to Nonlinear Location Estimation with RSS-based Fingerprint. (arXiv:2204.03724v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1\">Diego Corr&#xea;a da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durao_F/0/1/0/all/0/1\">Frederico Ara&#xfa;jo Dur&#xe3;o</a>",
          "description": "Recommender Systems use the user's profile to generate a recommendation list\nwith unknown items to a target user. Although the primary goal of traditional\nrecommendation systems is to deliver the most relevant items, such an effort\nunintentionally can cause collateral effects including low diversity and\nunbalanced genres or categories, benefiting particular groups of categories.\nThis paper proposes an approach to create recommendation lists with a\ncalibrated balance of genres, avoiding disproportion between the user's profile\ninterests and the recommendation list. The calibrated recommendations consider\nconcomitantly the relevance and the divergence between the genres distributions\nextracted from the user's preference and the recommendation list. The main\nclaim is that calibration can contribute positively to generate fairer\nrecommendations. In particular, we propose a new trade-off equation, which\nconsiders the users' bias to provide a recommendation list that seeks for the\nusers' tendencies. Moreover, we propose a conceptual framework and a decision\nprotocol to generate more than one thousand combinations of calibrated systems\nin order to find the best combination. We compare our approach against\nstate-of-the-art approaches using multiple domain datasets, which are analyzed\nby rank and calibration metrics. The results indicate that the trade-off, which\nconsiders the users' bias, produces positive effects on the precision and to\nthe fairness, thus generating recommendation lists that respect the genre\ndistribution and, through the decision protocol, we also found the best system\nfor each dataset.",
          "link": "http://arxiv.org/abs/2204.03706",
          "publishedOn": "2022-04-11T00:52:27.553Z",
          "wordCount": 674,
          "title": "Introducing a Framework and a Decision Protocol to Calibrate Recommender Systems. (arXiv:2204.03706v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">You Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Huiqi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1\">Angela Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thuerey_N/0/1/0/all/0/1\">Nils Thuerey</a>",
          "description": "We propose a novel approach to generate temporally coherent UV coordinates\nfor loose clothing. Our method is not constrained by human body outlines and\ncan capture loose garments and hair. We implemented a differentiable pipeline\nto learn UV mapping between a sequence of RGB inputs and textures via UV\ncoordinates. Instead of treating the UV coordinates of each frame separately,\nour data generation approach connects all UV coordinates via feature matching\nfor temporal stability. Subsequently, a generative model is trained to balance\nthe spatial quality and temporal stability. It is driven by supervised and\nunsupervised losses in both UV and image spaces. Our experiments show that the\ntrained models output high-quality UV coordinates and generalize to new poses.\nOnce a sequence of UV coordinates has been inferred by our model, it can be\nused to flexibly synthesize new looks and modified visual styles. Compared to\nexisting methods, our approach reduces the computational workload to animate\nnew outfits by several orders of magnitude.",
          "link": "http://arxiv.org/abs/2204.03671",
          "publishedOn": "2022-04-11T00:52:27.536Z",
          "wordCount": 601,
          "title": "TemporalUV: Capturing Loose Clothing with Temporally Coherent UV Coordinates. (arXiv:2204.03671v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1\">Erick Giovani Sperandio Nascimento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Julian Santana Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Figueiredo_I/0/1/0/all/0/1\">Ilan Sousa Figueiredo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guarieiro_L/0/1/0/all/0/1\">Lilian Lefol Nani Guarieiro</a>",
          "description": "Deep learning and big data algorithms have become widely used in industrial\napplications to optimize several tasks in many complex systems. Particularly,\ndeep learning model for diagnosing and prognosing machinery health has\nleveraged predictive maintenance (PdM) to be more accurate and reliable in\ndecision making, in this way avoiding unnecessary interventions, machinery\naccidents, and environment catastrophes. Recently, Transformer Neural Networks\nhave gained notoriety and have been increasingly the favorite choice for\nNatural Language Processing (NLP) tasks. Thus, given their recent major\nachievements in NLP, this paper proposes the development of an automatic fault\nclassifier model for predictive maintenance based on a modified version of the\nTransformer architecture, namely T4PdM, to identify multiple types of faults in\nrotating machinery. Experimental results are developed and presented for the\nMaFaulDa and CWRU databases. T4PdM was able to achieve an overall accuracy of\n99.98% and 98% for both datasets, respectively. In addition, the performance of\nthe proposed model is compared to other previously published works. It has\ndemonstrated the superiority of the model in detecting and classifying faults\nin rotating industrial machinery. Therefore, the proposed Transformer-based\nmodel can improve the performance of machinery fault analysis and diagnostic\nprocesses and leverage companies to a new era of the Industry 4.0. In addition,\nthis methodology can be adapted to any other task of time series\nclassification.",
          "link": "http://arxiv.org/abs/2204.03725",
          "publishedOn": "2022-04-11T00:52:27.528Z",
          "wordCount": 671,
          "title": "T4PdM: a Deep Neural Network based on the Transformer Architecture for Fault Diagnosis of Rotating Machinery. (arXiv:2204.03725v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Genssler_P/0/1/0/all/0/1\">Paul R. Genssler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vas_A/0/1/0/all/0/1\">Austin Vas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amrouch_H/0/1/0/all/0/1\">Hussam Amrouch</a>",
          "description": "Brain-inspired hyperdimensional computing (HDC) is an emerging machine\nlearning (ML) methods. It is based on large vectors of binary or bipolar\nsymbols and a few simple mathematical operations. The promise of HDC is a\nhighly efficient implementation for embedded systems like wearables. While fast\nimplementations have been presented, other constraints have not been considered\nfor edge computing. In this work, we aim at answering how thermal-friendly HDC\nfor edge computing is. Devices like smartwatches, smart glasses, or even mobile\nsystems have a restrictive cooling budget due to their limited volume. Although\nHDC operations are simple, the vectors are large, resulting in a high number of\nCPU operations and thus a heavy load on the entire system potentially causing\ntemperature violations. In this work, the impact of HDC on the chip's\ntemperature is investigated for the first time. We measure the temperature and\npower consumption of a commercial embedded system and compare HDC with\nconventional CNN. We reveal that HDC causes up to 6.8{\\deg}C higher\ntemperatures and leads to up to 47% more CPU throttling. Even when both HDC and\nCNN aim for the same throughput (i.e., perform a similar number of\nclassifications per second), HDC still causes higher on-chip temperatures due\nto the larger power consumption.",
          "link": "http://arxiv.org/abs/2204.03739",
          "publishedOn": "2022-04-11T00:52:27.521Z",
          "wordCount": 645,
          "title": "Brain-Inspired Hyperdimensional Computing: How Thermal-Friendly for Edge Computing?. (arXiv:2204.03739v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lawhon_M/0/1/0/all/0/1\">Matthew Lawhon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_C/0/1/0/all/0/1\">Chengzhi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junfeng Yang</a>",
          "description": "Deep networks achieve state-of-the-art performance on computer vision tasks,\nyet they fail under adversarial attacks that are imperceptible to humans. In\nthis paper, we propose a novel defense that can dynamically adapt the input\nusing the intrinsic structure from multiple self-supervised tasks. By\nsimultaneously using many self-supervised tasks, our defense avoids\nover-fitting the adapted image to one specific self-supervised task and\nrestores more intrinsic structure in the image compared to a single\nself-supervised task approach. Our approach further improves robustness and\nclean accuracy significantly compared to the state-of-the-art single task\nself-supervised defense. Our work is the first to connect multiple\nself-supervised tasks to robustness, and suggests that we can achieve better\nrobustness with more intrinsic signal from visual data.",
          "link": "http://arxiv.org/abs/2204.03714",
          "publishedOn": "2022-04-11T00:52:27.513Z",
          "wordCount": 564,
          "title": "Using Multiple Self-Supervised Tasks Improves Model Robustness. (arXiv:2204.03714v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oviedo_F/0/1/0/all/0/1\">Felipe Oviedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinnakota_S/0/1/0/all/0/1\">Srinivas Vinnakota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seleznev_E/0/1/0/all/0/1\">Eugene Seleznev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malhotra_H/0/1/0/all/0/1\">Hemant Malhotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_S/0/1/0/all/0/1\">Saqib Shaikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1\">Juan Lavista Ferres</a>",
          "description": "Millions of people around the world have low or no vision. Assistive software\napplications have been developed for a variety of day-to-day tasks, including\noptical character recognition, scene identification, person recognition, and\ncurrency recognition. This last task, the recognition of banknotes from\ndifferent denominations, has been addressed by the use of computer vision\nmodels for image recognition. However, the datasets and models available for\nthis task are limited, both in terms of dataset size and in variety of\ncurrencies covered. In this work, we collect a total of 24,826 images of\nbanknotes in variety of assistive settings, spanning 17 currencies and 112\ndenominations. Using supervised contrastive learning, we develop a machine\nlearning model for universal currency recognition. This model learns compliant\nembeddings of banknote images in a variety of contexts, which can be shared\npublicly (as a compressed vector representation), and can be used to train and\ntest specialized downstream models for any currency, including those not\ncovered by our dataset or for which only a few real images per denomination are\navailable (few-shot learning). We deploy a variation of this model for public\nuse in the last version of the Seeing AI app developed by Microsoft. We share\nour encoder model and the embeddings as an open dataset in our BankNote-Net\nrepository.",
          "link": "http://arxiv.org/abs/2204.03738",
          "publishedOn": "2022-04-11T00:52:27.506Z",
          "wordCount": 657,
          "title": "BankNote-Net: Open dataset for assistive universal currency recognition. (arXiv:2204.03738v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lim_B/0/1/0/all/0/1\">Bryan Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichenbach_A/0/1/0/all/0/1\">Alexander Reichenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1\">Antoine Cully</a>",
          "description": "Quality-Diversity (QD) algorithms can discover large and complex behavioural\nrepertoires consisting of both diverse and high-performing skills. However, the\ngeneration of behavioural repertoires has mainly been limited to simulation\nenvironments instead of real-world learning. This is because existing QD\nalgorithms need large numbers of evaluations as well as episodic resets, which\nrequire manual human supervision and interventions. This paper proposes\nReset-Free Quality-Diversity optimization (RF-QD) as a step towards autonomous\nlearning for robotics in open-ended environments. We build on Dynamics-Aware\nQuality-Diversity (DA-QD) and introduce a behaviour selection policy that\nleverages the diversity of the imagined repertoire and environmental\ninformation to intelligently select of behaviours that can act as automatic\nresets. We demonstrate this through a task of learning to walk within defined\ntraining zones with obstacles. Our experiments show that we can learn full\nrepertoires of legged locomotion controllers autonomously without manual resets\nwith high sample efficiency in spite of harsh safety constraints. Finally,\nusing an ablation of different target objectives, we show that it is important\nfor RF-QD to have diverse types solutions available for the behaviour selection\npolicy over solutions optimised with a specific objective. Videos and code\navailable at https://sites.google.com/view/rf-qd.",
          "link": "http://arxiv.org/abs/2204.03655",
          "publishedOn": "2022-04-11T00:52:27.486Z",
          "wordCount": 635,
          "title": "Learning to Walk Autonomously via Reset-Free Quality-Diversity. (arXiv:2204.03655v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03654",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1\">Fangyu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wei_Y/0/1/0/all/0/1\">Yanjie Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xi_W/0/1/0/all/0/1\">Wenhui Xi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1\">Yi Pan</a>",
          "description": "The development of noninvasive brain imaging such as resting-state functional\nmagnetic resonance imaging (rs-fMRI) and its combination with AI algorithm\nprovides a promising solution for the early diagnosis of Autism spectrum\ndisorder (ASD). However, the performance of the current ASD classification\nbased on rs-fMRI still needs to be improved. This paper introduces a\nclassification framework to aid ASD diagnosis based on rs-fMRI. In the\nframework, we proposed a novel filter feature selection method based on the\ndifference between step distribution curves (DSDC) to select remarkable\nfunctional connectivities (FCs) and utilized a multilayer perceptron (MLP)\nwhich was pretrained by a simplified Variational Autoencoder (VAE) for\nclassification. We also designed a pipeline consisting of a normalization\nprocedure and a modified hyperbolic tangent (tanh) activation function to\nreplace the original tanh function, further improving the model accuracy. Our\nmodel was evaluated by 10 times 10-fold cross-validation and achieved an\naverage accuracy of 78.12%, outperforming the state-of-the-art methods reported\non the same dataset. Given the importance of sensitivity and specificity in\ndisease diagnosis, two constraints were designed in our model which can improve\nthe model's sensitivity and specificity by up to 9.32% and 10.21%,\nrespectively. The added constraints allow our model to handle different\napplication scenarios and can be used broadly.",
          "link": "http://arxiv.org/abs/2204.03654",
          "publishedOn": "2022-04-11T00:52:27.479Z",
          "wordCount": 682,
          "title": "Identification of Autism spectrum disorder based on a novel feature selection method and Variational Autoencoder. (arXiv:2204.03654v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03657",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Criado_J/0/1/0/all/0/1\">Juan Carlos Criado</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Spannowsky_M/0/1/0/all/0/1\">Michael Spannowsky</a>",
          "description": "We present a general method, called Qade, for solving differential equations\nusing a quantum annealer. The solution is obtained as a linear combination of a\nset of basis functions. On current devices, Qade can solve systems of coupled\npartial differential equations that depend linearly on the solution and its\nderivatives, with non-linear variable coefficients and arbitrary inhomogeneous\nterms. We test the method with several examples and find that state-of-the-art\nquantum annealers can find the solution accurately for problems requiring a\nsmall enough function basis. We provide a Python package implementing the\nmethod at gitlab.com/jccriado/qade.",
          "link": "http://arxiv.org/abs/2204.03657",
          "publishedOn": "2022-04-11T00:52:27.472Z",
          "wordCount": 550,
          "title": "Qade: Solving Differential Equations on Quantum Annealers. (arXiv:2204.03657v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirzaeian_A/0/1/0/all/0/1\">Ali Mirzaeian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+D_S/0/1/0/all/0/1\">Sai Manoj P D</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latibari_B/0/1/0/all/0/1\">Banafsheh S. Latibari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savidis_I/0/1/0/all/0/1\">Ioannis Savidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Homayoun_H/0/1/0/all/0/1\">Houman Homayoun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasan_A/0/1/0/all/0/1\">Avesta Sasan</a>",
          "description": "This paper presents a novel model training solution, denoted as\nAdaptive-Gravity, for enhancing the robustness of deep neural network\nclassifiers against adversarial examples. We conceptualize the model\nparameters/features associated with each class as a mass characterized by its\ncentroid location and the spread (standard deviation of the distance) of\nfeatures around the centroid. We use the centroid associated with each cluster\nto derive an anti-gravity force that pushes the centroids of different classes\naway from one another during network training. Then we customized an objective\nfunction that aims to concentrate each class's features toward their\ncorresponding new centroid, which has been obtained by anti-gravity force. This\nmethodology results in a larger separation between different masses and reduces\nthe spread of features around each centroid. As a result, the samples are\npushed away from the space that adversarial examples could be mapped to,\neffectively increasing the degree of perturbation needed for making an\nadversarial example. We have implemented this training solution as an iterative\nmethod consisting of four steps at each iteration: 1) centroid extraction, 2)\nanti-gravity force calculation, 3) centroid relocation, and 4) gravity\ntraining. Gravity's efficiency is evaluated by measuring the corresponding\nfooling rates against various attack models, including FGSM, MIM, BIM, and PGD\nusing LeNet and ResNet110 networks, benchmarked against MNIST and CIFAR10\nclassification problems. Test results show that Gravity not only functions as a\npowerful instrument to robustify a model against state-of-the-art adversarial\nattacks but also effectively improves the model training accuracy.",
          "link": "http://arxiv.org/abs/2204.03694",
          "publishedOn": "2022-04-11T00:52:27.460Z",
          "wordCount": 682,
          "title": "Adaptive-Gravity: A Defense Against Adversarial Samples. (arXiv:2204.03694v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yutong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damani_M/0/1/0/all/0/1\">Mehul Damani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pamela Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuhong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sartoretti_G/0/1/0/all/0/1\">Guillaume Sartoretti</a>",
          "description": "Purpose of review: Recent advances in sensing, actuation, and computation\nhave opened the door to multi-robot systems consisting of hundreds/thousands of\nrobots, with promising applications to automated manufacturing, disaster\nrelief, harvesting, last-mile delivery, port/airport operations, or search and\nrescue. The community has leveraged model-free multi-agent reinforcement\nlearning (MARL) to devise efficient, scalable controllers for multi-robot\nsystems (MRS). This review aims to provide an analysis of the state-of-the-art\nin distributed MARL for multi-robot cooperation.\n\nRecent findings: Decentralized MRS face fundamental challenges, such as\nnon-stationarity and partial observability. Building upon the \"centralized\ntraining, decentralized execution\" paradigm, recent MARL approaches include\nindependent learning, centralized critic, value decomposition, and\ncommunication learning approaches. Cooperative behaviors are demonstrated\nthrough AI benchmarks and fundamental real-world robotic capabilities such as\nmulti-robot motion/path planning.\n\nSummary: This survey reports the challenges surrounding decentralized\nmodel-free MARL for multi-robot cooperation and existing classes of approaches.\nWe present benchmarks and robotic applications along with a discussion on\ncurrent open avenues for research.",
          "link": "http://arxiv.org/abs/2204.03516",
          "publishedOn": "2022-04-09T00:48:55.535Z",
          "wordCount": 615,
          "title": "Distributed Reinforcement Learning for Robot Teams: A Review. (arXiv:2204.03516v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yulun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cashman_M/0/1/0/all/0/1\">Mikaela Cashman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choma_N/0/1/0/all/0/1\">Nicholas Choma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_E/0/1/0/all/0/1\">&#xc9;rica T. Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergara_V/0/1/0/all/0/1\">Ver&#xf3;nica G. Melesse Vergara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Andrew Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Manesh Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brettin_T/0/1/0/all/0/1\">Thomas S. Brettin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_W/0/1/0/all/0/1\">Wibe A. de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Neeraj Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Head_M/0/1/0/all/0/1\">Martha S. Head</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1\">Rick L. Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugent_P/0/1/0/all/0/1\">Peter Nugent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_D/0/1/0/all/0/1\">Daniel A. Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1\">James B. Brown</a>",
          "description": "We developed Distilled Graph Attention Policy Network (DGAPN), a\nreinforcement learning model to generate novel graph-structured chemical\nrepresentations that optimize user-defined objectives by efficiently navigating\na physically constrained domain. The framework is examined on the task of\ngenerating molecules that are designed to bind, noncovalently, to functional\nsites of SARS-CoV-2 proteins. We present a spatial Graph Attention (sGAT)\nmechanism that leverages self-attention over both node and edge attributes as\nwell as encoding the spatial structure -- this capability is of considerable\ninterest in synthetic biology and drug discovery. An attentional policy network\nis introduced to learn the decision rules for a dynamic, fragment-based\nchemical environment, and state-of-the-art policy gradient techniques are\nemployed to train the network with stability. Exploration is driven by the\nstochasticity of the action space design and the innovation reward bonuses\nlearned and proposed by random network distillation. In experiments, our\nframework achieved outstanding results compared to state-of-the-art algorithms,\nwhile reducing the complexity of paths to chemical synthesis.",
          "link": "http://arxiv.org/abs/2106.02190",
          "publishedOn": "2022-04-09T00:48:55.510Z",
          "wordCount": 745,
          "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery. (arXiv:2106.02190v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05845",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Simpson_I/0/1/0/all/0/1\">Ivor J.A. Simpson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McManamon_A/0/1/0/all/0/1\">Ashley McManamon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Orzsik_B/0/1/0/all/0/1\">Bal&#xe1;zs &#xd6;rzsik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stone_A/0/1/0/all/0/1\">Alan J. Stone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blockley_N/0/1/0/all/0/1\">Nicholas P. Blockley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asllani_I/0/1/0/all/0/1\">Iris Asllani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colasanti_A/0/1/0/all/0/1\">Alessandro Colasanti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cercignani_M/0/1/0/all/0/1\">Mara Cercignani</a>",
          "description": "Streamlined qBOLD acquisitions enable experimentally straightforward\nobservations of brain oxygen metabolism. $R_2^\\prime$ maps are easily inferred;\nhowever, the Oxygen extraction fraction (OEF) and deoxygenated blood volume\n(DBV) are more ambiguously determined from the data. As such, existing\ninference methods tend to yield very noisy and underestimated OEF maps, while\noverestimating DBV.\n\nThis work describes a novel probabilistic machine learning approach that can\ninfer plausible distributions of OEF and DBV. Initially, we create a model that\nproduces informative voxelwise prior distribution based on synthetic training\ndata. Contrary to prior work, we model the joint distribution of OEF and DBV\nthrough a scaled multivariate logit-Normal distribution, which enables the\nvalues to be constrained within a plausible range. The prior distribution model\nis used to train an efficient amortized variational Bayesian inference model.\nThis model learns to infer OEF and DBV by predicting real image data, with few\ntraining data required, using the signal equations as a forward model.\n\nWe demonstrate that our approach enables the inference of smooth OEF and DBV\nmaps, with a physiologically plausible distribution that can be adapted through\nspecification of an informative prior distribution. Other benefits include\nmodel comparison (via the evidence lower bound) and uncertainty quantification\nfor identifying image artefacts. Results are demonstrated on a small study\ncomparing subjects undergoing hyperventilation and at rest. We illustrate that\nthe proposed approach allows measurement of gray matter differences in OEF and\nDBV and enables voxelwise comparison between conditions, where we observe\nsignificant increases in OEF and $R_2^\\prime$ during hyperventilation.",
          "link": "http://arxiv.org/abs/2203.05845",
          "publishedOn": "2022-04-09T00:48:55.502Z",
          "wordCount": 733,
          "title": "Flexible Amortized Variational Inference in qBOLD MRI. (arXiv:2203.05845v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03132",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zampetakis_M/0/1/0/all/0/1\">Manolis Zampetakis</a>",
          "description": "We consider the problem of computing an equilibrium in a class of nonlinear\ngeneralized Nash equilibrium problems (NGNEPs) in which the strategy sets for\neach player are defined by equality and inequality constraints that may depend\non the choices of rival players. While the asymptotic global convergence and\nlocal convergence rate of solution procedures have been studied in this\nsetting, the analysis of iteration complexity is still in its infancy. Our\ncontribution is to provide two simple first-order algorithmic frameworks based\non the quadratic penalty method and the augmented Lagrangian method,\nrespectively, with an accelerated mirror-prox algorithm as the inner loop. We\nprovide nonasymptotic theoretical guarantees for these algorithms. More\nspecifically, we establish the global convergence rate of our algorithms for\nsolving (strongly) monotone NGNEPs and we provide iteration complexity bounds\nexpressed in terms of the number of gradient evaluations. Experimental results\ndemonstrate the efficiency of our algorithms.",
          "link": "http://arxiv.org/abs/2204.03132",
          "publishedOn": "2022-04-09T00:48:55.494Z",
          "wordCount": 597,
          "title": "First-Order Algorithms for Nonlinear Generalized Nash Equilibrium Problems. (arXiv:2204.03132v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03219",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kao_W/0/1/0/all/0/1\">Wei-Tsung Kao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Mean opinion score (MOS) is a typical subjective evaluation metric for speech\nsynthesis systems. Since collecting MOS is time-consuming, it would be\ndesirable if there are accurate MOS prediction models for automatic evaluation.\nIn this work, we propose DDOS, a novel MOS prediction model. DDOS utilizes\ndomain adaptive pre-training to further pre-train self-supervised learning\nmodels on synthetic speech. And a proposed module is added to model the opinion\nscore distribution of each utterance. With the proposed components, DDOS\noutperforms previous works on BVCC dataset. And the zero shot transfer result\non BC2019 dataset is significantly improved. DDOS also wins second place in\nInterspeech 2022 VoiceMOS challenge in terms of system-level score.",
          "link": "http://arxiv.org/abs/2204.03219",
          "publishedOn": "2022-04-09T00:48:55.487Z",
          "wordCount": 580,
          "title": "DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores. (arXiv:2204.03219v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Unsupervised image-to-image translation aims to learn the translation between\ntwo visual domains without paired data. Despite the recent progress in image\ntranslation models, it remains challenging to build mappings between complex\ndomains with drastic visual discrepancies. In this work, we present a novel\nframework, Generative Prior-guided UNsupervised Image-to-image Translation\n(GP-UNIT), to improve the overall quality and applicability of the translation\nalgorithm. Our key insight is to leverage the generative prior from pre-trained\nclass-conditional GANs (e.g., BigGAN) to learn rich content correspondences\nacross various domains. We propose a novel coarse-to-fine scheme: we first\ndistill the generative prior to capture a robust coarse-level content\nrepresentation that can link objects at an abstract semantic level, based on\nwhich fine-level content features are adaptively learned for more accurate\nmulti-level content correspondences. Extensive experiments demonstrate the\nsuperiority of our versatile framework over state-of-the-art methods in robust,\nhigh-quality and diversified translations, even for challenging and distant\ndomains.",
          "link": "http://arxiv.org/abs/2204.03641",
          "publishedOn": "2022-04-09T00:48:55.479Z",
          "wordCount": 603,
          "title": "Unsupervised Image-to-Image Translation with Generative Prior. (arXiv:2204.03641v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maniati_G/0/1/0/all/0/1\">Georgia Maniati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vioni_A/0/1/0/all/0/1\">Alexandra Vioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikitaras_K/0/1/0/all/0/1\">Karolos Nikitaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klapsas_K/0/1/0/all/0/1\">Konstantinos Klapsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>",
          "description": "In this work, we present the SOMOS dataset, the first large-scale mean\nopinion scores (MOS) dataset consisting of solely neural text-to-speech (TTS)\nsamples. It can be employed to train automatic MOS prediction systems focused\non the assessment of modern synthesizers, and can stimulate advancements in\nacoustic model evaluation. It consists of 20K synthetic utterances of the LJ\nSpeech voice, a public domain speech dataset which is a common benchmark for\nbuilding neural acoustic models and vocoders. Utterances are generated from 200\nTTS systems including vanilla neural acoustic models as well as models which\nallow prosodic variations. An LPCNet vocoder is used for all systems, so that\nthe samples' variation depends only on the acoustic models. The synthesized\nutterances provide balanced and adequate domain and length coverage. We collect\nMOS naturalness evaluations on 3 English Amazon Mechanical Turk locales and\nshare practices leading to reliable crowdsourced annotations for this task.\nBaseline results of state-of-the-art MOS prediction models on the SOMOS dataset\nare presented, while we show the challenges that such models face when assigned\nto evaluate synthetic utterances.",
          "link": "http://arxiv.org/abs/2204.03040",
          "publishedOn": "2022-04-09T00:48:55.456Z",
          "wordCount": 650,
          "title": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis. (arXiv:2204.03040v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03341",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kieu_T/0/1/0/all/0/1\">Tung Kieu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chenjuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_C/0/1/0/all/0/1\">Christian S. Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiteng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Zheng</a>",
          "description": "Time series data occurs widely, and outlier detection is a fundamental\nproblem in data mining, which has numerous applications. Existing\nautoencoder-based approaches deliver state-of-the-art performance on\nchallenging real-world data but are vulnerable to outliers and exhibit low\nexplainability. To address these two limitations, we propose robust and\nexplainable unsupervised autoencoder frameworks that decompose an input time\nseries into a clean time series and an outlier time series using autoencoders.\nImproved explainability is achieved because clean time series are better\nexplained with easy-to-understand patterns such as trends and periodicities. We\nprovide insight into this by means of a post-hoc explainability analysis and\nempirical studies. In addition, since outliers are separated from clean time\nseries iteratively, our approach offers improved robustness to outliers, which\nin turn improves accuracy. We evaluate our approach on five real-world datasets\nand report improvements over the state-of-the-art approaches in terms of\nrobustness and explainability.\n\nThis is an extended version of \"Robust and Explainable Autoencoders for\nUnsupervised Time Series Outlier Detection\", to appear in IEEE ICDE 2022.",
          "link": "http://arxiv.org/abs/2204.03341",
          "publishedOn": "2022-04-09T00:48:55.449Z",
          "wordCount": 627,
          "title": "Robust and Explainable Autoencoders for Unsupervised Time Series Outlier Detection---Extended Version. (arXiv:2204.03341v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.06717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasic_M/0/1/0/all/0/1\">Marko Vasic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrovic_A/0/1/0/all/0/1\">Andrija Petrovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1\">Mladen Nikolic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurshid_S/0/1/0/all/0/1\">Sarfraz Khurshid</a>",
          "description": "Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adoption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to expose the inner workings of the model in a human\nunderstandable form. We present Mo\\\"ET, a novel model based on Mixture of\nExperts, consisting of decision tree experts and a generalized linear model\ngating function. Thanks to such gating function the model is more expressive\nthan the standard decision tree. To support non-differentiable decision trees\nas experts, we formulate a novel training procedure. In addition, we introduce\na hard thresholding version, Mo\\\"ETH, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, Mo\\\"ETH\nallows each prediction to be easily decomposed into a set of logical rules in a\nform which can be easily verified. While Mo\\\"ET is a general use model, we\nillustrate its power in the reinforcement learning setting. By training Mo\\\"ET\nmodels using an imitation learning procedure on deep RL agents we outperform\nthe previous state-of-the-art technique based on decision trees while\npreserving the verifiability of the models. Moreover, we show that Mo\\\"ET can\nalso be used in real-world supervised problems on which it outperforms other\nverifiable machine learning models.",
          "link": "http://arxiv.org/abs/1906.06717",
          "publishedOn": "2022-04-09T00:48:55.442Z",
          "wordCount": 750,
          "title": "Mo\\\"ET: Mixture of Expert Trees and its Application to Verifiable Reinforcement Learning. (arXiv:1906.06717v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.06336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "The Shapley value (SV) and Least core (LC) are classic methods in cooperative\ngame theory for cost/profit sharing problems. Both methods have recently been\nproposed as a principled solution for data valuation tasks, i.e., quantifying\nthe contribution of individual datum in machine learning. However, both SV and\nLC suffer computational challenges due to the need for retraining models on\ncombinatorially many data subsets. In this work, we propose to boost the\nefficiency in computing Shapley value or Least core by learning to estimate the\nperformance of a learning algorithm on unseen data combinations. Theoretically,\nwe derive bounds relating the error in the predicted learning performance to\nthe approximation error in SV and LC. Empirically, we show that the proposed\nmethod can significantly improve the accuracy of SV and LC estimation.",
          "link": "http://arxiv.org/abs/2107.06336",
          "publishedOn": "2022-04-09T00:48:55.433Z",
          "wordCount": 593,
          "title": "Improving Cooperative Game Theory-based Data Valuation via Data Utility Learning. (arXiv:2107.06336v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Nan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Supervised federated learning (FL) enables multiple clients to share the\ntrained model without sharing their labeled data. However, potential clients\nmight even be reluctant to label their own data, which could limit the\napplicability of FL in practice. In this paper, we show the possibility of\nunsupervised FL whose model is still a classifier for predicting class labels,\nif the class-prior probabilities are shifted while the class-conditional\ndistributions are shared among the unlabeled data owned by the clients. We\npropose federation of unsupervised learning (FedUL), where the unlabeled data\nare transformed into surrogate labeled data for each of the clients, a modified\nmodel is trained by supervised FL, and the wanted model is recovered from the\nmodified model. FedUL is a very general solution to unsupervised FL: it is\ncompatible with many supervised FL methods, and the recovery of the wanted\nmodel can be theoretically guaranteed as if the data have been labeled.\nExperiments on benchmark and real-world datasets demonstrate the effectiveness\nof FedUL. Code is available at https://github.com/lunanbit/FedUL.",
          "link": "http://arxiv.org/abs/2204.03304",
          "publishedOn": "2022-04-09T00:48:55.414Z",
          "wordCount": 615,
          "title": "Federated Learning from Only Unlabeled Data with Class-Conditional-Sharing Clients. (arXiv:2204.03304v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Junseok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Yunhak Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+In_Y/0/1/0/all/0/1\">Yeonjun In</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Namkyeong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hyun_D/0/1/0/all/0/1\">Dongmin Hyun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chanyoung Park</a>",
          "description": "Despite the success of Graph Neural Networks (GNNs) on various applications,\nGNNs encounter significant performance degradation when the amount of\nsupervision signals, i.e., number of labeled nodes, is limited, which is\nexpected as GNNs are trained solely based on the supervision obtained from the\nlabeled nodes. On the other hand,recent self-supervised learning paradigm aims\nto train GNNs by solving pretext tasks that do not require any labeled nodes,\nand it has shown to even outperform GNNs trained with few labeled nodes.\nHowever, a major drawback of self-supervised methods is that they fall short of\nlearning class discriminative node representations since no labeled information\nis utilized during training. To this end, we propose a novel semi-supervised\nmethod for graphs, GraFN, that leverages few labeled nodes to ensure nodes that\nbelong to the same class to be grouped together, thereby achieving the best of\nboth worlds of semi-supervised and self-supervised methods. Specifically, GraFN\nrandomly samples support nodes from labeled nodes and anchor nodes from the\nentire graph. Then, it minimizes the difference between two predicted class\ndistributions that are non-parametrically assigned by anchor-supports\nsimilarity from two differently augmented graphs. We experimentally show that\nGraFN surpasses both the semi-supervised and self-supervised methods in terms\nof node classification on real-world graphs. The source code for GraFN is\navailable at https://github.com/Junseok0207/GraFN.",
          "link": "http://arxiv.org/abs/2204.01303",
          "publishedOn": "2022-04-09T00:48:55.406Z",
          "wordCount": 690,
          "title": "GraFN: Semi-Supervised Node Classification on Graph with Few Labels via Non-Parametric Distribution Assignment. (arXiv:2204.01303v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shubin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jianming Deng</a>",
          "description": "Adopting reinforcement learning (RL) for traffic signal control is\nincreasingly popular. Most RL methods use fixed action interval (denoted as\ntduration) and actuate or maintain a phase every tduration, which makes the\nphase duration less dynamic and flexible. In addition, the actuated phase can\nbe arbitrary, affecting the real-world deployment, which requires a fixed\ncyclical phase structure. To address these challenges, we propose a multi-level\ntraffic signal control framework, DynLight, which uses an optimization method\nMax-QueueLength (M-QL) to determine the phase and uses a deep Q-network to\ndetermine the corresponding duration. Based on DynLight, we further propose\nDynLight-C that adopts a well trained deep Q-network of DynLight and replace\nM-QL by a fixed cyclical control policy that actuate a set of phases in fixed\norder to realize cyclical phase structure. Comprehensive experiments on\nmultiple real-world datasets demonstrate that DynLight achives a new\nstate-of-the-art. Furthermore, the deep Q-network of DynLight can learn well on\ndetermining the phase duration and DynLight-C demonstrates high performance for\ndeployment.",
          "link": "http://arxiv.org/abs/2204.03471",
          "publishedOn": "2022-04-09T00:48:55.399Z",
          "wordCount": 615,
          "title": "DynLight: Realize dynamic phase duration with multi-level traffic signal control. (arXiv:2204.03471v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.03398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Narang_A/0/1/0/all/0/1\">Adhyyan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faulkner_E/0/1/0/all/0/1\">Evan Faulkner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drusvyatskiy_D/0/1/0/all/0/1\">Dmitriy Drusvyatskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1\">Lillian J. Ratliff</a>",
          "description": "Learning problems commonly exhibit an interesting feedback mechanism wherein\nthe population data reacts to competing decision makers' actions. This paper\nformulates a new game theoretic framework for this phenomenon, called\n\"multi-player performative prediction\". We focus on two distinct solution\nconcepts, namely (i) performatively stable equilibria and (ii) Nash equilibria\nof the game. The latter equilibria are arguably more informative, but can be\nfound efficiently only when the game is monotone. We show that under mild\nassumptions, the performatively stable equilibria can be found efficiently by a\nvariety of algorithms, including repeated retraining and the repeated\n(stochastic) gradient method. We then establish transparent sufficient\nconditions for strong monotonicity of the game and use them to develop\nalgorithms for finding Nash equilibria. We investigate derivative free methods\nand adaptive gradient algorithms wherein each player alternates between\nlearning a parametric description of their distribution and gradient steps on\nthe empirical risk. Synthetic and semi-synthetic numerical experiments\nillustrate the results.",
          "link": "http://arxiv.org/abs/2201.03398",
          "publishedOn": "2022-04-09T00:48:55.388Z",
          "wordCount": null,
          "title": "Multiplayer Performative Prediction: Learning in Decision-Dependent Games. (arXiv:2201.03398v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03248",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sekimoto_K/0/1/0/all/0/1\">Kaiji Sekimoto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>",
          "description": "Although evaluation of the expectations on the Ising model is essential in\nvarious applications, this is frequently infeasible because of intractable\nmultiple summations (or integrations). Spatial Monte Carlo integration (SMCI)\nis a sampling-based approximation, and can provide high-accuracy estimations\nfor such intractable expectations. To evaluate the expectation of a function of\nvariables in a specific region (called target region), SMCI considers a larger\nregion containing the target region (called sum region). In SMCI, the multiple\nsummation for the variables in the sum region is precisely executed, and that\nin the outer region is evaluated by the sampling approximation such as the\nstandard Monte Carlo integration. It is guaranteed that the accuracy of the\nSMCI estimator is monotonically improved as the size of the sum region\nincreases. However, a haphazard expansion of the sum region could cause a\ncombinatorial explosion. Therefore, we hope to improve the accuracy without\nsuch region expansion. In this study, based on the theory of generalized least\nsquares, a new effective method is proposed by combining multiple SMCI\nestimators. The validity of the proposed method is demonstrated theoretically\nand numerically. The results indicate that the proposed method can be effective\nin the inverse Ising problem (or Boltzmann machine learning).",
          "link": "http://arxiv.org/abs/2204.03248",
          "publishedOn": "2022-04-09T00:48:55.387Z",
          "wordCount": 660,
          "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least Squares. (arXiv:2204.03248v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.06476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyon_F/0/1/0/all/0/1\">Fatih Cagatay Akyon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavusoglu_D/0/1/0/all/0/1\">Devrim Cavusoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cengiz_C/0/1/0/all/0/1\">Cemil Cengiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinuc_S/0/1/0/all/0/1\">Sinan Onur Altinuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Temizel_A/0/1/0/all/0/1\">Alptekin Temizel</a>",
          "description": "While exam-style questions are a fundamental educational tool serving a\nvariety of purposes, manual construction of questions is a complex process that\nrequires training, experience and resources. Automatic question generation (QG)\ntechniques can be utilized to satisfy the need for a continuous supply of new\nquestions by streamlining their generation. However, compared to automatic\nquestion answering (QA), QG is a more challenging task. In this work, we\nfine-tune a multilingual T5 (mT5) transformer in a multi-task setting for QA,\nQG and answer extraction tasks using Turkish QA datasets. To the best of our\nknowledge, this is the first academic work that performs automated text-to-text\nquestion generation from Turkish texts. Experimental evaluations show that the\nproposed multi-task setting achieves state-of-the-art Turkish question\nanswering and question generation performance on TQuADv1, TQuADv2 datasets and\nXQuAD Turkish split. The source code and the pre-trained models are available\nat https://github.com/obss/turkish-question-generation.",
          "link": "http://arxiv.org/abs/2111.06476",
          "publishedOn": "2022-04-09T00:48:55.387Z",
          "wordCount": null,
          "title": "Automated question generation and question answering from Turkish texts. (arXiv:2111.06476v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03193",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "A new data-driven method for operator learning of stochastic differential\nequations(SDE) is proposed in this paper. The central goal is to solve forward\nand inverse stochastic problems more effectively using limited data. Deep\noperator network(DeepONet) has been proposed recently for operator learning.\nCompared to other neural networks to learn functions, it aims at the problem of\nlearning nonlinear operators. However, it can be challenging by using the\noriginal model to learn nonlinear operators for high-dimensional stochastic\nproblems. We propose a new multi-resolution autoencoder DeepONet model referred\nto as MultiAuto-DeepONet to deal with this difficulty with the aid of\nconvolutional autoencoder. The encoder part of the network is designed to\nreduce the dimensionality as well as discover the hidden features of\nhigh-dimensional stochastic inputs. The decoder is designed to have a special\nstructure, i.e. in the form of DeepONet. The first DeepONet in decoder is\ndesigned to reconstruct the input function involving randomness while the\nsecond one is used to approximate the solution of desired equations. Those two\nDeepONets has a common branch net and two independent trunk nets. This\narchitecture enables us to deal with multi-resolution inputs naturally. By\nadding $L_1$ regularization to our network, we found the outputs from the\nbranch net and two trunk nets all have sparse structures. This reduces the\nnumber of trainable parameters in the neural network thus making the model more\nefficient. Finally, we conduct several numerical experiments to illustrate the\neffectiveness of our proposed MultiAuto-DeepONet model with uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2204.03193",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": 705,
          "title": "MultiAuto-DeepONet: A Multi-resolution Autoencoder DeepONet for Nonlinear Dimension Reduction, Uncertainty Quantification and Operator Learning of Forward and Inverse Stochastic Problems. (arXiv:2204.03193v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.01665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grelier_C/0/1/0/all/0/1\">Cyril Grelier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goudet_O/0/1/0/all/0/1\">Olivier Goudet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jin-Kao Hao</a>",
          "description": "This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.",
          "link": "http://arxiv.org/abs/2202.01665",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": null,
          "title": "On Monte Carlo Tree Search for Weighted Vertex Coloring. (arXiv:2202.01665v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gustineli_M/0/1/0/all/0/1\">Murilo Gustineli</a>",
          "description": "Artificial neural networks (ANN), typically referred to as neural networks,\nare a class of Machine Learning algorithms and have achieved widespread\nsuccess, having been inspired by the biological structure of the human brain.\nNeural networks are inherently powerful due to their ability to learn complex\nfunction approximations from data. This generalization ability has been able to\nimpact multidisciplinary areas involving image recognition, speech recognition,\nnatural language processing, and others. Activation functions are a crucial\nsub-component of neural networks. They define the output of a node in the\nnetwork given a set of inputs. This survey discusses the main concepts of\nactivation functions in neural networks, including; a brief introduction to\ndeep neural networks, a summary of what are activation functions and how they\nare used in neural networks, their most common properties, the different types\nof activation functions, some of the challenges, limitations, and alternative\nsolutions faced by activation functions, concluding with the final remarks.",
          "link": "http://arxiv.org/abs/2204.02921",
          "publishedOn": "2022-04-09T00:48:55.379Z",
          "wordCount": null,
          "title": "A survey on recently proposed activation functions for Deep Learning. (arXiv:2204.02921v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03495",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Principal component analysis (PCA) is a dimensionality reduction method in\ndata analysis that involves diagonalizing the covariance matrix of the dataset.\nRecently, quantum algorithms have been formulated for PCA based on\ndiagonalizing a density matrix. These algorithms assume that the covariance\nmatrix can be encoded in a density matrix, but a concrete protocol for this\nencoding has been lacking. Our work aims to address this gap. Assuming\namplitude encoding of the data, with the data given by the ensemble $\\{p_i,|\n\\psi_i \\rangle\\}$, then one can easily prepare the ensemble average density\nmatrix $\\overline{\\rho} = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i |$. We first\nshow that $\\overline{\\rho}$ is precisely the covariance matrix whenever the\ndataset is centered. For quantum datasets, we exploit global phase symmetry to\nargue that there always exists a centered dataset consistent with\n$\\overline{\\rho}$, and hence $\\overline{\\rho}$ can always be interpreted as a\ncovariance matrix. This provides a simple means for preparing the covariance\nmatrix for arbitrary quantum datasets or centered classical datasets. For\nuncentered classical datasets, our method is so-called \"PCA without centering\",\nwhich we interpret as PCA on a symmetrized dataset. We argue that this closely\ncorresponds to standard PCA, and we derive equations and inequalities that\nbound the deviation of the spectrum obtained with our method from that of\nstandard PCA. We numerically illustrate our method for the MNIST handwritten\ndigit dataset. We also argue that PCA on quantum datasets is natural and\nmeaningful, and we numerically implement our method for molecular ground-state\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03495",
          "publishedOn": "2022-04-09T00:48:55.370Z",
          "wordCount": null,
          "title": "Covariance matrix preparation for quantum principal component analysis. (arXiv:2204.03495v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadi_M/0/1/0/all/0/1\">Mohammad Abdul Hadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_I/0/1/0/all/0/1\">Imam Nur Bani Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thung_F/0/1/0/all/0/1\">Ferdian Thung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_K/0/1/0/all/0/1\">Kien Gia Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lingxiao_J/0/1/0/all/0/1\">Jiang Lingxiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fard_F/0/1/0/all/0/1\">Fatemeh H. Fard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1\">David Lo</a>",
          "description": "Developers frequently use APIs to implement certain functionalities, such as\nparsing Excel Files, reading and writing text files line by line, etc.\nDevelopers can greatly benefit from automatic API usage sequence generation\nbased on natural language queries for building applications in a faster and\ncleaner manner. Existing approaches utilize information retrieval models to\nsearch for matching API sequences given a query or use RNN-based\nencoder-decoder to generate API sequences. As it stands, the first approach\ntreats queries and API names as bags of words. It lacks deep comprehension of\nthe semantics of the queries. The latter approach adapts a neural language\nmodel to encode a user query into a fixed-length context vector and generate\nAPI sequences from the context vector.\n\nWe want to understand the effectiveness of recent Pre-trained Transformer\nbased Models (PTMs) for the API learning task. These PTMs are trained on large\nnatural language corpora in an unsupervised manner to retain contextual\nknowledge about the language and have found success in solving similar Natural\nLanguage Processing (NLP) problems. However, the applicability of PTMs has not\nyet been explored for the API sequence generation task. We use a dataset that\ncontains 7 million annotations collected from GitHub to evaluate the PTMs\nempirically. This dataset was also used to assess previous approaches. Based on\nour results, PTMs generate more accurate API sequences and outperform other\nrelated methods by around 11%. We have also identified two different\ntokenization approaches that can contribute to a significant boost in PTMs'\nperformance for the API sequence generation task.",
          "link": "http://arxiv.org/abs/2204.03498",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "On the Effectiveness of Pretrained Models for API Learning. (arXiv:2204.03498v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_W/0/1/0/all/0/1\">Wai Weng Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Layeghy_S/0/1/0/all/0/1\">Siamak Layeghy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarhan_M/0/1/0/all/0/1\">Mohanad Sarhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1\">Marcus Gallagher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portmann_M/0/1/0/all/0/1\">Marius Portmann</a>",
          "description": "This paper presents a new Android malware detection method based on Graph\nNeural Networks (GNNs) with Jumping-Knowledge (JK). Android function call\ngraphs (FCGs) consist of a set of program functions and their inter-procedural\ncalls. Thus, this paper proposes a GNN-based method for Android malware\ndetection by capturing meaningful intra-procedural call path patterns. In\naddition, a Jumping-Knowledge technique is applied to minimize the effect of\nthe over-smoothing problem, which is common in GNNs. The proposed method has\nbeen extensively evaluated using two benchmark datasets. The results\ndemonstrate the superiority of our approach compared to state-of-the-art\napproaches in terms of key classification metrics, which demonstrates the\npotential of GNNs in Android malware detection and classification.",
          "link": "http://arxiv.org/abs/2201.07537",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "Graph Neural Network-based Android Malware Classification with Jumping Knowledge. (arXiv:2201.07537v5 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shirvanimoghaddam_M/0/1/0/all/0/1\">Mahyar Shirvanimoghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yifeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_A/0/1/0/all/0/1\">Aradhika Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salari_A/0/1/0/all/0/1\">Ayoob Salari</a>",
          "description": "In this paper, we consider the federated learning (FL) problem in the\npresence of communication errors. We model the link between the devices and the\ncentral node (CN) by a packet erasure channel, where the local parameters from\ndevices are either erased or received correctly by CN with probability $e$ and\n$1-e$, respectively. We provide mathematical proof for the convergence of the\nFL algorithm in the presence of communication errors, where the CN uses past\nlocal updates when the fresh updates are not received from some devices. We\nshow via simulations that by using the past local updates, the FL algorithm can\nconverge in the presence of communication errors. We also show that when the\ndataset is uniformly distributed among devices, the FL algorithm that only uses\nfresh updates and discards missing updates might converge faster than the FL\nalgorithm that uses past local updates.",
          "link": "http://arxiv.org/abs/2201.12991",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "Federated Learning with Erroneous Communication Links. (arXiv:2201.12991v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1\">Peter Washington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutlu_C/0/1/0/all/0/1\">Cezmi Mutlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kline_A/0/1/0/all/0/1\">Aaron Kline</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_C/0/1/0/all/0/1\">Cathy Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunlap_K/0/1/0/all/0/1\">Kaitlyn Dunlap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kent_J/0/1/0/all/0/1\">Jack Kent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Husic_A/0/1/0/all/0/1\">Arman Husic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stockham_N/0/1/0/all/0/1\">Nate Stockham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chrisman_B/0/1/0/all/0/1\">Brianna Chrisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paskov_K/0/1/0/all/0/1\">Kelley Paskov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jae-Yoon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wall_D/0/1/0/all/0/1\">Dennis P. Wall</a>",
          "description": "Some of the most severe bottlenecks preventing widespread development of\nmachine learning models for human behavior include a dearth of labeled training\ndata and difficulty of acquiring high quality labels. Active learning is a\nparadigm for using algorithms to computationally select a useful subset of data\npoints to label using metrics for model uncertainty and data similarity. We\nexplore active learning for naturalistic computer vision emotion data, a\nparticularly heterogeneous and complex data space due to inherently subjective\nlabels. Using frames collected from gameplay acquired from a therapeutic\nsmartphone game for children with autism, we run a simulation of active\nlearning using gameplay prompts as metadata to aid in the active learning\nprocess. We find that active learning using information generated during\ngameplay slightly outperforms random selection of the same number of labeled\nframes. We next investigate a method to conduct active learning with subjective\ndata, such as in affective computing, and where multiple crowdsourced labels\ncan be acquired for each image. Using the Child Affective Facial Expression\n(CAFE) dataset, we simulate an active learning process for crowdsourcing many\nlabels and find that prioritizing frames using the entropy of the crowdsourced\nlabel distribution results in lower categorical cross-entropy loss compared to\nrandom frame selection. Collectively, these results demonstrate pilot\nevaluations of two novel active learning approaches for subjective affective\ndata collected in noisy settings.",
          "link": "http://arxiv.org/abs/2204.01915",
          "publishedOn": "2022-04-09T00:48:55.369Z",
          "wordCount": null,
          "title": "An Exploration of Active Learning for Affective Digital Phenotyping. (arXiv:2204.01915v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.02700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shia_E/0/1/0/all/0/1\">Ensheng Shia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongbin Sun</a>",
          "description": "Commit messages concisely describe the content of code diffs (i.e., code\nchanges) and the intent behind them. Recently, many approaches have been\nproposed to generate commit messages automatically. The information\nretrieval-based methods reuse the commit messages of similar code diffs, while\nthe neural-based methods learn the semantic connection between code diffs and\ncommit messages. However, the reused commit messages might not accurately\ndescribe the content/intent of code diffs and neural-based methods tend to\ngenerate high-frequent and repetitive tokens in the corpus. In this paper, we\ncombine the advantages of the two technical routes and propose a novel\nexemplar-based neural commit message generation model, which treats the similar\ncommit message as an exemplar and leverages it to guide the neural network\nmodel to generate an accurate commit message. We perform extensive experiments\nand the results confirm the effectiveness of our model.",
          "link": "http://arxiv.org/abs/2203.02700",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "ECMG: Exemplar-based Commit Message Generation. (arXiv:2203.02700v2 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.01543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naser_M/0/1/0/all/0/1\">M.Z. Naser</a>",
          "description": "Much of our experiments are designed to uncover the cause(s) and effect(s)\nbehind a data generating mechanism (i.e., phenomenon) we happen to be\ninterested in. Uncovering such relationships allows us to identify the true\nworking of a phenomenon and, most importantly, articulate a model that may\nenable us to further explore the phenomenon on hand and/or allow us to predict\nit accurately. Fundamentally, such models are likely to be derived via a causal\napproach (as opposed to an observational or empirical mean). In this approach,\ncausal discovery is required to create a causal model, which can then be\napplied to infer the influence of interventions, and answer any hypothetical\nquestions (i.e., in the form of What ifs? Etc.) that we might have. This paper\nbuilds a case for causal discovery and causal inference and contrasts that\nagainst traditional machine learning approaches; all from a civil and\nstructural engineering perspective. More specifically, this paper outlines the\nkey principles of causality and the most commonly used algorithms and packages\nfor causal discovery and causal inference. Finally, this paper also presents a\nseries of examples and case studies of how causal concepts can be adopted for\nour domain.",
          "link": "http://arxiv.org/abs/2204.01543",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "Causality, Causal Discovery, and Causal Inference in Structural Engineering. (arXiv:2204.01543v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langet_N/0/1/0/all/0/1\">Nad&#xe8;ge Langet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>",
          "description": "One of the latest self-supervised learning (SSL) methods, VICReg, showed a\ngreat performance both in the linear evaluation and the fine-tuning evaluation.\nHowever, VICReg is proposed in computer vision and it learns by pulling\nrepresentations of random crops of an image while maintaining the\nrepresentation space by the variance and covariance loss. However, VICReg would\nbe ineffective on non-stationary time series where different parts/crops of\ninput should be differently encoded to consider the non-stationarity. Another\nrecent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for\nencoding non-stationary time series. This study shows that a combination of a\nVICReg-style method and TNC is very effective for SSL on non-stationary time\nseries, where a non-stationary seismic signal time series is used as an\nevaluation dataset.",
          "link": "http://arxiv.org/abs/2204.02697",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verdecchia_R/0/1/0/all/0/1\">Roberto Verdecchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1\">Lu&#xed;s Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sallou_J/0/1/0/all/0/1\">June Sallou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Michelle Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wickenden_J/0/1/0/all/0/1\">James Wickenden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotellier_E/0/1/0/all/0/1\">Estelle Hotellier</a>",
          "description": "With the growing availability of large-scale datasets, and the popularization\nof affordable storage and computational capabilities, the energy consumed by AI\nis becoming a growing concern. To address this issue, in recent years, studies\nhave focused on demonstrating how AI energy efficiency can be improved by\ntuning the model training strategy. Nevertheless, how modifications applied to\ndatasets can impact the energy consumption of AI is still an open question. To\nfill this gap, in this exploratory study, we evaluate if data-centric\napproaches can be utilized to improve AI energy efficiency. To achieve our\ngoal, we conduct an empirical experiment, executed by considering 6 different\nAI algorithms, a dataset comprising 5,574 data points, and two dataset\nmodifications (number of data points and number of features). Our results show\nevidence that, by exclusively conducting modifications on datasets, energy\nconsumption can be drastically reduced (up to 92.16%), often at the cost of a\nnegligible or even absent accuracy decline. As additional introductory results,\nwe demonstrate how, by exclusively changing the algorithm used, energy savings\nup to two orders of magnitude can be achieved. In conclusion, this exploratory\ninvestigation empirically demonstrates the importance of applying data-centric\ntechniques to improve AI energy efficiency. Our results call for a research\nagenda that focuses on data-centric techniques, to further enable and\ndemocratize Green AI.",
          "link": "http://arxiv.org/abs/2204.02766",
          "publishedOn": "2022-04-09T00:48:55.368Z",
          "wordCount": null,
          "title": "Data-Centric Green AI: An Exploratory Empirical Study. (arXiv:2204.02766v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.03706",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1\">Pratik Ramprasad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yuantong Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1\">Guang Cheng</a>",
          "description": "The recent emergence of reinforcement learning has created a demand for\nrobust statistical inference methods for the parameter estimates computed using\nthese algorithms. Existing methods for statistical inference in online learning\nare restricted to settings involving independently sampled observations, while\nexisting statistical inference methods in reinforcement learning (RL) are\nlimited to the batch setting. The online bootstrap is a flexible and efficient\napproach for statistical inference in linear stochastic approximation\nalgorithms, but its efficacy in settings involving Markov noise, such as RL,\nhas yet to be explored. In this paper, we study the use of the online bootstrap\nmethod for statistical inference in RL. In particular, we focus on the temporal\ndifference (TD) learning and Gradient TD (GTD) learning algorithms, which are\nthemselves special instances of linear stochastic approximation under Markov\nnoise. The method is shown to be distributionally consistent for statistical\ninference in policy evaluation, and numerical experiments are included to\ndemonstrate the effectiveness of this algorithm at statistical inference tasks\nacross a range of real RL environments.",
          "link": "http://arxiv.org/abs/2108.03706",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning. (arXiv:2108.03706v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.00185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Matthew S. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Animesh Garg</a>",
          "description": "Policy gradient methods have been frequently applied to problems in control\nand reinforcement learning with great success, yet existing convergence\nanalysis still relies on non-intuitive, impractical and often opaque\nconditions. In particular, existing rates are achieved in limited settings,\nunder strict regularity conditions. In this work, we establish explicit\nconvergence rates of policy gradient methods, extending the convergence regime\nto weakly smooth policy classes with $L_2$ integrable gradient. We provide\nintuitive examples to illustrate the insight behind these new conditions.\nNotably, our analysis also shows that convergence rates are achievable for both\nthe standard policy gradient and the natural policy gradient algorithms under\nthese assumptions. Lastly we provide performance guarantees for the converged\npolicies.",
          "link": "http://arxiv.org/abs/2111.00185",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth Settings. (arXiv:2111.00185v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozumnyi_D/0/1/0/all/0/1\">Denys Rozumnyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1\">Martin R. Oswald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrari_V/0/1/0/all/0/1\">Vittorio Ferrari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We propose a method for jointly estimating the 3D motion, 3D shape, and\nappearance of highly motion-blurred objects from a video. To this end, we model\nthe blurred appearance of a fast moving object in a generative fashion by\nparametrizing its 3D position, rotation, velocity, acceleration, bounces,\nshape, and texture over the duration of a predefined time window spanning\nmultiple frames. Using differentiable rendering, we are able to estimate all\nparameters by minimizing the pixel-wise reprojection error to the input video\nvia backpropagating through a rendering pipeline that accounts for motion blur\nby averaging the graphics output over short time intervals. For that purpose,\nwe also estimate the camera exposure gap time within the same optimization. To\naccount for abrupt motion changes like bounces, we model the motion trajectory\nas a piece-wise polynomial, and we are able to estimate the specific time of\nthe bounce at sub-frame accuracy. Experiments on established benchmark datasets\ndemonstrate that our method outperforms previous methods for fast moving object\ndeblurring and 3D reconstruction.",
          "link": "http://arxiv.org/abs/2111.14465",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Motion-from-Blur: 3D Shape and Motion Estimation of Motion-blurred Objects in Videos. (arXiv:2111.14465v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04175",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Elmas_G/0/1/0/all/0/1\">Gokberk Elmas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dar_S/0/1/0/all/0/1\">Salman UH Dar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korkmaz_Y/0/1/0/all/0/1\">Yilmaz Korkmaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ceyani_E/0/1/0/all/0/1\">Emir Ceyani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Susam_B/0/1/0/all/0/1\">Burak Susam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozbey_M/0/1/0/all/0/1\">Muzaffer &#xd6;zbey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cukur_T/0/1/0/all/0/1\">Tolga &#xc7;ukur</a>",
          "description": "Multi-institutional efforts can facilitate training of deep MRI\nreconstruction models, albeit privacy risks arise during cross-site sharing of\nimaging data. Federated learning (FL) has recently been introduced to address\nprivacy concerns by enabling distributed training without transfer of imaging\ndata. Existing FL methods for MRI reconstruction employ conditional models to\nmap from undersampled to fully-sampled acquisitions via explicit knowledge of\nthe imaging operator. Since conditional models generalize poorly across\ndifferent acceleration rates or sampling densities, imaging operators must be\nfixed between training and testing, and they are typically matched across\nsites. To improve generalization and flexibility in multi-institutional\ncollaborations, here we introduce a novel method for MRI reconstruction based\non Federated learning of Generative IMage Priors (FedGIMP). FedGIMP leverages a\ntwo-stage approach: cross-site learning of a generative MRI prior, and\nsubject-specific injection of the imaging operator. The global MRI prior is\nlearned via an unconditional adversarial model that synthesizes high-quality MR\nimages based on latent variables. Specificity in the prior is preserved via a\nmapper subnetwork that produces site-specific latents. During inference, the\nprior is combined with subject-specific imaging operators to enable\nreconstruction, and further adapted to individual test samples by minimizing\ndata-consistency loss. Comprehensive experiments on multi-institutional\ndatasets clearly demonstrate enhanced generalization performance of FedGIMP\nagainst site-specific and federated methods based on conditional models, as\nwell as traditional reconstruction methods.",
          "link": "http://arxiv.org/abs/2202.04175",
          "publishedOn": "2022-04-09T00:48:55.367Z",
          "wordCount": null,
          "title": "Federated Learning of Generative Image Priors for MRI Reconstruction. (arXiv:2202.04175v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.12800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Solaiyappan_S/0/1/0/all/0/1\">Siddharth Solaiyappan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>",
          "description": "Deep generative networks in recent years have reinforced the need for caution\nwhile consuming various modalities of digital information. One avenue of\ndeepfake creation is aligned with injection and removal of tumors from medical\nscans. Failure to detect medical deepfakes can lead to large setbacks on\nhospital resources or even loss of life. This paper attempts to address the\ndetection of such attacks with a structured case study. Specifically, we\nevaluate eight different machine learning algorithms, which including three\nconventional machine learning methods, support vector machine, random forest,\ndecision tree, and five deep learning models, DenseNet121, DenseNet201,\nResNet50, ResNet101, VGG19, on distinguishing between tampered and untampered\nimages.For deep learning models, the five models are used for feature\nextraction, then fine-tune for each pre-trained model is performed. The\nfindings of this work show near perfect accuracy in detecting instances of\ntumor injections and removals.",
          "link": "http://arxiv.org/abs/2109.12800",
          "publishedOn": "2022-04-09T00:48:55.366Z",
          "wordCount": null,
          "title": "Machine Learning based Medical Image Deepfake Detection: A Comparative Study. (arXiv:2109.12800v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellano_A/0/1/0/all/0/1\">Agustin Castellano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_H/0/1/0/all/0/1\">Hancheng Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazerque_J/0/1/0/all/0/1\">Juan Bazerque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallada_E/0/1/0/all/0/1\">Enrique Mallada</a>",
          "description": "In this work we address the problem of finding feasible policies for\nConstrained Markov Decision Processes under probability one constraints. We\nargue that stationary policies are not sufficient for solving this problem, and\nthat a rich class of policies can be found by endowing the controller with a\nscalar quantity, so called budget, that tracks how close the agent is to\nviolating the constraint. We show that the minimal budget required to act\nsafely can be obtained as the smallest fixed point of a Bellman-like operator,\nfor which we analyze its convergence properties. We also show how to learn this\nquantity when the true kernel of the Markov decision process is not known,\nwhile providing sample-complexity bounds. The utility of knowing this minimal\nbudget relies in that it can aid in the search of optimal or near-optimal\npolicies by shrinking down the region of the state space the agent must\nnavigate. Simulations illustrate the different nature of probability one\nconstraints against the typically used constraints in expectation.",
          "link": "http://arxiv.org/abs/2112.05198",
          "publishedOn": "2022-04-09T00:48:55.365Z",
          "wordCount": null,
          "title": "Reinforcement Learning with Almost Sure Constraints. (arXiv:2112.05198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.11200",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kwak_Y/0/1/0/all/0/1\">Yunseok Kwak</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Yun_W/0/1/0/all/0/1\">Won Joon Yun</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Jae Pyoung Kim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cho_H/0/1/0/all/0/1\">Hyunhee Cho</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jung_S/0/1/0/all/0/1\">Soyi Jung</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Joongheon Kim</a>",
          "description": "Although deep learning (DL) has already become a state-of-the-art technology\nfor various data processing tasks, data security and computational overload\nproblems often arise due to their high data and computational power dependency.\nTo solve this problem, quantum deep learning (QDL) and distributed deep\nlearning (DDL) has emerged to complement existing DL methods. Furthermore, a\nquantum distributed deep learning (QDDL) technique that combines and maximizes\nthese advantages is getting attention. This paper compares several model\nstructures for QDDL and discusses their possibilities and limitations to\nleverage QDDL for some representative application scenarios.",
          "link": "http://arxiv.org/abs/2202.11200",
          "publishedOn": "2022-04-09T00:48:55.365Z",
          "wordCount": null,
          "title": "Quantum Distributed Deep Learning Architectures: Models, Discussions, and Applications. (arXiv:2202.11200v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.15783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Clustering algorithms partition a dataset into groups of similar points. The\nprimary contribution of this article is the Multiscale Spatially-Regularized\nDiffusion Learning (M-SRDL) clustering algorithm, which uses\nspatially-regularized diffusion distances to efficiently and accurately learn\nmultiple scales of latent structure in hyperspectral images. The M-SRDL\nclustering algorithm extracts clusterings at many scales from a hyperspectral\nimage and outputs these clusterings' variation of information-barycenter as an\nexemplar for all underlying cluster structure. We show that incorporating\nspatial regularization into a multiscale clustering framework results in\nsmoother and more coherent clusters when applied to hyperspectral data,\nyielding more accurate clustering labels.",
          "link": "http://arxiv.org/abs/2103.15783",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial Diffusion Geometry. (arXiv:2103.15783v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.02375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Praveer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1\">Jayashree Kalpathy-Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Federated learning is an emerging research paradigm for enabling\ncollaboratively training deep learning models without sharing patient data.\nHowever, the data from different institutions are usually heterogeneous across\ninstitutions, which may reduce the performance of models trained using\nfederated learning. In this study, we propose a novel heterogeneity-aware\nfederated learning method, SplitAVG, to overcome the performance drops from\ndata heterogeneity in federated learning. Unlike previous federated methods\nthat require complex heuristic training or hyper parameter tuning, our SplitAVG\nleverages the simple network split and feature map concatenation strategies to\nencourage the federated model training an unbiased estimator of the target data\ndistribution. We compare SplitAVG with seven state-of-the-art federated\nlearning methods, using centrally hosted training data as the baseline on a\nsuite of both synthetic and real-world federated datasets. We find that the\nperformance of models trained using all the comparison federated learning\nmethods degraded significantly with the increasing degrees of data\nheterogeneity. In contrast, SplitAVG method achieves comparable results to the\nbaseline method under all heterogeneous settings, that it achieves 96.2% of the\naccuracy and 110.4% of the mean absolute error obtained by the baseline in a\ndiabetic retinopathy binary classification dataset and a bone age prediction\ndataset, respectively, on highly heterogeneous data partitions. We conclude\nthat SplitAVG method can effectively overcome the performance drops from\nvariability in data distributions across institutions. Experimental results\nalso show that SplitAVG can be adapted to different base networks and\ngeneralized to various types of medical imaging tasks.",
          "link": "http://arxiv.org/abs/2107.02375",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "SplitAVG: A heterogeneity-aware federated deep learning method for medical imaging. (arXiv:2107.02375v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_T/0/1/0/all/0/1\">Tristan Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Edward J. Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_S/0/1/0/all/0/1\">Salem Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Mo Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.",
          "link": "http://arxiv.org/abs/2111.09266",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "GFlowNet Foundations. (arXiv:2111.09266v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zechun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1\">Kwang-Ting Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqiang Shen</a>",
          "description": "The nonuniform quantization strategy for compressing neural networks usually\nachieves better performance than its counterpart, i.e., uniform strategy, due\nto its superior representational capacity. However, many nonuniform\nquantization methods overlook the complicated projection process in\nimplementing the nonuniformly quantized weights/activations, which incurs\nnon-negligible time and space overhead in hardware deployment. In this study,\nwe propose Nonuniform-to-Uniform Quantization (N2UQ), a method that can\nmaintain the strong representation ability of nonuniform methods while being\nhardware-friendly and efficient as the uniform quantization for model\ninference. We achieve this through learning the flexible in-equidistant input\nthresholds to better fit the underlying distribution while quantizing these\nreal-valued inputs into equidistant output levels. To train the quantized\nnetwork with learnable input thresholds, we introduce a generalized\nstraight-through estimator (G-STE) for intractable backward derivative\ncalculation w.r.t. threshold parameters. Additionally, we consider entropy\npreserving regularization to further reduce information loss in weight\nquantization. Even under this adverse constraint of imposing uniformly\nquantized weights and activations, our N2UQ outperforms state-of-the-art\nnonuniform quantization methods by 0.5~1.7 on ImageNet, demonstrating the\ncontribution of N2UQ design. Code and models are available at:\nhttps://github.com/liuzechun/Nonuniform-to-Uniform-Quantization.",
          "link": "http://arxiv.org/abs/2111.14826",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation. (arXiv:2111.14826v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinozaki_T/0/1/0/all/0/1\">Takahiro Shinozaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>",
          "description": "The long-tailed class distribution in visual recognition tasks poses great\nchallenges for neural networks on how to handle the biased predictions between\nhead and tail classes, i.e., the model tends to classify tail classes as head\nclasses. While existing research focused on data resampling and loss function\nengineering, in this paper, we take a different perspective: the classification\nmargins. We study the relationship between the margins and logits\n(classification scores) and empirically observe the biased margins and the\nbiased logits are positively correlated. We propose MARC, a simple yet\neffective MARgin Calibration function to dynamically calibrate the biased\nmargins for unbiased logits. We validate MARC through extensive experiments on\ncommon long-tailed benchmarks including CIFAR-LT, ImageNet-LT, Places-LT, and\niNaturalist-LT. Experimental results demonstrate that our MARC achieves\nfavorable results on these benchmarks. In addition, MARC is extremely easy to\nimplement with just three lines of code. We hope this simple method will\nmotivate people to rethink the biased margins and biased logits in long-tailed\nvisual recognition.",
          "link": "http://arxiv.org/abs/2112.07225",
          "publishedOn": "2022-04-09T00:48:55.364Z",
          "wordCount": null,
          "title": "Margin Calibration for Long-Tailed Visual Recognition. (arXiv:2112.07225v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akyon_F/0/1/0/all/0/1\">Fatih Cagatay Akyon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altinuc_S/0/1/0/all/0/1\">Sinan Onur Altinuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Temizel_A/0/1/0/all/0/1\">Alptekin Temizel</a>",
          "description": "Detection of small objects and objects far away in the scene is a major\nchallenge in surveillance applications. Such objects are represented by small\nnumber of pixels in the image and lack sufficient details, making them\ndifficult to detect using conventional detectors. In this work, an open-source\nframework called Slicing Aided Hyper Inference (SAHI) is proposed that provides\na generic slicing aided inference and fine-tuning pipeline for small object\ndetection. The proposed technique is generic in the sense that it can be\napplied on top of any available object detector without any fine-tuning.\nExperimental evaluations, using object detection baselines on the Visdrone and\nxView aerial object detection datasets show that the proposed inference method\ncan increase object detection AP by 6.8%, 5.1% and 5.3% for FCOS, VFNet and\nTOOD detectors, respectively. Moreover, the detection accuracy can be further\nincreased with a slicing aided fine-tuning, resulting in a cumulative increase\nof 12.7%, 13.4% and 14.5% AP in the same order. Proposed technique has been\nintegrated with Detectron2, MMDetection and YOLOv5 models and it is publicly\navailable at https://github.com/obss/sahi.git .",
          "link": "http://arxiv.org/abs/2202.06934",
          "publishedOn": "2022-04-09T00:48:55.363Z",
          "wordCount": null,
          "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection. (arXiv:2202.06934v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05774",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yunhan Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1\">Quanyan Zhu</a>",
          "description": "In this work, we study the deception of a Linear-Quadratic-Gaussian (LQG)\nagent by manipulating the cost signals. We show that a small falsification of\nthe cost parameters will only lead to a bounded change in the optimal policy.\nThe bound is linear on the amount of falsification the attacker can apply to\nthe cost parameters. We propose an attack model where the attacker aims to\nmislead the agent into learning a `nefarious' policy by intentionally\nfalsifying the cost parameters. We formulate the attack's problem as a convex\noptimization problem and develop necessary and sufficient conditions to check\nthe achievability of the attacker's goal.\n\nWe showcase the adversarial manipulation on two types of LQG learners: the\nbatch RL learner and the other is the adaptive dynamic programming (ADP)\nlearner. Our results demonstrate that with only 2.296% of falsification on the\ncost data, the attacker misleads the batch RL into learning the 'nefarious'\npolicy that leads the vehicle to a dangerous position. The attacker can also\ngradually trick the ADP learner into learning the same `nefarious' policy by\nconsistently feeding the learner a falsified cost signal that stays close to\nthe actual cost signal. The paper aims to raise people's awareness of the\nsecurity threats faced by RL-enabled control systems.",
          "link": "http://arxiv.org/abs/2203.05774",
          "publishedOn": "2022-04-09T00:48:55.363Z",
          "wordCount": null,
          "title": "Reinforcement Learning for Linear Quadratic Control is Vulnerable Under Cost Manipulation. (arXiv:2203.05774v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.05113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kao_W/0/1/0/all/0/1\">Wei-Tsung Kao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Recently, adapting the idea of self-supervised learning (SSL) on continuous\nspeech has started gaining attention. SSL models pre-trained on a huge amount\nof unlabeled audio can generate general-purpose representations that benefit a\nwide variety of speech processing tasks. Despite their ubiquitous deployment,\nhowever, the potential privacy risks of these models have not been well\ninvestigated. In this paper, we present the first privacy analysis on several\nSSL speech models using Membership Inference Attacks (MIA) under black-box\naccess. The experiment results show that these pre-trained models are\nvulnerable to MIA and prone to membership information leakage with high Area\nUnder the Curve (AUC) in both utterance-level and speaker-level. Furthermore,\nwe also conduct several ablation studies to understand the factors that\ncontribute to the success of MIA.",
          "link": "http://arxiv.org/abs/2111.05113",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Membership Inference Attacks Against Self-supervised Speech Models. (arXiv:2111.05113v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bellinger_C/0/1/0/all/0/1\">Colin Bellinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drozdyuk_A/0/1/0/all/0/1\">Andriy Drozdyuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1\">Isaac Tamblyn</a>",
          "description": "The use of reinforcement learning (RL) in scientific applications, such as\nmaterials design and automated chemistry, is increasing. A major challenge,\nhowever, lies in fact that measuring the state of the system is often costly\nand time consuming in scientific applications, whereas policy learning with RL\nrequires a measurement after each time step. In this work, we make the\nmeasurement costs explicit in the form of a costed reward and propose a\nframework that enables off-the-shelf deep RL algorithms to learn a policy for\nboth selecting actions and determining whether or not to measure the current\nstate of the system at each time step. In this way, the agents learn to balance\nthe need for information with the cost of information. Our results show that\nwhen trained under this regime, the Dueling DQN and PPO agents can learn\noptimal action policies whilst making up to 50\\% fewer state measurements, and\nrecurrent neural networks can produce a greater than 50\\% reduction in\nmeasurements. We postulate the these reduction can help to lower the barrier to\napplying RL to real-world scientific applications.",
          "link": "http://arxiv.org/abs/2112.07535",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Scientific Discovery and the Cost of Measurement -- Balancing Information and Cost in Reinforcement Learning. (arXiv:2112.07535v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Donghwan Lee</a>",
          "description": "The goal of this paper is to investigate a control theoretic analysis of\nlinear stochastic iterative algorithm and temporal difference (TD) learning.\nTD-learning is a linear stochastic iterative algorithm to estimate the value\nfunction of a given policy for a Markov decision process, which is one of the\nmost popular and fundamental reinforcement learning algorithms. While there has\nbeen a series of successful works in theoretical analysis of TD-learning, it\nwas not until recently that researchers found some guarantees on its\nstatistical efficiency. In this paper, we propose a control theoretic\nfinite-time analysis TD-learning, which exploits standard notions in linear\nsystem control communities. Therefore, the proposed work provides additional\ninsights on TD-learning and reinforcement learning with simple concepts and\nanalysis tools in control theory.",
          "link": "http://arxiv.org/abs/2112.14417",
          "publishedOn": "2022-04-09T00:48:55.362Z",
          "wordCount": null,
          "title": "Control Theoretic Analysis of Temporal Difference Learning. (arXiv:2112.14417v4 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_C/0/1/0/all/0/1\">Carl Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>",
          "description": "The goal of imitation learning is to mimic expert behavior from\ndemonstrations, without access to an explicit reward signal. A popular class of\napproach infers the (unknown) reward function via inverse reinforcement\nlearning (IRL) followed by maximizing this reward function via reinforcement\nlearning (RL). The policies learned via these approaches are however very\nbrittle in practice and deteriorate quickly even with small test-time\nperturbations due to compounding errors. We propose Imitation with Planning at\nTest-time (IMPLANT), a new meta-algorithm for imitation learning that utilizes\ndecision-time planning to correct for compounding errors of any base imitation\npolicy. In contrast to existing approaches, we retain both the imitation policy\nand the rewards model at decision-time, thereby benefiting from the learning\nsignal of the two components. Empirically, we demonstrate that IMPLANT\nsignificantly outperforms benchmark imitation learning approaches on standard\ncontrol environments and excels at zero-shot generalization when subject to\nchallenging perturbations in test-time dynamics.",
          "link": "http://arxiv.org/abs/2204.03597",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning. (arXiv:2204.03597v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>",
          "description": "Representations of the world environment play a crucial role in artificial\nintelligence. It is often inefficient to conduct reasoning and inference\ndirectly in the space of raw sensory representations, such as pixel values of\nimages. Representation learning allows us to automatically discover suitable\nrepresentations from raw sensory data. For example, given raw sensory data, a\ndeep neural network learns nonlinear representations at its hidden layers,\nwhich are subsequently used for classification at its output layer. This\nhappens implicitly during training through minimizing a supervised or\nunsupervised loss. In this paper, we study the dynamics of such implicit\nnonlinear representation learning. We identify a pair of a new assumption and a\nnovel condition, called the common model structure assumption and the\ndata-architecture alignment condition. Under the common model structure\nassumption, the data-architecture alignment condition is shown to be sufficient\nfor the global convergence and necessary for the global optimality. Moreover,\nour theory explains how and when increasing the network size does and does not\nimprove the training behaviors in the practical regime. Our results provide\npractical guidance for designing a model structure: e.g., the common model\nstructure assumption can be used as a justification for using a particular\nmodel structure instead of others. We also derive a new training framework,\nwhich satisfies the data-architecture alignment condition by automatically\nmodifying any given training algorithm. Given a standard training algorithm,\nthe framework running its modified version is empirically shown to maintain\ncompetitive test performances while providing global convergence guarantees for\ndeep residual neural networks with convolutions, skip connections, and batch\nnormalization with datasets, including MNIST, CIFAR-10, CIFAR-100, Semeion,\nKMNIST and SVHN.",
          "link": "http://arxiv.org/abs/2106.14836",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croitoru_F/0/1/0/all/0/1\">Florinel-Alin Croitoru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigore_D/0/1/0/all/0/1\">Diana-Nicoleta Grigore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>",
          "description": "During the training process, deep neural networks implicitly learn to\nrepresent the input data samples through a hierarchy of features, where the\nsize of the hierarchy is determined by the number of layers. In this paper, we\nfocus on enforcing the discriminative power of the high-level representations,\nthat are typically learned by the deeper layers (closer to the output). To this\nend, we introduce a new loss term inspired by the Gini impurity, which is aimed\nat minimizing the entropy (increasing the discriminative power) of individual\nhigh-level features with respect to the class labels. Although our Gini loss\ninduces highly-discriminative features, it does not ensure that the\ndistribution of the high-level features matches the distribution of the\nclasses. As such, we introduce another loss term to minimize the\nKullback-Leibler divergence between the two distributions. We conduct\nexperiments on two image classification data sets (CIFAR-100 and Caltech 101),\nconsidering multiple neural architectures ranging from convolutional networks\n(ResNet-17, ResNet-18, ResNet-50) to transformers (CvT). Our empirical results\nshow that integrating our novel loss terms into the training objective\nconsistently outperforms the models trained with cross-entropy alone, without\nincreasing the inference time at all.",
          "link": "http://arxiv.org/abs/2202.07073",
          "publishedOn": "2022-04-09T00:48:55.361Z",
          "wordCount": null,
          "title": "Discriminability-enforcing loss to improve representation learning. (arXiv:2202.07073v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krug_A/0/1/0/all/0/1\">Andreas Krug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratul_R/0/1/0/all/0/1\">Raihan Kabir Ratul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stober_S/0/1/0/all/0/1\">Sebastian Stober</a>",
          "description": "Machine Learning with Deep Neural Networks (DNNs) has become a successful\ntool in solving tasks across various fields of application. The success of DNNs\nis strongly connected to their high complexity in terms of the number of\nnetwork layers or of neurons in each layer, which severely complicates to\nunderstand how DNNs solve their learned task. To improve the explainability of\nDNNs, we adapt methods from neuroscience because this field has a rich\nexperience in analyzing complex and opaque systems. In this work, we draw\ninspiration from how neuroscience uses topographic maps to visualize the\nactivity of the brain when it performs certain tasks. Transferring this\napproach to DNNs can help to visualize and understand their internal processes\nmore intuitively, too. However, the inner structures of brains and DNNs differ\nsubstantially. Therefore, to be able to visualize activations of neurons in\nDNNs as topographic maps, we research techniques to layout the neurons in a\ntwo-dimensional space in which neurons of similar activity are in the vicinity\nof each other. In this work, we introduce and compare different methods to\nobtain a topographic layout of the neurons in a network layer. Moreover, we\ndemonstrate how to use the resulting topographic activation maps to identify\nerrors or encoded biases in DNNs or data sets. Our novel visualization\ntechnique improves the transparency of DNN-based algorithmic decision-making\nsystems and is accessible to a broad audience because topographic maps are\nintuitive to interpret without expert-knowledge in Machine Learning.",
          "link": "http://arxiv.org/abs/2204.03528",
          "publishedOn": "2022-04-09T00:48:55.360Z",
          "wordCount": null,
          "title": "Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.02072",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Kalashev_O/0/1/0/all/0/1\">O. Kalashev</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kharuk_I/0/1/0/all/0/1\">I. Kharuk</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kuznetsov_M/0/1/0/all/0/1\">M. Kuznetsov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Rubtsov_G/0/1/0/all/0/1\">G. Rubtsov</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sako_T/0/1/0/all/0/1\">T. Sako</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Tsunesada_Y/0/1/0/all/0/1\">Y. Tsunesada</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zhezher_Y/0/1/0/all/0/1\">Ya. Zhezher</a>",
          "description": "We introduce a novel method for identifying the mass composition of\nultra-high-energy cosmic rays using deep learning. The key idea of the method\nis to use a chain of two neural networks. The first network predicts the type\nof a primary particle for individual events, while the second infers the mass\ncomposition of an ensemble of events. We apply this method to the Monte-Carlo\ndata for the Telescope Array Surface Detectors readings, on which it yields an\nunprecedented low error of 7% for 4-component approximation. We also discuss\nthe problems of applying the developed method to the experimental data, and the\nway they can be resolved.",
          "link": "http://arxiv.org/abs/2112.02072",
          "publishedOn": "2022-04-09T00:48:55.359Z",
          "wordCount": null,
          "title": "Deep learning method for identifying mass composition of ultra-high-energy cosmic rays. (arXiv:2112.02072v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yafei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_J/0/1/0/all/0/1\">John Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1\">Sebastian Scherer</a>",
          "description": "In traditional robot exploration methods, the robot usually does not have\nprior biases about the environment it is exploring. Thus the robot assigns\nequal importance to the goals which leads to insufficient exploration\nefficiency. Alternative, often a hand-tuned policy is used to tweak the value\nof goals. In this paper, we present a method to learn how \"good\" some states\nare, measured by the state value function, to provide a hint for the robot to\nmake exploration decisions. We propose to learn state value functions from\nprevious offline collected datasets and then transfer and improve the value\nfunction during testing in a new environment. Moreover, the environments\nusually have very few and even no extrinsic reward or feedback for the robot.\nTherefore in this work, we also tackle the problem of sparse extrinsic rewards\nfrom the environments. We design several intrinsic rewards to encourage the\nrobot to obtain more information during exploration. These reward functions\nthen become the building blocks of the state value functions. We test our\nmethod on challenging subterranean and urban environments. To the best of our\nknowledge, this work for the first time demonstrates value function prediction\nwith previous collected datasets to help exploration in challenging\nsubterranean environments.",
          "link": "http://arxiv.org/abs/2204.03140",
          "publishedOn": "2022-04-09T00:48:55.358Z",
          "wordCount": null,
          "title": "Learning and Transferring Value Function for Robot Exploration in Subterranean Environments. (arXiv:2204.03140v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1\">Satwik Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Swaroop Ghosh</a>",
          "description": "In the last few years, quantum computing has experienced a growth spurt. One\nexciting avenue of quantum computing is quantum machine learning (QML) which\ncan exploit the high dimensional Hilbert space to learn richer representations\nfrom limited data and thus can efficiently solve complex learning tasks.\nDespite the increased interest in QML, there have not been many studies that\ndiscuss the security aspects of QML. In this work, we explored the possible\nfuture applications of QML in the hardware security domain. We also expose the\nsecurity vulnerabilities of QML and emerging attack models, and corresponding\ncountermeasures.",
          "link": "http://arxiv.org/abs/2204.03625",
          "publishedOn": "2022-04-09T00:48:55.345Z",
          "wordCount": null,
          "title": "Security Aspects of Quantum Machine Learning: Opportunities, Threats and Defenses. (arXiv:2204.03625v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1\">Efthymios Tzinis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wichern_G/0/1/0/all/0/1\">Gordon Wichern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1\">Aswin Subramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smaragdis_P/0/1/0/all/0/1\">Paris Smaragdis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_J/0/1/0/all/0/1\">Jonathan Le Roux</a>",
          "description": "We introduce a new paradigm for single-channel target source separation where\nthe sources of interest can be distinguished using non-mutually exclusive\nconcepts (e.g., loudness, gender, language, spatial location, etc). Our\nproposed heterogeneous separation framework can seamlessly leverage datasets\nwith large distribution shifts and learn cross-domain representations under a\nvariety of concepts used as conditioning. Our experiments show that training\nseparation models with heterogeneous conditions facilitates the generalization\nto new concepts with unseen out-of-domain data while also performing\nsubstantially higher than single-domain specialist models. Notably, such\ntraining leads to more robust learning of new harder source separation\ndiscriminative concepts and can yield improvements over permutation invariant\ntraining with oracle source selection. We analyze the intrinsic behavior of\nsource separation training with heterogeneous metadata and propose ways to\nalleviate emerging problems with challenging separation conditions. We release\nthe collection of preparation recipes for all datasets used to further promote\nresearch towards this challenging task.",
          "link": "http://arxiv.org/abs/2204.03594",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Heterogeneous Target Speech Separation. (arXiv:2204.03594v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1\">Hilda S Ibriga</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>",
          "description": "We aim to provably complete a sparse and highly-missing tensor in the\npresence of covariate information along tensor modes. Our motivation comes from\nonline advertising where users click-through-rates (CTR) on ads over various\ndevices form a CTR tensor that has about 96% missing entries and has many zeros\non non-missing entries, which makes the standalone tensor completion method\nunsatisfactory. Beside the CTR tensor, additional ad features or user\ncharacteristics are often available. In this paper, we propose\nCovariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate\ninformation for the recovery of the sparse tensor. The key idea is to jointly\nextract latent components from both the tensor and the covariate matrix to\nlearn a synthetic representation. Theoretically, we derive the error bound for\nthe recovered tensor components and explicitly quantify the improvements on\nboth the reveal probability condition and the tensor recovery accuracy due to\ncovariates. Finally, we apply COSTCO to an advertisement dataset consisting of\na CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over\nthe baseline. An important by-product is that ad latent components from COSTCO\nreveal interesting ad clusters, which are useful for better ad targeting.",
          "link": "http://arxiv.org/abs/2103.06428",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1\">Willie Neiswanger</a>",
          "description": "With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. However, after assessing 40 tuning methods systematically, we find\nthat each faces certain limitations. In particular, methods that speed up\ntuning via knowledge transfer typically require the final performance of\nhyperparameters and do not focus on low-fidelity information. As we demonstrate\nempirically, this common practice is suboptimal and can incur an unnecessary\nuse of resources. It is more cost-efficient to instead leverage low-fidelity\ntuning observations to measure inter-task similarity and transfer knowledge\nfrom existing to new tasks accordingly. However, performing multi-fidelity\ntuning comes with its own challenges in the transfer setting: the noise in\nadditional observations and the need for performance forecasting. Therefore, we\npropose and conduct a thorough analysis of a multi-task multi-fidelity Bayesian\noptimization framework, which leads to the best instantiation--amortized\nauto-tuning (AT2). We further present an offline-computed 27-task\nhyperparameter recommendation (HyperRec) database to serve the community.\nExtensive experiments on HyperRec and other real-world databases illustrate the\neffectiveness of our AT2 method.",
          "link": "http://arxiv.org/abs/2106.09179",
          "publishedOn": "2022-04-09T00:48:55.344Z",
          "wordCount": null,
          "title": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for Hyperparameter Recommendation. (arXiv:2106.09179v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.02166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yushuo Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pengyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1\">Zhengping Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_K/0/1/0/all/0/1\">Kaigui Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "The convolutional neural network has achieved great success in fulfilling\ncomputer vision tasks despite large computation overhead against efficient\ndeployment. Structured (channel) pruning is usually applied to reduce the model\nredundancy while preserving the network structure, such that the pruned network\ncan be easily deployed in practice. However, existing structured pruning\nmethods require hand-crafted rules which may lead to tremendous pruning space.\nIn this paper, we introduce Differentiable Annealing Indicator Search (DAIS)\nthat leverages the strength of neural architecture search in the channel\npruning and automatically searches for the effective pruned model with given\nconstraints on computation overhead. Specifically, DAIS relaxes the binarized\nchannel indicators to be continuous and then jointly learns both indicators and\nmodel parameters via bi-level optimization. To bridge the non-negligible\ndiscrepancy between the continuous model and the target binarized model, DAIS\nproposes an annealing-based procedure to steer the indicator convergence\ntowards binarized states. Moreover, DAIS designs various regularizations based\non a priori structural knowledge to control the pruning sparsity and to improve\nmodel performance. Experimental results show that DAIS outperforms\nstate-of-the-art pruning methods on CIFAR-10, CIFAR-100, and ImageNet.",
          "link": "http://arxiv.org/abs/2011.02166",
          "publishedOn": "2022-04-09T00:48:55.343Z",
          "wordCount": null,
          "title": "DAIS: Automatic Channel Pruning via Differentiable Annealing Indicator Search. (arXiv:2011.02166v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.08877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parekh_V/0/1/0/all/0/1\">Vivek Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flore_D/0/1/0/all/0/1\">Dominik Flore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schops_S/0/1/0/all/0/1\">Sebastian Sch&#xf6;ps</a>",
          "description": "Conventional magneto-static finite element analysis of electrical machine\ndesign is time-consuming and computationally expensive. Since each machine\ntopology has a distinct set of parameters, design optimization is commonly\nperformed independently. This paper presents a novel method for predicting Key\nPerformance Indicators (KPIs) of differently parameterized electrical machine\ntopologies at the same time by mapping a high dimensional integrated design\nparameters in a lower dimensional latent space using a variational autoencoder.\nAfter training, via a latent space, the decoder and multi-layer neural network\nwill function as meta-models for sampling new designs and predicting associated\nKPIs, respectively. This enables parameter-based concurrent multi-topology\noptimization.",
          "link": "http://arxiv.org/abs/2201.08877",
          "publishedOn": "2022-04-09T00:48:55.343Z",
          "wordCount": null,
          "title": "Variational Autoencoder based Metamodeling for Multi-Objective Topology Optimization of Electrical Machines. (arXiv:2201.08877v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02978",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lemercier_J/0/1/0/all/0/1\">Jean-Marie Lemercier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thiemann_J/0/1/0/all/0/1\">Joachim Thiemann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Koning_R/0/1/0/all/0/1\">Raphael Koning</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gerkmann_T/0/1/0/all/0/1\">Timo Gerkmann</a>",
          "description": "A two-stage online dereverberation algorithm for hearing devices is presented\nin this paper. The approach combines a multi-channel multi-frame linear\nfiltering approach with a single-channel single-frame post-filter. Both\ncomponents rely on power spectral density (PSD) estimates provided by deep\nneural networks (DNNs). This contribution extends our prior work, which shows\nthat directly optimizing for a criterion at the output of the multi-channel\nlinear filtering stage results in a more efficient dereverberation, as compared\nto placing the criterion at the output of the DNN to optimize the PSD\nestimation. In the present work, we show that the dereverberation performance\nof the proposed first stage particularly improves the early-to-mid\nreverberation ratio if trained end-to-end. We thus argue that it can be\ncombined with a post-filtering stage which benefits from the early-to-mid ratio\nimprovement and is consequently able to efficiently suppress the residual late\nreverberation. This proposed two stage procedure is shown to be both very\neffective in terms of dereverberation performance and computational demands.\nFurthermore, the proposed system can be adapted to the needs of different types\nof hearing-device users by controlling the amount of reduction of early\nreflections. The proposed system outperforms the previously proposed end-to-end\nDNN-supported linear filtering algorithm, as well as other traditional\napproaches, based on an evaluation using the noise-free version of the WHAMR!\ndataset.",
          "link": "http://arxiv.org/abs/2204.02978",
          "publishedOn": "2022-04-09T00:48:55.342Z",
          "wordCount": null,
          "title": "End-To-End Optimization of Online Neural Network-supported Two-Stage Dereverberation for Hearing Devices. (arXiv:2204.02978v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01533",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cuesta_Ramirez_J/0/1/0/all/0/1\">Jhouben Cuesta-Ramirez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Riche_R/0/1/0/all/0/1\">Rodolphe Le Riche</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roustant_O/0/1/0/all/0/1\">Olivier Roustant</a>, <a href=\"http://arxiv.org/find/math/1/au:+Perrin_G/0/1/0/all/0/1\">Guillaume Perrin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Durantin_C/0/1/0/all/0/1\">Cedric Durantin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gliere_A/0/1/0/all/0/1\">Alain Gliere</a>",
          "description": "Most real optimization problems are defined over a mixed search space where\nthe variables are both discrete and continuous. In engineering applications,\nthe objective function is typically calculated with a numerically costly\nblack-box simulation.General mixed and costly optimization problems are\ntherefore of a great practical interest, yet their resolution remains in a\nlarge part an open scientific question. In this article, costly mixed problems\nare approached through Gaussian processes where the discrete variables are\nrelaxed into continuous latent variables. The continuous space is more easily\nharvested by classical Bayesian optimization techniques than a mixed space\nwould. Discrete variables are recovered either subsequently to the continuous\noptimization, or simultaneously with an additional continuous-discrete\ncompatibility constraint that is handled with augmented Lagrangians. Several\npossible implementations of such Bayesian mixed optimizers are compared. In\nparticular, the reformulation of the problem with continuous latent variables\nis put in competition with searches working directly in the mixed space. Among\nthe algorithms involving latent variables and an augmented Lagrangian, a\nparticular attention is devoted to the Lagrange multipliers for which a local\nand a global estimation techniques are studied. The comparisons are based on\nthe repeated optimization of three analytical functions and a beam design\nproblem.",
          "link": "http://arxiv.org/abs/2111.01533",
          "publishedOn": "2022-04-09T00:48:55.341Z",
          "wordCount": null,
          "title": "A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06416",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qingxu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_T/0/1/0/all/0/1\">Tenghai Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jianqiang Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Z/0/1/0/all/0/1\">Zhiqiang Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shiguang Wu</a>",
          "description": "When dealing with a series of imminent issues, humans can naturally\nconcentrate on a subset of these concerning issues by prioritizing them\naccording to their contributions to motivational indices, e.g., the probability\nof winning a game. This idea of concentration offers insights into\nreinforcement learning of sophisticated Large-scale Multi-Agent Systems (LMAS)\nparticipated by hundreds of agents. In such an LMAS, each agent receives a long\nseries of entity observations at each step, which can overwhelm existing\naggregation networks such as graph attention networks and cause inefficiency.\nIn this paper, we propose a concentration network called ConcNet. First,\nConcNet scores the observed entities considering several motivational indices,\ne.g., expected survival time and state value of the agents, and then ranks,\nprunes, and aggregates the encodings of observed entities to extract features.\nSecond, distinct from the well-known attention mechanism, ConcNet has a unique\nmotivational subnetwork to explicitly consider the motivational indices when\nscoring the observed entities. Furthermore, we present a concentration policy\ngradient architecture that can learn effective policies in LMAS from scratch.\nExtensive experiments demonstrate that the presented architecture has excellent\nscalability and flexibility, and significantly outperforms existing methods on\nLMAS benchmarks.",
          "link": "http://arxiv.org/abs/2203.06416",
          "publishedOn": "2022-04-09T00:48:55.340Z",
          "wordCount": 655,
          "title": "Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems. (arXiv:2203.06416v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daunhawer_I/0/1/0/all/0/1\">Imant Daunhawer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutter_T/0/1/0/all/0/1\">Thomas M. Sutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_Cheong_K/0/1/0/all/0/1\">Kieran Chin-Cheong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palumbo_E/0/1/0/all/0/1\">Emanuele Palumbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Multimodal variational autoencoders (VAEs) have shown promise as efficient\ngenerative models for weakly-supervised data. Yet, despite their advantage of\nweak supervision, they exhibit a gap in generative quality compared to unimodal\nVAEs, which are completely unsupervised. In an attempt to explain this gap, we\nuncover a fundamental limitation that applies to a large family of\nmixture-based multimodal VAEs. We prove that the sub-sampling of modalities\nenforces an undesirable upper bound on the multimodal ELBO and thereby limits\nthe generative quality of the respective models. Empirically, we showcase the\ngenerative quality gap on both synthetic and real data and present the\ntradeoffs between different variants of multimodal VAEs. We find that none of\nthe existing approaches fulfills all desired criteria of an effective\nmultimodal generative model when applied on more complex datasets than those\nused in previous benchmarks. In summary, we identify, formalize, and validate\nfundamental limitations of VAE-based approaches for modeling weakly-supervised\ndata and discuss implications for real-world applications.",
          "link": "http://arxiv.org/abs/2110.04121",
          "publishedOn": "2022-04-09T00:48:55.331Z",
          "wordCount": null,
          "title": "On the Limitations of Multimodal VAEs. (arXiv:2110.04121v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.09371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1\">Neeraj Varshney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>",
          "description": "It's better to say \"I can't answer\" than to answer incorrectly. This\nselective prediction ability is crucial for NLP systems to be reliably deployed\nin real-world applications. Prior work has shown that existing selective\nprediction techniques fail to perform well, especially in the out-of-domain\nsetting. In this work, we propose a method that improves probability estimates\nof models by calibrating them using prediction confidence and difficulty score\nof instances. Using these two signals, we first annotate held-out instances and\nthen train a calibrator to predict the likelihood of correctness of the model's\nprediction. We instantiate our method with Natural Language Inference (NLI) and\nDuplicate Detection (DD) tasks and evaluate it in both In-Domain (IID) and\nOut-of-Domain (OOD) settings. In (IID, OOD) settings, we show that the\nrepresentations learned by our calibrator result in an improvement of (15.81%,\n5.64%) and (6.19%, 13.9%) over 'MaxProb' -- a selective prediction baseline --\non NLI and DD tasks respectively.",
          "link": "http://arxiv.org/abs/2008.09371",
          "publishedOn": "2022-04-09T00:48:55.329Z",
          "wordCount": null,
          "title": "Towards Improving Selective Prediction Ability of NLP Systems. (arXiv:2008.09371v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abhishek_K/0/1/0/all/0/1\">Kumar Abhishek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_C/0/1/0/all/0/1\">Colin J. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamarneh_G/0/1/0/all/0/1\">Ghassan Hamarneh</a>",
          "description": "Modern deep learning training procedures rely on model regularization\ntechniques such as data augmentation methods, which generate training samples\nthat increase the diversity of data and richness of label information. A\npopular recent method, mixup, uses convex combinations of pairs of original\nsamples to generate new samples. However, as we show in our experiments, mixup\ncan produce undesirable synthetic samples, where the data is sampled off the\nmanifold and can contain incorrect labels. We propose $\\zeta$-mixup, a\ngeneralization of mixup with provably and demonstrably desirable properties\nthat allows convex combinations of $N \\geq 2$ samples, leading to more\nrealistic and diverse outputs that incorporate information from $N$ original\nsamples by using a $p$-series interpolant. We show that, compared to mixup,\n$\\zeta$-mixup better preserves the intrinsic dimensionality of the original\ndatasets, which is a desirable property for training generalizable models.\nFurthermore, we show that our implementation of $\\zeta$-mixup is faster than\nmixup, and extensive evaluation on controlled synthetic and 24 real-world\nnatural and medical image classification datasets shows that $\\zeta$-mixup\noutperforms mixup and traditional data augmentation techniques.",
          "link": "http://arxiv.org/abs/2204.03323",
          "publishedOn": "2022-04-09T00:48:55.328Z",
          "wordCount": null,
          "title": "Multi-Sample $\\zeta$-mixup: Richer, More Realistic Synthetic Samples from a $p$-Series Interpolant. (arXiv:2204.03323v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Svendsen_D/0/1/0/all/0/1\">Daniel Heestermans Svendsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1\">Daniel Hern&#xe1;ndez-Lobato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martino_L/0/1/0/all/0/1\">Luca Martino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1\">Valero Laparra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_A/0/1/0/all/0/1\">Alvaro Moreno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camps_Valls_G/0/1/0/all/0/1\">Gustau Camps-Valls</a>",
          "description": "Earth observation from satellites offers the possibility to monitor our\nplanet with unprecedented accuracy. Radiative transfer models (RTMs) encode the\nenergy transfer through the atmosphere, and are used to model and understand\nthe Earth system, as well as to estimate the parameters that describe the\nstatus of the Earth from satellite observations by inverse modeling. However,\nperforming inference over such simulators is a challenging problem. RTMs are\nnonlinear, non-differentiable and computationally costly codes, which adds a\nhigh level of difficulty in inference. In this paper, we introduce two\ncomputational techniques to infer not only point estimates of biophysical\nparameters but also their joint distribution. One of them is based on a\nvariational autoencoder approach and the second one is based on a Monte Carlo\nExpectation Maximization (MCEM) scheme. We compare and discuss benefits and\ndrawbacks of each approach. We also provide numerical comparisons in synthetic\nsimulations and the real PROSAIL model, a popular RTM that combines land\nvegetation leaf and canopy modeling. We analyze the performance of the two\napproaches for modeling and inferring the distribution of three key biophysical\nparameters for quantifying the terrestrial biosphere.",
          "link": "http://arxiv.org/abs/2204.03346",
          "publishedOn": "2022-04-09T00:48:55.327Z",
          "wordCount": null,
          "title": "Inference over radiative transfer models using variational and expectation maximization methods. (arXiv:2204.03346v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leslie_D/0/1/0/all/0/1\">David Leslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briggs_M/0/1/0/all/0/1\">Morgan Briggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perini_A/0/1/0/all/0/1\">Antonella Perini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayadeva_S/0/1/0/all/0/1\">Smera Jayadeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rincon_C/0/1/0/all/0/1\">Cami Rinc&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raval_N/0/1/0/all/0/1\">Noopur Raval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birhane_A/0/1/0/all/0/1\">Abeba Birhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powell_R/0/1/0/all/0/1\">Rosamund Powell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katell_M/0/1/0/all/0/1\">Michael Katell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitken_M/0/1/0/all/0/1\">Mhairi Aitken</a>",
          "description": "The idea of \"data justice\" is of recent academic vintage. It has arisen over\nthe past decade in Anglo-European research institutions as an attempt to bring\ntogether a critique of the power dynamics that underlie accelerating trends of\ndatafication with a normative commitment to the principles of social justice-a\ncommitment to the achievement of a society that is equitable, fair, and capable\nof confronting the root causes of injustice.However, despite the seeming\nnovelty of such a data justice pedigree, this joining up of the critique of the\npower imbalances that have shaped the digital and \"big data\" revolutions with a\ncommitment to social equity and constructive societal transformation has a\ndeeper historical, and more geographically diverse, provenance. As the stories\nof the data justice initiatives, activism, and advocacy contained in this\nvolume well evidence, practices of data justice across the globe have, in fact,\nlargely preceded the elaboration and crystallisation of the idea of data\njustice in contemporary academic discourse. In telling these data justice\nstories, we hope to provide the reader with two interdependent tools of data\njustice thinking: First, we aim to provide the reader with the critical\nleverage needed to discern those distortions and malformations of data justice\nthat manifest in subtle and explicit forms of power, domination, and coercion.\nSecond, we aim to provide the reader with access to the historically effective\nforms of normativity and ethical insight that have been marshalled by data\njustice activists and advocates as tools of societal transformation-so that\nthese forms of normativity and insight can be drawn on, in turn, as\nconstructive resources to spur future transformative data justice practices.",
          "link": "http://arxiv.org/abs/2204.03100",
          "publishedOn": "2022-04-09T00:48:55.326Z",
          "wordCount": null,
          "title": "Data Justice Stories: A Repository of Case Studies. (arXiv:2204.03100v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03379",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ben_Simon_T/0/1/0/all/0/1\">Talia Ben-Simon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Awwad_F/0/1/0/all/0/1\">Faten Awwad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cohen_J/0/1/0/all/0/1\">Jacob T. Cohen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>",
          "description": "Learning a new language involves constantly comparing speech productions with\nreference productions from the environment. Early in speech acquisition,\nchildren make articulatory adjustments to match their caregivers' speech.\nGrownup learners of a language tweak their speech to match the tutor reference.\nThis paper proposes a method to synthetically generate correct pronunciation\nfeedback given incorrect production. Furthermore, our aim is to generate the\ncorrected production while maintaining the speaker's original voice.\n\nThe system prompts the user to pronounce a phrase. The speech is recorded,\nand the samples associated with the inaccurate phoneme are masked with zeros.\nThis waveform serves as an input to a speech generator, implemented as a deep\nlearning inpainting system with a U-net architecture, and trained to output a\nreconstructed speech. The training set is composed of unimpaired proper speech\nexamples, and the generator is trained to reconstruct the original proper\nspeech. We evaluated the performance of our system on phoneme replacement of\nminimal pair words of English as well as on children with pronunciation\ndisorders. Results suggest that human listeners slightly prefer our generated\nspeech over a smoothed replacement of the inaccurate phoneme with a production\nof a different speaker.",
          "link": "http://arxiv.org/abs/2204.03379",
          "publishedOn": "2022-04-09T00:48:55.326Z",
          "wordCount": null,
          "title": "Correcting Misproducted Speech using Spectrogram Inpainting. (arXiv:2204.03379v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodrati_S/0/1/0/all/0/1\">Soroush Ghodrati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdanbakhsh_A/0/1/0/all/0/1\">Amir Yazdanbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeilzadeh_H/0/1/0/all/0/1\">Hadi Esmaeilzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Mingu Kang</a>",
          "description": "Self-attention is a key enabler of state-of-art accuracy for various\ntransformer-based Natural Language Processing models. This attention mechanism\ncalculates a correlation score for each word with respect to the other words in\na sentence. Commonly, only a small subset of words highly correlates with the\nword under attention, which is only determined at runtime. As such, a\nsignificant amount of computation is inconsequential due to low attention\nscores and can potentially be pruned. The main challenge is finding the\nthreshold for the scores below which subsequent computation will be\ninconsequential. Although such a threshold is discrete, this paper formulates\nits search through a soft differentiable regularizer integrated into the loss\nfunction of the training. This formulation piggy backs on the back-propagation\ntraining to analytically co-optimize the threshold and the weights\nsimultaneously, striking a formally optimal balance between accuracy and\ncomputation pruning. To best utilize this mathematical innovation, we devise a\nbit-serial architecture, dubbed LeOPArd, for transformer language models with\nbit-level early termination microarchitectural mechanism. We evaluate our\ndesign across 43 back-end tasks for MemN2N, BERT, ALBERT, GPT-2, and Vision\ntransformer models. Post-layout results show that, on average, LeOPArd yields\n1.9x and 3.9x speedup and energy reduction, respectively, while keeping the\naverage accuracy virtually intact (<0.2% degradation)",
          "link": "http://arxiv.org/abs/2204.03227",
          "publishedOn": "2022-04-09T00:48:55.325Z",
          "wordCount": null,
          "title": "Accelerating Attention through Gradient-Based Learned Runtime Pruning. (arXiv:2204.03227v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jiyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jungin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_D/0/1/0/all/0/1\">Dongbo Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kwanghoon Sohn</a>",
          "description": "The rise of deep neural networks has led to several breakthroughs for\nsemantic segmentation. In spite of this, a model trained on source domain often\nfails to work properly in new challenging domains, that is directly concerned\nwith the generalization capability of the model. In this paper, we present a\nnovel memory-guided domain generalization method for semantic segmentation\nbased on meta-learning framework. Especially, our method abstracts the\nconceptual knowledge of semantic classes into categorical memory which is\nconstant beyond the domains. Upon the meta-learning concept, we repeatedly\ntrain memory-guided networks and simulate virtual test to 1) learn how to\nmemorize a domain-agnostic and distinct information of classes and 2) offer an\nexternally settled memory as a class-guidance to reduce the ambiguity of\nrepresentation in the test data of arbitrary unseen domain. To this end, we\nalso propose memory divergence and feature cohesion losses, which encourage to\nlearn memory reading and update processes for category-aware domain\ngeneralization. Extensive experiments for semantic segmentation demonstrate the\nsuperior generalization capability of our method over state-of-the-art works on\nvarious benchmarks.",
          "link": "http://arxiv.org/abs/2204.03609",
          "publishedOn": "2022-04-09T00:48:55.321Z",
          "wordCount": null,
          "title": "Pin the Memory: Learning to Generalize Semantic Segmentation. (arXiv:2204.03609v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tz-Ying Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_G/0/1/0/all/0/1\">Gurumurthy Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhizhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1\">Avinash Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_N/0/1/0/all/0/1\">Nuno Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotika_R/0/1/0/all/0/1\">Rahul Bhotika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Class-incremental learning (CIL) has been widely studied under the setting of\nstarting from a small number of classes (base classes). Instead, we explore an\nunderstudied real-world setting of CIL that starts with a strong model\npre-trained on a large number of base classes. We hypothesize that a strong\nbase model can provide a good representation for novel classes and incremental\nlearning can be done with small adaptations. We propose a 2-stage training\nscheme, i) feature augmentation -- cloning part of the backbone and fine-tuning\nit on the novel data, and ii) fusion -- combining the base and novel\nclassifiers into a unified classifier. Experiments show that the proposed\nmethod significantly outperforms state-of-the-art CIL methods on the\nlarge-scale ImageNet dataset (e.g. +10% overall accuracy than the best). We\nalso propose and analyze understudied practical CIL scenarios, such as\nbase-novel overlap with distribution shift. Our proposed method is robust and\ngeneralizes to all analyzed CIL settings.",
          "link": "http://arxiv.org/abs/2204.03634",
          "publishedOn": "2022-04-09T00:48:55.317Z",
          "wordCount": null,
          "title": "Class-Incremental Learning with Strong Pre-trained Models. (arXiv:2204.03634v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.11048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhihua Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yao Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengfei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph\ndata and have achieved significant progress in graph analysis tasks (e.g., node\nclassification) in recent years. However, similar to other deep neural networks\nlike Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs),\nGNNs behave like a black box with their details hidden from model developers\nand users. It is therefore difficult to diagnose possible errors of GNNs.\nDespite many visual analytics studies being done on CNNs and RNNs, little\nresearch has addressed the challenges for GNNs. This paper fills the research\ngap with an interactive visual analysis tool, GNNLens, to assist model\ndevelopers and users in understanding and analyzing GNNs. Specifically,\nParallel Sets View and Projection View enable users to quickly identify and\nvalidate error patterns in the set of wrong predictions; Graph View and Feature\nMatrix View offer a detailed analysis of individual nodes to assist users in\nforming hypotheses about the error patterns. Since GNNs jointly model the graph\nstructure and the node features, we reveal the relative influences of the two\ntypes of information by comparing the predictions of three models: GNN,\nMulti-Layer Perceptron (MLP), and GNN Without Using Features (GNNWUF). Two case\nstudies and interviews with domain experts demonstrate the effectiveness of\nGNNLens in facilitating the understanding of GNN models and their errors.",
          "link": "http://arxiv.org/abs/2011.11048",
          "publishedOn": "2022-04-09T00:48:55.317Z",
          "wordCount": null,
          "title": "GNNLens: A Visual Analytics Approach for Prediction Error Diagnosis of Graph Neural Networks. (arXiv:2011.11048v6 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.05454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhenzhen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yuanlong Yu</a>",
          "description": "Feature selection is an important data preprocessing in data mining and\nmachine learning which can be used to reduce the feature dimension without\ndeteriorating model's performance. Since obtaining annotated data is laborious\nor even infeasible in many cases, unsupervised feature selection is more\npractical in reality. Though lots of methods for unsupervised feature selection\nhave been proposed, these methods select features independently, thus it is no\nguarantee that the group of selected features is optimal. What's more, the\nnumber of selected features must be tuned carefully to obtain a satisfactory\nresult. To tackle these problems, we propose a joint adaptive graph and\nstructured sparsity regularization unsupervised feature selection (JASFS)\nmethod in this paper, in which a $l_{2,0}$-norm regularization term with\nrespect to transformation matrix is imposed in the manifold learning for\nfeature selection, and a graph regularization term is incorporated into the\nlearning model to learn the local geometric structure of data adaptively. An\nefficient and simple iterative algorithm is designed to solve the proposed\noptimization problem with the analysis of computational complexity. After\noptimized, a subset of optimal features will be selected in group, and the\nnumber of selected features will be determined automatically. Experimental\nresults on eight benchmarks demonstrate the effectiveness and efficiency of the\nproposed method compared with several state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2010.05454",
          "publishedOn": "2022-04-09T00:48:55.315Z",
          "wordCount": null,
          "title": "Joint Adaptive Graph and Structured Sparsity Regularization for Unsupervised Feature Selection. (arXiv:2010.05454v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Narain_S/0/1/0/all/0/1\">Sanjai Narain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mak_E/0/1/0/all/0/1\">Emily Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chee_D/0/1/0/all/0/1\">Dana Chee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Englot_B/0/1/0/all/0/1\">Brendan Englot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pochiraju_K/0/1/0/all/0/1\">Kishore Pochiraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1\">Niraj K. Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_K/0/1/0/all/0/1\">Karthik Narayan</a>",
          "description": "System design tools are often only available as input-output blackboxes: for\na given design as input they compute an output representing system behavior.\nBlackboxes are intended to be run in the forward direction. This paper presents\na new method of solving the inverse design problem namely, given requirements\nor constraints on output, find an input that also optimizes an objective\nfunction. This problem is challenging for several reasons. First, blackboxes\nare not designed to be run in reverse. Second, inputs and outputs can be\ndiscrete and continuous. Third, finding designs concurrently satisfying a set\nof requirements is hard because designs satisfying individual requirements may\nconflict with each other. Fourth, blackbox evaluations can be expensive.\nFinally, blackboxes can sometimes fail to produce an output. This paper\npresents CNMA, a new method of solving the inverse problem that overcomes these\nchallenges. CNMA tries to sample only the part of the design space relevant to\nsolving the problem, leveraging the power of neural networks, Mixed Integer\nLinear Programs, and a new learning-from-failure feedback loop. The paper also\npresents a parallel version of CNMA that improves the efficiency and quality of\nsolutions over the sequential version, and tries to steer it away from local\noptima. CNMA's performance is evaluated against conventional optimization\nmethods for seven nonlinear design problems of 8 (two problems), 10, 15, 36 and\n60 real-valued dimensions and one with 186 binary dimensions. Conventional\nmethods evaluated are off-the-shelf implementations of Bayesian Optimization\nwith Gaussian Processes, Nelder Mead and Random Search. The first two do not\nsolve problems that are high-dimensional, have discrete and continuous\nvariables or whose blackboxes can fail to return values. CNMA solves all\nproblems, and surpasses the performance of conventional methods by up to 87%.",
          "link": "http://arxiv.org/abs/2104.01747",
          "publishedOn": "2022-04-09T00:48:55.314Z",
          "wordCount": null,
          "title": "Fast Design Space Exploration of Nonlinear Systems: Part I. (arXiv:2104.01747v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saragadam_V/0/1/0/all/0/1\">Vishwanath Saragadam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeraraghavan_A/0/1/0/all/0/1\">Ashok Veeraraghavan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "DeepTensor is a computationally efficient framework for low-rank\ndecomposition of matrices and tensors using deep generative networks. We\ndecompose a tensor as the product of low-rank tensor factors (e.g., a matrix as\nthe outer product of two vectors), where each low-rank tensor is generated by a\ndeep network (DN) that is trained in a self-supervised manner to minimize the\nmean-squared approximation error. Our key observation is that the implicit\nregularization inherent in DNs enables them to capture nonlinear signal\nstructures (e.g., manifolds) that are out of the reach of classical linear\nmethods like the singular value decomposition (SVD) and principal component\nanalysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance\ndeteriorates when the tensor's entries deviate from additive white Gaussian\nnoise, we demonstrate that the performance of DeepTensor is robust to a wide\nrange of distributions. We validate that DeepTensor is a robust and\ncomputationally efficient drop-in replacement for the SVD, PCA, nonnegative\nmatrix factorization (NMF), and similar decompositions by exploring a range of\nreal-world applications, including hyperspectral image denoising, 3D MRI\ntomography, and image classification. In particular, DeepTensor offers a 6dB\nsignal-to-noise ratio improvement over standard denoising methods for signals\ncorrupted by Poisson noise and learns to decompose 3D tensors 60 times faster\nthan a single DN equipped with 3D convolutions.",
          "link": "http://arxiv.org/abs/2204.03145",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors. (arXiv:2204.03145v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03305",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zezario_R/0/1/0/all/0/1\">Ryandhimas E. Zezario</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuh_C/0/1/0/all/0/1\">Chiou-Shann Fuh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Improving the user's hearing ability to understand speech in noisy\nenvironments is critical to the development of hearing aid (HA) devices. For\nthis, it is important to derive a metric that can fairly predict speech\nintelligibility for HA users. A straightforward approach is to conduct a\nsubjective listening test and use the test results as an evaluation metric.\nHowever, conducting large-scale listening tests is time-consuming and\nexpensive. Therefore, several evaluation metrics were derived as surrogates for\nsubjective listening test results. In this study, we propose a multi-branched\nspeech intelligibility prediction model (MBI-Net), for predicting the\nsubjective intelligibility scores of HA users. MBI-Net consists of two branches\nof models, with each branch consisting of a hearing loss model, a cross-domain\nfeature extraction module, and a speech intelligibility prediction model, to\nprocess speech signals from one channel. The outputs of the two branches are\nfused through a linear layer to obtain predicted speech intelligibility scores.\nExperimental results confirm the effectiveness of MBI-Net, which produces\nhigher prediction scores than the baseline system in Track 1 and Track 2 on the\nClarity Prediction Challenge 2022 dataset.",
          "link": "http://arxiv.org/abs/2204.03305",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids. (arXiv:2204.03305v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.05861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadi_M/0/1/0/all/0/1\">Mohammad Abdul Hadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fard_F/0/1/0/all/0/1\">Fatemeh H. Fard</a>",
          "description": "Context: Mobile app reviews written by users on app stores or social media\nare significant resources for app developers.Analyzing app reviews have proved\nto be useful for many areas of software engineering (e.g., requirement\nengineering, testing). Automatic classification of app reviews requires\nextensive efforts to manually curate a labeled dataset. When the classification\npurpose changes (e.g. identifying bugs versus usability issues or sentiment),\nnew datasets should be labeled, which prevents the extensibility of the\ndeveloped models for new desired classes/tasks in practice. Recent pre-trained\nneural language models (PTM) are trained on large corpora in an unsupervised\nmanner and have found success in solving similar Natural Language Processing\nproblems. However, the applicability of PTMs is not explored for app review\nclassification Objective: We investigate the benefits of PTMs for app review\nclassification compared to the existing models, as well as the transferability\nof PTMs in multiple settings. Method: We empirically study the accuracy and\ntime efficiency of PTMs compared to prior approaches using six datasets from\nliterature. In addition, we investigate the performance of the PTMs trained on\napp reviews (i.e. domain-specific PTMs) . We set up different studies to\nevaluate PTMs in multiple settings: binary vs. multi-class classification,\nzero-shot classification (when new labels are introduced to the model),\nmulti-task setting, and classification of reviews from different resources. The\ndatasets are manually labeled app review datasets from Google Play Store, Apple\nApp Store, and Twitter data. In all cases, Micro and Macro Precision, Recall,\nand F1-scores will be used and we will report the time required for training\nand prediction with the models.",
          "link": "http://arxiv.org/abs/2104.05861",
          "publishedOn": "2022-04-09T00:48:55.313Z",
          "wordCount": null,
          "title": "Evaluating Pre-Trained Models for User Feedback Analysis in Software Engineering: A Study on Classification of App-Reviews. (arXiv:2104.05861v3 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.10888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shangtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.",
          "link": "http://arxiv.org/abs/2004.10888",
          "publishedOn": "2022-04-09T00:48:55.312Z",
          "wordCount": null,
          "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning. (arXiv:2004.10888v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulhane_P/0/1/0/all/0/1\">Pankaj Gulhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Judy Hanwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yekhanin_S/0/1/0/all/0/1\">Sergey Yekhanin</a>",
          "description": "We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n\nKnown algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.",
          "link": "http://arxiv.org/abs/2002.09745",
          "publishedOn": "2022-04-09T00:48:55.311Z",
          "wordCount": null,
          "title": "Differentially Private Set Union. (arXiv:2002.09745v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jelcicova_Z/0/1/0/all/0/1\">Zuzana Jel&#x10d;icov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verhelst_M/0/1/0/all/0/1\">Marian Verhelst</a>",
          "description": "Multi-head self-attention forms the core of Transformer networks. However,\ntheir quadratically growing complexity with respect to the input sequence\nlength impedes their deployment on resource-constrained edge devices. We\naddress this challenge by proposing a dynamic pruning method, which exploits\nthe temporal stability of data across tokens to reduce inference cost. The\nthreshold-based method only retains significant differences between the\nsubsequent tokens, effectively reducing the number of multiply-accumulates, as\nwell as the internal tensor data sizes. The approach is evaluated on the Google\nSpeech Commands Dataset for keyword spotting, and the performance is compared\nagainst the baseline Keyword Transformer. Our experiments show that we can\nreduce ~80% of operations while maintaining the original 98.4% accuracy.\nMoreover, a reduction of ~87-94% operations can be achieved when only degrading\nthe accuracy by 1-4%, speeding up the multi-head self-attention inference by a\nfactor of ~7.5-16.",
          "link": "http://arxiv.org/abs/2204.03479",
          "publishedOn": "2022-04-09T00:48:55.309Z",
          "wordCount": null,
          "title": "Delta Keyword Transformer: Bringing Transformers to the Edge through Dynamically Pruned Multi-Head Self-Attention. (arXiv:2204.03479v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.08850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimmermann_R/0/1/0/all/0/1\">Roland S. Zimmermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_S/0/1/0/all/0/1\">Steffen Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1\">Matthias Bethge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>",
          "description": "Contrastive learning has recently seen tremendous success in self-supervised\nlearning. So far, however, it is largely unclear why the learned\nrepresentations generalize so effectively to a large variety of downstream\ntasks. We here prove that feedforward models trained with objectives belonging\nto the commonly used InfoNCE family learn to implicitly invert the underlying\ngenerative model of the observed data. While the proofs make certain\nstatistical assumptions about the generative model, we observe empirically that\nour findings hold even if these assumptions are severely violated. Our theory\nhighlights a fundamental connection between contrastive learning, generative\nmodeling, and nonlinear independent component analysis, thereby furthering our\nunderstanding of the learned representations as well as providing a theoretical\nfoundation to derive more effective contrastive losses.",
          "link": "http://arxiv.org/abs/2102.08850",
          "publishedOn": "2022-04-09T00:48:55.309Z",
          "wordCount": null,
          "title": "Contrastive Learning Inverts the Data Generating Process. (arXiv:2102.08850v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.00135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_G/0/1/0/all/0/1\">Guanghui Lan</a>",
          "description": "We present new policy mirror descent (PMD) methods for solving reinforcement\nlearning (RL) problems with either strongly convex or general convex\nregularizers. By exploring the structural properties of these overall highly\nnonconvex problems we show that the PMD methods exhibit fast linear rate of\nconvergence to the global optimality. We develop stochastic counterparts of\nthese methods, and establish an ${\\cal O}(1/\\epsilon)$ (resp., ${\\cal\nO}(1/\\epsilon^2)$) sampling complexity for solving these RL problems with\nstrongly (resp., general) convex regularizers using different sampling schemes,\nwhere $\\epsilon$ denote the target accuracy. We further show that the\ncomplexity for computing the gradients of these regularizers, if necessary, can\nbe bounded by ${\\cal O}\\{(\\log_\\gamma \\epsilon) [(1-\\gamma)L/\\mu]^{1/2}\\log\n(1/\\epsilon)\\}$ (resp., ${\\cal O} \\{(\\log_\\gamma \\epsilon )\n(L/\\epsilon)^{1/2}\\}$)for problems with strongly (resp., general) convex\nregularizers. Here $\\gamma$ denotes the discounting factor. To the best of our\nknowledge, these complexity bounds, along with our algorithmic developments,\nappear to be new in both optimization and RL literature. The introduction of\nthese convex regularizers also greatly expands the flexibility and\napplicability of RL models.",
          "link": "http://arxiv.org/abs/2102.00135",
          "publishedOn": "2022-04-09T00:48:55.308Z",
          "wordCount": null,
          "title": "Policy Mirror Descent for Reinforcement Learning: Linear Convergence, New Sampling Complexity, and Generalized Problem Classes. (arXiv:2102.00135v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haller_S/0/1/0/all/0/1\">Stefan Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aldea_A/0/1/0/all/0/1\">Adina Aldea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seifert_C/0/1/0/all/0/1\">Christin Seifert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strisciuglio_N/0/1/0/all/0/1\">Nicola Strisciuglio</a>",
          "description": "Automated short answer grading (ASAG) has gained attention in education as a\nmeans to scale educational tasks to the growing number of students. Recent\nprogress in Natural Language Processing and Machine Learning has largely\ninfluenced the field of ASAG, of which we survey the recent research\nadvancements. We complement previous surveys by providing a comprehensive\nanalysis of recently published methods that deploy deep learning approaches. In\nparticular, we focus our analysis on the transition from hand engineered\nfeatures to representation learning approaches, which learn representative\nfeatures for the task at hand automatically from large corpora of data. We\nstructure our analysis of deep learning methods along three categories: word\nembeddings, sequential models, and attention-based methods. Deep learning\nimpacted ASAG differently than other fields of NLP, as we noticed that the\nlearned representations alone do not contribute to achieve the best results,\nbut they rather show to work in a complementary way with hand-engineered\nfeatures. The best performance are indeed achieved by methods that combine the\ncarefully hand-engineered features with the power of the semantic descriptions\nprovided by the latest models, like transformers architectures. We identify\nchallenges and provide an outlook on research direction that can be addressed\nin the future",
          "link": "http://arxiv.org/abs/2204.03503",
          "publishedOn": "2022-04-09T00:48:55.306Z",
          "wordCount": null,
          "title": "Survey on Automated Short Answer Grading with Deep Learning: from Word Embeddings to Transformers. (arXiv:2204.03503v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.03081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_D/0/1/0/all/0/1\">Delaram Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeibi_A/0/1/0/all/0/1\">Afshin Shoeibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_N/0/1/0/all/0/1\">Navid Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moridian_P/0/1/0/all/0/1\">Parisa Moridian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadem_A/0/1/0/all/0/1\">Ali Khadem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadehsani_R/0/1/0/all/0/1\">Roohallah Alizadehsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshnehlab_M/0/1/0/all/0/1\">Mohammad Teshnehlab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorriz_J/0/1/0/all/0/1\">J. Manuel Gorriz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khozeimeh_F/0/1/0/all/0/1\">Fahime Khozeimeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu-Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1\">Saeid Nahavandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_U/0/1/0/all/0/1\">U Rajendra Acharya</a>",
          "description": "Schizophrenia (SZ) is a mental disorder that typically emerges in late\nadolescence or early adulthood. It reduces the life expectancy of patients by\n15 years. Abnormal behavior, perception of emotions, social relationships, and\nreality perception are among its most significant symptoms. Past studies have\nrevealed the temporal and anterior lobes of hippocampus regions of brain get\naffected by SZ. Also, increased volume of cerebrospinal fluid (CSF) and\ndecreased volume of white and gray matter can be observed due to this disease.\nThe magnetic resonance imaging (MRI) is the popular neuroimaging technique used\nto explore structural/functional brain abnormalities in SZ disorder owing to\nits high spatial resolution. Various artificial intelligence (AI) techniques\nhave been employed with advanced image/signal processing methods to obtain\naccurate diagnosis of SZ. This paper presents a comprehensive overview of\nstudies conducted on automated diagnosis of SZ using MRI modalities. Main\nfindings, various challenges, and future works in developing the automated SZ\ndetection are described in this paper.",
          "link": "http://arxiv.org/abs/2103.03081",
          "publishedOn": "2022-04-09T00:48:55.306Z",
          "wordCount": null,
          "title": "An Overview on Artificial Intelligence Techniques for Diagnosis of Schizophrenia Based on Magnetic Resonance Imaging Modalities: Methods, Challenges, and Future Works. (arXiv:2103.03081v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengchuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Bin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Ce Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "Visual recognition is recently learned via either supervised learning on\nhuman-annotated image-label data or language-image contrastive learning with\nwebly-crawled image-text pairs. While supervised learning may result in a more\ndiscriminative representation, language-image pretraining shows unprecedented\nzero-shot recognition capability, largely due to the different properties of\ndata sources and learning objectives. In this work, we introduce a new\nformulation by combining the two data sources into a common image-text-label\nspace. In this space, we propose a new learning paradigm, called Unified\nContrastive Learning (UniCL) with a single learning objective to seamlessly\nprompt the synergy of two data types. Extensive experiments show that our UniCL\nis an effective way of learning semantically rich yet discriminative\nrepresentations, universally for image recognition in zero-shot, linear-probe,\nfully finetuning and transfer learning scenarios. Particularly, it attains\ngains up to 9.2% and 14.5% in average on zero-shot recognition benchmarks over\nthe language-image contrastive learning and supervised learning methods,\nrespectively. In linear probe setting, it also boosts the performance over the\ntwo methods by 7.3% and 3.4%, respectively. Our study also indicates that UniCL\nstand-alone is a good learner on pure image-label data, rivaling the supervised\nlearning methods across three image classification datasets and two types of\nvision backbones, ResNet and Swin Transformer. Code is available at\nhttps://github.com/microsoft/UniCL.",
          "link": "http://arxiv.org/abs/2204.03610",
          "publishedOn": "2022-04-09T00:48:55.305Z",
          "wordCount": null,
          "title": "Unified Contrastive Learning in Image-Text-Label Space. (arXiv:2204.03610v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03572",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rocha_K/0/1/0/all/0/1\">Karoline da Rocha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bermudez_J/0/1/0/all/0/1\">Jos&#xe9; C. M. Bermudez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rivero_E/0/1/0/all/0/1\">Elena R. C. Rivero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Costa_M/0/1/0/all/0/1\">M&#xe1;rcio H. Costa</a>",
          "description": "The Epithelial Dysplasia (ED) is a tissue alteration commonly present in\nlesions preceding oral cancer, being its presence one of the most important\nfactors in the progression toward carcinoma. This study proposes a method to\ndesign a low computational cost classification system to support the detection\nof dysplastic epithelia, contributing to reduce the variability of pathologist\nassessments. We employ a multilayer artificial neural network (MLP-ANN) and\ndefining the regions of the epithelium to be assessed based on the knowledge of\nthe pathologist. The performance of the proposed solution was statistically\nevaluated. The implemented MLP-ANN presented an average accuracy of 87%, with a\nvariability much inferior to that obtained from three trained evaluators.\nMoreover, the proposed solution led to results which are very close to those\nobtained using a convolutional neural network (CNN) implemented by transfer\nlearning, with 100 times less computational complexity. In conclusion, our\nresults show that a simple neural network structure can lead to a performance\nequivalent to that of much more complex structures, which are routinely used in\nthe literature.",
          "link": "http://arxiv.org/abs/2204.03572",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "A Pathology-Based Machine Learning Method to Assist in Epithelial Dysplasia Diagnosis. (arXiv:2204.03572v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeh_R/0/1/0/all/0/1\">Raymond A. Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuan-Ting Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1\">Mark Hasegawa-Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>",
          "description": "Designing equivariance as an inductive bias into deep-nets has been a\nprominent approach to build effective models, e.g., a convolutional neural\nnetwork incorporates translation equivariance. However, incorporating these\ninductive biases requires knowledge about the equivariance properties of the\ndata, which may not be available, e.g., when encountering a new domain. To\naddress this, we study how to discover interpretable equivariances from data.\nSpecifically, we formulate this discovery process as an optimization problem\nover a model's parameter-sharing schemes. We propose to use the partition\ndistance to empirically quantify the accuracy of the recovered equivariance.\nAlso, we theoretically analyze the method for Gaussian data and provide a bound\non the mean squared gap between the studied discovery scheme and the oracle\nscheme. Empirically, we show that the approach recovers known equivariances,\nsuch as permutations and shifts, on sum of numbers and spatially-invariant\ndata.",
          "link": "http://arxiv.org/abs/2204.03640",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "Equivariance Discovery by Learned Parameter-Sharing. (arXiv:2204.03640v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02601",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lock_E/0/1/0/all/0/1\">Eric F. Lock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1\">Jun Young Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hoadley_K/0/1/0/all/0/1\">Katherine A. Hoadley</a>",
          "description": "Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.",
          "link": "http://arxiv.org/abs/2002.02601",
          "publishedOn": "2022-04-09T00:48:55.304Z",
          "wordCount": null,
          "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer analysis. (arXiv:2002.02601v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1\">Shounak Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullick_S/0/1/0/all/0/1\">Sankha Subhra Mullick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Swagatam Das</a>",
          "description": "Few-shot learning aims to transfer the knowledge acquired from training on a\ndiverse set of tasks, from a given task distribution, to generalize to unseen\ntasks, from the same distribution, with a limited amount of labeled data. The\nunderlying requirement for effective few-shot generalization is to learn a good\nrepresentation of the task manifold. One way to encourage this is to preserve\nlocal neighborhoods in the feature space learned by the few-shot learner. To\nthis end, we introduce the notion of interval bounds from the provably robust\ntraining literature to few-shot learning. The interval bounds are used to\ncharacterize neighborhoods around the training tasks. These neighborhoods can\nthen be preserved by minimizing the distance between a task and its respective\nbounds. We further introduce a novel strategy to artificially form new tasks\nfor training by interpolating between the available tasks and their respective\ninterval bounds, to aid in cases with a scarcity of tasks. We apply our\nframework to both model-agnostic meta-learning as well as prototype-based\nmetric-learning paradigms. The efficacy of our proposed approach is evident\nfrom the improved performance on several datasets from diverse domains in\ncomparison to a sizable number of recent competitors.",
          "link": "http://arxiv.org/abs/2204.03511",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "Interval Bound Propagation--aided Few-shot Learning. (arXiv:2204.03511v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03573",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tiwari_S/0/1/0/all/0/1\">Sadhana Tiwari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Sonali Agarwal</a>",
          "description": "Stress, anxiety, and nervousness are all high-risk health states in everyday\nlife. Previously, stress levels were determined by speaking with people and\ngaining insight into what they had experienced recently or in the past.\nTypically, stress is caused by an incidence that occurred a long time ago, but\nsometimes it is triggered by unknown factors. This is a challenging and complex\ntask, but recent research advances have provided numerous opportunities to\nautomate it. The fundamental features of most of these techniques are electro\ndermal activity (EDA) and heart rate values (HRV). We utilized an accelerometer\nto measure body motions to solve this challenge. The proposed novel method\nemploys a test that measures a subject's electrocardiogram (ECG), galvanic skin\nvalues (GSV), HRV values, and body movements in order to provide a low-cost and\ntime-saving solution for detecting stress lifestyle disease in modern times\nusing cyber physical systems. This study provides a new hybrid model for\nlifestyle disease classification that decreases execution time while picking\nthe best collection of characteristics and increases classification accuracy.\nThe developed approach is capable of dealing with the class imbalance problem\nby using WESAD (wearable stress and affect dataset) dataset. The new model uses\nthe Grid search (GS) method to select an optimized set of hyper parameters, and\nit uses a combination of the Correlation coefficient based Recursive feature\nelimination (CoC-RFE) method for optimal feature selection and gradient\nboosting as an estimator to classify the dataset, which achieves high accuracy\nand helps to provide smart, accurate, and high-quality healthcare systems. To\ndemonstrate the validity and utility of the proposed methodology, its\nperformance is compared to those of other well-established machine learning\nmodels.",
          "link": "http://arxiv.org/abs/2204.03573",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "An optimized hybrid solution for IoT based lifestyle disease classification using stress data. (arXiv:2204.03573v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.07401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qiaomin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modiano_E/0/1/0/all/0/1\">Eytan Modiano</a>",
          "description": "With the rapid advance of information technology, network systems have become\nincreasingly complex and hence the underlying system dynamics are often unknown\nor difficult to characterize. Finding a good network control policy is of\nsignificant importance to achieve desirable network performance (e.g., high\nthroughput or low delay). In this work, we consider using model-based\nreinforcement learning (RL) to learn the optimal control policy for queueing\nnetworks so that the average job delay (or equivalently the average queue\nbacklog) is minimized. Traditional approaches in RL, however, cannot handle the\nunbounded state spaces of the network control problem. To overcome this\ndifficulty, we propose a new algorithm, called Reinforcement Learning for\nQueueing Networks (RL-QN), which applies model-based RL methods over a finite\nsubset of the state space, while applying a known stabilizing policy for the\nrest of the states. We establish that the average queue backlog under RL-QN\nwith an appropriately constructed subset can be arbitrarily close to the\noptimal result. We evaluate RL-QN in dynamic server allocation, routing and\nswitching problems. Simulation results show that RL-QN minimizes the average\nqueue backlog effectively.",
          "link": "http://arxiv.org/abs/2011.07401",
          "publishedOn": "2022-04-09T00:48:55.303Z",
          "wordCount": null,
          "title": "RL-QN: A Reinforcement Learning Framework for Optimal Control of Queueing Systems. (arXiv:2011.07401v2 [cs.PF] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abaho_M/0/1/0/all/0/1\">M. Abaho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">D. Bollegala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williamson_P/0/1/0/all/0/1\">P. Williamson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodd_S/0/1/0/all/0/1\">S. Dodd</a>",
          "description": "Probing Pre-trained Language Models (PLMs) using prompts has indirectly\nimplied that language models (LMs) can be treated as knowledge bases. To this\nend, this phenomena has been effective especially when these LMs are fine-tuned\ntowards not just data of a specific domain, but also to the style or linguistic\npattern of the prompts themselves. We observe that, satisfying a particular\nlinguistic pattern in prompts is an unsustainable constraint that unnecessarily\nlengthens the probing task, especially because, they are often manually\ndesigned and the range of possible prompt template patterns can vary depending\non the prompting objective and domain. We therefore explore an idea of using a\nposition-attention mechanism to capture positional information of each word in\na prompt relative to the mask to be filled, hence avoiding the need to\nre-construct prompts when the prompts linguistic pattern changes. Using our\napproach, we demonstrate the ability of eliciting answers to rare prompt\ntemplates (in a case study on health outcome generation) such as Postfix and\nMixed patterns whose missing information is respectively at the start and in\nmultiple random places of the prompt. More so, using various biomedical PLMs,\nour approach consistently outperforms a baseline in which the default mask\nlanguage model (MLM) representation is used to predict masked tokens.",
          "link": "http://arxiv.org/abs/2204.03489",
          "publishedOn": "2022-04-09T00:48:55.302Z",
          "wordCount": null,
          "title": "Position-based Prompting for Health Outcome Generation. (arXiv:2204.03489v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Songlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>",
          "description": "Second-order semantic parsing with end-to-end mean-field inference has been\nshown good performance. In this work we aim to improve this method by modeling\nlabel correlations between adjacent arcs. However, direct modeling leads to\nmemory explosion because second-order score tensors have sizes of $O(n^3L^2)$\n($n$ is the sentence length and $L$ is the number of labels), which is not\naffordable. To tackle this computational challenge, we leverage tensor\ndecomposition techniques, and interestingly, we show that the large\nsecond-order score tensors have no need to be materialized during mean-field\ninference, thereby reducing the computational complexity from cubic to\nquadratic. We conduct experiments on SemEval 2015 Task 18 English datasets,\nshowing the effectiveness of modeling label correlations. Our code is publicly\navailable at https://github.com/sustcsonglin/mean-field-dep-parsing.",
          "link": "http://arxiv.org/abs/2204.03619",
          "publishedOn": "2022-04-09T00:48:55.302Z",
          "wordCount": null,
          "title": "Modeling Label Correlations for Second-Order Semantic Dependency Parsing with Mean-Field Inference. (arXiv:2204.03619v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tingting Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Siyao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>",
          "description": "As an emerging technology, federated learning (FL) involves training machine\nlearning models over distributed edge devices, which attracts sustained\nattention and has been extensively studied. However, the heterogeneity of\nclient data severely degrades the performance of FL compared with that in\ncentralized training. It causes the locally trained models of clients to move\nin different directions. On the one hand, it slows down or even stalls the\nglobal updates, leading to inefficient communication. On the other hand, it\nenlarges the distances between local models, resulting in an aggregated global\nmodel with poor performance. Fortunately, these shortcomings can be mitigated\nby reducing the angle between the directions that local models move in. Based\non this fact, we propose FedCos, which reduces the directional inconsistency of\nlocal models by introducing a cosine-similarity penalty. It promotes the local\nmodel iterations towards an auxiliary global direction. Moreover, our approach\nis auto-adapt to various non-IID settings without an elaborate selection of\nhyperparameters. The experimental results show that FedCos outperforms the\nwell-known baselines and can enhance them under a variety of FL scenes,\nincluding varying degrees of data heterogeneity, different number of\nparticipants, and cross-silo and cross-device settings. Besides, FedCos\nimproves communication efficiency by 2 to 5 times. With the help of FedCos,\nmultiple FL methods require significantly fewer communication rounds than\nbefore to obtain a model with comparable performance.",
          "link": "http://arxiv.org/abs/2204.03174",
          "publishedOn": "2022-04-09T00:48:55.301Z",
          "wordCount": null,
          "title": "FedCos: A Scene-adaptive Federated Optimization Enhancement for Performance Improvement. (arXiv:2204.03174v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "We introduce distributed NLI, a new NLU task with a goal to predict the\ndistribution of human judgements for natural language inference. We show that\nby applying additional distribution estimation methods, namely, Monte Carlo\n(MC) Dropout, Deep Ensemble, Re-Calibration, and Distribution Distillation,\nmodels can capture human judgement distribution more effectively than the\nsoftmax baseline. We show that MC Dropout is able to achieve decent performance\nwithout any distribution annotations while Re-Calibration can give further\nimprovements with extra distribution annotations, suggesting the value of\nmultiple annotations for one example in modeling the distribution of human\njudgements. Despite these improvements, the best results are still far below\nthe estimated human upper-bound, indicating that predicting the distribution of\nhuman judgements is still an open, challenging problem with a large room for\nimprovements. We showcase the common errors for MC Dropout and Re-Calibration.\nFinally, we give guidelines on the usage of these methods with different levels\nof data availability and encourage future work on modeling the human opinion\ndistribution for language reasoning. Our code and data are publicly available\nat https://github.com/easonnie/ChaosNLI",
          "link": "http://arxiv.org/abs/2104.08676",
          "publishedOn": "2022-04-09T00:48:55.301Z",
          "wordCount": null,
          "title": "Distributed NLI: Learning to Predict Human Opinion Distributions for Language Reasoning. (arXiv:2104.08676v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barkhof_C/0/1/0/all/0/1\">Claartje Barkhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1\">Wilker Aziz</a>",
          "description": "We propose a framework for the statistical evaluation of variational\nauto-encoders (VAEs) and test two instances of this framework in the context of\nmodelling images of handwritten digits and a corpus of English text. Our take\non evaluation is based on the idea of statistical model criticism, popular in\nBayesian data analysis, whereby a statistical model is evaluated in terms of\nits ability to reproduce statistics of an unknown data generating process from\nwhich we can obtain samples. A VAE learns not one, but two joint distributions\nover a shared sample space, each exploiting a choice of factorisation that\nmakes sampling tractable in one of two directions (latent-to-data,\ndata-to-latent). We evaluate samples from these distributions, assessing their\n(marginal) fit to the observed data and our choice of prior, and we also\nevaluate samples through a pipeline that connects the two distributions\nstarting from a data sample, assessing whether together they exploit and reveal\nlatent factors of variation that are useful to a practitioner. We show that\nthis methodology offers possibilities for model selection qualitatively beyond\nintrinsic evaluation metrics and at a finer granularity than commonly used\nstatistics can offer.",
          "link": "http://arxiv.org/abs/2204.03030",
          "publishedOn": "2022-04-09T00:48:55.300Z",
          "wordCount": null,
          "title": "Statistical Model Criticism of Variational Auto-Encoders. (arXiv:2204.03030v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bazzan_A/0/1/0/all/0/1\">Ana L. C. Bazzan</a>",
          "description": "As the demand for mobility in our society seems to increase, the various\nissues centered on urban mobility are among those that worry most city\ninhabitants in this planet. For instance, how to go from A to B in an efficient\n(but also less stressful) way? These questions and concerns have not changed\neven during the covid-19 pandemic; on the contrary, as the current stand,\npeople who are avoiding public transportation are only contributing to an\nincrease in the vehicular traffic. The are of intelligent transportation\nsystems (ITS) aims at investigating how to employ information and communication\ntechnologies to problems related to transportation. This may mean monitoring\nand managing the infrastructure (e.g., traffic roads, traffic signals, etc.).\nHowever, currently, ITS is also targeting the management of demand. In this\npanorama, artificial intelligence plays an important role, especially with the\nadvances in machine learning that translates in the use of computational\nvision, connected and autonomous vehicles, agent-based simulation, among\nothers. In the present work, a survey of several works developed by our group\nare discussed in a holistic perspective, i.e., they cover not only the supply\nside (as commonly found in ITS works), but also the demand side, and, in an\nnovel perspective, the integration of both.",
          "link": "http://arxiv.org/abs/2204.03570",
          "publishedOn": "2022-04-09T00:48:55.300Z",
          "wordCount": null,
          "title": "Improving Urban Mobility: using artificial intelligence and new technologies to connect supply and demand. (arXiv:2204.03570v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shaowu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunton_S/0/1/0/all/0/1\">Steven L. Brunton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "High-dimensional spatio-temporal dynamics can often be encoded in a\nlow-dimensional subspace. Engineering applications for modeling,\ncharacterization, design, and control of such large-scale systems often rely on\ndimensionality reduction to make solutions computationally tractable in\nreal-time. Common existing paradigms for dimensionality reduction include\nlinear methods, such as the singular value decomposition (SVD), and nonlinear\nmethods, such as variants of convolutional autoencoders (CAE). However, these\nencoding techniques lack the ability to efficiently represent the complexity\nassociated with spatio-temporal data, which often requires variable geometry,\nnon-uniform grid resolution, adaptive meshing, and/or parametric\ndependencies.To resolve these practical engineering challenges, we propose a\ngeneral framework called Neural Implicit Flow (NIF) that enables a\nmesh-agnostic, low-rank representation of large-scale, parametric,\nspatial-temporal data. NIF consists of two modified multilayer perceptrons\n(MLPs): (i) ShapeNet, which isolates and represents the spatial complexity, and\n(ii) ParameterNet, which accounts for any other input complexity, including\nparametric dependencies, time, and sensor measurements. We demonstrate the\nutility of NIF for parametric surrogate modeling, enabling the interpretable\nrepresentation and compression of complex spatio-temporal dynamics, efficient\nmany-spatial-query tasks, and improved generalization performance for sparse\nreconstruction.",
          "link": "http://arxiv.org/abs/2204.03216",
          "publishedOn": "2022-04-09T00:48:55.299Z",
          "wordCount": null,
          "title": "Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm of spatio-temporal data. (arXiv:2204.03216v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1\">Tal Ridnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawen_H/0/1/0/all/0/1\">Hussam Lawen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1\">Emanuel Ben-Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1\">Asaf Noy</a>",
          "description": "ImageNet serves as the primary dataset for evaluating the quality of\ncomputer-vision models. The common practice today is training each architecture\nwith a tailor-made scheme, designed and tuned by an expert. In this paper, we\npresent a unified scheme for training any backbone on ImageNet. The scheme,\nnamed USI (Unified Scheme for ImageNet), is based on knowledge distillation and\nmodern tricks. It requires no adjustments or hyper-parameters tuning between\ndifferent models, and is efficient in terms of training times. We test USI on a\nwide variety of architectures, including CNNs, Transformers, Mobile-oriented\nand MLP-only. On all models tested, USI outperforms previous state-of-the-art\nresults. Hence, we are able to transform training on ImageNet from an\nexpert-oriented task to an automatic seamless routine. Since USI accepts any\nbackbone and trains it to top results, it also enables to perform methodical\ncomparisons, and identify the most efficient backbones along the speed-accuracy\nPareto curve. Implementation is available\nat:https://github.com/Alibaba-MIIL/Solving_ImageNet",
          "link": "http://arxiv.org/abs/2204.03475",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results. (arXiv:2204.03475v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chau_R/0/1/0/all/0/1\">Rodrigo Chau</a>",
          "description": "We investigate the \"Visual Pushing for Grasping\" (VPG) system by Zeng et al.\nand the \"Hourglass\" system by Ewerton et al., an evolution of the former. The\nfocus of our work is the investigation of the capabilities of both systems to\nlearn long-term rewards and policies. Zeng et al. original task only needs a\nlimited amount of foresight. Ewerton et al. attain their best performance using\nan agent which only takes the most immediate action under consideration. We are\ninterested in the ability of their models and training algorithms to accurately\npredict long-term Q-Values. To evaluate this ability, we design a new bin\nsorting task and reward function. Our task requires agents to accurately\nestimate future rewards and therefore use high discount factors in their\nQ-Value calculation. We investigate the behaviour of an adaptation of the VPG\ntraining algorithm on our task. We show that this adaptation can not accurately\npredict the required long-term action sequences. In addition to the limitations\nidentified by Ewerton et al., it suffers from the known Deep Q-Learning problem\nof overestimated Q-Values. In an effort to solve our task, we turn to the\nHourglass models and combine them with the Double Q-Learning approach. We show\nthat this approach enables the models to accurately predict long-term action\nsequences when trained with large discount factors. Our results show that the\nDouble Q-Learning technique is essential for training with very high discount\nfactors, as the models Q-Value predictions diverge otherwise. We also\nexperiment with different approaches for discount factor scheduling, loss\ncalculation and exploration procedures. Our results show that the latter\nfactors do not visibly influence the model's performance for our task.",
          "link": "http://arxiv.org/abs/2204.03487",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Optimizing the Long-Term Behaviour of Deep Reinforcement Learning for Pushing and Grasping. (arXiv:2204.03487v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nayak_N/0/1/0/all/0/1\">Nihal V. Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peilin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>",
          "description": "We introduce compositional soft prompting (CSP), a parameter-efficient\nlearning technique to improve the zero-shot compositionality of large-scale\npretrained vision-language models (VLMs) without the overhead of fine-tuning\nthe entire model. VLMs can represent arbitrary classes as natural language\nprompts in their flexible text encoders but they underperform state-of-the-art\nmethods on compositional zero-shot benchmark tasks. To improve VLMs, we propose\na novel form of soft prompting. We treat the attributes and objects that are\ncomposed to define classes as learnable tokens of vocabulary and tune them on\nmultiple prompt compositions. During inference, we recompose the learned\nattribute-object vocabulary in new combinations and show that CSP outperforms\nthe original VLM on benchmark datasets by an average of 14.7 percentage points\nof accuracy. CSP also achieves new state-of-the-art accuracies on two out of\nthree benchmark datasets, while only fine-tuning a small number of parameters.\nFurther, we show that CSP improves generalization to higher-order\nattribute-attribute-object compositions and combinations of pretrained\nattributes and fine-tuned objects.",
          "link": "http://arxiv.org/abs/2204.03574",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Learning to Compose Soft Prompts for Compositional Zero-Shot Learning. (arXiv:2204.03574v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ribas_C/0/1/0/all/0/1\">Celso H. H. Ribas</a> (1,2), <a href=\"http://arxiv.org/find/cs/1/au:+Bermudez_J/0/1/0/all/0/1\">Jos&#xe9; C. M. Bermudez</a> (1) ((1) Digital Signal Processing Research Laboratory, Federal University of Santa Catarina, Santa Catarina, Brazil, (2) Superintendence of Inspection, National Telecommunications Agency, Amazonas, Brazil)",
          "description": "Access to data and data processing, including the use of machine learning\ntechniques, has become significantly easier and cheaper in recent years.\nNevertheless, solutions that can be widely adopted by regulators for market\nmonitoring and inspection targeting in a data-driven way have not been\nfrequently discussed by the scientific community. This article discusses the\nneed and the difficulties for the development of such solutions, presents an\neffective method to address regulation planning, and illustrates its use to\naccount for the most important and common subject for the majority of\nregulators: the consumer. This article hopes to contribute to increase the\nawareness of the regulatory community to the need for data processing methods\nthat are objective, impartial, transparent, explainable, simple to implement\nand with low computational cost, aiming to the implementation of risk-based\nregulation in the world.",
          "link": "http://arxiv.org/abs/2204.03583",
          "publishedOn": "2022-04-09T00:48:55.298Z",
          "wordCount": null,
          "title": "Risk-based regulation for all: The need and a method for a wide adoption solution for data-driven inspection targeting. (arXiv:2204.03583v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huertas_Tato_J/0/1/0/all/0/1\">Javier Huertas-Tato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1\">Alejandro Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_D/0/1/0/all/0/1\">David Camacho</a>",
          "description": "The appearance of complex attention-based language models such as BERT,\nRoberta or GPT-3 has allowed to address highly complex tasks in a plethora of\nscenarios. However, when applied to specific domains, these models encounter\nconsiderable difficulties. This is the case of Social Networks such as Twitter,\nan ever-changing stream of information written with informal and complex\nlanguage, where each message requires careful evaluation to be understood even\nby humans given the important role that context plays. Addressing tasks in this\ndomain through Natural Language Processing involves severe challenges. When\npowerful state-of-the-art multilingual language models are applied to this\nscenario, language specific nuances use to get lost in translation. To face\nthese challenges we present \\textbf{BERTuit}, the larger transformer proposed\nso far for Spanish language, pre-trained on a massive dataset of 230M Spanish\ntweets using RoBERTa optimization. Our motivation is to provide a powerful\nresource to better understand Spanish Twitter and to be used on applications\nfocused on this social network, with special emphasis on solutions devoted to\ntackle the spreading of misinformation in this platform. BERTuit is evaluated\non several tasks and compared against M-BERT, XLM-RoBERTa and XLM-T, very\ncompetitive multilingual transformers. The utility of our approach is shown\nwith applications, in this case: a zero-shot methodology to visualize groups of\nhoaxes and profiling authors spreading disinformation.\n\nMisinformation spreads wildly on platforms such as Twitter in languages other\nthan English, meaning performance of transformers may suffer when transferred\noutside English speaking communities.",
          "link": "http://arxiv.org/abs/2204.03465",
          "publishedOn": "2022-04-09T00:48:55.297Z",
          "wordCount": null,
          "title": "BERTuit: Understanding Spanish language in Twitter through a native transformer. (arXiv:2204.03465v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "Various neural network models have been proposed to tackle combinatorial\noptimization problems such as the travelling salesman problem (TSP). Existing\nlearning-based TSP methods adopt a simple setting that the training and testing\ndata are independent and identically distributed. However, the existing\nliterature fails to solve TSP instances when training and testing data have\ndifferent distributions. Concretely, we find that different training and\ntesting distribution will result in more difficult TSP instances, i.e., the\nsolution obtained by the model has a large gap from the optimal solution. To\ntackle this problem, in this work, we study learning-based TSP methods when\ntraining and testing data have different distributions using adaptive-hardness,\ni.e., how difficult a TSP instance can be for a solver. This problem is\nchallenging because it is non-trivial to (1) define hardness measurement\nquantitatively; (2) efficiently and continuously generate sufficiently hard TSP\ninstances upon model training; (3) fully utilize instances with different\nlevels of hardness to learn a more powerful TSP solver. To solve these\nchallenges, we first propose a principled hardness measurement to quantify the\nhardness of TSP instances. Then, we propose a hardness-adaptive generator to\ngenerate instances with different hardness. We further propose a curriculum\nlearner fully utilizing these instances to train the TSP solver. Experiments\nshow that our hardness-adaptive generator can generate instances ten times\nharder than the existing methods, and our proposed method achieves significant\nimprovement over state-of-the-art models in terms of the optimality gap.",
          "link": "http://arxiv.org/abs/2204.03236",
          "publishedOn": "2022-04-09T00:48:55.295Z",
          "wordCount": null,
          "title": "Learning to Solve Travelling Salesman Problem with Hardness-adaptive Curriculum. (arXiv:2204.03236v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yao-Yuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1\">Jaros&#x142;aw B&#x142;asiok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>",
          "description": "We investigate and leverage a connection between Differential Privacy (DP)\nand the recently proposed notion of Distributional Generalization (DG).\nApplying this connection, we introduce new conceptual tools for designing\ndeep-learning methods that bypass \"pathologies\" of standard stochastic gradient\ndescent (SGD). First, we prove that differentially private methods satisfy a\n\"What You See Is What You Get (WYSIWYG)\" generalization guarantee: whatever a\nmodel does on its train data is almost exactly what it will do at test time.\nThis guarantee is formally captured by distributional generalization. WYSIWYG\nenables principled algorithm design in deep learning by reducing\n$\\textit{generalization}$ concerns to $\\textit{optimization}$ ones: in order to\nmitigate unwanted behavior at test time, it is provably sufficient to mitigate\nthis behavior on the train data. This is notably false for standard (non-DP)\nmethods, hence this observation has applications even when privacy is not\nrequired. For example, importance sampling is known to fail for standard SGD,\nbut we show that it has exactly the intended effect for DP-trained models.\nThus, with DP-SGD, unlike with SGD, we can influence test-time behavior by\nmaking principled train-time interventions. We use these insights to construct\nsimple algorithms which match or outperform SOTA in several distributional\nrobustness applications, and to significantly improve the privacy vs. disparate\nimpact trade-off of DP-SGD. Finally, we also improve on known theoretical\nbounds relating differential privacy, stability, and distributional\ngeneralization.",
          "link": "http://arxiv.org/abs/2204.03230",
          "publishedOn": "2022-04-09T00:48:55.291Z",
          "wordCount": null,
          "title": "What You See is What You Get: Distributional Generalization for Algorithm Design in Deep Learning. (arXiv:2204.03230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sibo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianhua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasiou_C/0/1/0/all/0/1\">Charitos Anastasiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angeli_P/0/1/0/all/0/1\">Panagiota Angeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matar_O/0/1/0/all/0/1\">Omar K. Matar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi-Ke Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pain_C/0/1/0/all/0/1\">Christopher C. Pain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcucci_R/0/1/0/all/0/1\">Rossella Arcucci</a>",
          "description": "Reduced-order modelling and low-dimensional surrogate models generated using\nmachine learning algorithms have been widely applied in high-dimensional\ndynamical systems to improve the algorithmic efficiency. In this paper, we\ndevelop a system which combines reduced-order surrogate models with a novel\ndata assimilation (DA) technique used to incorporate real-time observations\nfrom different physical spaces. We make use of local smooth surrogate functions\nwhich link the space of encoded system variables and the one of current\nobservations to perform variational DA with a low computational cost. The new\nsystem, named Generalised Latent Assimilation can benefit both the efficiency\nprovided by the reduced-order modelling and the accuracy of data assimilation.\nA theoretical analysis of the difference between surrogate and original\nassimilation cost function is also provided in this paper where an upper bound,\ndepending on the size of the local training set, is given. The new approach is\ntested on a high-dimensional CFD application of a two-phase liquid flow with\nnon-linear observation operators that current Latent Assimilation methods can\nnot handle. Numerical results demonstrate that the proposed assimilation\napproach can significantly improve the reconstruction and prediction accuracy\nof the deep learning surrogate model which is nearly 1000 times faster than the\nCFD simulation.",
          "link": "http://arxiv.org/abs/2204.03497",
          "publishedOn": "2022-04-09T00:48:55.291Z",
          "wordCount": null,
          "title": "Generalised Latent Assimilation in Heterogeneous Reduced Spaces with Machine Learning Surrogate Models. (arXiv:2204.03497v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minkyu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hyun-Soo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jinho Kim</a>",
          "description": "Graph neural networks are powerful methods to handle graph-structured data.\nHowever, existing graph neural networks only learn higher-order feature\ninteractions implicitly. Thus, they cannot capture information that occurred in\nlow-order feature interactions. To overcome this problem, we propose Explicit\nFeature Interaction-aware Graph Neural Network (EFI-GNN), which explicitly\nlearns arbitrary-order feature interactions. EFI-GNN can jointly learn with any\nother graph neural network. We demonstrate that the joint learning method\nalways enhances performance on the various node classification tasks.\nFurthermore, since EFI-GNN is inherently a linear model, we can interpret the\nprediction result of EFI-GNN. With the computation rule, we can obtain an\nany-order feature's effect on the decision. By that, we visualize the effects\nof the first-order and second-order features as a form of a heatmap.",
          "link": "http://arxiv.org/abs/2204.03225",
          "publishedOn": "2022-04-09T00:48:55.282Z",
          "wordCount": null,
          "title": "Explicit Feature Interaction-aware Graph Neural Networks. (arXiv:2204.03225v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03439",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Gebhard_T/0/1/0/all/0/1\">Timothy D. Gebhard</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bonse_M/0/1/0/all/0/1\">Markus J. Bonse</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Quanz_S/0/1/0/all/0/1\">Sascha P. Quanz</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "High-contrast imaging of exoplanets hinges on powerful post-processing\nmethods to denoise the data and separate the signal of a companion from its\nhost star, which is typically orders of magnitude brighter. Existing\npost-processing algorithms do not use all prior domain knowledge that is\navailable about the problem. We propose a new method that builds on our\nunderstanding of the systematic noise and the causal structure of the\ndata-generating process. Our algorithm is based on a modified version of\nhalf-sibling regression (HSR), a flexible denoising framework that combines\nideas from the fields of machine learning and causality. We adapt the method to\naddress the specific requirements of high-contrast exoplanet imaging data\nobtained in pupil tracking mode. The key idea is to estimate the systematic\nnoise in a pixel by regressing the time series of this pixel onto a set of\ncausally independent, signal-free predictor pixels. We use regularized linear\nmodels in this work; however, other (non-linear) models are also possible. In a\nsecond step, we demonstrate how the HSR framework allows us to incorporate\nobserving conditions such as wind speed or air temperature as additional\npredictors. When we apply our method to four data sets from the VLT/NACO\ninstrument, our algorithm provides a better false-positive fraction than\nPCA-based PSF subtraction, a popular baseline method in the field.\nAdditionally, we find that the HSR-based method provides direct and accurate\nestimates for the contrast of the exoplanets without the need to insert\nartificial companions for calibration in the data sets. Finally, we present\nfirst evidence that using the observing conditions as additional predictors can\nimprove the results. Our HSR-based method provides an alternative, flexible and\npromising approach to the challenge of modeling and subtracting the stellar PSF\nand systematic noise in exoplanet imaging data.",
          "link": "http://arxiv.org/abs/2204.03439",
          "publishedOn": "2022-04-09T00:48:55.280Z",
          "wordCount": null,
          "title": "Half-sibling regression meets exoplanet imaging: PSF modeling and subtraction using a flexible, domain knowledge-driven, causal framework. (arXiv:2204.03439v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vamsi Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_L/0/1/0/all/0/1\">Likith Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Kumar Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dadi_K/0/1/0/all/0/1\">Kamalakar Dadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarra_C/0/1/0/all/0/1\">Chiranjeevi Yarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raju_B/0/1/0/all/0/1\">Bapi S. Raju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajendran_S/0/1/0/all/0/1\">Srijithesh Rajendran</a>",
          "description": "Modeling effective representations using multiple views that positively\ninfluence each other is challenging, and the existing methods perform poorly on\nElectroencephalogram (EEG) signals for sleep-staging tasks. In this paper, we\npropose a novel multi-view self-supervised method (mulEEG) for unsupervised EEG\nrepresentation learning. Our method attempts to effectively utilize the\ncomplementary information available in multiple views to learn better\nrepresentations. We introduce diverse loss that further encourages\ncomplementary information across multiple views. Our method with no access to\nlabels beats the supervised training while outperforming multi-view baseline\nmethods on transfer learning experiments carried out on sleep-staging tasks. We\nposit that our method was able to learn better representations by using\ncomplementary multi-views.",
          "link": "http://arxiv.org/abs/2204.03272",
          "publishedOn": "2022-04-09T00:48:55.279Z",
          "wordCount": null,
          "title": "mulEEG: A Multi-View Representation Learning on EEG Signals. (arXiv:2204.03272v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vital_F/0/1/0/all/0/1\">F&#xe1;bio Vital</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasco_M/0/1/0/all/0/1\">Miguel Vasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sardinha_A/0/1/0/all/0/1\">Alberto Sardinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_F/0/1/0/all/0/1\">Francisco Melo</a>",
          "description": "We present Perceive-Represent-Generate (PRG), a novel three-stage framework\nthat maps perceptual information of different modalities (e.g., visual or\nsound), corresponding to a sequence of instructions, to an adequate sequence of\nmovements to be executed by a robot. In the first stage, we perceive and\npre-process the given inputs, isolating individual commands from the complete\ninstruction provided by a human user. In the second stage we encode the\nindividual commands into a multimodal latent space, employing a deep generative\nmodel. Finally, in the third stage we convert the multimodal latent values into\nindividual trajectories and combine them into a single dynamic movement\nprimitive, allowing its execution in a robotic platform. We evaluate our\npipeline in the context of a novel robotic handwriting task, where the robot\nreceives as input a word through different perceptual modalities (e.g., image,\nsound), and generates the corresponding motion trajectory to write it, creating\ncoherent and readable handwritten words.",
          "link": "http://arxiv.org/abs/2204.03051",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "Perceive, Represent, Generate: Translating Multimodal Information to Robotic Motion Trajectories. (arXiv:2204.03051v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_P/0/1/0/all/0/1\">Priya Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonova_R/0/1/0/all/0/1\">Rika Antonova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>",
          "description": "Research in manipulation of deformable objects is typically conducted on a\nlimited range of scenarios, because handling each scenario on hardware takes\nsignificant effort. Realistic simulators with support for various types of\ndeformations and interactions have the potential to speed up experimentation\nwith novel tasks and algorithms. However, for highly deformable objects it is\nchallenging to align the output of a simulator with the behavior of real\nobjects. Manual tuning is not intuitive, hence automated methods are needed. We\nview this alignment problem as a joint perception-inference challenge and\ndemonstrate how to use recent neural network architectures to successfully\nperform simulation parameter inference from real point clouds. We analyze the\nperformance of various architectures, comparing their data and training\nrequirements. Furthermore, we propose to leverage differentiable point cloud\nsampling and differentiable simulation to significantly reduce the time to\nachieve the alignment. We employ an efficient way to propagate gradients from\npoint clouds to simulated meshes and further through to the physical simulation\nparameters, such as mass and stiffness. Experiments with highly deformable\nobjects show that our method can achieve comparable or better alignment with\nreal object behavior, while reducing the time needed to achieve this by more\nthan an order of magnitude. Videos and supplementary material are available at\nhttps://tinyurl.com/diffcloud.",
          "link": "http://arxiv.org/abs/2204.03139",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects. (arXiv:2204.03139v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsek_M/0/1/0/all/0/1\">Murat Simsek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantarci_B/0/1/0/all/0/1\">Burak Kantarci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouftah_H/0/1/0/all/0/1\">Hussein T. Mouftah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djukic_P/0/1/0/all/0/1\">Petar Djukic</a>",
          "description": "Despite its technological benefits, Internet of Things (IoT) has cyber\nweaknesses due to the vulnerabilities in the wireless medium. Machine learning\n(ML)-based methods are widely used against cyber threats in IoT networks with\npromising performance. Advanced persistent threat (APT) is prominent for\ncybercriminals to compromise networks, and it is crucial to long-term and\nharmful characteristics. However, it is difficult to apply ML-based approaches\nto identify APT attacks to obtain a promising detection performance due to an\nextremely small percentage among normal traffic. There are limited surveys to\nfully investigate APT attacks in IoT networks due to the lack of public\ndatasets with all types of APT attacks. It is worth to bridge the\nstate-of-the-art in network attack detection with APT attack detection in a\ncomprehensive review article. This survey article reviews the security\nchallenges in IoT networks and presents the well-known attacks, APT attacks,\nand threat models in IoT systems. Meanwhile, signature-based, anomaly-based,\nand hybrid intrusion detection systems are summarized for IoT networks. The\narticle highlights statistical insights regarding frequently applied ML-based\nmethods against network intrusion alongside the number of attacks types\ndetected. Finally, open issues and challenges for common network intrusion and\nAPT attacks are presented for future research.",
          "link": "http://arxiv.org/abs/2204.03433",
          "publishedOn": "2022-04-09T00:48:55.278Z",
          "wordCount": null,
          "title": "Machine Learning-Enabled IoT Security: Open Issues and Challenges Under Advanced Persistent Threats. (arXiv:2204.03433v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brinkmeyer_L/0/1/0/all/0/1\">Lukas Brinkmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drumond_R/0/1/0/all/0/1\">Rafael Rego Drumond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burchert_J/0/1/0/all/0/1\">Johannes Burchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1\">Lars Schmidt-Thieme</a>",
          "description": "Learning complex time series forecasting models usually requires a large\namount of data, as each model is trained from scratch for each task/data set.\nLeveraging learning experience with similar datasets is a well-established\ntechnique for classification problems called few-shot classification. However,\nexisting approaches cannot be applied to time-series forecasting because i)\nmultivariate time-series datasets have different channels and ii) forecasting\nis principally different from classification. In this paper we formalize the\nproblem of few-shot forecasting of time-series with heterogeneous channels for\nthe first time. Extending recent work on heterogeneous attributes in vector\ndata, we develop a model composed of permutation-invariant deep set-blocks\nwhich incorporate a temporal embedding. We assemble the first meta-dataset of\n40 multivariate time-series datasets and show through experiments that our\nmodel provides a good generalization, outperforming baselines carried over from\nsimpler scenarios that either fail to learn across tasks or miss temporal\ninformation.",
          "link": "http://arxiv.org/abs/2204.03456",
          "publishedOn": "2022-04-09T00:48:55.276Z",
          "wordCount": null,
          "title": "Few-Shot Forecasting of Time-Series with Heterogeneous Channels. (arXiv:2204.03456v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ott_F/0/1/0/all/0/1\">Felix Ott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heublein_L/0/1/0/all/0/1\">Lucas Heublein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutschler_C/0/1/0/all/0/1\">Christopher Mutschler</a>",
          "description": "The performance of a machine learning model degrades when it is applied to\ndata from a similar but different domain than the data it has initially been\ntrained on. To mitigate this domain shift problem, domain adaptation (DA)\ntechniques search for an optimal transformation that converts the (current)\ninput data from a source domain to a target domain to learn a domain-invariant\nrepresentations that reduces domain discrepancy.\n\nThis paper proposes a novel supervised domain adaptation based on two steps.\nFirst, we search for an optimal class-dependent transformation from the source\nto the target domain from a few samples. We consider optimal transport methods\nsuch as the earth mover distance with Laplacian regularization, Sinkhorn\ntransport and correlation alignment. Second, we use embedding similarity\ntechniques to select the corresponding transformation at inference. We use\ncorrelation metrics and maximum mean discrepancy with higher-order moment\nmatching techniques. We conduct an extensive evaluation on time-series datasets\nwith domain shift including simulated and various online handwriting datasets\nto demonstrate the performance.",
          "link": "http://arxiv.org/abs/2204.03342",
          "publishedOn": "2022-04-09T00:48:55.275Z",
          "wordCount": null,
          "title": "Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift. (arXiv:2204.03342v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daghero_F/0/1/0/all/0/1\">Francesco Daghero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burrello_A/0/1/0/all/0/1\">Alessio Burrello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliari_D/0/1/0/all/0/1\">Daniele Jahier Pagliari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poncino_M/0/1/0/all/0/1\">Massimo Poncino</a>",
          "description": "Energy-efficient machine learning models that can run directly on edge\ndevices are of great interest in IoT applications, as they can reduce network\npressure and response latency, and improve privacy. An effective way to obtain\nenergy-efficiency with small accuracy drops is to sequentially execute a set of\nincreasingly complex models, early-stopping the procedure for \"easy\" inputs\nthat can be confidently classified by the smallest models. As a stopping\ncriterion, current methods employ a single threshold on the output\nprobabilities produced by each model. In this work, we show that such a\ncriterion is sub-optimal for datasets that include classes of different\ncomplexity, and we demonstrate a more general approach based on per-classes\nthresholds. With experiments on a low-power end-node, we show that our method\ncan significantly reduce the energy consumption compared to the\nsingle-threshold approach.",
          "link": "http://arxiv.org/abs/2204.03431",
          "publishedOn": "2022-04-09T00:48:55.274Z",
          "wordCount": null,
          "title": "Energy-Efficient Adaptive Machine Learning on IoT End-Nodes With Class-Dependent Confidence. (arXiv:2204.03431v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balagansky_N/0/1/0/all/0/1\">Nikita Balagansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavrilov_D/0/1/0/all/0/1\">Daniil Gavrilov</a>",
          "description": "Currently, pre-trained models can be considered the default choice for a wide\nrange of NLP tasks. Despite their SoTA results, there is practical evidence\nthat these models may require a different number of computing layers for\ndifferent input sequences, since evaluating all layers leads to overconfidence\non wrong predictions (namely overthinking). This problem can potentially be\nsolved by implementing adaptive computation time approaches, which were first\ndesigned to improve inference speed. Recently proposed PonderNet may be a\npromising solution for performing an early exit by treating the exit layers\nindex as a latent variable. However, the originally proposed exit criterion,\nrelying on sampling from trained posterior distribution on the probability of\nexiting from i-th layer, introduces major variance in model outputs,\nsignificantly reducing the resulting models performance. In this paper, we\npropose Ponder ALBERT (PALBERT): an improvement to PonderNet with a novel\ndeterministic Q-exit criterion and a revisited model architecture. We compared\nPALBERT with recent methods for performing an early exit. We observed that the\nproposed changes can be considered significant improvements on the original\nPonderNet architecture and outperform PABEE on a wide range of GLUE tasks. In\naddition, we also performed an in-depth ablation study of the proposed\narchitecture to further understand Lambda layers and their performance.",
          "link": "http://arxiv.org/abs/2204.03276",
          "publishedOn": "2022-04-09T00:48:55.273Z",
          "wordCount": null,
          "title": "PALBERT: Teaching ALBERT to Ponder. (arXiv:2204.03276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hedegaard_L/0/1/0/all/0/1\">Lukas Hedegaard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "We present Continual Inference, a Python library for implementing Continual\nInference Networks (CINs) in PyTorch, a class of Neural Networks designed\nspecifically for efficient inference in both online and batch processing\nscenarios. We offer a comprehensive introduction and guide to CINs and their\nimplementation in practice, and provide best-practices and code examples for\ncomposing complex modules for modern Deep Learning. Continual Inference is\nreadily downloadable via the Python Package Index and at\n\\url{www.github.com/lukashedegaard/continual-inference}.",
          "link": "http://arxiv.org/abs/2204.03418",
          "publishedOn": "2022-04-09T00:48:55.272Z",
          "wordCount": null,
          "title": "Continual Inference: A Library for Efficient Online Inference with Deep Neural Networks in PyTorch. (arXiv:2204.03418v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_N/0/1/0/all/0/1\">Niloofar Ranjbar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safabakhsh_R/0/1/0/all/0/1\">Reza Safabakhsh</a>",
          "description": "Nowadays, deep neural networks are being used in many domains because of\ntheir high accuracy results. However, they are considered as \"black box\", means\nthat they are not explainable for humans. On the other hand, in some tasks such\nas medical, economic, and self-driving cars, users want the model to be\ninterpretable to decide if they can trust these results or not. In this work,\nwe present a modified version of an autoencoder-based approach for local\ninterpretability called ALIME. The ALIME itself is inspired by a famous method\ncalled Local Interpretable Model-agnostic Explanations (LIME). LIME generates a\nsingle instance level explanation by generating new data around the instance\nand training a local linear interpretable model. ALIME uses an autoencoder to\nweigh the new data around the sample. Nevertheless, the ALIME uses a linear\nmodel as the interpretable model to be trained locally, just like the LIME.\nThis work proposes a new approach, which uses a decision tree instead of the\nlinear model, as the interpretable model. We evaluate the proposed model in\ncase of stability, local fidelity, and interpretability on different datasets.\nCompared to ALIME, the experiments show significant results on stability and\nlocal fidelity and improved results on interpretability.",
          "link": "http://arxiv.org/abs/2204.03321",
          "publishedOn": "2022-04-09T00:48:55.271Z",
          "wordCount": null,
          "title": "Using Decision Tree as Local Interpretable Model in Autoencoder-based LIME. (arXiv:2204.03321v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venezian_E/0/1/0/all/0/1\">Elad Venezian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>",
          "description": "Pretrained models are the standard starting point for training. This approach\nconsistently outperforms the use of a random initialization. However,\npretraining is a costly endeavour that few can undertake.\n\nIn this paper, we create better base models at hardly any cost, by fusing\nmultiple existing fine tuned models into one. Specifically, we fuse by\naveraging the weights of these models. We show that the fused model results\nsurpass the pretrained model ones. We also show that fusing is often better\nthan intertraining.\n\nWe find that fusing is less dependent on the target task. Furthermore, weight\ndecay nullifies intertraining effects but not those of fusing.",
          "link": "http://arxiv.org/abs/2204.03044",
          "publishedOn": "2022-04-09T00:48:55.270Z",
          "wordCount": null,
          "title": "Fusing finetuned models for better pretraining. (arXiv:2204.03044v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwary_S/0/1/0/all/0/1\">Saurabh Tiwary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1\">Paul Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>",
          "description": "We present a new framework AMOS that pretrains text encoders with an\nAdversarial learning curriculum via a Mixture Of Signals from multiple\nauxiliary generators. Following ELECTRA-style pretraining, the main encoder is\ntrained as a discriminator to detect replaced tokens generated by auxiliary\nmasked language models (MLMs). Different from ELECTRA which trains one MLM as\nthe generator, we jointly train multiple MLMs of different sizes to provide\ntraining signals at various levels of difficulty. To push the discriminator to\nlearn better with challenging replaced tokens, we learn mixture weights over\nthe auxiliary MLMs' outputs to maximize the discriminator loss by\nbackpropagating the gradient from the discriminator via Gumbel-Softmax. For\nbetter pretraining efficiency, we propose a way to assemble multiple MLMs into\none unified auxiliary model. AMOS outperforms ELECTRA and recent\nstate-of-the-art pretrained models by about 1 point on the GLUE benchmark for\nBERT base-sized models.",
          "link": "http://arxiv.org/abs/2204.03243",
          "publishedOn": "2022-04-09T00:48:55.270Z",
          "wordCount": null,
          "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators. (arXiv:2204.03243v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Jeffrey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1\">Rajat Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tumma_N/0/1/0/all/0/1\">Neehal Tumma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "Topic models are some of the most popular ways to represent textual data in\nan interpret-able manner. Recently, advances in deep generative models,\nspecifically auto-encoding variational Bayes (AEVB), have led to the\nintroduction of unsupervised neural topic models, which leverage deep\ngenerative models as opposed to traditional statistics-based topic models. We\nextend upon these neural topic models by introducing the Label-Indexed Neural\nTopic Model (LI-NTM), which is, to the extent of our knowledge, the first\neffective upstream semi-supervised neural topic model. We find that LI-NTM\noutperforms existing neural topic models in document reconstruction benchmarks,\nwith the most notable results in low labeled data regimes and for data-sets\nwith informative labels; furthermore, our jointly learned classifier\noutperforms baseline classifiers in ablation studies.",
          "link": "http://arxiv.org/abs/2204.03208",
          "publishedOn": "2022-04-09T00:48:55.269Z",
          "wordCount": null,
          "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling. (arXiv:2204.03208v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adibi_A/0/1/0/all/0/1\">Arman Adibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1\">Aritra Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>",
          "description": "Recent years have witnessed a growing interest in the topic of min-max\noptimization, owing to its relevance in the context of generative adversarial\nnetworks (GANs), robust control and optimization, and reinforcement learning.\nMotivated by this line of work, we consider a multi-agent min-max learning\nproblem, and focus on the emerging challenge of contending with worst-case\nByzantine adversarial agents in such a setup. By drawing on recent results from\nrobust statistics, we design a robust distributed variant of the extra-gradient\nalgorithm - a popular algorithmic approach for min-max optimization. Our main\ncontribution is to provide a crisp analysis of the proposed robust\nextra-gradient algorithm for smooth convex-concave and smooth strongly\nconvex-strongly concave functions. Specifically, we establish statistical rates\nof convergence to approximate saddle points. Our rates are near-optimal, and\nreveal both the effect of adversarial corruption and the benefit of\ncollaboration among the non-faulty agents. Notably, this is the first paper to\nprovide formal theoretical guarantees for large-scale distributed min-max\nlearning in the presence of adversarial agents.",
          "link": "http://arxiv.org/abs/2204.03187",
          "publishedOn": "2022-04-09T00:48:55.268Z",
          "wordCount": null,
          "title": "Distributed Statistical Min-Max Learning in the Presence of Byzantine Agents. (arXiv:2204.03187v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03214",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Seung Ick Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Muhammad Ejaz Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camtepe_S/0/1/0/all/0/1\">Seyit Camtepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pieprzyk_J/0/1/0/all/0/1\">Josef Pieprzyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1\">Surya Nepal</a>",
          "description": "The large transformer-based language models demonstrate excellent performance\nin natural language processing. By considering the closeness of natural\nlanguages to the high-level programming language such as C/C++, this work\nstudies how good are the large transformer-based language models detecting\nsoftware vulnerabilities. Our results demonstrate the well performance of these\nmodels on software vulnerability detection. The answer enables extending\ntransformer-based language models to vulnerability detection and leveraging\nsuperior performance beyond the natural language processing domain. Besides, we\nperform the model's security check using Microsoft's Counterfit, a command-line\ntool to assess the model's security. Our results find that these models are\nvulnerable to adversarial examples. In this regard, we present a simple\ncountermeasure and its result. Experimenting with large models is always a\nchallenge due to the requirement of computing resources and platforms/libraries\n& dependencies. Based on the experiences and difficulties we faced during this\nwork, we present our recommendation while choosing the platforms to run these\nlarge models. Moreover, the popular platforms are surveyed thoroughly in this\npaper.",
          "link": "http://arxiv.org/abs/2204.03214",
          "publishedOn": "2022-04-09T00:48:55.266Z",
          "wordCount": null,
          "title": "Transformer-Based Language Models for Software Vulnerability Detection: Performance, Model's Security and Platforms. (arXiv:2204.03214v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emerson_H/0/1/0/all/0/1\">Harry Emerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guy_M/0/1/0/all/0/1\">Matt Guy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McConville_R/0/1/0/all/0/1\">Ryan McConville</a>",
          "description": "Hybrid closed loop systems represent the future of care for people with type\n1 diabetes (T1D). These devices usually utilise simple control algorithms to\nselect the optimal insulin dose for maintaining blood glucose levels within a\nhealthy range. Online reinforcement learning (RL) has been utilised as a method\nfor further enhancing glucose control in these devices. Previous approaches\nhave been shown to reduce patient risk and improve time spent in the target\nrange when compared to classical control algorithms, but are prone to\ninstability in the learning process, often resulting in the selection of unsafe\nactions. This work presents an evaluation of offline RL as a means for\ndeveloping clinically effective dosing policies without the need for patient\ninteraction. This paper examines the utility of BCQ, CQL and TD3-BC in managing\nthe blood glucose of nine virtual patients within the UVA/Padova glucose\ndynamics simulator. When trained on less than a tenth of the data required by\nonline RL approaches, this work shows that offline RL can significantly\nincrease time in the healthy blood glucose range when compared to the strongest\nstate-of-art baseline. This is achieved without any associated increase in low\nblood glucose events. Offline RL is also shown to be able to correct for common\nand challenging scenarios such as incorrect bolus dosing, irregular meal\ntimings and sub-optimal training data.",
          "link": "http://arxiv.org/abs/2204.03376",
          "publishedOn": "2022-04-09T00:48:55.265Z",
          "wordCount": null,
          "title": "Offline Reinforcement Learning for Safer Blood Glucose Control in People with Type 1 Diabetes. (arXiv:2204.03376v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thomas_J/0/1/0/all/0/1\">Josephine M. Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moallemy_Oureh_A/0/1/0/all/0/1\">Alice Moallemy-Oureh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beddar_Wiesing_S/0/1/0/all/0/1\">Silvia Beddar-Wiesing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holzhuter_C/0/1/0/all/0/1\">Clara Holzh&#xfc;ter</a>",
          "description": "Graphs are ubiquitous in nature and can therefore serve as models for many\npractical but also theoretical problems. Based on this, the young research\nfield of Graph Neural Networks (GNNs) has emerged. Despite the youth of the\nfield and the speed in which new models are developed, many good surveys have\nbeen published in the last years. Nevertheless, an overview on which graph\ntypes can be modeled by GNNs is missing. In this survey, we give a detailed\noverview of already existing GNNs and, unlike previous surveys, categorize them\naccording to their ability to handle different graph types. We consider GNNs\noperating on static as well as on dynamic graphs of different structural\nconstitutions, with or without node or edge attributes. Moreover in the dynamic\ncase, we separate the models in discrete-time and continuous-time dynamic\ngraphs based on their architecture. According to our findings, there are still\ngraph types, that are not covered by existing GNN models. Specifically, models\nconcerning heterogeneity in attributes are missing and the deletion of nodes\nand edges is only covered rarely.",
          "link": "http://arxiv.org/abs/2204.03080",
          "publishedOn": "2022-04-09T00:48:55.264Z",
          "wordCount": null,
          "title": "Graph Neural Networks Designed for Different Graph Types: A Survey. (arXiv:2204.03080v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weikai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1\">Meng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Songcan Chen</a>",
          "description": "Unsupervised Source (data) Free domain adaptation (USFDA) aims to transfer\nknowledge from a well-trained source model to a related but unlabeled target\ndomain. In such a scenario, all conventional adaptation methods that require\nsource data fail. To combat this challenge, existing USFDAs turn to transfer\nknowledge by aligning the target feature to the latent distribution hidden in\nthe source model. However, such information is naturally limited. Thus, the\nalignment in such a scenario is not only difficult but also insufficient, which\ndegrades the target generalization performance. To relieve this dilemma in\ncurrent USFDAs, we are motivated to explore a new perspective to boost their\nperformance. For this purpose and gaining necessary insight, we look back upon\nthe origin of the domain adaptation and first theoretically derive a new-brand\ntarget generalization error bound based on the model smoothness. Then,\nfollowing the theoretical insight, a general and model-smoothness-guided\nJacobian norm (JN) regularizer is designed and imposed on the target domain to\nmitigate this dilemma. Extensive experiments are conducted to validate its\neffectiveness. In its implementation, just with a few lines of codes added to\nthe existing USFDAs, we achieve superior results on various benchmark datasets.",
          "link": "http://arxiv.org/abs/2204.03467",
          "publishedOn": "2022-04-09T00:48:55.263Z",
          "wordCount": null,
          "title": "Jacobian Norm for Unsupervised Source-Free Domain Adaptation. (arXiv:2204.03467v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangjoon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "The widespread application of artificial intelligence in health research is\ncurrently hampered by limitations in data availability. Distributed learning\nmethods such as federated learning (FL) and shared learning (SL) are introduced\nto solve this problem as well as data management and ownership issues with\ntheir different strengths and weaknesses. The recent proposal of federated\nsplit task-agnostic (FeSTA) learning tries to reconcile the distinct merits of\nFL and SL by enabling the multi-task collaboration between participants through\nVision Transformer (ViT) architecture, but they suffer from higher\ncommunication overhead. To address this, here we present a multi-task\ndistributed learning using ViT with random patch permutation. Instead of using\na CNN based head as in FeSTA, p-FeSTA adopts a randomly permuting simple patch\nembedder, improving the multi-task learning performance without sacrificing\nprivacy. Experimental results confirm that the proposed method significantly\nenhances the benefit of multi-task collaboration, communication efficiency, and\nprivacy preservation, shedding light on practical multi-task distributed\nlearning in the field of medical imaging.",
          "link": "http://arxiv.org/abs/2204.03500",
          "publishedOn": "2022-04-09T00:48:55.247Z",
          "wordCount": null,
          "title": "Multi-Task Distributed Learning using Vision Transformer with Random Patch Permutation. (arXiv:2204.03500v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1\">Steve Kommrusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monperrus_M/0/1/0/all/0/1\">Martin Monperrus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1\">Louis-No&#xeb;l Pouchet</a>",
          "description": "We target the problem of automatically synthesizing proofs of semantic\nequivalence between two programs made of sequences of statements. We represent\nprograms using abstract syntax trees (AST), where a given set of\nsemantics-preserving rewrite rules can be applied on a specific AST pattern to\ngenerate a transformed and semantically equivalent program. In our system, two\nprograms are equivalent if there exists a sequence of application of these\nrewrite rules that leads to rewriting one program into the other. We propose a\nneural network architecture based on a transformer model to generate proofs of\nequivalence between program pairs. The system outputs a sequence of rewrites,\nand the validity of the sequence is simply checked by verifying it can be\napplied. If no valid sequence is produced by the neural network, the system\nreports the programs as non-equivalent, ensuring by design no programs may be\nincorrectly reported as equivalent. Our system is fully implemented for a given\ngrammar. To efficiently train the system to generate such sequences, we develop\nan original incremental training technique, named self-supervised sample\nselection. We extensively study the effectiveness of this novel training\napproach on proofs of increasing complexity and length. Our system, S4Eq,\nachieves 97% proof success on a curated dataset of 10,000 pairs of equivalent\nprograms.",
          "link": "http://arxiv.org/abs/2109.10476",
          "publishedOn": "2022-04-09T00:48:55.246Z",
          "wordCount": null,
          "title": "Self-Supervised Learning to Prove Equivalence Between Programs via Semantics-Preserving Rewrite Rules. (arXiv:2109.10476v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03564",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khalid_U/0/1/0/all/0/1\">Umar Khalid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karim_N/0/1/0/all/0/1\">Nazmul Karim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>",
          "description": "Deep neural networks (DNNs) designed for computer vision and natural language\nprocessing tasks cannot be directly applied to the radio frequency (RF)\ndatasets. To address this challenge, we propose to convert the raw RF data to\ndata types that are suitable for off-the-shelf DNNs by introducing a\nconvolutional transform technique. In addition, we propose a simple 5-layer\nconvolutional neural network architecture (CONV-5) that can operate with raw RF\nI/Q data without any transformation. Further, we put forward an RF dataset,\nreferred to as RF1024, to facilitate future RF research. RF1024 consists of 8\ndifferent RF modulation classes with each class having 1000/200 training/test\nsamples. Each sample of the RF1024 dataset contains 1024 complex I/Q values.\nLastly, the experiments are performed on the RadioML2016 and RF1024 datasets to\ndemonstrate the improved classification performance.",
          "link": "http://arxiv.org/abs/2204.03564",
          "publishedOn": "2022-04-09T00:48:55.190Z",
          "wordCount": null,
          "title": "RF Signal Transformation and Classification using Deep Neural Networks. (arXiv:2204.03564v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiqin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kangxue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>",
          "description": "In this paper, we address the problem of texture representation for 3D shapes\nfor the challenging and underexplored tasks of texture transfer and synthesis.\nPrevious works either apply spherical texture maps which may lead to large\ndistortions, or use continuous texture fields that yield smooth outputs lacking\ndetails. We argue that the traditional way of representing textures with images\nand linking them to a 3D mesh via UV mapping is more desirable, since\nsynthesizing 2D images is a well-studied problem. We propose AUV-Net which\nlearns to embed 3D surfaces into a 2D aligned UV space, by mapping the\ncorresponding semantic parts of different 3D shapes to the same location in the\nUV space. As a result, textures are aligned across objects, and can thus be\neasily synthesized by generative models of images. Texture alignment is learned\nin an unsupervised manner by a simple yet effective texture alignment module,\ntaking inspiration from traditional works on linear subspace learning. The\nlearned UV mapping and aligned texture representations enable a variety of\napplications including texture transfer, texture synthesis, and textured single\nview 3D reconstruction. We conduct experiments on multiple datasets to\ndemonstrate the effectiveness of our method. Project page:\nhttps://nv-tlabs.github.io/AUV-NET.",
          "link": "http://arxiv.org/abs/2204.03105",
          "publishedOn": "2022-04-09T00:48:55.189Z",
          "wordCount": null,
          "title": "AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis. (arXiv:2204.03105v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yonghai Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yichuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freris_N/0/1/0/all/0/1\">Nikolaos M. Freris</a>",
          "description": "Federated Learning (FL) is an emerging framework for distributed processing\nof large data volumes by edge devices subject to limited communication\nbandwidths, heterogeneity in data distributions and computational resources, as\nwell as privacy considerations. In this paper, we introduce a new FL protocol\ntermed FedADMM based on primal-dual optimization. The proposed method leverages\ndual variables to tackle statistical heterogeneity, and accommodates system\nheterogeneity by tolerating variable amount of work performed by clients.\nFedADMM maintains identical communication costs per round as FedAvg/Prox, and\ngeneralizes them via the augmented Lagrangian. A convergence proof is\nestablished for nonconvex objectives, under no restrictions in terms of data\ndissimilarity or number of participants per round of the algorithm. We\ndemonstrate the merits through extensive experiments on real datasets, under\nboth IID and non-IID data distributions across clients. FedADMM consistently\noutperforms all baseline methods in terms of communication efficiency, with the\nnumber of rounds needed to reach a prescribed accuracy reduced by up to 87%.\nThe algorithm effectively adapts to heterogeneous data distributions through\nthe use of dual variables, without the need for hyperparameter tuning, and its\nadvantages are more pronounced in large-scale systems.",
          "link": "http://arxiv.org/abs/2204.03529",
          "publishedOn": "2022-04-09T00:48:55.189Z",
          "wordCount": null,
          "title": "FedADMM: A Robust Federated Deep Learning Framework with Adaptivity to System Heterogeneity. (arXiv:2204.03529v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03310",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zezario_R/0/1/0/all/0/1\">Ryandhimas E. Zezario</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_S/0/1/0/all/0/1\">Szu-wei Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuh_C/0/1/0/all/0/1\">Chiou-Shann Fuh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Recently, deep learning (DL)-based non-intrusive speech assessment models\nhave attracted great attention. Many studies report that these DL-based models\nyield satisfactory assessment performance and good flexibility, but their\nperformance in unseen environments remains a challenge. Furthermore, compared\nto quality scores, fewer studies elaborate deep learning models to estimate\nintelligibility scores. This study proposes a multi-task speech intelligibility\nprediction model, called MTI-Net, for simultaneously predicting human and\nmachine intelligibility measures. Specifically, given a speech utterance,\nMTI-Net is designed to predict subjective listening test results and word error\nrate (WER) scores. We also investigate several methods that can improve the\nprediction performance of MTI-Net. First, we compare different features\n(including low-level features and embeddings from self-supervised learning\n(SSL) models) and prediction targets of MTI-Net. Second, we explore the effect\nof transfer learning and multi-tasking learning on training MTI-Net. Finally,\nwe examine the potential advantages of fine-tuning SSL embeddings. Experimental\nresults demonstrate the effectiveness of using cross-domain features,\nmulti-task learning, and fine-tuning SSL embeddings. Furthermore, it is\nconfirmed that the intelligibility and WER scores predicted by MTI-Net are\nhighly correlated with the ground-truth scores.",
          "link": "http://arxiv.org/abs/2204.03310",
          "publishedOn": "2022-04-09T00:48:55.188Z",
          "wordCount": null,
          "title": "MTI-Net: A Multi-Target Speech Intelligibility Prediction Model. (arXiv:2204.03310v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minghui Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangnan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_K/0/1/0/all/0/1\">Keping Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_V/0/1/0/all/0/1\">Victor C.M.Leung</a>",
          "description": "Due to the rapid growth of data transmissions in internet of vehicles (IoV),\nfinding schemes that can effectively alleviate access congestion has become an\nimportant issue. Recently, many traffic control schemes have been studied.\nNevertheless, the dynamics of traffic and the heterogeneous requirements of\ndifferent IoV applications are not considered in most existing studies, which\nis significant for the random access resource allocation. In this paper, we\nconsider a hybrid traffic control scheme and use proximal policy optimization\n(PPO) method to tackle it. Firstly, IoV devices are divided into various\nclasses based on delay characteristics. The target of maximizing the successful\ntransmission of packets with the success rate constraint is established. Then,\nthe optimization objective is transformed into a markov decision process (MDP)\nmodel. Finally, the access class barring (ACB) factors are obtained based on\nthe PPO method to maximize the number of successful access devices. The\nperformance of the proposal algorithm in respect of successful events and delay\ncompared to existing schemes is verified by simulations.",
          "link": "http://arxiv.org/abs/2204.03504",
          "publishedOn": "2022-04-09T00:48:55.108Z",
          "wordCount": null,
          "title": "AI-aided Traffic Control Scheme for M2M Communications in the Internet of Vehicles. (arXiv:2204.03504v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_P/0/1/0/all/0/1\">Praveen Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afli_H/0/1/0/all/0/1\">Haithem Afli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasanuzzaman_M/0/1/0/all/0/1\">Mohammed Hasanuzzaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scully_T/0/1/0/all/0/1\">Ted Scully</a>",
          "description": "Deep Learning-based models have been widely investigated, and they have\ndemonstrated significant performance on non-trivial tasks such as speech\nrecognition, image processing, and natural language understanding. However,\nthis is at the cost of substantial data requirements. Considering the\nwidespread proliferation of edge devices (e.g. Internet of Things devices) over\nthe last decade, Deep Learning in the edge paradigm, such as device-cloud\nintegrated platforms, is required to leverage its superior performance.\nMoreover, it is suitable from the data requirements perspective in the edge\nparadigm because the proliferation of edge devices has resulted in an explosion\nin the volume of generated and collected data. However, there are difficulties\ndue to other requirements such as high computation, high latency, and high\nbandwidth caused by Deep Learning applications in real-world scenarios. In this\nregard, this survey paper investigates Deep Learning at the edge, its\narchitecture, enabling technologies, and model adaption techniques, where edge\nservers and edge devices participate in deep learning training and inference.\nFor simplicity, we call this paradigm the All-in EDGE paradigm. Besides, this\npaper presents the key performance metrics for Deep Learning at the All-in EDGE\nparadigm to evaluate various deep learning techniques and choose a suitable\ndesign. Moreover, various open challenges arising from the deployment of Deep\nLearning at the All-in EDGE paradigm are identified and discussed.",
          "link": "http://arxiv.org/abs/2204.03326",
          "publishedOn": "2022-04-09T00:48:55.107Z",
          "wordCount": null,
          "title": "Enabling Deep Learning for All-in EDGE paradigm. (arXiv:2204.03326v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopacz_A/0/1/0/all/0/1\">Anik&#xf3; Kopacz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mester_A/0/1/0/all/0/1\">&#xc1;gnes Mester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolumban_S/0/1/0/all/0/1\">S&#xe1;ndor Kolumb&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehel_C/0/1/0/all/0/1\">Csat&#xf3; Lehel</a>",
          "description": "We propose a train rescheduling algorithm which applies a standardized\nfeature selection based on pairwise conflicts in order to serve as input for\nthe reinforcement learning framework. We implement an analytical method which\nidentifies and optimally solves every conflict arising between two trains, then\nwe design a corresponding observation space which features the most relevant\ninformation considering these conflicts. The data obtained this way then\ntranslates to actions in the context of the reinforcement learning framework.\nWe test our preliminary model using the evaluation metrics of the Flatland\nChallenge. The empirical results indicate that the suggested feature space\nprovides meaningful observations, from which a sensible scheduling policy can\nbe learned.",
          "link": "http://arxiv.org/abs/2204.03061",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Standardized feature extraction from pairwise conflicts applied to the train rescheduling problem. (arXiv:2204.03061v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingna Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Chunfeng Cui</a>",
          "description": "Adversarial perturbations have drawn great attentions in various deep neural\nnetworks. Most of them are computed by iterations and cannot be interpreted\nvery well. In contrast, little attentions are paid to basic machine learning\nmodels such as support vector machines. In this paper, we investigate the\noptimization models and the interpretations for three types of adversarial\nperturbations against support vector machines, including sample-adversarial\nperturbations (sAP), class-universal adversarial perturbations (cuAP) as well\nas universal adversarial perturbations (uAP). For linear binary/multi\nclassification support vector machines (SVMs), we derive the explicit solutions\nfor sAP, cuAP and uAP (binary case), and approximate solution for uAP of\nmulti-classification. We also obtain the upper bound of fooling rate for uAP.\nSuch results not only increase the interpretability of the three adversarial\nperturbations, but also provide great convenience in computation since\niterative process can be avoided. Numerical results show that our method is\nfast and effective in calculating three types of adversarial perturbations.",
          "link": "http://arxiv.org/abs/2204.03154",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Optimization Models and Interpretations for Three Types of Adversarial Perturbations against Support Vector Machines. (arXiv:2204.03154v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ermolov_A/0/1/0/all/0/1\">Aleksandr Ermolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1\">Enver Sangineto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>",
          "description": "Environments in Reinforcement Learning are usually only partially observable.\nTo address this problem, a possible solution is to provide the agent with\ninformation about the past. However, providing complete observations of\nnumerous steps can be excessive. Inspired by human memory, we propose to\nrepresent history with only important changes in the environment and, in our\napproach, to obtain automatically this representation using self-supervision.\nOur method (TempAl) aligns temporally-close frames, revealing a general, slowly\nvarying state of the environment. This procedure is based on contrastive loss,\nwhich pulls embeddings of nearby observations to each other while pushing away\nother samples from the batch. It can be interpreted as a metric that captures\nthe temporal relations of observations. We propose to combine both common\ninstantaneous and our history representation and we evaluate TempAl on all\navailable Atari games from the Arcade Learning Environment. TempAl surpasses\nthe instantaneous-only baseline in 35 environments out of 49. The source code\nof the method and of all the experiments is available at\nhttps://github.com/htdt/tempal.",
          "link": "http://arxiv.org/abs/2204.03525",
          "publishedOn": "2022-04-09T00:48:55.105Z",
          "wordCount": null,
          "title": "Temporal Alignment for History Representation in Reinforcement Learning. (arXiv:2204.03525v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zongmin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yitian Xu</a>",
          "description": "Direct multi-task twin support vector machine (DMTSVM) explores the shared\ninformation between multiple correlated tasks, then it produces better\ngeneralization performance. However, it contains matrix inversion operation\nwhen solving the dual problems, so it costs much running time. Moreover, kernel\ntrick cannot be directly utilized in the nonlinear case. To effectively avoid\nabove problems, a novel multi-task nonparallel support vector machine (MTNPSVM)\nincluding linear and nonlinear cases is proposed in this paper. By introducing\nepsilon-insensitive loss instead of square loss in DMTSVM, MTNPSVM effectively\navoids matrix inversion operation and takes full advantage of the kernel trick.\nTheoretical implication of the model is further discussed. To further improve\nthe computational efficiency, the alternating direction method of multipliers\n(ADMM) is employed when solving the dual problem. The computational complexity\nand convergence of the algorithm are provided. In addition, the property and\nsensitivity of the parameter in model are further explored. The experimental\nresults on fifteen benchmark datasets and twelve image datasets demonstrate the\nvalidity of MTNPSVM in comparison with the state-of-the-art algorithms.\nFinally, it is applied to real Chinese Wine dataset, and also verifies its\neffectiveness.",
          "link": "http://arxiv.org/abs/2204.02972",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Multi-task nonparallel support vector machine for classification. (arXiv:2204.02972v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yi Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagduyu_Y/0/1/0/all/0/1\">Yalin E. Sagduyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erpek_T/0/1/0/all/0/1\">Tugba Erpek</a>",
          "description": "NextG networks are intended to provide the flexibility of sharing the\nspectrum with incumbent users and support various spectrum monitoring tasks\nsuch as anomaly detection, fault diagnostics, user equipment identification,\nand authentication. A network of wireless sensors is needed to monitor the\nspectrum for signal transmissions of interest over a large deployment area.\nEach sensor receives signals under a specific channel condition depending on\nits location and trains an individual model of a deep neural network (DNN)\naccordingly to classify signals. To improve the accuracy, individual sensors\nmay exchange sensing data or sensor results with each other or with a fusion\ncenter (such as in cooperative spectrum sensing). In this paper, distributed\nfederated learning over a multi-hop wireless network is considered to\ncollectively train a DNN for signal identification. In distributed federated\nlearning, each sensor broadcasts its trained model to its neighbors, collects\nthe DNN models from its neighbors, and aggregates them to initialize its own\nmodel for the next round of training. Without exchanging any spectrum data,\nthis process is repeated over time such that a common DNN is built across the\nnetwork while preserving the privacy associated with signals collected at\ndifferent locations. Signal classification accuracy and convergence time are\nevaluated for different network topologies (including line, star, ring, grid,\nand random networks) and packet loss events. Then, the reduction of\ncommunication overhead and energy consumption is considered with random\nparticipation of sensors in model updates. The results show the feasibility of\nextending cooperative spectrum sensing over a general multi-hop wireless\nnetwork through federated learning and indicate its robustness to wireless\nnetwork effects, thereby sustaining high accuracy with low communication\noverhead and energy consumption.",
          "link": "http://arxiv.org/abs/2204.03027",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Federated Learning for Distributed Spectrum Sensing in NextG Communication Networks. (arXiv:2204.03027v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1\">Maria-Florina Balcan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seiler_C/0/1/0/all/0/1\">Christopher Seiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Dravyansh Sharma</a>",
          "description": "Data-driven algorithm configuration is a promising, learning-based approach\nfor beyond worst-case analysis of algorithms with tunable parameters. An\nimportant open problem is the design of efficient data-driven algorithms for\nalgorithm families with more than one parameter. In this work we provide\nalgorithms for efficient (output-polynomial) multidimensional parameter tuning,\ni.e. for families with a small constant number of parameters, for three very\ndifferent combinatorial problems -- linkage-based clustering, dynamic\nprogramming for sequence alignment, and auction design for two-part tariff\nschemes. We extend the single-parameter clustering algorithm of Balcan et al.\n2020 arXiv:1907.00533 to multiple parameters and to the sequence alignment\nproblem by proposing an execution graph which compactly represents all the\nstates the algorithm could attain for all possible parameter values. A key\nproblem-specific challenge is to efficiently compute how the partition of the\nparameter space (into regions with unique algorithmic states) changes with a\nsingle algorithmic step. We give algorithms which improve on the runtime of\npreviously best known results for linkage-based clustering, sequence alignment\nand two-part tariff pricing.",
          "link": "http://arxiv.org/abs/2204.03569",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "Faster algorithms for learning to link, align sequences, and price two-part tariffs. (arXiv:2204.03569v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">Leon Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>",
          "description": "Regularization is a fundamental technique to prevent over-fitting and to\nimprove generalization performances by constraining a model's complexity.\nCurrent Deep Networks heavily rely on regularizers such as Data-Augmentation\n(DA) or weight-decay, and employ structural risk minimization, i.e.\ncross-validation, to select the optimal regularization hyper-parameters. In\nthis study, we demonstrate that techniques such as DA or weight decay produce a\nmodel with a reduced complexity that is unfair across classes. The optimal\namount of DA or weight decay found from cross-validation leads to disastrous\nmodel performances on some classes e.g. on Imagenet with a resnet50, the \"barn\nspider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by\nintroducing random crop DA during training. Even more surprising, such\nperformance drop also appears when introducing uninformative regularization\ntechniques such as weight decay. Those results demonstrate that our search for\never increasing generalization performance -- averaged over all classes and\nsamples -- has left us with models and regularizers that silently sacrifice\nperformances on some classes. This scenario can become dangerous when deploying\na model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on\nINaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889\nwhen introducing random crop DA during the Imagenet pre-training phase. Those\nresults demonstrate that designing novel regularizers without class-dependent\nbias remains an open research question.",
          "link": "http://arxiv.org/abs/2204.03632",
          "publishedOn": "2022-04-09T00:48:55.104Z",
          "wordCount": null,
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shashank Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaonkar_R/0/1/0/all/0/1\">Radhika Gaonkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>",
          "description": "Pre-trained language models (LMs) have been shown to memorize a substantial\namount of knowledge from the pre-training corpora; however, they are still\nlimited in recalling factually correct knowledge given a certain context.\nHence, they tend to suffer from counterfactual or hallucinatory generation when\nused in knowledge-intensive natural language generation (NLG) tasks. Recent\nremedies to this problem focus on modifying either the pre-training or task\nfine-tuning objectives to incorporate knowledge, which normally require\nadditional costly training or architecture modification of LMs for practical\napplications. We present Knowledge Infused Decoding (KID) -- a novel decoding\nalgorithm for generative LMs, which dynamically infuses external knowledge into\neach step of the LM decoding. Specifically, we maintain a local knowledge\nmemory based on the current context, interacting with a dynamically created\nexternal knowledge trie, and continuously update the local memory as a\nknowledge-aware constraint to guide decoding via reinforcement learning. On six\ndiverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART)\narmed with KID outperform many task-optimized state-of-the-art models, and show\nparticularly strong performance in few-shot scenarios over seven related\nknowledge-infusion techniques. Human evaluation confirms KID's ability to\ngenerate more relevant and factual language for the input context when compared\nwith multiple baselines. Finally, KID also alleviates exposure bias and\nprovides stable generation quality when generating longer sequences. Code for\nKID is available at https://github.com/microsoft/KID.",
          "link": "http://arxiv.org/abs/2204.03084",
          "publishedOn": "2022-04-09T00:48:55.103Z",
          "wordCount": null,
          "title": "Knowledge Infused Decoding. (arXiv:2204.03084v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Ming Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamura_T/0/1/0/all/0/1\">Toshiyo Tamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ono_N/0/1/0/all/0/1\">Naoaki Ono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altaf_Ul_Amin_M/0/1/0/all/0/1\">MD Altaf-Ul-Amin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanaya_S/0/1/0/all/0/1\">Shigehiko Kanaya</a>",
          "description": "Considering the natural frequency characteristics in sleep medicine, this\npaper first proposes a time-frequency framework for the representation learning\nof the electroencephalogram (EEG) following the definition of the American\nAcademy of Sleep Medicine. To meet the temporal-random and transient nature of\nthe defining characteristics of sleep stages, we further design a\ncontext-sensitive flexible pipeline that automatically adapts to the attributes\nof data itself. That is, the input EEG spectrogram is partitioned into a\nsequence of patches in the time and frequency axes, and then input to a\ndelicate deep learning network for further representation learning to extract\nthe stage-dependent features, which are used in the classification step\nfinally. The proposed pipeline is validated against a large database, i.e., the\nSleep Heart Health Study (SHHS), and the results demonstrate that the\ncompetitive performance for the wake, N2, and N3 stages outperforms the\nstate-of-art works, with the F1 scores being 0.93, 0.88, and 0.87,\nrespectively, and the proposed method has a high inter-rater reliability of\n0.80 kappa. Importantly, we visualize the stage scoring process of the model\ndecision with the Layer-wise Relevance Propagation (LRP) method, which shows\nthat the proposed pipeline is more sensitive and perceivable in the\ndecision-making process than the baseline pipelines. Therefore, the pipeline\ntogether with the LRP method can provide better model interpretability, which\nis important for clinical support.",
          "link": "http://arxiv.org/abs/2204.03173",
          "publishedOn": "2022-04-09T00:48:55.103Z",
          "wordCount": null,
          "title": "Enhancement on Model Interpretability and Sleep Stage Scoring Performance with A Novel Pipeline Based on Deep Neural Network. (arXiv:2204.03173v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1\">Jonathan Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1\">Tim Salimans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1\">Alexey Gritsenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1\">William Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1\">David J. Fleet</a>",
          "description": "Generating temporally coherent high fidelity video is an important milestone\nin generative modeling research. We make progress towards this milestone by\nproposing a diffusion model for video generation that shows very promising\ninitial results. Our model is a natural extension of the standard image\ndiffusion architecture, and it enables jointly training from image and video\ndata, which we find to reduce the variance of minibatch gradients and speed up\noptimization. To generate long and higher resolution videos we introduce a new\nconditional sampling technique for spatial and temporal video extension that\nperforms better than previously proposed methods. We present the first results\non a large text-conditioned video generation task, as well as state-of-the-art\nresults on an established unconditional video generation benchmark.\nSupplementary material is available at https://video-diffusion.github.io/",
          "link": "http://arxiv.org/abs/2204.03458",
          "publishedOn": "2022-04-09T00:48:55.102Z",
          "wordCount": null,
          "title": "Video Diffusion Models. (arXiv:2204.03458v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02973",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yanyong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kejun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiuwen Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianrui Li</a>",
          "description": "Multi-view unsupervised feature selection has been proven to be efficient in\nreducing the dimensionality of multi-view unlabeled data with high dimensions.\nThe previous methods assume all of the views are complete. However, in real\napplications, the multi-view data are often incomplete, i.e., some views of\ninstances are missing, which will result in the failure of these methods.\nBesides, while the data arrive in form of streams, these existing methods will\nsuffer the issues of high storage cost and expensive computation time. To\naddress these issues, we propose an Incremental Incomplete Multi-view\nUnsupervised Feature Selection method (I$^2$MUFS) on incomplete multi-view\nstreaming data. By jointly considering the consistent and complementary\ninformation across different views, I$^2$MUFS embeds the unsupervised feature\nselection into an extended weighted non-negative matrix factorization model,\nwhich can learn a consensus clustering indicator matrix and fuse different\nlatent feature matrices with adaptive view weights. Furthermore, we introduce\nthe incremental leaning mechanisms to develop an alternative iterative\nalgorithm, where the feature selection matrix is incrementally updated, rather\nthan recomputing on the entire updated data from scratch. A series of\nexperiments are conducted to verify the effectiveness of the proposed method by\ncomparing with several state-of-the-art methods. The experimental results\ndemonstrate the effectiveness and efficiency of the proposed method in terms of\nthe clustering metrics and the computational cost.",
          "link": "http://arxiv.org/abs/2204.02973",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Incremental Unsupervised Feature Selection for Dynamic Incomplete Multi-view Data. (arXiv:2204.02973v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_E/0/1/0/all/0/1\">Ensheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gub_W/0/1/0/all/0/1\">Wenchao Gub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongbin Sun</a>",
          "description": "Code search aims to retrieve the most semantically relevant code snippet for\na given natural language query. Recently, large-scale code pre-trained models\nsuch as CodeBERT and GraphCodeBERT learn generic representations of source code\nand have achieved substantial improvement on code search task. However, the\nhigh-quality sequence-level representations of code snippets have not been\nsufficiently explored. In this paper, we propose a new approach with multimodal\ncontrastive learning and soft data augmentation for code search. Multimodal\ncontrastive learning is used to pull together the representations of code-query\npairs and push apart the unpaired code snippets and queries. Moreover, data\naugmentation is critical in contrastive learning for learning high-quality\nrepresentations. However, only semantic-preserving augmentations for source\ncode are considered in existing work. In this work, we propose to do soft data\naugmentation by dynamically masking and replacing some tokens in code sequences\nto generate code snippets that are similar but not necessarily\nsemantic-preserving as positive samples for paired queries. We conduct\nextensive experiments to evaluate the effectiveness of our approach on a\nlarge-scale dataset with six programming languages. The experimental results\nshow that our approach significantly outperforms the state-of-the-art methods.\nWe also adapt our techniques to several pre-trained models such as RoBERTa and\nCodeBERT, and significantly boost their performance on the code search task.",
          "link": "http://arxiv.org/abs/2204.03293",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Enhancing Semantic Code Search with Multimodal Contrastive Learning and Soft Data Augmentation. (arXiv:2204.03293v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klapsas_K/0/1/0/all/0/1\">Konstantinos Klapsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikitaras_K/0/1/0/all/0/1\">Karolos Nikitaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vamvoukakis_G/0/1/0/all/0/1\">Georgios Vamvoukakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakoulidis_P/0/1/0/all/0/1\">Panos Kakoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markopoulos_K/0/1/0/all/0/1\">Konstantinos Markopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raptis_S/0/1/0/all/0/1\">Spyros Raptis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jho_G/0/1/0/all/0/1\">Gunu Jho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>",
          "description": "Voice cloning is a difficult task which requires robust and informative\nfeatures incorporated in a high quality TTS system in order to effectively copy\nan unseen speaker's voice. In our work, we utilize features learned in a\nself-supervised framework via the Bootstrap Your Own Latent (BYOL) method,\nwhich is shown to produce high quality speech representations when specific\naudio augmentations are applied to the vanilla algorithm. We further extend the\naugmentations in the training procedure to aid the resulting features to\ncapture the speaker identity and to make them robust to noise and acoustic\nconditions. The learned features are used as pre-trained utterance-level\nembeddings and as inputs to a Non-Attentive Tacotron based architecture, aiming\nto achieve multispeaker speech synthesis without utilizing additional speaker\nfeatures. This method enables us to train our model in an unlabeled\nmultispeaker dataset as well as use unseen speaker embeddings to copy a\nspeaker's voice. Subjective and objective evaluations are used to validate the\nproposed model, as well as the robustness to the acoustic conditions of the\ntarget utterance.",
          "link": "http://arxiv.org/abs/2204.03421",
          "publishedOn": "2022-04-09T00:48:55.002Z",
          "wordCount": null,
          "title": "Self supervised learning for robust voice cloning. (arXiv:2204.03421v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03565",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhu_L/0/1/0/all/0/1\">Lingwei Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Odani_K/0/1/0/all/0/1\">Koki Odani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_G/0/1/0/all/0/1\">Guang Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kan_Y/0/1/0/all/0/1\">Yirong Kan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1\">Renyuan Zhang</a>",
          "description": "Recently there has seen promising results on automatic stage scoring by\nextracting spatio-temporal features from electroencephalogram (EEG). Such\nmethods entail laborious manual feature engineering and domain knowledge. In\nthis study, we propose an adaptive scheme to probabilistically encode, filter\nand accumulate the input signals and weight the resultant features by the\nhalf-Gaussian probabilities of signal intensities. The adaptive representations\nare subsequently fed into a transformer model to automatically mine the\nrelevance between features and corresponding stages. Extensive experiments on\nthe largest public dataset against state-of-the-art methods validate the\neffectiveness of our proposed method and reveal promising future directions.",
          "link": "http://arxiv.org/abs/2204.03565",
          "publishedOn": "2022-04-09T00:48:55.001Z",
          "wordCount": null,
          "title": "Adaptive Spike-Like Representation of EEG Signals for Sleep Stages Scoring. (arXiv:2204.03565v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03125",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Niu_K/0/1/0/all/0/1\">Kaicheng Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_M/0/1/0/all/0/1\">Mi Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdallah_C/0/1/0/all/0/1\">Chaouki T. Abdallah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hayajneh_M/0/1/0/all/0/1\">Mohammad Hayajneh</a>",
          "description": "Recurrent neural networks (RNNs) have many advantages over more traditional\nsystem identification techniques. They may be applied to linear and nonlinear\nsystems, and they require fewer modeling assumptions. However, these neural\nnetwork models may also need larger amounts of data to learn and generalize.\nFurthermore, neural networks training is a time-consuming process. Hence,\nbuilding upon long-short term memory neural networks (LSTM), this paper\nproposes using two types of deep transfer learning, namely parameter\nfine-tuning and freezing, to reduce the data and computation requirements for\nsystem identification. We apply these techniques to identify two dynamical\nsystems, namely a second-order linear system and a Wiener-Hammerstein nonlinear\nsystem. Results show that compared with direct learning, our method accelerates\nlearning by 10% to 50%, which also saves data and computing resources.",
          "link": "http://arxiv.org/abs/2204.03125",
          "publishedOn": "2022-04-09T00:48:54.812Z",
          "wordCount": null,
          "title": "Deep transfer learning for system identification using long short-term memory neural networks. (arXiv:2204.03125v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1\">Matthew Ciolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hambrick_D/0/1/0/all/0/1\">Dominick Hambrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>",
          "description": "The sensor to shooter timeline is affected by two main variables: satellite\npositioning and asset positioning. Speeding up satellite positioning by adding\nmore sensors or by decreasing processing time is important only if there is a\nprepared shooter, otherwise the main source of time is getting the shooter into\nposition. However, the intelligence community should work towards the\nexploitation of sensors to the highest speed and effectiveness possible.\nAchieving a high effectiveness while keeping speed high is a tradeoff that must\nbe considered in the sensor to shooter timeline. In this paper we investigate\ntwo main ideas, increasing the effectiveness of satellite imagery through image\nmanipulation and how on-board image manipulation would affect the sensor to\nshooter timeline. We cover these ideas in four scenarios: Discrete Event\nSimulation of onboard processing versus ground station processing, quality of\ninformation with cloud cover removal, information improvement with super\nresolution, and data reduction with image to caption. This paper will show how\nimage manipulation techniques such as Super Resolution, Cloud Removal, and\nImage to Caption will improve the quality of delivered information in addition\nto showing how those processes effect the sensor to shooter timeline.",
          "link": "http://arxiv.org/abs/2203.00116",
          "publishedOn": "2022-04-03T00:52:40.822Z",
          "wordCount": 682,
          "title": "Enhancing Satellite Imagery using Deep Learning for the Sensor To Shooter Timeline. (arXiv:2203.00116v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nitzan_Y/0/1/0/all/0/1\">Yotam Nitzan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1\">Kfir Aberman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qiurui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liba_O/0/1/0/all/0/1\">Orly Liba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarom_M/0/1/0/all/0/1\">Michal Yarom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandelsman_Y/0/1/0/all/0/1\">Yossi Gandelsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosseri_I/0/1/0/all/0/1\">Inbar Mosseri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1\">Yael Pritch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_or_D/0/1/0/all/0/1\">Daniel Cohen-or</a>",
          "description": "We introduce MyStyle, a personalized deep generative prior trained with a few\nshots of an individual. MyStyle allows to reconstruct, enhance and edit images\nof a specific person, such that the output is faithful to the person's key\nfacial characteristics. Given a small reference set of portrait images of a\nperson (~100), we tune the weights of a pretrained StyleGAN face generator to\nform a local, low-dimensional, personalized manifold in the latent space. We\nshow that this manifold constitutes a personalized region that spans latent\ncodes associated with diverse portrait images of the individual. Moreover, we\ndemonstrate that we obtain a personalized generative prior, and propose a\nunified approach to apply it to various ill-posed image enhancement problems,\nsuch as inpainting and super-resolution, as well as semantic editing. Using the\npersonalized generative prior we obtain outputs that exhibit high-fidelity to\nthe input images and are also faithful to the key facial characteristics of the\nindividual in the reference set. We demonstrate our method with fair-use images\nof numerous widely recognizable individuals for whom we have the prior\nknowledge for a qualitative evaluation of the expected outcome. We evaluate our\napproach against few-shots baselines and show that our personalized prior,\nquantitatively and qualitatively, outperforms state-of-the-art alternatives.",
          "link": "http://arxiv.org/abs/2203.17272",
          "publishedOn": "2022-04-02T00:47:22.631Z",
          "wordCount": 665,
          "title": "MyStyle: A Personalized Generative Prior. (arXiv:2203.17272v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.06159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hessel_M/0/1/0/all/0/1\">Matteo Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danihelka_I/0/1/0/all/0/1\">Ivo Danihelka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viola_F/0/1/0/all/0/1\">Fabio Viola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guez_A/0/1/0/all/0/1\">Arthur Guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1\">Simon Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sifre_L/0/1/0/all/0/1\">Laurent Sifre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1\">Theophane Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1\">David Silver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasselt_H/0/1/0/all/0/1\">Hado van Hasselt</a>",
          "description": "We propose a novel policy update that combines regularized policy\noptimization with model learning as an auxiliary loss. The update (henceforth\nMuesli) matches MuZero's state-of-the-art performance on Atari. Notably, Muesli\ndoes so without using deep search: it acts directly with a policy network and\nhas computation speed comparable to model-free baselines. The Atari results are\ncomplemented by extensive ablations, and by additional results on continuous\ncontrol and 9x9 Go.",
          "link": "http://arxiv.org/abs/2104.06159",
          "publishedOn": "2022-04-02T00:47:22.555Z",
          "wordCount": 544,
          "title": "Muesli: Combining Improvements in Policy Optimization. (arXiv:2104.06159v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17218",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chaubey_A/0/1/0/all/0/1\">Ashutosh Chaubey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sinha_S/0/1/0/all/0/1\">Sparsh Sinha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghose_S/0/1/0/all/0/1\">Susmita Ghose</a>",
          "description": "Speaker identification systems in a real-world scenario are tasked to\nidentify a speaker amongst a set of enrolled speakers given just a few samples\nfor each enrolled speaker. This paper demonstrates the effectiveness of\nmeta-learning and relation networks for this use case. We propose improved\nrelation networks for speaker verification and few-shot (unseen) speaker\nidentification. The use of relation networks facilitates joint training of the\nfrontend speaker encoder and the backend model. Inspired by the use of\nprototypical networks in speaker verification and to increase the\ndiscriminability of the speaker embeddings, we train the model to classify\nsamples in the current episode amongst all speakers present in the training\nset. Furthermore, we propose a new training regime for faster model convergence\nby extracting more information from a given meta-learning episode with\nnegligible extra computation. We evaluate the proposed techniques on VoxCeleb,\nSITW and VCTK datasets on the tasks of speaker verification and unseen speaker\nidentification. The proposed approach outperforms the existing approaches\nconsistently on both tasks.",
          "link": "http://arxiv.org/abs/2203.17218",
          "publishedOn": "2022-04-02T00:47:22.447Z",
          "wordCount": 618,
          "title": "Improved Relation Networks for End-to-End Speaker Verification and Identification. (arXiv:2203.17218v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nowroozi_E/0/1/0/all/0/1\">Ehsan Nowroozi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mekdad_Y/0/1/0/all/0/1\">Yassine Mekdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berenjestanaki_M/0/1/0/all/0/1\">Mohammad Hajian Berenjestanaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fergougui_A/0/1/0/all/0/1\">Abdeslam EL Fergougui</a>",
          "description": "Convolutional Neural Networks (CNNs) models are one of the most frequently\nused deep learning networks, and extensively used in both academia and\nindustry. Recent studies demonstrated that adversarial attacks against such\nmodels can maintain their effectiveness even when used on models other than the\none targeted by the attacker. This major property is known as transferability,\nand makes CNNs ill-suited for security applications. In this paper, we provide\nthe first comprehensive study which assesses the robustness of CNN-based models\nfor computer networks against adversarial transferability. Furthermore, we\ninvestigate whether the transferability property issue holds in computer\nnetworks applications. In our experiments, we first consider five different\nattacks: the Iterative Fast Gradient Method (I-FGSM), the Jacobian-based\nSaliency Map (JSMA), the Limited-memory Broyden Fletcher Goldfarb Shanno BFGS\n(L- BFGS), the Projected Gradient Descent (PGD), and the DeepFool attack. Then,\nwe perform these attacks against three well- known datasets: the Network-based\nDetection of IoT (N-BaIoT) dataset, the Domain Generating Algorithms (DGA)\ndataset, and the RIPE Atlas dataset. Our experimental results show clearly that\nthe transferability happens in specific use cases for the I- FGSM, the JSMA,\nand the LBFGS attack. In such scenarios, the attack success rate on the target\nnetwork range from 63.00% to 100%. Finally, we suggest two shielding strategies\nto hinder the attack transferability, by considering the Most Powerful Attacks\n(MPAs), and the mismatch LSTM architecture.",
          "link": "http://arxiv.org/abs/2110.04488",
          "publishedOn": "2022-04-02T00:47:22.395Z",
          "wordCount": 726,
          "title": "Demystifying the Transferability of Adversarial Attacks in Computer Networks. (arXiv:2110.04488v3 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamansavascilar_B/0/1/0/all/0/1\">Baris Yamansavascilar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baktir_A/0/1/0/all/0/1\">Ahmet Cihat Baktir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonmez_C/0/1/0/all/0/1\">Cagatay Sonmez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozgovde_A/0/1/0/all/0/1\">Atay Ozgovde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ersoy_C/0/1/0/all/0/1\">Cem Ersoy</a>",
          "description": "The improvements in the edge computing technology pave the road for\ndiversified applications that demand real-time interaction. However, due to the\nmobility of the end-users and the dynamic edge environment, it becomes\nchallenging to handle the task offloading with high performance. Moreover,\nsince each application in mobile devices has different characteristics, a task\norchestrator must be adaptive and have the ability to learn the dynamics of the\nenvironment. For this purpose, we develop a deep reinforcement learning based\ntask orchestrator, DeepEdge, which learns to meet different task requirements\nwithout needing human interaction even under the heavily-loaded stochastic\nnetwork conditions in terms of mobile users and applications. Given the dynamic\noffloading requests and time-varying communication conditions, we successfully\nmodel the problem as a Markov process and then apply the Double Deep Q-Network\n(DDQN) algorithm to implement DeepEdge. To evaluate the robustness of DeepEdge,\nwe experiment with four different applications including image rendering,\ninfotainment, pervasive health, and augmented reality in the network under\nvarious loads. Furthermore, we compare the performance of our agent with the\nfour different task offloading approaches in the literature. Our results show\nthat DeepEdge outperforms its competitors in terms of the percentage of\nsatisfactorily completed tasks.",
          "link": "http://arxiv.org/abs/2110.01863",
          "publishedOn": "2022-04-02T00:47:22.386Z",
          "wordCount": 692,
          "title": "DeepEdge: A Deep Reinforcement Learning based Task Orchestrator for Edge Computing. (arXiv:2110.01863v2 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.16712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as Markov Decision Process\n(MDP) optimization, is a important challenge in artificial intelligence. Two\nkey approaches to this problem are reinforcement learning (RL) and planning.\nThis paper presents a survey of the integration of both fields, better known as\nmodel-based reinforcement learning. Model-based RL has two main steps. First,\nwe systematically cover approaches to dynamics model learning, including\nchallenges like dealing with stochasticity, uncertainty, partial observability,\nand temporal abstraction. Second, we present a systematic categorization of\nplanning-learning integration, including aspects like: where to start planning,\nwhat budgets to allocate to planning and real data collection, how to plan, and\nhow to integrate planning in the learning and acting loop. After these two\nsections, we also discuss implicit model-based RL as an end-to-end alternative\nfor model learning and planning, and we cover the potential benefits of\nmodel-based RL. Along the way, the survey also draws connections to several\nrelated RL fields, like hierarchical RL and transfer learning. Altogether, the\nsurvey presents a broad conceptual overview of the combination of planning and\nlearning for MDP optimization.",
          "link": "http://arxiv.org/abs/2006.16712",
          "publishedOn": "2022-04-02T00:47:22.362Z",
          "wordCount": 665,
          "title": "Model-based Reinforcement Learning: A Survey. (arXiv:2006.16712v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yanbo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yueqin Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qianyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chengyao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1\">Bo Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wayne Wu</a>",
          "description": "Recent advances like StyleGAN have promoted the growth of controllable facial\nediting. To address its core challenge of attribute decoupling in a single\nlatent space, attempts have been made to adopt dual-space GAN for better\ndisentanglement of style and content representations. Nonetheless, these\nmethods are still incompetent to obtain plausible editing results with high\ncontrollability, especially for complicated attributes. In this study, we\nhighlight the importance of interaction in a dual-space GAN for more\ncontrollable editing. We propose TransEditor, a novel Transformer-based\nframework to enhance such interaction. Besides, we develop a new dual-space\nediting and inversion strategy to provide additional editing flexibility.\nExtensive experiments demonstrate the superiority of the proposed framework in\nimage quality and editing capability, suggesting the effectiveness of\nTransEditor for highly controllable facial editing.",
          "link": "http://arxiv.org/abs/2203.17266",
          "publishedOn": "2022-04-02T00:47:22.354Z",
          "wordCount": 593,
          "title": "TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing. (arXiv:2203.17266v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.15009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as optimization of a Markov\nDecision Process, is a key challenge in artificial intelligence. Two successful\napproaches to MDP optimization are reinforcement learning and planning, which\nboth largely have their own research communities. However, if both research\nfields solve the same problem, then we might be able to disentangle the common\nfactors in their solution approaches. Therefore, this paper presents a unifying\nalgorithmic framework for reinforcement learning and planning (FRAP), which\nidentifies underlying dimensions on which MDP planning and learning algorithms\nhave to decide. At the end of the paper, we compare a variety of well-known\nplanning, model-free and model-based RL algorithms along these dimensions.\nAltogether, the framework may help provide deeper insight in the algorithmic\ndesign space of planning and reinforcement learning.",
          "link": "http://arxiv.org/abs/2006.15009",
          "publishedOn": "2022-04-02T00:47:22.346Z",
          "wordCount": 623,
          "title": "A Unifying Framework for Reinforcement Learning and Planning. (arXiv:2006.15009v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.11821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McLaughlin_N/0/1/0/all/0/1\">Niall McLaughlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rincon_J/0/1/0/all/0/1\">Jesus Martinez del Rincon</a>",
          "description": "In this paper we study data augmentation for opcode sequence based Android\nmalware detection. Data augmentation has been successfully used in many areas\nof deep-learning to significantly improve model performance. Typically, data\naugmentation simulates realistic variations in data to increase the apparent\ndiversity of the training-set. However, for opcode-based malware analysis it is\nnot immediately clear how to apply data augmentation. Hence we first study the\nuse of fixed transformations, then progress to adaptive methods. We propose a\nnovel data augmentation method -- Self-Embedding Language Model Augmentation --\nthat uses a malware detection network's own opcode embedding layer to measure\nopcode similarity for adaptive augmentation. To the best of our knowledge this\nis the first paper to carry out a systematic study of different augmentation\nmethods for opcode sequence based Android malware classification.",
          "link": "http://arxiv.org/abs/2106.11821",
          "publishedOn": "2022-04-02T00:47:22.338Z",
          "wordCount": 605,
          "title": "Data Augmentation for Opcode Sequence Based Malware Detection. (arXiv:2106.11821v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.12558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>",
          "description": "Machine learning has developed a variety of tools for learning and\nrepresenting high-dimensional distributions with structure. Recent years have\nalso seen big advances in designing multi-item mechanisms. Akin to overfitting,\nhowever, these mechanisms can be extremely sensitive to the Bayesian prior that\nthey target, which becomes problematic when that prior is only approximately\nknown. At the same time, even if access to the exact Bayesian prior is given,\nit is known that optimal or even approximately optimal multi-item mechanisms\nrun into sample, computational, representation and communication intractability\nbarriers.\n\nWe consider a natural class of multi-item mechanism design problems with very\nlarge numbers of items, but where the bidders' value distributions can be\nwell-approximated by a topic model akin to those used in recommendation systems\nwith very large numbers of possible recommendations. We propose a mechanism\ndesign framework for this setting, building on a recent robustification\nframework by Brustle et al., which disentangles the statistical challenge of\nestimating a multi-dimensional prior from the task of designing a good\nmechanism for it, and robustifies the performance of the latter against the\nestimation error of the former. We provide an extension of this framework\nappropriate for our setting, which allows us to exploit the expressive power of\ntopic models to reduce the effective dimensionality of the mechanism design\nproblem and remove the dependence of its computational, communication and\nrepresentation complexity on the number of items.",
          "link": "http://arxiv.org/abs/2110.12558",
          "publishedOn": "2022-04-02T00:47:22.316Z",
          "wordCount": 702,
          "title": "Recommender Systems meet Mechanism Design. (arXiv:2110.12558v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.11956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin-Chun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfeng Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingshuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shaoming Song</a>",
          "description": "Automatically mining sentiment tendency contained in natural language is a\nfundamental research to some artificial intelligent applications, where\nsolutions alternate with challenges. Transfer learning and multi-task learning\ntechniques have been leveraged to mitigate the supervision sparsity and\ncollaborate multiple heterogeneous domains correspondingly. Recent years, the\nsensitive nature of users' private data raises another challenge for sentiment\nclassification, i.e., data privacy protection. In this paper, we resort to\nfederated learning for multiple domain sentiment classification under the\nconstraint that the corpora must be stored on decentralized devices. In view of\nthe heterogeneous semantics across multiple parties and the peculiarities of\nword embedding, we pertinently provide corresponding solutions. First, we\npropose a Knowledge Transfer Enhanced Private-Shared (KTEPS) framework for\nbetter model aggregation and personalization in federated sentiment\nclassification. Second, we propose KTEPS$^\\star$ with the consideration of the\nrich semantic and huge embedding size properties of word vectors, utilizing\nProjection-based Dimension Reduction (PDR) methods for privacy protection and\nefficient transmission simultaneously. We propose two federated sentiment\nclassification scenes based on public benchmarks, and verify the superiorities\nof our proposed methods with abundant experimental investigations.",
          "link": "http://arxiv.org/abs/2107.11956",
          "publishedOn": "2022-04-02T00:47:22.309Z",
          "wordCount": 646,
          "title": "Preliminary Steps Towards Federated Sentiment Classification. (arXiv:2107.11956v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.06053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galhotra_S/0/1/0/all/0/1\">Sainyam Galhotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1\">Kush R. Varshney</a>",
          "description": "The use of machine learning (ML) in high-stakes societal decisions has\nencouraged the consideration of fairness throughout the ML lifecycle. Although\ndata integration is one of the primary steps to generate high quality training\ndata, most of the fairness literature ignores this stage. In this work, we\nconsider fairness in the integration component of data management, aiming to\nidentify features that improve prediction without adding any bias to the\ndataset. We work under the causal interventional fairness paradigm. Without\nrequiring the underlying structural causal model a priori, we propose an\napproach to identify a sub-collection of features that ensure the fairness of\nthe dataset by performing conditional independence tests between different\nsubsets of features. We use group testing to improve the complexity of the\napproach. We theoretically prove the correctness of the proposed algorithm to\nidentify features that ensure interventional fairness and show that sub-linear\nconditional independence tests are sufficient to identify these variables. A\ndetailed empirical evaluation is performed on real-world datasets to\ndemonstrate the efficacy and efficiency of our technique.",
          "link": "http://arxiv.org/abs/2006.06053",
          "publishedOn": "2022-04-02T00:47:22.302Z",
          "wordCount": 653,
          "title": "Causal Feature Selection for Algorithmic Fairness. (arXiv:2006.06053v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Ziang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>",
          "description": "Multi-agent reinforcement learning has made substantial empirical progresses\nin solving games with a large number of players. However, theoretically, the\nbest known sample complexity for finding a Nash equilibrium in general-sum\ngames scales exponentially in the number of players due to the size of the\njoint action space, and there is a matching exponential lower bound. This paper\ninvestigates what learning goals admit better sample complexities in the\nsetting of $m$-player general-sum Markov games with $H$ steps, $S$ states, and\n$A_i$ actions per player. First, we design algorithms for learning an\n$\\epsilon$-Coarse Correlated Equilibrium (CCE) in\n$\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$ episodes, and an\n$\\epsilon$-Correlated Equilibrium (CE) in\n$\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$ episodes. This\nis the first line of results for learning CCE and CE with sample complexities\npolynomial in $\\max_{i\\le m} A_i$. Our algorithm for learning CE integrates an\nadversarial bandit subroutine which minimizes a weighted swap regret, along\nwith several novel designs in the outer loop. Second, we consider the important\nspecial case of Markov Potential Games, and design an algorithm that learns an\n$\\epsilon$-approximate Nash equilibrium within\n$\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$ episodes (when only\nhighlighting the dependence on $S$, $A_i$, and $\\epsilon$), which only depends\nlinearly in $\\sum_{i\\le m} A_i$ and significantly improves over existing\nefficient algorithm in the $\\epsilon$ dependence. Overall, our results shed\nlight on what equilibria or structural assumptions on the game may enable\nsample-efficient learning with many players.",
          "link": "http://arxiv.org/abs/2110.04184",
          "publishedOn": "2022-04-02T00:47:22.294Z",
          "wordCount": 719,
          "title": "When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?. (arXiv:2110.04184v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.13492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Viet-Anh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh H. T. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khong_A/0/1/0/all/0/1\">Andy W. H. Khong</a>",
          "description": "We introduce a block-online variant of the temporal feature-wise linear\nmodulation (TFiLM) model to achieve bandwidth extension. The proposed\narchitecture simplifies the UNet backbone of the TFiLM to reduce inference time\nand employs an efficient transformer at the bottleneck to alleviate performance\ndegradation. We also utilize self-supervised pretraining and data augmentation\nto enhance the quality of bandwidth extended signals and reduce the sensitivity\nwith respect to downsampling methods. Experiment results on the VCTK dataset\nshow that the proposed method outperforms several recent baselines in both\nintrusive and non-intrusive metrics. Pretraining and filter augmentation also\nhelp stabilize and enhance the overall performance.",
          "link": "http://arxiv.org/abs/2110.13492",
          "publishedOn": "2022-04-02T00:47:22.286Z",
          "wordCount": 607,
          "title": "TUNet: A Block-online Bandwidth Extension Model based on Transformers and Self-supervised Pretraining. (arXiv:2110.13492v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.04605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chunlin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1\">Daoyi Dong</a>",
          "description": "Evolution strategies (ES), as a family of black-box optimization algorithms,\nrecently emerge as a scalable alternative to reinforcement learning (RL)\napproaches such as Q-learning or policy gradient, and are much faster when many\ncentral processing units (CPUs) are available due to better parallelization. In\nthis paper, we propose a systematic incremental learning method for ES in\ndynamic environments. The goal is to adjust previously learned policy to a new\none incrementally whenever the environment changes. We incorporate an instance\nweighting mechanism with ES to facilitate its learning adaptation, while\nretaining scalability of ES. During parameter updating, higher weights are\nassigned to instances that contain more new knowledge, thus encouraging the\nsearch distribution to move towards new promising areas of parameter space. We\npropose two easy-to-implement metrics to calculate the weights: instance\nnovelty and instance quality. Instance novelty measures an instance's\ndifference from the previous optimum in the original environment, while\ninstance quality corresponds to how well an instance performs in the new\nenvironment. The resulting algorithm, Instance Weighted Incremental Evolution\nStrategies (IW-IES), is verified to achieve significantly improved performance\non challenging RL tasks ranging from robot navigation to locomotion. This paper\nthus introduces a family of scalable ES algorithms for RL domains that enables\nrapid learning adaptation to dynamic environments.",
          "link": "http://arxiv.org/abs/2010.04605",
          "publishedOn": "2022-04-02T00:47:22.258Z",
          "wordCount": 711,
          "title": "Instance Weighted Incremental Evolution Strategies for Reinforcement Learning in Dynamic Environments. (arXiv:2010.04605v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.01661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1\">Pit Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maurer_Y/0/1/0/all/0/1\">Yves Maurer</a>",
          "description": "Iterating with new and improved OCR solutions enforces decision making when\nit comes to targeting the right candidates for reprocessing. This especially\napplies when the underlying data collection is of considerable size and rather\ndiverse in terms of fonts, languages, periods of publication and consequently\nOCR quality. This article captures the efforts of the National Library of\nLuxembourg to support those targeting decisions. They are crucial in order to\nguarantee low computational overhead and reduced quality degradation risks,\ncombined with a more quantifiable OCR improvement. In particular, this work\nexplains the methodology of the library with respect to text block level\nquality assessment. Through extension of this technique, a regression model,\nthat is able to take into account the enhancement potential of a new OCR\nengine, is also presented. They both mark promising approaches, especially for\ncultural institutions dealing with historical data of lower quality.",
          "link": "http://arxiv.org/abs/2110.01661",
          "publishedOn": "2022-04-02T00:47:22.250Z",
          "wordCount": 646,
          "title": "Rerunning OCR: A Machine Learning Approach to Quality Assessment and Enhancement Prediction. (arXiv:2110.01661v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hemati_H/0/1/0/all/0/1\">Hamed Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>",
          "description": "Training a multi-speaker Text-to-Speech (TTS) model from scratch is\ncomputationally expensive and adding new speakers to the dataset requires the\nmodel to be re-trained. The naive solution of sequential fine-tuning of a model\nfor new speakers can lead to poor performance of older speakers. This\nphenomenon is known as catastrophic forgetting. In this paper, we look at TTS\nmodeling from a continual learning perspective, where the goal is to add new\nspeakers without forgetting previous speakers. Therefore, we first propose an\nexperimental setup and show that serial fine-tuning for new speakers can cause\nthe forgetting of the earlier speakers. Then we exploit two well-known\ntechniques for continual learning, namely experience replay and weight\nregularization. We reveal how one can mitigate the effect of degradation in\nspeech synthesis diversity in sequential training of new speakers using these\nmethods. Finally, we present a simple extension to experience replay to improve\nthe results in extreme setups where we have access to very small buffers.",
          "link": "http://arxiv.org/abs/2103.14512",
          "publishedOn": "2022-04-02T00:47:22.243Z",
          "wordCount": 629,
          "title": "Continual Speaker Adaptation for Text-to-Speech Synthesis. (arXiv:2103.14512v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montanari_A/0/1/0/all/0/1\">Andrea Montanari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuchen Wu</a>",
          "description": "A substantial body of empirical work documents the lack of robustness in deep\nlearning models to adversarial examples. Recent theoretical work proved that\nadversarial examples are ubiquitous in two-layers networks with sub-exponential\nwidth and ReLU or smooth activations, and multi-layer ReLU networks with\nsub-exponential width. We present a result of the same type, with no\nrestriction on width and for general locally Lipschitz continuous activations.\n\nMore precisely, given a neural network $f(\\,\\cdot\\,;{\\boldsymbol \\theta})$\nwith random weights ${\\boldsymbol \\theta}$, and feature vector ${\\boldsymbol\nx}$, we show that an adversarial example ${\\boldsymbol x}'$ can be found with\nhigh probability along the direction of the gradient $\\nabla_{{\\boldsymbol\nx}}f({\\boldsymbol x};{\\boldsymbol \\theta})$. Our proof is based on a Gaussian\nconditioning technique. Instead of proving that $f$ is approximately linear in\na neighborhood of ${\\boldsymbol x}$, we characterize the joint distribution of\n$f({\\boldsymbol x};{\\boldsymbol \\theta})$ and $f({\\boldsymbol x}';{\\boldsymbol\n\\theta})$ for ${\\boldsymbol x}' = {\\boldsymbol x}-s({\\boldsymbol\nx})\\nabla_{{\\boldsymbol x}}f({\\boldsymbol x};{\\boldsymbol \\theta})$.",
          "link": "http://arxiv.org/abs/2203.17209",
          "publishedOn": "2022-04-02T00:47:22.235Z",
          "wordCount": 600,
          "title": "Adversarial Examples in Random Neural Networks with General Activations. (arXiv:2203.17209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albanie_S/0/1/0/all/0/1\">Samuel Albanie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1\">Dylan Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1\">Jo&#xe3;o F. Henriques</a>",
          "description": "The field of machine learning has achieved striking progress in recent years,\nwitnessing breakthrough results on language modelling, protein folding and\nnitpickingly fine-grained dog breed classification. Some even succeeded at\nplaying computer games and board games, a feat both of engineering and of\nsetting their employers' expectations. The central contribution of this work is\nto carefully examine whether this progress, and technology more broadly, can be\nexpected to continue indefinitely. Through a rigorous application of\nstatistical theory and failure to extrapolate beyond the training data, we\nanswer firmly in the negative and provide details: technology will peak at 3:07\nam (BST) on 20th July, 2032. We then explore the implications of this finding,\ndiscovering that individuals awake at this ungodly hour with access to a\nsufficiently powerful computer possess an opportunity for myriad forms of\nlong-term linguistic 'lock in'. All we need is a large (>> 1W) data centre to\nseize this pivotal moment. By setting our analogue alarm clocks, we propose a\ntractable algorithm to ensure that, for the future of humanity, the British\nspelling of colour becomes the default spelling across more than 80% of the\nglobal word processing software market.",
          "link": "http://arxiv.org/abs/2203.17265",
          "publishedOn": "2022-04-02T00:47:22.214Z",
          "wordCount": 629,
          "title": "A 23 MW data centre is all you need. (arXiv:2203.17265v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirheidari_B/0/1/0/all/0/1\">Bahman Mirheidari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bittar_A/0/1/0/all/0/1\">Andr&#xe9; Bittar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cummins_N/0/1/0/all/0/1\">Nicholas Cummins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downs_J/0/1/0/all/0/1\">Johnny Downs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_H/0/1/0/all/0/1\">Helen L. Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christensen_H/0/1/0/all/0/1\">Heidi Christensen</a>",
          "description": "We present a novel feasibility study on the automatic recognition of\nExpressed Emotion (EE), a family environment concept based on caregivers\nspeaking freely about their relative/family member. We describe an automated\napproach for determining the \\textit{degree of warmth}, a key component of EE,\nfrom acoustic and text features acquired from a sample of 37 recorded\ninterviews. These recordings, collected over 20 years ago, are derived from a\nnationally representative birth cohort of 2,232 British twin children and were\nmanually coded for EE. We outline the core steps of extracting usable\ninformation from recordings with highly variable audio quality and assess the\nefficacy of four machine learning approaches trained with different\ncombinations of acoustic and text features. Despite the challenges of working\nwith this legacy data, we demonstrated that the degree of warmth can be\npredicted with an $F_{1}$-score of \\textbf{61.5\\%}. In this paper, we summarise\nour learning and provide recommendations for future work using real-world\nspeech samples.",
          "link": "http://arxiv.org/abs/2203.17242",
          "publishedOn": "2022-04-02T00:47:20.632Z",
          "wordCount": null,
          "title": "Automatic Detection of Expressed Emotion from Five-Minute Speech Samples: Challenges and Opportunities. (arXiv:2203.17242v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aflalo_E/0/1/0/all/0/1\">Estelle Aflalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Meng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_S/0/1/0/all/0/1\">Shao-Yen Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_V/0/1/0/all/0/1\">Vasudev Lal</a>",
          "description": "Breakthroughs in transformer-based models have revolutionized not only the\nNLP field, but also vision and multimodal systems. However, although\nvisualization and interpretability tools have become available for NLP models,\ninternal mechanisms of vision and multimodal transformers remain largely\nopaque. With the success of these transformers, it is increasingly critical to\nunderstand their inner workings, as unraveling these black-boxes will lead to\nmore capable and trustworthy models. To contribute to this quest, we propose\nVL-InterpreT, which provides novel interactive visualizations for interpreting\nthe attentions and hidden representations in multimodal transformers.\nVL-InterpreT is a task agnostic and integrated tool that (1) tracks a variety\nof statistics in attention heads throughout all layers for both vision and\nlanguage components, (2) visualizes cross-modal and intra-modal attentions\nthrough easily readable heatmaps, and (3) plots the hidden representations of\nvision and language tokens as they pass through the transformer layers. In this\npaper, we demonstrate the functionalities of VL-InterpreT through the analysis\nof KD-VLP, an end-to-end pretraining vision-language multimodal\ntransformer-based model, in the tasks of Visual Commonsense Reasoning (VCR) and\nWebQA, two visual question answering benchmarks. Furthermore, we also present a\nfew interesting findings about multimodal transformer behaviors that were\nlearned through our tool.",
          "link": "http://arxiv.org/abs/2203.17247",
          "publishedOn": "2022-04-02T00:47:20.632Z",
          "wordCount": null,
          "title": "VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers. (arXiv:2203.17247v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17065",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ymeraj_E/0/1/0/all/0/1\">Endi Ymeraj</a>",
          "description": "Wind energy is one of the cleanest renewable electricity sources and can help\nin addressing the challenge of climate change. One of the drawbacks of\nwind-generated energy is the large space necessary to install a wind farm; this\narises from the fact that placing wind turbines in a limited area would hinder\ntheir productivity and therefore not be economically convenient. This naturally\nleads to an optimisation problem, which has three specific challenges: (1)\nmultiple conflicting objectives (2) computationally expensive simulation models\nand (3) optimisation over design sets instead of design vectors. The first and\nsecond challenges can be addressed by using surrogate-assisted e.g.\\ Bayesian\nmulti-objective optimisation. However, the traditional Bayesian optimisation\ncannot be applied as the optimisation function in the problem relies on design\nsets instead of design vectors. This paper extends the applicability of\nBayesian multi-objective optimisation to set based optimisation for solving the\nwind farm layout problem. We use a set-based kernel in Gaussian process to\nquantify the correlation between wind farms (with a different number of\nturbines). The results on the given data set of wind energy and direction\nclearly show the potential of using set-based Bayesian multi-objective\noptimisation.",
          "link": "http://arxiv.org/abs/2203.17065",
          "publishedOn": "2022-04-02T00:47:20.631Z",
          "wordCount": null,
          "title": "Wind Farm Layout Optimisation using Set Based Multi-objective Bayesian Optimisation. (arXiv:2203.17065v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1\">Nanyang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kaican Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoyue Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Runpeng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Fengwei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Deep learning has achieved tremendous success with independent and\nidentically distributed (i.i.d.) data. However, the performance of neural\nnetworks often degenerates drastically when encountering out-of-distribution\n(OoD) data, i.e., when training and test data are sampled from different\ndistributions. While a plethora of algorithms have been proposed for OoD\ngeneralization, our understanding of the data used to train and evaluate these\nalgorithms remains stagnant. In this work, we first identify and measure two\ndistinct kinds of distribution shifts that are ubiquitous in various datasets.\nNext, through extensive experiments, we compare OoD generalization algorithms\nacross two groups of benchmarks, each dominated by one of the distribution\nshifts, revealing their strengths on one shift as well as limitations on the\nother shift. Overall, we position existing datasets and algorithms from\ndifferent research areas seemingly unconnected into the same coherent picture.\nIt may serve as a foothold that can be resorted to by future OoD generalization\nresearch. Our code is available at https://github.com/ynysjtu/ood_bench.",
          "link": "http://arxiv.org/abs/2106.03721",
          "publishedOn": "2022-04-02T00:47:20.388Z",
          "wordCount": null,
          "title": "OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization. (arXiv:2106.03721v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muller_N/0/1/0/all/0/1\">Nicolas M. M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czempin_P/0/1/0/all/0/1\">Pavel Czempin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieckmann_F/0/1/0/all/0/1\">Franziska Dieckmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Froghyar_A/0/1/0/all/0/1\">Adam Froghyar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottinger_K/0/1/0/all/0/1\">Konstantin B&#xf6;ttinger</a>",
          "description": "Current text-to-speech algorithms produce realistic fakes of human voices,\nmaking deepfake detection a much-needed area of research. While researchers\nhave presented various techniques for detecting audio spoofs, it is often\nunclear exactly why these architectures are successful: Preprocessing steps,\nhyperparameter settings, and the degree of fine-tuning are not consistent\nacross related work. Which factors contribute to success, and which are\naccidental? In this work, we address this problem: We systematize audio\nspoofing detection by re-implementing and uniformly evaluating architectures\nfrom related work. We identify overarching features for successful audio\ndeepfake detection, such as using cqtspec or logspec features instead of\nmelspec features, which improves performance by 37% EER on average, all other\nfactors constant. Additionally, we evaluate generalization capabilities: We\ncollect and publish a new dataset consisting of 37.9 hours of found audio\nrecordings of celebrities and politicians, of which 17.2 hours are deepfakes.\nWe find that related work performs poorly on such real-world data (performance\ndegradation of up to one thousand percent). This may suggest that the community\nhas tailored its solutions too closely to the prevailing ASVSpoof benchmark and\nthat deepfakes are much harder to detect outside the lab than previously\nthought.",
          "link": "http://arxiv.org/abs/2203.16263",
          "publishedOn": "2022-04-02T00:47:20.194Z",
          "wordCount": null,
          "title": "Does Audio Deepfake Detection Generalize?. (arXiv:2203.16263v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14452",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Vargas_Calderon_V/0/1/0/all/0/1\">Vladimir Vargas-Calder&#xf3;n</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gonzalez_F/0/1/0/all/0/1\">Fabio A. Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Vinck_Posada_H/0/1/0/all/0/1\">Herbert Vinck-Posada</a>",
          "description": "We demonstrate the implementation of a novel machine learning framework for\nprobability density estimation and classification using quantum circuits. The\nframework maps a training data set or a single data sample to the quantum state\nof a physical system through quantum feature maps. The quantum state of the\narbitrarily large training data set summarises its probability distribution in\na finite-dimensional quantum wave function. By projecting the quantum state of\na new data sample onto the quantum state of the training data set, one can\nderive statistics to classify or estimate the density of the new data sample.\nRemarkably, the implementation of our framework on a real quantum device does\nnot require any optimisation of quantum circuit parameters. Nonetheless, we\ndiscuss a variational quantum circuit approach that could leverage quantum\nadvantage for our framework.",
          "link": "http://arxiv.org/abs/2203.14452",
          "publishedOn": "2022-04-02T00:47:20.189Z",
          "wordCount": null,
          "title": "Optimisation-free Classification and Density Estimation with Quantum Circuits. (arXiv:2203.14452v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Can Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haichun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaohong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shilin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asad_Z/0/1/0/all/0/1\">Zuhayr Asad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coburn_L/0/1/0/all/0/1\">Lori A. Coburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_K/0/1/0/all/0/1\">Keith T. Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuankai Huo</a>",
          "description": "The rapid development of diagnostic technologies in healthcare is leading to\nhigher requirements for physicians to handle and integrate the heterogeneous,\nyet complementary data that are produced during routine practice. For instance,\nthe personalized diagnosis and treatment planning for a single cancer patient\nrelies on the various images (e.g., radiological, pathological, and camera\nimages) and non-image data (e.g., clinical data and genomic data). However,\nsuch decision-making procedures can be subjective, qualitative, and have large\ninter-subject variabilities. With the recent advances in multi-modal deep\nlearning technologies, an increasingly large number of efforts have been\ndevoted to a key question: how do we extract and aggregate multi-modal\ninformation to ultimately provide more objective, quantitative computer-aided\nclinical decision making? This paper reviews the recent studies on dealing with\nsuch a question. Briefly, this review will include the (1) overview of current\nmulti-modal learning workflows, (2) summarization of multi-modal fusion\nmethods, (3) discussion of the performance, (4) applications in disease\ndiagnosis and prognosis, and (5) challenges and future directions.",
          "link": "http://arxiv.org/abs/2203.15588",
          "publishedOn": "2022-04-02T00:47:20.170Z",
          "wordCount": null,
          "title": "Deep Multi-modal Fusion of Image and Non-image Data in Disease Diagnosis and Prognosis: A Review. (arXiv:2203.15588v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16336",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zabihi_S/0/1/0/all/0/1\">Soheil Zabihi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rahimian_E/0/1/0/all/0/1\">Elahe Rahimian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asif_A/0/1/0/all/0/1\">Amir Asif</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohammadi_A/0/1/0/all/0/1\">Arash Mohammadi</a>",
          "description": "Deep learning-based Hand Gesture Recognition (HGR) via surface Electromyogram\n(sEMG) signals has recently shown significant potential for development of\nadvanced myoelectric-controlled prosthesis. Existing deep learning approaches,\ntypically, include only one model as such can hardly maintain acceptable\ngeneralization performance in changing scenarios. In this paper, we aim to\naddress this challenge by capitalizing on the recent advances of hybrid models\nand transformers. In other words, we propose a hybrid framework based on the\ntransformer architecture, which is a relatively new and revolutionizing deep\nlearning model. The proposed hybrid architecture, referred to as the\nTransformer for Hand Gesture Recognition (TraHGR), consists of two parallel\npaths followed by a linear layer that acts as a fusion center to integrate the\nadvantage of each module and provide robustness over different scenarios. We\nevaluated the proposed architecture TraHGR based on the commonly used second\nNinapro dataset, referred to as the DB2. The sEMG signals in the DB2 dataset\nare measured in the real-life conditions from 40 healthy users, each performing\n49 gestures. We have conducted extensive set of experiments to test and\nvalidate the proposed TraHGR architecture, and have compared its achievable\naccuracy with more than five recently proposed HGR classification algorithms\nover the same dataset. We have also compared the results of the proposed TraHGR\narchitecture with each individual path and demonstrated the distinguishing\npower of the proposed hybrid architecture. The recognition accuracies of the\nproposed TraHGR architecture are 86.18%, 88.91%, 81.44%, and 93.84%, which are\n2.48%, 5.12%, 8.82%, and 4.30% higher than the state-ofthe-art performance for\nDB2 (49 gestures), DB2-B (17 gestures), DB2-C (23 gestures), and DB2-D (9\ngestures), respectively.",
          "link": "http://arxiv.org/abs/2203.16336",
          "publishedOn": "2022-04-02T00:47:20.170Z",
          "wordCount": null,
          "title": "TraHGR: Transformer for Hand Gesture Recognition via ElectroMyography. (arXiv:2203.16336v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.03028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Christen_S/0/1/0/all/0/1\">Sammy Christen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocabas_M/0/1/0/all/0/1\">Muhammed Kocabas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aksan_E/0/1/0/all/0/1\">Emre Aksan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwangbo_J/0/1/0/all/0/1\">Jemin Hwangbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "We introduce the dynamic grasp synthesis task: given an object with a known\n6D pose and a grasp reference, our goal is to generate motions that move the\nobject to a target 6D pose. This is challenging, because it requires reasoning\nabout the complex articulation of the human hand and the intricate physical\ninteraction with the object. We propose a novel method that frames this problem\nin the reinforcement learning framework and leverages a physics simulation,\nboth to learn and to evaluate such dynamic interactions. A hierarchical\napproach decomposes the task into low-level grasping and high-level motion\nsynthesis. It can be used to generate novel hand sequences that approach,\ngrasp, and move an object to a desired location, while retaining\nhuman-likeness. We show that our approach leads to stable grasps and generates\na wide range of motions. Furthermore, even imperfect labels can be corrected by\nour method to generate dynamic interaction sequences.",
          "link": "http://arxiv.org/abs/2112.03028",
          "publishedOn": "2022-04-02T00:47:20.170Z",
          "wordCount": null,
          "title": "D-Grasp: Physically Plausible Dynamic Grasp Synthesis for Hand-Object Interactions. (arXiv:2112.03028v2 [cs.RO] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15937",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yang_M/0/1/0/all/0/1\">Mu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hirschi_K/0/1/0/all/0/1\">Kevin Hirschi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Looney_S/0/1/0/all/0/1\">Stephen D. Looney</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kang_O/0/1/0/all/0/1\">Okim Kang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hansen_J/0/1/0/all/0/1\">John H. L. Hansen</a>",
          "description": "Current leading mispronunciation detection and diagnosis (MDD) systems\nachieve promising performance via end-to-end phoneme recognition. One challenge\nof such end-to-end solutions is the scarcity of human-annotated phonemes on\nnatural L2 speech. In this work, we leverage unlabeled L2 speech via a\npseudo-labeling (PL) procedure and extend the fine-tuning approach based on\npre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec\n2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples\nplus the created pseudo-labeled L2 speech samples. Our pseudo labels are\ndynamic and are produced by an ensemble of the online model on-the-fly, which\nensures that our model is robust to pseudo label noise. We show that\nfine-tuning with pseudo labels gains a 5.35% phoneme error rate reduction and\n2.48% MDD F1 score improvement over a labeled-samples-only fine-tuning\nbaseline. The proposed PL method is also shown to outperform conventional\noffline PL methods. Compared to the state-of-the-art MDD systems, our MDD\nsolution achieves a more accurate and consistent phonetic error diagnosis. In\naddition, we conduct an open test on a separate UTD-4Accents dataset, where our\nsystem recognition outputs show a strong correlation with human perception,\nbased on accentedness and intelligibility.",
          "link": "http://arxiv.org/abs/2203.15937",
          "publishedOn": "2022-04-02T00:47:20.169Z",
          "wordCount": null,
          "title": "Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment. (arXiv:2203.15937v1 [eess.AS] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.14542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1\">Nazmul Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizve_M/0/1/0/all/0/1\">Mamshad Nayeem Rizve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1\">Ajmal Mian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Supervised deep learning methods require a large repository of annotated\ndata; hence, label noise is inevitable. Training with such noisy data\nnegatively impacts the generalization performance of deep neural networks. To\ncombat label noise, recent state-of-the-art methods employ some sort of sample\nselection mechanism to select a possibly clean subset of data. Next, an\noff-the-shelf semi-supervised learning method is used for training where\nrejected samples are treated as unlabeled data. Our comprehensive analysis\nshows that current selection methods disproportionately select samples from\neasy (fast learnable) classes while rejecting those from relatively harder\nones. This creates class imbalance in the selected clean set and in turn,\ndeteriorates performance under high label noise. In this work, we propose\nUNICON, a simple yet effective sample selection method which is robust to high\nlabel noise. To address the disproportionate selection of easy and hard\nsamples, we introduce a Jensen-Shannon divergence based uniform selection\nmechanism which does not require any probabilistic modeling and hyperparameter\ntuning. We complement our selection method with contrastive learning to further\ncombat the memorization of noisy labels. Extensive experimentation on multiple\nbenchmark datasets demonstrates the effectiveness of UNICON; we obtain an 11.4%\nimprovement over the current state-of-the-art on CIFAR100 dataset with a 90%\nnoise rate. Our code is publicly available",
          "link": "http://arxiv.org/abs/2203.14542",
          "publishedOn": "2022-04-02T00:47:20.167Z",
          "wordCount": null,
          "title": "UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning. (arXiv:2203.14542v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.06537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenkai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yunfang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "The conventional wisdom behind learning deep classification models is to\nfocus on bad-classified examples and ignore well-classified examples that are\nfar from the decision boundary. For instance, when training with cross-entropy\nloss, examples with higher likelihoods (i.e., well-classified examples)\ncontribute smaller gradients in back-propagation. However, we theoretically\nshow that this common practice hinders representation learning, energy\noptimization, and margin growth. To counteract this deficiency, we propose to\nreward well-classified examples with additive bonuses to revive their\ncontribution to the learning process. This counterexample theoretically\naddresses these three issues. We empirically support this claim by directly\nverifying the theoretical results or significant performance improvement with\nour counterexample on diverse tasks, including image classification, graph\nclassification, and machine translation. Furthermore, this paper shows that we\ncan deal with complex scenarios, such as imbalanced classification, OOD\ndetection, and applications under adversarial attacks because our idea can\nsolve these three issues. Code is available at:\nhttps://github.com/lancopku/well-classified-examples-are-underestimated.",
          "link": "http://arxiv.org/abs/2110.06537",
          "publishedOn": "2022-04-02T00:47:20.159Z",
          "wordCount": null,
          "title": "Well-classified Examples are Underestimated in Classification with Deep Neural Networks. (arXiv:2110.06537v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.08377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1\">Rohit Girdhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mannat Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravi_N/0/1/0/all/0/1\">Nikhila Ravi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maaten_L/0/1/0/all/0/1\">Laurens van der Maaten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1\">Armand Joulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>",
          "description": "Prior work has studied different visual modalities in isolation and developed\nseparate architectures for recognition of images, videos, and 3D data. Instead,\nin this paper, we propose a single model which excels at classifying images,\nvideos, and single-view 3D data using exactly the same model parameters. Our\n'Omnivore' model leverages the flexibility of transformer-based architectures\nand is trained jointly on classification tasks from different modalities.\nOmnivore is simple to train, uses off-the-shelf standard datasets, and performs\nat-par or better than modality-specific models of the same size. A single\nOmnivore model obtains 86.0% on ImageNet, 84.1% on Kinetics, and 67.1% on SUN\nRGB-D. After finetuning, our models outperform prior work on a variety of\nvision tasks and generalize across modalities. Omnivore's shared visual\nrepresentation naturally enables cross-modal recognition without access to\ncorrespondences between modalities. We hope our results motivate researchers to\nmodel visual modalities together.",
          "link": "http://arxiv.org/abs/2201.08377",
          "publishedOn": "2022-04-02T00:47:20.158Z",
          "wordCount": null,
          "title": "Omnivore: A Single Model for Many Visual Modalities. (arXiv:2201.08377v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zhihao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Siqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhijie Yan</a>",
          "description": "Overlapping speech diarization has been traditionally treated as a\nmulti-label classification problem. In this paper, we reformulate this task as\na single-label prediction problem by encoding multiple binary labels into a\nsingle label with the power set, which represents the possible combinations of\ntarget speakers. This formulation has two benefits. First, the overlaps of\ntarget speakers are explicitly modeled. Second, threshold selection is no\nlonger needed. Through this formulation, we propose the speaker embedding-aware\nneural diarization (SEND) framework, where a speech encoder, a speaker encoder,\ntwo similarity scorers, and a post-processing network are jointly optimized to\npredict the encoded labels according to the similarities between speech\nfeatures and speaker embeddings. Experimental results show that SEND has a\nstable learning process and can be trained on highly overlapped data without\nextra initialization. More importantly, our method achieves the\nstate-of-the-art performance in real meeting scenarios with fewer model\nparameters and lower computational complexity.",
          "link": "http://arxiv.org/abs/2203.09767",
          "publishedOn": "2022-04-02T00:47:20.157Z",
          "wordCount": null,
          "title": "Speaker Embedding-aware Neural Diarization: an Efficient Framework for Overlapping Speech Diarization in Meeting Scenarios. (arXiv:2203.09767v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peri_N/0/1/0/all/0/1\">Neehar Peri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luiten_J/0/1/0/all/0/1\">Jonathon Luiten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mengtian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osep_A/0/1/0/all/0/1\">Aljo&#x161;a O&#x161;ep</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1\">Laura Leal-Taix&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>",
          "description": "Object detection and forecasting are fundamental components of embodied\nperception. These two problems, however, are largely studied in isolation by\nthe community. In this paper, we propose an end-to-end approach for detection\nand motion forecasting based on raw sensor measurement as opposed to ground\ntruth tracks. Instead of predicting the current frame locations and forecasting\nforward in time, we directly predict future object locations and backcast to\ndetermine where each trajectory began. Our approach not only improves overall\naccuracy compared to other modular or end-to-end baselines, it also prompts us\nto rethink the role of explicit tracking for embodied perception. Additionally,\nby linking future and current locations in a many-to-one manner, our approach\nis able to reason about multiple futures, a capability that was previously\nconsidered difficult for end-to-end approaches. We conduct extensive\nexperiments on the popular nuScenes dataset and demonstrate the empirical\neffectiveness of our approach. In addition, we investigate the appropriateness\nof reusing standard forecasting metrics for an end-to-end setup, and find a\nnumber of limitations which allow us to build simple baselines to game these\nmetrics. We address this issue with a novel set of joint forecasting and\ndetection metrics that extend the commonly used AP metrics from the detection\ncommunity to measuring forecasting accuracy. Our code is available at\nhttps://github.com/neeharperi/FutureDet",
          "link": "http://arxiv.org/abs/2203.16297",
          "publishedOn": "2022-04-02T00:47:20.155Z",
          "wordCount": null,
          "title": "Forecasting from LiDAR via Future Object Detection. (arXiv:2203.16297v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1\">Guimin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Mingyue Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiechao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Sikun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1\">Lihua Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1\">Robert Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_B/0/1/0/all/0/1\">Bradford Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1\">Laura E. Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boukhechba_M/0/1/0/all/0/1\">Mehdi Boukhechba</a>",
          "description": "The Internet of Things (IoT) boom has revolutionized almost every corner of\npeople's daily lives: healthcare, home, transportation, manufacturing, supply\nchain, and so on. With the recent development of sensor and communication\ntechnologies, IoT devices including smart wearables, cameras, smartwatches, and\nautonomous vehicles can accurately measure and perceive their surrounding\nenvironment. Continuous sensing generates massive amounts of data and presents\nchallenges for machine learning. Deep learning models (e.g., convolution neural\nnetworks and recurrent neural networks) have been extensively employed in\nsolving IoT tasks by learning patterns from multi-modal sensory data. Graph\nNeural Networks (GNNs), an emerging and fast-growing family of neural network\nmodels, can capture complex interactions within sensor topology and have been\ndemonstrated to achieve state-of-the-art results in numerous IoT learning\ntasks. In this survey, we present a comprehensive review of recent advances in\nthe application of GNNs to the IoT field, including a deep dive analysis of GNN\ndesign in various IoT sensing environments, an overarching list of public data\nand source code from the collected publications, and future research\ndirections. To keep track of newly published works, we collect representative\npapers and their open-source implementations and create a Github repository at\nhttps://github.com/GuiminDong/GNN4IoT.",
          "link": "http://arxiv.org/abs/2203.15935",
          "publishedOn": "2022-04-02T00:47:20.154Z",
          "wordCount": null,
          "title": "Graph Neural Networks in IoT: A Survey. (arXiv:2203.15935v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenbin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_J/0/1/0/all/0/1\">Jeremy C. Weiss</a>",
          "description": "Recent works in artificial intelligence fairness attempt to mitigate\ndiscrimination by proposing constrained optimization programs that achieve\nparity for some fairness statistic. Most assume availability of the class\nlabel, which is impractical in many real-world applications such as precision\nmedicine, actuarial analysis and recidivism prediction. Here we consider\nfairness in longitudinal right-censored environments, where the time to event\nmight be unknown, resulting in censorship of the class label and\ninapplicability of existing fairness studies. We devise applicable fairness\nmeasures, propose a debiasing algorithm, and provide necessary theoretical\nconstructs to bridge fairness with and without censorship for these important\nand socially-sensitive tasks. Our experiments on four censored datasets confirm\nthe utility of our approach.",
          "link": "http://arxiv.org/abs/2203.16024",
          "publishedOn": "2022-04-02T00:47:20.144Z",
          "wordCount": null,
          "title": "Longitudinal Fairness with Censorship. (arXiv:2203.16024v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chun-Hsien Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pu-Jen Cheng</a>",
          "description": "Word embedding is a modern distributed word representations approach widely\nused in many natural language processing tasks. Converting the vocabulary in a\nlegal document into a word embedding model facilitates subjecting legal\ndocuments to machine learning, deep learning, and other algorithms and\nsubsequently performing the downstream tasks of natural language processing\nvis-\\`a-vis, for instance, document classification, contract review, and\nmachine translation. The most common and practical approach of accuracy\nevaluation with the word embedding model uses a benchmark set with linguistic\nrules or the relationship between words to perform analogy reasoning via\nalgebraic calculation. This paper proposes establishing a 1,134 Legal\nAnalogical Reasoning Questions Set (LARQS) from the 2,388 Chinese Codex corpus\nusing five kinds of legal relations, which are then used to evaluate the\naccuracy of the Chinese word embedding model. Moreover, we discovered that\nlegal relations might be ubiquitous in the word embedding model.",
          "link": "http://arxiv.org/abs/2203.15173",
          "publishedOn": "2022-04-02T00:47:20.144Z",
          "wordCount": null,
          "title": "An Evaluation Dataset for Legal Word Embedding: A Case Study On Chinese Codex. (arXiv:2203.15173v1 [cs.CL] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.12438",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gupta_V/0/1/0/all/0/1\">Vishal Gupta</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_M/0/1/0/all/0/1\">Michael Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rusmevichientong_P/0/1/0/all/0/1\">Paat Rusmevichientong</a>",
          "description": "Motivated by the poor performance of cross-validation in settings where data\nare scarce, we propose a novel estimator of the out-of-sample performance of a\npolicy in data-driven optimization.Our approach exploits the optimization\nproblem's sensitivity analysis to estimate the gradient of the optimal\nobjective value with respect to the amount of noise in the data and uses the\nestimated gradient to debias the policy's in-sample performance. Unlike\ncross-validation techniques, our approach avoids sacrificing data for a test\nset, utilizes all data when training and, hence, is well-suited to settings\nwhere data are scarce. We prove bounds on the bias and variance of our\nestimator for optimization problems with uncertain linear objectives but known,\npotentially non-convex, feasible regions. For more specialized optimization\nproblems where the feasible region is \"weakly-coupled\" in a certain sense, we\nprove stronger results. Specifically, we provide explicit high-probability\nbounds on the error of our estimator that hold uniformly over a policy class\nand depends on the problem's dimension and policy class's complexity. Our\nbounds show that under mild conditions, the error of our estimator vanishes as\nthe dimension of the optimization problem grows, even if the amount of\navailable data remains small and constant. Said differently, we prove our\nestimator performs well in the small-data, large-scale regime. Finally, we\nnumerically compare our proposed method to state-of-the-art approaches through\na case-study on dispatching emergency medical response services using real\ndata. Our method provides more accurate estimates of out-of-sample performance\nand learns better-performing policies.",
          "link": "http://arxiv.org/abs/2107.12438",
          "publishedOn": "2022-04-02T00:47:20.143Z",
          "wordCount": null,
          "title": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization. (arXiv:2107.12438v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yuhao Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kunlin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Song Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_I/0/1/0/all/0/1\">Ignavier Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Shan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_T/0/1/0/all/0/1\">Teng Fei</a>",
          "description": "Spatial clustering has been widely used for spatial data mining and knowledge\ndiscovery. An ideal multivariate spatial clustering should consider both\nspatial contiguity and aspatial attributes. Existing spatial clustering\napproaches may face challenges for discovering repeated geographic patterns\nwith spatial contiguity maintained. In this paper, we propose a Spatial\nToeplitz Inverse Covariance-Based Clustering (STICC) method that considers both\nattributes and spatial relationships of geographic objects for multivariate\nspatial clustering. A subregion is created for each geographic object serving\nas the basic unit when performing clustering. A Markov random field is then\nconstructed to characterize the attribute dependencies of subregions. Using a\nspatial consistency strategy, nearby objects are encouraged to belong to the\nsame cluster. To test the performance of the proposed STICC algorithm, we apply\nit in two use cases. The comparison results with several baseline methods show\nthat the STICC outperforms others significantly in terms of adjusted rand index\nand macro-F1 score. Join count statistics is also calculated and shows that the\nspatial contiguity is well preserved by STICC. Such a spatial clustering method\nmay benefit various applications in the fields of geography, remote sensing,\ntransportation, and urban planning, etc.",
          "link": "http://arxiv.org/abs/2203.09611",
          "publishedOn": "2022-04-02T00:47:20.143Z",
          "wordCount": null,
          "title": "STICC: A multivariate spatial clustering method for repeated geographic pattern discovery with consideration of spatial contiguity. (arXiv:2203.09611v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1\">Matthew Ciolino</a>",
          "description": "If a unit cannot receive intelligence from a source due to external factors,\nwe consider them disadvantaged users. We categorize this as a preoccupied unit\nworking on a low connectivity device on the edge. This case requires that we\nuse a different approach to deliver intelligence, particularly satellite\nimagery information, than normally employed. To address this, we propose a\nsurvey of information reduction techniques to deliver the information from a\nsatellite image in a smaller package. We investigate four techniques to aid in\nthe reduction of delivered information: traditional image compression, neural\nnetwork image compression, object detection image cutout, and image to caption.\nEach of these mechanisms have their benefits and tradeoffs when considered for\na disadvantaged user.",
          "link": "http://arxiv.org/abs/2203.13686",
          "publishedOn": "2022-04-02T00:47:20.143Z",
          "wordCount": null,
          "title": "Image Compression and Actionable Intelligence With Deep Neural Networks. (arXiv:2203.13686v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hemati_H/0/1/0/all/0/1\">Hamed Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schreyer_M/0/1/0/all/0/1\">Marco Schreyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>",
          "description": "International audit standards require the direct assessment of a financial\nstatement's underlying accounting journal entries. Driven by advances in\nartificial intelligence, deep-learning inspired audit techniques emerged to\nexamine vast quantities of journal entry data. However, in regular audits, most\nof the proposed methods are applied to learn from a comparably stationary\njournal entry population, e.g., of a financial quarter or year. Ignoring\nsituations where audit relevant distribution changes are not evident in the\ntraining data or become incrementally available over time. In contrast, in\ncontinuous auditing, deep-learning models are continually trained on a stream\nof recorded journal entries, e.g., of the last hour. Resulting in situations\nwhere previous knowledge interferes with new information and will be entirely\noverwritten. This work proposes a continual anomaly detection framework to\novercome both challenges and designed to learn from a stream of journal entry\ndata experiences. The framework is evaluated based on deliberately designed\naudit scenarios and two real-world datasets. Our experimental results provide\ninitial evidence that such a learning scheme offers the ability to reduce\nfalse-positive alerts and false-negative decisions.",
          "link": "http://arxiv.org/abs/2112.13215",
          "publishedOn": "2022-04-02T00:47:20.142Z",
          "wordCount": null,
          "title": "Continual Learning for Unsupervised Anomaly Detection in Continuous Auditing of Financial Accounting Data. (arXiv:2112.13215v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Augustin_M/0/1/0/all/0/1\">Mihai-Cezar Augustin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonvin_V/0/1/0/all/0/1\">Vivien Bonvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houssou_R/0/1/0/all/0/1\">Regis Houssou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rappos_E/0/1/0/all/0/1\">Efstratios Rappos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robert_Nicoud_S/0/1/0/all/0/1\">Stephan Robert-Nicoud</a>",
          "description": "In classification problems, supervised machine-learning methods outperform\ntraditional algorithms, thanks to the ability of neural networks to learn\ncomplex patterns. However, in two-class classification tasks like anomaly or\nfraud detection, unsupervised methods could do even better, because their\nprediction is not limited to previously learned types of anomalies. An\nintuitive approach of anomaly detection can be based on the distances from the\ncenters of mass of the two respective classes. Autoencoders, although trained\nwithout supervision, can also detect anomalies: considering the center of mass\nof the normal points, reconstructions have now radii, with largest radii most\nlikely indicating anomalous points. Of course, radii-based classification were\nalready possible without interposing an autoencoder. In any space, radial\nclassification can be operated, to some extent. In order to outperform it, we\nproceed to radial deformations of data (i.e. centric compression or expansions\nof axes) and autoencoder training. Any autoencoder that makes use of a data\ncenter is here baptized a centric autoencoder (cAE). A special type is the cAE\ntrained with a uniformly compressed dataset, named the centripetal autoencoder\n(cpAE). The new concept is studied here in relation with a schematic artificial\ndataset, and the derived methods show consistent score improvements. But tested\non real banking data, our radial deformation supervised algorithms alone still\nperform better that cAEs, as expected from most supervised methods;\nnonetheless, in hybrid approaches, cAEs can be combined with a radial\ndeformation of space, improving its classification score. We expect that\ncentric autoencoders will become irreplaceable objects in anomaly live\ndetection based on geometry, thanks to their ability to stem naturally on\ngeometrical algorithms and to their native capability of detecting unknown\nanomaly types.",
          "link": "http://arxiv.org/abs/2203.15884",
          "publishedOn": "2022-04-02T00:47:20.142Z",
          "wordCount": null,
          "title": "Radial Autoencoders for Enhanced Anomaly Detection. (arXiv:2203.15884v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.13634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avranas_A/0/1/0/all/0/1\">Apostolos Avranas</a> (EURECOM), <a href=\"http://arxiv.org/find/cs/1/au:+Kountouris_M/0/1/0/all/0/1\">Marios Kountouris</a> (EURECOM), <a href=\"http://arxiv.org/find/cs/1/au:+Ciblat_P/0/1/0/all/0/1\">Philippe Ciblat</a> (T&#xe9;l&#xe9;com Paris)",
          "description": "The problem of resource constrained scheduling in a dynamic and heterogeneous\nwireless setting is considered here. In our setup, the available limited\nbandwidth resources are allocated in order to serve randomly arriving service\ndemands, which in turn belong to different classes in terms of payload data\nrequirement, delay tolerance, and importance/priority. In addition to\nheterogeneous traffic, another major challenge stems from random service rates\ndue to time-varying wireless communication channels. Various approaches for\nscheduling and resource allocation can be used, ranging from simple greedy\nheuristics and constrained optimization to combinatorics. Those methods are\ntailored to specific network or application configuration and are usually\nsuboptimal. To this purpose, we resort to deep reinforcement learning (DRL) and\npropose a distributional Deep Deterministic Policy Gradient (DDPG) algorithm\ncombined with Deep Sets to tackle the aforementioned problem. Furthermore, we\npresent a novel way to use a Dueling Network, which leads to further\nperformance improvement. Our proposed algorithm is tested on both synthetic and\nreal data, showing consistent gains against state-of-the-art conventional\nmethods from combinatorics, optimization, and scheduling metrics.",
          "link": "http://arxiv.org/abs/2011.13634",
          "publishedOn": "2022-04-02T00:47:20.141Z",
          "wordCount": null,
          "title": "Deep Reinforcement Learning for Resource Constrained Multiclass Scheduling in Wireless Networks. (arXiv:2011.13634v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15547",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bright_J/0/1/0/all/0/1\">Jerrin Bright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajkumar_S/0/1/0/all/0/1\">Suryaprakash Rajkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doss_A/0/1/0/all/0/1\">Arockia Selvakumar Arockia Doss</a>",
          "description": "Convolutional Neural Networks need the construction of informative features,\nwhich are determined by channel-wise and spatial-wise information at the\nnetwork's layers. In this research, we focus on bringing in a novel solution\nthat uses sophisticated optimization for enhancing both the spatial and channel\ncomponents inside each layer's receptive field. Capsule Networks were used to\nunderstand the spatial association between features in the feature map.\nStandalone capsule networks have shown good results on comparatively simple\ndatasets than on complex datasets as a result of the inordinate amount of\nfeature information. Thus, to tackle this issue, we have proposed ME-CapsNet by\nintroducing deeper convolutional layers to extract important features before\npassing through modules of capsule layers strategically to improve the\nperformance of the network significantly. The deeper convolutional layer\nincludes blocks of Squeeze-Excitation networks which use a stochastic sampling\napproach for progressively reducing the spatial size thereby dynamically\nrecalibrating the channels by reconstructing their interdependencies without\nmuch loss of important feature information. Extensive experimentation was done\nusing commonly used datasets demonstrating the efficiency of the proposed\nME-CapsNet, which clearly outperforms various research works by achieving\nhigher accuracy with minimal model complexity in complex datasets.",
          "link": "http://arxiv.org/abs/2203.15547",
          "publishedOn": "2022-04-02T00:47:20.141Z",
          "wordCount": null,
          "title": "ME-CapsNet: A Multi-Enhanced Capsule Networks with Routing Mechanism. (arXiv:2203.15547v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.01522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhi Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Baosheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Despite the success of deep neural networks, there are still many challenges\nin deep representation learning due to the data scarcity issues such as data\nimbalance, unseen distribution, and domain shift. To address the\nabove-mentioned issues, a variety of methods have been devised to explore the\nsample relationships in a vanilla way (i.e., from the perspectives of either\nthe input or the loss function), failing to explore the internal structure of\ndeep neural networks for learning with sample relationships. Inspired by this,\nwe propose to enable deep neural networks themselves with the ability to learn\nthe sample relationships from each mini-batch. Specifically, we introduce a\nbatch transformer module or BatchFormer, which is then applied into the batch\ndimension of each mini-batch to implicitly explore sample relationships during\ntraining. By doing this, the proposed method enables the collaboration of\ndifferent samples, e.g., the head-class samples can also contribute to the\nlearning of the tail classes for long-tailed recognition. Furthermore, to\nmitigate the gap between training and testing, we share the classifier between\nwith or without the BatchFormer during training, which can thus be removed\nduring testing. We perform extensive experiments on over ten datasets and the\nproposed method achieves significant improvements on different data scarcity\napplications without any bells and whistles, including the tasks of long-tailed\nrecognition, compositional zero-shot learning, domain generalization, and\ncontrastive learning. Code will be made publicly available at\nhttps://github.com/zhihou7/BatchFormer.",
          "link": "http://arxiv.org/abs/2203.01522",
          "publishedOn": "2022-04-02T00:47:20.141Z",
          "wordCount": null,
          "title": "BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning. (arXiv:2203.01522v2 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Karren Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markovic_D/0/1/0/all/0/1\">Dejan Markovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krenn_S/0/1/0/all/0/1\">Steven Krenn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_V/0/1/0/all/0/1\">Vasu Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_A/0/1/0/all/0/1\">Alexander Richard</a>",
          "description": "Since facial actions such as lip movements contain significant information\nabout speech content, it is not surprising that audio-visual speech enhancement\nmethods are more accurate than their audio-only counterparts. Yet,\nstate-of-the-art approaches still struggle to generate clean, realistic speech\nwithout noise artifacts and unnatural distortions in challenging acoustic\nenvironments. In this paper, we propose a novel audio-visual speech enhancement\nframework for high-fidelity telecommunications in AR/VR. Our approach leverages\naudio-visual speech cues to generate the codes of a neural speech codec,\nenabling efficient synthesis of clean, realistic speech from noisy signals.\nGiven the importance of speaker-specific cues in speech, we focus on developing\npersonalized models that work well for individual speakers. We demonstrate the\nefficacy of our approach on a new audio-visual speech dataset collected in an\nunconstrained, large vocabulary setting, as well as existing audio-visual\ndatasets, outperforming speech enhancement baselines on both quantitative\nmetrics and human evaluation studies. Please see the supplemental video for\nqualitative results at\nhttps://github.com/facebookresearch/facestar/releases/download/paper_materials/video.mp4.",
          "link": "http://arxiv.org/abs/2203.17263",
          "publishedOn": "2022-04-02T00:47:20.131Z",
          "wordCount": null,
          "title": "Audio-Visual Speech Codecs: Rethinking Audio-Visual Speech Enhancement by Re-Synthesis. (arXiv:2203.17263v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chengxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengyuan Zhang</a>",
          "description": "Previous research has looked into ways to improve speech emotion recognition\n(SER) by utilizing both acoustic and linguistic cues of speech. However, the\npotential association between state-of-the-art ASR models and the SER task has\nyet to be investigated. In this paper, we propose a novel channel and\ntemporal-wise attention RNN (CTA-RNN) architecture based on the intermediate\nrepresentations of pre-trained ASR models. Specifically, the embeddings of a\nlarge-scale pre-trained end-to-end ASR encoder contain both acoustic and\nlinguistic information, as well as the ability to generalize to different\nspeakers, making them well suited for downstream SER task. To further exploit\nthe embeddings from different layers of the ASR encoder, we propose a novel\nCTA-RNN architecture to capture the emotional salient parts of embeddings in\nboth the channel and temporal directions. We evaluate our approach on two\npopular benchmark datasets, IEMOCAP and MSP-IMPROV, using both within-corpus\nand cross-corpus settings. Experimental results show that our proposed method\ncan achieve excellent performance in terms of accuracy and robustness.",
          "link": "http://arxiv.org/abs/2203.17023",
          "publishedOn": "2022-04-02T00:47:20.119Z",
          "wordCount": null,
          "title": "CTA-RNN: Channel and Temporal-wise Attention RNN Leveraging Pre-trained ASR Embeddings for Speech Emotion Recognition. (arXiv:2203.17023v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.06392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hemati_H/0/1/0/all/0/1\">Hamed Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>",
          "description": "Recent neural Text-to-Speech (TTS) models have been shown to perform very\nwell when enough data is available. However, fine-tuning them for new speakers\nor languages is not straightforward in a low-resource setup. In this paper, we\nshow that by applying minor modifications to a Tacotron model, one can transfer\nan existing TTS model for new speakers from the same or a different language\nusing only 20 minutes of data. For this purpose, we first introduce a base\nmulti-lingual Tacotron with language-agnostic input, then demonstrate how\ntransfer learning is done for different scenarios of speaker adaptation without\nexploiting any pre-trained speaker encoder or code-switching technique. We\nevaluate the transferred model in both subjective and objective ways.",
          "link": "http://arxiv.org/abs/2011.06392",
          "publishedOn": "2022-04-02T00:47:20.118Z",
          "wordCount": null,
          "title": "Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker Adaptation and Pronunciation Enhancement. (arXiv:2011.06392v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.05885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dankers_V/0/1/0/all/0/1\">Verna Dankers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1\">Elia Bruni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>",
          "description": "Obtaining human-like performance in NLP is often argued to require\ncompositional generalisation. Whether neural networks exhibit this ability is\nusually studied by training models on highly compositional synthetic data.\nHowever, compositionality in natural language is much more complex than the\nrigid, arithmetic-like version such data adheres to, and artificial\ncompositionality tests thus do not allow us to determine how neural models deal\nwith more realistic forms of compositionality. In this work, we re-instantiate\nthree compositionality tests from the literature and reformulate them for\nneural machine translation (NMT). Our results highlight that: i) unfavourably,\nmodels trained on more data are more compositional; ii) models are sometimes\nless compositional than expected, but sometimes more, exemplifying that\ndifferent levels of compositionality are required, and models are not always\nable to modulate between them correctly; iii) some of the non-compositional\nbehaviours are mistakes, whereas others reflect the natural variation in data.\nApart from an empirical study, our work is a call to action: we should rethink\nthe evaluation of compositionality in neural networks and develop benchmarks\nusing real data to evaluate compositionality on natural language, where\ncomposing meaning is not as straightforward as doing the math.",
          "link": "http://arxiv.org/abs/2108.05885",
          "publishedOn": "2022-04-02T00:47:20.118Z",
          "wordCount": null,
          "title": "The paradox of the compositionality of natural language: a neural machine translation case study. (arXiv:2108.05885v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.13366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Shijie Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zuohui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "For a long period, different recommendation tasks typically require designing\ntask-specific architectures and training objectives. As a result, it is hard to\ntransfer the learned knowledge and representations from one task to another,\nthus restricting the generalization ability of existing recommendation\napproaches, e.g., a sequential recommendation model can hardly be applied or\ntransferred to a review generation method. To deal with such issues,\nconsidering that language grounding is a powerful medium to describe and\nrepresent various problems or tasks, we present a flexible and unified\ntext-to-text paradigm called \"Pretrain, Personalized Prompt, and Predict\nParadigm\" (P5) for recommendation, which unifies various recommendation tasks\nin a shared framework. In P5, all data such as user-item interactions, item\nmetadata, and user reviews are converted to a common format -- natural language\nsequences. The rich information from natural language assist P5 to capture\ndeeper semantics for recommendation. P5 learns different tasks with the same\nlanguage modeling objective during pretraining. Thus, it possesses the\npotential to serve as the foundation model for downstream recommendation tasks,\nallows easy integration with other modalities, and enables instruction-based\nrecommendation, which will revolutionize the technical form of recommender\nsystem towards universal recommendation engine. With adaptive personalized\nprompt for different users, P5 is able to make predictions in a zero-shot or\nfew-shot manner and largely reduces the necessity for extensive fine-tuning. On\nseveral recommendation benchmarks, we conduct experiments to show the\neffectiveness of our generative approach. We will release our prompts and\npretrained P5 language model to help advance future research on Recommendation\nas Language Processing (RLP) and Personalized Foundation Models.",
          "link": "http://arxiv.org/abs/2203.13366",
          "publishedOn": "2022-04-02T00:47:20.118Z",
          "wordCount": null,
          "title": "Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5). (arXiv:2203.13366v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.10811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ben_Shabat_Y/0/1/0/all/0/1\">Yizhak Ben-Shabat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koneputugodage_C/0/1/0/all/0/1\">Chamin Hewa Koneputugodage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>",
          "description": "Shape implicit neural representations (INRs) have recently shown to be\neffective in shape analysis and reconstruction tasks. Existing INRs require\npoint coordinates to learn the implicit level sets of the shape. When a normal\nvector is available for each point, a higher fidelity representation can be\nlearned, however normal vectors are often not provided as raw data.\nFurthermore, the method's initialization has been shown to play a crucial role\nfor surface reconstruction. In this paper, we propose a divergence guided shape\nrepresentation learning approach that does not require normal vectors as input.\nWe show that incorporating a soft constraint on the divergence of the distance\nfunction favours smooth solutions that reliably orients gradients to match the\nunknown normal at each point, in some cases even better than approaches that\nuse ground truth normal vectors directly. Additionally, we introduce a novel\ngeometric initialization method for sinusoidal INRs that further improves\nconvergence to the desired solution. We evaluate the effectiveness of our\napproach on the task of surface reconstruction and shape space learning and\nshow SOTA performance compared to other unoriented methods. Code and model\nparameters available at our project page https://chumbyte.github.io/DiGS-Site/.",
          "link": "http://arxiv.org/abs/2106.10811",
          "publishedOn": "2022-04-02T00:47:20.117Z",
          "wordCount": null,
          "title": "DiGS : Divergence guided shape implicit neural representation for unoriented point clouds. (arXiv:2106.10811v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przyborowski_M/0/1/0/all/0/1\">Mateusz Przyborowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pabis_M/0/1/0/all/0/1\">Mateusz Pabi&#x15b;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janusz_A/0/1/0/all/0/1\">Andrzej Janusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Dominik &#x15a;l&#x119;zak</a>",
          "description": "Gaussian mixture models find their place as a powerful tool, mostly in the\nclustering problem, but with proper preparation also in feature extraction,\npattern recognition, image segmentation and in general machine learning. When\nfaced with the problem of schema matching, different mixture models computed on\ndifferent pieces of data can maintain crucial information about the structure\nof the dataset. In order to measure or compare results from mixture models, the\nWasserstein distance can be very useful, however it is not easy to calculate\nfor mixture distributions. In this paper we derive one of possible\napproximations for the Wasserstein distance between Gaussian mixture models and\nreduce it to linear problem. Furthermore, application examples concerning real\nworld data are shown.",
          "link": "http://arxiv.org/abs/2111.14244",
          "publishedOn": "2022-04-02T00:47:20.117Z",
          "wordCount": null,
          "title": "Schema matching using Gaussian mixture models with Wasserstein distance. (arXiv:2111.14244v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17275",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xingyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunzhu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1\">David Held</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>",
          "description": "We consider the problem of sequential robotic manipulation of deformable\nobjects using tools. Previous works have shown that differentiable physics\nsimulators provide gradients to the environment state and help trajectory\noptimization to converge orders of magnitude faster than model-free\nreinforcement learning algorithms for deformable object manipulation. However,\nsuch gradient-based trajectory optimization typically requires access to the\nfull simulator states and can only solve short-horizon, single-skill tasks due\nto local optima. In this work, we propose a novel framework, named DiffSkill,\nthat uses a differentiable physics simulator for skill abstraction to solve\nlong-horizon deformable object manipulation tasks from sensory observations. In\nparticular, we first obtain short-horizon skills using individual tools from a\ngradient-based optimizer, using the full state information in a differentiable\nsimulator; we then learn a neural skill abstractor from the demonstration\ntrajectories which takes RGBD images as input. Finally, we plan over the skills\nby finding the intermediate goals and then solve long-horizon tasks. We show\nthe advantages of our method in a new set of sequential deformable object\nmanipulation tasks compared to previous reinforcement learning algorithms and\ncompared to the trajectory optimizer.",
          "link": "http://arxiv.org/abs/2203.17275",
          "publishedOn": "2022-04-02T00:47:20.110Z",
          "wordCount": null,
          "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools. (arXiv:2203.17275v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.12967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haroush_M/0/1/0/all/0/1\">Matan Haroush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_T/0/1/0/all/0/1\">Tzviel Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_R/0/1/0/all/0/1\">Ruth Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1\">Daniel Soudry</a>",
          "description": "Background. Commonly, Deep Neural Networks (DNNs) generalize well on samples\ndrawn from a distribution similar to that of the training set. However, DNNs'\npredictions are brittle and unreliable when the test samples are drawn from a\ndissimilar distribution. This is a major concern for deployment in real-world\napplications, where such behavior may come at a considerable cost, such as\nindustrial production lines, autonomous vehicles, or healthcare applications.\nContributions. We frame Out Of Distribution (OOD) detection in DNNs as a\nstatistical hypothesis testing problem. Tests generated within our proposed\nframework combine evidence from the entire network. Unlike previous OOD\ndetection heuristics, this framework returns a $p$-value for each test sample.\nIt is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD\nfor an actual in-distribution sample) for test data. Moreover, this allows to\ncombine several detectors while maintaining the T1E. Building on this\nframework, we suggest a novel OOD procedure based on low-order statistics. Our\nmethod achieves comparable or better results than state-of-the-art methods on\nwell-accepted OOD benchmarks, without retraining the network parameters or\nassuming prior knowledge on the test distribution -- and at a fraction of the\ncomputational cost.",
          "link": "http://arxiv.org/abs/2102.12967",
          "publishedOn": "2022-04-02T00:47:20.110Z",
          "wordCount": null,
          "title": "A statistical framework for efficient out of distribution detection in deep neural networks. (arXiv:2102.12967v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Batz_K/0/1/0/all/0/1\">Kevin Batz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallus_A/0/1/0/all/0/1\">Adrian Gallus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaminski_B/0/1/0/all/0/1\">Benjamin Lucien Kaminski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katoen_J/0/1/0/all/0/1\">Joost-Pieter Katoen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winkler_T/0/1/0/all/0/1\">Tobias Winkler</a>",
          "description": "We study weighted programming, a programming paradigm for specifying\nmathematical models. More specifically, the weighted programs we investigate\nare like usual imperative programs with two additional features: (1)\nnondeterministic branching and (2) weighting execution traces. Weights can be\nnumbers but also other objects like words from an alphabet, polynomials, formal\npower series, or cardinal numbers. We argue that weighted programming as a\nparadigm can be used to specify mathematical models beyond probability\ndistributions (as is done in probabilistic programming).\n\nWe develop weakest-precondition- and weakest-liberal-precondition-style\ncalculi \\`{a} la Dijkstra for reasoning about mathematical models specified by\nweighted programs. We present several case studies. For instance, we use\nweighted programming to model the ski rental problem - an optimization problem.\nWe model not only the optimization problem itself, but also the best\ndeterministic online algorithm for solving this problem as weighted programs.\nBy means of weakest-precondition-style reasoning, we can determine the\ncompetitive ratio of the online algorithm on source code level.",
          "link": "http://arxiv.org/abs/2202.07577",
          "publishedOn": "2022-04-02T00:47:20.110Z",
          "wordCount": null,
          "title": "Weighted Programming. (arXiv:2202.07577v2 [cs.PL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fuyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tingyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1\">Yu Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1\">Yatao Bian</a>",
          "description": "As a powerful tool for modeling complex relationships, hypergraphs are\ngaining popularity from the graph learning community. However, commonly used\nframeworks in deep hypergraph learning focus on hypergraphs with\n\\textit{edge-independent vertex weights}(EIVWs), without considering\nhypergraphs with \\textit{edge-dependent vertex weights} (EDVWs) that have more\nmodeling power. To compensate for this, in this paper, we present General\nHypergraph Spectral Convolution(GHSC), a general learning framework that not\nonly can handle EDVW and EIVW hypergraphs, but more importantly, enables\ntheoretically explicitly utilizing the existing powerful Graph Convolutional\nNeural Networks (GCNNs) such that largely ease the design of Hypergraph Neural\nNetworks. In this framework, the graph Laplacian of the given undirected GCNNs\nis replaced with a unified hypergraph Laplacian that incorporates vertex weight\ninformation from a random walk perspective by equating our defined generalized\nhypergraphs with simple undirected graphs. Extensive experiments from various\ndomains including social network analysis, visual objective classification,\nprotein learning demonstrate that the proposed framework can achieve\nstate-of-the-art performance.",
          "link": "http://arxiv.org/abs/2203.16939",
          "publishedOn": "2022-04-02T00:47:20.109Z",
          "wordCount": null,
          "title": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs and Undirected Graphs. (arXiv:2203.16939v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1908.02203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Udeshi_S/0/1/0/all/0/1\">Sakshi Udeshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shanshan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_G/0/1/0/all/0/1\">Gerald Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loh_L/0/1/0/all/0/1\">Lionell Loh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawshan_L/0/1/0/all/0/1\">Louth Rawshan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1\">Sudipta Chattopadhyay</a>",
          "description": "Machine Learning (ML) has automated a multitude of our day-to-day decision\nmaking domains such as education, employment and driving automation. The\ncontinued success of ML largely depends on our ability to trust the model we\nare using. Recently, a new class of attacks called Backdoor Attacks have been\ndeveloped. These attacks undermine the user's trust in ML models. In this work,\nwe present NEO, a model agnostic framework to detect and mitigate such backdoor\nattacks in image classification ML models. For a given image classification\nmodel, our approach analyses the inputs it receives and determines if the model\nis backdoored. In addition to this feature, we also mitigate these attacks by\ndetermining the correct predictions of the poisoned images. An appealing\nfeature of NEO is that it can, for the first time, isolate and reconstruct the\nbackdoor trigger. NEO is also the first defence methodology, to the best of our\nknowledge that is completely blackbox.\n\nWe have implemented NEO and evaluated it against three state of the art\npoisoned models. These models include highly critical applications such as\ntraffic sign detection (USTS) and facial detection. In our evaluation, we show\nthat NEO can detect $\\approx$88% of the poisoned inputs on average and it is as\nfast as 4.4 ms per input image. We also reconstruct the poisoned input for the\nuser to effectively test their systems.",
          "link": "http://arxiv.org/abs/1908.02203",
          "publishedOn": "2022-04-02T00:47:20.106Z",
          "wordCount": null,
          "title": "Model Agnostic Defence against Backdoor Attacks in Machine Learning. (arXiv:1908.02203v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16822",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasad_A/0/1/0/all/0/1\">Amrutha Prasad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sarfjoo_S/0/1/0/all/0/1\">Saeed Sarfjoo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kleinert_M/0/1/0/all/0/1\">Matthias Kleinert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Helmke_H/0/1/0/all/0/1\">Hartmut Helmke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ohneiser_O/0/1/0/all/0/1\">Oliver Ohneiser</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhan_Q/0/1/0/all/0/1\">Qingran Zhan</a>",
          "description": "Recent work on self-supervised pre-training focus on leveraging large-scale\nunlabeled speech data to build robust end-to-end (E2E) acoustic models (AM)\nthat can be later fine-tuned on downstream tasks e.g., automatic speech\nrecognition (ASR). Yet, few works investigated the impact on performance when\nthe data substantially differs between the pre-training and downstream\nfine-tuning phases (i.e., domain shift). We target this scenario by analyzing\nthe robustness of Wav2Vec2.0 and XLS-R models on downstream ASR for a\ncompletely unseen domain, i.e., air traffic control (ATC) communications. We\nbenchmark the proposed models on four challenging ATC test sets\n(signal-to-noise ratio varies between 5 to 20 dB). Relative word error rate\n(WER) reduction between 20% to 40% are obtained in comparison to hybrid-based\nstate-of-the-art ASR baselines by fine-tuning E2E acoustic models with a small\nfraction of labeled data. We also study the impact of fine-tuning data size on\nWERs, going from 5 minutes (few-shot) to 15 hours.",
          "link": "http://arxiv.org/abs/2203.16822",
          "publishedOn": "2022-04-02T00:47:20.105Z",
          "wordCount": null,
          "title": "How Does Pre-trained Wav2Vec2.0 Perform on Domain Shifted ASR? An Extensive Benchmark on Air Traffic Control Communications. (arXiv:2203.16822v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.14785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1\">Tianyu Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huishuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yinpeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Correctly classifying adversarial examples is an essential but challenging\nrequirement for safely deploying machine learning models. As reported in\nRobustBench, even the state-of-the-art adversarially trained models struggle to\nexceed 67% robust test accuracy on CIFAR-10, which is far from practical. A\ncomplementary way towards robustness is to introduce a rejection option,\nallowing the model to not return predictions on uncertain inputs, where\nconfidence is a commonly used certainty proxy. Along with this routine, we find\nthat confidence and a rectified confidence (R-Con) can form two coupled\nrejection metrics, which could provably distinguish wrongly classified inputs\nfrom correctly classified ones. This intriguing property sheds light on using\ncoupling strategies to better detect and reject adversarial examples. We\nevaluate our rectified rejection (RR) module on CIFAR-10, CIFAR-10-C, and\nCIFAR-100 under several attacks including adaptive ones, and demonstrate that\nthe RR module is compatible with different adversarial training frameworks on\nimproving robustness, with little extra computation. The code is available at\nhttps://github.com/P2333/Rectified-Rejection.",
          "link": "http://arxiv.org/abs/2105.14785",
          "publishedOn": "2022-04-02T00:47:20.105Z",
          "wordCount": null,
          "title": "Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart. (arXiv:2105.14785v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.04671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1\">Yuejiao Sun</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xiao_Q/0/1/0/all/0/1\">Quan Xiao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>",
          "description": "Stochastic bilevel optimization generalizes the classic stochastic\noptimization from the minimization of a single objective to the minimization of\nan objective function that depends the solution of another optimization\nproblem. Recently, stochastic bilevel optimization is regaining popularity in\nemerging machine learning applications such as hyper-parameter optimization and\nmodel-agnostic meta learning. To solve this class of stochastic optimization\nproblems, existing methods require either double-loop or two-timescale updates,\nwhich are sometimes less efficient. This paper develops a new optimization\nmethod for a class of stochastic bilevel problems that we term Single-Timescale\nstochAstic BiLevEl optimization (STABLE) method. STABLE runs in a single loop\nfashion, and uses a single-timescale update with a fixed batch size. To achieve\nan $\\epsilon$-stationary point of the bilevel problem, STABLE requires ${\\cal\nO}(\\epsilon^{-2})$ samples in total; and to achieve an $\\epsilon$-optimal\nsolution in the strongly convex case, STABLE requires ${\\cal O}(\\epsilon^{-1})$\nsamples. To the best of our knowledge, this is the first bilevel optimization\nalgorithm achieving the same order of sample complexity as the stochastic\ngradient descent method for the single-level stochastic optimization.",
          "link": "http://arxiv.org/abs/2102.04671",
          "publishedOn": "2022-04-02T00:47:20.103Z",
          "wordCount": null,
          "title": "A Single-Timescale Method for Stochastic Bilevel Optimization. (arXiv:2102.04671v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17019",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chernyak_B/0/1/0/all/0/1\">Bronya R. Chernyak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Simon_T/0/1/0/all/0/1\">Talia Ben Simon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Segal_Y/0/1/0/all/0/1\">Yael Segal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Steffman_J/0/1/0/all/0/1\">Jeremy Steffman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chodroff_E/0/1/0/all/0/1\">Eleanor Chodroff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cole_J/0/1/0/all/0/1\">Jennifer S. Cole</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>",
          "description": "Vocal fry or creaky voice refers to a voice quality characterized by\nirregular glottal opening and low pitch. It occurs in diverse languages and is\nprevalent in American English, where it is used not only to mark phrase\nfinality, but also sociolinguistic factors and affect. Due to its irregular\nperiodicity, creaky voice challenges automatic speech processing and\nrecognition systems, particularly for languages where creak is frequently used.\n\nThis paper proposes a deep learning model to detect creaky voice in fluent\nspeech. The model is composed of an encoder and a classifier trained together.\nThe encoder takes the raw waveform and learns a representation using a\nconvolutional neural network. The classifier is implemented as a multi-headed\nfully-connected network trained to detect creaky voice, voicing, and pitch,\nwhere the last two are used to refine creak prediction. The model is trained\nand tested on speech of American English speakers, annotated for creak by\ntrained phoneticians.\n\nWe evaluated the performance of our system using two encoders: one is\ntailored for the task, and the other is based on a state-of-the-art\nunsupervised representation. Results suggest our best-performing system has\nimproved recall and F1 scores compared to previous methods on unseen data.",
          "link": "http://arxiv.org/abs/2203.17019",
          "publishedOn": "2022-04-02T00:47:20.102Z",
          "wordCount": null,
          "title": "DeepFry: Identifying Vocal Fry Using Deep Neural Networks. (arXiv:2203.17019v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17004",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Welker_S/0/1/0/all/0/1\">Simon Welker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Richter_J/0/1/0/all/0/1\">Julius Richter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gerkmann_T/0/1/0/all/0/1\">Timo Gerkmann</a>",
          "description": "Score-based generative models (SGMs) have recently shown impressive results\nfor difficult generative tasks such as the unconditional and conditional\ngeneration of natural images and audio signals. In this work, we extend these\nmodels to the complex short-time Fourier transform (STFT) domain, proposing a\nnovel training task for speech enhancement using a complex-valued deep neural\nnetwork. We derive this training task within the formalism of stochastic\ndifferential equations, thereby enabling the use of predictor-corrector\nsamplers. We provide alternative formulations inspired by previous publications\non using SGMs for speech enhancement, avoiding the need for any prior\nassumptions on the noise distribution and making the training task purely\ngenerative which, as we show, results in improved enhancement performance.",
          "link": "http://arxiv.org/abs/2203.17004",
          "publishedOn": "2022-04-02T00:47:20.085Z",
          "wordCount": null,
          "title": "Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain. (arXiv:2203.17004v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Houssou_R/0/1/0/all/0/1\">Regis Houssou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augustin_M/0/1/0/all/0/1\">Mihai-Cezar Augustin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rappos_E/0/1/0/all/0/1\">Efstratios Rappos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonvin_V/0/1/0/all/0/1\">Vivien Bonvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robert_Nicoud_S/0/1/0/all/0/1\">Stephan Robert-Nicoud</a>",
          "description": "This paper proposes a new method to generate synthetic data sets based on\ncopula models. Our goal is to produce surrogate data resembling real data in\nterms of marginal and joint distributions. We present a complete and reliable\nalgorithm for generating a synthetic data set comprising numeric or categorical\nvariables. Applying our methodology to two datasets shows better performance\ncompared to other methods such as SMOTE and autoencoders.",
          "link": "http://arxiv.org/abs/2203.17250",
          "publishedOn": "2022-04-02T00:47:20.085Z",
          "wordCount": null,
          "title": "Generation and Simulation of Synthetic Datasets with Copulas. (arXiv:2203.17250v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Yitzhak Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ehsani_K/0/1/0/all/0/1\">Kiana Ehsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuran Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>",
          "description": "We propose Continuous Scene Representations (CSR), a scene representation\nconstructed by an embodied agent navigating within a space, where objects and\ntheir relationships are modeled by continuous valued embeddings. Our method\ncaptures feature relationships between objects, composes them into a graph\nstructure on-the-fly, and situates an embodied agent within the representation.\nOur key insight is to embed pair-wise relationships between objects in a latent\nspace. This allows for a richer representation compared to discrete relations\n(e.g., [support], [next-to]) commonly used for building scene representations.\nCSR can track objects as the agent moves in a scene, update the representation\naccordingly, and detect changes in room configurations. Using CSR, we\noutperform state-of-the-art approaches for the challenging downstream task of\nvisual room rearrangement, without any task specific training. Moreover, we\nshow the learned embeddings capture salient spatial details of the scene and\nshow applicability to real world data. A summery video and code is available at\nhttps://prior.allenai.org/projects/csr.",
          "link": "http://arxiv.org/abs/2203.17251",
          "publishedOn": "2022-04-02T00:47:20.084Z",
          "wordCount": null,
          "title": "Continuous Scene Representations for Embodied AI. (arXiv:2203.17251v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gulati_M/0/1/0/all/0/1\">Manoj Gulati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arjunan_P/0/1/0/all/0/1\">Pandarasamy Arjunan</a>",
          "description": "Modern buildings are densely equipped with smart energy meters, which\nperiodically generate a massive amount of time-series data yielding few million\ndata points every day. This data can be leveraged to discover the underlying\nloads, infer their energy consumption patterns, inter-dependencies on\nenvironmental factors, and the building's operational properties. Furthermore,\nit allows us to simultaneously identify anomalies present in the electricity\nconsumption profiles, which is a big step towards saving energy and achieving\nglobal sustainability. However, to date, the lack of large-scale annotated\nenergy consumption datasets hinders the ongoing research in anomaly detection.\nWe contribute to this effort by releasing a well-annotated version of a\npublicly available ASHRAE Great Energy Predictor III data set containing 1,413\nsmart electricity meter time series spanning over one year. In addition, we\nbenchmark the performance of eight state-of-the-art anomaly detection methods\non our dataset and compare their performance.",
          "link": "http://arxiv.org/abs/2203.17256",
          "publishedOn": "2022-04-02T00:47:20.082Z",
          "wordCount": null,
          "title": "LEAD1.0: A Large-scale Annotated Dataset for Energy Anomaly Detection in Commercial Buildings. (arXiv:2203.17256v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1\">Stephen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_R/0/1/0/all/0/1\">Roy Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1\">Mahdi Soltanolkotabi</a>",
          "description": "We initiate a study of supervised learning from many independent sequences\n(\"trajectories\") of non-independent covariates, reflecting tasks in sequence\nmodeling, control, and reinforcement learning. Conceptually, our\nmulti-trajectory setup sits between two traditional settings in statistical\nlearning theory: learning from independent examples and learning from a single\nauto-correlated sequence. Our conditions for efficient learning generalize the\nformer setting--trajectories must be non-degenerate in ways that extend\nstandard requirements for independent examples. They do not require that\ntrajectories be ergodic, long, nor strictly stable.\n\nFor linear least-squares regression, given $n$-dimensional examples produced\nby $m$ trajectories, each of length $T$, we observe a notable change in\nstatistical efficiency as the number of trajectories increases from a few\n(namely $m \\lesssim n$) to many (namely $m \\gtrsim n$). Specifically, we\nestablish that the worst-case error rate this problem is $\\Theta(n / m T)$\nwhenever $m \\gtrsim n$. Meanwhile, when $m \\lesssim n$, we establish a (sharp)\nlower bound of $\\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by\na simple, marginally unstable linear dynamical system. A key upshot is that, in\ndomains where trajectories regularly reset, the error rate eventually behaves\nas if all of the examples were independent altogether, drawn from their\nmarginals. As a corollary of our analysis, we also improve guarantees for the\nlinear system identification problem.",
          "link": "http://arxiv.org/abs/2203.17193",
          "publishedOn": "2022-04-02T00:47:20.077Z",
          "wordCount": null,
          "title": "Learning from many trajectories. (arXiv:2203.17193v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yen-Lun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanjun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chung-Che Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jyh-Shing Roger Jang</a>",
          "description": "The countermeasure (CM) model is developed to protect Automatic Speaker\nVerification (ASV) systems from spoof attacks and prevent resulting personal\ninformation leakage. Based on practicality and security considerations, the CM\nmodel is usually deployed on edge devices, which have more limited computing\nresources and storage space than cloud- based systems. This work proposes\ntraining strategies for a lightweight CM model for ASV, using generalized end-\nto-end (GE2E) pre-training and adversarial fine-tuning to improve performance,\nand applying knowledge distillation (KD) to reduce the size of the CM model. In\nthe evalua- tion phase of the ASVspoof 2021 Logical Access task, the\nlightweight ResNetSE model reaches min t-DCF 0.2695 and EER 3.54%. Compared to\nthe teacher model, the lightweight student model only uses 22.5% of parameters\nand 21.1% of multiply and accumulate operands of the teacher model.",
          "link": "http://arxiv.org/abs/2203.17031",
          "publishedOn": "2022-04-02T00:47:20.076Z",
          "wordCount": null,
          "title": "Training strategy for a lightweight countermeasure model for automatic speaker verification. (arXiv:2203.17031v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Izadi_M/0/1/0/all/0/1\">Maliheh Izadi</a>",
          "description": "Users use Issue Tracking Systems to keep track and manage issue reports in\ntheir repositories. An issue is a rich source of software information that\ncontains different reports including a problem, a request for new features, or\nmerely a question about the software product. As the number of these issues\nincreases, it becomes harder to manage them manually. Thus, automatic\napproaches are proposed to help facilitate the management of issue reports.\n\nThis paper describes CatIss, an automatic CATegorizer of ISSue reports which\nis built upon the Transformer-based pre-trained RoBERTa model. CatIss\nclassifies issue reports into three main categories of Bug reports,\nEnhancement/feature requests, and Questions. First, the datasets provided for\nthe NLBSE tool competition are cleaned and preprocessed. Then, the pre-trained\nRoBERTa model is fine-tuned on the preprocessed dataset. Evaluating CatIss on\nabout 80 thousand issue reports from GitHub, indicates that it performs very\nwell surpassing the competition baseline, TicketTagger, and achieving 87.2%\nF1-score (micro average). Additionally, as CatIss is trained on a wide set of\nrepositories, it is a generic prediction model, hence applicable for any unseen\nsoftware project or projects with little historical data. Scripts for cleaning\nthe datasets, training CatIss, and evaluating the model are publicly available.",
          "link": "http://arxiv.org/abs/2203.17196",
          "publishedOn": "2022-04-02T00:47:20.076Z",
          "wordCount": null,
          "title": "CatIss: An Intelligent Tool for Categorizing Issues Reports using Transformers. (arXiv:2203.17196v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dapeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ran He</a>",
          "description": "To ease the burden of labeling, unsupervised domain adaptation (UDA) aims to\ntransfer knowledge in previous and related labeled datasets (sources) to a new\nunlabeled dataset (target). Despite impressive progress, prior methods always\nneed to access the raw source data and develop data-dependent alignment\napproaches to recognize the target samples in a transductive learning manner,\nwhich may raise privacy concerns from source individuals. Several recent\nstudies resort to an alternative solution by exploiting the well-trained\nwhite-box model from the source domain, yet, it may still leak the raw data\nthrough generative adversarial learning. This paper studies a practical and\ninteresting setting for UDA, where only black-box source models (i.e., only\nnetwork predictions are available) are provided during adaptation in the target\ndomain. To solve this problem, we propose a new two-step knowledge adaptation\nframework called DIstill and fine-tuNE (DINE). Taking into consideration the\ntarget data structure, DINE first distills the knowledge from the source\npredictor to a customized target model, then fine-tunes the distilled model to\nfurther fit the target domain. Besides, neural networks are not required to be\nidentical across domains in DINE, even allowing effective adaptation on a\nlow-resource device. Empirical results on three UDA scenarios (i.e.,\nsingle-source, multi-source, and partial-set) confirm that DINE achieves highly\ncompetitive performance compared to state-of-the-art data-dependent approaches.\nCode is available at \\url{https://github.com/tim-learn/DINE/}.",
          "link": "http://arxiv.org/abs/2104.01539",
          "publishedOn": "2022-04-02T00:47:20.076Z",
          "wordCount": null,
          "title": "DINE: Domain Adaptation from Single and Multiple Black-box Predictors. (arXiv:2104.01539v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17128",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cohen_S/0/1/0/all/0/1\">Samuel N. Cohen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_D/0/1/0/all/0/1\">Deqing Jiang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sirignano_J/0/1/0/all/0/1\">Justin Sirignano</a>",
          "description": "Solving high-dimensional partial differential equations (PDEs) is a major\nchallenge in scientific computing. We develop a new numerical method for\nsolving elliptic-type PDEs by adapting the Q-learning algorithm in\nreinforcement learning. Our \"Q-PDE\" algorithm is mesh-free and therefore has\nthe potential to overcome the curse of dimensionality. Using a neural tangent\nkernel (NTK) approach, we prove that the neural network approximator for the\nPDE solution, trained with the Q-PDE algorithm, converges to the trajectory of\nan infinite-dimensional ordinary differential equation (ODE) as the number of\nhidden units $\\rightarrow \\infty$. For monotone PDE (i.e. those given by\nmonotone operators, which may be nonlinear), despite the lack of a spectral gap\nin the NTK, we then prove that the limit neural network, which satisfies the\ninfinite-dimensional ODE, converges in $L^2$ to the PDE solution as the\ntraining time $\\rightarrow \\infty$. More generally, we can prove that any fixed\npoint of the wide-network limit for the Q-PDE algorithm is a solution of the\nPDE (not necessarily under the monotone condition). The numerical performance\nof the Q-PDE algorithm is studied for several elliptic PDEs.",
          "link": "http://arxiv.org/abs/2203.17128",
          "publishedOn": "2022-04-02T00:47:20.075Z",
          "wordCount": null,
          "title": "Neural Q-learning for solving elliptic PDEs. (arXiv:2203.17128v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weizhi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingrui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiyu Li</a>",
          "description": "Dimension reduction and data quantization are two important methods for\nreducing data complexity. In the paper, we study the methodology of first\nreducing data dimension by random projection and then quantizing the\nprojections to ternary or binary codes, which has been widely applied in\nclassification. Usually, the quantization will seriously degrade the accuracy\nof classification due to high quantization errors. Interestingly, however, we\nobserve that the quantization could provide comparable and often superior\naccuracy, as the data to be quantized are sparse features generated with common\nfilters. Furthermore, this quantization property could be maintained in the\nrandom projections of sparse features, if both the features and random\nprojection matrices are sufficiently sparse. By conducting extensive\nexperiments, we validate and analyze this intriguing property.",
          "link": "http://arxiv.org/abs/2203.16798",
          "publishedOn": "2022-04-02T00:47:20.074Z",
          "wordCount": null,
          "title": "Ternary and Binary Quantization for Improved Classification. (arXiv:2203.16798v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hardt_M/0/1/0/all/0/1\">Moritz Hardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagadeesan_M/0/1/0/all/0/1\">Meena Jagadeesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendler_Dunner_C/0/1/0/all/0/1\">Celestine Mendler-D&#xfc;nner</a>",
          "description": "We introduce the notion of performative power, which measures the ability of\na firm operating an algorithmic system, such as a digital content\nrecommendation platform, to steer a population. We relate performative power to\nthe economic theory of market power. Traditional economic concepts are well\nknown to struggle with identifying anti-competitive patterns in digital\nplatforms--a core challenge is the difficulty of defining the market, its\nparticipants, products, and prices. Performative power sidesteps the problem of\nmarket definition by focusing on a directly observable statistical measure\ninstead. High performative power enables a platform to profit from steering\nparticipant behavior, whereas low performative power ensures that learning from\nhistorical data is close to optimal.\n\nOur first general result shows that under low performative power, a firm\ncannot do better than standard supervised learning on observed data. We draw an\nanalogy with a firm being a price-taker, an economic condition that arises\nunder perfect competition in classical market models. We then contrast this\nwith a market where performative power is concentrated and show that the\nequilibrium state can differ significantly. We go on to study performative\npower in a concrete setting of strategic classification where participants can\nswitch between competing firms. We show that monopolies maximize performative\npower and disutility for the participant, while competition and outside options\ndecrease performative power. We end on a discussion of connections to measures\nof market power in economics and of the relationship with ongoing antitrust\ndebates.",
          "link": "http://arxiv.org/abs/2203.17232",
          "publishedOn": "2022-04-02T00:47:20.074Z",
          "wordCount": null,
          "title": "Performative Power. (arXiv:2203.17232v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16582",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Biwei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magliacane_S/0/1/0/all/0/1\">Sara Magliacane</a>",
          "description": "Dealing with non-stationarity in environments (i.e., transition dynamics) and\nobjectives (i.e., reward functions) is a challenging problem that is crucial in\nreal-world applications of reinforcement learning (RL). Most existing\napproaches only focus on families of stationary MDPs, in which the\nnon-stationarity is episodic, i.e., the change is only possible across\nepisodes. The few works that do consider non-stationarity without a specific\nboundary, i.e., also allow for changes within an episode, model the changes\nmonolithically in a single shared embedding vector. In this paper, we propose\nFactored Adaptation for Non-Stationary RL (FANS-RL), a factored adaption\napproach that explicitly learns the individual latent change factors affecting\nthe transition dynamics and reward functions. FANS-RL learns jointly the\nstructure of a factored MDP and a factored representation of the time-varying\nchange factors, as well as the specific state components that they affect, via\na factored non-stationary variational autoencoder. Through this general\nframework, we can consider general non-stationary scenarios with different\nchanging function types and changing frequency. Experimental results\ndemonstrate that FANS-RL outperforms existing approaches in terms of rewards,\ncompactness of the latent state representation and robustness to varying\ndegrees of non-stationarity.",
          "link": "http://arxiv.org/abs/2203.16582",
          "publishedOn": "2022-04-02T00:47:20.073Z",
          "wordCount": null,
          "title": "Factored Adaptation for Non-Stationary Reinforcement Learning. (arXiv:2203.16582v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1\">James Seale Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Junjiao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1\">Yen-Chang Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1\">Zsolt Kira</a>",
          "description": "Continual learning describes a setting where machine learning models learn\nnovel concepts from continuously shifting training data, while simultaneously\navoiding degradation of knowledge on previously seen classes (a phenomenon\nknown as the catastrophic forgetting problem) which may disappear from the\ntraining data for extended periods of time. Current approaches for continual\nlearning of a single expanding task (aka class-incremental continual learning)\nrequire extensive rehearsal of previously seen data to avoid this degradation\nof knowledge. Unfortunately, rehearsal comes at a sharp cost to memory and\ncomputation, and it may also violate data-privacy. Instead, we explore\ncombining knowledge distillation and parameter regularization in new ways to\nachieve strong continual learning performance without rehearsal. Specifically,\nwe take a deep dive into common continual learning techniques: prediction\ndistillation, feature distillation, L2 parameter regularization, and EWC\nparameter regularization. We first disprove the common assumption that\nparameter regularization techniques fail for rehearsal-free continual learning\nof a single, expanding task. Next, we explore how to leverage knowledge from a\npre-trained model in rehearsal-free continual learning and find that vanilla L2\nparameter regularization outperforms EWC parameter regularization and feature\ndistillation. We then highlight the impact of the rehearsal-free continual\nlearning settings with a classifier expansion benchmark, showing that a\nstrategy based on our findings combined with a positive/negative label\nbalancing heuristic can close the performance gap between the upper bound and\nthe existing strategies by up to roughly 50%. Finally, we show that a simple\nmethod consisting of pre-training, L2 regularization, and prediction\ndistillation can even outperform rehearsal-based methods on the common\nCIFAR-100 benchmark.",
          "link": "http://arxiv.org/abs/2203.17269",
          "publishedOn": "2022-04-02T00:47:20.070Z",
          "wordCount": null,
          "title": "A Closer Look at Rehearsal-Free Continual Learning. (arXiv:2203.17269v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Organisciak_D/0/1/0/all/0/1\">Daniel Organisciak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Hubert P. H. Shum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nwoye_E/0/1/0/all/0/1\">Ephraim Nwoye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>",
          "description": "Schizophrenia is a severe mental health condition that requires a long and\ncomplicated diagnostic process. However, early diagnosis is vital to control\nsymptoms. Deep learning has recently become a popular way to analyse and\ninterpret medical data. Past attempts to use deep learning for schizophrenia\ndiagnosis from brain-imaging data have shown promise but suffer from a large\ntraining-application gap - it is difficult to apply lab research to the real\nworld. We propose to reduce this training-application gap by focusing on\nreadily accessible data. We collect a data set of psychiatric observations of\npatients based on DSM-5 criteria. Because similar data is already recorded in\nall mental health clinics that diagnose schizophrenia using DSM-5, our method\ncould be easily integrated into current processes as a tool to assist\nclinicians, whilst abiding by formal diagnostic criteria. To facilitate\nreal-world usage of our system, we show that it is interpretable and robust.\nUnderstanding how a machine learning tool reaches its diagnosis is essential to\nallow clinicians to trust that diagnosis. To interpret the framework, we fuse\ntwo complementary attention mechanisms, 'squeeze and excitation' and\n'self-attention', to determine global attribute importance and attribute\ninteractivity, respectively. The model uses these importance scores to make\ndecisions. This allows clinicians to understand how a diagnosis was reached,\nimproving trust in the model. Because machine learning models often struggle to\ngeneralise to data from different sources, we perform experiments with\naugmented test data to evaluate the model's applicability to the real world. We\nfind that our model is more robust to perturbations, and should therefore\nperform better in a clinical setting. It achieves 98% accuracy with 10-fold\ncross-validation.",
          "link": "http://arxiv.org/abs/2203.17085",
          "publishedOn": "2022-04-02T00:47:20.069Z",
          "wordCount": null,
          "title": "RobIn: A Robust Interpretable Deep Network for Schizophrenia Diagnosis. (arXiv:2203.17085v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17066",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hazra_S/0/1/0/all/0/1\">Souvik Hazra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_H/0/1/0/all/0/1\">Hao Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiprit_G/0/1/0/all/0/1\">Gamze Naz Kiprit</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stephan_M/0/1/0/all/0/1\">Michael Stephan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Servadei_L/0/1/0/all/0/1\">Lorenzo Servadei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wille_R/0/1/0/all/0/1\">Robert Wille</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Weigel_R/0/1/0/all/0/1\">Robert Weigel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Santra_A/0/1/0/all/0/1\">Avik Santra</a>",
          "description": "Gesture recognition is one of the most intuitive ways of interaction and has\ngathered particular attention for human computer interaction. Radar sensors\npossess multiple intrinsic properties, such as their ability to work in low\nillumination, harsh weather conditions, and being low-cost and compact, making\nthem highly preferable for a gesture recognition solution. However, most\nliterature work focuses on solutions with a limited range that is lower than a\nmeter. We propose a novel architecture for a long-range (1m - 2m) gesture\nrecognition solution that leverages a point cloud-based cross-learning approach\nfrom camera point cloud to 60-GHz FMCW radar point cloud, which allows learning\nbetter representations while suppressing noise. We use a variant of Dynamic\nGraph CNN (DGCNN) for the cross-learning, enabling us to model relationships\nbetween the points at a local and global level and to model the temporal\ndynamics a Bi-LSTM network is employed. In the experimental results section, we\ndemonstrate our model's overall accuracy of 98.4% for five gestures and its\ngeneralization capability.",
          "link": "http://arxiv.org/abs/2203.17066",
          "publishedOn": "2022-04-02T00:47:20.067Z",
          "wordCount": null,
          "title": "Cross-modal Learning of Graph Representations using Radar Point Cloud for Long-Range Gesture Recognition. (arXiv:2203.17066v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prasad_L/0/1/0/all/0/1\">Lodagala V S V Durga Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sreyan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umesh_S/0/1/0/all/0/1\">S. Umesh</a>",
          "description": "While self-supervised speech representation learning (SSL) models serve a\nvariety of downstream tasks, these models have been observed to overfit to the\ndomain from which the unlabelled data originates. To alleviate this issue, we\npropose PADA (Pruning Assisted Domain Adaptation) and zero out redundant\nweights from models pre-trained on large amounts of out-of-domain (OOD) data.\nIntuitively, this helps to make space for the target-domain ASR finetuning. The\nredundant weights can be identified through various pruning strategies which\nhave been discussed in detail as a part of this work. Specifically, we\ninvestigate the effect of the recently discovered Task-Agnostic and Task-Aware\npruning on PADA and propose a new pruning paradigm based on the latter, which\nwe call Cross-Domain Task-Aware Pruning (CD-TAW). CD-TAW obtains the initial\npruning mask from a well fine-tuned OOD model, which makes it starkly different\nfrom the rest of the pruning strategies discussed in the paper. Our proposed\nCD-TAW methodology achieves up to 20.6% relative WER improvement over our\nbaseline when fine-tuned on a 2-hour subset of Switchboard data without\nlanguage model (LM) decoding. Furthermore, we conduct a detailed analysis to\nhighlight the key design choices of our proposed method.",
          "link": "http://arxiv.org/abs/2203.16965",
          "publishedOn": "2022-04-02T00:47:20.064Z",
          "wordCount": null,
          "title": "PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations. (arXiv:2203.16965v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Landverk_M/0/1/0/all/0/1\">Marius C. Landverk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riemer_Sorensen_S/0/1/0/all/0/1\">Signe Riemer-S&#xf8;rensen</a>",
          "description": "Measuring model performance is a key issue for deep learning practitioners.\nHowever, we often lack the ability to explain why a specific architecture\nattains superior predictive accuracy for a given data set. Often, validation\naccuracy is used as a performance heuristic quantifying how well a network\ngeneralizes to unseen data, but it does not capture anything about the\ninformation flow in the model. Mutual information can be used as a measure of\nthe quality of internal representations in deep learning models, and the\ninformation plane may provide insights into whether the model exploits the\navailable information in the data. The information plane has previously been\nexplored for fully connected neural networks and convolutional architectures.\nWe present an architecture-agnostic method for tracking a network's internal\nrepresentations during training, which are then used to create the mutual\ninformation plane. The method is exemplified for graph-based neural networks\nfitted on citation data. We compare how the inductive bias introduced in\ngraph-based architectures changes the mutual information plane relative to a\nfully connected neural network.",
          "link": "http://arxiv.org/abs/2203.16887",
          "publishedOn": "2022-04-02T00:47:20.019Z",
          "wordCount": null,
          "title": "Mutual information estimation for graph convolutional neural networks. (arXiv:2203.16887v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1\">Harrie Oosterhuis</a>",
          "description": "Clicks on rankings suffer from position bias: generally items on lower ranks\nare less likely to be examined - and thus clicked - by users, in spite of their\nactual preferences between items. The prevalent approach to unbiased\nclick-based Learning-to-Rank (LTR) is based on counterfactual\nInverse-Propensity-Scoring (IPS) estimation. Unique about LTR is the fact that\nstandard Doubly-Robust (DR) estimation - which combines IPS with regression\npredictions - is inapplicable since the treatment variable - indicating whether\na user examined an item - cannot be observed in the data. In this paper, we\nintroduce a novel DR estimator that uses the expectation of treatment per rank\ninstead. Our novel DR estimator has more robust unbiasedness conditions than\nthe existing IPS approach, and in addition, provides enormous decreases in\nvariance: our experimental results indicate it requires several orders of\nmagnitude fewer datapoints to converge at optimal performance. For the unbiased\nLTR field, our DR estimator contributes both increases in state-of-the-art\nperformance and the most robust theoretical guarantees of all known LTR\nestimators.",
          "link": "http://arxiv.org/abs/2203.17118",
          "publishedOn": "2022-04-02T00:47:20.019Z",
          "wordCount": null,
          "title": "Doubly-Robust Estimation for Unbiased Learning-to-Rank from Position-Biased Click Feedback. (arXiv:2203.17118v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Heming Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>",
          "description": "In this paper, we propose Generalized Aggressive Decoding (GAD) -- a novel\napproach to accelerating autoregressive translation with no quality loss,\nthrough the collaboration of autoregressive and non-autoregressive translation\n(NAT) of the Transformer. At each decoding iteration, GAD aggressively decodes\na number of tokens in parallel as a draft through NAT and then verifies them in\nthe autoregressive manner, where only the tokens that pass the verification are\nkept as decoded tokens. GAD can achieve the same performance as autoregressive\ntranslation but much more efficiently because both NAT drafting and\nautoregressive verification are fast due to parallel computing. We conduct\nexperiments in the WMT14 English-German translation task and confirm that the\nvanilla GAD yields exactly the same results as greedy decoding with an around\n3x speedup, and that its variant (GAD++) with an advanced verification strategy\nnot only outperforms the greedy translation and even achieves the comparable\ntranslation quality with the beam search result, but also further improves the\ndecoding speed, resulting in an around 5x speedup over autoregressive\ntranslation. Our models and codes are available at\nhttps://github.com/hemingkx/Generalized-Aggressive-Decoding.",
          "link": "http://arxiv.org/abs/2203.16487",
          "publishedOn": "2022-04-02T00:47:20.019Z",
          "wordCount": null,
          "title": "Lossless Speedup of Autoregressive Translation with Generalized Aggressive Decoding. (arXiv:2203.16487v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hyung Won Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levskaya_A/0/1/0/all/0/1\">Anselm Levskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_G/0/1/0/all/0/1\">Gaurav Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradbury_J/0/1/0/all/0/1\">James Bradbury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andor_D/0/1/0/all/0/1\">Daniel Andor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1\">Sharan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lester_B/0/1/0/all/0/1\">Brian Lester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffney_C/0/1/0/all/0/1\">Colin Gaffney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohiuddin_A/0/1/0/all/0/1\">Afroz Mohiuddin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawthorne_C/0/1/0/all/0/1\">Curtis Hawthorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewkowycz_A/0/1/0/all/0/1\">Aitor Lewkowycz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salcianu_A/0/1/0/all/0/1\">Alex Salcianu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zee_M/0/1/0/all/0/1\">Marc van Zee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1\">Jacob Austin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Sebastian Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soares_L/0/1/0/all/0/1\">Livio Baldini Soares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Haitang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvyashchenko_S/0/1/0/all/0/1\">Sasha Tsvyashchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1\">Aakanksha Chowdhery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastings_J/0/1/0/all/0/1\">Jasmijn Bastings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulian_J/0/1/0/all/0/1\">Jannis Bulian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_X/0/1/0/all/0/1\">Xavier Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Andrew Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenealy_K/0/1/0/all/0/1\">Kathleen Kenealy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jonathan H. Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stephan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrette_D/0/1/0/all/0/1\">Dan Garrette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Thorp_J/0/1/0/all/0/1\">James Lee-Thorp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shazeer_N/0/1/0/all/0/1\">Noam Shazeer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_M/0/1/0/all/0/1\">Marvin Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosma_M/0/1/0/all/0/1\">Maarten Bosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passos_A/0/1/0/all/0/1\">Alexandre Passos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maitin_Shepard_J/0/1/0/all/0/1\">Jeremy Maitin-Shepard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fiedel_N/0/1/0/all/0/1\">Noah Fiedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omernick_M/0/1/0/all/0/1\">Mark Omernick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saeta_B/0/1/0/all/0/1\">Brennan Saeta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sepassi_R/0/1/0/all/0/1\">Ryan Sepassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiridonov_A/0/1/0/all/0/1\">Alexander Spiridonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newlan_J/0/1/0/all/0/1\">Joshua Newlan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gesmundo_A/0/1/0/all/0/1\">Andrea Gesmundo</a>",
          "description": "Recent neural network-based language models have benefited greatly from\nscaling up the size of training datasets and the number of parameters in the\nmodels themselves. Scaling can be complicated due to various factors including\nthe need to distribute computation on supercomputer clusters (e.g., TPUs),\nprevent bottlenecks when infeeding data, and ensure reproducible results. In\nthis work, we present two software libraries that ease these issues:\n$\\texttt{t5x}$ simplifies the process of building and training large language\nmodels at scale while maintaining ease of use, and $\\texttt{seqio}$ provides a\ntask-based API for simple creation of fast and reproducible training data and\nevaluation pipelines. These open-source libraries have been used to train\nmodels with hundreds of billions of parameters on datasets with multiple\nterabytes of training data.\n\nAlong with the libraries, we release configurations and instructions for\nT5-like encoder-decoder models as well as GPT-like decoder-only architectures.\n\n$\\texttt{t5x}$ and $\\texttt{seqio}$ are open source and available at\nhttps://github.com/google-research/t5x and https://github.com/google/seqio,\nrespectively.",
          "link": "http://arxiv.org/abs/2203.17189",
          "publishedOn": "2022-04-02T00:47:20.018Z",
          "wordCount": null,
          "title": "Scaling Up Models and Data with $\\texttt{t5x}$ and $\\texttt{seqio}$. (arXiv:2203.17189v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ao_J/0/1/0/all/0/1\">Junyi Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Long Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Tom Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_L/0/1/0/all/0/1\">Lirong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "This paper studies a novel pre-training technique with unpaired speech data,\nSpeech2C, for encoder-decoder based automatic speech recognition (ASR). Within\na multi-task learning framework, we introduce two pre-training tasks for the\nencoder-decoder network using acoustic units, i.e., pseudo codes, derived from\nan offline clustering model. One is to predict the pseudo codes via masked\nlanguage modeling in encoder output, like HuBERT model, while the other lets\nthe decoder learn to reconstruct pseudo codes autoregressively instead of\ngenerating textual scripts. In this way, the decoder learns to reconstruct\noriginal speech information with codes before learning to generate correct\ntext. Comprehensive experiments on the LibriSpeech corpus show that the\nproposed Speech2C can relatively reduce the word error rate (WER) by 19.2% over\nthe method without decoder pre-training, and also outperforms significantly the\nstate-of-the-art wav2vec 2.0 and HuBERT on fine-tuning subsets of 10h and 100h.",
          "link": "http://arxiv.org/abs/2203.17113",
          "publishedOn": "2022-04-02T00:47:20.004Z",
          "wordCount": null,
          "title": "Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data. (arXiv:2203.17113v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17138",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bohez_S/0/1/0/all/0/1\">Steven Bohez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tunyasuvunakool_S/0/1/0/all/0/1\">Saran Tunyasuvunakool</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brakel_P/0/1/0/all/0/1\">Philemon Brakel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_F/0/1/0/all/0/1\">Fereshteh Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasenclever_L/0/1/0/all/0/1\">Leonard Hasenclever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tassa_Y/0/1/0/all/0/1\">Yuval Tassa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisotto_E/0/1/0/all/0/1\">Emilio Parisotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Humplik_J/0/1/0/all/0/1\">Jan Humplik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haarnoja_T/0/1/0/all/0/1\">Tuomas Haarnoja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafner_R/0/1/0/all/0/1\">Roland Hafner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulfmeier_M/0/1/0/all/0/1\">Markus Wulfmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neunert_M/0/1/0/all/0/1\">Michael Neunert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_B/0/1/0/all/0/1\">Ben Moran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegel_N/0/1/0/all/0/1\">Noah Siegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huber_A/0/1/0/all/0/1\">Andrea Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romano_F/0/1/0/all/0/1\">Francesco Romano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batchelor_N/0/1/0/all/0/1\">Nathan Batchelor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casarini_F/0/1/0/all/0/1\">Federico Casarini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merel_J/0/1/0/all/0/1\">Josh Merel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadsell_R/0/1/0/all/0/1\">Raia Hadsell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>",
          "description": "We investigate the use of prior knowledge of human and animal movement to\nlearn reusable locomotion skills for real legged robots. Our approach builds\nupon previous work on imitating human or dog Motion Capture (MoCap) data to\nlearn a movement skill module. Once learned, this skill module can be reused\nfor complex downstream tasks. Importantly, due to the prior imposed by the\nMoCap data, our approach does not require extensive reward engineering to\nproduce sensible and natural looking behavior at the time of reuse. This makes\nit easy to create well-regularized, task-oriented controllers that are suitable\nfor deployment on real robots. We demonstrate how our skill module can be used\nfor imitation, and train controllable walking and ball dribbling policies for\nboth the ANYmal quadruped and OP3 humanoid. These policies are then deployed on\nhardware via zero-shot simulation-to-reality transfer. Accompanying videos are\navailable at https://bit.ly/robot-npmp.",
          "link": "http://arxiv.org/abs/2203.17138",
          "publishedOn": "2022-04-02T00:47:20.004Z",
          "wordCount": null,
          "title": "Imitate and Repurpose: Learning Reusable Robot Movement Skills From Human and Animal Behaviors. (arXiv:2203.17138v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17089",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Nikoloska_I/0/1/0/all/0/1\">Ivana Nikoloska</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Simeone_O/0/1/0/all/0/1\">Osvaldo Simeone</a>",
          "description": "Near-term noisy intermediate-scale quantum circuits can efficiently implement\nimplicit probabilistic models in discrete spaces, supporting distributions that\nare practically infeasible to sample from using classical means. One of the\npossible applications of such models, also known as Born machines, is\nprobabilistic inference, which is at the core of Bayesian methods. This paper\nstudies the use of Born machines for the problem of training binary Bayesian\nneural networks. In the proposed approach, a Born machine is used to model the\nvariational distribution of the binary weights of the neural network, and data\nfrom multiple tasks is used to reduce training data requirements on new tasks.\nThe method combines gradient-based meta-learning and variational inference via\nBorn machines, and is shown in a prototypical regression problem to outperform\nconventional joint learning strategies.",
          "link": "http://arxiv.org/abs/2203.17089",
          "publishedOn": "2022-04-02T00:47:20.003Z",
          "wordCount": null,
          "title": "Quantum-Aided Meta-Learning for Bayesian Binary Neural Networks via Born Machines. (arXiv:2203.17089v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17070",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eichenberger_C/0/1/0/all/0/1\">Christian Eichenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neun_M/0/1/0/all/0/1\">Moritz Neun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_H/0/1/0/all/0/1\">Henry Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herruzo_P/0/1/0/all/0/1\">Pedro Herruzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spanring_M/0/1/0/all/0/1\">Markus Spanring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yichao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Sungbin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konyakhin_V/0/1/0/all/0/1\">Vsevolod Konyakhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukashina_N/0/1/0/all/0/1\">Nina Lukashina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shpilman_A/0/1/0/all/0/1\">Aleksei Shpilman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiedemann_N/0/1/0/all/0/1\">Nina Wiedemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raubal_M/0/1/0/all/0/1\">Martin Raubal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_H/0/1/0/all/0/1\">Hai L. Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohajerpoor_R/0/1/0/all/0/1\">Reza Mohajerpoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1\">Chen Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Inhi Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hermes_L/0/1/0/all/0/1\">Luca Hermes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnik_A/0/1/0/all/0/1\">Andrew Melnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velioglu_R/0/1/0/all/0/1\">Riza Velioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieth_M/0/1/0/all/0/1\">Markus Vieth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schilling_M/0/1/0/all/0/1\">Malte Schilling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojesomo_A/0/1/0/all/0/1\">Alabi Bojesomo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzouqi_H/0/1/0/all/0/1\">Hasan Al Marzouqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liatsis_P/0/1/0/all/0/1\">Panos Liatsis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santokhi_J/0/1/0/all/0/1\">Jay Santokhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hillier_D/0/1/0/all/0/1\">Dylan Hillier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yiming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarwar_J/0/1/0/all/0/1\">Joned Sarwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_A/0/1/0/all/0/1\">Anna Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewage_E/0/1/0/all/0/1\">Emil Hewage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonietz_D/0/1/0/all/0/1\">David Jonietz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1\">Fei Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruca_A/0/1/0/all/0/1\">Aleksandra Gruca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopp_M/0/1/0/all/0/1\">Michael Kopp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreil_D/0/1/0/all/0/1\">David Kreil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>",
          "description": "The IARAI Traffic4cast competitions at NeurIPS 2019 and 2020 showed that\nneural networks can successfully predict future traffic conditions 1 hour into\nthe future on simply aggregated GPS probe data in time and space bins. We thus\nreinterpreted the challenge of forecasting traffic conditions as a movie\ncompletion task. U-Nets proved to be the winning architecture, demonstrating an\nability to extract relevant features in this complex real-world geo-spatial\nprocess. Building on the previous competitions, Traffic4cast 2021 now focuses\non the question of model robustness and generalizability across time and space.\nMoving from one city to an entirely different city, or moving from pre-COVID\ntimes to times after COVID hit the world thus introduces a clear domain shift.\nWe thus, for the first time, release data featuring such domain shifts. The\ncompetition now covers ten cities over 2 years, providing data compiled from\nover 10^12 GPS probe data. Winning solutions captured traffic dynamics\nsufficiently well to even cope with these complex domain shifts. Surprisingly,\nthis seemed to require only the previous 1h traffic dynamic history and static\nroad graph as input.",
          "link": "http://arxiv.org/abs/2203.17070",
          "publishedOn": "2022-04-02T00:47:20.002Z",
          "wordCount": null,
          "title": "Traffic4cast at NeurIPS 2021 - Temporal and Spatial Few-Shot Transfer Learning in Gridded Geo-Spatial Processes. (arXiv:2203.17070v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17001",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_S/0/1/0/all/0/1\">Shuai Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_J/0/1/0/all/0/1\">Jiatong Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qian_T/0/1/0/all/0/1\">Tao Qian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_Q/0/1/0/all/0/1\">Qin Jin</a>",
          "description": "Deep learning based singing voice synthesis (SVS) systems have been\ndemonstrated to flexibly generate singing with better qualities, compared to\nconventional statistical parametric based methods. However, neural systems are\ngenerally data-hungry and have difficulty to reach reasonable singing quality\nwith limited public available training data. In this work, we explore different\ndata augmentation methods to boost the training of SVS systems, including\nseveral strategies customized to SVS based on pitch augmentation and mix-up\naugmentation. To further stabilize the training, we introduce the\ncycle-consistent training strategy. Extensive experiments on two public singing\ndatabases demonstrate that our proposed augmentation methods and the\nstabilizing training strategy can significantly improve the performance on both\nobjective and subjective evaluations.",
          "link": "http://arxiv.org/abs/2203.17001",
          "publishedOn": "2022-04-02T00:47:20.000Z",
          "wordCount": null,
          "title": "SingAug: Data Augmentation for Singing Voice Synthesis with Cycle-consistent Training Strategy. (arXiv:2203.17001v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siuzdak_H/0/1/0/all/0/1\">Hubert Siuzdak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dura_P/0/1/0/all/0/1\">Piotr Dura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijn_P/0/1/0/all/0/1\">Pol van Rijn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacoby_N/0/1/0/all/0/1\">Nori Jacoby</a>",
          "description": "Recent advances in neural text-to-speech research have been dominated by\ntwo-stage pipelines utilizing low-level intermediate speech representation such\nas mel-spectrograms. However, such predetermined features are fundamentally\nlimited, because they do not allow to exploit the full potential of a\ndata-driven approach through learning hidden representations. For this reason,\nseveral end-to-end methods have been proposed. However, such models are harder\nto train and require a large number of high-quality recordings with\ntranscriptions. Here, we propose WavThruVec - a two-stage architecture that\nresolves the bottleneck by using high-dimensional Wav2Vec 2.0 embeddings as\nintermediate speech representation. Since these hidden activations provide\nhigh-level linguistic features, they are more robust to noise. That allows us\nto utilize annotated speech datasets of a lower quality to train the\nfirst-stage module. At the same time, the second-stage component can be trained\non large-scale untranscribed audio corpora, as Wav2Vec 2.0 embeddings are\ntime-aligned and speaker-independent. This results in an increased\ngeneralization capability to out-of-vocabulary words, as well as to a better\ngeneralization to unseen speakers. We show that the proposed model not only\nmatches the quality of state-of-the-art neural models, but also presents useful\nproperties enabling tasks like voice conversion or zero-shot synthesis.",
          "link": "http://arxiv.org/abs/2203.16930",
          "publishedOn": "2022-04-02T00:47:19.999Z",
          "wordCount": null,
          "title": "WavThruVec: Latent speech representation as intermediate features for neural speech synthesis. (arXiv:2203.16930v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yiran Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_P/0/1/0/all/0/1\">Pratyay Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_T/0/1/0/all/0/1\">Tejas Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yezhou Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>",
          "description": "We present a debiased dataset for the Person-centric Visual Grounding (PCVG)\ntask first proposed by Cui et al. (2021) in the Who's Waldo dataset. Given an\nimage and a caption, PCVG requires pairing up a person's name mentioned in a\ncaption with a bounding box that points to the person in the image. We find\nthat the original Who's Waldo dataset compiled for this task contains a large\nnumber of biased samples that are solvable simply by heuristic methods; for\ninstance, in many cases the first name in the sentence corresponds to the\nlargest bounding box, or the sequence of names in the sentence corresponds to\nan exact left-to-right order in the image. Naturally, models trained on these\nbiased data lead to over-estimation of performance on the benchmark. To enforce\nmodels being correct for the correct reasons, we design automated tools to\nfilter and debias the original dataset by ruling out all examples of\ninsufficient context, such as those with no verb or with a long chain of\nconjunct names in their captions. Our experiments show that our new sub-sampled\ndataset contains less bias with much lowered heuristic performances and widened\ngaps between heuristic and supervised methods. We also demonstrate the same\nbenchmark model trained on our debiased training set outperforms that trained\non the original biased (and larger) training set on our debiased test set. We\nargue our debiased dataset offers the PCVG task a more practical baseline for\nreliable benchmarking and future improvements.",
          "link": "http://arxiv.org/abs/2203.16682",
          "publishedOn": "2022-04-02T00:47:19.996Z",
          "wordCount": null,
          "title": "To Find Waldo You Need Contextual Cues: Debiasing Who's Waldo. (arXiv:2203.16682v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mehra_S/0/1/0/all/0/1\">Srishti Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louka_R/0/1/0/all/0/1\">Robert Louka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixun Zhang</a>",
          "description": "Environmental, Social, and Governance (ESG) are non-financial factors that\nare garnering attention from investors as they increasingly look to apply these\nas part of their analysis to identify material risks and growth opportunities.\nSome of this attention is also driven by clients who, now more aware than ever,\nare demanding for their money to be managed and invested responsibly. As the\ninterest in ESG grows, so does the need for investors to have access to\nconsumable ESG information. Since most of it is in text form in reports,\ndisclosures, press releases, and 10-Q filings, we see a need for sophisticated\nNLP techniques for classification tasks for ESG text. We hypothesize that an\nESG domain-specific pre-trained model will help with such and study building of\nthe same in this paper. We explored doing this by fine-tuning BERTs pre-trained\nweights using ESG specific text and then further fine-tuning the model for a\nclassification task. We were able to achieve accuracy better than the original\nBERT and baseline models in environment-specific classification tasks.",
          "link": "http://arxiv.org/abs/2203.16788",
          "publishedOn": "2022-04-02T00:47:19.995Z",
          "wordCount": null,
          "title": "ESGBERT: Language Model to Help with Classification Tasks Related to Companies Environmental, Social, and Governance Practices. (arXiv:2203.16788v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujita_O/0/1/0/all/0/1\">Osamu Fujita</a>",
          "description": "This paper investigates probability density functions (PDFs) that are\ncontinuous everywhere, nearly uniform around the mode of distribution, and\nadaptable to a variety of distribution shapes ranging from bell-shaped to\nrectangular. From the viewpoint of computational tractability, the PDF based on\nthe Fermi-Dirac or logistic function is advantageous in estimating its shape\nparameters. The most appropriate PDF for $n$-variate distribution is of the\nform:\n$p\\left(\\mathbf{x}\\right)\\propto\\left[\\cosh\\left(\\left[\\left(\\mathbf{x}-\\mathbf{m}\\right)^{\\mathsf{T}}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{x}-\\mathbf{m}\\right)\\right]^{n/2}\\right)+\\cosh\\left(r^{n}\\right)\\right]^{-1}$\nwhere $\\mathbf{x},\\mathbf{m}\\in\\mathbb{R}^{n}$, $\\boldsymbol{\\Sigma}$ is an\n$n\\times n$ positive definite matrix, and $r>0$ is a shape parameter. The\nflat-topped PDFs can be used as a component of mixture models in machine\nlearning to improve goodness of fit and make a model as simple as possible.",
          "link": "http://arxiv.org/abs/2203.17027",
          "publishedOn": "2022-04-02T00:47:19.988Z",
          "wordCount": null,
          "title": "Flat-topped Probability Density Functions for Mixture Models. (arXiv:2203.17027v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Swalpa Kumar Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deria_A/0/1/0/all/0/1\">Ankur Deria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Danfeng Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasti_B/0/1/0/all/0/1\">Behnood Rasti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaza_A/0/1/0/all/0/1\">Antonio Plaza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1\">Jocelyn Chanussot</a>",
          "description": "Vision transformer (ViT) has been trending in image classification tasks due\nto its promising performance when compared to convolutional neural networks\n(CNNs). As a result, many researchers have tried to incorporate ViT models in\nhyperspectral image (HSI) classification tasks, but without achieving\nsatisfactory performance. To this paper, we introduce a new multimodal fusion\ntransformer (MFT) network for HSI land-cover classification, which utilizes\nother sources of multimodal data in addition to HSI. Instead of using\nconventional feature fusion techniques, other multimodal data are used as an\nexternal classification (CLS) token in the transformer encoder, which helps\nachieving better generalization. ViT and other similar transformer models use a\nrandomly initialized external classification token {and fail to generalize\nwell}. However, the use of a feature embedding derived from other sources of\nmultimodal data, such as light detection and ranging (LiDAR), offers the\npotential to improve those models by means of a CLS. The concept of\ntokenization is used in our work to generate CLS and HSI patch tokens, helping\nto learn key features in a reduced feature space. We also introduce a new\nattention mechanism for improving the exchange of information between HSI\ntokens and the CLS (e.g., LiDAR) token. Extensive experiments are carried out\non widely used and benchmark datasets i.e., the University of Houston, Trento,\nUniversity of Southern Mississippi Gulfpark (MUUFL), and Augsburg. In the\nresults section, we compare the proposed MFT model with other state-of-the-art\ntransformer models, classical CNN models, as well as conventional classifiers.\nThe superior performance achieved by the proposed model is due to the use of\nmultimodal information as external classification tokens.",
          "link": "http://arxiv.org/abs/2203.16952",
          "publishedOn": "2022-04-02T00:47:19.987Z",
          "wordCount": null,
          "title": "Multimodal Fusion Transformer for Remote Sensing Image Classification. (arXiv:2203.16952v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kashkin_A/0/1/0/all/0/1\">A. Kashkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karpukhin_I/0/1/0/all/0/1\">I. Karpukhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shishkin_S/0/1/0/all/0/1\">S. Shishkin</a>",
          "description": "The goal of voice conversion (VC) is to convert input voice to match the\ntarget speaker's voice while keeping text and prosody intact. VC is usually\nused in entertainment and speaking-aid systems, as well as applied for speech\ndata generation and augmentation. The development of any-to-any VC systems,\nwhich are capable of generating voices unseen during model training, is of\nparticular interest to both researchers and the industry. Despite recent\nprogress, any-to-any conversion quality is still inferior to natural speech.\n\nIn this work, we propose a new any-to-any voice conversion pipeline. Our\napproach uses automated speech recognition (ASR) features, pitch tracking, and\na state-of-the-art waveform prediction model. According to multiple subjective\nand objective evaluations, our method outperforms modern baselines in terms of\nvoice quality, similarity and consistency.",
          "link": "http://arxiv.org/abs/2203.16937",
          "publishedOn": "2022-04-02T00:47:19.985Z",
          "wordCount": null,
          "title": "HiFi-VC: High Quality ASR-Based Voice Conversion. (arXiv:2203.16937v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kanghyun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hye Yoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Deokki Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Joonsang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1\">Noseong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngsok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinho Lee</a>",
          "description": "Model quantization is considered as a promising method to greatly reduce the\nresource requirements of deep neural networks. To deal with the performance\ndrop induced by quantization errors, a popular method is to use training data\nto fine-tune quantized networks. In real-world environments, however, such a\nmethod is frequently infeasible because training data is unavailable due to\nsecurity, privacy, or confidentiality concerns. Zero-shot quantization\naddresses such problems, usually by taking information from the weights of a\nfull-precision teacher network to compensate the performance drop of the\nquantized networks. In this paper, we first analyze the loss surface of\nstate-of-the-art zero-shot quantization techniques and provide several\nfindings. In contrast to usual knowledge distillation problems, zero-shot\nquantization often suffers from 1) the difficulty of optimizing multiple loss\nterms together, and 2) the poor generalization capability due to the use of\nsynthetic samples. Furthermore, we observe that many weights fail to cross the\nrounding threshold during training the quantized networks even when it is\nnecessary to do so for better performance. Based on the observations, we\npropose AIT, a simple yet powerful technique for zero-shot quantization, which\naddresses the aforementioned two problems in the following way: AIT i) uses a\nKL distance loss only without a cross-entropy loss, and ii) manipulates\ngradients to guarantee that a certain portion of weights are properly updated\nafter crossing the rounding thresholds. Experiments show that AIT outperforms\nthe performance of many existing methods by a great margin, taking over the\noverall state-of-the-art position in the field.",
          "link": "http://arxiv.org/abs/2203.17008",
          "publishedOn": "2022-04-02T00:47:19.984Z",
          "wordCount": null,
          "title": "It's All In the Teacher: Zero-Shot Quantization Brought Closer to the Teacher. (arXiv:2203.17008v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qinghua Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1\">Alexander N. Gorban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirkes_E/0/1/0/all/0/1\">Evgeny M. Mirkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bac_J/0/1/0/all/0/1\">Jonathan Bac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zinovyev_A/0/1/0/all/0/1\">Andrei Zinovyev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1\">Ivan Y. Tyukin</a>",
          "description": "Finding best architectures of learning machines, such as deep neural\nnetworks, is a well-known technical and theoretical challenge. Recent work by\nMellor et al (2021) showed that there may exist correlations between the\naccuracies of trained networks and the values of some easily computable\nmeasures defined on randomly initialised networks which may enable to search\ntens of thousands of neural architectures without training. Mellor et al used\nthe Hamming distance evaluated over all ReLU neurons as such a measure.\nMotivated by these findings, in our work, we ask the question of the existence\nof other and perhaps more principled measures which could be used as\ndeterminants of success of a given neural architecture. In particular, we\nexamine, if the dimensionality and quasi-orthogonality of neural networks'\nfeature space could be correlated with the network's performance after\ntraining. We showed, using the setup as in Mellor et al, that dimensionality\nand quasi-orthogonality may jointly serve as network's performance\ndiscriminants. In addition to offering new opportunities to accelerate neural\narchitecture search, our findings suggest important relationships between the\nnetworks' final performance and properties of their randomly initialised\nfeature spaces: data dimension and quasi-orthogonality.",
          "link": "http://arxiv.org/abs/2203.16687",
          "publishedOn": "2022-04-02T00:47:19.983Z",
          "wordCount": null,
          "title": "Quasi-orthogonality and intrinsic dimensions as measures of learning and generalisation. (arXiv:2203.16687v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katayose_T/0/1/0/all/0/1\">Taisuke Katayose</a>",
          "description": "Recently machine learning using neural networks has been developed, and many\nnew methods have been suggested. On the other hand, a system that has true\nversatility has not been developed, and there remain many fields in which the\nhuman brain has advantages over machine learning. We considered how the human\nbrain recognizes events and memorizes them and succeeded to reproduce the\nsystem of the human brain on a machine learning model with a new autoencoder\nneural network (NN). The previous autoencoders have the problem that they\ncannot define well what is the features of the input data, and we need to\nrestrict the middle layer of the autoencoder artificially. We solve this\nproblem by defining a new loss function that reflects the information entropy,\nand it enables the NN to compress the input data ideally and automatically\ndiscover the hidden law behind the input data set. The loss function used in\nour NN is based on the free-energy principle which is known as the unified\nbrain theory, and our study is the first concrete formularization of this\nprinciple. The result of this study can be applied to any kind of data analysis\nand also to cognitive science.",
          "link": "http://arxiv.org/abs/2203.16941",
          "publishedOn": "2022-04-02T00:47:19.982Z",
          "wordCount": null,
          "title": "The ideal data compression and automatic discovery of hidden law using neural network. (arXiv:2203.16941v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16773",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tseng_W/0/1/0/all/0/1\">Wei-Cheng Tseng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Speech representations learned from Self-supervised learning (SSL) models\nhave been found beneficial for various speech processing tasks. However,\nutilizing SSL representations usually requires fine-tuning the pre-trained\nmodels or designing task-specific downstream models and loss functions, causing\nmuch memory usage and human labor. On the other hand, prompting in Natural\nLanguage Processing (NLP) is an efficient and widely used technique to leverage\npre-trained language models (LMs). Nevertheless, such a paradigm is little\nstudied in the speech community. We report in this paper the first exploration\nof the prompt tuning paradigm for speech processing tasks based on Generative\nSpoken Language Model (GSLM). Experiment results show that the prompt tuning\ntechnique achieves competitive performance in speech classification tasks with\nfewer trainable parameters than fine-tuning specialized downstream models. We\nfurther study the technique in challenging sequence generation tasks. Prompt\ntuning also demonstrates its potential, while the limitation and possible\nresearch directions are discussed in this paper.",
          "link": "http://arxiv.org/abs/2203.16773",
          "publishedOn": "2022-04-02T00:47:19.981Z",
          "wordCount": null,
          "title": "An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks. (arXiv:2203.16773v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hillebrecht_B/0/1/0/all/0/1\">Birgit Hillebrecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unger_B/0/1/0/all/0/1\">Benjamin Unger</a>",
          "description": "Physics-informed neural networks (PINNs) are one popular approach to\nintroduce a priori knowledge about physical systems into the learning\nframework. PINNs are known to be robust for smaller training sets, derive\nbetter generalization problems, and are faster to train. In this paper, we show\nthat using PINNs in comparison with purely data-driven neural networks is not\nonly favorable for training performance but allows us to extract significant\ninformation on the quality of the approximated solution. Assuming that the\nunderlying differential equation for the PINN training is an ordinary\ndifferential equation, we derive a rigorous upper limit on the PINN prediction\nerror. This bound is applicable even for input data not included in the\ntraining phase and without any prior knowledge about the true solution.\nTherefore, our a posteriori error estimation is an essential step to certify\nthe PINN. We apply our error estimator exemplarily to two academic toy\nproblems, whereof one falls in the category of model-predictive control and\nthereby shows the practical use of the derived results.",
          "link": "http://arxiv.org/abs/2203.17055",
          "publishedOn": "2022-04-02T00:47:19.981Z",
          "wordCount": null,
          "title": "Certified machine learning: A posteriori error estimation for physics-informed neural networks. (arXiv:2203.17055v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mahdi S. Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuli_M/0/1/0/all/0/1\">Mathieu Tuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plataniotis_K/0/1/0/all/0/1\">Konstantinos N. Plataniotis</a>",
          "description": "Explaining the generalization characteristics of deep learning is an emerging\ntopic in advanced machine learning. There are several unanswered questions\nabout how learning under stochastic optimization really works and why certain\nstrategies are better than others. In this paper, we address the following\nquestion: \\textit{can we probe intermediate layers of a deep neural network to\nidentify and quantify the learning quality of each layer?} With this question\nin mind, we propose new explainability metrics that measure the redundant\ninformation in a network's layers using a low-rank factorization framework and\nquantify a complexity measure that is highly correlated with the generalization\nperformance of a given optimizer, network, and dataset. We subsequently exploit\nthese metrics to augment the Stochastic Gradient Descent (SGD) optimizer by\nadaptively adjusting the learning rate in each layer to improve in\ngeneralization performance. Our augmented SGD -- dubbed RMSGD -- introduces\nminimal computational overhead compared to SOTA methods and outperforms them by\nexhibiting strong generalization characteristics across application,\narchitecture, and dataset.",
          "link": "http://arxiv.org/abs/2203.16723",
          "publishedOn": "2022-04-02T00:47:19.978Z",
          "wordCount": null,
          "title": "Exploiting Explainable Metrics for Augmented SGD. (arXiv:2203.16723v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antoniou_A/0/1/0/all/0/1\">Anna Antoniou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dossena_G/0/1/0/all/0/1\">Giacomo Dossena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacMillan_J/0/1/0/all/0/1\">Julia MacMillan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamblin_S/0/1/0/all/0/1\">Steven Hamblin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David Clifton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrone_P/0/1/0/all/0/1\">Paula Petrone</a>",
          "description": "Objective: The use of routinely-acquired medical data for research purposes\nrequires the protection of patient confidentiality via data anonymisation. The\nobjective of this work is to calculate the risk of re-identification arising\nfrom a malicious attack to an anonymised dataset, as described below. Methods:\nWe first present an analytical means of estimating the probability of\nre-identification of a single patient in a k-anonymised dataset of Electronic\nHealth Record (EHR) data. Second, we generalize this solution to obtain the\nprobability of multiple patients being re-identified. We provide synthetic\nvalidation via Monte Carlo simulations to illustrate the accuracy of the\nestimates obtained. Results: The proposed analytical framework for risk\nestimation provides re-identification probabilities that are in agreement with\nthose provided by simulation in a number of scenarios. Our work is limited by\nconservative assumptions which inflate the re-identification probability.\nDiscussion: Our estimates show that the re-identification probability increases\nwith the proportion of the dataset maliciously obtained and that it has an\ninverse relationship with the equivalence class size. Our recursive approach\nextends the applicability domain to the general case of a multi-patient\nre-identification attack in an arbitrary k-anonymisation scheme. Conclusion: We\nprescribe a systematic way to parametrize the k-anonymisation process based on\na pre-determined re-identification probability. We observed that the benefits\nof a reduced re-identification risk that come with increasing k-size may not be\nworth the reduction in data granularity when one is considering benchmarking\nthe re-identification probability on the size of the portion of the dataset\nmaliciously obtained by the adversary.",
          "link": "http://arxiv.org/abs/2203.16921",
          "publishedOn": "2022-04-02T00:47:19.951Z",
          "wordCount": null,
          "title": "Assessing the risk of re-identification arising from an attack on anonymised data. (arXiv:2203.16921v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1\">Emiel Hoogeboom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satorras_V/0/1/0/all/0/1\">Victor Garcia Satorras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vignac_C/0/1/0/all/0/1\">Cl&#xe9;ment Vignac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "This work introduces a diffusion model for molecule generation in 3D that is\nequivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model\n(EDM) learns to denoise a diffusion process with an equivariant network that\njointly operates on both continuous (atom coordinates) and categorical features\n(atom types). In addition, we provide a probabilistic analysis which admits\nlikelihood computation of molecules using our model. Experimentally, the\nproposed method significantly outperforms previous 3D molecular generative\nmethods regarding the quality of generated samples and efficiency at training\ntime.",
          "link": "http://arxiv.org/abs/2203.17003",
          "publishedOn": "2022-04-02T00:47:19.950Z",
          "wordCount": null,
          "title": "Equivariant Diffusion for Molecule Generation in 3D. (arXiv:2203.17003v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wallingford_M/0/1/0/all/0/1\">Matthew Wallingford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1\">Avinash Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fowlkes_C/0/1/0/all/0/1\">Charless Fowlkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotika_R/0/1/0/all/0/1\">Rahul Bhotika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Adapting pre-trained models with broad capabilities has become standard\npractice for learning a wide range of downstream tasks. The typical approach of\nfine-tuning different models for each task is performant, but incurs a\nsubstantial memory cost. To efficiently learn multiple downstream tasks we\nintroduce Task Adaptive Parameter Sharing (TAPS), a general method for tuning a\nbase model to a new task by adaptively modifying a small, task-specific subset\nof layers. This enables multi-task learning while minimizing resources used and\ncompetition between tasks. TAPS solves a joint optimization problem which\ndetermines which layers to share with the base model and the value of the\ntask-specific weights. Further, a sparsity penalty on the number of active\nlayers encourages weight sharing with the base model. Compared to other\nmethods, TAPS retains high accuracy on downstream tasks while introducing few\ntask-specific parameters. Moreover, TAPS is agnostic to the model architecture\nand requires only minor changes to the training scheme. We evaluate our method\non a suite of fine-tuning tasks and architectures (ResNet, DenseNet, ViT) and\nshow that it achieves state-of-the-art performance while being simple to\nimplement.",
          "link": "http://arxiv.org/abs/2203.16708",
          "publishedOn": "2022-04-02T00:47:19.937Z",
          "wordCount": null,
          "title": "Task Adaptive Parameter Sharing for Multi-Task Learning. (arXiv:2203.16708v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sen_D/0/1/0/all/0/1\">Dipayan Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+A%2E_P/0/1/0/all/0/1\">Prashanth L.A.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalan_A/0/1/0/all/0/1\">Aditya Gopalan</a>",
          "description": "We consider the problem of sequentially learning to estimate, in the mean\nsquared error (MSE) sense, a Gaussian $K$-vector of unknown covariance by\nobserving only $m < K$ of its entries in each round. This reduces to learning\nan optimal subset for estimating the entire vector. Towards this, we first\nestablish an exponential concentration bound for an estimate of the MSE for\neach observable subset. We then frame the estimation problem with bandit\nfeedback in the best-subset identification setting. We propose a variant of the\nsuccessive elimination algorithm to cater to the adaptive estimation problem,\nand we derive an upper bound on the sample complexity of this algorithm. In\naddition, to understand the fundamental limit on the sample complexity of this\nadaptive estimation bandit problem, we derive a minimax lower bound.",
          "link": "http://arxiv.org/abs/2203.16810",
          "publishedOn": "2022-04-02T00:47:19.937Z",
          "wordCount": null,
          "title": "Adaptive Estimation of Random Vectors with Bandit Feedback. (arXiv:2203.16810v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazirbas_C/0/1/0/all/0/1\">Caner Hazirbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordo_A/0/1/0/all/0/1\">Albert Gordo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozgenel_F/0/1/0/all/0/1\">Firat Ozgenel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1\">Cristian Canton Ferrer</a>",
          "description": "Our work focuses on addressing sample deficiency from low-density regions of\ndata manifold in common image datasets. We leverage diffusion process based\ngenerative models to synthesize novel images from low-density regions. We\nobserve that uniform sampling from diffusion models predominantly samples from\nhigh-density regions of the data manifold. Therefore, we modify the sampling\nprocess to guide it towards low-density regions while simultaneously\nmaintaining the fidelity of synthetic data. We rigorously demonstrate that our\nprocess successfully generates novel high fidelity samples from low-density\nregions. We further examine generated samples and show that the model does not\nmemorize low-density data and indeed learns to generate novel samples from\nlow-density regions.",
          "link": "http://arxiv.org/abs/2203.17260",
          "publishedOn": "2022-04-02T00:47:19.934Z",
          "wordCount": null,
          "title": "Generating High Fidelity Data from Low-density Regions using Diffusion Models. (arXiv:2203.17260v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16776",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zheng_H/0/1/0/all/0/1\">Huahuan Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+An_K/0/1/0/all/0/1\">Keyu An</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ou_Z/0/1/0/all/0/1\">Zhijian Ou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1\">Chen Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ding_K/0/1/0/all/0/1\">Ke Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wan_G/0/1/0/all/0/1\">Guanglu Wan</a>",
          "description": "Utilizing text-only data with an external language model (LM) in end-to-end\nRNN-Transducer (RNN-T) for speech recognition is challenging. Recently, a class\nof methods such as density ratio (DR) and ILM estimation (ILME) have been\ndeveloped, outperforming the classic shallow fusion (SF) method. The basic idea\nbehind these methods is that RNN-T posterior should first subtract the\nimplicitly learned ILM prior, in order to integrate the external LM. While\nrecent studies suggest that RNN-T only learns some low-order language model\ninformation, the DR method uses a well-trained ILM. We hypothesize that this\nsetting is appropriate and may deteriorate the performance of the DR method,\nand propose a low-order density ratio method (LODR) by training a low-order\nweak ILM for DR. Extensive empirical experiments are conducted on both\nin-domain and cross-domain scenarios on English LibriSpeech & Tedlium-2 and\nChinese WenetSpeech & AISHELL-1 datasets. It is shown that LODR consistently\noutperforms SF in all tasks, while performing generally close to ILME and\nbetter than DR in most tests.",
          "link": "http://arxiv.org/abs/2203.16776",
          "publishedOn": "2022-04-02T00:47:19.927Z",
          "wordCount": null,
          "title": "An Empirical Study of Language Model Integration for Transducer based Speech Recognition. (arXiv:2203.16776v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1\">Takami Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qi Alfred Chen</a>",
          "description": "After the 2017 TuSimple Lane Detection Challenge, its dataset and evaluation\nbased on accuracy and F1 score have become the de facto standard to measure the\nperformance of lane detection methods. While they have played a major role in\nimproving the performance of lane detection methods, the validity of this\nevaluation method in downstream tasks has not been adequately researched. In\nthis study, we design 2 new driving-oriented metrics for lane detection:\nEnd-to-End Lateral Deviation metric (E2E-LD) is directly formulated based on\nthe requirements of autonomous driving, a core downstream task of lane\ndetection; Per-frame Simulated Lateral Deviation metric (PSLD) is a lightweight\nsurrogate metric of E2E-LD. To evaluate the validity of the metrics, we conduct\na large-scale empirical study with 4 major types of lane detection approaches\non the TuSimple dataset and our newly constructed dataset Comma2k19-LD. Our\nresults show that the conventional metrics have strongly negative correlations\n($\\leq$-0.55) with E2E-LD, meaning that some recent improvements purely\ntargeting the conventional metrics may not have led to meaningful improvements\nin autonomous driving, but rather may actually have made it worse by\noverfitting to the conventional metrics. As autonomous driving is a\nsecurity/safety-critical system, the underestimation of robustness hinders the\nsound development of practical lane detection models. We hope that our study\nwill help the community achieve more downstream task-aware evaluations for lane\ndetection.",
          "link": "http://arxiv.org/abs/2203.16851",
          "publishedOn": "2022-04-02T00:47:19.926Z",
          "wordCount": null,
          "title": "Towards Driving-Oriented Metric for Lane Detection Models. (arXiv:2203.16851v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16673",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yue Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>",
          "description": "This paper studies the problem of identifying low-order linear systems via\nHankel nuclear norm regularization. Hankel regularization encourages the\nlow-rankness of the Hankel matrix, which maps to the low-orderness of the\nsystem. We provide novel statistical analysis for this regularization and\ncarefully contrast it with the unregularized ordinary least-squares (OLS)\nestimator. Our analysis leads to new bounds on estimating the impulse response\nand the Hankel matrix associated with the linear system. We first design an\ninput excitation and show that Hankel regularization enables one to recover the\nsystem using optimal number of observations in the true system order and\nachieve strong statistical estimation rates. Surprisingly, we demonstrate that\nthe input design indeed matters, by showing that intuitive choices such as\ni.i.d. Gaussian input leads to provably sub-optimal sample complexity. To\nbetter understand the benefits of regularization, we also revisit the OLS\nestimator. Besides refining existing bounds, we experimentally identify when\nregularized approach improves over OLS: (1) For low-order systems with slow\nimpulse-response decay, OLS method performs poorly in terms of sample\ncomplexity, (2) Hankel matrix returned by regularization has a more clear\nsingular value gap that ease identification of the system order, (3) Hankel\nregularization is less sensitive to hyperparameter choice. Finally, we\nestablish model selection guarantees through a joint train-validation procedure\nwhere we tune the regularization parameter for near-optimal estimation.",
          "link": "http://arxiv.org/abs/2203.16673",
          "publishedOn": "2022-04-02T00:47:19.925Z",
          "wordCount": null,
          "title": "System Identification via Nuclear Norm Regularization. (arXiv:2203.16673v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junjie Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi-Gang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grebogi_C/0/1/0/all/0/1\">Celso Grebogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1\">Ying-Cheng Lai</a>",
          "description": "We develop a deep convolutional neural network (DCNN) based framework for\nmodel-free prediction of the occurrence of extreme events both in time (\"when\")\nand in space (\"where\") in nonlinear physical systems of spatial dimension two.\nThe measurements or data are a set of two-dimensional snapshots or images. For\na desired time horizon of prediction, a proper labeling scheme can be\ndesignated to enable successful training of the DCNN and subsequent prediction\nof extreme events in time. Given that an extreme event has been predicted to\noccur within the time horizon, a space-based labeling scheme can be applied to\npredict, within certain resolution, the location at which the event will occur.\nWe use synthetic data from the 2D complex Ginzburg-Landau equation and\nempirical wind speed data of the North Atlantic ocean to demonstrate and\nvalidate our machine-learning based prediction framework. The trade-offs among\nthe prediction horizon, spatial resolution, and accuracy are illustrated, and\nthe detrimental effect of spatially biased occurrence of extreme event on\nprediction accuracy is discussed. The deep learning framework is viable for\npredicting extreme events in the real world.",
          "link": "http://arxiv.org/abs/2203.17155",
          "publishedOn": "2022-04-02T00:47:19.924Z",
          "wordCount": null,
          "title": "Predicting extreme events from data using deep machine learning: when and where. (arXiv:2203.17155v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elazar_N/0/1/0/all/0/1\">Nathan Elazar</a>",
          "description": "We explore the use of class-conditional autoregressive (CA) models to perform\nimage classification on MNIST-10. Autoregressive models assign probability to\nan entire input by combining probabilities from each individual feature; hence\nclassification decisions made by a CA can be readily decomposed into\ncontributions from each each input feature. That is to say, CA are inherently\nlocally interpretable. Our experiments show that naively training a CA achieves\nmuch worse accuracy compared to a standard classifier, however this is due to\nover-fitting and not a lack of expressive power. Using knowledge distillation\nfrom a standard classifier, a student CA can be trained to match the\nperformance of the teacher while still being interpretable.",
          "link": "http://arxiv.org/abs/2203.17002",
          "publishedOn": "2022-04-02T00:47:19.923Z",
          "wordCount": null,
          "title": "Conditional Autoregressors are Interpretable Classifiers. (arXiv:2203.17002v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ayache_E/0/1/0/all/0/1\">Eliot H. Ayache</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omand_C/0/1/0/all/0/1\">Conor M.B. Omand</a>",
          "description": "In recent years, the field of machine learning has seen rapid growth, with\napplications in a variety of domains, including image recognition, natural\nlanguage processing, and predictive modeling. In this paper, we explore the\napplication of machine learning to the generation of scientific articles. We\npresent a method for using machine learning to generate scientific articles\nbased on a data set of scientific papers. The method uses a machine-learning\nalgorithm to learn the structure of a scientific article and a set of training\ndata consisting of scientific papers. The machine-learning algorithm is used to\ngenerate a scientific article based on the data set of scientific papers. We\nevaluate the performance of the method by comparing the generated article to a\nset of manually written articles. The results show that the machine-generated\narticle is of similar quality to the manually written articles.",
          "link": "http://arxiv.org/abs/2203.16569",
          "publishedOn": "2022-04-02T00:47:19.911Z",
          "wordCount": null,
          "title": "Generating Scientific Articles with Machine Learning. (arXiv:2203.16569v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16587",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chatterjee_S/0/1/0/all/0/1\">Sabyasachi Chatterjee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Goswami_S/0/1/0/all/0/1\">Subhajit Goswami</a>",
          "description": "We consider the problem of estimating piecewise regular functions in an\nonline setting, i.e., the data arrive sequentially and at any round our task is\nto predict the value of the true function at the next revealed point using the\navailable data from past predictions. We propose a suitably modified version of\na recently developed online learning algorithm called the sleeping experts\naggregation algorithm. We show that this estimator satisfies oracle risk bounds\nsimultaneously for all local regions of the domain. As concrete instantiations\nof the expert aggregation algorithm proposed here, we study an online mean\naggregation and an online linear regression aggregation algorithm where experts\ncorrespond to the set of dyadic subrectangles of the domain. The resulting\nalgorithms are near linear time computable in the sample size. We specifically\nfocus on the performance of these online algorithms in the context of\nestimating piecewise polynomial and bounded variation function classes in the\nfixed design setup. The simultaneous oracle risk bounds we obtain for these\nestimators in this context provide new and improved (in certain aspects)\nguarantees even in the batch setting and are not available for the state of the\nart batch learning estimators.",
          "link": "http://arxiv.org/abs/2203.16587",
          "publishedOn": "2022-04-02T00:47:19.910Z",
          "wordCount": null,
          "title": "Spatially Adaptive Online Prediction of Piecewise Regular Functions. (arXiv:2203.16587v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_M/0/1/0/all/0/1\">Morio Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuba_H/0/1/0/all/0/1\">Hiroya Matsuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kujirai_T/0/1/0/all/0/1\">Toshihiro Kujirai</a>",
          "description": "Meta-reinforcement learning (meta-RL) acquires meta-policies that show good\nperformance for tasks in a wide task distribution. However, conventional\nmeta-RL, which learns meta-policies by randomly sampling tasks, has been\nreported to show meta-overfitting for certain tasks, especially for easy tasks\nwhere an agent can easily get high scores. To reduce effects of the\nmeta-overfitting, we considered meta-RL with curriculum-based task sampling.\nOur method is Robust Meta Reinforcement Learning with Guided Task Sampling\n(RMRL-GTS), which is an effective method that restricts task sampling based on\nscores and epochs. We show that in order to achieve robust meta-RL, it is\nnecessary not only to intensively sample tasks with poor scores, but also to\nrestrict and expand the task regions of the tasks to be sampled.",
          "link": "http://arxiv.org/abs/2203.16801",
          "publishedOn": "2022-04-02T00:47:19.910Z",
          "wordCount": null,
          "title": "Robust Meta-Reinforcement Learning with Curriculum-Based Task Sampling. (arXiv:2203.16801v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yang Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumura_T/0/1/0/all/0/1\">Tadayuki Matsumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuji_T/0/1/0/all/0/1\">Taiki Fuji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ito_K/0/1/0/all/0/1\">Kiyoto Ito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizuno_H/0/1/0/all/0/1\">Hiroyuki Mizuno</a>",
          "description": "We present Mask Atari, a new benchmark to help solve partially observable\nMarkov decision process (POMDP) problems with Deep Reinforcement Learning\n(DRL)-based approaches. To achieve a simulation environment for the POMDP\nproblems, Mask Atari is constructed based on Atari 2600 games with\ncontrollable, moveable, and learnable masks as the observation area for the\ntarget agent, especially with the active information gathering (AIG) setting in\nPOMDPs. Given that one does not yet exist, Mask Atari provides a challenging,\nefficient benchmark for evaluating the methods that focus on the above problem.\nMoreover, the mask operation is a trial for introducing the receptive field in\nthe human vision system into a simulation environment for an agent, which means\nthe evaluations are not biased from the sensing ability and purely focus on the\ncognitive performance of the methods when compared with the human baseline. We\ndescribe the challenges and features of our benchmark and evaluate several\nbaselines with Mask Atari.",
          "link": "http://arxiv.org/abs/2203.16777",
          "publishedOn": "2022-04-02T00:47:19.908Z",
          "wordCount": null,
          "title": "Mask Atari for Deep Reinforcement Learning as POMDP Benchmarks. (arXiv:2203.16777v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoopes_A/0/1/0/all/0/1\">Andrew Hoopes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_M/0/1/0/all/0/1\">Malte Hoffmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greve_D/0/1/0/all/0/1\">Douglas N. Greve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischl_B/0/1/0/all/0/1\">Bruce Fischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guttag_J/0/1/0/all/0/1\">John Guttag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalca_A/0/1/0/all/0/1\">Adrian V. Dalca</a>",
          "description": "We introduce HyperMorph, a framework that facilitates efficient\nhyperparameter tuning in learning-based deformable image registration.\nClassical registration algorithms perform an iterative pair-wise optimization\nto compute a deformation field that aligns two images. Recent learning-based\napproaches leverage large image datasets to learn a function that rapidly\nestimates a deformation for a given image pair. In both strategies, the\naccuracy of the resulting spatial correspondences is strongly influenced by the\nchoice of certain hyperparameter values. However, an effective hyperparameter\nsearch consumes substantial time and human effort as it often involves training\nmultiple models for different fixed hyperparameter values and may lead to\nsuboptimal registration. We propose an amortized hyperparameter learning\nstrategy to alleviate this burden by learning the impact of hyperparameters on\ndeformation fields. We design a meta network, or hypernetwork, that predicts\nthe parameters of a registration network for input hyperparameters, thereby\ncomprising a single model that generates the optimal deformation field\ncorresponding to given hyperparameter values. This strategy enables fast,\nhigh-resolution hyperparameter search at test-time, reducing the inefficiency\nof traditional approaches while increasing flexibility. We also demonstrate\nadditional benefits of HyperMorph, including enhanced robustness to model\ninitialization and the ability to rapidly identify optimal hyperparameter\nvalues specific to a dataset, image contrast, task, or even anatomical region,\nall without the need to retrain models. We make our code publicly available at\nthis http URL",
          "link": "http://arxiv.org/abs/2203.16680",
          "publishedOn": "2022-04-02T00:47:19.906Z",
          "wordCount": null,
          "title": "Learning the Effect of Registration Hyperparameters with HyperMorph. (arXiv:2203.16680v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16691",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Baade_A/0/1/0/all/0/1\">Alan Baade</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_P/0/1/0/all/0/1\">Puyuan Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harwath_D/0/1/0/all/0/1\">David Harwath</a>",
          "description": "In this paper, we propose a simple yet powerful improvement over the recent\nSelf-Supervised Audio Spectrogram Transformer (SSAST) model for speech and\naudio classification. Specifically, we leverage the insight that the SSAST uses\na very high masking ratio (75%) during pretraining, meaning that the vast\nmajority of self-attention compute is performed on mask tokens. We address this\nby integrating the encoder-decoder architecture from Masked Autoencoders are\nScalable Vision Learners (MAE) into the SSAST, where a deep encoder operates on\nonly unmasked input, and a shallow decoder operates on encoder outputs and mask\ntokens. We find that MAE-like pretraining can provide a 3x speedup and 2x\nmemory usage reduction over the vanilla SSAST using current audio pretraining\nstrategies with ordinary model and input sizes. When fine-tuning on downstream\ntasks, which only uses the encoder, we find that our approach outperforms the\nSSAST on a variety of downstream tasks. We further conduct comprehensive\nevaluations into different strategies of pretraining and explore differences in\nMAE-style pretraining between the visual and audio domains.",
          "link": "http://arxiv.org/abs/2203.16691",
          "publishedOn": "2022-04-02T00:47:19.904Z",
          "wordCount": null,
          "title": "MAE-AST: Masked Autoencoding Audio Spectrogram Transformer. (arXiv:2203.16691v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16940",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Diaz_Guerra_D/0/1/0/all/0/1\">David Diaz-Guerra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Miguel_A/0/1/0/all/0/1\">Antonio Miguel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beltran_J/0/1/0/all/0/1\">Jose R. Beltran</a>",
          "description": "In this paper, we present a new model for Direction of Arrival (DOA)\nestimation of sound sources based on an Icosahedral Convolutional Neural\nNetwork (CNN) applied over SRP-PHAT power maps computed from the signals\nreceived by a microphone array. This icosahedral CNN is equivariant to the 60\nrotational symmetries of the icosahedron, which represent a good approximation\nof the continuous space of spherical rotations, and can be implemented using\nstandard 2D convolutional layers, having a lower computational cost than most\nof the spherical CNNs. In addition, instead of using fully connected layers\nafter the icosahedral convolutions, we propose a new soft-argmax function that\ncan be seen as a differentiable version of the argmax function and allows us to\nsolve the DOA estimation as a regression problem interpreting the output of the\nconvolutional layers as a probability distribution. We prove that using models\nthat fit the equivariances of the problem allows us to outperform other\nstate-of-the-art models with a lower computational cost and more robustness,\nobtaining root mean square localization errors lower than 10{\\deg} even in\nscenarios with a reverberation time $T_{60}$ of 1.5 s.",
          "link": "http://arxiv.org/abs/2203.16940",
          "publishedOn": "2022-04-02T00:47:19.904Z",
          "wordCount": null,
          "title": "Direction of Arrival Estimation of Sound Sources Using Icosahedral CNNs. (arXiv:2203.16940v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17028",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1\">Yong Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Youlong Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanming Shi</a>",
          "description": "Federated learning (FL), as a disruptive machine learning paradigm, enables\nthe collaborative training of a global model over decentralized local datasets\nwithout sharing them. It spans a wide scope of applications from\nInternet-of-Things (IoT) to biomedical engineering and drug discovery. To\nsupport low-latency and high-privacy FL over wireless networks, in this paper,\nwe propose a reconfigurable intelligent surface (RIS) empowered over-the-air FL\nsystem to alleviate the dilemma between learning accuracy and privacy. This is\nachieved by simultaneously exploiting the channel propagation reconfigurability\nwith RIS for boosting the receive signal power, as well as waveform\nsuperposition property with over-the-air computation (AirComp) for fast model\naggregation. By considering a practical scenario where high-dimensional local\nmodel updates are transmitted across multiple communication blocks, we\ncharacterize the convergence behaviors of the differentially private federated\noptimization algorithm. We further formulate a system optimization problem to\noptimize the learning accuracy while satisfying privacy and power constraints\nvia the joint design of transmit power, artificial noise, and phase shifts at\nRIS, for which a two-step alternating minimization framework is developed.\nSimulation results validate our systematic, theoretical, and algorithmic\nachievements and demonstrate that RIS can achieve a better trade-off between\nprivacy and accuracy for over-the-air FL systems.",
          "link": "http://arxiv.org/abs/2203.17028",
          "publishedOn": "2022-04-02T00:47:19.901Z",
          "wordCount": null,
          "title": "Differentially Private Federated Learning via Reconfigurable Intelligent Surface. (arXiv:2203.17028v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heydari_S/0/1/0/all/0/1\">Sajjad Heydari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Livi_L/0/1/0/all/0/1\">Lorenzo Livi</a>",
          "description": "Hypergraph representations are both more efficient and better suited to\ndescribe data characterized by relations between two or more objects. In this\nwork, we present the first graph neural network based on message passing\ncapable of processing hypergraph-structured data. We show that the proposed\nmodel defines a design space for neural network models for hypergraphs, thus\ngeneralizing existing models for hypergraphs. We report experiments on a\nbenchmark dataset for node classification, highlighting the effectiveness of\nthe proposed model with respect to other state-of-the-art methods for graphs\nand hypergraphs. We also discuss the benefits of using hypergraph\nrepresentations and, at the same time, highlight the limitation of using\nequivalent graph representations when the underlying problem has relations\namong more than two objects.",
          "link": "http://arxiv.org/abs/2203.16995",
          "publishedOn": "2022-04-02T00:47:19.900Z",
          "wordCount": null,
          "title": "Message Passing Neural Networks for Hypergraphs. (arXiv:2203.16995v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amit Kumar Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asif_A/0/1/0/all/0/1\">Abdullah Al Asif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1\">Anik Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md. Nur Hossain</a>",
          "description": "Hate speech has spread more rapidly through the daily use of technology and,\nmost notably, by sharing your opinions or feelings on social media in a\nnegative aspect. Although numerous works have been carried out in detecting\nhate speeches in English, German, and other languages, very few works have been\ncarried out in the context of the Bengali language. In contrast, millions of\npeople communicate on social media in Bengali. The few existing works that have\nbeen carried out need improvements in both accuracy and interpretability. This\narticle proposed encoder decoder based machine learning model, a popular tool\nin NLP, to classify user's Bengali comments on Facebook pages. A dataset of\n7,425 Bengali comments, consisting of seven distinct categories of hate\nspeeches, was used to train and evaluate our model. For extracting and encoding\nlocal features from the comments, 1D convolutional layers were used. Finally,\nthe attention mechanism, LSTM, and GRU based decoders have been used for\npredicting hate speech categories. Among the three encoder decoder algorithms,\nthe attention-based decoder obtained the best accuracy (77%).",
          "link": "http://arxiv.org/abs/2203.16775",
          "publishedOn": "2022-04-02T00:47:19.899Z",
          "wordCount": null,
          "title": "Bangla hate speech detection on social media using attention-based recurrent neural network. (arXiv:2203.16775v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1\">Trung X. Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_A/0/1/0/all/0/1\">Axi Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Zhinan Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1\">In So Kweon</a>",
          "description": "Contrastive learning (CL) is widely known to require many negative samples,\n65536 in MoCo for instance, for which the performance of a dictionary-free\nframework is often inferior because the negative sample size (NSS) is limited\nby its mini-batch size (MBS). To decouple the NSS from the MBS, a dynamic\ndictionary has been adopted in a large volume of CL frameworks, among which\narguably the most popular one is MoCo family. In essence, MoCo adopts a\nmomentum-based queue dictionary, for which we perform a fine-grained analysis\nof its size and consistency. We point out that InfoNCE loss used in MoCo\nimplicitly attract anchors to their corresponding positive sample with various\nstrength of penalties and identify such inter-anchor hardness-awareness\nproperty as a major reason for the necessity of a large dictionary. Our\nfindings motivate us to simplify MoCo v2 via the removal of its dictionary as\nwell as momentum. Based on an InfoNCE with the proposed dual temperature, our\nsimplified frameworks, SimMoCo and SimCo, outperform MoCo v2 by a visible\nmargin. Moreover, our work bridges the gap between CL and non-CL frameworks,\ncontributing to a more unified understanding of these two mainstream frameworks\nin SSL. Code is available at: https://bit.ly/3LkQbaT.",
          "link": "http://arxiv.org/abs/2203.17248",
          "publishedOn": "2022-04-02T00:47:19.898Z",
          "wordCount": null,
          "title": "Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo. (arXiv:2203.17248v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.07914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wenqian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junyang Jin</a>",
          "description": "Diagnosis of ice accretion on wind turbine blades is all the time a hard nut\nto crack in condition monitoring of wind farms. Existing methods focus on\nmechanism analysis of icing process, deviation degree analysis of feature\nengineering. However, there have not been deep researches of neural networks\napplied in this field at present. Supervisory control and data acquisition\n(SCADA) makes it possible to train networks through continuously providing not\nonly operation parameters and performance parameters of wind turbines but also\nenvironmental parameters and operation modes. This paper explores the\npossibility that using convolutional neural networks (CNNs), generative\nadversarial networks (GANs) and domain adaption learning to establish\nintelligent diagnosis frameworks under different training scenarios.\nSpecifically, PGANC and PGANT are proposed for sufficient and non-sufficient\ntarget wind turbine labeled data, respectively. The basic idea is that we\nconsider a two-stage training with parallel GANs, which are aimed at capturing\nintrinsic features for normal and icing samples, followed by classification CNN\nor domain adaption module in various training cases. Model validation on three\nwind turbine SCADA data shows that two-stage training can effectively improve\nthe model performance. Besides, if there is no sufficient labeled data for a\ntarget turbine, which is an extremely common phenomenon in real industrial\npractices, the addition of domain adaption learning makes the trained model\nshow better performance. Overall, our proposed intelligent diagnosis frameworks\ncan achieve more accurate detection on the same wind turbine and more\ngeneralized capability on a new wind turbine, compared with other machine\nlearning models and conventional CNNs.",
          "link": "http://arxiv.org/abs/2101.07914",
          "publishedOn": "2022-04-02T00:47:19.898Z",
          "wordCount": null,
          "title": "Intelligent Icing Detection Model of Wind Turbine Blades Based on SCADA data. (arXiv:2101.07914v1 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16944",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Berrone_S/0/1/0/all/0/1\">Stefano Berrone</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Oberto_D/0/1/0/all/0/1\">Davide Oberto</a>",
          "description": "In the present paper a new data-driven model to close and increase accuracy\nof RANS equations is proposed. It is based on the direct approximation of the\ndivergence of the Reynolds Stress Tensor (RST) through a Neural Network (NN).\nThis choice is driven by the presence of the divergence of RST in the RANS\nequations. Furthermore, once this data-driven approach is trained, there is no\nneed to run any turbulence model to close the equations. Finally, it is well\nknown that a good approximation of a function it is not necessarily a good\napproximation of its derivative. The architecture and inputs choices of the\nproposed network guarantee both Galilean and coordinates-frame rotation\ninvariances by looking to a vector basis expansion of the divergence of the\nRST. Two well-known test cases are used to show advantages of the proposed\nmethod compared to classic turbulence models.",
          "link": "http://arxiv.org/abs/2203.16944",
          "publishedOn": "2022-04-02T00:47:19.895Z",
          "wordCount": null,
          "title": "A data-driven approach for the closure of RANS models by the divergence of the Reynolds Stress Tensor. (arXiv:2203.16944v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1812.00086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Heda Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haiping Lu</a>",
          "description": "Graph convolutional network (GCN) is an emerging neural network approach. It\nlearns new representation of a node by aggregating feature vectors of all\nneighbors in the aggregation process without considering whether the neighbors\nor features are useful or not. Recent methods have improved solutions by\nsampling a fixed size set of neighbors, or assigning different weights to\ndifferent neighbors in the aggregation process, but features within a feature\nvector are still treated equally in the aggregation process. In this paper, we\nintroduce a new convolution operation on regular size feature maps constructed\nfrom features of a fixed node bandwidth via sampling to get the first-level\nnode representation, which is then passed to a standard GCN to learn the\nsecond-level node representation. Experiments show that our method outperforms\ncompeting methods in semi-supervised node classification tasks. Furthermore,\nour method opens new doors for exploring new GCN architectures, particularly\ndeeper GCN models.",
          "link": "http://arxiv.org/abs/1812.00086",
          "publishedOn": "2022-04-02T00:47:19.893Z",
          "wordCount": null,
          "title": "Graph Node-Feature Convolution for Representation Learning. (arXiv:1812.00086v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.04704",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Alanwar_A/0/1/0/all/0/1\">Amr Alanwar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niazi_M/0/1/0/all/0/1\">Muhammad Umar B. Niazi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "This paper proposes a data-driven set-based estimation algorithm for a class\nof nonlinear systems with polynomial nonlinearities. Using the system's\ninput-output data, the proposed method computes a set that guarantees the\ninclusion of the system's state in real-time. Although the system is assumed to\nbe a polynomial type, the exact polynomial functions, and their coefficients\nare assumed to be unknown. To this end, the estimator relies on offline and\nonline phases. The offline phase utilizes past input-output data to estimate a\nset of possible coefficients of the polynomial system. Then, using this\nestimated set of coefficients and the side information about the system, the\nonline phase provides a set estimate of the state. Finally, the proposed\nmethodology is evaluated through its application on SIR (Susceptible, Infected,\nRecovered) epidemic model.",
          "link": "http://arxiv.org/abs/2111.04704",
          "publishedOn": "2022-04-02T00:47:19.892Z",
          "wordCount": null,
          "title": "Data-driven Set-based Estimation of Polynomial Systems with Application to SIR Epidemics. (arXiv:2111.04704v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.11251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanchen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lu Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xuemin Lin</a>",
          "description": "Subgraph matching is a fundamental problem in various fields that use graph\nstructured data. Subgraph matching algorithms enumerate all isomorphic\nembeddings of a query graph q in a data graph G. An important branch of\nmatching algorithms exploit the backtracking search approach which recursively\nextends intermediate results following a matching order of query vertices. It\nhas been shown that the matching order plays a critical role in time efficiency\nof these backtracking based subgraph matching algorithms. In recent years, many\nadvanced techniques for query vertex ordering (i.e., matching order generation)\nhave been proposed to reduce the unpromising intermediate results according to\nthe preset heuristic rules. In this paper, for the first time we apply the\nReinforcement Learning (RL) and Graph Neural Networks (GNNs) techniques to\ngenerate the high-quality matching order for subgraph matching algorithms.\nInstead of using the fixed heuristics to generate the matching order, our model\ncould capture and make full use of the graph information, and thus determine\nthe query vertex order with the adaptive learning-based rule that could\nsignificantly reduces the number of redundant enumerations. With the help of\nthe reinforcement learning framework, our model is able to consider the\nlong-term benefits rather than only consider the local information at current\nordering step.Extensive experiments on six real-life data graphs demonstrate\nthat our proposed matching order generation technique could reduce up to two\norders of magnitude of query processing time compared to the state-of-the-art\nalgorithms.",
          "link": "http://arxiv.org/abs/2201.11251",
          "publishedOn": "2022-04-02T00:47:19.869Z",
          "wordCount": null,
          "title": "Reinforcement Learning Based Query Vertex Ordering Model for Subgraph Matching. (arXiv:2201.11251v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1\">Shivani Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_N/0/1/0/all/0/1\">Niladri Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Subir Kumar Saha</a>",
          "description": "An increasing number of machine learning models have been deployed in domains\nwith high stakes such as finance and healthcare. Despite their superior\nperformances, many models are black boxes in nature which are hard to explain.\nThere are growing efforts for researchers to develop methods to interpret these\nblack-box models. Post hoc explanations based on perturbations, such as LIME,\nare widely used approaches to interpret a machine learning model after it has\nbeen built. This class of methods has been shown to exhibit large instability,\nposing serious challenges to the effectiveness of the method itself and harming\nuser trust. In this paper, we propose S-LIME, which utilizes a hypothesis\ntesting framework based on central limit theorem for determining the number of\nperturbation points needed to guarantee stability of the resulting explanation.\nExperiments on both simulated and real world data sets are provided to\ndemonstrate the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2203.17081",
          "publishedOn": "2022-04-02T00:47:19.836Z",
          "wordCount": null,
          "title": "Interpretation of Black Box NLP Models: A Survey. (arXiv:2203.17081v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.00645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maskey_S/0/1/0/all/0/1\">Sohir Maskey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1\">Ron Levie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yunseok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>",
          "description": "Message passing neural networks (MPNN) have seen a steep rise in popularity\nsince their introduction as generalizations of convolutional neural networks to\ngraph structured data, and are now considered state-of-the-art tools for\nsolving a large variety of graph-focused problems. We study the generalization\ncapabilities of MPNNs in graph classification. We assume that graphs of\ndifferent classes are sampled from different random graph models. Based on this\ndata distribution, we derive a non-asymptotic bound on the generalization gap\nbetween the empirical and statistical loss, that decreases to zero as the\ngraphs become larger. This is proven by showing that a MPNN, applied on a\ngraph, approximates the MPNN applied on the geometric model that the graph\ndiscretizes.",
          "link": "http://arxiv.org/abs/2202.00645",
          "publishedOn": "2022-04-02T00:47:19.836Z",
          "wordCount": null,
          "title": "Stability and Generalization Capabilities of Message Passing Graph Neural Networks. (arXiv:2202.00645v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.05781",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sarfjoo_S/0/1/0/all/0/1\">Seyyed Saeed Sarfjoo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasad_A/0/1/0/all/0/1\">Amrutha Prasad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ondrej_K/0/1/0/all/0/1\">Karel Ondrej</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ohneiser_O/0/1/0/all/0/1\">Oliver Ohneiser</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Helmke_H/0/1/0/all/0/1\">Hartmut Helmke</a>",
          "description": "Automatic speech recognition (ASR) allows transcribing the communications\nbetween air traffic controllers (ATCOs) and aircraft pilots. The transcriptions\nare used later to extract ATC named entities e.g., aircraft callsigns, command\ntypes, or values. One common challenge is Speech Activity Detection (SAD) and\ndiarization system. If one of them fails then two or more single speaker\nsegments remain in the same recording, jeopardizing the overall system's\nperformance. We propose a system that combines the segmentation of a SAD module\nwith a BERT model that performs speaker change detection (SCD) and speaker role\ndetection (SRD) by chunking ASR transcripts i.e., diarization with a defined\nnumber of speakers together with SRD. The proposed model is evaluated on\nreal-life ATC test sets. It reaches up to 0.90/0.95 F1-score on ATCO/pilot SRD,\nwhich means a 27% relative improvement on diarization error rate (DER) compared\nto standard acoustic-based diarization. Results are measured on ASR transcripts\nof challenging ATC test sets with $\\sim$13\\% word error rate, and the\nrobustness of the system is even validated on noisy ASR transcripts.",
          "link": "http://arxiv.org/abs/2110.05781",
          "publishedOn": "2022-04-02T00:47:19.834Z",
          "wordCount": null,
          "title": "BERTraffic: BERT-based Joint Speaker Role and Speaker Change Detection for Air Traffic Control Communications. (arXiv:2110.05781v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moritz_N/0/1/0/all/0/1\">Niko Moritz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hori_T/0/1/0/all/0/1\">Takaaki Hori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_J/0/1/0/all/0/1\">Jonathan Le Roux</a>",
          "description": "The recurrent neural network transducer (RNN-T) objective plays a major role\nin building today's best automatic speech recognition (ASR) systems for\nproduction. Similarly to the connectionist temporal classification (CTC)\nobjective, the RNN-T loss uses specific rules that define how a set of\nalignments is generated to form a lattice for the full-sum training. However,\nit is yet largely unknown if these rules are optimal and do lead to the best\npossible ASR results. In this work, we present a new transducer objective\nfunction that generalizes the RNN-T loss to accept a graph representation of\nthe labels, thus providing a flexible and efficient framework to manipulate\ntraining lattices, e.g., for studying different transition rules, implementing\ndifferent transducer losses, or restricting alignments. We demonstrate that\ntransducer-based ASR with CTC-like lattice achieves better results compared to\nstandard RNN-T, while also ensuring a strictly monotonic alignment, which will\nallow better optimization of the decoding procedure. For example, the proposed\nCTC-like transducer achieves an improvement of 4.8% on the test-other condition\nof LibriSpeech relative to an equivalent RNN-T based system.",
          "link": "http://arxiv.org/abs/2111.01272",
          "publishedOn": "2022-04-02T00:47:19.827Z",
          "wordCount": null,
          "title": "Sequence Transduction with Graph-based Supervision. (arXiv:2111.01272v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.06484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tsung-Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liou_Y/0/1/0/all/0/1\">Yi-Syuan Liou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shao-Ji Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hsin-Ying Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tung-I Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Chih Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Winston H. Hsu</a>",
          "description": "In the field of domain adaptation, a trade-off exists between the model\nperformance and the number of target domain annotations. Active learning,\nmaximizing model performance with few informative labeled data, comes in handy\nfor such a scenario. In this work, we present D2ADA, a general active domain\nadaptation framework for semantic segmentation. To adapt the model to the\ntarget domain with minimum queried labels, we propose acquiring labels of the\nsamples with high probability density in the target domain yet with low\nprobability density in the source domain, complementary to the existing source\ndomain labeled data. To further facilitate labeling efficiency, we design a\ndynamic scheduling policy to adjust the labeling budgets between domain\nexploration and model uncertainty over time. Extensive experiments show that\nour method outperforms existing active learning and domain adaptation baselines\non two benchmarks, GTA5 -> Cityscapes and SYNTHIA -> Cityscapes. With less than\n5% target domain annotations, our method reaches comparable results with that\nof full supervision.",
          "link": "http://arxiv.org/abs/2202.06484",
          "publishedOn": "2022-04-02T00:47:19.827Z",
          "wordCount": null,
          "title": "D2ADA: Dynamic Density-aware Active Domain Adaptation for Semantic Segmentation. (arXiv:2202.06484v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17241",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hickman_R/0/1/0/all/0/1\">Riley J. Hickman</a>, <a href=\"http://arxiv.org/find/math/1/au:+Aldeghi_M/0/1/0/all/0/1\">Matteo Aldeghi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hase_F/0/1/0/all/0/1\">Florian H&#xe4;se</a>, <a href=\"http://arxiv.org/find/math/1/au:+Aspuru_Guzik_A/0/1/0/all/0/1\">Al&#xe1;n Aspuru-Guzik</a>",
          "description": "Optimization strategies driven by machine learning, such as Bayesian\noptimization, are being explored across experimental sciences as an efficient\nalternative to traditional design of experiment. When combined with automated\nlaboratory hardware and high-performance computing, these strategies enable\nnext-generation platforms for autonomous experimentation. However, the\npractical application of these approaches is hampered by a lack of flexible\nsoftware and algorithms tailored to the unique requirements of chemical\nresearch. One such aspect is the pervasive presence of constraints in the\nexperimental conditions when optimizing chemical processes or protocols, and in\nthe chemical space that is accessible when designing functional molecules or\nmaterials. Although many of these constraints are known a priori, they can be\ninterdependent, non-linear, and result in non-compact optimization domains. In\nthis work, we extend our experiment planning algorithms Phoenics and Gryffin\nsuch that they can handle arbitrary known constraints via an intuitive and\nflexible interface. We benchmark these extended algorithms on continuous and\ndiscrete test functions with a diverse set of constraints, demonstrating their\nflexibility and robustness. In addition, we illustrate their practical utility\nin two simulated chemical research scenarios: the optimization of the synthesis\nof o-xylenyl Buckminsterfullerene adducts under constrained flow conditions,\nand the design of redox active molecules for flow batteries under synthetic\naccessibility constraints. The tools developed constitute a simple, yet\nversatile strategy to enable model-based optimization with known experimental\nconstraints, contributing to its applicability as a core component of\nautonomous platforms for scientific discovery.",
          "link": "http://arxiv.org/abs/2203.17241",
          "publishedOn": "2022-04-02T00:47:19.825Z",
          "wordCount": null,
          "title": "Bayesian optimization with known experimental and design constraints for chemistry applications. (arXiv:2203.17241v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.09562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukhija_B/0/1/0/all/0/1\">Bhavya Sukhija</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turchetta_M/0/1/0/all/0/1\">Matteo Turchetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1\">David Lindner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trimpe_S/0/1/0/all/0/1\">Sebastian Trimpe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baumann_D/0/1/0/all/0/1\">Dominik Baumann</a>",
          "description": "Learning optimal control policies directly on physical systems is challenging\nsince even a single failure can lead to costly hardware damage. Most existing\nmodel-free learning methods that guarantee safety, i.e., no failures, during\nexploration are limited to local optima. A notable exception is the GoSafe\nalgorithm, which, unfortunately, cannot handle high-dimensional systems and\nhence cannot be applied to most real-world dynamical systems. This work\nproposes GoSafeOpt as the first algorithm that can safely discover globally\noptimal policies for high-dimensional systems while giving safety and\noptimality guarantees. We demonstrate the superiority of GoSafeOpt over\ncompeting model-free safe learning methods on a robot arm that would be\nprohibitive for GoSafe.",
          "link": "http://arxiv.org/abs/2201.09562",
          "publishedOn": "2022-04-02T00:47:19.824Z",
          "wordCount": null,
          "title": "GoSafeOpt: Scalable Safe Exploration for Global Optimization of Dynamical Systems. (arXiv:2201.09562v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rueegg_N/0/1/0/all/0/1\">Nadine Rueegg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuffi_S/0/1/0/all/0/1\">Silvia Zuffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1\">Konrad Schindler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1\">Michael J. Black</a>",
          "description": "Our goal is to recover the 3D shape and pose of dogs from a single image.\nThis is a challenging task because dogs exhibit a wide range of shapes and\nappearances, and are highly articulated. Recent work has proposed to directly\nregress the SMAL animal model, with additional limb scale parameters, from\nimages. Our method, called BARC (Breed-Augmented Regression using\nClassification), goes beyond prior work in several important ways. First, we\nmodify the SMAL shape space to be more appropriate for representing dog shape.\nBut, even with a better shape model, the problem of regressing dog shape from\nan image is still challenging because we lack paired images with 3D ground\ntruth. To compensate for the lack of paired data, we formulate novel losses\nthat exploit information about dog breeds. In particular, we exploit the fact\nthat dogs of the same breed have similar body shapes. We formulate a novel\nbreed similarity loss consisting of two parts: One term encourages the shape of\ndogs from the same breed to be more similar than dogs of different breeds. The\nsecond one, a breed classification loss, helps to produce recognizable\nbreed-specific shapes. Through ablation studies, we find that our breed losses\nsignificantly improve shape accuracy over a baseline without them. We also\ncompare BARC qualitatively to WLDO with a perceptual study and find that our\napproach produces dogs that are significantly more realistic. This work shows\nthat a-priori information about genetic similarity can help to compensate for\nthe lack of 3D training data. This concept may be applicable to other animal\nspecies or groups of species. Our code is publicly available for research\npurposes at https://barc.is.tue.mpg.de/.",
          "link": "http://arxiv.org/abs/2203.15536",
          "publishedOn": "2022-04-02T00:47:19.824Z",
          "wordCount": null,
          "title": "BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed Information. (arXiv:2203.15536v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.12970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rongjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuming He</a>",
          "description": "Scene Graph Generation (SGG) remains a challenging visual understanding task\ndue to its compositional property. Most previous works adopt a bottom-up\ntwo-stage or a point-based one-stage approach, which often suffers from high\ntime complexity or sub-optimal designs. In this work, we propose a novel SGG\nmethod to address the aforementioned issues, formulating the task as a\nbipartite graph construction problem. To solve the problem, we develop a\ntransformer-based end-to-end framework that first generates the entity and\npredicate proposal set, followed by inferring directed edges to form the\nrelation triplets. In particular, we develop a new entity-aware predicate\nrepresentation based on a structural predicate generator that leverages the\ncompositional property of relationships. Moreover, we design a graph assembling\nmodule to infer the connectivity of the bipartite scene graph based on our\nentity-aware structure, enabling us to generate the scene graph in an\nend-to-end manner. Extensive experimental results show that our design is able\nto achieve the state-of-the-art or comparable performance on two challenging\nbenchmarks, surpassing most of the existing approaches and enjoying higher\nefficiency in inference. We hope our model can serve as a strong baseline for\nthe Transformer-based scene graph generation. Code is available:\nhttps://github.com/Scarecrow0/SGTR",
          "link": "http://arxiv.org/abs/2112.12970",
          "publishedOn": "2022-04-02T00:47:19.823Z",
          "wordCount": null,
          "title": "SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.11594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1\">Haoran You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_T/0/1/0/all/0/1\">Tong Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "Graph Convolutional Networks (GCNs) have emerged as the state-of-the-art\ngraph learning model. However, it can be notoriously challenging to inference\nGCNs over large graph datasets, limiting their application to large real-world\ngraphs and hindering the exploration of deeper and more sophisticated GCN\ngraphs. This is because real-world graphs can be extremely large and sparse.\nFurthermore, the node degree of GCNs tends to follow the power-law distribution\nand therefore have highly irregular adjacency matrices, resulting in\nprohibitive inefficiencies in both data processing and movement and thus\nsubstantially limiting the achievable GCN acceleration efficiency. To this end,\nthis paper proposes a GCN algorithm and accelerator Co-Design framework dubbed\nGCoD which can largely alleviate the aforementioned GCN irregularity and boost\nGCNs' inference efficiency. Specifically, on the algorithm level, GCoD\nintegrates a split and conquer GCN training strategy that polarizes the graphs\nto be either denser or sparser in local neighborhoods without compromising the\nmodel accuracy, resulting in graph adjacency matrices that (mostly) have merely\ntwo levels of workload and enjoys largely enhanced regularity and thus ease of\nacceleration. On the hardware level, we further develop a dedicated two-pronged\naccelerator with a separated engine to process each of the aforementioned\ndenser and sparser workloads, further boosting the overall utilization and\nacceleration efficiency. Extensive experiments and ablation studies validate\nthat our GCoD consistently reduces the number of off-chip accesses, leading to\nspeedups of 15286x, 294x, 7.8x, and 2.5x as compared to CPUs, GPUs, and\nprior-art GCN accelerators including HyGCN and AWB-GCN, respectively, while\nmaintaining or even improving the task accuracy. Codes are available at\nhttps://github.com/RICE-EIC/GCoD.",
          "link": "http://arxiv.org/abs/2112.11594",
          "publishedOn": "2022-04-02T00:47:19.818Z",
          "wordCount": null,
          "title": "GCoD: Graph Convolutional Network Acceleration via Dedicated Algorithm and Accelerator Co-Design. (arXiv:2112.11594v2 [cs.AR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jian Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olszewski_K/0/1/0/all/0/1\">Kyle Olszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_M/0/1/0/all/0/1\">Menglei Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1\">Sergey Tulyakov</a>",
          "description": "Recent research explosion on Neural Radiance Field (NeRF) shows the\nencouraging potential to represent complex scenes with neural networks. One\nmajor drawback of NeRF is its prohibitive inference time: Rendering a single\npixel requires querying the NeRF network hundreds of times. To resolve it,\nexisting efforts mainly attempt to reduce the number of required sampled\npoints. However, the problem of iterative sampling still exists. On the other\nhand, Neural Light Field (NeLF) presents a more straightforward representation\nover NeRF in novel view synthesis -- the rendering of a pixel amounts to one\nsingle forward pass without ray-marching. In this work, we present a deep\nresidual MLP network (88 layers) to effectively learn the light field. We show\nthe key to successfully learning such a deep NeLF network is to have sufficient\ndata, for which we transfer the knowledge from a pre-trained NeRF model via\ndata distillation. Extensive experiments on both synthetic and real-world\nscenes show the merits of our method over other counterpart algorithms. On the\nsynthetic scenes, we achieve 26-35x FLOPs reduction (per camera ray) and 28-31x\nruntime speedup, meanwhile delivering significantly better (1.4-2.8 dB average\nPSNR improvement) rendering quality than NeRF without any customized\nimplementation tricks.",
          "link": "http://arxiv.org/abs/2203.17261",
          "publishedOn": "2022-04-02T00:47:19.817Z",
          "wordCount": null,
          "title": "R2L: Distilling Neural Radiance Field to Neural Light Field for Efficient Novel View Synthesis. (arXiv:2203.17261v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.02165",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bassi_P/0/1/0/all/0/1\">Pedro R. A. S. Bassi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Attux_R/0/1/0/all/0/1\">Romis Attux</a>",
          "description": "Objective: To propose novel SSVEP classification methodologies using deep\nneural networks (DNNs) and improve performances in single-channel and\nuser-independent brain-computer interfaces (BCIs) with small data lengths.\nApproach: We propose the utilization of filter banks (creating sub-band\ncomponents of the EEG signal) in conjunction with DNNs. In this context, we\ncreated three different models: a recurrent neural network (FBRNN) analyzing\nthe time domain, a 2D convolutional neural network (FBCNN-2D) processing\ncomplex spectrum features and a 3D convolutional neural network (FBCNN-3D)\nanalyzing complex spectrograms, which we introduce in this study as possible\ninput for SSVEP classification. We tested our neural networks on three open\ndatasets and conceived them so as not to require calibration from the final\nuser, simulating a user-independent BCI. Results: The DNNs with the filter\nbanks surpassed the accuracy of similar networks without this preprocessing\nstep by considerable margins, and they outperformed common SSVEP classification\nmethods (SVM and FBCCA) by even higher margins. Conclusion and significance:\nFilter banks allow different types of deep neural networks to more efficiently\nanalyze the harmonic components of SSVEP. Complex spectrograms carry more\ninformation than complex spectrum features and the magnitude spectrum, allowing\nthe FBCNN-3D to surpass the other CNNs. The performances obtained in the\nchallenging classification problems indicates a strong potential for the\nconstruction of portable, economical, fast and low-latency BCIs.",
          "link": "http://arxiv.org/abs/2109.02165",
          "publishedOn": "2022-04-02T00:47:19.760Z",
          "wordCount": null,
          "title": "FBDNN: Filter Banks and Deep Neural Networks for Portable and Fast Brain-Computer Interfaces. (arXiv:2109.02165v4 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendieta_M/0/1/0/all/0/1\">Matias Mendieta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Taojiannan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zhengming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>",
          "description": "Federated learning (FL) is a promising strategy for performing\nprivacy-preserving, distributed learning with a network of clients (i.e., edge\ndevices). However, the data distribution among clients is often non-IID in\nnature, making efficient optimization difficult. To alleviate this issue, many\nFL algorithms focus on mitigating the effects of data heterogeneity across\nclients by introducing a variety of proximal terms, some incurring considerable\ncompute and/or memory overheads, to restrain local updates with respect to the\nglobal model. Instead, we consider rethinking solutions to data heterogeneity\nin FL with a focus on local learning generality rather than proximal\nrestriction. To this end, we first present a systematic study informed by\nsecond-order indicators to better understand algorithm effectiveness in FL.\nInterestingly, we find that standard regularization methods are surprisingly\nstrong performers in mitigating data heterogeneity effects. Based on our\nfindings, we further propose a simple and effective method, FedAlign, to\novercome data heterogeneity and the pitfalls of previous methods. FedAlign\nachieves competitive accuracy with state-of-the-art FL methods across a variety\nof settings while minimizing computation and memory overhead. Code is available\nat https://github.com/mmendiet/FedAlign",
          "link": "http://arxiv.org/abs/2111.14213",
          "publishedOn": "2022-04-02T00:47:19.748Z",
          "wordCount": null,
          "title": "Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning. (arXiv:2111.14213v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ath_G/0/1/0/all/0/1\">George De Ath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahat_A/0/1/0/all/0/1\">Alma A. M. Rahat</a>",
          "description": "Optimisation problems often have multiple conflicting objectives that can be\ncomputationally and/or financially expensive. Mono-surrogate Bayesian\noptimisation (BO) is a popular model-based approach for optimising such\nblack-box functions. It combines objective values via scalarisation and builds\na Gaussian process (GP) surrogate of the scalarised values. The location which\nmaximises a cheap-to-query acquisition function is chosen as the next location\nto expensively evaluate. While BO is an effective strategy, the use of GPs is\nlimiting. Their performance decreases as the problem input dimensionality\nincreases, and their computational complexity scales cubically with the amount\nof data. To address these limitations, we extend previous work on BO by\ndensity-ratio estimation (BORE) to the multi-objective setting. BORE links the\ncomputation of the probability of improvement acquisition function to that of\nprobabilistic classification. This enables the use of state-of-the-art\nclassifiers in a BO-like framework. In this work we present MBORE:\nmulti-objective Bayesian optimisation by density-ratio estimation, and compare\nit to BO across a range of synthetic and real-world benchmarks. We find that\nMBORE performs as well as or better than BO on a wide variety of problems, and\nthat it outperforms BO on high-dimensional and real-world problems.",
          "link": "http://arxiv.org/abs/2203.16912",
          "publishedOn": "2022-04-02T00:47:19.737Z",
          "wordCount": null,
          "title": "MBORE: Multi-objective Bayesian Optimisation by Density-Ratio Estimation. (arXiv:2203.16912v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jing_X/0/1/0/all/0/1\">Xin Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parada_Cabaleiro_E/0/1/0/all/0/1\">Emilia Parada-Cabaleiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triantafyllopoulos_A/0/1/0/all/0/1\">Andreas Triantafyllopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Meishu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zijiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn W. Schuller</a>",
          "description": "Detecting COVID-19 from audio signals, such as breathing and coughing, can be\nused as a fast and efficient pre-testing method to reduce the virus\ntransmission. Due to the promising results of deep learning networks in\nmodelling time sequences, and since applications to rapidly identify COVID\nin-the-wild should require low computational effort, we present a\ntemporal-oriented broadcasting residual learning method that achieves efficient\ncomputation and high accuracy with a small model size. Based on the\nEfficientNet architecture, our novel network, named Temporal-oriented\nResNet~(TorNet), constitutes of a broadcasting learning block, i.e. the\nAlternating Broadcast (AB) Block, which contains several Broadcast Residual\nBlocks (BC ResBlocks) and a convolution layer. With the AB Block, the network\nobtains useful audio-temporal features and higher level embeddings effectively\nwith much less computation than Recurrent Neural Networks~(RNNs), typically\nused to model temporal information. TorNet achieves 72.2% Unweighted Average\nRecall (UAR) on the INTERPSEECH 2021 Computational Paralinguistics Challenge\nCOVID-19 cough Sub-Challenge, by this showing competitive results with a higher\ncomputational efficiency than other state-of-the-art alternatives.",
          "link": "http://arxiv.org/abs/2203.17012",
          "publishedOn": "2022-04-02T00:47:19.737Z",
          "wordCount": null,
          "title": "A Temporal-oriented Broadcast ResNet for COVID-19 Detection. (arXiv:2203.17012v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jalota_D/0/1/0/all/0/1\">Devansh Jalota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Karthik Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizan_N/0/1/0/all/0/1\">Navid Azizan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johari_R/0/1/0/all/0/1\">Ramesh Johari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "In transportation networks, users typically choose routes in a decentralized\nand self-interested manner to minimize their individual travel costs, which, in\npractice, often results in inefficient overall outcomes for society. As a\nresult, there has been a growing interest in designing road tolling schemes to\ncope with these efficiency losses and steer users toward a system-efficient\ntraffic pattern. However, the efficacy of road tolling schemes often relies on\nhaving access to complete information on users' trip attributes, such as their\norigin-destination (O-D) travel information and their values of time, which may\nnot be available in practice.\n\nMotivated by this practical consideration, we propose an online learning\napproach to set tolls in a traffic network to drive heterogeneous users with\ndifferent values of time toward a system-efficient traffic pattern. In\nparticular, we develop a simple yet effective algorithm that adjusts tolls at\neach time period solely based on the observed aggregate flows on the roads of\nthe network without relying on any additional trip attributes of users, thereby\npreserving user privacy. In the setting where the O-D pairs and values of time\nof users are drawn i.i.d. at each period, we show that our approach obtains an\nexpected regret and road capacity violation of $O(\\sqrt{T})$, where $T$ is the\nnumber of periods over which tolls are updated. Our regret guarantee is\nrelative to an offline oracle that has complete information on users' trip\nattributes. We further establish a $\\Omega(\\sqrt{T})$ lower bound on the regret\nof any algorithm, which establishes that our algorithm is optimal up to\nconstants. Finally, we demonstrate the superior performance of our approach\nrelative to several benchmarks on a real-world transportation network, thereby\nhighlighting its practical applicability.",
          "link": "http://arxiv.org/abs/2203.17150",
          "publishedOn": "2022-04-02T00:47:19.736Z",
          "wordCount": null,
          "title": "Online Learning for Traffic Routing under Unknown Preferences. (arXiv:2203.17150v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Flow-based generative models have shown an excellent ability to explicitly\nlearn the probability density function of data via a sequence of invertible\ntransformations. Yet, learning attentions in generative flows remains\nunderstudied, while it has made breakthroughs in other domains. To fill the\ngap, this paper introduces two types of invertible attention mechanisms, i.e.,\nmap-based and transformer-based attentions, for both unconditional and\nconditional generative flows. The key idea is to exploit a masked scheme of\nthese two attentions to learn long-range data dependencies in the context of\ngenerative flows. The masked scheme allows for invertible attention modules\nwith tractable Jacobian determinants, enabling its seamless integration at any\npositions of the flow-based models. The proposed attention mechanisms lead to\nmore efficient generative flows, due to their capability of modeling the\nlong-term data dependencies. Evaluation on multiple image synthesis tasks shows\nthat the proposed attention flows result in efficient models and compare\nfavorably against the state-of-the-art unconditional and conditional generative\nflows.",
          "link": "http://arxiv.org/abs/2106.03959",
          "publishedOn": "2022-04-02T00:47:19.732Z",
          "wordCount": null,
          "title": "Generative Flows with Invertible Attentions. (arXiv:2106.03959v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Da-Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "New classes arise frequently in our ever-changing world, e.g., emerging\ntopics in social media and new types of products in e-commerce. A model should\nrecognize new classes and meanwhile maintain discriminability over old classes.\nUnder severe circumstances, only limited novel instances are available to\nincrementally update the model. The task of recognizing few-shot new classes\nwithout forgetting old classes is called few-shot class-incremental learning\n(FSCIL). In this work, we propose a new paradigm for FSCIL based on\nmeta-learning by LearnIng Multi-phase Incremental Tasks (LIMIT), which\nsynthesizes fake FSCIL tasks from the base dataset. The data format of fake\ntasks is consistent with the `real' incremental tasks, and we can build a\ngeneralizable feature space for the unseen tasks through meta-learning.\nBesides, LIMIT also constructs a calibration module based on transformer, which\ncalibrates the old class classifiers and new class prototypes into the same\nscale and fills in the semantic gap. The calibration module also adaptively\ncontextualizes the instance-specific embedding with a set-to-set function.\nLIMIT efficiently adapts to new classes and meanwhile resists forgetting over\nold classes. Experiments on three benchmark datasets (CIFAR100, miniImageNet,\nand CUB200) and large-scale dataset, i.e., ImageNet ILSVRC2012 validate that\nLIMIT achieves state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2203.17030",
          "publishedOn": "2022-04-02T00:47:19.731Z",
          "wordCount": null,
          "title": "Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks. (arXiv:2203.17030v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Abigail J. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chesmore_G/0/1/0/all/0/1\">Grace E. Chesmore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocha_K/0/1/0/all/0/1\">Kyle A. Rocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farah_A/0/1/0/all/0/1\">Amanda Farah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sayeed_M/0/1/0/all/0/1\">Maryum Sayeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myles_J/0/1/0/all/0/1\">Justin Myles</a>",
          "description": "$\\textit{The Bachelor}$ is a reality TV dating show in which a single\nbachelor selects his wife from a pool of approximately 30 female contestants\nover eight weeks of filming (American Broadcasting Company 2002). We collected\nthe following data on all 422 contestants that participated in seasons 11\nthrough 25: their Age, Hometown, Career, Race, Week they got their first 1-on-1\ndate, whether they got the first impression rose, and what \"place\" they ended\nup getting. We then trained three machine learning models to predict the ideal\ncharacteristics of a successful contestant on $\\textit{The Bachelor}$. The\nthree algorithms that we tested were: random forest classification, neural\nnetworks, and linear regression. We found consistency across all three models,\nalthough the neural network performed the best overall. Our models found that a\nwoman has the highest probability of progressing far on $\\textit{The Bachelor}$\nif she is: 26 years old, white, from the Northwest, works as an dancer,\nreceived a 1-on-1 in week 6, and did not receive the First Impression Rose. Our\nmethodology is broadly applicable to all romantic reality television, and our\nresults will inform future $\\textit{The Bachelor}$ production and contestant\nstrategies. While our models were relatively successful, we still encountered\nhigh misclassification rates. This may be because: (1) Our training dataset had\nfewer than 400 points or (2) Our models were too simple to parameterize the\ncomplex romantic connections contestants forge over the course of a season.",
          "link": "http://arxiv.org/abs/2203.16648",
          "publishedOn": "2022-04-02T00:47:19.728Z",
          "wordCount": null,
          "title": "Predicting Winners of the Reality TV Dating Show $\\textit{The Bachelor}$ Using Machine Learning Algorithms. (arXiv:2203.16648v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sungyong Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesemer_S/0/1/0/all/0/1\">Sam Griesemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Physics-informed machine learning (PIML), referring to the combination of\nprior knowledge of physics, which is the high level abstraction of natural\nphenomenons and human behaviours in the long history, with data-driven machine\nlearning models, has emerged as an effective way to mitigate the shortage of\ntraining data, to increase models' generalizability and to ensure the physical\nplausibility of results. In this paper, we survey an abundant number of recent\nworks in PIML and summarize them from three aspects: (1) motivations of PIML,\n(2) physics knowledge in PIML, (3) methods of physics knowledge integration in\nPIML. We also discuss current challenges and corresponding research\nopportunities in PIML.",
          "link": "http://arxiv.org/abs/2203.16797",
          "publishedOn": "2022-04-02T00:47:19.728Z",
          "wordCount": null,
          "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed Machine Learning. (arXiv:2203.16797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17226",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ross_I/0/1/0/all/0/1\">I. M. Ross</a>",
          "description": "Nesterov's accelerated gradient algorithm is derived from first principles.\nThe first principles are founded on the recently-developed optimal control\ntheory for optimization. This theory frames an optimization problem as an\noptimal control problem whose trajectories generate various continuous-time\nalgorithms. The algorithmic trajectories satisfy the necessary conditions for\noptimal control. The necessary conditions produce a controllable dynamical\nsystem for accelerated optimization. Stabilizing this system via a quadratic\ncontrol Lyapunov function generates an ordinary differential equation. An Euler\ndiscretization of the resulting differential equation produces Nesterov's\nalgorithm. In this context, this result solves the purported mystery\nsurrounding the algorithm.",
          "link": "http://arxiv.org/abs/2203.17226",
          "publishedOn": "2022-04-02T00:47:19.727Z",
          "wordCount": null,
          "title": "A Derivation of Nesterov's Accelerated Gradient Algorithm from Optimal Control Theory. (arXiv:2203.17226v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elbanna_G/0/1/0/all/0/1\">Gasser Elbanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biryukov_A/0/1/0/all/0/1\">Alice Biryukov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheidwasser_Clow_N/0/1/0/all/0/1\">Neil Scheidwasser-Clow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orlandic_L/0/1/0/all/0/1\">Lara Orlandic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mainar_P/0/1/0/all/0/1\">Pablo Mainar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kegler_M/0/1/0/all/0/1\">Mikolaj Kegler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beckmann_P/0/1/0/all/0/1\">Pierre Beckmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cernak_M/0/1/0/all/0/1\">Milos Cernak</a>",
          "description": "As a neurophysiological response to threat or adverse conditions, stress can\naffect cognition, emotion and behaviour with potentially detrimental effects on\nhealth in the case of sustained exposure. Since the affective content of speech\nis inherently modulated by an individual's physical and mental state, a\nsubstantial body of research has been devoted to the study of paralinguistic\ncorrelates of stress-inducing task load. Historically, voice stress analysis\n(VSA) has been conducted using conventional digital signal processing (DSP)\ntechniques. Despite the development of modern methods based on deep neural\nnetworks (DNNs), accurately detecting stress in speech remains difficult due to\nthe wide variety of stressors and considerable variability in the individual\nstress perception. To that end, we introduce a set of five datasets for task\nload detection in speech. The voice recordings were collected as either\ncognitive or physical stress was induced in the cohort of volunteers, with a\ncumulative number of more than a hundred speakers. We used the datasets to\ndesign and evaluate a novel self-supervised audio representation that leverages\nthe effectiveness of handcrafted features (DSP-based) and the complexity of\ndata-driven DNN representations. Notably, the proposed approach outperformed\nboth extensive handcrafted feature sets and novel DNN-based audio\nrepresentation learning approaches.",
          "link": "http://arxiv.org/abs/2203.16637",
          "publishedOn": "2022-04-02T00:47:19.726Z",
          "wordCount": null,
          "title": "Hybrid Handcrafted and Learnable Audio Representation for Analysis of Speech Under Cognitive and Physical Load. (arXiv:2203.16637v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_M/0/1/0/all/0/1\">Meiyu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhe Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Junping Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feifei_K/0/1/0/all/0/1\">Kou Feifei</a>",
          "description": "Learning knowledge representation of scientific paper data is a problem to be\nsolved, and how to learn the representation of paper nodes in scientific paper\nheterogeneous network is the core to solve this problem. This paper proposes an\nunsupervised cluster-level scientific paper heterogeneous graph node\nrepresentation learning method (UCHL), aiming at obtaining the representation\nof nodes (authors, institutions, papers, etc.) in the heterogeneous graph of\nscientific papers. Based on the heterogeneous graph representation, this paper\nperforms link prediction on the entire heterogeneous graph and obtains the\nrelationship between the edges of the nodes, that is, the relationship between\npapers and papers. Experiments results show that the proposed method achieves\nexcellent performance on multiple evaluation metrics on real scientific paper\ndatasets.",
          "link": "http://arxiv.org/abs/2203.16751",
          "publishedOn": "2022-04-02T00:47:19.720Z",
          "wordCount": null,
          "title": "An unsupervised cluster-level based method for learning node representations of heterogeneous graphs in scientific papers. (arXiv:2203.16751v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xixin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shoukang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xunying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>",
          "description": "Deep neural networks have brought significant advancements to speech emotion\nrecognition (SER). However, the architecture design in SER is mainly based on\nexpert knowledge and empirical (trial-and-error) evaluations, which is\ntime-consuming and resource intensive. In this paper, we propose to apply\nneural architecture search (NAS) techniques to automatically configure the SER\nmodels. To accelerate the candidate architecture optimization, we propose a\nuniform path dropout strategy to encourage all candidate architecture\noperations to be equally optimized. Experimental results of two different\nneural structures on IEMOCAP show that NAS can improve SER performance (54.89\\%\nto 56.28\\%) while maintaining model parameter sizes. The proposed dropout\nstrategy also shows superiority over the previous approaches.",
          "link": "http://arxiv.org/abs/2203.16928",
          "publishedOn": "2022-04-02T00:47:19.716Z",
          "wordCount": null,
          "title": "Neural Architecture Search for Speech Emotion Recognition. (arXiv:2203.16928v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1\">Guanxing Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Hao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xinghao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_X/0/1/0/all/0/1\">Xiaotong Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbas_S/0/1/0/all/0/1\">Saqlain Abbas</a>",
          "description": "Acoustic source localization has been applied in different fields, such as\naeronautics and ocean science, generally using multiple microphones array data\nto reconstruct the source location. However, the model-based beamforming\nmethods fail to achieve the high-resolution of conventional beamforming maps.\nDeep neural networks are also appropriate to locate the sound source, but in\ngeneral, these methods with complex network structures are hard to be\nrecognized by hardware. In this paper, a novel neural network, termed the\nAcoustic-Net, is proposed to locate and quantify the sound source simply using\nthe original signals. The experiments demonstrate that the proposed method\nsignificantly improves the accuracy of sound source prediction and the\ncomputing speed, which may generalize well to real data. The code and trained\nmodels are available at https://github.com/JoaquinChou/Acoustic-Net.",
          "link": "http://arxiv.org/abs/2203.16988",
          "publishedOn": "2022-04-02T00:47:19.716Z",
          "wordCount": null,
          "title": "Acoustic-Net: A Novel Neural Network for Sound Localization and Quantification. (arXiv:2203.16988v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1\">Chlo&#xe9; Clavel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labeau_M/0/1/0/all/0/1\">Matthieu Labeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassell_J/0/1/0/all/0/1\">Justine Cassell</a>",
          "description": "Some exciting new approaches to neural architectures for the analysis of\nconversation have been introduced over the past couple of years. These include\nneural architectures for detecting emotion, dialogue acts, and sentiment\npolarity. They take advantage of some of the key attributes of contemporary\nmachine learning, such as recurrent neural networks with attention mechanisms\nand transformer-based approaches. However, while the architectures themselves\nare extremely promising, the phenomena they have been applied to to date are\nbut a small part of what makes conversation engaging. In this paper we survey\nthese neural architectures and what they have been applied to. On the basis of\nthe social science literature, we then describe what we believe to be the most\nfundamental and definitional feature of conversation, which is its\nco-construction over time by two or more interlocutors. We discuss how neural\narchitectures of the sort surveyed could profitably be applied to these more\nfundamental aspects of conversation, and what this buys us in terms of a better\nanalysis of conversation and even, in the longer term, a better way of\ngenerating conversation for a conversational system.",
          "link": "http://arxiv.org/abs/2203.16891",
          "publishedOn": "2022-04-02T00:47:19.714Z",
          "wordCount": null,
          "title": "A survey of neural models for the automatic analysis of conversation: Towards a better integration of the social sciences. (arXiv:2203.16891v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanzi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>",
          "description": "In recent years, hypergraph learning has attracted great attention due to its\ncapacity in representing complex and high-order relationships. However, current\nneural network approaches designed for hypergraphs are mostly shallow, thus\nlimiting their ability to extract information from high-order neighbors. In\nthis paper, we show both theoretically and empirically, that the performance of\nhypergraph neural networks does not improve as the number of layers increases,\nwhich is known as the over-smoothing problem. To tackle this issue, we develop\na new deep hypergraph convolutional network called Deep-HGCN, which can\nmaintain the heterogeneity of node representation in deep layers. Specifically,\nwe prove that a $k$-layer Deep-HGCN simulates a polynomial filter of order $k$\nwith arbitrary coefficients, which can relieve the problem of over-smoothing.\nExperimental results on various datasets demonstrate the superior performance\nof the proposed model comparing to the state-of-the-art hypergraph learning\napproaches.",
          "link": "http://arxiv.org/abs/2203.17159",
          "publishedOn": "2022-04-02T00:47:19.714Z",
          "wordCount": null,
          "title": "Preventing Over-Smoothing for Hypergraph Neural Networks. (arXiv:2203.17159v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1\">Ivan Y. Tyukin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_O/0/1/0/all/0/1\">Oliver Sutton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1\">Alexander N. Gorban</a>",
          "description": "In this work we consider the problem of data classification in post-classical\nsettings were the number of training examples consists of mere few data points.\nWe explore the phenomenon and reveal key relationships between dimensionality\nof AI model's feature space, non-degeneracy of data distributions, and the\nmodel's generalisation capabilities. The main thrust of our present analysis is\non the influence of nonlinear feature transformations mapping original data\ninto higher- and possibly infinite-dimensional spaces on the resulting model's\ngeneralisation capabilities. Subject to appropriate assumptions, we establish\nnew relationships between intrinsic dimensions of the transformed data and the\nprobabilities to learn successfully from few presentations.",
          "link": "http://arxiv.org/abs/2203.16935",
          "publishedOn": "2022-04-02T00:47:19.694Z",
          "wordCount": null,
          "title": "Learning from few examples with nonlinear feature maps. (arXiv:2203.16935v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Avinash Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikuesan_R/0/1/0/all/0/1\">Richard Adeyemi Ikuesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venter_H/0/1/0/all/0/1\">Hein Venter</a>",
          "description": "Ransomware attacks have increased significantly in recent years, causing\ngreat destruction and damage to critical systems and business operations.\nAttackers are unfailingly finding innovative ways to bypass detection\nmechanisms, whichencouraged the adoption of artificial intelligence. However,\nmost research summarizes the general features of AI and induces many false\npositives, as the behavior of ransomware constantly differs to bypass\ndetection. Focusing on the key indicating features of ransomware becomes vital\nas this guides the investigator to the inner workings and main function of\nransomware itself. By utilizing access privileges in process memory, the main\nfunction of the ransomware can be detected more easily and accurately.\nFurthermore, new signatures and fingerprints of ransomware families can be\nidentified to classify novel ransomware attacks correctly. The current research\nused the process memory access privileges of the different memory regions of\nthe behavior of an executable to quickly determine its intent before serious\nharm can occur. To achieve this aim, several well-known machine learning\nalgorithms were explored with an accuracy range of 81.38 to 96.28 percents. The\nstudy thus confirms the feasibility of utilizing process memory as a detection\nmechanism for ransomware.",
          "link": "http://arxiv.org/abs/2203.16871",
          "publishedOn": "2022-04-02T00:47:19.684Z",
          "wordCount": null,
          "title": "Ransomware Detection using Process Memory. (arXiv:2203.16871v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16874",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoli Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>",
          "description": "Many complex real world phenomena exhibit abrupt, intermittent or jumping\nbehaviors, which are more suitable to be described by stochastic differential\nequations under non-Gaussian L\\'evy noise. Among these complex phenomena, the\nmost likely transition paths between metastable states are important since\nthese rare events may have high impact in certain scenarios. Based on the large\ndeviation principle, the most likely transition path could be treated as the\nminimizer of the rate function upon paths that connect two points. One of the\nchallenges to calculate the most likely transition path for stochastic\ndynamical systems under non-Gaussian L\\'evy noise is that the associated rate\nfunction can not be explicitly expressed by paths. For this reason, we\nformulate an optimal control problem to obtain the optimal state as the most\nlikely transition path. We then develop a neural network method to solve this\nissue. Several experiments are investigated for both Gaussian and non-Gaussian\ncases.",
          "link": "http://arxiv.org/abs/2203.16874",
          "publishedOn": "2022-04-02T00:47:19.675Z",
          "wordCount": null,
          "title": "An Optimal Control Method to Compute the Most Likely Transition Path for Stochastic Dynamical Systems with Jumps. (arXiv:2203.16874v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16711",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Najafi_K/0/1/0/all/0/1\">Khadijeh Najafi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sharma_K/0/1/0/all/0/1\">Kunal Sharma</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1\">Francesco Tacchino</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jiang_L/0/1/0/all/0/1\">Liang Jiang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Mezzacapo_A/0/1/0/all/0/1\">Antonio Mezzacapo</a>",
          "description": "Parametrized quantum circuits can be used as quantum neural networks and have\nthe potential to outperform their classical counterparts when trained for\naddressing learning problems. To date, much of the results on their performance\non practical problems are heuristic in nature. In particular, the convergence\nrate for the training of quantum neural networks is not fully understood. Here,\nwe analyze the dynamics of gradient descent for the training error of a class\nof variational quantum machine learning models. We define wide quantum neural\nnetworks as parameterized quantum circuits in the limit of a large number of\nqubits and variational parameters. We then find a simple analytic formula that\ncaptures the average behavior of their loss function and discuss the\nconsequences of our findings. For example, for random quantum circuits, we\npredict and characterize an exponential decay of the residual training error as\na function of the parameters of the system. We finally validate our analytic\nresults with numerical experiments.",
          "link": "http://arxiv.org/abs/2203.16711",
          "publishedOn": "2022-04-02T00:47:19.645Z",
          "wordCount": null,
          "title": "An analytic theory for the dynamics of wide quantum neural networks. (arXiv:2203.16711v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16852",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lim_D/0/1/0/all/0/1\">Dan Lim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_S/0/1/0/all/0/1\">Sunghee Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_E/0/1/0/all/0/1\">Eesung Kim</a>",
          "description": "In neural text-to-speech (TTS), two-stage system or a cascade of separately\nlearned models have shown synthesis quality close to human speech. For example,\nFastSpeech2 transforms an input text to a mel-spectrogram and then HiFi-GAN\ngenerates a raw waveform from a mel-spectogram where they are called an\nacoustic feature generator and a neural vocoder respectively. However, their\ntraining pipeline is somewhat cumbersome in that it requires a fine-tuning and\nan accurate speech-text alignment for optimal performance. In this work, we\npresent end-to-end text-to-speech (E2E-TTS) model which has a simplified\ntraining pipeline and outperforms a cascade of separately learned models.\nSpecifically, our proposed model is jointly trained FastSpeech2 and HiFi-GAN\nwith an alignment module. Since there is no acoustic feature mismatch between\ntraining and inference, it does not requires fine-tuning. Furthermore, we\nremove dependency on an external speech-text alignment tool by adopting an\nalignment learning objective in our joint training framework. Experiments on\nLJSpeech corpus shows that the proposed model outperforms publicly available,\nstate-of-the-art implementations of ESPNet2-TTS on subjective evaluation (MOS)\nand some objective evaluations.",
          "link": "http://arxiv.org/abs/2203.16852",
          "publishedOn": "2022-04-02T00:47:19.632Z",
          "wordCount": null,
          "title": "JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech. (arXiv:2203.16852v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16642",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Goerigk_M/0/1/0/all/0/1\">Marc Goerigk</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kurtz_J/0/1/0/all/0/1\">Jannis Kurtz</a>",
          "description": "In this work we study robust one- and two-stage problems with discrete\nuncertainty sets which are known to be hard to solve even if the underlying\ndeterministic problem is easy. Popular solution methods iteratively generate\nscenario constraints and possibly second-stage variables. This way, by solving\na sequence of smaller problems, it is often possible to avoid the complexity of\nconsidering all scenarios simultaneously. A key ingredient for the performance\nof the iterative methods is a good selection of start scenarios. In this paper\nwe propose a data-driven heuristic to seed the iterative solution method with a\nset of starting scenarios that provide a strong lower bound early in the\nprocess, and result in considerably smaller overall solution times compared to\nother benchmark methods. Our heuristic learns the relevance of a scenario by\nextracting information from training data based on a combined similarity\nmeasure between robust problem instances and single scenarios. Our experiments\nshow that predicting even a small number of good start scenarios by our method\ncan considerably reduce the computation time of the iterative methods.",
          "link": "http://arxiv.org/abs/2203.16642",
          "publishedOn": "2022-04-02T00:47:19.618Z",
          "wordCount": null,
          "title": "Data-driven Prediction of Relevant Scenarios for Robust Optimization. (arXiv:2203.16642v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17164",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Bondar_D/0/1/0/all/0/1\">Denys I. Bondar</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Popovych_Z/0/1/0/all/0/1\">Zakhar Popovych</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jacobs_K/0/1/0/all/0/1\">Kurt Jacobs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Korpas_G/0/1/0/all/0/1\">Georgios Korpas</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Marecek_J/0/1/0/all/0/1\">Jakub Marecek</a>",
          "description": "Current quantum devices suffer imperfections as a result of fabrication, as\nwell as noise and dissipation as a result of coupling to their immediate\nenvironments. Because of this, it is often difficult to obtain accurate models\nof their dynamics from first principles. An alternative is to extract such\nmodels from time-series measurements of their behavior. Here, we formulate this\nsystem-identification problem as a polynomial optimization problem. Recent\nadvances in optimization have provided globally convergent solvers for this\nclass of problems, which using our formulation prove estimates of the Kraus map\nor the Lindblad equation. We include an overview of the state-of-the-art\nalgorithms, bounds, and convergence rates, and illustrate the use of this\napproach to modeling open quantum systems.",
          "link": "http://arxiv.org/abs/2203.17164",
          "publishedOn": "2022-04-02T00:47:19.521Z",
          "wordCount": null,
          "title": "Recovering models of open quantum systems from data via polynomial optimization: Towards globally convergent quantum system identification. (arXiv:2203.17164v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16749",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Koizumi_Y/0/1/0/all/0/1\">Yuma Koizumi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zen_H/0/1/0/all/0/1\">Heiga Zen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yatabe_K/0/1/0/all/0/1\">Kohei Yatabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_N/0/1/0/all/0/1\">Nanxin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bacchiani_M/0/1/0/all/0/1\">Michiel Bacchiani</a>",
          "description": "Neural vocoder using denoising diffusion probabilistic model (DDPM) has been\nimproved by adaptation of the diffusion noise distribution to given acoustic\nfeatures. In this study, we propose SpecGrad that adapts the diffusion noise so\nthat its time-varying spectral envelope becomes close to the conditioning\nlog-mel spectrogram. This adaptation by time-varying filtering improves the\nsound quality especially in the high-frequency bands. It is processed in the\ntime-frequency domain to keep the computational cost almost the same as the\nconventional DDPM-based neural vocoders. Experimental results showed that\nSpecGrad generates higher-fidelity speech waveform than conventional DDPM-based\nneural vocoders in both analysis-synthesis and speech enhancement scenarios.\nAudio demos are available at wavegrad.github.io/specgrad/.",
          "link": "http://arxiv.org/abs/2203.16749",
          "publishedOn": "2022-04-02T00:47:19.470Z",
          "wordCount": null,
          "title": "SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping. (arXiv:2203.16749v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1\">Nian Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhengyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanchet_J/0/1/0/all/0/1\">Jose Blanchet</a>",
          "description": "Policy learning using historical observational data is an important problem\nthat has found widespread applications. Examples include selecting offers,\nprices, advertisements to send to customers, as well as selecting which\nmedication to prescribe to a patient. However, existing literature rests on the\ncrucial assumption that the future environment where the learned policy will be\ndeployed is the same as the past environment that has generated the data -- an\nassumption that is often false or too coarse an approximation. In this paper,\nwe lift this assumption and aim to learn a distributionally robust policy with\nincomplete observational data. We first present a policy evaluation procedure\nthat allows us to assess how well the policy does under the worst-case\nenvironment shift. We then establish a central limit theorem type guarantee for\nthis proposed policy evaluation scheme. Leveraging this evaluation scheme, we\nfurther propose a novel learning algorithm that is able to learn a policy that\nis robust to adversarial perturbations and unknown covariate shifts with a\nperformance guarantee based on the theory of uniform convergence. Finally, we\nempirically test the effectiveness of our proposed algorithm in synthetic\ndatasets and demonstrate that it provides the robustness that is missing using\nstandard policy learning algorithms. We conclude the paper by providing a\ncomprehensive application of our methods in the context of a real-world voting\ndataset.",
          "link": "http://arxiv.org/abs/2006.05630",
          "publishedOn": "2022-04-02T00:47:19.450Z",
          "wordCount": null,
          "title": "Distributional Robust Batch Contextual Bandits. (arXiv:2006.05630v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamel_C/0/1/0/all/0/1\">Craig M. Hamel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_K/0/1/0/all/0/1\">Kevin N. Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramer_S/0/1/0/all/0/1\">Sharlotte L.B. Kramer</a>",
          "description": "The calibration of solid constitutive models with full-field experimental\ndata is a long-standing challenge, especially in materials which undergo large\ndeformation. In this paper, we propose a physics-informed deep-learning\nframework for the discovery of constitutive model parameterizations given\nfull-field displacement data and global force-displacement data. Contrary to\nthe majority of recent literature in this field, we work with the weak form of\nthe governing equations rather than the strong form to impose physical\nconstraints upon the neural network predictions. The approach presented in this\npaper is computationally efficient, suitable for irregular geometric domains,\nand readily ingests displacement data without the need for interpolation onto a\ncomputational grid. A selection of canonical hyperelastic materials models\nsuitable for different material classes is considered including the\nNeo-Hookean, Gent, and Blatz-Ko constitutive models as exemplars for general\nhyperelastic behavior, polymer behavior with lock-up, and compressible foam\nbehavior respectively. We demonstrate that physics informed machine learning is\nan enabling technology and may shift the paradigm of how full-field\nexperimental data is utilized to calibrate constitutive models under finite\ndeformations.",
          "link": "http://arxiv.org/abs/2203.16577",
          "publishedOn": "2022-04-02T00:47:18.841Z",
          "wordCount": 614,
          "title": "Calibrating constitutive models with full-field data via physics informed neural networks. (arXiv:2203.16577v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aru_J/0/1/0/all/0/1\">Jaan Aru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labash_A/0/1/0/all/0/1\">Aqeel Labash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corcoll_O/0/1/0/all/0/1\">Oriol Corcoll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_R/0/1/0/all/0/1\">Raul Vicente</a>",
          "description": "Theory of Mind is an essential ability of humans to infer the mental states\nof others. Here we provide a coherent summary of the potential, current\nprogress, and problems of deep learning approaches to Theory of Mind. We\nhighlight that many current findings can be explained through shortcuts. These\nshortcuts arise because the tasks used to investigate Theory of Mind in deep\nlearning systems have been too narrow. Thus, we encourage researchers to\ninvestigate Theory of Mind in complex open-ended environments. Furthermore, to\ninspire future deep learning systems we provide a concise overview of prior\nwork done in humans. We further argue that when studying Theory of Mind with\ndeep learning, the research's main focus and contribution ought to be opening\nup the network's representations. We recommend researchers use tools from the\nfield of interpretability of AI to study the relationship between different\nnetwork components and aspects of Theory of Mind.",
          "link": "http://arxiv.org/abs/2203.16540",
          "publishedOn": "2022-04-02T00:47:18.834Z",
          "wordCount": 602,
          "title": "Mind the gap: Challenges of deep learning approaches to Theory of Mind. (arXiv:2203.16540v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>",
          "description": "Many important machine learning applications involve regularized nonconvex\nbi-level optimization. However, the existing gradient-based bi-level\noptimization algorithms cannot handle nonconvex or nonsmooth regularizers, and\nthey suffer from a high computation complexity in nonconvex bi-level\noptimization. In this work, we study a proximal gradient-type algorithm that\nadopts the approximate implicit differentiation (AID) scheme for nonconvex\nbi-level optimization with possibly nonconvex and nonsmooth regularizers. In\nparticular, the algorithm applies the Nesterov's momentum to accelerate the\ncomputation of the implicit gradient involved in AID. We provide a\ncomprehensive analysis of the global convergence properties of this algorithm\nthrough identifying its intrinsic potential function. In particular, we\nformally establish the convergence of the model parameters to a critical point\nof the bi-level problem, and obtain an improved computation complexity\n$\\mathcal{O}(\\kappa^{3.5}\\epsilon^{-2})$ over the state-of-the-art result.\nMoreover, we analyze the asymptotic convergence rates of this algorithm under a\nclass of local nonconvex geometries characterized by a {\\L}ojasiewicz-type\ngradient inequality. Experiment on hyper-parameter optimization demonstrates\nthe effectiveness of our algorithm.",
          "link": "http://arxiv.org/abs/2203.16615",
          "publishedOn": "2022-04-02T00:47:18.783Z",
          "wordCount": 617,
          "title": "A Fast and Convergent Proximal Algorithm for Regularized Nonconvex and Nonsmooth Bi-level Optimization. (arXiv:2203.16615v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bombari_S/0/1/0/all/0/1\">Simone Bombari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yusheng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1\">Kunwar Yashraj Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appalaraju_S/0/1/0/all/0/1\">Srikar Appalaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_V/0/1/0/all/0/1\">Vijay Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Memorization of the relation between entities in a dataset can lead to\nprivacy issues when using a trained model for question answering. We introduce\nRelational Memorization (RM) to understand, quantify and control this\nphenomenon. While bounding general memorization can have detrimental effects on\nthe performance of a trained model, bounding RM does not prevent effective\nlearning. The difference is most pronounced when the data distribution is\nlong-tailed, with many queries having only few training examples: Impeding\ngeneral memorization prevents effective learning, while impeding only\nrelational memorization still allows learning general properties of the\nunderlying concepts. We formalize the notion of Relational Privacy (RP) and,\ninspired by Differential Privacy (DP), we provide a possible definition of\nDifferential Relational Privacy (DrP). These notions can be used to describe\nand compute bounds on the amount of RM in a trained model. We illustrate\nRelational Privacy concepts in experiments with large-scale models for Question\nAnswering.",
          "link": "http://arxiv.org/abs/2203.16701",
          "publishedOn": "2022-04-02T00:47:18.726Z",
          "wordCount": 609,
          "title": "Towards Differential Relational Privacy and its use in Question Answering. (arXiv:2203.16701v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1\">Aldo Gael Carranza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Many popular contextual bandit algorithms estimate reward models to inform\ndecision making. However, true rewards can contain action-independent\nredundancies that are not relevant for decision making and only increase the\nstatistical complexity of accurate estimation. It is sufficient and more\ndata-efficient to estimate the simplest function that explains the reward\ndifferences between actions, that is, the heterogeneous treatment effect,\ncommonly understood to be more structured and simpler than the reward.\nMotivated by this observation, building on recent work on oracle-based\nalgorithms, we design a statistically optimal and computationally efficient\nalgorithm using heterogeneous treatment effect estimation oracles. Our results\nprovide the first universal reduction of contextual bandits to a\ngeneral-purpose heterogeneous treatment effect estimation method. We show that\nour approach is more robust to model misspecification than reward estimation\nmethods based on squared error regression oracles. Experimentally, we show the\nbenefits of heterogeneous treatment effect estimation in contextual bandits\nover reward estimation.",
          "link": "http://arxiv.org/abs/2203.16668",
          "publishedOn": "2022-04-02T00:47:18.378Z",
          "wordCount": 601,
          "title": "Flexible and Efficient Contextual Bandits with Heterogeneous Treatment Effect Oracle. (arXiv:2203.16668v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16707",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Yao_J/0/1/0/all/0/1\">Jiahao Yao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_H/0/1/0/all/0/1\">Haoya Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bukov_M/0/1/0/all/0/1\">Marin Bukov</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lin_L/0/1/0/all/0/1\">Lin Lin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ying_L/0/1/0/all/0/1\">Lexing Ying</a>",
          "description": "Variational quantum algorithms stand at the forefront of simulations on\nnear-term and future fault-tolerant quantum devices. While most variational\nquantum algorithms involve only continuous optimization variables, the\nrepresentational power of the variational ansatz can sometimes be significantly\nenhanced by adding certain discrete optimization variables, as is exemplified\nby the generalized quantum approximate optimization algorithm (QAOA). However,\nthe hybrid discrete-continuous optimization problem in the generalized QAOA\nposes a challenge to the optimization. We propose a new algorithm called\nMCTS-QAOA, which combines a Monte Carlo tree search method with an improved\nnatural policy gradient solver to optimize the discrete and continuous\nvariables in the quantum circuit, respectively. We find that MCTS-QAOA has\nexcellent noise-resilience properties and outperforms prior algorithms in\nchallenging instances of the generalized QAOA.",
          "link": "http://arxiv.org/abs/2203.16707",
          "publishedOn": "2022-04-02T00:47:18.372Z",
          "wordCount": 577,
          "title": "Monte Carlo Tree Search based Hybrid Optimization of Variational Quantum Circuits. (arXiv:2203.16707v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olivier_R/0/1/0/all/0/1\">Raphael Olivier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>",
          "description": "Like many other tasks involving neural networks, Speech Recognition models\nare vulnerable to adversarial attacks. However recent research has pointed out\ndifferences between attacks and defenses on ASR models compared to image\nmodels. Improving the robustness of ASR models requires a paradigm shift from\nevaluating attacks on one or a few models to a systemic approach in evaluation.\nWe lay the ground for such research by evaluating on various architectures a\nrepresentative set of adversarial attacks: targeted and untargeted,\noptimization and speech processing-based, white-box, black-box and targeted\nattacks. Our results show that the relative strengths of different attack\nalgorithms vary considerably when changing the model architecture, and that the\nresults of some attacks are not to be blindly trusted. They also indicate that\ntraining choices such as self-supervised pretraining can significantly impact\nrobustness by enabling transferable perturbations. We release our source code\nas a package that should help future research in evaluating their attacks and\ndefenses.",
          "link": "http://arxiv.org/abs/2203.16536",
          "publishedOn": "2022-04-02T00:47:18.330Z",
          "wordCount": 616,
          "title": "Recent improvements of ASR models in the face of adversarial attacks. (arXiv:2203.16536v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cacciapuoti_R/0/1/0/all/0/1\">Rosalba Cacciapuoti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAmore_L/0/1/0/all/0/1\">Luisa D&#x27;Amore</a>",
          "description": "We focus on Partial Differential Equation (PDE) based Data Assimilatio\nproblems (DA) solved by means of variational approaches and Kalman filter\nalgorithm. Recently, we presented a Domain Decomposition framework (we call it\nDD-DA, for short) performing a decomposition of the whole physical domain along\nspace and time directions, and joining the idea of Schwarz' methods and\nparallel in time approaches. For effective parallelization of DD-DA algorithms,\nthe computational load assigned to subdomains must be equally distributed.\nUsually computational cost is proportional to the amount of data entities\nassigned to partitions. Good quality partitioning also requires the volume of\ncommunication during calculation to be kept at its minimum. In order to deal\nwith DD-DA problems where the observations are nonuniformly distributed and\ngeneral sparse, in the present work we employ a parallel load balancing\nalgorithm based on adaptive and dynamic defining of boundaries of DD -- which\nis aimed to balance workload according to data location. We call it DyDD. As\nthe numerical model underlying DA problems arising from the so-called\ndiscretize-then-optimize approach is the constrained least square model (CLS),\nwe will use CLS as a reference state estimation problem and we validate DyDD on\ndifferent scenarios.",
          "link": "http://arxiv.org/abs/2203.16535",
          "publishedOn": "2022-04-02T00:47:18.324Z",
          "wordCount": 669,
          "title": "Parallel framework for Dynamic Domain Decomposition of Data Assimilation problems a case study on Kalman Filter algorithm. (arXiv:2203.16535v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16683",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Rocha_K/0/1/0/all/0/1\">Kyle Akira Rocha</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Andrews_J/0/1/0/all/0/1\">Jeff J. Andrews</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Berry_C/0/1/0/all/0/1\">Christopher P. L. Berry</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Doctor_Z/0/1/0/all/0/1\">Zoheyr Doctor</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Marchant_P/0/1/0/all/0/1\">Pablo Marchant</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kalogera_V/0/1/0/all/0/1\">Vicky Kalogera</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Coughlin_S/0/1/0/all/0/1\">Scott Coughlin</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Bavera_S/0/1/0/all/0/1\">Simone S. Bavera</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dotter_A/0/1/0/all/0/1\">Aaron Dotter</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Fragos_T/0/1/0/all/0/1\">Tassos Fragos</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kovlakas_K/0/1/0/all/0/1\">Konstantinos Kovlakas</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Misra_D/0/1/0/all/0/1\">Devina Misra</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Xing_Z/0/1/0/all/0/1\">Zepei Xing</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zapartas_E/0/1/0/all/0/1\">Emmanouil Zapartas</a>",
          "description": "Binary stars undergo a variety of interactions and evolutionary phases,\ncritical for predicting and explaining observed properties. Binary population\nsynthesis with full stellar-structure and evolution simulations are\ncomputationally expensive requiring a large number of mass-transfer sequences.\nThe recently developed binary population synthesis code POSYDON incorporates\ngrids of MESA binary star simulations which are then interpolated to model\nlarge-scale populations of massive binaries. The traditional method of\ncomputing a high-density rectilinear grid of simulations is not scalable for\nhigher-dimension grids, accounting for a range of metallicities, rotation, and\neccentricity. We present a new active learning algorithm, psy-cris, which uses\nmachine learning in the data-gathering process to adaptively and iteratively\nselect targeted simulations to run, resulting in a custom, high-performance\ntraining set. We test psy-cris on a toy problem and find the resulting training\nsets require fewer simulations for accurate classification and regression than\neither regular or randomly sampled grids. We further apply psy-cris to the\ntarget problem of building a dynamic grid of MESA simulations, and we\ndemonstrate that, even without fine tuning, a simulation set of only $\\sim 1/4$\nthe size of a rectilinear grid is sufficient to achieve the same classification\naccuracy. We anticipate further gains when algorithmic parameters are optimized\nfor the targeted application. We find that optimizing for classification only\nmay lead to performance losses in regression, and vice versa. Lowering the\ncomputational cost of producing grids will enable future versions of POSYDON to\ncover more input parameters while preserving interpolation accuracies.",
          "link": "http://arxiv.org/abs/2203.16683",
          "publishedOn": "2022-04-02T00:47:18.317Z",
          "wordCount": 726,
          "title": "Active Learning for Computationally Efficient Distribution of Binary Evolution Simulations. (arXiv:2203.16683v1 [astro-ph.SR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michelis_M/0/1/0/all/0/1\">Mike Y. Michelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katzschmann_R/0/1/0/all/0/1\">Robert K. Katzschmann</a>",
          "description": "Enhancing neural networks with knowledge of physical equations has become an\nefficient way of solving various physics problems, from fluid flow to\nelectromagnetism. Graph neural networks show promise in accurately representing\nirregularly meshed objects and learning their dynamics, but have so far\nrequired supervision through large datasets. In this work, we represent meshes\nnaturally as graphs, process these using Graph Networks, and formulate our\nphysics-based loss to provide an unsupervised learning framework for partial\ndifferential equations (PDE). We quantitatively compare our results to a\nclassical numerical PDE solver, and show that our computationally efficient\napproach can be used as an interactive PDE solver that is adjusting boundary\nconditions in real-time and remains sufficiently close to the baseline\nsolution. Our inherently differentiable framework will enable the application\nof PDE solvers in interactive settings, such as model-based control of\nsoft-body deformations, or in gradient-based optimization methods that require\na fully differentiable pipeline.",
          "link": "http://arxiv.org/abs/2203.16628",
          "publishedOn": "2022-04-02T00:47:18.309Z",
          "wordCount": 583,
          "title": "Physics-constrained Unsupervised Learning of Partial Differential Equations using Meshes. (arXiv:2203.16628v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16622",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Baid_U/0/1/0/all/0/1\">Ujjwal Baid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pati_S/0/1/0/all/0/1\">Sarthak Pati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurc_T/0/1/0/all/0/1\">Tahsin M. Kurc</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gupta_R/0/1/0/all/0/1\">Rajarsi Gupta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bremer_E/0/1/0/all/0/1\">Erich Bremer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abousamra_S/0/1/0/all/0/1\">Shahira Abousamra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thakur_S/0/1/0/all/0/1\">Siddhesh P. Thakur</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saltz_J/0/1/0/all/0/1\">Joel H. Saltz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bakas_S/0/1/0/all/0/1\">Spyridon Bakas</a>",
          "description": "We evaluate the performance of federated learning (FL) in developing deep\nlearning models for analysis of digitized tissue sections. A classification\napplication was considered as the example use case, on quantifiying the\ndistribution of tumor infiltrating lymphocytes within whole slide images\n(WSIs). A deep learning classification model was trained using 50*50 square\nmicron patches extracted from the WSIs. We simulated a FL environment in which\na dataset, generated from WSIs of cancer from numerous anatomical sites\navailable by The Cancer Genome Atlas repository, is partitioned in 8 different\nnodes. Our results show that the model trained with the federated training\napproach achieves similar performance, both quantitatively and qualitatively,\nto that of a model trained with all the training data pooled at a centralized\nlocation. Our study shows that FL has tremendous potential for enabling\ndevelopment of more robust and accurate models for histopathology image\nanalysis without having to collect large and diverse training data at a single\nlocation.",
          "link": "http://arxiv.org/abs/2203.16622",
          "publishedOn": "2022-04-02T00:47:18.291Z",
          "wordCount": 624,
          "title": "Federated Learning for the Classification of Tumor Infiltrating Lymphocytes. (arXiv:2203.16622v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1\">Zhenrui Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Huimin Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kou_Z/0/1/0/all/0/1\">Ziyi Kou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1\">Lanyu Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>",
          "description": "Modern smart sensor-based energy management systems leverage non-intrusive\nload monitoring (NILM) to predict and optimize appliance load distribution in\nreal-time. NILM, or energy disaggregation, refers to the decomposition of\nelectricity usage conditioned on the aggregated power signals (i.e., smart\nsensor on the main channel). Based on real-time appliance power prediction\nusing sensory technology, energy disaggregation has great potential to increase\nelectricity efficiency and reduce energy expenditure. With the introduction of\ntransformer models, NILM has achieved significant improvements in predicting\ndevice power readings. Nevertheless, transformers are less efficient due to\nO(l^2) complexity w.r.t. sequence length l. Moreover, transformers can fail to\ncapture local signal patterns in sequence-to-point settings due to the lack of\ninductive bias in local context. In this work, we propose an efficient\nlocalness transformer for non-intrusive load monitoring (ELTransformer).\nSpecifically, we leverage normalization functions and switch the order of\nmatrix multiplication to approximate self-attention and reduce computational\ncomplexity. Additionally, we introduce localness modeling with sparse local\nattention heads and relative position encodings to enhance the model capacity\nin extracting short-term local patterns. To the best of our knowledge,\nELTransformer is the first NILM model that addresses computational complexity\nand localness modeling in NILM. With extensive experiments and quantitative\nanalyses, we demonstrate the efficiency and effectiveness of the the proposed\nELTransformer with considerable improvements compared to state-of-the-art\nbaselines.",
          "link": "http://arxiv.org/abs/2203.16537",
          "publishedOn": "2022-04-02T00:47:18.284Z",
          "wordCount": 668,
          "title": "Efficient Localness Transformer for Smart Sensor-Based Energy Disaggregation. (arXiv:2203.16537v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yu-Huai Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Shin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Pin-Tuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>",
          "description": "In traditional speaker diarization systems, a well-trained speaker model is a\nkey component to extract representations from consecutive and partially\noverlapping segments in a long speech session. To be more consistent with the\nback-end segmentation and clustering, we propose a new CNN-based speaker\nmodeling scheme, which takes into account the heterogeneity of the speakers in\neach training segment and batch. We randomly and synthetically augment the\ntraining data into a set of segments, each of which contains more than one\nspeaker and some overlapping parts. A soft label is imposed on each segment\nbased on its speaker occupation ratio, and the standard cross entropy loss is\nimplemented in model training. In this way, the speaker model should have the\nability to generate a geometrically meaningful embedding for each multi-speaker\nsegment. Experimental results show that our system is superior to the baseline\nsystem using x-vectors in two speaker diarization tasks. In the CALLHOME task\ntrained on the NIST SRE and Switchboard datasets, our system achieves a\nrelative reduction of 12.93% in DER. In Track 2 of CHiME-6, our system provides\n13.24%, 12.60%, and 5.65% relative reductions in DER, JER, and WER,\nrespectively.",
          "link": "http://arxiv.org/abs/2203.16646",
          "publishedOn": "2022-04-02T00:47:18.278Z",
          "wordCount": 652,
          "title": "Generation of Speaker Representations Using Heterogeneous Training Batch Assembly. (arXiv:2203.16646v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miculicich_L/0/1/0/all/0/1\">Lesly Miculicich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>",
          "description": "The state-of-the-art models for coreference resolution are based on\nindependent mention pair-wise decisions. We propose a modelling approach that\nlearns coreference at the document-level and takes global decisions. For this\npurpose, we model coreference links in a graph structure where the nodes are\ntokens in the text, and the edges represent the relationship between them. Our\nmodel predicts the graph in a non-autoregressive manner, then iteratively\nrefines it based on previous predictions, allowing global dependencies between\ndecisions. The experimental results show improvements over various baselines,\nreinforcing the hypothesis that document-level information improves conference\nresolution.",
          "link": "http://arxiv.org/abs/2203.16574",
          "publishedOn": "2022-04-02T00:47:18.269Z",
          "wordCount": 523,
          "title": "Graph Refinement for Coreference Resolution. (arXiv:2203.16574v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beckham_C/0/1/0/all/0/1\">Christopher Beckham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Laradji_I/0/1/0/all/0/1\">Issam Laradji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rodriguez_P/0/1/0/all/0/1\">Pau Rodriguez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vazquez_D/0/1/0/all/0/1\">David Vazquez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowrouzezahrai_D/0/1/0/all/0/1\">Derek Nowrouzezahrai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "In this paper, we explore the use of GAN-based few-shot data augmentation as\na method to improve few-shot classification performance. We perform an\nexploration into how a GAN can be fine-tuned for such a task (one of which is\nin a class-incremental manner), as well as a rigorous empirical investigation\ninto how well these models can perform to improve few-shot classification. We\nidentify issues related to the difficulty of training such generative models\nunder a purely supervised regime with very few examples, as well as issues\nregarding the evaluation protocols of existing works. We also find that in this\nregime, classification accuracy is highly sensitive to how the classes of the\ndataset are randomly split. Therefore, we propose a semi-supervised fine-tuning\napproach as a more pragmatic way forward to address these problems.",
          "link": "http://arxiv.org/abs/2203.16662",
          "publishedOn": "2022-04-02T00:47:18.263Z",
          "wordCount": 572,
          "title": "Challenges in leveraging GANs for few-shot data augmentation. (arXiv:2203.16662v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hersche_M/0/1/0/all/0/1\">Michael Hersche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karunaratne_G/0/1/0/all/0/1\">Geethan Karunaratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherubini_G/0/1/0/all/0/1\">Giovanni Cherubini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1\">Abu Sebastian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahimi_A/0/1/0/all/0/1\">Abbas Rahimi</a>",
          "description": "Continually learning new classes from fresh data without forgetting previous\nknowledge of old classes is a very challenging research problem. Moreover, it\nis imperative that such learning must respect certain memory and computational\nconstraints such as (i) training samples are limited to only a few per class,\n(ii) the computational cost of learning a novel class remains constant, and\n(iii) the memory footprint of the model grows at most linearly with the number\nof classes observed. To meet the above constraints, we propose C-FSCIL, which\nis architecturally composed of a frozen meta-learned feature extractor, a\ntrainable fixed-size fully connected layer, and a rewritable dynamically\ngrowing memory that stores as many vectors as the number of encountered\nclasses. C-FSCIL provides three update modes that offer a trade-off between\naccuracy and compute-memory cost of learning novel classes. C-FSCIL exploits\nhyperdimensional embedding that allows to continually express many more classes\nthan the fixed dimensions in the vector space, with minimal interference. The\nquality of class vector representations is further improved by aligning them\nquasi-orthogonally to each other by means of novel loss functions. Experiments\non the CIFAR100, miniImageNet, and Omniglot datasets show that C-FSCIL\noutperforms the baselines with remarkable accuracy and compression. It also\nscales up to the largest problem size ever tried in this few-shot setting by\nlearning 423 novel classes on top of 1200 base classes with less than 1.6%\naccuracy drop. Our code is available at\nhttps://github.com/IBM/constrained-FSCIL.",
          "link": "http://arxiv.org/abs/2203.16588",
          "publishedOn": "2022-04-02T00:47:18.256Z",
          "wordCount": 682,
          "title": "Constrained Few-shot Class-incremental Learning. (arXiv:2203.16588v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_H/0/1/0/all/0/1\">Heng Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zi-Xiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chunling Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1\">Wu-Hao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenglong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Rui-Bo Jin</a>",
          "description": "Orbital angular momentum of light is regarded as a valuable resource in\nquantum technology, especially in quantum communication and quantum sensing and\nranging. However, the OAM state of light is susceptible to undesirable\nexperimental conditions such as propagation distance and phase distortions,\nwhich hinders the potential for the realistic implementation of relevant\ntechnologies. In this article, we exploit an enhanced deep learning neural\nnetwork to identify different OAM modes of light at multiple propagation\ndistances with phase distortions. Specifically, our trained deep learning\nneural network can efficiently identify the vortex beam's topological charge\nand propagation distance with 97% accuracy. Our technique has important\nimplications for OAM based communication and sensing protocols.",
          "link": "http://arxiv.org/abs/2203.16539",
          "publishedOn": "2022-04-02T00:47:18.225Z",
          "wordCount": 591,
          "title": "Identification of diffracted vortex beams at different propagation distances using deep learning. (arXiv:2203.16539v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mei_L/0/1/0/all/0/1\">Lingjie Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>",
          "description": "We present a meta-learning framework for learning new visual concepts\nquickly, from just one or a few examples, guided by multiple naturally\noccurring data streams: simultaneously looking at images, reading sentences\nthat describe the objects in the scene, and interpreting supplemental sentences\nthat relate the novel concept with other concepts. The learned concepts support\ndownstream applications, such as answering questions by reasoning about unseen\nimages. Our model, namely FALCON, represents individual visual concepts, such\nas colors and shapes, as axis-aligned boxes in a high-dimensional space (the\n\"box embedding space\"). Given an input image and its paired sentence, our model\nfirst resolves the referential expression in the sentence and associates the\nnovel concept with particular objects in the scene. Next, our model interprets\nsupplemental sentences to relate the novel concept with other known concepts,\nsuch as \"X has property Y\" or \"X is a kind of Y\". Finally, it infers an optimal\nbox embedding for the novel concept that jointly 1) maximizes the likelihood of\nthe observed instances in the image, and 2) satisfies the relationships between\nthe novel concepts and the known ones. We demonstrate the effectiveness of our\nmodel on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2203.16639",
          "publishedOn": "2022-04-02T00:47:18.216Z",
          "wordCount": 672,
          "title": "FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations. (arXiv:2203.16639v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haviv_A/0/1/0/all/0/1\">Adi Haviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1\">Ori Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Press_O/0/1/0/all/0/1\">Ofir Press</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izsak_P/0/1/0/all/0/1\">Peter Izsak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>",
          "description": "Transformers typically require some form of positional encoding, such as\npositional embeddings, to process natural language sequences. Surprisingly, we\nfind that transformer language models without any explicit positional encoding\nare still competitive with standard models, and that this phenomenon is robust\nacross different datasets, model sizes, and sequence lengths. Probing\nexperiments reveal that such models acquire an implicit notion of absolute\npositions throughout the network, effectively compensating for the missing\ninformation. We conjecture that causal attention enables the model to infer the\nnumber of predecessors that each token can attend to, thereby approximating its\nabsolute position.",
          "link": "http://arxiv.org/abs/2203.16634",
          "publishedOn": "2022-04-02T00:47:18.191Z",
          "wordCount": 545,
          "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information. (arXiv:2203.16634v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lentzas_A/0/1/0/all/0/1\">Athanasios Lentzas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vrakas_D/0/1/0/all/0/1\">Dimitris Vrakas</a>",
          "description": "Home absence detection is an emerging field on smart home installations.\nIdentifying whether or not the residents of the house are present, is important\nin numerous scenarios. Possible scenarios include but are not limited to:\nelderly people living alone, people suffering from dementia, home quarantine.\nThe majority of published papers focus on either pressure / door sensors or\ncameras in order to detect outing events. Although the aforementioned\napproaches provide solid results, they are intrusive and require modifications\nfor sensor placement. In our work, appliance electrical use is investigated as\na means for detecting the presence or absence of residents. The energy use is\nthe result of power disaggregation, a non intrusive / non invasive sensing\nmethod. Since a dataset providing energy data and ground truth for home absence\nis not available, artificial outing events were introduced on the UK-DALE\ndataset, a well known dataset for Non Intrusive Load Monitoring (NILM). Several\nmachine learning algorithms were evaluated using the generated dataset.\nBenchmark results have shown that home absence detection using appliance power\nconsumption is feasible.",
          "link": "http://arxiv.org/abs/2203.16538",
          "publishedOn": "2022-04-02T00:47:18.184Z",
          "wordCount": 637,
          "title": "Machine Learning Approaches for Non-Intrusive Home Absence Detection Based on Appliance Electrical Use. (arXiv:2203.16538v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.04420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1\">Harshavardhan Kamarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1\">Alexander Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>",
          "description": "In real-time forecasting in public health, data collection is a non-trivial\nand demanding task. Often after initially released, it undergoes several\nrevisions later (maybe due to human or technical constraints) - as a result, it\nmay take weeks until the data reaches to a stable value. This so-called\n'backfill' phenomenon and its effect on model performance has been barely\nstudied in the prior literature. In this paper, we introduce the multi-variate\nbackfill problem using COVID-19 as the motivating example. We construct a\ndetailed dataset composed of relevant signals over the past year of the\npandemic. We then systematically characterize several patterns in backfill\ndynamics and leverage our observations for formulating a novel problem and\nneural framework Back2Future that aims to refines a given model's predictions\nin real-time. Our extensive experiments demonstrate that our method refines the\nperformance of top models for COVID-19 forecasting, in contrast to non-trivial\nbaselines, yielding 18% improvement over baselines, enabling us obtain a new\nSOTA performance. In addition, we show that our model improves model evaluation\ntoo; hence policy-makers can better understand the true accuracy of forecasting\nmodels in real-time.",
          "link": "http://arxiv.org/abs/2106.04420",
          "publishedOn": "2022-03-27T00:51:42.565Z",
          "wordCount": 756,
          "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future. (arXiv:2106.04420v7 [cs.LG] UPDATED)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2204.09664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "We study the theory of neural network (NN) from the lens of classical\nnonparametric regression problems with a focus on NN's ability to adaptively\nestimate functions with heterogeneous smoothness -- a property of functions in\nBesov or Bounded Variation (BV) classes. Existing work on this problem requires\ntuning the NN architecture based on the function spaces and sample sizes. We\nconsider a \"Parallel NN\" variant of deep ReLU networks and show that the\nstandard weight decay is equivalent to promoting the $\\ell_p$-sparsity\n($0<p<1$) of the coefficient vector of an end-to-end learned function bases,\ni.e., a dictionary. Using this equivalence, we further establish that by tuning\nonly the weight decay, such Parallel NN achieves an estimation error\narbitrarily close to the minimax rates for both the Besov and BV classes.\nNotably, it gets exponentially closer to minimax optimal as the NN gets deeper.\nOur research sheds new lights on why depth matters and how NNs are more\npowerful than kernel methods.",
          "link": "http://arxiv.org/abs/2204.09664",
          "publishedOn": "2022-04-23T00:53:50.168Z",
          "wordCount": 610,
          "title": "Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?. (arXiv:2204.09664v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bennett_M/0/1/0/all/0/1\">Michele Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balusu_J/0/1/0/all/0/1\">Jaya Balusu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_K/0/1/0/all/0/1\">Karin Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleczyk_E/0/1/0/all/0/1\">Ewa J. Kleczyk</a>",
          "description": "The COVID-19 pandemic has dramatically changed how healthcare is delivered to\npatients, how patients interact with healthcare providers, and how healthcare\ninformation is disseminated to both healthcare providers and patients.\nAnalytical models that were trained and tested pre-pandemic may no longer be\nperforming up to expectations, providing unreliable and irrelevant learning\n(ML) models given that ML depends on the basic principle that what happened in\nthe past are likely to repeat in the future. ML faced to two important\ndegradation principles, concept drift, when the underlying properties and\ncharacteristics of the variables change and data drift, when the data\ndistributions, probabilities, co-variates, and other variable relationships\nchange, both of which are prime culprits of model failure. Therefore, detecting\nand diagnosing drift in existing models is something that has become an\nimperative. And perhaps even more important is a shift in our mindset towards a\nconscious recognition that drift is inevitable, and model building must\nincorporate intentional resilience, the ability to offset and recover quickly\nfrom failure, and proactive robustness, avoiding failure by developing models\nthat are less vulnerable to drift and disruption.",
          "link": "http://arxiv.org/abs/2204.10227",
          "publishedOn": "2022-04-23T00:53:50.137Z",
          "wordCount": 694,
          "title": "The Silent Problem -- Machine Learning Model Failure -- How to Diagnose and Fix Ailing Machine Learning Models. (arXiv:2204.10227v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.10754",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dolera_E/0/1/0/all/0/1\">Emanuele Dolera</a>, <a href=\"http://arxiv.org/find/math/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mainini_E/0/1/0/all/0/1\">Edoardo Mainini</a>",
          "description": "In this paper, we develop a novel approach to posterior contractions rates\n(PCRs), for both finite-dimensional (parametric) and infinite-dimensional\n(nonparametric) Bayesian models. Critical to our approach is the combination of\nan assumption of local Lipschitz-continuity for the posterior distribution with\na dynamic formulation of the Wasserstein distance, here referred to as\nWasserstein dynamics, which allows to set forth a connection between the\nproblem of establishing PCRs and some classical problems in mathematical\nanalysis, probability theory and mathematical statistics: the Laplace method\nfor approximating integrals, Sanov's large deviation principles in the\nWasserstein distance, rates of convergence of the mean Glivenko-Cantelli\ntheorem, and estimates of weighted Poincar\\'e-Wirtinger constants. Under\ndominated Bayesian models, we present two main results: i) a theorem on PCRs\nfor the regular infinite-dimensional exponential family of statistical models;\nii) a theorem on PCRs for a general dominated statistical model. Some\napplications of our results are presented for the regular parametric model, the\nmultinomial model, the finite-dimensional and the infinite-dimensional\nlogistic-Gaussian model and the infinite-dimensional linear regression. In\ngeneral, our results lead to optimal PCRs in finite dimension, whereas in\ninfinite dimension it is shown how the prior distribution may affect PCRs. With\nregards to infinite-dimensional Bayesian models for density estimation, our\napproach to PCRs is the first to consider strong norm distances on parameter\nspaces of functions, such as Sobolev-like norms, as most of the approaches in\nthe classical (frequentist) and Bayesian literature deal with spaces of density\nfunctions endowed with $\\mathrm{L}^p$ norms or the Hellinger distance.",
          "link": "http://arxiv.org/abs/2203.10754",
          "publishedOn": "2022-04-23T00:53:50.120Z",
          "wordCount": 706,
          "title": "Strong posterior contraction rates via Wasserstein dynamics. (arXiv:2203.10754v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.07295",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saito_Y/0/1/0/all/0/1\">Yuta Saito</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nomura_M/0/1/0/all/0/1\">Masahiro Nomura</a>",
          "description": "We study offline recommender learning from explicit rating feedback in the\npresence of selection bias. A current promising solution for the bias is the\ninverse propensity score (IPS) estimation. However, the performance of existing\npropensity-based methods can suffer significantly from the propensity\nestimation bias. In fact, most of the previous IPS-based methods require some\namount of missing-completely-at-random (MCAR) data to accurately estimate the\npropensity. This leads to a critical self-contradiction; IPS is ineffective\nwithout MCAR data, even though it originally aims to learn recommenders from\nonly missing-not-at-random feedback. To resolve this propensity contradiction,\nwe derive a propensity-independent generalization error bound and propose a\nnovel algorithm to minimize the theoretical bound via adversarial learning. Our\ntheory and algorithm do not require a propensity estimation procedure, thereby\nleading to a well-performing rating predictor without the true propensity\ninformation. Extensive experiments demonstrate that the proposed approach is\nsuperior to a range of existing methods both in rating prediction and ranking\nmetrics in practical settings without MCAR data.",
          "link": "http://arxiv.org/abs/1910.07295",
          "publishedOn": "2022-04-23T00:53:50.104Z",
          "wordCount": 656,
          "title": "Towards Resolving Propensity Contradiction in Offline Recommender Learning. (arXiv:1910.07295v6 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09790",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Galaz_Garcia_F/0/1/0/all/0/1\">Fernando Galaz-Garcia</a>, <a href=\"http://arxiv.org/find/math/1/au:+Papamichalis_M/0/1/0/all/0/1\">Marios Papamichalis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Turnbull_K/0/1/0/all/0/1\">Kathryn Turnbull</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lunagomez_S/0/1/0/all/0/1\">Simon Lunagomez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Airoldi_E/0/1/0/all/0/1\">Edoardo Airoldi</a>",
          "description": "We provide a general framework for constructing probability distributions on\nRiemannian manifolds, taking advantage of area-preserving maps and isometries.\nControl over distributions' properties, such as parameters, symmetry and\nmodality yield a family of flexible distributions that are straightforward to\nsample from, suitable for use within Monte Carlo algorithms and latent variable\nmodels, such as autoencoders. As an illustration, we empirically validate our\napproach by utilizing our proposed distributions within a variational\nautoencoder and a latent space network model. Finally, we take advantage of the\ngeneralized description of this framework to posit questions for future work.",
          "link": "http://arxiv.org/abs/2204.09790",
          "publishedOn": "2022-04-23T00:53:50.095Z",
          "wordCount": 555,
          "title": "Wrapped Distributions on homogeneous Riemannian manifolds. (arXiv:2204.09790v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1\">Qi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>",
          "description": "Despite the success of reinforcement learning (RL) for Markov decision\nprocesses (MDPs) with function approximation, most RL algorithms easily fail if\nthe agent only has partial observations of the state. Such a setting is often\nmodeled as a partially observable Markov decision process (POMDP). Existing\nsample-efficient algorithms for POMDPs are restricted to the tabular setting\nwhere the state and observation spaces are finite. In this paper, we make the\nfirst attempt at tackling the tension between function approximation and\npartial observability. In specific, we focus on a class of undercomplete POMDPs\nwith linear function approximations, which allows the state and observation\nspaces to be infinite. For such POMDPs, we show that the optimal policy and\nvalue function can be characterized by a sequence of finite-memory Bellman\noperators. We propose an RL algorithm that constructs optimistic estimators of\nthese operators via reproducing kernel Hilbert space (RKHS) embedding.\nMoreover, we theoretically prove that the proposed algorithm finds an\n$\\varepsilon$-optimal policy with $\\tilde O (1/\\varepsilon^2)$ episodes of\nexploration. Also, this sample complexity only depends on the intrinsic\ndimension of the POMDP polynomially and is independent of the size of the state\nand observation spaces. To our best knowledge, we develop the first provably\nsample-efficient algorithm for POMDPs with function approximation.",
          "link": "http://arxiv.org/abs/2204.09787",
          "publishedOn": "2022-04-23T00:53:49.554Z",
          "wordCount": null,
          "title": "Sample-Efficient Reinforcement Learning for POMDPs with Linear Function Approximations. (arXiv:2204.09787v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00953",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Shen_Y/0/1/0/all/0/1\">Yinan Shen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1\">Jingyang Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cai_J/0/1/0/all/0/1\">Jian-Feng Cai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xia_D/0/1/0/all/0/1\">Dong Xia</a>",
          "description": "Low-rank matrix estimation under heavy-tailed noise is challenging, both\ncomputationally and statistically. Convex approaches have been proven\nstatistically optimal but suffer from high computational costs, especially\nsince robust loss functions are usually non-smooth. More recently,\ncomputationally fast non-convex approaches via sub-gradient descent are\nproposed, which, unfortunately, fail to deliver a statistically consistent\nestimator even under sub-Gaussian noise. In this paper, we introduce a novel\nRiemannian sub-gradient (RsGrad) algorithm which is not only computationally\nefficient with linear convergence but also is statistically optimal, be the\nnoise Gaussian or heavy-tailed. Convergence theory is established for a general\nframework and specific applications to absolute loss, Huber loss, and quantile\nloss are investigated. Compared with existing non-convex methods, ours reveals\na surprising phenomenon of dual-phase convergence. In phase one, RsGrad behaves\nas in a typical non-smooth optimization that requires gradually decaying\nstepsizes. However, phase one only delivers a statistically sub-optimal\nestimator which is already observed in the existing literature. Interestingly,\nduring phase two, RsGrad converges linearly as if minimizing a smooth and\nstrongly convex objective function and thus a constant stepsize suffices.\nUnderlying the phase-two convergence is the smoothing effect of random noise to\nthe non-smooth robust losses in an area close but not too close to the truth.\nLastly, RsGrad is applicable for low-rank tensor estimation under heavy-tailed\nnoise where a statistically optimal rate is attainable with the same phenomenon\nof dual-phase convergence, and a novel shrinkage-based second-order moment\nmethod is guaranteed to deliver a warm initialization. Numerical simulations\nconfirm our theoretical discovery and showcase the superiority of RsGrad over\nprior methods.",
          "link": "http://arxiv.org/abs/2203.00953",
          "publishedOn": "2022-04-23T00:53:49.542Z",
          "wordCount": null,
          "title": "Computationally Efficient and Statistically Optimal Robust Low-rank Matrix and Tensor Estimation. (arXiv:2203.00953v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Pretrained language models have achieved state-of-the-art performance when\nadapted to a downstream NLP task. However, theoretical analysis of these models\nis scarce and challenging since the pretraining and downstream tasks can be\nvery different. We propose an analysis framework that links the pretraining and\ndownstream tasks with an underlying latent variable generative model of text --\nthe downstream classifier must recover a function of the posterior distribution\nover the latent variables. We analyze head tuning (learning a classifier on top\nof the frozen pretrained model) and prompt tuning in this setting. The\ngenerative model in our analysis is either a Hidden Markov Model (HMM) or an\nHMM augmented with a latent memory component, motivated by long-term\ndependencies in natural language. We show that 1) under certain non-degeneracy\nconditions on the HMM, simple classification heads can solve the downstream\ntask, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy\nconditions, and 3) our recovery guarantees for the memory-augmented HMM are\nstronger than for the vanilla HMM because task-relevant information is easier\nto recover from the long-term memory. Experiments on synthetically generated\ndata from HMMs back our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.09226",
          "publishedOn": "2022-04-23T00:53:49.532Z",
          "wordCount": null,
          "title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning. (arXiv:2106.09226v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.10510",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ovsianas_A/0/1/0/all/0/1\">Andrius Ovsianas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fernandes_D/0/1/0/all/0/1\">David Fernandes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1\">Nikolas N&#xfc;sken</a>",
          "description": "In this work we explore a new framework for approximate Bayesian inference in\nlarge datasets based on stochastic control (i.e. Schr\\\"odinger bridges). We\nadvocate stochastic control as a finite time and low variance alternative to\npopular steady-state methods such as stochastic gradient Langevin dynamics\n(SGLD). Furthermore, we discuss and adapt the existing theoretical guarantees\nof this framework and establish connections to already existing VI routines in\nSDE-based models.",
          "link": "http://arxiv.org/abs/2111.10510",
          "publishedOn": "2022-04-23T00:53:49.517Z",
          "wordCount": null,
          "title": "Bayesian Learning via Neural Schr\\\"odinger-F\\\"ollmer Flows. (arXiv:2111.10510v8 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingxiao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>",
          "description": "Message Passing Neural Networks (MPNNs) are a common type of Graph Neural\nNetwork (GNN), in which each node's representation is computed recursively by\naggregating representations (messages) from its immediate neighbors akin to a\nstar-shaped pattern. MPNNs are appealing for being efficient and scalable,\nhow-ever their expressiveness is upper-bounded by the 1st-order\nWeisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose\nhighly expressive models at the cost of scalability and sometimes\ngeneralization performance. Our work stands between these two regimes: we\nintroduce a general framework to uplift any MPNN to be more expressive, with\nlimited scalability overhead and greatly improved practical performance. We\nachieve this by extending local aggregation in MPNNs from star patterns to\ngeneral subgraph patterns (e.g.,k-egonets):in our framework, each node\nrepresentation is computed as the encoding of a surrounding induced subgraph\nrather than encoding of immediate neighbors only (i.e. a star). We choose the\nsubgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design\na general framework that serves as a wrapper to up-lift any GNN. We call our\nproposed method GNN-AK(GNN As Kernel), as the framework resembles a\nconvolutional neural network by replacing the kernel with GNNs. Theoretically,\nwe show that our framework is strictly more powerful than 1&2-WL, and is not\nless powerful than 3-WL. We also design subgraph sampling strategies which\ngreatly reduce memory footprint and improve speed while maintaining\nperformance. Our method sets new state-of-the-art performance by large margins\nfor several well-known graph ML tasks; specifically, 0.08 MAE on ZINC,74.79%\nand 86.887% accuracy on CIFAR10 and PATTERN respectively.",
          "link": "http://arxiv.org/abs/2110.03753",
          "publishedOn": "2022-04-23T00:53:49.513Z",
          "wordCount": null,
          "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness. (arXiv:2110.03753v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1807.06919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Resnick_C/0/1/0/all/0/1\">Cinjon Resnick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1\">Alexander Peysakhovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Model-free reinforcement learning (RL) requires a large number of trials to\nlearn a good policy, especially in environments with sparse rewards. We explore\na method to improve the sample efficiency when we have access to\ndemonstrations. Our approach, Backplay, uses a single demonstration to\nconstruct a curriculum for a given task. Rather than starting each training\nepisode in the environment's fixed initial state, we start the agent near the\nend of the demonstration and move the starting point backwards during the\ncourse of training until we reach the initial state. Our contributions are that\nwe analytically characterize the types of environments where Backplay can\nimprove training speed, demonstrate the effectiveness of Backplay both in large\ngrid worlds and a complex four player zero-sum game (Pommerman), and show that\nBackplay compares favorably to other competitive methods known to improve\nsample efficiency. This includes reward shaping, behavioral cloning, and\nreverse curriculum generation.",
          "link": "http://arxiv.org/abs/1807.06919",
          "publishedOn": "2022-04-23T00:53:49.511Z",
          "wordCount": null,
          "title": "Backplay: \"Man muss immer umkehren\". (arXiv:1807.06919v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.09139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilault_J/0/1/0/all/0/1\">Jonathan Pilault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhattami_A/0/1/0/all/0/1\">Amine Elhattami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Multi-Task Learning (MTL) networks have emerged as a promising method for\ntransferring learned knowledge across different tasks. However, MTL must deal\nwith challenges such as: overfitting to low resource tasks, catastrophic\nforgetting, and negative task transfer, or learning interference. Often, in\nNatural Language Processing (NLP), a separate model per task is needed to\nobtain the best performance. However, many fine-tuning approaches are both\nparameter inefficient, i.e., potentially involving one new model per task, and\nhighly susceptible to losing knowledge acquired during pretraining. We propose\na novel Transformer architecture consisting of a new conditional attention\nmechanism as well as a set of task-conditioned modules that facilitate weight\nsharing. Through this construction (a hypernetwork adapter), we achieve more\nefficient parameter sharing and mitigate forgetting by keeping half of the\nweights of a pretrained model fixed. We also use a new multi-task data sampling\nstrategy to mitigate the negative effects of data imbalance across tasks. Using\nthis approach, we are able to surpass single task fine-tuning methods while\nbeing parameter and data efficient (using around 66% of the data for weight\nupdates). Compared to other BERT Large methods on GLUE, our 8-task model\nsurpasses other Adapter methods by 2.8% and our 24-task model outperforms by\n0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger\nvariant of our single multi-task model approach performs competitively across\n26 NLP tasks and yields state-of-the-art results on a number of test and\ndevelopment sets. Our code is publicly available at\nhttps://github.com/CAMTL/CA-MTL.",
          "link": "http://arxiv.org/abs/2009.09139",
          "publishedOn": "2022-04-23T00:53:49.505Z",
          "wordCount": null,
          "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data. (arXiv:2009.09139v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.03622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kendrick Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yining Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Self-training algorithms, which train a model to fit pseudolabels predicted\nby another previously-learned model, have been very successful for learning\nwith unlabeled data using neural networks. However, the current theoretical\nunderstanding of self-training only applies to linear models. This work\nprovides a unified theoretical analysis of self-training with deep networks for\nsemi-supervised learning, unsupervised domain adaptation, and unsupervised\nlearning. At the core of our analysis is a simple but realistic \"expansion\"\nassumption, which states that a low probability subset of the data must expand\nto a neighborhood with large probability relative to the subset. We also assume\nthat neighborhoods of examples in different classes have minimal overlap. We\nprove that under these assumptions, the minimizers of population objectives\nbased on self-training and input-consistency regularization will achieve high\naccuracy with respect to ground-truth labels. By using off-the-shelf\ngeneralization bounds, we immediately convert this result to sample complexity\nguarantees for neural nets that are polynomial in the margin and Lipschitzness.\nOur results help explain the empirical successes of recently proposed\nself-training algorithms which use input consistency regularization.",
          "link": "http://arxiv.org/abs/2010.03622",
          "publishedOn": "2022-04-23T00:53:49.492Z",
          "wordCount": null,
          "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10177",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Morel_R/0/1/0/all/0/1\">Rudy Morel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rochette_G/0/1/0/all/0/1\">Gaspar Rochette</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leonarduzzi_R/0/1/0/all/0/1\">Roberto Leonarduzzi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bouchaud_J/0/1/0/all/0/1\">Jean-Philippe Bouchaud</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mallat_S/0/1/0/all/0/1\">St&#xe9;phane Mallat</a>",
          "description": "We introduce a scattering covariance matrix which provides non-Gaussian\nmodels of time-series having stationary increments. A complex wavelet transform\ncomputes signal variations at each scale. Dependencies across scales are\ncaptured by the joint covariance across time and scales of complex wavelet\ncoefficients and their modulus. This covariance is nearly diagonalized by a\nsecond wavelet transform, which defines the scattering covariance. We show that\nthis set of moments characterizes a wide range of non-Gaussian properties of\nmulti-scale processes. This is analyzed for a variety of processes, including\nfractional Brownian motions, Poisson, multifractal random walks and Hawkes\nprocesses. We prove that self-similar processes have a scattering covariance\nmatrix which is scale invariant. This property can be estimated numerically and\ndefines a class of wide-sense self-similar processes. We build maximum entropy\nmodels conditioned by scattering covariance coefficients, and generate new\ntime-series with a microcanonical sampling algorithm. Applications are shown\nfor highly non-Gaussian financial and turbulence time-series.",
          "link": "http://arxiv.org/abs/2204.10177",
          "publishedOn": "2022-04-23T00:53:49.487Z",
          "wordCount": null,
          "title": "Scale Dependencies and Self-Similarity Through Wavelet Scattering Covariance. (arXiv:2204.10177v1 [physics.data-an])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10031",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Deville_Y/0/1/0/all/0/1\">Yannick Deville</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Deville_A/0/1/0/all/0/1\">Alain Deville</a>",
          "description": "Two types of states are widely used in quantum mechanics, namely\n(deterministic-coefficient) pure states and statistical mixtures. A density\noperator can be associated with each of them. We here address a third type of\nstates, that we previously introduced in a more restricted framework. These\nstates generalize pure ones by replacing each of their deterministic ket\ncoefficients by a random variable. We therefore call them Random-Coefficient\nPure States, or RCPS. We analyze their properties and their relationships with\nboth types of usual states. We show that RCPS contain much richer information\nthan the density operator and mean of observables that we associate with them.\nThis occurs because the latter operator only exploits the second-order\nstatistics of the random state coefficients, whereas their higher-order\nstatistics contain additional information. That information can be accessed in\npractice with the multiple-preparation procedure that we propose for RCPS, by\nusing second-order and higher-order statistics of associated random\nprobabilities of measurement outcomes. Exploiting these higher-order statistics\nopens the way to a very general approach for performing advanced quantum\ninformation processing tasks. We illustrate the relevance of this approach with\na generic example, dealing with the estimation of parameters of a quantum\nprocess and thus related to quantum process tomography. This parameter\nestimation is performed in the non-blind (i.e. supervised) or blind (i.e.\nunsupervised) mode. We show that this problem cannot be solved by using only\nthe density operator \\rho of an RCPS and the associated mean value Tr(\\rho A)\nof the operator A that corresponds to the considered physical quantity. We\nsucceed in solving this problem by exploiting a fourth-order statistical\nparameter of state coefficients, in addition to second-order statistics.\nNumerical tests validate this result.",
          "link": "http://arxiv.org/abs/2204.10031",
          "publishedOn": "2022-04-23T00:53:49.467Z",
          "wordCount": null,
          "title": "Beyond the density operator and Tr(\\rho A): Exploiting the higher-order statistics of random-coefficient pure states for quantum information processing. (arXiv:2204.10031v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1\">Anjul Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Pushkar Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Swasti Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_K/0/1/0/all/0/1\">Klaus Mueller</a>",
          "description": "Infographics are an aesthetic visual representation of information following\nspecific design principles of human perception. Designing infographics can be a\ntedious process for non-experts and time-consuming, even for professional\ndesigners. With the help of designers, we propose a semi-automated infographic\nframework for general structured and flow-based infographic design generation.\nFor novice designers, our framework automatically creates and ranks infographic\ndesigns for a user-provided text with no requirement for design input. However,\nexpert designers can still provide custom design inputs to customize the\ninfographics. We will also contribute an individual visual group (VG) designs\ndataset (in SVG), along with a 1k complete infographic image dataset with\nsegmented VGs in this work. Evaluation results confirm that by using our\nframework, designers from all expertise levels can generate generic infographic\ndesigns faster than existing methods while maintaining the same quality as\nhand-designed infographics templates.",
          "link": "http://arxiv.org/abs/2204.09904",
          "publishedOn": "2022-04-23T00:53:49.465Z",
          "wordCount": null,
          "title": "Infographics Wizard: Flexible Infographics Authoring and Design Exploration. (arXiv:2204.09904v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tibo_A/0/1/0/all/0/1\">Alessandro Tibo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_T/0/1/0/all/0/1\">Thomas Dyhre Nielsen</a>",
          "description": "Gaussian processes (GPs) are powerful but computationally expensive machine\nlearning models, requiring an estimate of the kernel covariance matrix for\nevery prediction. In large and complex domains, such as graphs, sets, or\nimages, the choice of suitable kernel can also be non-trivial to determine,\nproviding an additional obstacle to the learning task. Over the last decade,\nthese challenges have resulted in significant advances being made in terms of\nscalability and expressivity, exemplified by, e.g., the use of inducing points\nand neural network kernel approximations. In this paper, we propose inducing\nGaussian process networks (IGN), a simple framework for simultaneously learning\nthe feature space as well as the inducing points. The inducing points, in\nparticular, are learned directly in the feature space, enabling a seamless\nrepresentation of complex structured domains while also facilitating scalable\ngradient-based learning methods. We consider both regression and (binary)\nclassification tasks and report on experimental results for real-world data\nsets showing that IGNs provide significant advances over state-of-the-art\nmethods. We also demonstrate how IGNs can be used to effectively model complex\ndomains using neural network architectures.",
          "link": "http://arxiv.org/abs/2204.09889",
          "publishedOn": "2022-04-23T00:53:49.400Z",
          "wordCount": null,
          "title": "Inducing Gaussian Process Networks. (arXiv:2204.09889v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10140",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+He_Y/0/1/0/all/0/1\">Yang-Hui He</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lee_K/0/1/0/all/0/1\">Kyu-Hwan Lee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Oliver_T/0/1/0/all/0/1\">Thomas Oliver</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pozdnyakov_A/0/1/0/all/0/1\">Alexey Pozdnyakov</a>",
          "description": "We investigate the average value of the $p$th Dirichlet coefficients of\nelliptic curves for a prime p in a fixed conductor range with given rank.\nPlotting this average yields a striking oscillating pattern, the details of\nwhich vary with the rank. Based on this observation, we perform various\ndata-scientific experiments with the goal of classifying elliptic curves\naccording to their ranks.",
          "link": "http://arxiv.org/abs/2204.10140",
          "publishedOn": "2022-04-23T00:53:49.385Z",
          "wordCount": null,
          "title": "Murmurations of elliptic curves. (arXiv:2204.10140v1 [math.NT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Magron_P/0/1/0/all/0/1\">Paul Magron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1\">C&#xe9;dric F&#xe9;votte</a>",
          "description": "This paper tackles the problem of decomposing binary data using matrix\nfactorization. We consider the family of mean-parametrized Bernoulli models, a\nclass of generative models that are well suited for modeling binary data and\nenables interpretability of the factors. We factorize the Bernoulli parameter\nand consider an additional Beta prior on one of the factors to further improve\nthe model's expressive power. While similar models have been proposed in the\nliterature, they only exploit the Beta prior as a proxy to ensure a valid\nBernoulli parameter in a Bayesian setting; in practice it reduces to a uniform\nor uninformative prior. Besides, estimation in these models has focused on\ncostly Bayesian inference. In this paper, we propose a simple yet very\nefficient majorization-minimization algorithm for maximum a posteriori\nestimation. Our approach leverages the Beta prior whose parameters can be tuned\nto improve performance in matrix completion tasks. Experiments conducted on\nthree public binary datasets show that our approach offers an excellent\ntrade-off between prediction performance, computational complexity, and\ninterpretability.",
          "link": "http://arxiv.org/abs/2204.09741",
          "publishedOn": "2022-04-23T00:53:49.349Z",
          "wordCount": null,
          "title": "A majorization-minimization algorithm for nonnegative binary matrix factorization. (arXiv:2204.09741v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.10461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clarke_R/0/1/0/all/0/1\">Ross M. Clarke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oldewage_E/0/1/0/all/0/1\">Elre T. Oldewage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>",
          "description": "Machine learning training methods depend plentifully and intricately on\nhyperparameters, motivating automated strategies for their optimisation. Many\nexisting algorithms restart training for each new hyperparameter choice, at\nconsiderable computational cost. Some hypergradient-based one-pass methods\nexist, but these either cannot be applied to arbitrary optimiser\nhyperparameters (such as learning rates and momenta) or take several times\nlonger to train than their base models. We extend these existing methods to\ndevelop an approximate hypergradient-based hyperparameter optimiser which is\napplicable to any continuous hyperparameter appearing in a differentiable model\nweight update, yet requires only one training episode, with no restarts. We\nalso provide a motivating argument for convergence to the true hypergradient,\nand perform tractable gradient-based optimisation of independent learning rates\nfor each model parameter. Our method performs competitively from varied random\nhyperparameter initialisations on several UCI datasets and Fashion-MNIST (using\na one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a\nResNet-18), in time only 2-3x greater than vanilla training.",
          "link": "http://arxiv.org/abs/2110.10461",
          "publishedOn": "2022-04-23T00:53:49.212Z",
          "wordCount": 655,
          "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation. (arXiv:2110.10461v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.06662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_P/0/1/0/all/0/1\">Pengzhou Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1\">Kenji Fukumizu</a>",
          "description": "NOTE: This preprint has a flawed theoretical formulation. Please avoid it and\nrefer to the ICLR22 publication https://openreview.net/forum?id=q7n2RngwOM.\nAlso, arXiv:2109.15062 contains some new ideas on unobserved Confounding.\n\nAs an important problem of causal inference, we discuss the identification\nand estimation of treatment effects under unobserved confounding. Representing\nthe confounder as a latent variable, we propose Intact-VAE, a new variant of\nvariational autoencoder (VAE), motivated by the prognostic score that is\nsufficient for identifying treatment effects. We theoretically show that, under\ncertain settings, treatment effects are identified by our model, and further,\nbased on the identifiability of our model (i.e., determinacy of\nrepresentation), our VAE is a consistent estimator with representation balanced\nfor treatment groups. Experiments on (semi-)synthetic datasets show\nstate-of-the-art performance under diverse settings.",
          "link": "http://arxiv.org/abs/2101.06662",
          "publishedOn": "2022-04-23T00:53:49.152Z",
          "wordCount": 606,
          "title": "Intact-VAE: Estimating Treatment Effects under Unobserved Confounding. (arXiv:2101.06662v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10228",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sadjadi_S/0/1/0/all/0/1\">Seyed Omid Sadjadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greenberg_C/0/1/0/all/0/1\">Craig Greenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singer_E/0/1/0/all/0/1\">Elliot Singer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mason_L/0/1/0/all/0/1\">Lisa Mason</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Reynolds_D/0/1/0/all/0/1\">Douglas Reynolds</a>",
          "description": "The US National Institute of Standards and Technology (NIST) has been\nconducting a second iteration of the CTS challenge since August 2020. The\ncurrent iteration of the CTS Challenge is a leaderboard-style speaker\nrecognition evaluation using telephony data extracted from the unexposed\nportions of the Call My Net 2 (CMN2) and Multi-Language Speech (MLS) corpora\ncollected by the LDC. The CTS Challenge is currently organized in a similar\nmanner to the SRE19 CTS Challenge, offering only an open training condition\nusing two evaluation subsets, namely Progress and Test. Unlike in the SRE19\nChallenge, no training or development set was initially released, and NIST has\npublicly released the leaderboards on both subsets for the CTS Challenge. Which\nsubset (i.e., Progress or Test) a trial belongs to is unknown to challenge\nparticipants, and each system submission needs to contain outputs for all of\nthe trials. The CTS Challenge has also served, and will continue to do so, as a\nprerequisite for entrance to the regular SREs (such as SRE21). Since August\n2020, a total of 53 organizations (forming 33 teams) from academia and industry\nhave participated in the CTS Challenge and submitted more than 4400 valid\nsystem outputs. This paper presents an overview of the evaluation and several\nanalyses of system performance for some primary conditions in the CTS\nChallenge. The CTS Challenge results thus far indicate remarkable improvements\nin performance due to 1) speaker embeddings extracted using large-scale and\ncomplex neural network architectures such as ResNets along with angular margin\nlosses for speaker embedding extraction, 2) extensive data augmentation, 3) the\nuse of large amounts of in-house proprietary data from a large number of\nlabeled speakers, 4) long-duration fine-tuning.",
          "link": "http://arxiv.org/abs/2204.10228",
          "publishedOn": "2022-04-23T00:53:49.144Z",
          "wordCount": 729,
          "title": "The NIST CTS Speaker Recognition Challenge. (arXiv:2204.10228v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Douglas_A/0/1/0/all/0/1\">Alyson Douglas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manshausen_P/0/1/0/all/0/1\">Peter Manshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinshausen_N/0/1/0/all/0/1\">Nicolai Meinshausen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stier_P/0/1/0/all/0/1\">Philip Stier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>",
          "description": "Estimating the effects of continuous-valued interventions from observational\ndata is critically important in fields such as climate science, healthcare, and\neconomics. Recent work focuses on designing neural-network architectures and\nregularization functions to allow for scalable estimation of average and\nindividual-level dose response curves from high-dimensional, large-sample data.\nSuch methodologies assume ignorability (all confounding variables are observed)\nand positivity (all levels of treatment can be observed for every unit\ndescribed by a given covariate value), which are especially challenged in the\ncontinuous treatment regime. Developing scalable sensitivity and uncertainty\nanalyses that allow us to understand the ignorance induced in our estimates\nwhen these assumptions are relaxed receives less attention. Here, we develop a\ncontinuous treatment-effect marginal sensitivity model (CMSM) and derive bounds\nthat agree with both the observed data and a researcher-defined level of hidden\nconfounding. We introduce a scalable algorithm to derive the bounds and\nuncertainty-aware deep models to efficiently estimate these bounds for\nhigh-dimensional, large-sample observational data. We validate our methods\nusing both synthetic and real-world experiments. For the latter, we work in\nconcert with climate scientists interested in evaluating the climatological\nimpacts of human emissions on cloud properties using satellite observations\nfrom the past 15 years: a finite-data problem known to be complicated by the\npresence of a multitude of unobserved confounders.",
          "link": "http://arxiv.org/abs/2204.10022",
          "publishedOn": "2022-04-23T00:53:49.105Z",
          "wordCount": 668,
          "title": "Scalable Sensitivity and Uncertainty Analysis for Causal-Effect Estimates of Continuous-Valued Interventions. (arXiv:2204.10022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1905.09449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Donghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Zuyuan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xinwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jinshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>",
          "description": "The great success of deep neural networks is built upon their\nover-parameterization, which smooths the optimization landscape without\ndegrading the generalization ability. Despite the benefits of\nover-parameterization, a huge amount of parameters makes deep networks\ncumbersome in daily life applications. Though techniques such as pruning and\ndistillation are developed, they are expensive in fully training a dense\nnetwork as backward selection methods, and there is still a void on\nsystematically exploring forward selection methods for learning structural\nsparsity in deep networks. To fill in this gap, this paper proposes a new\napproach based on differential inclusions of inverse scale spaces, which\ngenerate a family of models from simple to complex ones along the dynamics via\ncoupling a pair of parameters, such that over-parameterized deep models and\ntheir structural sparsity can be explored simultaneously. This kind of\ndifferential inclusion scheme has a simple discretization, dubbed Deep\nstructure splitting Linearized Bregman Iteration (DessiLBI), whose global\nconvergence in learning deep networks could be established under the\nKurdyka-Lojasiewicz framework. Experimental evidence shows that our method\nachieves comparable and even better performance than the competitive optimizers\nin exploring the sparse structure of several widely used backbones on the\nbenchmark datasets. Remarkably, with early stopping, our method unveils\n`winning tickets' in early epochs: the effective sparse network structures with\ncomparable test accuracy to fully trained over-parameterized models, that are\nfurther transferable to similar alternative tasks. Furthermore, our method is\nable to grow networks efficiently with adaptive filter configurations,\ndemonstrating a good performance with much less computational cost. Codes and\nmodels can be downloaded at {https://github.com/DessiLBI2020/DessiLBI}.",
          "link": "http://arxiv.org/abs/1905.09449",
          "publishedOn": "2022-04-23T00:53:49.098Z",
          "wordCount": 811,
          "title": "Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces. (arXiv:1905.09449v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10268",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Caro_M/0/1/0/all/0/1\">Matthias C. Caro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ezzell_N/0/1/0/all/0/1\">Nicholas Ezzell</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gibbs_J/0/1/0/all/0/1\">Joe Gibbs</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sornborger_A/0/1/0/all/0/1\">Andrew T. Sornborger</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Holmes_Z/0/1/0/all/0/1\">Zo&#xeb; Holmes</a>",
          "description": "Generalization bounds are a critical tool to assess the training data\nrequirements of Quantum Machine Learning (QML). Recent work has established\nguarantees for in-distribution generalization of quantum neural networks\n(QNNs), where training and testing data are assumed to be drawn from the same\ndata distribution. However, there are currently no results on\nout-of-distribution generalization in QML, where we require a trained model to\nperform well even on data drawn from a distribution different from the training\ndistribution. In this work, we prove out-of-distribution generalization for the\ntask of learning an unknown unitary using a QNN and for a broad class of\ntraining and testing distributions. In particular, we show that one can learn\nthe action of a unitary on entangled states using only product state training\ndata. We numerically illustrate this by showing that the evolution of a\nHeisenberg spin chain can be learned using only product training states. Since\nproduct states can be prepared using only single-qubit gates, this advances the\nprospects of learning quantum dynamics using near term quantum computers and\nquantum experiments, and further opens up new methods for both the classical\nand quantum compilation of quantum circuits.",
          "link": "http://arxiv.org/abs/2204.10268",
          "publishedOn": "2022-04-23T00:53:49.091Z",
          "wordCount": 656,
          "title": "Out-of-distribution generalization for learning quantum dynamics. (arXiv:2204.10268v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.10018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1\">Sebastian Farquhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carey_R/0/1/0/all/0/1\">Ryan Carey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Everitt_T/0/1/0/all/0/1\">Tom Everitt</a>",
          "description": "We present a general framework for training safe agents whose naive\nincentives are unsafe. As an example, manipulative or deceptive behaviour can\nimprove rewards but should be avoided. Most approaches fail here: agents\nmaximize expected return by any means necessary. We formally describe settings\nwith 'delicate' parts of the state which should not be used as a means to an\nend. We then train agents to maximize the causal effect of actions on the\nexpected return which is not mediated by the delicate parts of state, using\nCausal Influence Diagram analysis. The resulting agents have no incentive to\ncontrol the delicate state. We further show how our framework unifies and\ngeneralizes existing proposals.",
          "link": "http://arxiv.org/abs/2204.10018",
          "publishedOn": "2022-04-23T00:53:49.042Z",
          "wordCount": 550,
          "title": "Path-Specific Objectives for Safer Agent Incentives. (arXiv:2204.10018v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.09938",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Janssen_J/0/1/0/all/0/1\">Joseph Janssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guan_V/0/1/0/all/0/1\">Vincent Guan</a>",
          "description": "Scientists frequently prioritize learning from data rather than training the\nbest possible model; however, research in machine learning often prioritizes\nthe latter. The development of marginal feature importance methods, such as\nmarginal contribution feature importance, attempts to break this trend by\nproviding a useful framework for explaining relationships in data in an\ninterpretable fashion. In this work, we generalize the framework of marginal\ncontribution feature importance to improve performance with regards to\ndetecting correlated interactions and reducing runtime. To do so, we consider\n\"information subsets\" of the set of features $F$ and show that our importance\nmetric can be computed directly after applying fair representation learning\nmethods from the AI fairness literature. The methods of optimal transport and\nlinear regression are considered and explored experimentally for removing all\nthe information of our feature of interest $f$ from the feature set $F$. Given\nthese implementations, we show on real and simulated data that ultra marginal\nfeature importance performs at least as well as marginal contribution feature\nimportance, with substantially faster computation time and better performance\nin the presence of correlated interactions and unrelated features.",
          "link": "http://arxiv.org/abs/2204.09938",
          "publishedOn": "2022-04-23T00:53:49.007Z",
          "wordCount": 616,
          "title": "Ultra Marginal Feature Importance. (arXiv:2204.09938v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potosnak_W/0/1/0/all/0/1\">Willa Potosnak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "Applications of machine learning in healthcare often require working with\ntime-to-event prediction tasks including prognostication of an adverse event,\nre-hospitalization or death. Such outcomes are typically subject to censoring\ndue to loss of follow up. Standard machine learning methods cannot be applied\nin a straightforward manner to datasets with censored outcomes. In this paper,\nwe present auton-survival, an open-source repository of tools to streamline\nworking with censored time-to-event or survival data. auton-survival includes\ntools for survival regression, adjustment in the presence of domain shift,\ncounterfactual estimation, phenotyping for risk stratification, evaluation, as\nwell as estimation of treatment effects. Through real world case studies\nemploying a large subset of the SEER oncology incidence data, we demonstrate\nthe ability of auton-survival to rapidly support data scientists in answering\ncomplex health and epidemiological questions.",
          "link": "http://arxiv.org/abs/2204.07276",
          "publishedOn": "2022-04-18T00:59:13.761Z",
          "wordCount": null,
          "title": "auton-survival: an Open-Source Package for Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data. (arXiv:2204.07276v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07172",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1\">Gabriel Loaiza-Ganem</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ross_B/0/1/0/all/0/1\">Brendan Leigh Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caterini_A/0/1/0/all/0/1\">Anthony L. Caterini</a>",
          "description": "Likelihood-based, or explicit, deep generative models use neural networks to\nconstruct flexible high-dimensional densities. This formulation directly\ncontradicts the manifold hypothesis, which states that observed data lies on a\nlow-dimensional manifold embedded in high-dimensional ambient space. In this\npaper we investigate the pathologies of maximum-likelihood training in the\npresence of this dimensionality mismatch. We formally prove that degenerate\noptima are achieved wherein the manifold itself is learned but not the\ndistribution on it, a phenomenon we call manifold overfitting. We propose a\nclass of two-step procedures consisting of a dimensionality reduction step\nfollowed by maximum-likelihood density estimation, and prove that they recover\nthe data-generating distribution in the nonparametric regime, thus avoiding\nmanifold overfitting. We also show that these procedures enable density\nestimation on the manifolds learned by implicit models, such as generative\nadversarial networks, hence addressing a major shortcoming of these models.\nSeveral recently proposed methods are instances of our two-step procedures; we\nthus unify, extend, and theoretically justify a large class of models.",
          "link": "http://arxiv.org/abs/2204.07172",
          "publishedOn": "2022-04-18T00:59:13.754Z",
          "wordCount": null,
          "title": "Diagnosing and Fixing Manifold Overfitting in Deep Generative Models. (arXiv:2204.07172v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03310",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nystrom_K/0/1/0/all/0/1\">Kaj Nystr&#xf6;m</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vestberg_M/0/1/0/all/0/1\">Matias Vestberg</a>",
          "description": "The Monge-Amp\\`ere equation is a fully nonlinear partial differential\nequation (PDE) of fundamental importance in analysis, geometry and in the\napplied sciences. In this paper we solve the Dirichlet problem associated with\nthe Monge-Amp\\`ere equation using neural networks and we show that an ansatz\nusing deep input convex neural networks can be used to find the unique convex\nsolution. As part of our analysis we study the effect of singularities,\ndiscontinuities and noise in the source function, we consider nontrivial\ndomains, and we investigate how the method performs in higher dimensions. We\nalso compare this method to an alternative approach in which standard\nfeed-forward networks are used together with a loss function which penalizes\nlack of convexity.",
          "link": "http://arxiv.org/abs/2110.03310",
          "publishedOn": "2022-04-18T00:59:13.749Z",
          "wordCount": null,
          "title": "Solving the Dirichlet problem for the Monge-Amp\\`ere equation using neural networks. (arXiv:2110.03310v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nath_U/0/1/0/all/0/1\">Utkarsh Nath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kushagra_S/0/1/0/all/0/1\">Shrinu Kushagra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yingzhen Yang</a>",
          "description": "Compressing deep neural networks while maintaining accuracy is important when\nwe want to deploy large, powerful models in production and/or edge devices. One\ncommon technique used to achieve this goal is knowledge distillation.\nTypically, the output of a static pre-defined teacher (a large base network) is\nused as soft labels to train and transfer information to a student (or smaller)\nnetwork. In this paper, we introduce Adjoined Networks, or AN, a learning\nparadigm that trains both the original base network and the smaller compressed\nnetwork together. In our training approach, the parameters of the smaller\nnetwork are shared across both the base and the compressed networks. Using our\ntraining paradigm, we can simultaneously compress (the student network) and\nregularize (the teacher network) any architecture. In this paper, we focus on\npopular CNN-based architectures used for computer vision tasks. We conduct an\nextensive experimental evaluation of our training paradigm on various\nlarge-scale datasets. Using ResNet-50 as the base network, AN achieves 71.8%\ntop-1 accuracy with only 1.8M parameters and 1.6 GFLOPs on the ImageNet\ndata-set. We further propose Differentiable Adjoined Networks (DAN), a training\nparadigm that augments AN by using neural architecture search to jointly learn\nboth the width and the weights for each layer of the smaller network. DAN\nachieves ResNet-50 level accuracy on ImageNet with $3.8\\times$ fewer parameters\nand $2.2\\times$ fewer FLOPs.",
          "link": "http://arxiv.org/abs/2006.05624",
          "publishedOn": "2022-04-18T00:59:13.748Z",
          "wordCount": null,
          "title": "Adjoined Networks: A Training Paradigm with Applications to Network Compression. (arXiv:2006.05624v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.13579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ruo Yu Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francois_Lavet_V/0/1/0/all/0/1\">Vincent Fran&#xe7;ois-Lavet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "We present a new approach for efficient exploration which leverages a\nlow-dimensional encoding of the environment learned with a combination of\nmodel-based and model-free objectives. Our approach uses intrinsic rewards that\nare based on the distance of nearest neighbors in the low dimensional\nrepresentational space to gauge novelty. We then leverage these intrinsic\nrewards for sample-efficient exploration with planning routines in\nrepresentational space for hard exploration tasks with sparse rewards. One key\nelement of our approach is the use of information theoretic principles to shape\nour representations in a way so that our novelty reward goes beyond pixel\nsimilarity. We test our approach on a number of maze tasks, as well as a\ncontrol problem and show that our exploration approach is more sample-efficient\ncompared to strong baselines.",
          "link": "http://arxiv.org/abs/2009.13579",
          "publishedOn": "2022-04-18T00:59:13.716Z",
          "wordCount": null,
          "title": "Novelty Search in Representational Space for Sample Efficient Exploration. (arXiv:2009.13579v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1\">Paras Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruocheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candan_K/0/1/0/all/0/1\">K. Sel&#xe7;uk Candan</a>",
          "description": "Recommender systems aim to recommend new items to users by learning user and\nitem representations. In practice, these representations are highly entangled\nas they consist of information about multiple factors, including user's\ninterests, item attributes along with confounding factors such as user\nconformity, and item popularity. Considering these entangled representations\nfor inferring user preference may lead to biased recommendations (e.g., when\nthe recommender model recommends popular items even if they do not align with\nthe user's interests).\n\nRecent research proposes to debias by modeling a recommender system from a\ncausal perspective. The exposure and the ratings are analogous to the treatment\nand the outcome in the causal inference framework, respectively. The critical\nchallenge in this setting is accounting for the hidden confounders. These\nconfounders are unobserved, making it hard to measure them. On the other hand,\nsince these confounders affect both the exposure and the ratings, it is\nessential to account for them in generating debiased recommendations. To better\napproximate hidden confounders, we propose to leverage network information\n(i.e., user-social and user-item networks), which are shown to influence how\nusers discover and interact with an item. Aside from the user conformity,\naspects of confounding such as item popularity present in the network\ninformation is also captured in our method with the aid of \\textit{causal\ndisentanglement} which unravels the learned representations into independent\nfactors that are responsible for (a) modeling the exposure of an item to the\nuser, (b) predicting the ratings, and (c) controlling the hidden confounders.\nExperiments on real-world datasets validate the effectiveness of the proposed\nmodel for debiasing recommender systems.",
          "link": "http://arxiv.org/abs/2204.07221",
          "publishedOn": "2022-04-18T00:59:13.643Z",
          "wordCount": null,
          "title": "Causal Disentanglement with Network Information for Debiased Recommendations. (arXiv:2204.07221v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07526",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dudeja_R/0/1/0/all/0/1\">Rishabh Dudeja</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hsu_D/0/1/0/all/0/1\">Daniel Hsu</a>",
          "description": "Tensor PCA is a stylized statistical inference problem introduced by\nMontanari and Richard to study the computational difficulty of estimating an\nunknown parameter from higher-order moment tensors. Unlike its matrix\ncounterpart, Tensor PCA exhibits a statistical-computational gap, i.e., a\nsample size regime where the problem is information-theoretically solvable but\nconjectured to be computationally hard. This paper derives computational lower\nbounds on the run-time of memory bounded algorithms for Tensor PCA using\ncommunication complexity. These lower bounds specify a trade-off among the\nnumber of passes through the data sample, the sample size, and the memory\nrequired by any algorithm that successfully solves Tensor PCA. While the lower\nbounds do not rule out polynomial-time algorithms, they do imply that many\ncommonly-used algorithms, such as gradient descent and power method, must have\na higher iteration count when the sample size is not large enough. Similar\nlower bounds are obtained for Non-Gaussian Component Analysis, a family of\nstatistical estimation problems in which low-order moment tensors carry no\ninformation about the unknown parameter. Finally, stronger lower bounds are\nobtained for an asymmetric variant of Tensor PCA and related statistical\nestimation problems. These results explain why many estimators for these\nproblems use a memory state that is significantly larger than the effective\ndimensionality of the parameter of interest.",
          "link": "http://arxiv.org/abs/2204.07526",
          "publishedOn": "2022-04-18T00:59:13.634Z",
          "wordCount": null,
          "title": "Statistical-Computational Trade-offs in Tensor PCA and Related Problems via Communication Complexity. (arXiv:2204.07526v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungjae Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kyungwoo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wanmo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1\">Il-Chul Moon</a>",
          "description": "Recent advances in diffusion models bring the state-of-the art performance on\nimage generation tasks. However, empirical results on previous research in\ndiffusion models imply that there is an inverse correlation on performances for\ndensity estimation and sample generation. This paper analyzes that the inverse\ncorrelation arises because density estimation is mostly contributed from small\ndiffusion time, whereas sample generation mainly depends on large diffusion\ntime. However, training score network on both small and large diffusion time is\ndemanding because of the loss imbalance issue. To successfully train the score\nnetwork on both small and large diffusion time, this paper introduces a\ntraining technique, Soft Truncation, that softens the truncation time for every\nmini-batch update, which is universally applicable to any types of diffusion\nmodels. It turns out that Soft Truncation is equivalent to a diffusion model\nwith a general weight, and we prove the variational bound of the general\nweighted diffusion model. In view of this variational bound, Soft Truncation\nbecomes a natural way to train the score network. In experiments, Soft\nTruncation achieves the state-of-the-art performance on CIFAR-10, CelebA,\nCelebA-HQ $256\\times 256$, and STL-10 datasets.",
          "link": "http://arxiv.org/abs/2106.05527",
          "publishedOn": "2022-04-18T00:59:12.624Z",
          "wordCount": 695,
          "title": "Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation. (arXiv:2106.05527v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.08966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1\">Fabio Sigrist</a>",
          "description": "Latent Gaussian models and boosting are widely used techniques in statistics\nand machine learning. Tree-boosting shows excellent prediction accuracy on many\ndata sets, but potential drawbacks are that it assumes conditional independence\nof samples, produces discontinuous predictions for, e.g., spatial data, and it\ncan have difficulty with high-cardinality categorical variables. Latent\nGaussian models, such as Gaussian process and grouped random effects models,\nare flexible prior models which explicitly model dependence among samples and\nwhich allow for efficient learning of predictor functions and for making\nprobabilistic predictions. However, existing latent Gaussian models usually\nassume either a zero or a linear prior mean function which can be an\nunrealistic assumption. This article introduces a novel approach that combines\nboosting and latent Gaussian models to remedy the above-mentioned drawbacks and\nto leverage the advantages of both techniques. We obtain increased prediction\naccuracy compared to existing approaches in both simulated and real-world data\nexperiments.",
          "link": "http://arxiv.org/abs/2105.08966",
          "publishedOn": "2022-04-18T00:59:12.591Z",
          "wordCount": 628,
          "title": "Latent Gaussian Model Boosting. (arXiv:2105.08966v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.10545",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vaiciukynas_E/0/1/0/all/0/1\">Evaldas Vaiciukynas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Danenas_P/0/1/0/all/0/1\">Paulius Danenas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kontrimas_V/0/1/0/all/0/1\">Vilius Kontrimas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Butleris_R/0/1/0/all/0/1\">Rimantas Butleris</a>",
          "description": "Amounts of historical data collected increase and business intelligence\napplicability with automatic forecasting of time series are in high demand.\nWhile no single time series modeling method is universal to all types of\ndynamics, forecasting using an ensemble of several methods is often seen as a\ncompromise. Instead of fixing ensemble diversity and size, we propose to\npredict these aspects adaptively using meta-learning. Meta-learning here\nconsiders two separate random forest regression models, built on 390\ntime-series features, to rank 22 univariate forecasting methods and recommend\nensemble size. The forecasting ensemble is consequently formed from methods\nranked as the best, and forecasts are pooled using either simple or weighted\naverage (with a weight corresponding to reciprocal rank). The proposed approach\nwas tested on 12561 micro-economic time-series (expanded to 38633 for various\nforecasting horizons) of M4 competition where meta-learning outperformed Theta\nand Comb benchmarks by relative forecasting errors for all data types and\nhorizons. Best overall results were achieved by weighted pooling with a\nsymmetric mean absolute percentage error of 9.21% versus 11.05% obtained using\nthe Theta method.",
          "link": "http://arxiv.org/abs/2011.10545",
          "publishedOn": "2022-04-18T00:59:12.570Z",
          "wordCount": 669,
          "title": "Two-Step Meta-Learning for Time-Series Forecasting Ensemble. (arXiv:2011.10545v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.12426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sandler_A/0/1/0/all/0/1\">Adam Sandler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1\">Diego Klabjan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yuan Luo</a>",
          "description": "We develop methods for reducing the dimensionality of large data sets, common\nin biomedical applications. Learning about patients using genetic data often\nincludes more features than observations, which makes direct supervised\nlearning difficult. One method of reducing the feature space is to use latent\nDirichlet allocation to group genetic variants in an unsupervised manner.\nLatent Dirichlet allocation describes a patient as a mixture of topics\ncorresponding to genetic variants. This can be generalized as a Bayesian tensor\ndecomposition to account for multiple feature variables. Our most significant\ncontributions are with hierarchical topic modeling. We design distinct methods\nof incorporating hierarchical topic modeling, based on nested Chinese\nrestaurant processes and Pachinko Allocation Machine, into Bayesian tensor\ndecomposition. We apply these models to examine patients with one of four\ncommon types of cancer (breast, lung, prostate, and colorectal) and siblings\nwith and without autism spectrum disorder. We linked the genes with their\nbiological pathways and combine this information into a tensor of patients,\ncounts of their genetic variants, and the genes' membership in pathways. We\nfind that our trained models outperform baseline models, with respect to\ncoherence, by up to 40%.",
          "link": "http://arxiv.org/abs/1911.12426",
          "publishedOn": "2022-04-18T00:59:12.561Z",
          "wordCount": 669,
          "title": "Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data Analysis. (arXiv:1911.12426v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.00036",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lakshminarayanan_B/0/1/0/all/0/1\">Braghadeesh Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rojas_C/0/1/0/all/0/1\">Cristian R. Rojas</a>",
          "description": "One of the most important problems in system identification and statistics is\nhow to estimate the unknown parameters of a given model. Optimization methods\nand specialized procedures, such as Empirical Minimization (EM) can be used in\ncase the likelihood function can be computed. For situations where one can only\nsimulate from a parametric model, but the likelihood is difficult or impossible\nto evaluate, a technique known as the Two-Stage (TS) Approach can be applied to\nobtain reliable parametric estimates. Unfortunately, there is currently a lack\nof theoretical justification for TS. In this paper, we propose a statistical\ndecision-theoretical derivation of TS, which leads to Bayesian and Minimax\nestimators. We also show how to apply the TS approach on models for independent\nand identically distributed samples, by computing quantiles of the data as a\nfirst step, and using a linear function as the second stage. The proposed\nmethod is illustrated via numerical simulations.",
          "link": "http://arxiv.org/abs/2204.00036",
          "publishedOn": "2022-04-18T00:59:12.537Z",
          "wordCount": 621,
          "title": "A Statistical Decision-Theoretical Perspective on the Two-Stage Approach to Parameter Estimation. (arXiv:2204.00036v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1607.01624",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Naik_C/0/1/0/all/0/1\">Cian Naik</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caron_F/0/1/0/all/0/1\">Francois Caron</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rousseau_J/0/1/0/all/0/1\">Judith Rousseau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Palla_K/0/1/0/all/0/1\">Konstantina Palla</a>",
          "description": "In this paper we propose a Bayesian nonparametric approach to modelling\nsparse time-varying networks. A positive parameter is associated to each node\nof a network, which models the sociability of that node. Sociabilities are\nassumed to evolve over time, and are modelled via a dynamic point process\nmodel. The model is able to capture long term evolution of the sociabilities.\nMoreover, it yields sparse graphs, where the number of edges grows\nsubquadratically with the number of nodes. The evolution of the sociabilities\nis described by a tractable time-varying generalised gamma process. We provide\nsome theoretical insights into the model and apply it to three datasets: a\nsimulated network, a network of hyperlinks between communities on Reddit, and a\nnetwork of co-occurences of words in Reuters news articles after the September\n11th attacks.",
          "link": "http://arxiv.org/abs/1607.01624",
          "publishedOn": "2022-04-18T00:59:12.529Z",
          "wordCount": 585,
          "title": "Bayesian Nonparametrics for Sparse Dynamic Networks. (arXiv:1607.01624v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.08604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Galvez_B/0/1/0/all/0/1\">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granqvist_F/0/1/0/all/0/1\">Filip Granqvist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalen_R/0/1/0/all/0/1\">Rogier van Dalen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seigel_M/0/1/0/all/0/1\">Matt Seigel</a>",
          "description": "Federated learning with differential privacy, or private federated learning,\nprovides a strategy to train machine learning models while respecting users'\nprivacy. However, differential privacy can disproportionately degrade the\nperformance of the models on under-represented groups, as these parts of the\ndistribution are difficult to learn in the presence of noise. Existing\napproaches for enforcing fairness in machine learning models have considered\nthe centralized setting, in which the algorithm has access to the users' data.\nThis paper introduces an algorithm to enforce group fairness in private\nfederated learning, where users' data does not leave their devices. First, the\npaper extends the modified method of differential multipliers to empirical risk\nminimization with fairness constraints, thus providing an algorithm to enforce\nfairness in the central setting. Then, this algorithm is extended to the\nprivate federated learning setting. The proposed algorithm, \\texttt{FPFL}, is\ntested on a federated version of the Adult dataset and an \"unfair\" version of\nthe FEMNIST dataset. The experiments on these datasets show how private\nfederated learning accentuates unfairness in the trained models, and how FPFL\nis able to mitigate such unfairness.",
          "link": "http://arxiv.org/abs/2109.08604",
          "publishedOn": "2022-04-18T00:59:12.521Z",
          "wordCount": 677,
          "title": "Enforcing fairness in private federated learning via the modified method of differential multipliers. (arXiv:2109.08604v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07293",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wenying Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coker_B/0/1/0/all/0/1\">Beau Coker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jeremiah Zhe Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coull_B/0/1/0/all/0/1\">Brent A. Coull</a>",
          "description": "We develop a simple and unified framework for nonlinear variable selection\nthat incorporates model uncertainty and is compatible with a wide range of\nmachine learning models (e.g., tree ensembles, kernel methods and neural\nnetwork). In particular, for a learned nonlinear model $f(\\mathbf{x})$, we\nconsider quantifying the importance of an input variable $\\mathbf{x}^j$ using\nthe integrated gradient measure $\\psi_j = \\Vert \\frac{\\partial}{\\partial\n\\mathbf{x}^j} f(\\mathbf{x})\\Vert^2_2$. We then (1) provide a principled\napproach for quantifying variable selection uncertainty by deriving its\nposterior distribution, and (2) show that the approach is generalizable even to\nnon-differentiable models such as tree ensembles. Rigorous Bayesian\nnonparametric theorems are derived to guarantee the posterior consistency and\nasymptotic uncertainty of the proposed approach. Extensive simulation confirms\nthat the proposed algorithm outperforms existing classic and recent variable\nselection methods.",
          "link": "http://arxiv.org/abs/2204.07293",
          "publishedOn": "2022-04-18T00:59:12.513Z",
          "wordCount": 580,
          "title": "Towards a Unified Framework for Uncertainty-aware Nonlinear Variable Selection with Theoretical Guarantees. (arXiv:2204.07293v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1909.04746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khaled_A/0/1/0/all/0/1\">Ahmed Khaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "We provide a new analysis of local SGD, removing unnecessary assumptions and\nelaborating on the difference between two data regimes: identical and\nheterogeneous. In both cases, we improve the existing theory and provide values\nof the optimal stepsize and optimal number of local iterations. Our bounds are\nbased on a new notion of variance that is specific to local SGD methods with\ndifferent data. The tightness of our results is guaranteed by recovering known\nstatements when we plug $H=1$, where $H$ is the number of local steps. The\nempirical evidence further validates the severe impact of data heterogeneity on\nthe performance of local SGD.",
          "link": "http://arxiv.org/abs/1909.04746",
          "publishedOn": "2022-04-18T00:59:12.496Z",
          "wordCount": 618,
          "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data. (arXiv:1909.04746v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melnychuk_V/0/1/0/all/0/1\">Valentyn Melnychuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frauen_D/0/1/0/all/0/1\">Dennis Frauen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Estimating counterfactual outcomes over time from observational data is\nrelevant for many applications (e.g., personalized medicine). Yet,\nstate-of-the-art methods build upon simple long short-term memory (LSTM)\nnetworks, thus rendering inferences for complex, long-range dependencies\nchallenging. In this paper, we develop a novel Causal Transformer for\nestimating counterfactual outcomes over time. Our model is specifically\ndesigned to capture complex, long-range dependencies among time-varying\nconfounders. For this, we combine three transformer subnetworks with separate\ninputs for time-varying covariates, previous treatments, and previous outcomes\ninto a joint network with in-between cross-attentions. We further develop a\ncustom, end-to-end training procedure for our Causal Transformer. Specifically,\nwe propose a novel counterfactual domain confusion loss to address confounding\nbias: it aims to learn adversarial balanced representations, so that they are\npredictive of the next outcome but non-predictive of the current treatment\nassignment. We evaluate our Causal Transformer based on synthetic and\nreal-world datasets, where it achieves superior performance over current\nbaselines. To the best of our knowledge, this is the first work proposing\ntransformer-based architecture for estimating counterfactual outcomes from\nlongitudinal data.",
          "link": "http://arxiv.org/abs/2204.07258",
          "publishedOn": "2022-04-18T00:59:12.488Z",
          "wordCount": 608,
          "title": "Causal Transformer for Estimating Counterfactual Outcomes. (arXiv:2204.07258v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.14790",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+King_B/0/1/0/all/0/1\">Brian King</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kowal_D/0/1/0/all/0/1\">Daniel R. Kowal</a>",
          "description": "Dynamic Linear Models (DLMs) are commonly employed for time series analysis\ndue to their versatile structure, simple recursive updating, ability to handle\nmissing data, and probabilistic forecasting. However, the options for count\ntime series are limited: Gaussian DLMs require continuous data, while\nPoisson-based alternatives often lack sufficient modeling flexibility. We\nintroduce a novel semiparametric methodology for count time series by warping a\nGaussian DLM. The warping function has two components: a (nonparametric)\ntransformation operator that provides distributional flexibility and a rounding\noperator that ensures the correct support for the discrete data-generating\nprocess. We develop conjugate inference for the warped DLM, which enables\nanalytic and recursive updates for the state space filtering and smoothing\ndistributions. We leverage these results to produce customized and efficient\nalgorithms for inference and forecasting, including Monte Carlo simulation for\noffline analysis and an optimal particle filter for online inference. This\nframework unifies and extends a variety of discrete time series models and is\nvalid for natural counts, rounded values, and multivariate observations.\nSimulation studies illustrate the excellent forecasting capabilities of the\nwarped DLM. The proposed approach is applied to a multivariate time series of\ndaily overdose counts and demonstrates both modeling and computational\nsuccesses.",
          "link": "http://arxiv.org/abs/2110.14790",
          "publishedOn": "2022-04-18T00:59:12.480Z",
          "wordCount": 656,
          "title": "Warped Dynamic Linear Models for Time Series of Counts. (arXiv:2110.14790v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshima_T/0/1/0/all/0/1\">Takeshi Teshima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tojo_K/0/1/0/all/0/1\">Koichi Tojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oono_K/0/1/0/all/0/1\">Kenta Oono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Invertible neural networks (INNs) are neural network architectures with\ninvertibility by design. Thanks to their invertibility and the tractability of\nJacobian, INNs have various machine learning applications such as probabilistic\nmodeling, generative modeling, and representation learning. However, their\nattractive properties often come at the cost of restricting the layer designs,\nwhich poses a question on their representation power: can we use these models\nto approximate sufficiently diverse functions? To answer this question, we have\ndeveloped a general theoretical framework to investigate the representation\npower of INNs, building on a structure theorem of differential geometry. The\nframework simplifies the approximation problem of diffeomorphisms, which\nenables us to show the universal approximation properties of INNs. We apply the\nframework to two representative classes of INNs, namely Coupling-Flow-based\nINNs (CF-INNs) and Neural Ordinary Differential Equations (NODEs), and\nelucidate their high representation power despite the restrictions on their\narchitectures.",
          "link": "http://arxiv.org/abs/2204.07415",
          "publishedOn": "2022-04-18T00:59:12.472Z",
          "wordCount": 638,
          "title": "Universal approximation property of invertible neural networks. (arXiv:2204.07415v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_Klimroth_M/0/1/0/all/0/1\">Max Hahn-Klimroth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaaser_D/0/1/0/all/0/1\">Dominik Kaaser</a>",
          "description": "In the pooled data problem we are given a set of $n$ agents, each of which\nholds a hidden state bit, either $0$ or $1$. A querying procedure returns for a\nquery set the sum of the states of the queried agents. The goal is to\nreconstruct the states using as few queries as possible. In this paper we\nconsider two noise models for the pooled data problem. In the noisy channel\nmodel, the result for each agent flips with a certain probability. In the noisy\nquery model, each query result is subject to random Gaussian noise. Our results\nare twofold. First, we present and analyze for both error models a simple and\nefficient distributed algorithm that reconstructs the initial states in a\ngreedy fashion. Our novel analysis pins down the range of error probabilities\nand distributions for which our algorithm reconstructs the exact initial states\nwith high probability. Secondly, we present simulation results of our algorithm\nand compare its performance with approximate message passing (AMP) algorithms\nthat are conjectured to be optimal in a number of related problems.",
          "link": "http://arxiv.org/abs/2204.07491",
          "publishedOn": "2022-04-18T00:59:12.452Z",
          "wordCount": 635,
          "title": "Distributed Reconstruction of Noisy Pooled Data. (arXiv:2204.07491v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07136",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pozdnyakov_S/0/1/0/all/0/1\">Sergey N. Pozdnyakov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ceriotti_M/0/1/0/all/0/1\">Michele Ceriotti</a>",
          "description": "Graph neural networks (GNN) are very popular methods in machine learning and\nhave been applied very successfully to the prediction of the properties of\nmolecules and materials. First-order GNNs are well known to be incomplete,\ni.e., there exist graphs that are distinct but appear identical when seen\nthrough the lens of the GNN. More complicated schemes have thus been designed\nto increase their resolving power. Applications to molecules (and more\ngenerally, point clouds), however, add a geometric dimension to the problem.\nThe most straightforward and prevalent approach to construct graph\nrepresentation for molecules regards atoms as vertices in a graph and draws a\nbond between each pair of atoms within a chosen cutoff. Bonds can be decorated\nwith the distance between atoms, and the resulting \"distance graph NNs\" (dGNN)\nhave empirically demonstrated excellent resolving power and are widely used in\nchemical ML, with all known indistinguishable graphs being resolved in the\nfully-connected limit. Here we show that even for the restricted case of\nfully-connected graphs induced by 3D atom clouds dGNNs are not complete. We\nconstruct pairs of distinct point clouds that generate graphs that, for any\ncutoff radius, are equivalent based on a first-order Weisfeiler-Lehman test.\nThis class of degenerate structures includes chemically-plausible\nconfigurations, setting an ultimate limit to the expressive power of some of\nthe well-established GNN architectures for atomistic machine learning. Models\nthat explicitly use angular or directional information in the description of\natomic environments can resolve these degeneracies.",
          "link": "http://arxiv.org/abs/2201.07136",
          "publishedOn": "2022-04-16T00:51:43.716Z",
          "wordCount": null,
          "title": "Incompleteness of graph convolutional neural networks for points clouds in three dimensions. (arXiv:2201.07136v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ley_D/0/1/0/all/0/1\">Dan Ley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Saumitra Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>",
          "description": "Counterfactual explanations have been widely studied in explainability, with\na range of application dependent methods emerging in fairness, recourse and\nmodel understanding. However, the major shortcoming associated with these\nmethods is their inability to provide explanations beyond the local or\ninstance-level. While some works touch upon the notion of a global explanation,\ntypically suggesting to aggregate masses of local explanations in the hope of\nascertaining global properties, few provide frameworks that are either reliable\nor computationally tractable. Meanwhile, practitioners are requesting more\nefficient and interactive explainability tools. We take this opportunity to\ninvestigate existing global methods, with a focus on implementing and improving\nActionable Recourse Summaries (AReS), the only known global counterfactual\nexplanation framework for recourse.",
          "link": "http://arxiv.org/abs/2204.06917",
          "publishedOn": "2022-04-16T00:51:43.712Z",
          "wordCount": null,
          "title": "Global Counterfactual Explanations: Investigations, Implementations and Improvements. (arXiv:2204.06917v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.05933",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Freguglia_V/0/1/0/all/0/1\">Victor Freguglia</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Garcia_N/0/1/0/all/0/1\">Nancy Lopes Garcia</a>",
          "description": "We consider the problem of estimating the interacting neighborhood of a\nMarkov Random Field model with finite support and homogeneous pairwise\ninteractions based on relative positions of a two-dimensional lattice. Using a\nBayesian framework, we propose a Reversible Jump Monte Carlo Markov Chain\nalgorithm that jumps across subsets of a maximal range neighborhood, allowing\nus to perform model selection based on a marginal pseudoposterior distribution\nof models.",
          "link": "http://arxiv.org/abs/2204.05933",
          "publishedOn": "2022-04-16T00:51:43.711Z",
          "wordCount": null,
          "title": "Sparse Interaction Neighborhood Selection for Markov Random Fields via Reversible Jump and Pseudoposteriors. (arXiv:2204.05933v2 [stat.CO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04219",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ren_T/0/1/0/all/0/1\">Tongzheng Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhuo_J/0/1/0/all/0/1\">Jiacheng Zhuo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>",
          "description": "It is known that when the statistical models are singular, i.e., the Fisher\ninformation matrix at the true parameter is degenerate, the fixed step-size\ngradient descent algorithm takes polynomial number of steps in terms of the\nsample size $n$ to converge to a final statistical radius around the true\nparameter, which can be unsatisfactory for the application. To further improve\nthat computational complexity, we consider the utilization of the second-order\ninformation in the design of optimization algorithms. Specifically, we study\nthe normalized gradient descent (NormGD) algorithm for solving parameter\nestimation in parametric statistical models, which is a variant of gradient\ndescent algorithm whose step size is scaled by the maximum eigenvalue of the\nHessian matrix of the empirical loss function of statistical models. When the\npopulation loss function, i.e., the limit of the empirical loss function when\n$n$ goes to infinity, is homogeneous in all directions, we demonstrate that the\nNormGD iterates reach a final statistical radius around the true parameter\nafter a logarithmic number of iterations in terms of $n$. Therefore, for fixed\ndimension $d$, the NormGD algorithm achieves the optimal overall computational\ncomplexity $\\mathcal{O}(n)$ to reach the final statistical radius. This\ncomputational complexity is cheaper than that of the fixed step-size gradient\ndescent algorithm, which is of the order $\\mathcal{O}(n^{\\tau})$ for some $\\tau\n> 1$, to reach the same statistical radius. We illustrate our general theory\nunder two statistical models: generalized linear models and mixture models, and\nexperimental results support our prediction with general theory.",
          "link": "http://arxiv.org/abs/2202.04219",
          "publishedOn": "2022-04-16T00:51:43.709Z",
          "wordCount": null,
          "title": "Improving Computational Complexity in Statistical Models with Second-Order Information. (arXiv:2202.04219v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jenul_A/0/1/0/all/0/1\">Anna Jenul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schrunner_S/0/1/0/all/0/1\">Stefan Schrunner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_B/0/1/0/all/0/1\">Bao Ngoc Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helin_R/0/1/0/all/0/1\">Runar Helin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futsaether_C/0/1/0/all/0/1\">Cecilia Marie Futs&#xe6;ther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liland_K/0/1/0/all/0/1\">Kristian Hovde Liland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomic_O/0/1/0/all/0/1\">Oliver Tomic</a>",
          "description": "In artificial neural networks, understanding the contributions of input\nfeatures on the prediction fosters model explainability and delivers relevant\ninformation about the dataset. While typical setups for feature importance\nranking assess input features individually, in this study, we go one step\nfurther and rank the importance of groups of features, denoted as\nfeature-blocks. A feature-block can contain features of a specific type or\nfeatures derived from a particular source, which are presented to the neural\nnetwork in separate input branches (multiblock ANNs). This work presents three\nmethods pursuing distinct strategies to rank features in multiblock ANNs by\ntheir importance: (1) a composite strategy building on individual feature\nimportance rankings, (2) a knock-in, and (3) a knock-out strategy. While the\ncomposite strategy builds on state-of-the-art feature importance rankings,\nknock-in and knock-out strategies evaluate the block as a whole via a mutual\ninformation criterion. Our experiments consist of a simulation study validating\nall three approaches, followed by a case study on two distinct real-world\ndatasets to compare the strategies. We conclude that each strategy has its\nmerits for specific application scenarios.",
          "link": "http://arxiv.org/abs/2109.10279",
          "publishedOn": "2022-04-16T00:51:43.700Z",
          "wordCount": null,
          "title": "Ranking Feature-Block Importance in Artificial Multiblock Neural Networks. (arXiv:2109.10279v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.07232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trummer_I/0/1/0/all/0/1\">Immanuel Trummer</a>",
          "description": "In black-box optimization problems, we aim to maximize an unknown objective\nfunction, where the function is only accessible through feedbacks of an\nevaluation or simulation oracle. In real-life, the feedbacks of such oracles\nare often noisy and available after some unknown delay that may depend on the\ncomputation time of the oracle. Additionally, if the exact evaluations are\nexpensive but coarse approximations are available at a lower cost, the\nfeedbacks can have multi-fidelity. In order to address this problem, we propose\na generic extension of hierarchical optimistic tree search (HOO), called\nProCrastinated Tree Search (PCTS), that flexibly accommodates a delay and\nnoise-tolerant bandit algorithm. We provide a generic proof technique to\nquantify regret of PCTS under delayed, noisy, and multi-fidelity feedbacks.\nSpecifically, we derive regret bounds of PCTS enabled with delayed-UCB1 (DUCB1)\nand delayed-UCB-V (DUCBV) algorithms. Given a horizon $T$, PCTS retains the\nregret bound of non-delayed HOO for expected delay of $O(\\log T)$ and worsens\nby $O(T^{\\frac{1-\\alpha}{d+2}})$ for expected delays of $O(T^{1-\\alpha})$ for\n$\\alpha \\in (0,1]$. We experimentally validate on multiple synthetic functions\nand hyperparameter tuning problems that PCTS outperforms the state-of-the-art\nblack-box optimization methods for feedbacks with different noise levels,\ndelays, and fidelity.",
          "link": "http://arxiv.org/abs/2110.07232",
          "publishedOn": "2022-04-16T00:51:42.726Z",
          "wordCount": null,
          "title": "Procrastinated Tree Search: Black-box Optimization with Delayed, Noisy, and Multi-Fidelity Feedback. (arXiv:2110.07232v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.10431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1\">Haewon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "We investigate the fairness concerns of training a machine learning model\nusing data with missing values. Even though there are a number of fairness\nintervention methods in the literature, most of them require a complete\ntraining set as input. In practice, data can have missing values, and data\nmissing patterns can depend on group attributes (e.g. gender or race). Simply\napplying off-the-shelf fair learning algorithms to an imputed dataset may lead\nto an unfair model. In this paper, we first theoretically analyze different\nsources of discrimination risks when training with an imputed dataset. Then, we\npropose an integrated approach based on decision trees that does not require a\nseparate process of imputation and learning. Instead, we train a tree with\nmissing incorporated as attribute (MIA), which does not require explicit\nimputation, and we optimize a fairness-regularized objective function. We\ndemonstrate that our approach outperforms existing fairness intervention\nmethods applied to an imputed dataset, through several experiments on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2109.10431",
          "publishedOn": "2022-04-16T00:51:42.676Z",
          "wordCount": null,
          "title": "Fairness without Imputation: A Decision Tree Approach for Fair Prediction with Missing Values. (arXiv:2109.10431v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.13001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_T/0/1/0/all/0/1\">Thang Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1\">Yasin Abbasi-Yadkori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andr&#xe1;s Gy&#xf6;rgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vernade_C/0/1/0/all/0/1\">Claire Vernade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study a sequential decision problem where the learner faces a sequence of\n$K$-armed stochastic bandit tasks. The tasks may be designed by an adversary,\nbut the adversary is constrained to choose the optimal arm of each task in a\nsmaller (but unknown) subset of $M$ arms. The task boundaries might be known\n(the bandit meta-learning setting), or unknown (the non-stationary bandit\nsetting), and the number of tasks $N$ as well as the total number of rounds $T$\nare known ($N$ could be unknown in the meta-learning setting). We design an\nalgorithm based on a reduction to bandit submodular maximization, and show that\nits regret in both settings is smaller than the simple baseline of\n$\\tilde{O}(\\sqrt{KNT})$ that can be obtained by using standard algorithms\ndesigned for non-stationary bandit problems. For the bandit meta-learning\nproblem with fixed task length $\\tau$, we show that the regret of the algorithm\nis bounded as $\\tilde{O}(N\\sqrt{M \\tau}+N^{2/3})$. Under additional assumptions\non the identifiability of the optimal arms in each task, we show a bandit\nmeta-learning algorithm with an improved $\\tilde{O}(N\\sqrt{M \\tau}+N^{1/2})$\nregret.",
          "link": "http://arxiv.org/abs/2202.13001",
          "publishedOn": "2022-04-16T00:51:42.512Z",
          "wordCount": null,
          "title": "Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_K/0/1/0/all/0/1\">Kaan Gokcesu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokcesu_H/0/1/0/all/0/1\">Hakan Gokcesu</a>",
          "description": "We study the problem of expert advice under partial bandit feedback setting\nand create a sequential minimax optimal algorithm. Our algorithm works with a\nmore general partial monitoring setting, where, in contrast to the classical\nbandit feedback, the losses can be revealed in an adversarial manner. Our\nalgorithm adopts a universal prediction perspective, whose performance is\nanalyzed with regret against a general expert selection sequence. The regret we\nstudy is against a general competition class that covers many settings (such as\nthe switching or contextual experts settings) and the expert selection\nsequences in the competition class are determined by the application at hand.\nOur regret bounds are second order bounds in terms of the sum of squared losses\nand the normalized regret of our algorithm is invariant under arbitrary affine\ntransforms of the loss sequence. Our algorithm is truly online and does not use\nany preliminary information about the loss sequences.",
          "link": "http://arxiv.org/abs/2204.06660",
          "publishedOn": "2022-04-16T00:51:42.461Z",
          "wordCount": 620,
          "title": "Second Order Regret Bounds Against Generalized Expert Sequences under Partial Bandit Feedback. (arXiv:2204.06660v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.04788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1\">Hsiang Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1\">Mario Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "Disparate treatment occurs when a machine learning model yields different\ndecisions for individuals based on a sensitive attribute (e.g., age, sex). In\ndomains where prediction accuracy is paramount, it could potentially be\nacceptable to fit a model which exhibits disparate treatment. To evaluate the\neffect of disparate treatment, we compare the performance of split classifiers\n(i.e., classifiers trained and deployed separately on each group) with\ngroup-blind classifiers (i.e., classifiers which do not use a sensitive\nattribute). We introduce the benefit-of-splitting for quantifying the\nperformance improvement by splitting classifiers. Computing the\nbenefit-of-splitting directly from its definition could be intractable since it\ninvolves solving optimization problems over an infinite-dimensional functional\nspace. Under different performance measures, we (i) prove an equivalent\nexpression for the benefit-of-splitting which can be efficiently computed by\nsolving small-scale convex programs; (ii) provide sharp upper and lower bounds\nfor the benefit-of-splitting which reveal precise conditions where a\ngroup-blind classifier will always suffer from a non-trivial performance gap\nfrom the split classifiers. In the finite sample regime, splitting is not\nnecessarily beneficial and we provide data-dependent bounds to understand this\neffect. Finally, we validate our theoretical results through numerical\nexperiments on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2002.04788",
          "publishedOn": "2022-04-16T00:51:42.364Z",
          "wordCount": 705,
          "title": "To Split or Not to Split: The Impact of Disparate Treatment in Classification. (arXiv:2002.04788v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.15619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruoning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1\">Kangning Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1\">Raymond H. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plemmons_R/0/1/0/all/0/1\">Robert J. Plemmons</a>",
          "description": "In this work, a novel algorithm called SVM with Shape-adaptive Reconstruction\nand Smoothed Total Variation (SaR-SVM-STV) is introduced to classify\nhyperspectral images, which makes full use of spatial and spectral information.\nThe Shape-adaptive Reconstruction (SaR) is introduced to preprocess each pixel\nbased on the Pearson Correlation between pixels in its shape-adaptive (SA)\nregion. Support Vector Machines (SVMs) are trained to estimate the pixel-wise\nprobability maps of each class. Then the Smoothed Total Variation (STV) model\nis applied to denoise and generate the final classification map. Experiments\nshow that SaR-SVM-STV outperforms the SVM-STV method with a few training\nlabels, demonstrating the significance of reconstructing hyperspectral images\nbefore classification.",
          "link": "http://arxiv.org/abs/2203.15619",
          "publishedOn": "2022-04-16T00:51:38.063Z",
          "wordCount": 600,
          "title": "Classification of Hyperspectral Images Using SVM with Shape-adaptive Reconstruction and Smoothed Total Variation. (arXiv:2203.15619v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1903.09668",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yuexi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Polson_N/0/1/0/all/0/1\">Nicholas G. Polson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolov_V/0/1/0/all/0/1\">Vadim O. Sokolov</a>",
          "description": "Deep Learning (DL) methods have emerged as one of the most powerful tools for\nfunctional approximation and prediction. While the representation properties of\nDL have been well studied, uncertainty quantification remains challenging and\nlargely unexplored. Data augmentation techniques are a natural approach to\nprovide uncertainty quantification and to incorporate stochastic Monte Carlo\nsearch into stochastic gradient descent (SGD) methods. The purpose of our paper\nis to show that training DL architectures with data augmentation leads to\nefficiency gains. We use the theory of scale mixtures of normals to derive data\naugmentation strategies for deep learning. This allows variants of the\nexpectation-maximization and MCMC algorithms to be brought to bear on these\nhigh dimensional nonlinear deep learning models. To demonstrate our\nmethodology, we develop data augmentation algorithms for a variety of commonly\nused activation functions: logit, ReLU, leaky ReLU and SVM. Our methodology is\ncompared to traditional stochastic gradient descent with back-propagation. Our\noptimization procedure leads to a version of iteratively re-weighted least\nsquares and can be implemented at scale with accelerated linear algebra methods\nproviding substantial improvement in speed. We illustrate our methodology on a\nnumber of standard datasets. Finally, we conclude with directions for future\nresearch.",
          "link": "http://arxiv.org/abs/1903.09668",
          "publishedOn": "2022-04-16T00:51:38.054Z",
          "wordCount": 660,
          "title": "Data Augmentation for Bayesian Deep Learning. (arXiv:1903.09668v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06990",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bellec_P/0/1/0/all/0/1\">Pierre C Bellec</a>",
          "description": "We consider observations $(X,y)$ from single index models with unknown link\nfunction, Gaussian covariates and a regularized M-estimator $\\hat\\beta$\nconstructed from convex loss function and regularizer. In the regime where\nsample size $n$ and dimension $p$ are both increasing such that $p/n$ has a\nfinite limit, the behavior of the empirical distribution of $\\hat\\beta$ and the\npredicted values $X\\hat\\beta$ has been previously characterized in a number of\nmodels: The empirical distributions are known to converge to proximal operators\nof the loss and penalty in a related Gaussian sequence model, which captures\nthe interplay between ratio $p/n$, loss, regularization and the data generating\nprocess. This connection between$(\\hat\\beta,X\\hat\\beta)$ and the corresponding\nproximal operators require solving fixed-point equations that typically involve\nunobservable quantities such as the prior distribution on the index or the link\nfunction.\n\nThis paper develops a different theory to describe the empirical distribution\nof $\\hat\\beta$ and $X\\hat\\beta$: Approximations of $(\\hat\\beta,X\\hat\\beta)$ in\nterms of proximal operators are provided that only involve observable\nadjustments. These proposed observable adjustments are data-driven, e.g., do\nnot require prior knowledge of the index or the link function. These new\nadjustments yield confidence intervals for individual components of the index,\nas well as estimators of the correlation of $\\hat\\beta$ with the index. The\ninterplay between loss, regularization and the model is thus captured in a\ndata-driven manner, without solving the fixed-point equations studied in\nprevious works. The results apply to both strongly convex regularizers and\nunregularized M-estimation. Simulations are provided for the square and\nlogistic loss in single index models including logistic regression and 1-bit\ncompressed sensing with 20\\% corrupted bits.",
          "link": "http://arxiv.org/abs/2204.06990",
          "publishedOn": "2022-04-16T00:51:38.046Z",
          "wordCount": 698,
          "title": "Observable adjustments in single-index models for regularized M-estimators. (arXiv:2204.06990v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06935",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1\">Zhijun Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schaeffer_H/0/1/0/all/0/1\">Hayden Schaeffer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1\">Rachel Ward</a>",
          "description": "The spectra of random feature matrices provide essential information on the\nconditioning of the linear system used in random feature regression problems\nand are thus connected to the consistency and generalization of random feature\nmodels. Random feature matrices are asymmetric rectangular nonlinear matrices\ndepending on two input variables, the data and the weights, which can make\ntheir characterization challenging. We consider two settings for the two input\nvariables, either both are random variables or one is a random variable and the\nother is well-separated, i.e. there is a minimum distance between points. With\nconditions on the dimension, the complexity ratio, and the sampling variance,\nwe show that the singular values of these matrices concentrate near their full\nexpectation and near one with high-probability. In particular, since the\ndimension depends only on the logarithm of the number of random weights or the\nnumber of data points, our complexity bounds can be achieved even in moderate\ndimensions for many practical setting. The theoretical results are verified\nwith numerical experiments.",
          "link": "http://arxiv.org/abs/2204.06935",
          "publishedOn": "2022-04-16T00:51:38.038Z",
          "wordCount": 609,
          "title": "Concentration of Random Feature Matrices in High-Dimensions. (arXiv:2204.06935v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.06997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bruinsma_W/0/1/0/all/0/1\">Wessel P. Bruinsma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tegner_M/0/1/0/all/0/1\">Martin Tegn&#xe9;r</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "The Gaussian Process Convolution Model (GPCM; Tobar et al., 2015a) is a model\nfor signals with complex spectral structure. A significant limitation of the\nGPCM is that it assumes a rapidly decaying spectrum: it can only model smooth\nsignals. Moreover, inference in the GPCM currently requires (1) a mean-field\nassumption, resulting in poorly calibrated uncertainties, and (2) a tedious\nvariational optimisation of large covariance matrices. We redesign the GPCM\nmodel to induce a richer distribution over the spectrum with relaxed\nassumptions about smoothness: the Causal Gaussian Process Convolution Model\n(CGPCM) introduces a causality assumption into the GPCM, and the Rough Gaussian\nProcess Convolution Model (RGPCM) can be interpreted as a Bayesian\nnonparametric generalisation of the fractional Ornstein-Uhlenbeck process. We\nalso propose a more effective variational inference scheme, going beyond the\nmean-field assumption: we design a Gibbs sampler which directly samples from\nthe optimal variational solution, circumventing any variational optimisation\nentirely. The proposed variations of the GPCM are validated in experiments on\nsynthetic and real-world data, showing promising results.",
          "link": "http://arxiv.org/abs/2203.06997",
          "publishedOn": "2022-04-16T00:51:38.017Z",
          "wordCount": 641,
          "title": "Modelling Non-Smooth Signals with Complex Spectral Structure. (arXiv:2203.06997v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamm_K/0/1/0/all/0/1\">Keaton Hamm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henscheid_N/0/1/0/all/0/1\">Nick Henscheid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Shujie Kang</a>",
          "description": "In this paper, we propose Wasserstein Isometric Mapping (Wassmap), a\nparameter-free nonlinear dimensionality reduction technique that provides\nsolutions to some drawbacks in existing global nonlinear dimensionality\nreduction algorithms in imaging applications. Wassmap represents images via\nprobability measures in Wasserstein space, then uses pairwise quadratic\nWasserstein distances between the associated measures to produce a\nlow-dimensional, approximately isometric embedding. We show that the algorithm\nis able to exactly recover parameters of some image manifolds including those\ngenerated by translations or dilations of a fixed generating measure.\nAdditionally, we show that a discrete version of the algorithm retrieves\nparameters from manifolds generated from discrete measures by providing a\ntheoretical bridge to transfer recovery results from functional data to\ndiscrete data. Testing of the proposed algorithms on various image data\nmanifolds show that Wassmap yields good embeddings compared with other global\ntechniques.",
          "link": "http://arxiv.org/abs/2204.06645",
          "publishedOn": "2022-04-16T00:51:38.009Z",
          "wordCount": 585,
          "title": "Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning. (arXiv:2204.06645v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.06246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "Making an informed decision -- for example, when choosing a career or housing\n-- requires knowledge about the available options. Such knowledge is generally\nacquired through costly trial and error, but this learning process can be\ndisrupted by competition. In this work, we study how competition affects the\nlong-term outcomes of individuals as they learn. We build on a line of work\nthat models this setting as a two-sided matching market with bandit learners. A\nrecent result in this area states that it is impossible to simultaneously\nguarantee two natural desiderata: stability and low optimal regret for all\nagents. Resource-allocating platforms can point to this result as a\njustification for assigning good long-term outcomes to some agents and poor\nones to others. We show that this impossibility need not hold true. In\nparticular, by modeling two additional components of competition -- namely,\ncosts and transfers -- we prove that it is possible to simultaneously guarantee\nfour desiderata: stability, low optimal regret, fairness in the distribution of\nregret, and high social welfare.",
          "link": "http://arxiv.org/abs/2102.06246",
          "publishedOn": "2022-04-16T00:51:38.001Z",
          "wordCount": 663,
          "title": "Regret, stability & fairness in matching markets with bandit learners. (arXiv:2102.06246v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06664",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Niss_L/0/1/0/all/0/1\">Laura Niss</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yuekai Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1\">Ambuj Tewari</a>",
          "description": "Sampling biases in training data are a major source of algorithmic biases in\nmachine learning systems. Although there are many methods that attempt to\nmitigate such algorithmic biases during training, the most direct and obvious\nway is simply collecting more representative training data. In this paper, we\nconsider the task of assembling a training dataset in which minority groups are\nadequately represented from a given set of data sources. In essence, this is an\nadaptive sampling problem to determine if a given point lies in the convex hull\nof the means from a set of unknown distributions. We present adaptive sampling\nmethods to determine, with high confidence, whether it is possible to assemble\na representative dataset from the given data sources. We also demonstrate the\nefficacy of our policies in simulations in the Bernoulli and a multinomial\nsetting.",
          "link": "http://arxiv.org/abs/2204.06664",
          "publishedOn": "2022-04-16T00:51:37.994Z",
          "wordCount": 575,
          "title": "Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms. (arXiv:2204.06664v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.08928",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_K/0/1/0/all/0/1\">Kan Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_X/0/1/0/all/0/1\">Xuanyi Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Unstructured text provides decision-makers with a rich data source in many\ndomains, ranging from product reviews in retailing to nursing notes in\nhealthcare. To leverage this information, words are typically translated into\nword embeddings -- vectors that encode the semantic relationships between words\n-- through unsupervised learning algorithms such as matrix factorization.\nHowever, learning word embeddings from new domains with limited training data\ncan be challenging, because the meaning/usage may be different in the new\ndomain, e.g., the word \"positive\" typically has positive sentiment, but often\nhas negative sentiment in medical notes since it may imply that a patient is\ntested positive for a disease. Intuitively, we expect that only a small number\nof domain-specific words may have new meanings/usages. We propose an intuitive\ntwo-stage estimator that exploits this structure via a group-sparse penalty to\nefficiently transfer learn domain-specific word embeddings by combining\nlarge-scale text corpora (such as Wikipedia) with limited domain-specific text\ndata. We bound the generalization error of our estimator, proving that it can\nachieve the same accuracy (compared to not transfer learning) with\nsubstantially less domain-specific data when only a small number of embeddings\nare altered between domains. Our results provide the first bounds on\ngroup-sparse matrix factorization, which may be of independent interest. We\nempirically evaluate the effectiveness of our approach compared to\nstate-of-the-art fine-tuning heuristics from natural language processing.",
          "link": "http://arxiv.org/abs/2104.08928",
          "publishedOn": "2022-04-16T00:51:37.986Z",
          "wordCount": 685,
          "title": "Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings. (arXiv:2104.08928v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yufei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Ting Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stringhini_G/0/1/0/all/0/1\">Gianluca Stringhini</a>",
          "description": "Previous security research efforts orbiting around graphs have been\nexclusively focusing on either (de-)anonymizing the graphs or understanding the\nsecurity and privacy issues of graph neural networks. Little attention has been\npaid to understand the privacy risks of integrating the output from graph\nembedding models (e.g., node embeddings) with complex downstream machine\nlearning pipelines. In this paper, we fill this gap and propose a novel\nmodel-agnostic graph recovery attack that exploits the implicit graph\nstructural information preserved in the embeddings of graph nodes. We show that\nan adversary can recover edges with decent accuracy by only gaining access to\nthe node embedding matrix of the original graph without interactions with the\nnode embedding models. We demonstrate the effectiveness and applicability of\nour graph recovery attack through extensive experiments.",
          "link": "http://arxiv.org/abs/2204.06963",
          "publishedOn": "2022-04-16T00:51:37.963Z",
          "wordCount": 594,
          "title": "Finding MNEMON: Reviving Memories of Node Embeddings. (arXiv:2204.06963v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caillon_A/0/1/0/all/0/1\">Antoine Caillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esling_P/0/1/0/all/0/1\">Philippe Esling</a>",
          "description": "Deep learning models are mostly used in an offline inference fashion.\nHowever, this strongly limits the use of these models inside audio generation\nsetups, as most creative workflows are based on real-time digital signal\nprocessing. Although approaches based on recurrent networks can be naturally\nadapted to this buffer-based computation, the use of convolutions still poses\nsome serious challenges. To tackle this issue, the use of causal streaming\nconvolutions have been proposed. However, this requires specific complexified\ntraining and can impact the resulting audio quality.\n\nIn this paper, we introduce a new method allowing to produce non-causal\nstreaming models. This allows to make any convolutional model compatible with\nreal-time buffer-based processing. As our method is based on a post-training\nreconfiguration of the model, we show that it is able to transform models\ntrained without causal constraints into a streaming model. We show how our\nmethod can be adapted to fit complex architectures with parallel branches. To\nevaluate our method, we apply it on the recent RAVE model, which provides\nhigh-quality real-time audio synthesis. We test our approach on multiple music\nand speech datasets and show that it is faster than overlap-add methods, while\nhaving no impact on the generation quality. Finally, we introduce two\nopen-source implementation of our work as Max/MSP and PureData externals, and\nas a VST audio plugin. This allows to endow traditional digital audio\nworkstation with real-time neural audio synthesis on a laptop CPU.",
          "link": "http://arxiv.org/abs/2204.07064",
          "publishedOn": "2022-04-16T00:51:37.955Z",
          "wordCount": 676,
          "title": "Streamable Neural Audio Synthesis With Non-Causal Convolutions. (arXiv:2204.07064v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.05842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dwivedi_R/0/1/0/all/0/1\">Raaz Dwivedi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "We introduce kernel thinning, a new procedure for compressing a distribution\n$\\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given\na suitable reproducing kernel $\\mathbf{k}$ and $\\mathcal{O}(n^2)$ time, kernel\nthinning compresses an $n$-point approximation to $\\mathbb{P}$ into a\n$\\sqrt{n}$-point approximation with comparable worst-case integration error\nacross the associated reproducing kernel Hilbert space. With high probability,\nthe maximum discrepancy in integration error is\n$\\mathcal{O}_d(n^{-1/2}\\sqrt{\\log n})$ for compactly supported $\\mathbb{P}$ and\n$\\mathcal{O}_d(n^{-\\frac{1}{2}} (\\log n)^{(d+1)/2}\\sqrt{\\log\\log n})$ for\nsub-exponential $\\mathbb{P}$ on $\\mathbb{R}^d$. In contrast, an equal-sized\ni.i.d. sample from $\\mathbb{P}$ suffers $\\Omega(n^{-1/4})$ integration error.\nOur sub-exponential guarantees resemble the classical quasi-Monte Carlo error\nrates for uniform $\\mathbb{P}$ on $[0,1]^d$ but apply to general distributions\non $\\mathbb{R}^d$ and a wide range of common kernels. We use our results to\nderive explicit non-asymptotic maximum mean discrepancy bounds for Gaussian,\nMat\\'ern, and B-spline kernels and present two vignettes illustrating the\npractical benefits of kernel thinning over i.i.d. sampling and standard Markov\nchain Monte Carlo thinning, in dimensions $d=2$ through $100$.",
          "link": "http://arxiv.org/abs/2105.05842",
          "publishedOn": "2022-04-16T00:51:37.947Z",
          "wordCount": 674,
          "title": "Kernel Thinning. (arXiv:2105.05842v7 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorinova_M/0/1/0/all/0/1\">Maria I. Gorinova</a>",
          "description": "Probabilistic programming is a growing area that strives to make statistical\nanalysis more accessible, by separating probabilistic modelling from\nprobabilistic inference. In practice this decoupling is difficult. No single\ninference algorithm can be used as a probabilistic programming back-end that is\nsimultaneously reliable, efficient, black-box, and general. Probabilistic\nprogramming languages often choose a single algorithm to apply to a given\nproblem, thus inheriting its limitations. While substantial work has been done\nboth to formalise probabilistic programming and to improve efficiency of\ninference, there has been little work that makes use of the available program\nstructure, by formally analysing it, to better utilise the underlying inference\nalgorithm.\n\nThis dissertation presents three novel techniques (both static and dynamic),\nwhich aim to improve probabilistic programming using program analysis. The\ntechniques analyse a probabilistic program and adapt it to make inference more\nefficient, sometimes in a way that would have been tedious or impossible to do\nby hand.",
          "link": "http://arxiv.org/abs/2204.06868",
          "publishedOn": "2022-04-16T00:51:37.939Z",
          "wordCount": 588,
          "title": "Program Analysis of Probabilistic Programs. (arXiv:2204.06868v1 [cs.PL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.13669",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herrera_C/0/1/0/all/0/1\">Calypso Herrera</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krach_F/0/1/0/all/0/1\">Florian Krach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruyssen_P/0/1/0/all/0/1\">Pierre Ruyssen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1\">Josef Teichmann</a>",
          "description": "This paper presents new machine learning approaches to approximate the\nsolutions of optimal stopping problems. The key idea of these methods is to use\nneural networks, where the parameters of the hidden layers are generated\nrandomly and only the last layer is trained, in order to approximate the\ncontinuation value. Our approaches are applicable to high dimensional problems\nwhere the existing approaches become increasingly impractical. In addition,\nsince our approaches can be optimized using simple linear regression, they are\neasy to implement and theoretical guarantees are provided. Our randomized\nreinforcement learning approach and randomized recurrent neural network\napproach outperform the state-of-the-art and other relevant machine learning\napproaches in Markovian and non-Markovian examples, respectively. In\nparticular, we test our approaches on Black-Scholes, Heston, rough Heston and\nfractional Brownian motion. Moreover, we show that they can also be used to\nefficiently compute Greeks of American options.",
          "link": "http://arxiv.org/abs/2104.13669",
          "publishedOn": "2022-04-16T00:51:37.915Z",
          "wordCount": 607,
          "title": "Optimal Stopping via Randomized Neural Networks. (arXiv:2104.13669v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.11234",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Diethe_T/0/1/0/all/0/1\">Tom Diethe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flach_P/0/1/0/all/0/1\">Peter Flach</a>",
          "description": "The use of episodic memory in continual learning has demonstrated\neffectiveness for alleviating catastrophic forgetting. In recent studies,\ngradient-based approaches have been developed to make more efficient use of\ncompact episodic memory. Such approaches refine the gradients resulting from\nnew samples by those from memorized samples, aiming to reduce the diversity of\ngradients from different tasks. In this paper, we clarify the relation between\ndiversity of gradients and discriminativeness of representations, showing\nshared as well as conflicting interests between Deep Metric Learning and\ncontinual learning, thus demonstrating pros and cons of learning discriminative\nrepresentations in continual learning. Based on these findings, we propose a\nsimple method -- Semi-Discriminative Representation Loss (SDRL) -- for\ncontinual learning. In comparison with state-of-the-art methods, SDRL shows\nbetter performance with low computational cost on multiple benchmark tasks in\nthe setting of online continual learning.",
          "link": "http://arxiv.org/abs/2006.11234",
          "publishedOn": "2022-04-16T00:51:37.905Z",
          "wordCount": 607,
          "title": "Semi-Discriminative Representation Loss for Online Continual Learning. (arXiv:2006.11234v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.04109",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nabi_R/0/1/0/all/0/1\">Razieh Nabi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malinsky_D/0/1/0/all/0/1\">Daniel Malinsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shpitser_I/0/1/0/all/0/1\">Ilya Shpitser</a>",
          "description": "Recently there has been sustained interest in modifying prediction algorithms\nto satisfy fairness constraints. These constraints are typically complex\nnonlinear functionals of the observed data distribution. Focusing on the\npath-specific causal constraints proposed by Nabi and Shpitser (2018), we\nintroduce new theoretical results and optimization techniques to make model\ntraining easier and more accurate. Specifically, we show how to reparameterize\nthe observed data likelihood such that fairness constraints correspond directly\nto parameters that appear in the likelihood, transforming a complex constrained\noptimization objective into a simple optimization problem with box constraints.\nWe also exploit methods from empirical likelihood theory in statistics to\nimprove predictive performance by constraining baseline covariates, without\nrequiring parametric models. We combine the merits of both proposals to\noptimize a hybrid reparameterized likelihood. The techniques presented here\nshould be applicable more broadly to fair prediction proposals that impose\nconstraints on predictive models.",
          "link": "http://arxiv.org/abs/1910.04109",
          "publishedOn": "2022-04-16T00:51:37.897Z",
          "wordCount": 621,
          "title": "Optimal Training of Fair Predictive Models. (arXiv:1910.04109v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07124",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blumlein_T/0/1/0/all/0/1\">Theresa Bl&#xfc;mlein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Persson_J/0/1/0/all/0/1\">Joel Persson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>",
          "description": "Dynamic treatment regimes (DTRs) are used in medicine to tailor sequential\ntreatment decisions to patients by considering patient heterogeneity. Common\nmethods for learning optimal DTRs, however, have shortcomings: they are\ntypically based on outcome prediction and not treatment effect estimation, or\nthey use linear models that are restrictive for patient data from modern\nelectronic health records. To address these shortcomings, we develop two novel\nmethods for learning optimal DTRs that effectively handle complex patient data.\nWe call our methods DTR-CT and DTR-CF. Our methods are based on a data-driven\nestimation of heterogeneous treatment effects using causal tree methods,\nspecifically causal trees and causal forests, that learn non-linear\nrelationships, control for time-varying confounding, are doubly robust, and\nexplainable. To the best of our knowledge, our paper is the first that adapts\ncausal tree methods for learning optimal DTRs. We evaluate our proposed methods\nusing synthetic data and then apply them to real-world data from intensive care\nunits. Our methods outperform state-of-the-art baselines in terms of cumulative\nregret and percentage of optimal decisions by a considerable margin. Our work\nimproves treatment recommendations from electronic health record and is thus of\ndirect relevance for personalized medicine.",
          "link": "http://arxiv.org/abs/2204.07124",
          "publishedOn": "2022-04-16T00:51:37.887Z",
          "wordCount": 644,
          "title": "Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine. (arXiv:2204.07124v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Butler_A/0/1/0/all/0/1\">Andrew Butler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_R/0/1/0/all/0/1\">Roy H. Kwon</a>",
          "description": "Many problems in engineering and statistics involve both predictive\nforecasting and decision-based optimization. Traditionally, predictive models\nare optimized independently from the final decision-based optimization problem.\nIn contrast, a `smart, predict then optimize' (SPO) framework optimizes\nprediction models to explicitly minimize the final downstream decision loss. In\nthis paper we present dboost, a gradient boosting algorithm for training\nprediction model ensembles to minimize decision regret. The dboost framework\nsupports any convex optimization program that can be cast as convex quadratic\ncone program and gradient boosting is performed by implicit differentiation of\na custom fixed-point mapping. To our knowledge, the dboost framework is the\nfirst general purpose implementation of gradient boosting to predict and\noptimize problems. Experimental results comparing with state-of-the-art SPO\nmethods show that dboost can further reduce out-of-sample decision regret.",
          "link": "http://arxiv.org/abs/2204.06895",
          "publishedOn": "2022-04-16T00:51:37.876Z",
          "wordCount": 573,
          "title": "Gradient boosting for convex cone predict and optimize problems. (arXiv:2204.06895v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.01799",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Menictas_M/0/1/0/all/0/1\">Marianne Menictas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Credico_G/0/1/0/all/0/1\">Gioia Di Credico</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wand_M/0/1/0/all/0/1\">Matt P. Wand</a>",
          "description": "We derive streamlined mean field variational Bayes algorithms for fitting\nlinear mixed models with crossed random effects. In the most general situation,\nwhere the dimensions of the crossed groups are arbitrarily large, streamlining\nis hindered by lack of sparseness in the underlying least squares system.\nBecause of this fact we also consider a hierarchy of relaxations of the mean\nfield product restriction. The least stringent product restriction delivers a\nhigh degree of inferential accuracy. However, this accuracy must be mitigated\nagainst its higher storage and computing demands. Faster sparse storage and\ncomputing alternatives are also provided, but come with the price of diminished\ninferential accuracy. This article provides full algorithmic details of three\nvariational inference strategies, presents detailed empirical results on their\npros and cons and, thus, guides the users on their choice of variational\ninference approach depending on the problem size and computing resources.",
          "link": "http://arxiv.org/abs/1910.01799",
          "publishedOn": "2022-04-16T00:51:37.851Z",
          "wordCount": 611,
          "title": "Streamlined Variational Inference for Linear Mixed Models with Crossed Random Effects. (arXiv:1910.01799v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06900",
          "author": "<a href=\"http://arxiv.org/find/nucl-ex/1/au:+Graczykowski_L/0/1/0/all/0/1\">&#x141;ukasz Kamil Graczykowski</a>, <a href=\"http://arxiv.org/find/nucl-ex/1/au:+Jakubowska_M/0/1/0/all/0/1\">Monika Jakubowska</a>, <a href=\"http://arxiv.org/find/nucl-ex/1/au:+Deja_K/0/1/0/all/0/1\">Kamil Rafa&#x142; Deja</a>, <a href=\"http://arxiv.org/find/nucl-ex/1/au:+Kabus_M/0/1/0/all/0/1\">Maja Kabus</a> (for the ALICE Collaboration)",
          "description": "Particle identification (PID) is one of the main strengths of the ALICE\nexperiment at the LHC. It is a crucial ingredient for detailed studies of the\nstrongly interacting matter formed in ultrarelativistic heavy-ion collisions.\nALICE provides PID information via various experimental techniques, allowing\nfor the identification of particles over a broad momentum range (from around\n100 MeV/$c$ to around 50 GeV/$c$). The main challenge is how to combine the\ninformation from various detectors effectively. Therefore, PID represents a\nmodel classification problem, which can be addressed using Machine Learning\n(ML) solutions. Moreover, the complexity of the detector and richness of the\ndetection techniques make PID an interesting area of research also for the\ncomputer science community. In this work, we show the current status of the ML\napproach to PID in ALICE. We discuss the preliminary work with the Random\nForest approach for the LHC Run 2 and a more advanced solution based on Domain\nAdaptation Neural Networks, including a proposal for its future implementation\nwithin the ALICE computing software for the upcoming LHC Run 3.",
          "link": "http://arxiv.org/abs/2204.06900",
          "publishedOn": "2022-04-16T00:51:37.843Z",
          "wordCount": 650,
          "title": "Using Machine Learning for Particle Identification in ALICE. (arXiv:2204.06900v1 [nucl-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Visani_G/0/1/0/all/0/1\">Giorgio Visani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graffi_G/0/1/0/all/0/1\">Giacomo Graffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfero_M/0/1/0/all/0/1\">Mattia Alfero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagli_E/0/1/0/all/0/1\">Enrico Bagli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Capuzzo_D/0/1/0/all/0/1\">Davide Capuzzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chesani_F/0/1/0/all/0/1\">Federico Chesani</a>",
          "description": "The switch from a Model-Centric to a Data-Centric mindset is putting emphasis\non data and its quality rather than algorithms, bringing forward new\nchallenges. In particular, the sensitive nature of the information in highly\nregulated scenarios needs to be accounted for. Specific approaches to address\nthe privacy issue have been developed, as Privacy Enhancing Technologies.\nHowever, they frequently cause loss of information, putting forward a crucial\ntrade-off among data quality and privacy. A clever way to bypass such a\nconundrum relies on Synthetic Data: data obtained from a generative process,\nlearning the real data properties. Both Academia and Industry realized the\nimportance of evaluating synthetic data quality: without all-round reliable\nmetrics, the innovative data generation task has no proper objective function\nto maximize. Despite that, the topic remains under-explored. For this reason,\nwe systematically catalog the important traits of synthetic data quality and\nprivacy, and devise a specific methodology to test them. The result is DAISYnt\n(aDoption of Artificial Intelligence SYnthesis): a comprehensive suite of\nadvanced tests, which sets a de facto standard for synthetic data evaluation.\nAs a practical use-case, a variety of generative algorithms have been trained\non real-world Credit Bureau Data. The best model has been assessed, using\nDAISYnt on the different synthetic replicas. Further potential uses, among\nothers, entail auditing and fine-tuning of generative models or ensuring high\nquality of a given synthetic dataset. From a prescriptive viewpoint,\neventually, DAISYnt may pave the way to synthetic data adoption in highly\nregulated domains, ranging from Finance to Healthcare, through Insurance and\nEducation.",
          "link": "http://arxiv.org/abs/2204.06297",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "Enabling Synthetic Data adoption in regulated domains. (arXiv:2204.06297v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dandi_Y/0/1/0/all/0/1\">Yatin Dandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koloskova_A/0/1/0/all/0/1\">Anastasia Koloskova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U. Stich</a>",
          "description": "Decentralized learning provides an effective framework to train machine\nlearning models with data distributed over arbitrary communication graphs.\nHowever, most existing approaches toward decentralized learning disregard the\ninteraction between data heterogeneity and graph topology. In this paper, we\ncharacterize the dependence of convergence on the relationship between the\nmixing weights of the graph and the data heterogeneity across nodes. We propose\na metric that quantifies the ability of a graph to mix the current gradients.\nWe further prove that the metric controls the convergence rate, particularly in\nsettings where the heterogeneity across nodes dominates the stochasticity\nbetween updates for a given node. Motivated by our analysis, we propose an\napproach that periodically and efficiently optimizes the metric using standard\nconvex constrained optimization and sketching techniques. Through comprehensive\nexperiments on standard computer vision and NLP benchmarks, we show that our\napproach leads to improvement in test performance for a wide range of tasks.",
          "link": "http://arxiv.org/abs/2204.06477",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "Data-heterogeneity-aware Mixing for Decentralized Learning. (arXiv:2204.06477v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06544",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Papacharalampous_G/0/1/0/all/0/1\">Georgia Papacharalampous</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyralis_H/0/1/0/all/0/1\">Hristos Tyralis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Markonis_Y/0/1/0/all/0/1\">Yannis Markonis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maca_P/0/1/0/all/0/1\">Petr Maca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanel_M/0/1/0/all/0/1\">Martin Hanel</a>",
          "description": "Detailed feature investigations and comparisons across climates, continents\nand time series types can progress our understanding and modelling ability of\nthe Earth's hydroclimate and its dynamics. As a step towards these important\ndirections, we here propose and extensively apply a multifaceted and\nengineering-friendly methodological framework for the thorough characterization\nof seasonal hydroclimatic dependence, variability and change at the global\nscale. We apply this framework using over 13 000 quarterly temperature,\nprecipitation and river flow time series. In these time series, the seasonal\nhydroclimatic behaviour is represented by 3-month means of earth-observed\nvariables. In our analyses, we also adopt the well-established Koppen-Geiger\nclimate classification system and define continental-scale regions with large\nor medium density of observational stations. In this context, we provide in\nparallel seasonal hydroclimatic feature summaries and comparisons in terms of\nautocorrelation, seasonality, temporal variation, entropy, long-range\ndependence and trends. We find notable differences to characterize the\nmagnitudes of most of these features across the various Koppen-Geiger climate\nclasses, as well as between several continental-scale geographical regions. We,\ntherefore, deem that the consideration of the comparative summaries could be\nmore beneficial in water resources engineering contexts than the also provided\nglobal summaries. Lastly, we apply explainable machine learning to compare the\ninvestigated features with respect to how informative they are in explaining\nand predicting either the main Koppen-Geiger climate or the continental-scale\nregion, with the entropy, long-range dependence and trend features being\n(roughly) found to be less informative than the remaining ones at the seasonal\ntime scale.",
          "link": "http://arxiv.org/abs/2204.06544",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "Features of the Earth's seasonal hydroclimate: Characterizations and comparisons across the Koppen-Geiger climates and across continents. (arXiv:2204.06544v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Siviero_E/0/1/0/all/0/1\">Emilia Siviero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chautru_E/0/1/0/all/0/1\">Emilie Chautru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1\">Stephan Cl&#xe9;men&#xe7;on</a>",
          "description": "In the Big Data era, with the ubiquity of geolocation sensors in particular,\nmassive datasets exhibiting a possibly complex spatial dependence structure are\nbecoming increasingly available. In this context, the standard probabilistic\ntheory of statistical learning does not apply directly and guarantees of the\ngeneralization capacity of predictive rules learned from such data are left to\nestablish. We analyze here the simple Kriging task, the flagship problem in\nGeostatistics: the values of a square integrable random field $X=\\{X_s\\}_{s\\in\nS}$, $S\\subset \\mathbb{R}^2$, with unknown covariance structure are to be\npredicted with minimum quadratic risk, based upon observing a single\nrealization of the spatial process at a finite number of locations $s_1,\\;\n\\ldots,\\; s_n$ in $S$. Despite the connection of this minimization problem with\nkernel ridge regression, establishing the generalization capacity of empirical\nrisk minimizers is far from straightforward, due to the non i.i.d. nature of\nthe spatial data $X_{s_1},\\; \\ldots,\\; X_{s_n}$ involved. In this article,\nnonasymptotic bounds of order $O_{\\mathbb{P}}(1/n)$ are proved for the excess\nrisk of a plug-in predictive rule mimicking the true minimizer in the case of\nisotropic stationary Gaussian processes observed at locations forming a regular\ngrid. These theoretical results, as well as the role played by the technical\nconditions required to establish them, are illustrated by various numerical\nexperiments and hopefully pave the way for further developments in statistical\nlearning based on spatial data.",
          "link": "http://arxiv.org/abs/2202.07365",
          "publishedOn": "2022-04-14T00:58:51.989Z",
          "wordCount": null,
          "title": "A Statistical Learning View of Simple Kriging. (arXiv:2202.07365v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2101.10102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Renjue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pengfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Cheng-Chao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Youcheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Bai Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>",
          "description": "To analyse local robustness properties of deep neural networks (DNNs), we\npresent a practical framework from a model learning perspective. Based on\nblack-box model learning with scenario optimisation, we abstract the local\nbehaviour of a DNN via an affine model with the probably approximately correct\n(PAC) guarantee. From the learned model, we can infer the corresponding\nPAC-model robustness property. The innovation of our work is the integration of\nmodel learning into PAC robustness analysis: that is, we construct a PAC\nguarantee on the model level instead of sample distribution, which induces a\nmore faithful and accurate robustness evaluation. This is in contrast to\nexisting statistical methods without model learning. We implement our method in\na prototypical tool named DeepPAC. As a black-box method, DeepPAC is scalable\nand efficient, especially when DNNs have complex structures or high-dimensional\ninputs. We extensively evaluate DeepPAC, with 4 baselines (using formal\nverification, statistical methods, testing and adversarial attack) and 20 DNN\nmodels across 3 datasets, including MNIST, CIFAR-10, and ImageNet. It is shown\nthat DeepPAC outperforms the state-of-the-art statistical method PROVERO, and\nit achieves more practical robustness analysis than the formal verification\ntool ERAN. Also, its results are consistent with existing DNN testing work like\nDeepGini.",
          "link": "http://arxiv.org/abs/2101.10102",
          "publishedOn": "2022-04-14T00:58:51.988Z",
          "wordCount": null,
          "title": "Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning. (arXiv:2101.10102v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06375",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Blanke_M/0/1/0/all/0/1\">Matthieu Blanke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lelarge_M/0/1/0/all/0/1\">Marc Lelarge</a>",
          "description": "This work addresses the problem of exploration in an unknown environment. For\nlinear dynamical systems, we use an experimental design framework and introduce\nan online greedy policy where the control maximizes the information of the next\nstep. In a setting with a limited number of experimental trials, our algorithm\nhas low complexity and shows experimentally competitive performances compared\nto more elaborate gradient-based methods.",
          "link": "http://arxiv.org/abs/2204.06375",
          "publishedOn": "2022-04-14T00:58:51.987Z",
          "wordCount": null,
          "title": "Online greedy identification of linear dynamical systems. (arXiv:2204.06375v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ant&#xf4;nio H. Ribeiro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>",
          "description": "As machine learning models start to be used in critical applications, their\nvulnerabilities and brittleness become a pressing concern. Adversarial attacks\nare a popular framework for studying these vulnerabilities. In this work, we\nstudy the error of linear regression in the face of adversarial attacks. We\nprovide bounds of the error in terms of the traditional risk and the parameter\nnorm and show how these bounds can be leveraged and make it possible to use\nanalysis from non-adversarial setups to study the adversarial risk. The\nusefulness of these results is illustrated by shedding light on whether or not\noverparameterized linear models can be adversarially robust. We show that\nadding features to linear models might be either a source of additional\nrobustness or brittleness. We show that these differences appear due to scaling\nand how the $\\ell_1$ and $\\ell_2$ norms of random projections concentrate. We\nalso show how the reformulation we propose allows for solving adversarial\ntraining as a convex optimization problem. This is then used as a tool to study\nhow adversarial training and other regularization methods might affect the\nrobustness of the estimated models.",
          "link": "http://arxiv.org/abs/2204.06274",
          "publishedOn": "2022-04-14T00:58:51.986Z",
          "wordCount": null,
          "title": "Overparameterized Linear Regression under Adversarial Attacks. (arXiv:2204.06274v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.15646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Floto_G/0/1/0/all/0/1\">Griffin Floto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kremer_S/0/1/0/all/0/1\">Stefan Kremer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nica_M/0/1/0/all/0/1\">Mihai Nica</a>",
          "description": "An important property for deep neural networks is the ability to perform\nrobust out-of-distribution detection on previously unseen data. This property\nis essential for safety purposes when deploying models for real world\napplications. Recent studies show that probabilistic generative models can\nperform poorly on this task, which is surprising given that they seek to\nestimate the likelihood of training data. To alleviate this issue, we propose\nthe exponentially tilted Gaussian prior distribution for the Variational\nAutoencoder (VAE) which pulls points onto the surface of a hyper-sphere in\nlatent space. This achieves state-of-the art results on the area under the\ncurve-receiver operator characteristics metric using just the log-likelihood\nthat the VAE naturally assigns. Because this prior is a simple modification of\nthe traditional VAE prior, it is faster and easier to implement than\ncompetitive methods.",
          "link": "http://arxiv.org/abs/2111.15646",
          "publishedOn": "2022-04-14T00:58:51.943Z",
          "wordCount": null,
          "title": "The Exponentially Tilted Gaussian Prior for Variational Autoencoders. (arXiv:2111.15646v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06043",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Burkner_P/0/1/0/all/0/1\">Paul-Christian B&#xfc;rkner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kroker_I/0/1/0/all/0/1\">Ilja Kr&#xf6;ker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oladyshkin_S/0/1/0/all/0/1\">Sergey Oladyshkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowak_W/0/1/0/all/0/1\">Wolfgang Nowak</a>",
          "description": "Polynomial chaos expansion (PCE) is a versatile tool widely used in\nuncertainty quantification and machine learning, but its successful application\ndepends strongly on the accuracy and reliability of the resulting PCE-based\nresponse surface. High accuracy typically requires high polynomial degrees,\ndemanding many training points especially in high-dimensional problems through\nthe curse of dimensionality. So-called sparse PCE concepts work with a much\nsmaller selection of basis polynomials compared to conventional PCE approaches\nand can overcome the curse of dimensionality very efficiently, but have to pay\nspecific attention to their strategies of choosing training points.\nFurthermore, the approximation error resembles an uncertainty that most\nexisting PCE-based methods do not estimate. In this study, we develop and\nevaluate a fully Bayesian approach to establish the PCE representation via\njoint shrinkage priors and Markov chain Monte Carlo. The suggested Bayesian PCE\nmodel directly aims to solve the two challenges named above: achieving a sparse\nPCE representation and estimating uncertainty of the PCE itself. The embedded\nBayesian regularizing via the joint shrinkage prior allows using higher\npolynomial degrees for given training points due to its ability to handle\nunderdetermined situations, where the number of considered PCE coefficients\ncould be much larger than the number of available training points. We also\nexplore multiple variable selection methods to construct sparse PCE expansions\nbased on the established Bayesian representations, while globally selecting the\nmost meaningful orthonormal polynomials given the available training data. We\ndemonstrate the advantages of our Bayesian PCE and the corresponding\nsparsity-inducing methods on several benchmarks.",
          "link": "http://arxiv.org/abs/2204.06043",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "The sparse Polynomial Chaos expansion: a fully Bayesian approach with joint priors on the coefficients and global selection of terms. (arXiv:2204.06043v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06150",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Horowitz_H/0/1/0/all/0/1\">Haim Horowitz</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rao_P/0/1/0/all/0/1\">Pooja Rao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Radha_S/0/1/0/all/0/1\">Santosh Kumar Radha</a>",
          "description": "Synthetic data generation has proven to be a promising solution for\naddressing data availability issues in various domains. Even more challenging\nis the generation of synthetic time series data, where one has to preserve\ntemporal dynamics, i.e., the generated time series must respect the original\nrelationships between variables across time. Recently proposed techniques such\nas generative adversarial networks (GANs) and quantum-GANs lack the ability to\nattend to the time series specific temporal correlations adequately. We propose\nusing the inherent nature of quantum computers to simulate quantum dynamics as\na technique to encode such features. We start by assuming that a given time\nseries can be generated by a quantum process, after which we proceed to learn\nthat quantum process using quantum machine learning. We then use the learned\nmodel to generate out-of-sample time series and show that it captures unique\nand complex features of the learned time series. We also study the class of\ntime series that can be modeled using this technique. Finally, we\nexperimentally demonstrate the proposed algorithm on an 11-qubit trapped-ion\nquantum machine.",
          "link": "http://arxiv.org/abs/2204.06150",
          "publishedOn": "2022-04-14T00:58:51.901Z",
          "wordCount": null,
          "title": "A quantum generative model for multi-dimensional time series using Hamiltonian learning. (arXiv:2204.06150v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06264",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Levy_T/0/1/0/all/0/1\">Tomer Levy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Abramovich_F/0/1/0/all/0/1\">Felix Abramovich</a>",
          "description": "We consider high-dimensional multiclass classification by sparse multinomial\nlogistic regression. Unlike binary classification, in the multiclass setup one\ncan think about an entire spectrum of possible notions of sparsity associated\nwith different structural assumptions on the regression coefficients matrix. We\npropose a computationally feasible feature selection procedure based on\npenalized maximum likelihood with convex penalties capturing a specific type of\nsparsity at hand. In particular, we consider global sparsity, double row-wise\nsparsity, and low-rank sparsity, and show that with the properly chosen tuning\nparameters the derived plug-in classifiers attain the minimax generalization\nerror bounds (in terms of misclassification excess risk) within the\ncorresponding classes of multiclass sparse linear classifiers. The developed\napproach is general and can be adapted to other types of sparsity as well.",
          "link": "http://arxiv.org/abs/2204.06264",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Generalization Error Bounds for Multiclass Sparse Linear Classifiers. (arXiv:2204.06264v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.08924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asghari_S/0/1/0/all/0/1\">Seyed Mohammad Asghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwaracherla_V/0/1/0/all/0/1\">Vikranth Dwaracherla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahimi_M/0/1/0/all/0/1\">Morteza Ibrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Effective decision, exploration, and adaptation often require an agent to\nknow what it knows and, also, what it does not know. This capability relies on\nthe quality of \\textit{joint} predictions of labels assigned to multiple\ninputs. Conventional neural networks lack this capability and, since most\nresearch has focused on marginal predictions, this shortcoming has been largely\noverlooked. By assessing the quality of joint predictions it is possible to\ndetermine whether a neural network effectively distinguishes between epistemic\nuncertainty (that due to lack of knowledge) and aleatoric uncertainty (that due\nto chance). We introduce the \\textit{epistemic neural network} (ENN) as a\ngeneral interface for uncertainty modeling in deep learning. While prior\napproaches to uncertainty modeling can be viewed as ENNs, the new interface\nfacilitates comparison of joint predictions, and the design of novel\narchitectures and algorithms. In particular, we introduce the \\textit{epinet}:\nan architecture that can supplement any existing neural network, including\npretrained models, and trained with modest incremental computation to represent\nuncertainty. With an epinet, conventional neural networks outperform very large\nensembles, consisting of hundreds or more particles, with orders of magnitude\nless computation. We demonstrate this efficacy across synthetic data, ImageNet,\nand sequential decision problems. As part of this effort we open-source\nexperiment code.",
          "link": "http://arxiv.org/abs/2107.08924",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Epistemic Neural Networks. (arXiv:2107.08924v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.11507",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yuexi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaji_T/0/1/0/all/0/1\">Tetsuya Kaji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rockova_V/0/1/0/all/0/1\">Veronika Ro&#x10d;kov&#xe1;</a>",
          "description": "Approximate Bayesian Computation (ABC) enables statistical inference in\nsimulator-based models whose likelihoods are difficult to calculate but easy to\nsimulate from. ABC constructs a kernel-type approximation to the posterior\ndistribution through an accept/reject mechanism which compares summary\nstatistics of real and simulated data. To obviate the need for summary\nstatistics, we directly compare empirical distributions with a Kullback-Leibler\n(KL) divergence estimator obtained via contrastive learning. In particular, we\nblend flexible machine learning classifiers within ABC to automate fake/real\ndata comparisons. We consider the traditional accept/reject kernel as well as\nan exponential weighting scheme which does not require the ABC acceptance\nthreshold. Our theoretical results show that the rate at which our ABC\nposterior distributions concentrate around the true parameter depends on the\nestimation error of the classifier. We derive limiting posterior shape results\nand find that, with a properly scaled exponential kernel, asymptotic normality\nholds. We demonstrate the usefulness of our approach on simulated examples as\nwell as real data in the context of stock volatility estimation.",
          "link": "http://arxiv.org/abs/2111.11507",
          "publishedOn": "2022-04-14T00:58:51.900Z",
          "wordCount": null,
          "title": "Approximate Bayesian Computation via Classification. (arXiv:2111.11507v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06445",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1\">Haibao Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhai_H/0/1/0/all/0/1\">Hongzhi Zhai</a>",
          "description": "Multi-label learning is often used to mine the correlation between variables\nand multiple labels, and its research focuses on fully extracting the\ninformation between variables and labels. The $\\ell_{2,1}$ regularization is\noften used to get a sparse coefficient matrix, but the problem of\nmulticollinearity among variables cannot be effectively solved. In this paper,\nthe proposed model can choose the most relevant variables by solving a joint\nconstraint optimization problem using the $\\ell_{2,1}$ regularization and\nFrobenius regularization. In manifold regularization, we carry out a random\nwalk strategy based on the joint structure to construct a neighborhood graph,\nwhich is highly robust to outliers. In addition, we give an iterative algorithm\nof the proposed method and proved the convergence of this algorithm. The\nexperiments on the real-world data sets also show that the comprehensive\nperformance of our method is consistently better than the classical method.",
          "link": "http://arxiv.org/abs/2204.06445",
          "publishedOn": "2022-04-14T00:58:51.899Z",
          "wordCount": null,
          "title": "Random Graph Embedding and Joint Sparse Regularization for Multi-label Feature Selection. (arXiv:2204.06445v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.07084",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Osa_T/0/1/0/all/0/1\">Takayuki Osa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tangkaratt_V/0/1/0/all/0/1\">Voot Tangkaratt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Reinforcement learning algorithms are typically limited to learning a single\nsolution for a specified task, even though diverse solutions often exist.\nRecent studies showed that learning a set of diverse solutions is beneficial\nbecause diversity enables robust few-shot adaptation. Although existing methods\nlearn diverse solutions by using the mutual information as unsupervised\nrewards, such an approach often suffers from the bias of the gradient estimator\ninduced by value function approximation. In this study, we propose a novel\nmethod that can learn diverse solutions without suffering the bias problem. In\nour method, a policy conditioned on a continuous or discrete latent variable is\ntrained by directly maximizing the variational lower bound of the mutual\ninformation, instead of using the mutual information as unsupervised rewards as\nin previous studies. Through extensive experiments on robot locomotion tasks,\nwe demonstrate that the proposed method successfully learns an infinite set of\ndiverse solutions by learning continuous latent variables, which is more\nchallenging than learning a finite number of solutions. Subsequently, we show\nthat our method enables more effective few-shot adaptation compared with\nexisting methods.",
          "link": "http://arxiv.org/abs/2103.07084",
          "publishedOn": "2022-04-14T00:58:51.899Z",
          "wordCount": null,
          "title": "Discovering Diverse Solutions in Deep Reinforcement Learning by Maximizing State-Action-Based Mutual Information. (arXiv:2103.07084v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06270",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Sahlstrom_T/0/1/0/all/0/1\">Teemu Sahlstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tarvainen_T/0/1/0/all/0/1\">Tanja Tarvainen</a>",
          "description": "There has been an increasing interest in utilizing machine learning methods\nin inverse problems and imaging. Most of the work has, however, concentrated on\nimage reconstruction problems, and the number of studies regarding the full\nsolution of the inverse problem is limited. In this work, we study a machine\nlearning based approach for the Bayesian inverse problem of photoacoustic\ntomography. We develop an approach for estimating the posterior distribution in\nphotoacoustic tomography using an approach based on the variational\nautoencoder. The approach is evaluated with numerical simulations and compared\nto the solution of the inverse problem using a Bayesian approach.",
          "link": "http://arxiv.org/abs/2204.06270",
          "publishedOn": "2022-04-14T00:58:51.898Z",
          "wordCount": null,
          "title": "Utilizing variational autoencoders in the Bayesian inverse problem of photoacoustic tomography. (arXiv:2204.06270v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06476",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Waudby_Smith_I/0/1/0/all/0/1\">Ian Waudby-Smith</a>, <a href=\"http://arxiv.org/find/math/1/au:+Arbour_D/0/1/0/all/0/1\">David Arbour</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sinha_R/0/1/0/all/0/1\">Ritwik Sinha</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kennedy_E/0/1/0/all/0/1\">Edward H. Kennedy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "This work introduces time-uniform analogues of confidence intervals based on\nthe central limit theorem (CLT). Our methods take the form of confidence\nsequences (CS) -- sequences of confidence intervals that are uniformly valid\nover time. CSs provide valid inference at arbitrary stopping times, incurring\nno penalties for \"peeking\" at the data, unlike classical confidence intervals\nwhich require the sample size to be fixed in advance. Existing CSs in the\nliterature are nonasymptotic, requiring strong assumptions on the data, while\nthe classical (fixed-time) CLT is ubiquitous due to the weak assumptions it\nimposes. Our work bridges the gap by introducing time-uniform CSs that only\nrequire CLT-like assumptions. While the CLT approximates the distribution of a\nsample average by that of a Gaussian at a fixed sample size, we use strong\ninvariance principles like the seminal work of Koml\\'os, Major, and Tusn\\'ady\nto uniformly approximate the entire sample average process by an implicit\nBrownian motion. Applying Robbins' normal mixture martingale method to this\nBrownian motion then yields closed-form time-uniform boundaries. We combine\nthese boundaries with doubly robust estimators to derive nonparametric CSs for\nthe average treatment effect (and other causal estimands). These allow\nrandomized experiments and observational studies to be continuously monitored\nand adaptively stopped, all while controlling the type-I error.",
          "link": "http://arxiv.org/abs/2103.06476",
          "publishedOn": "2022-04-14T00:58:51.898Z",
          "wordCount": null,
          "title": "Time-uniform central limit theory with applications to anytime-valid causal inference. (arXiv:2103.06476v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannan_H/0/1/0/all/0/1\">Harish Kannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1\">Alexander Cloninger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1\">Rayan Saab</a>",
          "description": "We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping\nmethods for quantizing the Random Fourier features (RFFs) associated with\nshift-invariant kernels. We prove that our quantized RFFs -- even in the case\nof $1$-bit quantization -- allow a high accuracy approximation of the\nunderlying kernels, and the approximation error decays at least polynomially\nfast as the dimension of the RFFs increases. We also show that the quantized\nRFFs can be further compressed, yielding an excellent trade-off between memory\nuse and accuracy. Namely, the approximation error now decays exponentially as a\nfunction of the bits used. Moreover, we empirically show by testing the\nperformance of our methods on several machine learning tasks that our method\ncompares favorably to other state of the art quantization methods in this\ncontext.",
          "link": "http://arxiv.org/abs/2106.02614",
          "publishedOn": "2022-04-14T00:58:51.898Z",
          "wordCount": null,
          "title": "Sigma-Delta and Distributed Noise-Shaping Quantization Methods for Random Fourier Features. (arXiv:2106.02614v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1902.07190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perea_J/0/1/0/all/0/1\">Jose A. Perea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munch_E/0/1/0/all/0/1\">Elizabeth Munch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasawneh_F/0/1/0/all/0/1\">Firas A. Khasawneh</a>",
          "description": "The persistence diagram is an increasingly useful tool from Topological Data\nAnalysis, but its use alongside typical machine learning techniques requires\nmathematical finesse. The most success to date has come from methods that map\npersistence diagrams into vector spaces, in a way which maximizes the structure\npreserved. This process is commonly referred to as featurization. In this\npaper, we describe a mathematical framework for featurization called\n\\emph{template functions}, and we show that it addresses the problem of\napproximating continuous functions on compact subsets of the space of\npersistence diagrams. Specifically, we begin by characterizing relative\ncompactness with respect to the bottleneck distance, and then provide explicit\ntheoretical methods for constructing compact-open dense subsets of continuous\nfunctions on persistence diagrams. These dense subsets -- obtained via template\nfunctions -- are leveraged for supervised learning tasks with persistence\ndiagrams. Specifically, we test the method for classification and regression\nalgorithms on several examples including shape data and dynamical systems.",
          "link": "http://arxiv.org/abs/1902.07190",
          "publishedOn": "2022-04-14T00:58:51.897Z",
          "wordCount": null,
          "title": "Approximating Continuous Functions on Persistence Diagrams Using Template Functions. (arXiv:1902.07190v3 [cs.CG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.05848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changjun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaomo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofang Wang</a>",
          "description": "The demand of probabilistic time series forecasting has been recently raised\nin various dynamic system scenarios, for example, system identification and\nprognostic and health management of machines. To this end, we combine the\nadvances in both deep generative models and state space model (SSM) to come up\nwith a novel, data-driven deep probabilistic sequence model. Specifically, we\nfollow the popular encoder-decoder generative structure to build the recurrent\nneural networks (RNN) assisted variational sequence model on an augmented\nrecurrent input space, which could induce rich stochastic sequence dependency.\nBesides, in order to alleviate the inconsistency issue of the posterior between\ntraining and predicting as well as improving the mining of dynamic patterns, we\n(i) propose using a lagged hybrid output as input for the posterior at next\ntime step, which brings training and predicting into alignment; and (ii)\nfurther devise a generalized auto-regressive strategy that encodes all the\nhistorical dependencies for the posterior. Thereafter, we first investigate the\nmethodological characteristics of the proposed deep probabilistic sequence\nmodel on toy cases, and then comprehensively demonstrate the superiority of our\nmodel against existing deep probabilistic SSM models through extensive\nnumerical experiments on eight system identification benchmarks from various\ndynamic systems. Finally, we apply our sequence model to a real-world\ncentrifugal compressor forecasting problem, and again verify its outstanding\nperformance by quantifying the time series predictive distribution.",
          "link": "http://arxiv.org/abs/2106.05848",
          "publishedOn": "2022-04-14T00:58:51.897Z",
          "wordCount": null,
          "title": "Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems. (arXiv:2106.05848v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1810.03730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1\">Christian Walder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lexing Xie</a>",
          "description": "In this paper, we develop an efficient nonparametric Bayesian estimation of\nthe kernel function of Hawkes processes. The non-parametric Bayesian approach\nis important because it provides flexible Hawkes kernels and quantifies their\nuncertainty. Our method is based on the cluster representation of Hawkes\nprocesses. Utilizing the finite support assumption of the Hawkes process, we\nefficiently sample random branching structures and thus, we split the Hawkes\nprocess into clusters of Poisson processes. We derive two algorithms -- a block\nGibbs sampler and a maximum a posteriori estimator based on expectation\nmaximization -- and we show that our methods have a linear time complexity,\nboth theoretically and empirically. On synthetic data, we show our methods to\nbe able to infer flexible Hawkes triggering kernels. On two large-scale Twitter\ndiffusion datasets, we show that our methods outperform the current\nstate-of-the-art in goodness-of-fit and that the time complexity is linear in\nthe size of the dataset. We also observe that on diffusions related to online\nvideos, the learned kernels reflect the perceived longevity for different\ncontent types such as music or pets videos.",
          "link": "http://arxiv.org/abs/1810.03730",
          "publishedOn": "2022-04-14T00:58:51.823Z",
          "wordCount": null,
          "title": "Efficient Non-parametric Bayesian Hawkes Processes. (arXiv:1810.03730v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06242",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qoku_A/0/1/0/all/0/1\">Arber Qoku</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buettner_F/0/1/0/all/0/1\">Florian Buettner</a>",
          "description": "Many real-world systems are described not only by data from a single source\nbut via multiple data views. For example, in genomic medicine, a patient can be\ndescribed by data from different molecular layers. This raises the need for\nmulti-view models that are able to disentangle variation within and across data\nviews in an interpretable manner. Latent variable models with structured\nsparsity are a commonly used tool to address this modeling task but\ninterpretability is cumbersome since it requires a direct inspection and\ninterpretation of each factor via a specialized domain expert. Here, we propose\nMuVI, a novel approach for domain-informed multi-view latent variable models,\nfacilitating the analysis of multi-view data in an inherently explainable\nmanner. We demonstrate that our model (i) is able to integrate noisy domain\nexpertise in form of feature sets, (ii) is robust to noise in the encoded\ndomain knowledge, (iii) results in identifiable factors and (iv) is able to\ninfer interpretable and biologically meaningful axes of variation in a\nreal-world multi-view dataset of cancer patients.",
          "link": "http://arxiv.org/abs/2204.06242",
          "publishedOn": "2022-04-14T00:58:51.777Z",
          "wordCount": null,
          "title": "Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity. (arXiv:2204.06242v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06540",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Papacharalampous_G/0/1/0/all/0/1\">Georgia Papacharalampous</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyralis_H/0/1/0/all/0/1\">Hristos Tyralis</a>",
          "description": "Regression-based frameworks for streamflow regionalization are built around\ncatchment attributes that traditionally originate from catchment hydrology,\nflood frequency analysis and their interplay. In this work, we deviated from\nthis traditional path by formulating and extensively investigating the first\nregression-based streamflow regionalization frameworks that largely emerge from\ngeneral-purpose time series features for data science and, more precisely, from\na large variety of such features. We focused on 28 features that included\n(partial) autocorrelation, entropy, temporal variation, seasonality, trend,\nlumpiness, stability, nonlinearity, linearity, spikiness, curvature and others.\nWe estimated these features for daily temperature, precipitation and streamflow\ntime series from 511 catchments, and then merged them within regionalization\ncontexts with traditional topographic, land cover, soil and geologic\nattributes. Precipitation and temperature features (e.g., the spectral entropy,\nseasonality strength and lag-1 autocorrelation of the precipitation time\nseries, and the stability and trend strength of the temperature time series)\nwere found to be useful predictors of many streamflow features. The same\napplies to traditional attributes, such as the catchment mean elevation.\nRelationships between predictor and dependent variables were also revealed,\nwhile the spectral entropy, the seasonality strength and several\nautocorrelation features of the streamflow time series were found to be more\nregionalizable than others.",
          "link": "http://arxiv.org/abs/2204.06540",
          "publishedOn": "2022-04-14T00:58:51.589Z",
          "wordCount": null,
          "title": "Time series features for supporting hydrometeorological explorations and predictions in ungauged locations using large datasets. (arXiv:2204.06540v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06108",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Richardson_N/0/1/0/all/0/1\">Nicholas Richardson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schaeffer_H/0/1/0/all/0/1\">Hayden Schaeffer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tran_G/0/1/0/all/0/1\">Giang Tran</a>",
          "description": "Signal decomposition and multiscale signal analysis provide many useful tools\nfor time-frequency analysis. We proposed a random feature method for analyzing\ntime-series data by constructing a sparse approximation to the spectrogram. The\nrandomization is both in the time window locations and the frequency sampling,\nwhich lowers the overall sampling and computational cost. The sparsification of\nthe spectrogram leads to a sharp separation between time-frequency clusters\nwhich makes it easier to identify intrinsic modes, and thus leads to a new\ndata-driven mode decomposition. The applications include signal representation,\noutlier removal, and mode decomposition. On the benchmark tests, we show that\nour approach outperforms other state-of-the-art decomposition methods.",
          "link": "http://arxiv.org/abs/2204.06108",
          "publishedOn": "2022-04-14T00:58:51.579Z",
          "wordCount": null,
          "title": "SRMD: Sparse Random Mode Decomposition. (arXiv:2204.06108v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1\">Martin Josifoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_N/0/1/0/all/0/1\">Nicola De Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petroni_F/0/1/0/all/0/1\">Fabio Petroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>",
          "description": "Structured and grounded representation of text is typically formalized by\nclosed information extraction, the problem of extracting an exhaustive set of\n(subject, relation, object) triplets that are consistent with a predefined set\nof entities and relations from a knowledge base schema. Most existing works are\npipelines prone to error accumulation, and all approaches are only applicable\nto unrealistically small numbers of entities and relations. We introduce GenIE\n(generative information extraction), the first end-to-end autoregressive\nformulation of closed information extraction. GenIE naturally exploits the\nlanguage knowledge from the pre-trained transformer by autoregressively\ngenerating relations and entities in textual form. Thanks to a new bi-level\nconstrained generation strategy, only triplets consistent with the predefined\nknowledge base schema are produced. Our experiments show that GenIE is\nstate-of-the-art on closed information extraction, generalizes from fewer\ntraining data points than baselines, and scales to a previously unmanageable\nnumber of entities and relations. With this work, closed information extraction\nbecomes practical in realistic scenarios, providing new opportunities for\ndownstream tasks. Finally, this work paves the way towards a unified end-to-end\napproach to the core tasks of information extraction. Code, data and models\navailable at https://github.com/epfl-dlab/GenIE.",
          "link": "http://arxiv.org/abs/2112.08340",
          "publishedOn": "2022-04-14T00:58:51.579Z",
          "wordCount": null,
          "title": "GenIE: Generative Information Extraction. (arXiv:2112.08340v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12363",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saad_F/0/1/0/all/0/1\">Feras A. Saad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cusumano_Towner_M/0/1/0/all/0/1\">Marco Cusumano-Towner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mansinghka_V/0/1/0/all/0/1\">Vikash K. Mansinghka</a>",
          "description": "Estimating information-theoretic quantities such as entropy and mutual\ninformation is central to many problems in statistics and machine learning, but\nchallenging in high dimensions. This paper presents estimators of entropy via\ninference (EEVI), which deliver upper and lower bounds on many information\nquantities for arbitrary variables in a probabilistic generative model. These\nestimators use importance sampling with proposal distribution families that\ninclude amortized variational inference and sequential Monte Carlo, which can\nbe tailored to the target model and used to squeeze true information values\nwith high accuracy. We present several theoretical properties of EEVI and\ndemonstrate scalability and efficacy on two problems from the medical domain:\n(i) in an expert system for diagnosing liver disorders, we rank medical tests\naccording to how informative they are about latent diseases, given a pattern of\nobserved symptoms and patient attributes; and (ii) in a differential equation\nmodel of carbohydrate metabolism, we find optimal times to take blood glucose\nmeasurements that maximize information about a diabetic patient's insulin\nsensitivity, given their meal and medication schedule.",
          "link": "http://arxiv.org/abs/2202.12363",
          "publishedOn": "2022-04-14T00:58:51.503Z",
          "wordCount": null,
          "title": "Estimators of Entropy and Information via Inference in Probabilistic Models. (arXiv:2202.12363v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.01808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isacchini_G/0/1/0/all/0/1\">Giulio Isacchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spisak_N/0/1/0/all/0/1\">Natanael Spisak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourmohammad_A/0/1/0/all/0/1\">Armita Nourmohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mora_T/0/1/0/all/0/1\">Thierry Mora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walczak_A/0/1/0/all/0/1\">Aleksandra M. Walczak</a>",
          "description": "Simulation-based inference enables learning the parameters of a model even\nwhen its likelihood cannot be computed in practice. One class of methods uses\ndata simulated with different parameters to infer models of the\nlikelihood-to-evidence ratio, or equivalently the posterior function. Here we\nframe the inference task as an estimation of an energy function parametrized\nwith an artificial neural network. We present an intuitive approach where the\noptimal model of the likelihood-to-evidence ratio is found by maximizing the\nlikelihood of simulated data. Within this framework, the connection between the\ntask of simulation-based inference and mutual information maximization is\nclear, and we show how several known methods of posterior estimation relate to\nalternative lower bounds to mutual information. These distinct objective\nfunctions aim at the same optimal energy form and therefore can be directly\nbenchmarked. We compare their accuracy in the inference of model parameters,\nfocusing on four dynamical systems that encompass common challenges in time\nseries analysis: dynamics driven by multiplicative noise, nonlinear\ninteractions, chaotic behavior, and high-dimensional parameter space.",
          "link": "http://arxiv.org/abs/2106.01808",
          "publishedOn": "2022-04-11T00:52:26.948Z",
          "wordCount": 653,
          "title": "MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories. (arXiv:2106.01808v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.02445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1\">Kirill Shevkunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1\">Liudmila Prokhorenkova</a>",
          "description": "Various non-trivial spaces are becoming popular for embedding structured data\nsuch as graphs, texts, or images. Following spherical and hyperbolic spaces,\nmore general product spaces have been proposed. However, searching for the best\nconfiguration of product space is a resource-intensive procedure, which reduces\nthe practical applicability of the idea. We generalize the concept of product\nspace and introduce an overlapping space that does not have the configuration\nsearch problem. The main idea is to allow subsets of coordinates to be shared\nbetween spaces of different types (Euclidean, hyperbolic, spherical). As a\nresult, parameter optimization automatically learns the optimal configuration.\nAdditionally, overlapping spaces allow for more compact representations since\ntheir geometry is more complex. Our experiments confirm that overlapping spaces\noutperform the competitors in graph embedding tasks. Here, we consider both\ndistortion setup, where the aim is to preserve distances, and ranking setup,\nwhere the relative order should be preserved. The proposed method effectively\nsolves the problem and outperforms the competitors in both settings. We also\nperform an empirical analysis in a realistic information retrieval task, where\nwe compare all spaces by incorporating them into DSSM. In this case, the\nproposed overlapping space consistently achieves nearly optimal results without\nany configuration tuning. This allows for reducing training time, which can be\nsignificant in large-scale applications.",
          "link": "http://arxiv.org/abs/2007.02445",
          "publishedOn": "2022-04-11T00:52:26.939Z",
          "wordCount": 697,
          "title": "Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.02016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "The noise transition matrix plays a central role in the problem of learning\nfrom noisy labels. Among many other reasons, a significant number of existing\nsolutions rely on access to it. Estimating the transition matrix without using\nground truth labels is a critical and challenging task. When label noise\ntransition depends on each instance, the problem of identifying the\ninstance-dependent noise transition matrix becomes substantially more\nchallenging. Despite recent works proposing solutions for learning from\ninstance-dependent noisy labels, we lack a unified understanding of when such a\nproblem remains identifiable, and therefore learnable. This paper seeks to\nprovide answers to a sequence of related questions: What are the primary\nfactors that contribute to the identifiability of a noise transition matrix?\nCan we explain the observed empirical successes? When a problem is not\nidentifiable, what can we do to make it so? We will relate our theoretical\nfindings to the literature and hope to provide guidelines for developing\neffective solutions for battling instance-dependent label noise.",
          "link": "http://arxiv.org/abs/2202.02016",
          "publishedOn": "2022-04-11T00:52:26.931Z",
          "wordCount": 621,
          "title": "Identifiability of Label Noise Transition Matrix. (arXiv:2202.02016v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.04888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Christopher Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1\">Taisuke Yasuda</a>",
          "description": "We study active sampling algorithms for linear regression, which aim to query\nonly a few entries of a target vector $b\\in\\mathbb R^n$ and output a near\nminimizer to $\\min_{x\\in\\mathbb R^d} \\|Ax-b\\|$, for a design matrix\n$A\\in\\mathbb R^{n \\times d}$ and loss $\\|\\cdot\\|$.\n\nFor $p$ norm regression for any $0<p<\\infty$, we give an algorithm based on\nLewis weight sampling outputting a $(1+\\epsilon)$-approximate solution using\njust $\\tilde O(d/\\epsilon^2)$ queries to $b$ for $p\\in(0,1)$,\n$\\tilde{O}(d/\\epsilon)$ queries for $1<p<2$, and\n$\\tilde{O}(d^{p/2}/\\epsilon^p)$ queries for $2<p<\\infty$. For $0<p<2$, our\nbounds are optimal up to log factors, settling the query complexity for this\nrange. For $2<p<\\infty$, our dependence on $d$ is optimal, while our dependence\non $\\epsilon$ is off by at most $\\epsilon$, up to log factors. Our result\nresolves an open question of [CD21], who gave near optimal bounds for the $1$\nnorm, but required $d^2/\\epsilon^2$ samples for $\\ell_p$ regression with\n$1<p<2$, and gave no bounds for $2<p<\\infty$ or $0<p<1$.\n\nWe also give the first total sensitivity bound of\n$O(d^{\\max\\{1,p/2\\}}\\log^2n)$ for loss functions of degree $p$ polynomial\ngrowth, improving a result of [TMF20]. By combining this with our techniques\nfor $\\ell_p$ regression, we obtain an active regression algorithm making\n$\\tilde O(d^{1+\\max\\{1,p/2\\}}/\\mathrm{poly}(\\epsilon))$ queries for such loss\nfunctions, including the Tukey and Huber losses, answering another question of\n[CD21]. For the Huber loss, we further improve our bound to $\\tilde\nO(d^{4-2\\sqrt2}/\\mathrm{poly}(\\epsilon))$ samples. Our sensitivity bounds also\nhave many applications, including Orlicz norm subspace embeddings, robust\nsubspace approximation, and dimension reduction for smoothed $p$-norms.\n\nFinally, our active sampling results give the first sublinear time algorithms\nfor Kronecker product regression under every $p$ norm.",
          "link": "http://arxiv.org/abs/2111.04888",
          "publishedOn": "2022-04-11T00:52:26.924Z",
          "wordCount": 761,
          "title": "Active Linear Regression for $\\ell_p$ Norms and Beyond. (arXiv:2111.04888v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00464",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1\">Chris Junchi Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1\">Nicolas Loizou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roux_N/0/1/0/all/0/1\">Nicolas Le Roux</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We study the stochastic bilinear minimax optimization problem, presenting an\nanalysis of the same-sample Stochastic ExtraGradient (SEG) method with constant\nstep size, and presenting variations of the method that yield favorable\nconvergence. In sharp contrasts with the basic SEG method whose last iterate\nonly contracts to a fixed neighborhood of the Nash equilibrium, SEG augmented\nwith iteration averaging provably converges to the Nash equilibrium under the\nsame standard settings, and such a rate is further improved by incorporating a\nscheduled restarting procedure. In the interpolation setting where noise\nvanishes at the Nash equilibrium, we achieve an optimal convergence rate up to\ntight constants. We present numerical experiments that validate our theoretical\nfindings and demonstrate the effectiveness of the SEG method when equipped with\niteration averaging and restarting.",
          "link": "http://arxiv.org/abs/2107.00464",
          "publishedOn": "2022-04-11T00:52:26.916Z",
          "wordCount": 647,
          "title": "On the Convergence of Stochastic Extragradient for Bilinear Games using Restarted Iteration Averaging. (arXiv:2107.00464v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.10439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_A/0/1/0/all/0/1\">Alexander Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_A/0/1/0/all/0/1\">Andrew H. Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1\">Berkin Bilgic</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ba_D/0/1/0/all/0/1\">Demba Ba</a>",
          "description": "Sparse Bayesian learning (SBL) is a powerful framework for tackling the\nsparse coding problem while also providing uncertainty quantification. The most\npopular inference algorithms for SBL exhibit prohibitively large computational\ncosts for high-dimensional problems due to the need to maintain a large\ncovariance matrix. To resolve this issue, we introduce a new method for\naccelerating SBL inference -- named covariance-free expectation maximization\n(CoFEM) -- that avoids explicit computation of the covariance matrix. CoFEM\nsolves multiple linear systems to obtain unbiased estimates of the posterior\nstatistics needed by SBL. This is accomplished by exploiting innovations from\nnumerical linear algebra such as preconditioned conjugate gradient and a\nlittle-known diagonal estimation rule. For a large class of compressed sensing\nmatrices, we provide theoretical justifications for why our method scales well\nin high-dimensional settings. Through simulations, we show that CoFEM can be up\nto thousands of times faster than existing baselines without sacrificing coding\naccuracy. Through applications to calcium imaging deconvolution and\nmulti-contrast MRI reconstruction, we show that CoFEM enables SBL to tractably\ntackle high-dimensional sparse coding problems of practical interest.",
          "link": "http://arxiv.org/abs/2105.10439",
          "publishedOn": "2022-04-11T00:52:26.898Z",
          "wordCount": 635,
          "title": "Covariance-Free Sparse Bayesian Learning. (arXiv:2105.10439v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03771",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Min_J/0/1/0/all/0/1\">Joosung Min</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elliott_L/0/1/0/all/0/1\">Lloyd T. Elliott</a>",
          "description": "$Q$-learning is the most fundamental model-free reinforcement learning\nalgorithm. Deployment of $Q$-learning requires approximation of the\nstate-action value function (also known as the $Q$-function). In this work, we\nprovide online random forests as $Q$-function approximators and propose a novel\nmethod wherein the random forest is grown as learning proceeds (through\nexpanding forests). We demonstrate improved performance of our methods over\nstate-of-the-art Deep $Q$-Networks in two OpenAI gyms (`blackjack' and\n`inverted pendulum') but not in the `lunar lander' gym. We suspect that the\nresilience to overfitting enjoyed by random forests recommends our method for\ncommon tasks that do not require a strong representation of the problem domain.\nWe show that expanding forests (in which the number of trees increases as data\ncomes in) improve performance, suggesting that expanding forests are viable for\nother applications of online random forests beyond the reinforcement learning\nsetting.",
          "link": "http://arxiv.org/abs/2204.03771",
          "publishedOn": "2022-04-11T00:52:26.891Z",
          "wordCount": 563,
          "title": "Q-learning with online random forests. (arXiv:2204.03771v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.00594",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1\">Salah Zaiem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1\">Slim Essid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heba_A/0/1/0/all/0/1\">Abdel Heba</a>",
          "description": "Through solving pretext tasks, self-supervised learning leverages unlabeled\ndata to extract useful latent representations replacing traditional input\nfeatures in the downstream task. In audio/speech signal processing, a wide\nrange of features where engineered through decades of research efforts. As it\nturns out, learning to predict such features (a.k.a pseudo-labels) has proven\nto be a particularly relevant pretext task, leading to useful self-supervised\nrepresentations which prove to be effective for downstream tasks. However,\nmethods and common practices for combining such pretext tasks for better\nperformance on the downstream task have not been explored and understood\nproperly. In fact, the process relies almost exclusively on a computationally\nheavy experimental procedure, which becomes intractable with the increase of\nthe number of pretext tasks. This paper introduces a method to select a group\nof pretext tasks among a set of candidates. The method we propose estimates\ncalibrated weights for the partial losses corresponding to the considered\npretext tasks during the self-supervised training process. The experiments\nconducted on automatic speech recognition, speaker and emotion recognition\nvalidate our approach, as the groups selected and weighted with our method\nperform better than classic baselines, thus facilitating the selection and\ncombination of relevant pseudo-labels for self-supervised representation\nlearning.",
          "link": "http://arxiv.org/abs/2107.00594",
          "publishedOn": "2022-04-11T00:52:26.883Z",
          "wordCount": 690,
          "title": "Pretext Tasks selection for multitask self-supervised speech representation learning. (arXiv:2107.00594v4 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Anru R. Zhang</a>",
          "description": "We consider the problem of learning high dimensional polynomial\ntransformations of Gaussians. Given samples of the form $p(x)$, where $x\\sim\nN(0, \\mathrm{Id}_r)$ is hidden and $p: \\mathbb{R}^r \\to \\mathbb{R}^d$ is a\nfunction where every output coordinate is a low-degree polynomial, the goal is\nto learn the distribution over $p(x)$. This problem is natural in its own\nright, but is also an important special case of learning deep generative\nmodels, namely pushforwards of Gaussians under two-layer neural networks with\npolynomial activations. Understanding the learnability of such generative\nmodels is crucial to understanding why they perform so well in practice.\n\nOur first main result is a polynomial-time algorithm for learning quadratic\ntransformations of Gaussians in a smoothed setting. Our second main result is a\npolynomial-time algorithm for learning constant-degree polynomial\ntransformations of Gaussian in a smoothed setting, when the rank of the\nassociated tensors is small. In fact our results extend to any\nrotation-invariant input distribution, not just Gaussian. These are the first\nend-to-end guarantees for learning a pushforward under a neural network with\nmore than one layer.\n\nAlong the way, we also give the first polynomial-time algorithms with\nprovable guarantees for tensor ring decomposition, a popular generalization of\ntensor decomposition that is used in practice to implicitly store large\ntensors.",
          "link": "http://arxiv.org/abs/2204.04209",
          "publishedOn": "2022-04-11T00:52:26.875Z",
          "wordCount": 641,
          "title": "Learning Polynomial Transformations. (arXiv:2204.04209v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.05097",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Manh Tuan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1\">Noseong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>",
          "description": "Graph neural networks (GNNs) have received massive attention in the field of\nmachine learning on graphs. Inspired by the success of neural networks, a line\nof research has been conducted to train GNNs to deal with various tasks, such\nas node classification, graph classification, and link prediction. In this\nwork, our task of interest is graph classification. Several GNN models have\nbeen proposed and shown great accuracy in this task. However, the question is\nwhether usual training methods fully realize the capacity of the GNN models.\n\nIn this work, we propose a two-stage training framework based on triplet\nloss. In the first stage, GNN is trained to map each graph to a Euclidean-space\nvector so that graphs of the same class are close while those of different\nclasses are mapped far apart. Once graphs are well-separated based on labels, a\nclassifier is trained to distinguish between different classes. This method is\ngeneric in the sense that it is compatible with any GNN model. By adapting five\nGNN models to our method, we demonstrate the consistent improvement in accuracy\nand utilization of each GNN's allocated capacity over the original training\nmethod of each model up to 5.4\\% points in 12 datasets.",
          "link": "http://arxiv.org/abs/2011.05097",
          "publishedOn": "2022-04-11T00:52:26.867Z",
          "wordCount": 684,
          "title": "Two-stage Training of Graph Neural Networks for Graph Classification. (arXiv:2011.05097v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.00246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hong Jun Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Deep learning has proven effective across a range of data sets. In light of\nthis, a natural inquiry is: \"for what data generating processes can deep\nlearning succeed?\" In this work, we study the sample complexity of learning\nmultilayer data generating processes of a sort for which deep neural networks\nseem to be suited. We develop general and elegant information-theoretic tools\nthat accommodate analysis of any data generating process -- shallow or deep,\nparametric or nonparametric, noiseless or noisy. We then use these tools to\ncharacterize the dependence of sample complexity on the depth of multilayer\nprocesses. Our results indicate roughly linear dependence on depth. This is in\ncontrast to previous results that suggest exponential or high-order polynomial\ndependence.",
          "link": "http://arxiv.org/abs/2203.00246",
          "publishedOn": "2022-04-11T00:52:26.848Z",
          "wordCount": 585,
          "title": "Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.09040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kensen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bieber_D/0/1/0/all/0/1\">David Bieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>",
          "description": "The success and popularity of deep learning is on the rise, partially due to\npowerful deep learning frameworks such as TensorFlow and PyTorch that make it\neasier to develop deep learning models. However, these libraries also come with\nsteep learning curves, since programming in these frameworks is quite different\nfrom traditional imperative programming with explicit loops and conditionals.\nIn this work, we present a tool called TF-Coder for programming by example in\nTensorFlow. TF-Coder uses a bottom-up weighted enumerative search, with\nvalue-based pruning of equivalent expressions and flexible type- and\nvalue-based filtering to ensure that expressions adhere to various requirements\nimposed by the TensorFlow library. We train models to predict TensorFlow\noperations from features of the input and output tensors and natural language\ndescriptions of tasks, to prioritize relevant operations during search.\nTF-Coder solves 63 of 70 real-world tasks within 5 minutes, sometimes finding\nsimpler solutions in less time compared to experienced human programmers.",
          "link": "http://arxiv.org/abs/2003.09040",
          "publishedOn": "2022-04-11T00:52:26.839Z",
          "wordCount": 664,
          "title": "TF-Coder: Program Synthesis for Tensor Manipulations. (arXiv:2003.09040v4 [cs.PL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.00632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pauli_P/0/1/0/all/0/1\">Patricia Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funcke_N/0/1/0/all/0/1\">Niklas Funcke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gramlich_D/0/1/0/all/0/1\">Dennis Gramlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Msalmi_M/0/1/0/all/0/1\">Mohamed Amine Msalmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allgower_F/0/1/0/all/0/1\">Frank Allg&#xf6;wer</a>",
          "description": "This paper is concerned with the training of neural networks (NNs) under\nsemidefinite constraints, which allows for NN training with robustness and\nstability guarantees. In particular, we set up an efficient and scalable\ntraining scheme for NN training problems of this kind based on interior point\nmethods, while we also exploit the structure of the underlying matrix\nconstraint. We apply our training scheme to several relevant examples that have\nbeen studied in the literature and newly present the application of the method\nto the training of Wasserstein generative adversarial networks (WGANs). In\nnumerical examples, we show the superiority of our method and its applicability\nto WGAN training.",
          "link": "http://arxiv.org/abs/2201.00632",
          "publishedOn": "2022-04-11T00:52:26.832Z",
          "wordCount": 583,
          "title": "Neural network training under semidefinite constraints. (arXiv:2201.00632v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.06170",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_Q/0/1/0/all/0/1\">Qiaohui Lin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lunde_R/0/1/0/all/0/1\">Robert Lunde</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarkar_P/0/1/0/all/0/1\">Purnamrita Sarkar</a>",
          "description": "We propose a new class of multiplier bootstraps for count functionals,\nranging from a fast, approximate linear bootstrap tailored to sparse, massive\ngraphs to a quadratic bootstrap procedure that offers refined accuracy for\nsmaller, denser graphs. For the fast, approximate linear bootstrap, we show\nthat $\\sqrt{n}$-consistent inference of the count functional is attainable in\ncertain computational regimes that depend on the sparsity level of the graph.\nFurthermore, even in more challenging regimes, we prove that our bootstrap\nprocedure offers valid coverage and vanishing confidence intervals. For the\nquadratic bootstrap, we establish an Edgeworth expansion and show that this\nprocedure offers higher-order accuracy under appropriate sparsity conditions.\nWe complement our theoretical results with a simulation study and real data\nanalysis and verify that our procedure offers state-of-the-art performance for\nseveral functionals.",
          "link": "http://arxiv.org/abs/2009.06170",
          "publishedOn": "2022-04-11T00:52:26.823Z",
          "wordCount": 616,
          "title": "Trading off Accuracy for Speedup: Multiplier Bootstraps for Subgraph Counts. (arXiv:2009.06170v5 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03784",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takahashi_C/0/1/0/all/0/1\">Chako Takahashi</a>",
          "description": "The evaluation of the free energy of a stochastic model is considered to be a\nsignificant issue in various fields of physics and machine learning. However,\nthe exact free energy evaluation is computationally infeasible because it\nincludes an intractable partition function. Annealed importance sampling (AIS)\nis a type of importance sampling based on the Markov chain Monte Carlo method,\nwhich is similar to a simulated annealing, and can effectively approximate the\nfree energy. This study proposes a new AIS-based approach, referred to as\nmarginalized AIS (mAIS). The statistical efficiency of mAIS is investigated in\ndetail based on a theoretical and numerical perspectives. Based on the\ninvestigation, it has been proved that mAIS is more effective than AIS under a\ncertain condition.",
          "link": "http://arxiv.org/abs/2204.03784",
          "publishedOn": "2022-04-11T00:52:26.805Z",
          "wordCount": 564,
          "title": "Free Energy Evaluation Using Marginalized Annealed Importance Sampling. (arXiv:2204.03784v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2007.02455",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xing_L/0/1/0/all/0/1\">Li Xing</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Joun_S/0/1/0/all/0/1\">Songwan Joun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mackay_K/0/1/0/all/0/1\">Kurt Mackay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lesperance_M/0/1/0/all/0/1\">Mary Lesperance</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xuekui Zhang</a>",
          "description": "Background: Selecting feature genes to predict phenotypes is one of the\ntypical tasks in analyzing genomics data. Though many general-purpose\nalgorithms were developed for prediction, dealing with highly correlated genes\nin the prediction model is still not well addressed. High correlation among\ngenes introduces technical problems, such as multi-collinearity issues, leading\nto unreliable prediction models. Furthermore, when a causal gene (whose\nvariants have an actual biological effect on a phenotype) is highly correlated\nwith other genes, most algorithms select the feature gene from the correlated\ngroup in a purely data-driven manner. Since the correlation structure among\ngenes could change substantially when condition changes, the prediction model\nbased on not correctly selected feature genes is unreliable. Therefore, we aim\nto keep the causal biological signal in the prediction process and build a more\nrobust prediction model.\n\nMethod: We propose a grouping algorithm, which treats highly correlated genes\nas a group and uses their common pattern to represent the group's biological\nsignal in feature selection. Our novel grouping algorithm can be integrated\ninto existing prediction algorithms to enhance their prediction performance.\nOur proposed grouping method has two advantages. First, using the gene group's\ncommon patterns makes the prediction more robust and reliable under condition\nchange. Second, it reports whole correlated gene groups as discovered\nbiomarkers for prediction tasks, allowing researchers to conduct follow-up\nstudies to identify causal genes within the identified groups.\n\nResult: Using real benchmark scRNA-seq datasets with simulated cell\nphenotypes, we demonstrate our novel method significantly outperforms standard\nmodels in both (1) prediction of cell phenotypes and (2) feature gene\nselection.",
          "link": "http://arxiv.org/abs/2007.02455",
          "publishedOn": "2022-04-11T00:52:26.796Z",
          "wordCount": 741,
          "title": "Handling highly correlated genes in prediction analysis of genomic studies. (arXiv:2007.02455v4 [stat.AP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04099",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Araya_E/0/1/0/all/0/1\">Ernesto Araya</a>, <a href=\"http://arxiv.org/find/math/1/au:+Braun_G/0/1/0/all/0/1\">Guillaume Braun</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tyagi_H/0/1/0/all/0/1\">Hemant Tyagi</a>",
          "description": "In the graph matching problem we observe two graphs $G,H$ and the goal is to\nfind an assignment (or matching) between their vertices such that some measure\nof edge agreement is maximized. We assume in this work that the observed pair\n$G,H$ has been drawn from the correlated Wigner model -- a popular model for\ncorrelated weighted graphs -- where the entries of the adjacency matrices of\n$G$ and $H$ are independent Gaussians and each edge of $G$ is correlated with\none edge of $H$ (determined by the unknown matching) with the edge correlation\ndescribed by a parameter $\\sigma\\in [0,1)$. In this paper, we analyse the\nperformance of the projected power method (PPM) as a seeded graph matching\nalgorithm where we are given an initial partially correct matching (called the\nseed) as side information. We prove that if the seed is close enough to the\nground-truth matching, then with high probability, PPM iteratively improves the\nseed and recovers the ground-truth matching (either partially or exactly) in\n$\\mathcal{O}(\\log n)$ iterations. Our results prove that PPM works even in\nregimes of constant $\\sigma$, thus extending the analysis in (Mao et al.,2021)\nfor the sparse Erd\\\"os-Renyi model to the (dense) Wigner model. As a byproduct\nof our analysis, we see that the PPM framework generalizes some of the\nstate-of-art algorithms for seeded graph matching. We support and complement\nour theoretical findings with numerical experiments on synthetic data.",
          "link": "http://arxiv.org/abs/2204.04099",
          "publishedOn": "2022-04-11T00:52:26.788Z",
          "wordCount": 672,
          "title": "Seeded graph matching for the correlated Wigner model via the projected power method. (arXiv:2204.04099v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.06428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ibriga_H/0/1/0/all/0/1\">Hilda S Ibriga</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>",
          "description": "We aim to provably complete a sparse and highly-missing tensor in the\npresence of covariate information along tensor modes. Our motivation comes from\nonline advertising where users click-through-rates (CTR) on ads over various\ndevices form a CTR tensor that has about 96% missing entries and has many zeros\non non-missing entries, which makes the standalone tensor completion method\nunsatisfactory. Beside the CTR tensor, additional ad features or user\ncharacteristics are often available. In this paper, we propose\nCovariate-assisted Sparse Tensor Completion (COSTCO) to incorporate covariate\ninformation for the recovery of the sparse tensor. The key idea is to jointly\nextract latent components from both the tensor and the covariate matrix to\nlearn a synthetic representation. Theoretically, we derive the error bound for\nthe recovered tensor components and explicitly quantify the improvements on\nboth the reveal probability condition and the tensor recovery accuracy due to\ncovariates. Finally, we apply COSTCO to an advertisement dataset consisting of\na CTR tensor and ad covariate matrix, leading to 23% accuracy improvement over\nthe baseline. An important by-product is that ad latent components from COSTCO\nreveal interesting ad clusters, which are useful for better ad targeting.",
          "link": "http://arxiv.org/abs/2103.06428",
          "publishedOn": "2022-04-09T00:48:55.162Z",
          "wordCount": 664,
          "title": "Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03495",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Principal component analysis (PCA) is a dimensionality reduction method in\ndata analysis that involves diagonalizing the covariance matrix of the dataset.\nRecently, quantum algorithms have been formulated for PCA based on\ndiagonalizing a density matrix. These algorithms assume that the covariance\nmatrix can be encoded in a density matrix, but a concrete protocol for this\nencoding has been lacking. Our work aims to address this gap. Assuming\namplitude encoding of the data, with the data given by the ensemble $\\{p_i,|\n\\psi_i \\rangle\\}$, then one can easily prepare the ensemble average density\nmatrix $\\overline{\\rho} = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i |$. We first\nshow that $\\overline{\\rho}$ is precisely the covariance matrix whenever the\ndataset is centered. For quantum datasets, we exploit global phase symmetry to\nargue that there always exists a centered dataset consistent with\n$\\overline{\\rho}$, and hence $\\overline{\\rho}$ can always be interpreted as a\ncovariance matrix. This provides a simple means for preparing the covariance\nmatrix for arbitrary quantum datasets or centered classical datasets. For\nuncentered classical datasets, our method is so-called \"PCA without centering\",\nwhich we interpret as PCA on a symmetrized dataset. We argue that this closely\ncorresponds to standard PCA, and we derive equations and inequalities that\nbound the deviation of the spectrum obtained with our method from that of\nstandard PCA. We numerically illustrate our method for the MNIST handwritten\ndigit dataset. We also argue that PCA on quantum datasets is natural and\nmeaningful, and we numerically implement our method for molecular ground-state\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03495",
          "publishedOn": "2022-04-09T00:48:55.140Z",
          "wordCount": 702,
          "title": "Covariance matrix preparation for quantum principal component analysis. (arXiv:2204.03495v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.07896",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Esteban_Perez_A/0/1/0/all/0/1\">Adri&#xe1;n Esteban-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Morales_J/0/1/0/all/0/1\">Juan M. Morales</a>",
          "description": "In this paper, we develop a distributionally robust chance-constrained\nformulation of the Optimal Power Flow problem (OPF) whereby the system operator\ncan leverage contextual information. For this purpose, we exploit an ambiguity\nset based on probability trimmings and optimal transport through which the\ndispatch solution is protected against the incomplete knowledge of the\nrelationship between the OPF uncertainties and the context that is conveyed by\na sample of their joint probability distribution. We provide a tractable\nreformulation of the proposed distributionally robust chance-constrained OPF\nproblem under the popular conditional-value-at-risk approximation. By way of\nnumerical experiments run on a modified IEEE-118 bus network with wind\nuncertainty, we show how the power system can substantially benefit from taking\ninto account the well-known statistical dependence between the point forecast\nof wind power outputs and its associated prediction error. Furthermore, the\nexperiments conducted also reveal that the distributional robustness conferred\non the OPF solution by our probability-trimmings-based approach is superior to\nthat bestowed by alternative approaches in terms of expected cost and system\nreliability.",
          "link": "http://arxiv.org/abs/2109.07896",
          "publishedOn": "2022-04-09T00:48:55.132Z",
          "wordCount": 629,
          "title": "Distributionally Robust Optimal Power Flow with Contextual Information. (arXiv:2109.07896v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01533",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cuesta_Ramirez_J/0/1/0/all/0/1\">Jhouben Cuesta-Ramirez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Riche_R/0/1/0/all/0/1\">Rodolphe Le Riche</a>, <a href=\"http://arxiv.org/find/math/1/au:+Roustant_O/0/1/0/all/0/1\">Olivier Roustant</a>, <a href=\"http://arxiv.org/find/math/1/au:+Perrin_G/0/1/0/all/0/1\">Guillaume Perrin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Durantin_C/0/1/0/all/0/1\">Cedric Durantin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gliere_A/0/1/0/all/0/1\">Alain Gliere</a>",
          "description": "Most real optimization problems are defined over a mixed search space where\nthe variables are both discrete and continuous. In engineering applications,\nthe objective function is typically calculated with a numerically costly\nblack-box simulation.General mixed and costly optimization problems are\ntherefore of a great practical interest, yet their resolution remains in a\nlarge part an open scientific question. In this article, costly mixed problems\nare approached through Gaussian processes where the discrete variables are\nrelaxed into continuous latent variables. The continuous space is more easily\nharvested by classical Bayesian optimization techniques than a mixed space\nwould. Discrete variables are recovered either subsequently to the continuous\noptimization, or simultaneously with an additional continuous-discrete\ncompatibility constraint that is handled with augmented Lagrangians. Several\npossible implementations of such Bayesian mixed optimizers are compared. In\nparticular, the reformulation of the problem with continuous latent variables\nis put in competition with searches working directly in the mixed space. Among\nthe algorithms involving latent variables and an augmented Lagrangian, a\nparticular attention is devoted to the Lagrange multipliers for which a local\nand a global estimation techniques are studied. The comparisons are based on\nthe repeated optimization of three analytical functions and a beam design\nproblem.",
          "link": "http://arxiv.org/abs/2111.01533",
          "publishedOn": "2022-04-09T00:48:55.116Z",
          "wordCount": 683,
          "title": "A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.06717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasic_M/0/1/0/all/0/1\">Marko Vasic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrovic_A/0/1/0/all/0/1\">Andrija Petrovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1\">Mladen Nikolic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rishabh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurshid_S/0/1/0/all/0/1\">Sarfraz Khurshid</a>",
          "description": "Rapid advancements in deep learning have led to many recent breakthroughs.\nWhile deep learning models achieve superior performance, often statistically\nbetter than humans, their adoption into safety-critical settings, such as\nhealthcare or self-driving cars is hindered by their inability to provide\nsafety guarantees or to expose the inner workings of the model in a human\nunderstandable form. We present Mo\\\"ET, a novel model based on Mixture of\nExperts, consisting of decision tree experts and a generalized linear model\ngating function. Thanks to such gating function the model is more expressive\nthan the standard decision tree. To support non-differentiable decision trees\nas experts, we formulate a novel training procedure. In addition, we introduce\na hard thresholding version, Mo\\\"ETH, in which predictions are made solely by a\nsingle expert chosen via the gating function. Thanks to that property, Mo\\\"ETH\nallows each prediction to be easily decomposed into a set of logical rules in a\nform which can be easily verified. While Mo\\\"ET is a general use model, we\nillustrate its power in the reinforcement learning setting. By training Mo\\\"ET\nmodels using an imitation learning procedure on deep RL agents we outperform\nthe previous state-of-the-art technique based on decision trees while\npreserving the verifiability of the models. Moreover, we show that Mo\\\"ET can\nalso be used in real-world supervised problems on which it outperforms other\nverifiable machine learning models.",
          "link": "http://arxiv.org/abs/1906.06717",
          "publishedOn": "2022-04-09T00:48:55.098Z",
          "wordCount": 750,
          "title": "Mo\\\"ET: Mixture of Expert Trees and its Application to Verifiable Reinforcement Learning. (arXiv:1906.06717v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.09179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiswanger_W/0/1/0/all/0/1\">Willie Neiswanger</a>",
          "description": "With the surge in the number of hyperparameters and training times of modern\nmachine learning models, hyperparameter tuning is becoming increasingly\nexpensive. However, after assessing 40 tuning methods systematically, we find\nthat each faces certain limitations. In particular, methods that speed up\ntuning via knowledge transfer typically require the final performance of\nhyperparameters and do not focus on low-fidelity information. As we demonstrate\nempirically, this common practice is suboptimal and can incur an unnecessary\nuse of resources. It is more cost-efficient to instead leverage low-fidelity\ntuning observations to measure inter-task similarity and transfer knowledge\nfrom existing to new tasks accordingly. However, performing multi-fidelity\ntuning comes with its own challenges in the transfer setting: the noise in\nadditional observations and the need for performance forecasting. Therefore, we\npropose and conduct a thorough analysis of a multi-task multi-fidelity Bayesian\noptimization framework, which leads to the best instantiation--amortized\nauto-tuning (AT2). We further present an offline-computed 27-task\nhyperparameter recommendation (HyperRec) database to serve the community.\nExtensive experiments on HyperRec and other real-world databases illustrate the\neffectiveness of our AT2 method.",
          "link": "http://arxiv.org/abs/2106.09179",
          "publishedOn": "2022-04-09T00:48:55.076Z",
          "wordCount": 647,
          "title": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for Hyperparameter Recommendation. (arXiv:2106.09179v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Jeffrey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1\">Rajat Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tumma_N/0/1/0/all/0/1\">Neehal Tumma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "Topic models are some of the most popular ways to represent textual data in\nan interpret-able manner. Recently, advances in deep generative models,\nspecifically auto-encoding variational Bayes (AEVB), have led to the\nintroduction of unsupervised neural topic models, which leverage deep\ngenerative models as opposed to traditional statistics-based topic models. We\nextend upon these neural topic models by introducing the Label-Indexed Neural\nTopic Model (LI-NTM), which is, to the extent of our knowledge, the first\neffective upstream semi-supervised neural topic model. We find that LI-NTM\noutperforms existing neural topic models in document reconstruction benchmarks,\nwith the most notable results in low labeled data regimes and for data-sets\nwith informative labels; furthermore, our jointly learned classifier\noutperforms baseline classifiers in ablation studies.",
          "link": "http://arxiv.org/abs/2204.03208",
          "publishedOn": "2022-04-09T00:48:55.069Z",
          "wordCount": 586,
          "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling. (arXiv:2204.03208v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.09745",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulhane_P/0/1/0/all/0/1\">Pankaj Gulhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Judy Hanwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yekhanin_S/0/1/0/all/0/1\">Sergey Yekhanin</a>",
          "description": "We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n\nKnown algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.",
          "link": "http://arxiv.org/abs/2002.09745",
          "publishedOn": "2022-04-09T00:48:55.060Z",
          "wordCount": 754,
          "title": "Differentially Private Set Union. (arXiv:2002.09745v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krug_A/0/1/0/all/0/1\">Andreas Krug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratul_R/0/1/0/all/0/1\">Raihan Kabir Ratul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stober_S/0/1/0/all/0/1\">Sebastian Stober</a>",
          "description": "Machine Learning with Deep Neural Networks (DNNs) has become a successful\ntool in solving tasks across various fields of application. The success of DNNs\nis strongly connected to their high complexity in terms of the number of\nnetwork layers or of neurons in each layer, which severely complicates to\nunderstand how DNNs solve their learned task. To improve the explainability of\nDNNs, we adapt methods from neuroscience because this field has a rich\nexperience in analyzing complex and opaque systems. In this work, we draw\ninspiration from how neuroscience uses topographic maps to visualize the\nactivity of the brain when it performs certain tasks. Transferring this\napproach to DNNs can help to visualize and understand their internal processes\nmore intuitively, too. However, the inner structures of brains and DNNs differ\nsubstantially. Therefore, to be able to visualize activations of neurons in\nDNNs as topographic maps, we research techniques to layout the neurons in a\ntwo-dimensional space in which neurons of similar activity are in the vicinity\nof each other. In this work, we introduce and compare different methods to\nobtain a topographic layout of the neurons in a network layer. Moreover, we\ndemonstrate how to use the resulting topographic activation maps to identify\nerrors or encoded biases in DNNs or data sets. Our novel visualization\ntechnique improves the transparency of DNN-based algorithmic decision-making\nsystems and is accessible to a broad audience because topographic maps are\nintuitive to interpret without expert-knowledge in Machine Learning.",
          "link": "http://arxiv.org/abs/2204.03528",
          "publishedOn": "2022-04-09T00:48:55.052Z",
          "wordCount": null,
          "title": "Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">Leon Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>",
          "description": "Regularization is a fundamental technique to prevent over-fitting and to\nimprove generalization performances by constraining a model's complexity.\nCurrent Deep Networks heavily rely on regularizers such as Data-Augmentation\n(DA) or weight-decay, and employ structural risk minimization, i.e.\ncross-validation, to select the optimal regularization hyper-parameters. In\nthis study, we demonstrate that techniques such as DA or weight decay produce a\nmodel with a reduced complexity that is unfair across classes. The optimal\namount of DA or weight decay found from cross-validation leads to disastrous\nmodel performances on some classes e.g. on Imagenet with a resnet50, the \"barn\nspider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by\nintroducing random crop DA during training. Even more surprising, such\nperformance drop also appears when introducing uninformative regularization\ntechniques such as weight decay. Those results demonstrate that our search for\never increasing generalization performance -- averaged over all classes and\nsamples -- has left us with models and regularizers that silently sacrifice\nperformances on some classes. This scenario can become dangerous when deploying\na model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on\nINaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889\nwhen introducing random crop DA during the Imagenet pre-training phase. Those\nresults demonstrate that designing novel regularizers without class-dependent\nbias remains an open research question.",
          "link": "http://arxiv.org/abs/2204.03632",
          "publishedOn": "2022-04-09T00:48:55.052Z",
          "wordCount": null,
          "title": "The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03406",
          "author": "<a href=\"http://arxiv.org/find/hep-th/1/au:+Loukas_O/0/1/0/all/0/1\">Orestis Loukas</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Chung_H/0/1/0/all/0/1\">Ho Ryun Chung</a>",
          "description": "The estimation of categorical distributions under marginal constraints\nsummarizing some sample from a population in the most-generalizable way is key\nfor many machine-learning and data-driven approaches. We provide a\nparameter-agnostic theoretical framework that enables this task ensuring (i)\nthat a categorical distribution of Maximum Entropy under marginal constraints\nalways exists and (ii) that it is unique. The procedure of iterative\nproportional fitting (IPF) naturally estimates that distribution from any\nconsistent set of marginal constraints directly in the space of probabilities,\nthus deductively identifying a least-biased characterization of the population.\nThe theoretical framework together with IPF leads to a holistic workflow that\nenables modeling any class of categorical distributions solely using the\nphenomenological information provided.",
          "link": "http://arxiv.org/abs/2204.03406",
          "publishedOn": "2022-04-09T00:48:55.049Z",
          "wordCount": 565,
          "title": "Categorical Distributions of Maximum Entropy under Marginal Constraints. (arXiv:2204.03406v1 [hep-th])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.09266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_T/0/1/0/all/0/1\">Tristan Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Edward J. Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_S/0/1/0/all/0/1\">Salem Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_M/0/1/0/all/0/1\">Mo Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.",
          "link": "http://arxiv.org/abs/2111.09266",
          "publishedOn": "2022-04-09T00:48:55.042Z",
          "wordCount": 632,
          "title": "GFlowNet Foundations. (arXiv:2111.09266v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.05845",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Simpson_I/0/1/0/all/0/1\">Ivor J.A. Simpson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McManamon_A/0/1/0/all/0/1\">Ashley McManamon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Orzsik_B/0/1/0/all/0/1\">Bal&#xe1;zs &#xd6;rzsik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stone_A/0/1/0/all/0/1\">Alan J. Stone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blockley_N/0/1/0/all/0/1\">Nicholas P. Blockley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asllani_I/0/1/0/all/0/1\">Iris Asllani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colasanti_A/0/1/0/all/0/1\">Alessandro Colasanti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cercignani_M/0/1/0/all/0/1\">Mara Cercignani</a>",
          "description": "Streamlined qBOLD acquisitions enable experimentally straightforward\nobservations of brain oxygen metabolism. $R_2^\\prime$ maps are easily inferred;\nhowever, the Oxygen extraction fraction (OEF) and deoxygenated blood volume\n(DBV) are more ambiguously determined from the data. As such, existing\ninference methods tend to yield very noisy and underestimated OEF maps, while\noverestimating DBV.\n\nThis work describes a novel probabilistic machine learning approach that can\ninfer plausible distributions of OEF and DBV. Initially, we create a model that\nproduces informative voxelwise prior distribution based on synthetic training\ndata. Contrary to prior work, we model the joint distribution of OEF and DBV\nthrough a scaled multivariate logit-Normal distribution, which enables the\nvalues to be constrained within a plausible range. The prior distribution model\nis used to train an efficient amortized variational Bayesian inference model.\nThis model learns to infer OEF and DBV by predicting real image data, with few\ntraining data required, using the signal equations as a forward model.\n\nWe demonstrate that our approach enables the inference of smooth OEF and DBV\nmaps, with a physiologically plausible distribution that can be adapted through\nspecification of an informative prior distribution. Other benefits include\nmodel comparison (via the evidence lower bound) and uncertainty quantification\nfor identifying image artefacts. Results are demonstrated on a small study\ncomparing subjects undergoing hyperventilation and at rest. We illustrate that\nthe proposed approach allows measurement of gray matter differences in OEF and\nDBV and enables voxelwise comparison between conditions, where we observe\nsignificant increases in OEF and $R_2^\\prime$ during hyperventilation.",
          "link": "http://arxiv.org/abs/2203.05845",
          "publishedOn": "2022-04-09T00:48:55.020Z",
          "wordCount": 733,
          "title": "Flexible Amortized Variational Inference in qBOLD MRI. (arXiv:2203.05845v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.15783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polk_S/0/1/0/all/0/1\">Sam L. Polk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_J/0/1/0/all/0/1\">James M. Murphy</a>",
          "description": "Clustering algorithms partition a dataset into groups of similar points. The\nprimary contribution of this article is the Multiscale Spatially-Regularized\nDiffusion Learning (M-SRDL) clustering algorithm, which uses\nspatially-regularized diffusion distances to efficiently and accurately learn\nmultiple scales of latent structure in hyperspectral images. The M-SRDL\nclustering algorithm extracts clusterings at many scales from a hyperspectral\nimage and outputs these clusterings' variation of information-barycenter as an\nexemplar for all underlying cluster structure. We show that incorporating\nspatial regularization into a multiscale clustering framework results in\nsmoother and more coherent clusters when applied to hyperspectral data,\nyielding more accurate clustering labels.",
          "link": "http://arxiv.org/abs/2103.15783",
          "publishedOn": "2022-04-09T00:48:55.011Z",
          "wordCount": 581,
          "title": "Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial Diffusion Geometry. (arXiv:2103.15783v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03562",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cheng_K/0/1/0/all/0/1\">Kai Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zimmermann_R/0/1/0/all/0/1\">Ralf Zimmermann</a>",
          "description": "Gradient-enhanced Kriging (GE-Kriging) is a well-established surrogate\nmodelling technique for approximating expensive computational models. However,\nit tends to get impractical for high-dimensional problems due to the large\ninherent correlation matrix and the associated high-dimensional hyper-parameter\ntuning problem. To address these issues, we propose a new method in this paper,\ncalled sliced GE-Kriging (SGE-Kriging) for reducing both the size of the\ncorrelation matrix and the number of hyper-parameters. Firstly, we perform a\nderivative-based global sensitivity analysis to detect the relative importance\nof each input variable with respect to model response. Then, we propose to\nsplit the training sample set into multiple slices, and invoke Bayes' theorem\nto approximate the full likelihood function via a sliced likelihood function,\nin which multiple small correlation matrices are utilized to describe the\ncorrelation of the sample set. Additionally, we replace the original\nhigh-dimensional hyper-parameter tuning problem with a low-dimensional\ncounterpart by learning the relationship between the hyper-parameters and the\nglobal sensitivity indices. Finally, we validate SGE-Kriging by means of\nnumerical experiments with several benchmarks problems. The results show that\nthe SGE-Kriging model features an accuracy and robustness that is comparable to\nthe standard one but comes at much less training costs. The benefits are most\nevident in high-dimensional problems.",
          "link": "http://arxiv.org/abs/2204.03562",
          "publishedOn": "2022-04-09T00:48:54.964Z",
          "wordCount": null,
          "title": "Sliced gradient-enhanced Kriging for high-dimensional function approximation. (arXiv:2204.03562v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.11079",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Leiner_J/0/1/0/all/0/1\">James Leiner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duan_B/0/1/0/all/0/1\">Boyan Duan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1\">Larry Wasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "Suppose we observe a random vector $X$ from some distribution $P$ in a known\nfamily with unknown parameters. We ask the following question: when is it\npossible to split $X$ into two parts $f(X)$ and $g(X)$ such that neither part\nis sufficient to reconstruct $X$ by itself, but both together can recover $X$\nfully, and the joint distribution of $(f(X),g(X))$ is tractable? As one\nexample, if $X=(X_1,\\dots,X_n)$ and $P$ is a product distribution, then for any\n$m<n$, we can split the sample to define $f(X)=(X_1,\\dots,X_m)$ and\n$g(X)=(X_{m+1},\\dots,X_n)$. Rasines and Young (2021) offers an alternative\nroute of accomplishing this task through randomization of $X$ with additive\nGaussian noise which enables post-selection inference in finite samples for\nGaussian distributed data and asymptotically for non-Gaussian additive models.\nIn this paper, we offer a more general methodology for achieving such a split\nin finite samples by borrowing ideas from Bayesian inference to yield a\n(frequentist) solution that can be viewed as a continuous analog of data\nsplitting. We call our method data blurring, as an alternative to data\nsplitting, data carving and p-value masking. We exemplify the method on a few\nprototypical applications, such as post-selection inference for trend filtering\nand other regression problems.",
          "link": "http://arxiv.org/abs/2112.11079",
          "publishedOn": "2022-04-09T00:48:54.964Z",
          "wordCount": null,
          "title": "Data blurring: sample splitting a single sample. (arXiv:2112.11079v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.03706",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ramprasad_P/0/1/0/all/0/1\">Pratik Ramprasad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yuantong Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Will Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_G/0/1/0/all/0/1\">Guang Cheng</a>",
          "description": "The recent emergence of reinforcement learning has created a demand for\nrobust statistical inference methods for the parameter estimates computed using\nthese algorithms. Existing methods for statistical inference in online learning\nare restricted to settings involving independently sampled observations, while\nexisting statistical inference methods in reinforcement learning (RL) are\nlimited to the batch setting. The online bootstrap is a flexible and efficient\napproach for statistical inference in linear stochastic approximation\nalgorithms, but its efficacy in settings involving Markov noise, such as RL,\nhas yet to be explored. In this paper, we study the use of the online bootstrap\nmethod for statistical inference in RL. In particular, we focus on the temporal\ndifference (TD) learning and Gradient TD (GTD) learning algorithms, which are\nthemselves special instances of linear stochastic approximation under Markov\nnoise. The method is shown to be distributionally consistent for statistical\ninference in policy evaluation, and numerical experiments are included to\ndemonstrate the effectiveness of this algorithm at statistical inference tasks\nacross a range of real RL environments.",
          "link": "http://arxiv.org/abs/2108.03706",
          "publishedOn": "2022-04-09T00:48:54.961Z",
          "wordCount": 673,
          "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement Learning. (arXiv:2108.03706v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>",
          "description": "Representations of the world environment play a crucial role in artificial\nintelligence. It is often inefficient to conduct reasoning and inference\ndirectly in the space of raw sensory representations, such as pixel values of\nimages. Representation learning allows us to automatically discover suitable\nrepresentations from raw sensory data. For example, given raw sensory data, a\ndeep neural network learns nonlinear representations at its hidden layers,\nwhich are subsequently used for classification at its output layer. This\nhappens implicitly during training through minimizing a supervised or\nunsupervised loss. In this paper, we study the dynamics of such implicit\nnonlinear representation learning. We identify a pair of a new assumption and a\nnovel condition, called the common model structure assumption and the\ndata-architecture alignment condition. Under the common model structure\nassumption, the data-architecture alignment condition is shown to be sufficient\nfor the global convergence and necessary for the global optimality. Moreover,\nour theory explains how and when increasing the network size does and does not\nimprove the training behaviors in the practical regime. Our results provide\npractical guidance for designing a model structure: e.g., the common model\nstructure assumption can be used as a justification for using a particular\nmodel structure instead of others. We also derive a new training framework,\nwhich satisfies the data-architecture alignment condition by automatically\nmodifying any given training algorithm. Given a standard training algorithm,\nthe framework running its modified version is empirically shown to maintain\ncompetitive test performances while providing global convergence guarantees for\ndeep residual neural networks with convolutions, skip connections, and batch\nnormalization with datasets, including MNIST, CIFAR-10, CIFAR-100, Semeion,\nKMNIST and SVHN.",
          "link": "http://arxiv.org/abs/2106.14836",
          "publishedOn": "2022-04-09T00:48:54.953Z",
          "wordCount": 777,
          "title": "Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.02697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daesoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aune_E/0/1/0/all/0/1\">Erlend Aune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langet_N/0/1/0/all/0/1\">Nad&#xe8;ge Langet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eidsvik_J/0/1/0/all/0/1\">Jo Eidsvik</a>",
          "description": "One of the latest self-supervised learning (SSL) methods, VICReg, showed a\ngreat performance both in the linear evaluation and the fine-tuning evaluation.\nHowever, VICReg is proposed in computer vision and it learns by pulling\nrepresentations of random crops of an image while maintaining the\nrepresentation space by the variance and covariance loss. However, VICReg would\nbe ineffective on non-stationary time series where different parts/crops of\ninput should be differently encoded to consider the non-stationarity. Another\nrecent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for\nencoding non-stationary time series. This study shows that a combination of a\nVICReg-style method and TNC is very effective for SSL on non-stationary time\nseries, where a non-stationary seismic signal time series is used as an\nevaluation dataset.",
          "link": "http://arxiv.org/abs/2204.02697",
          "publishedOn": "2022-04-09T00:48:54.916Z",
          "wordCount": 592,
          "title": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.02601",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lock_E/0/1/0/all/0/1\">Eric F. Lock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1\">Jun Young Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hoadley_K/0/1/0/all/0/1\">Katherine A. Hoadley</a>",
          "description": "Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.",
          "link": "http://arxiv.org/abs/2002.02601",
          "publishedOn": "2022-04-09T00:48:54.898Z",
          "wordCount": 683,
          "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer analysis. (arXiv:2002.02601v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2004.10888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shangtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.",
          "link": "http://arxiv.org/abs/2004.10888",
          "publishedOn": "2022-04-09T00:48:54.883Z",
          "wordCount": 644,
          "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning. (arXiv:2004.10888v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saragadam_V/0/1/0/all/0/1\">Vishwanath Saragadam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeraraghavan_A/0/1/0/all/0/1\">Ashok Veeraraghavan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "DeepTensor is a computationally efficient framework for low-rank\ndecomposition of matrices and tensors using deep generative networks. We\ndecompose a tensor as the product of low-rank tensor factors (e.g., a matrix as\nthe outer product of two vectors), where each low-rank tensor is generated by a\ndeep network (DN) that is trained in a self-supervised manner to minimize the\nmean-squared approximation error. Our key observation is that the implicit\nregularization inherent in DNs enables them to capture nonlinear signal\nstructures (e.g., manifolds) that are out of the reach of classical linear\nmethods like the singular value decomposition (SVD) and principal component\nanalysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance\ndeteriorates when the tensor's entries deviate from additive white Gaussian\nnoise, we demonstrate that the performance of DeepTensor is robust to a wide\nrange of distributions. We validate that DeepTensor is a robust and\ncomputationally efficient drop-in replacement for the SVD, PCA, nonnegative\nmatrix factorization (NMF), and similar decompositions by exploring a range of\nreal-world applications, including hyperspectral image denoising, 3D MRI\ntomography, and image classification. In particular, DeepTensor offers a 6dB\nsignal-to-noise ratio improvement over standard denoising methods for signals\ncorrupted by Poisson noise and learns to decompose 3D tensors 60 times faster\nthan a single DN equipped with 3D convolutions.",
          "link": "http://arxiv.org/abs/2204.03145",
          "publishedOn": "2022-04-09T00:48:53.175Z",
          "wordCount": 659,
          "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors. (arXiv:2204.03145v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03193",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiahao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Shiqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "A new data-driven method for operator learning of stochastic differential\nequations(SDE) is proposed in this paper. The central goal is to solve forward\nand inverse stochastic problems more effectively using limited data. Deep\noperator network(DeepONet) has been proposed recently for operator learning.\nCompared to other neural networks to learn functions, it aims at the problem of\nlearning nonlinear operators. However, it can be challenging by using the\noriginal model to learn nonlinear operators for high-dimensional stochastic\nproblems. We propose a new multi-resolution autoencoder DeepONet model referred\nto as MultiAuto-DeepONet to deal with this difficulty with the aid of\nconvolutional autoencoder. The encoder part of the network is designed to\nreduce the dimensionality as well as discover the hidden features of\nhigh-dimensional stochastic inputs. The decoder is designed to have a special\nstructure, i.e. in the form of DeepONet. The first DeepONet in decoder is\ndesigned to reconstruct the input function involving randomness while the\nsecond one is used to approximate the solution of desired equations. Those two\nDeepONets has a common branch net and two independent trunk nets. This\narchitecture enables us to deal with multi-resolution inputs naturally. By\nadding $L_1$ regularization to our network, we found the outputs from the\nbranch net and two trunk nets all have sparse structures. This reduces the\nnumber of trainable parameters in the neural network thus making the model more\nefficient. Finally, we conduct several numerical experiments to illustrate the\neffectiveness of our proposed MultiAuto-DeepONet model with uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2204.03193",
          "publishedOn": "2022-04-09T00:48:53.167Z",
          "wordCount": 705,
          "title": "MultiAuto-DeepONet: A Multi-resolution Autoencoder DeepONet for Nonlinear Dimension Reduction, Uncertainty Quantification and Operator Learning of Forward and Inverse Stochastic Problems. (arXiv:2204.03193v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03123",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+John_M/0/1/0/all/0/1\">Majnu John</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vettam_S/0/1/0/all/0/1\">Sujit Vettam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yihren Wu</a>",
          "description": "Nonconvex penalties are utilized for regularization in high-dimensional\nstatistical learning algorithms primarily because they yield unbiased or nearly\nunbiased estimators for the parameters in the model. Nonconvex penalties\nexisting in the literature such as SCAD, MCP, Laplace and arctan have a\nsingularity at origin which makes them useful also for variable selection.\nHowever, in several high-dimensional frameworks such as deep learning, variable\nselection is less of a concern. In this paper, we present a nonconvex penalty\nwhich is smooth at origin. The paper includes asymptotic results for ordinary\nleast squares estimators regularized with the new penalty function, showing\nasymptotic bias that vanishes exponentially fast. We also conducted an\nempirical study employing deep neural network architecture on three datasets\nand convolutional neural network on four datasets. The empirical study showed\nbetter performance for the new regularization approach in five out of the seven\ndatasets.",
          "link": "http://arxiv.org/abs/2204.03123",
          "publishedOn": "2022-04-09T00:48:53.143Z",
          "wordCount": 594,
          "title": "A novel nonconvex, smooth-at-origin penalty for statistical learning. (arXiv:2204.03123v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barkhof_C/0/1/0/all/0/1\">Claartje Barkhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1\">Wilker Aziz</a>",
          "description": "We propose a framework for the statistical evaluation of variational\nauto-encoders (VAEs) and test two instances of this framework in the context of\nmodelling images of handwritten digits and a corpus of English text. Our take\non evaluation is based on the idea of statistical model criticism, popular in\nBayesian data analysis, whereby a statistical model is evaluated in terms of\nits ability to reproduce statistics of an unknown data generating process from\nwhich we can obtain samples. A VAE learns not one, but two joint distributions\nover a shared sample space, each exploiting a choice of factorisation that\nmakes sampling tractable in one of two directions (latent-to-data,\ndata-to-latent). We evaluate samples from these distributions, assessing their\n(marginal) fit to the observed data and our choice of prior, and we also\nevaluate samples through a pipeline that connects the two distributions\nstarting from a data sample, assessing whether together they exploit and reveal\nlatent factors of variation that are useful to a practitioner. We show that\nthis methodology offers possibilities for model selection qualitatively beyond\nintrinsic evaluation metrics and at a finer granularity than commonly used\nstatistics can offer.",
          "link": "http://arxiv.org/abs/2204.03030",
          "publishedOn": "2022-04-09T00:48:53.135Z",
          "wordCount": 625,
          "title": "Statistical Model Criticism of Variational Auto-Encoders. (arXiv:2204.03030v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yao-Yuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1\">Jaros&#x142;aw B&#x142;asiok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>",
          "description": "We investigate and leverage a connection between Differential Privacy (DP)\nand the recently proposed notion of Distributional Generalization (DG).\nApplying this connection, we introduce new conceptual tools for designing\ndeep-learning methods that bypass \"pathologies\" of standard stochastic gradient\ndescent (SGD). First, we prove that differentially private methods satisfy a\n\"What You See Is What You Get (WYSIWYG)\" generalization guarantee: whatever a\nmodel does on its train data is almost exactly what it will do at test time.\nThis guarantee is formally captured by distributional generalization. WYSIWYG\nenables principled algorithm design in deep learning by reducing\n$\\textit{generalization}$ concerns to $\\textit{optimization}$ ones: in order to\nmitigate unwanted behavior at test time, it is provably sufficient to mitigate\nthis behavior on the train data. This is notably false for standard (non-DP)\nmethods, hence this observation has applications even when privacy is not\nrequired. For example, importance sampling is known to fail for standard SGD,\nbut we show that it has exactly the intended effect for DP-trained models.\nThus, with DP-SGD, unlike with SGD, we can influence test-time behavior by\nmaking principled train-time interventions. We use these insights to construct\nsimple algorithms which match or outperform SOTA in several distributional\nrobustness applications, and to significantly improve the privacy vs. disparate\nimpact trade-off of DP-SGD. Finally, we also improve on known theoretical\nbounds relating differential privacy, stability, and distributional\ngeneralization.",
          "link": "http://arxiv.org/abs/2204.03230",
          "publishedOn": "2022-04-09T00:48:53.125Z",
          "wordCount": 701,
          "title": "What You See is What You Get: Distributional Generalization for Algorithm Design in Deep Learning. (arXiv:2204.03230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03248",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sekimoto_K/0/1/0/all/0/1\">Kaiji Sekimoto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yasuda_M/0/1/0/all/0/1\">Muneki Yasuda</a>",
          "description": "Although evaluation of the expectations on the Ising model is essential in\nvarious applications, this is frequently infeasible because of intractable\nmultiple summations (or integrations). Spatial Monte Carlo integration (SMCI)\nis a sampling-based approximation, and can provide high-accuracy estimations\nfor such intractable expectations. To evaluate the expectation of a function of\nvariables in a specific region (called target region), SMCI considers a larger\nregion containing the target region (called sum region). In SMCI, the multiple\nsummation for the variables in the sum region is precisely executed, and that\nin the outer region is evaluated by the sampling approximation such as the\nstandard Monte Carlo integration. It is guaranteed that the accuracy of the\nSMCI estimator is monotonically improved as the size of the sum region\nincreases. However, a haphazard expansion of the sum region could cause a\ncombinatorial explosion. Therefore, we hope to improve the accuracy without\nsuch region expansion. In this study, based on the theory of generalized least\nsquares, a new effective method is proposed by combining multiple SMCI\nestimators. The validity of the proposed method is demonstrated theoretically\nand numerically. The results indicate that the proposed method can be effective\nin the inverse Ising problem (or Boltzmann machine learning).",
          "link": "http://arxiv.org/abs/2204.03248",
          "publishedOn": "2022-04-09T00:48:49.945Z",
          "wordCount": 660,
          "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least Squares. (arXiv:2204.03248v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.04671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1\">Yuejiao Sun</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xiao_Q/0/1/0/all/0/1\">Quan Xiao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>",
          "description": "Stochastic bilevel optimization generalizes the classic stochastic\noptimization from the minimization of a single objective to the minimization of\nan objective function that depends the solution of another optimization\nproblem. Recently, stochastic bilevel optimization is regaining popularity in\nemerging machine learning applications such as hyper-parameter optimization and\nmodel-agnostic meta learning. To solve this class of stochastic optimization\nproblems, existing methods require either double-loop or two-timescale updates,\nwhich are sometimes less efficient. This paper develops a new optimization\nmethod for a class of stochastic bilevel problems that we term Single-Timescale\nstochAstic BiLevEl optimization (STABLE) method. STABLE runs in a single loop\nfashion, and uses a single-timescale update with a fixed batch size. To achieve\nan $\\epsilon$-stationary point of the bilevel problem, STABLE requires ${\\cal\nO}(\\epsilon^{-2})$ samples in total; and to achieve an $\\epsilon$-optimal\nsolution in the strongly convex case, STABLE requires ${\\cal O}(\\epsilon^{-1})$\nsamples. To the best of our knowledge, this is the first bilevel optimization\nalgorithm achieving the same order of sample complexity as the stochastic\ngradient descent method for the single-level stochastic optimization.",
          "link": "http://arxiv.org/abs/2102.04671",
          "publishedOn": "2022-04-02T00:47:19.824Z",
          "wordCount": null,
          "title": "A Single-Timescale Method for Stochastic Bilevel Optimization. (arXiv:2102.04671v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujita_O/0/1/0/all/0/1\">Osamu Fujita</a>",
          "description": "This paper investigates probability density functions (PDFs) that are\ncontinuous everywhere, nearly uniform around the mode of distribution, and\nadaptable to a variety of distribution shapes ranging from bell-shaped to\nrectangular. From the viewpoint of computational tractability, the PDF based on\nthe Fermi-Dirac or logistic function is advantageous in estimating its shape\nparameters. The most appropriate PDF for $n$-variate distribution is of the\nform:\n$p\\left(\\mathbf{x}\\right)\\propto\\left[\\cosh\\left(\\left[\\left(\\mathbf{x}-\\mathbf{m}\\right)^{\\mathsf{T}}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{x}-\\mathbf{m}\\right)\\right]^{n/2}\\right)+\\cosh\\left(r^{n}\\right)\\right]^{-1}$\nwhere $\\mathbf{x},\\mathbf{m}\\in\\mathbb{R}^{n}$, $\\boldsymbol{\\Sigma}$ is an\n$n\\times n$ positive definite matrix, and $r>0$ is a shape parameter. The\nflat-topped PDFs can be used as a component of mixture models in machine\nlearning to improve goodness of fit and make a model as simple as possible.",
          "link": "http://arxiv.org/abs/2203.17027",
          "publishedOn": "2022-04-02T00:47:19.817Z",
          "wordCount": null,
          "title": "Flat-topped Probability Density Functions for Mixture Models. (arXiv:2203.17027v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1\">Emiel Hoogeboom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satorras_V/0/1/0/all/0/1\">Victor Garcia Satorras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vignac_C/0/1/0/all/0/1\">Cl&#xe9;ment Vignac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "This work introduces a diffusion model for molecule generation in 3D that is\nequivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model\n(EDM) learns to denoise a diffusion process with an equivariant network that\njointly operates on both continuous (atom coordinates) and categorical features\n(atom types). In addition, we provide a probabilistic analysis which admits\nlikelihood computation of molecules using our model. Experimentally, the\nproposed method significantly outperforms previous 3D molecular generative\nmethods regarding the quality of generated samples and efficiency at training\ntime.",
          "link": "http://arxiv.org/abs/2203.17003",
          "publishedOn": "2022-04-02T00:47:19.814Z",
          "wordCount": null,
          "title": "Equivariant Diffusion for Molecule Generation in 3D. (arXiv:2203.17003v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.16712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as Markov Decision Process\n(MDP) optimization, is a important challenge in artificial intelligence. Two\nkey approaches to this problem are reinforcement learning (RL) and planning.\nThis paper presents a survey of the integration of both fields, better known as\nmodel-based reinforcement learning. Model-based RL has two main steps. First,\nwe systematically cover approaches to dynamics model learning, including\nchallenges like dealing with stochasticity, uncertainty, partial observability,\nand temporal abstraction. Second, we present a systematic categorization of\nplanning-learning integration, including aspects like: where to start planning,\nwhat budgets to allocate to planning and real data collection, how to plan, and\nhow to integrate planning in the learning and acting loop. After these two\nsections, we also discuss implicit model-based RL as an end-to-end alternative\nfor model learning and planning, and we cover the potential benefits of\nmodel-based RL. Along the way, the survey also draws connections to several\nrelated RL fields, like hierarchical RL and transfer learning. Altogether, the\nsurvey presents a broad conceptual overview of the combination of planning and\nlearning for MDP optimization.",
          "link": "http://arxiv.org/abs/2006.16712",
          "publishedOn": "2022-04-02T00:47:19.814Z",
          "wordCount": null,
          "title": "Model-based Reinforcement Learning: A Survey. (arXiv:2006.16712v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yuhao Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kunlin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Song Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_I/0/1/0/all/0/1\">Ignavier Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Shan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_T/0/1/0/all/0/1\">Teng Fei</a>",
          "description": "Spatial clustering has been widely used for spatial data mining and knowledge\ndiscovery. An ideal multivariate spatial clustering should consider both\nspatial contiguity and aspatial attributes. Existing spatial clustering\napproaches may face challenges for discovering repeated geographic patterns\nwith spatial contiguity maintained. In this paper, we propose a Spatial\nToeplitz Inverse Covariance-Based Clustering (STICC) method that considers both\nattributes and spatial relationships of geographic objects for multivariate\nspatial clustering. A subregion is created for each geographic object serving\nas the basic unit when performing clustering. A Markov random field is then\nconstructed to characterize the attribute dependencies of subregions. Using a\nspatial consistency strategy, nearby objects are encouraged to belong to the\nsame cluster. To test the performance of the proposed STICC algorithm, we apply\nit in two use cases. The comparison results with several baseline methods show\nthat the STICC outperforms others significantly in terms of adjusted rand index\nand macro-F1 score. Join count statistics is also calculated and shows that the\nspatial contiguity is well preserved by STICC. Such a spatial clustering method\nmay benefit various applications in the fields of geography, remote sensing,\ntransportation, and urban planning, etc.",
          "link": "http://arxiv.org/abs/2203.09611",
          "publishedOn": "2022-04-02T00:47:19.814Z",
          "wordCount": null,
          "title": "STICC: A multivariate spatial clustering method for repeated geographic pattern discovery with consideration of spatial contiguity. (arXiv:2203.09611v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16711",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Najafi_K/0/1/0/all/0/1\">Khadijeh Najafi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sharma_K/0/1/0/all/0/1\">Kunal Sharma</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tacchino_F/0/1/0/all/0/1\">Francesco Tacchino</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jiang_L/0/1/0/all/0/1\">Liang Jiang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Mezzacapo_A/0/1/0/all/0/1\">Antonio Mezzacapo</a>",
          "description": "Parametrized quantum circuits can be used as quantum neural networks and have\nthe potential to outperform their classical counterparts when trained for\naddressing learning problems. To date, much of the results on their performance\non practical problems are heuristic in nature. In particular, the convergence\nrate for the training of quantum neural networks is not fully understood. Here,\nwe analyze the dynamics of gradient descent for the training error of a class\nof variational quantum machine learning models. We define wide quantum neural\nnetworks as parameterized quantum circuits in the limit of a large number of\nqubits and variational parameters. We then find a simple analytic formula that\ncaptures the average behavior of their loss function and discuss the\nconsequences of our findings. For example, for random quantum circuits, we\npredict and characterize an exponential decay of the residual training error as\na function of the parameters of the system. We finally validate our analytic\nresults with numerical experiments.",
          "link": "http://arxiv.org/abs/2203.16711",
          "publishedOn": "2022-04-02T00:47:19.813Z",
          "wordCount": null,
          "title": "An analytic theory for the dynamics of wide quantum neural networks. (arXiv:2203.16711v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17128",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cohen_S/0/1/0/all/0/1\">Samuel N. Cohen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_D/0/1/0/all/0/1\">Deqing Jiang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sirignano_J/0/1/0/all/0/1\">Justin Sirignano</a>",
          "description": "Solving high-dimensional partial differential equations (PDEs) is a major\nchallenge in scientific computing. We develop a new numerical method for\nsolving elliptic-type PDEs by adapting the Q-learning algorithm in\nreinforcement learning. Our \"Q-PDE\" algorithm is mesh-free and therefore has\nthe potential to overcome the curse of dimensionality. Using a neural tangent\nkernel (NTK) approach, we prove that the neural network approximator for the\nPDE solution, trained with the Q-PDE algorithm, converges to the trajectory of\nan infinite-dimensional ordinary differential equation (ODE) as the number of\nhidden units $\\rightarrow \\infty$. For monotone PDE (i.e. those given by\nmonotone operators, which may be nonlinear), despite the lack of a spectral gap\nin the NTK, we then prove that the limit neural network, which satisfies the\ninfinite-dimensional ODE, converges in $L^2$ to the PDE solution as the\ntraining time $\\rightarrow \\infty$. More generally, we can prove that any fixed\npoint of the wide-network limit for the Q-PDE algorithm is a solution of the\nPDE (not necessarily under the monotone condition). The numerical performance\nof the Q-PDE algorithm is studied for several elliptic PDEs.",
          "link": "http://arxiv.org/abs/2203.17128",
          "publishedOn": "2022-04-02T00:47:19.813Z",
          "wordCount": null,
          "title": "Neural Q-learning for solving elliptic PDEs. (arXiv:2203.17128v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1812.00086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Heda Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haiping Lu</a>",
          "description": "Graph convolutional network (GCN) is an emerging neural network approach. It\nlearns new representation of a node by aggregating feature vectors of all\nneighbors in the aggregation process without considering whether the neighbors\nor features are useful or not. Recent methods have improved solutions by\nsampling a fixed size set of neighbors, or assigning different weights to\ndifferent neighbors in the aggregation process, but features within a feature\nvector are still treated equally in the aggregation process. In this paper, we\nintroduce a new convolution operation on regular size feature maps constructed\nfrom features of a fixed node bandwidth via sampling to get the first-level\nnode representation, which is then passed to a standard GCN to learn the\nsecond-level node representation. Experiments show that our method outperforms\ncompeting methods in semi-supervised node classification tasks. Furthermore,\nour method opens new doors for exploring new GCN architectures, particularly\ndeeper GCN models.",
          "link": "http://arxiv.org/abs/1812.00086",
          "publishedOn": "2022-04-02T00:47:19.813Z",
          "wordCount": null,
          "title": "Graph Node-Feature Convolution for Representation Learning. (arXiv:1812.00086v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ath_G/0/1/0/all/0/1\">George De Ath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahat_A/0/1/0/all/0/1\">Alma A. M. Rahat</a>",
          "description": "Optimisation problems often have multiple conflicting objectives that can be\ncomputationally and/or financially expensive. Mono-surrogate Bayesian\noptimisation (BO) is a popular model-based approach for optimising such\nblack-box functions. It combines objective values via scalarisation and builds\na Gaussian process (GP) surrogate of the scalarised values. The location which\nmaximises a cheap-to-query acquisition function is chosen as the next location\nto expensively evaluate. While BO is an effective strategy, the use of GPs is\nlimiting. Their performance decreases as the problem input dimensionality\nincreases, and their computational complexity scales cubically with the amount\nof data. To address these limitations, we extend previous work on BO by\ndensity-ratio estimation (BORE) to the multi-objective setting. BORE links the\ncomputation of the probability of improvement acquisition function to that of\nprobabilistic classification. This enables the use of state-of-the-art\nclassifiers in a BO-like framework. In this work we present MBORE:\nmulti-objective Bayesian optimisation by density-ratio estimation, and compare\nit to BO across a range of synthetic and real-world benchmarks. We find that\nMBORE performs as well as or better than BO on a wide variety of problems, and\nthat it outperforms BO on high-dimensional and real-world problems.",
          "link": "http://arxiv.org/abs/2203.16912",
          "publishedOn": "2022-04-02T00:47:19.811Z",
          "wordCount": null,
          "title": "MBORE: Multi-objective Bayesian Optimisation by Density-Ratio Estimation. (arXiv:2203.16912v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1\">Stephen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_R/0/1/0/all/0/1\">Roy Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1\">Mahdi Soltanolkotabi</a>",
          "description": "We initiate a study of supervised learning from many independent sequences\n(\"trajectories\") of non-independent covariates, reflecting tasks in sequence\nmodeling, control, and reinforcement learning. Conceptually, our\nmulti-trajectory setup sits between two traditional settings in statistical\nlearning theory: learning from independent examples and learning from a single\nauto-correlated sequence. Our conditions for efficient learning generalize the\nformer setting--trajectories must be non-degenerate in ways that extend\nstandard requirements for independent examples. They do not require that\ntrajectories be ergodic, long, nor strictly stable.\n\nFor linear least-squares regression, given $n$-dimensional examples produced\nby $m$ trajectories, each of length $T$, we observe a notable change in\nstatistical efficiency as the number of trajectories increases from a few\n(namely $m \\lesssim n$) to many (namely $m \\gtrsim n$). Specifically, we\nestablish that the worst-case error rate this problem is $\\Theta(n / m T)$\nwhenever $m \\gtrsim n$. Meanwhile, when $m \\lesssim n$, we establish a (sharp)\nlower bound of $\\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by\na simple, marginally unstable linear dynamical system. A key upshot is that, in\ndomains where trajectories regularly reset, the error rate eventually behaves\nas if all of the examples were independent altogether, drawn from their\nmarginals. As a corollary of our analysis, we also improve guarantees for the\nlinear system identification problem.",
          "link": "http://arxiv.org/abs/2203.17193",
          "publishedOn": "2022-04-02T00:47:19.809Z",
          "wordCount": null,
          "title": "Learning from many trajectories. (arXiv:2203.17193v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16749",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Koizumi_Y/0/1/0/all/0/1\">Yuma Koizumi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zen_H/0/1/0/all/0/1\">Heiga Zen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yatabe_K/0/1/0/all/0/1\">Kohei Yatabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_N/0/1/0/all/0/1\">Nanxin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bacchiani_M/0/1/0/all/0/1\">Michiel Bacchiani</a>",
          "description": "Neural vocoder using denoising diffusion probabilistic model (DDPM) has been\nimproved by adaptation of the diffusion noise distribution to given acoustic\nfeatures. In this study, we propose SpecGrad that adapts the diffusion noise so\nthat its time-varying spectral envelope becomes close to the conditioning\nlog-mel spectrogram. This adaptation by time-varying filtering improves the\nsound quality especially in the high-frequency bands. It is processed in the\ntime-frequency domain to keep the computational cost almost the same as the\nconventional DDPM-based neural vocoders. Experimental results showed that\nSpecGrad generates higher-fidelity speech waveform than conventional DDPM-based\nneural vocoders in both analysis-synthesis and speech enhancement scenarios.\nAudio demos are available at wavegrad.github.io/specgrad/.",
          "link": "http://arxiv.org/abs/2203.16749",
          "publishedOn": "2022-04-02T00:47:19.804Z",
          "wordCount": null,
          "title": "SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping. (arXiv:2203.16749v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.04184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Ziang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>",
          "description": "Multi-agent reinforcement learning has made substantial empirical progresses\nin solving games with a large number of players. However, theoretically, the\nbest known sample complexity for finding a Nash equilibrium in general-sum\ngames scales exponentially in the number of players due to the size of the\njoint action space, and there is a matching exponential lower bound. This paper\ninvestigates what learning goals admit better sample complexities in the\nsetting of $m$-player general-sum Markov games with $H$ steps, $S$ states, and\n$A_i$ actions per player. First, we design algorithms for learning an\n$\\epsilon$-Coarse Correlated Equilibrium (CCE) in\n$\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$ episodes, and an\n$\\epsilon$-Correlated Equilibrium (CE) in\n$\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$ episodes. This\nis the first line of results for learning CCE and CE with sample complexities\npolynomial in $\\max_{i\\le m} A_i$. Our algorithm for learning CE integrates an\nadversarial bandit subroutine which minimizes a weighted swap regret, along\nwith several novel designs in the outer loop. Second, we consider the important\nspecial case of Markov Potential Games, and design an algorithm that learns an\n$\\epsilon$-approximate Nash equilibrium within\n$\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$ episodes (when only\nhighlighting the dependence on $S$, $A_i$, and $\\epsilon$), which only depends\nlinearly in $\\sum_{i\\le m} A_i$ and significantly improves over existing\nefficient algorithm in the $\\epsilon$ dependence. Overall, our results shed\nlight on what equilibria or structural assumptions on the game may enable\nsample-efficient learning with many players.",
          "link": "http://arxiv.org/abs/2110.04184",
          "publishedOn": "2022-04-02T00:47:19.782Z",
          "wordCount": null,
          "title": "When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?. (arXiv:2110.04184v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sungyong Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griesemer_S/0/1/0/all/0/1\">Sam Griesemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Physics-informed machine learning (PIML), referring to the combination of\nprior knowledge of physics, which is the high level abstraction of natural\nphenomenons and human behaviours in the long history, with data-driven machine\nlearning models, has emerged as an effective way to mitigate the shortage of\ntraining data, to increase models' generalizability and to ensure the physical\nplausibility of results. In this paper, we survey an abundant number of recent\nworks in PIML and summarize them from three aspects: (1) motivations of PIML,\n(2) physics knowledge in PIML, (3) methods of physics knowledge integration in\nPIML. We also discuss current challenges and corresponding research\nopportunities in PIML.",
          "link": "http://arxiv.org/abs/2203.16797",
          "publishedOn": "2022-04-02T00:47:19.777Z",
          "wordCount": null,
          "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed Machine Learning. (arXiv:2203.16797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1\">Nian Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhengyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanchet_J/0/1/0/all/0/1\">Jose Blanchet</a>",
          "description": "Policy learning using historical observational data is an important problem\nthat has found widespread applications. Examples include selecting offers,\nprices, advertisements to send to customers, as well as selecting which\nmedication to prescribe to a patient. However, existing literature rests on the\ncrucial assumption that the future environment where the learned policy will be\ndeployed is the same as the past environment that has generated the data -- an\nassumption that is often false or too coarse an approximation. In this paper,\nwe lift this assumption and aim to learn a distributionally robust policy with\nincomplete observational data. We first present a policy evaluation procedure\nthat allows us to assess how well the policy does under the worst-case\nenvironment shift. We then establish a central limit theorem type guarantee for\nthis proposed policy evaluation scheme. Leveraging this evaluation scheme, we\nfurther propose a novel learning algorithm that is able to learn a policy that\nis robust to adversarial perturbations and unknown covariate shifts with a\nperformance guarantee based on the theory of uniform convergence. Finally, we\nempirically test the effectiveness of our proposed algorithm in synthetic\ndatasets and demonstrate that it provides the robustness that is missing using\nstandard policy learning algorithms. We conclude the paper by providing a\ncomprehensive application of our methods in the context of a real-world voting\ndataset.",
          "link": "http://arxiv.org/abs/2006.05630",
          "publishedOn": "2022-04-02T00:47:19.775Z",
          "wordCount": null,
          "title": "Distributional Robust Batch Contextual Bandits. (arXiv:2006.05630v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.12967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haroush_M/0/1/0/all/0/1\">Matan Haroush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frostig_T/0/1/0/all/0/1\">Tzviel Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_R/0/1/0/all/0/1\">Ruth Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1\">Daniel Soudry</a>",
          "description": "Background. Commonly, Deep Neural Networks (DNNs) generalize well on samples\ndrawn from a distribution similar to that of the training set. However, DNNs'\npredictions are brittle and unreliable when the test samples are drawn from a\ndissimilar distribution. This is a major concern for deployment in real-world\napplications, where such behavior may come at a considerable cost, such as\nindustrial production lines, autonomous vehicles, or healthcare applications.\nContributions. We frame Out Of Distribution (OOD) detection in DNNs as a\nstatistical hypothesis testing problem. Tests generated within our proposed\nframework combine evidence from the entire network. Unlike previous OOD\ndetection heuristics, this framework returns a $p$-value for each test sample.\nIt is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD\nfor an actual in-distribution sample) for test data. Moreover, this allows to\ncombine several detectors while maintaining the T1E. Building on this\nframework, we suggest a novel OOD procedure based on low-order statistics. Our\nmethod achieves comparable or better results than state-of-the-art methods on\nwell-accepted OOD benchmarks, without retraining the network parameters or\nassuming prior knowledge on the test distribution -- and at a fraction of the\ncomputational cost.",
          "link": "http://arxiv.org/abs/2102.12967",
          "publishedOn": "2022-04-02T00:47:19.775Z",
          "wordCount": null,
          "title": "A statistical framework for efficient out of distribution detection in deep neural networks. (arXiv:2102.12967v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.06053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galhotra_S/0/1/0/all/0/1\">Sainyam Galhotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1\">Kush R. Varshney</a>",
          "description": "The use of machine learning (ML) in high-stakes societal decisions has\nencouraged the consideration of fairness throughout the ML lifecycle. Although\ndata integration is one of the primary steps to generate high quality training\ndata, most of the fairness literature ignores this stage. In this work, we\nconsider fairness in the integration component of data management, aiming to\nidentify features that improve prediction without adding any bias to the\ndataset. We work under the causal interventional fairness paradigm. Without\nrequiring the underlying structural causal model a priori, we propose an\napproach to identify a sub-collection of features that ensure the fairness of\nthe dataset by performing conditional independence tests between different\nsubsets of features. We use group testing to improve the complexity of the\napproach. We theoretically prove the correctness of the proposed algorithm to\nidentify features that ensure interventional fairness and show that sub-linear\nconditional independence tests are sufficient to identify these variables. A\ndetailed empirical evaluation is performed on real-world datasets to\ndemonstrate the efficacy and efficiency of our technique.",
          "link": "http://arxiv.org/abs/2006.06053",
          "publishedOn": "2022-04-02T00:47:19.773Z",
          "wordCount": null,
          "title": "Causal Feature Selection for Algorithmic Fairness. (arXiv:2006.06053v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaohan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yunpeng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_G/0/1/0/all/0/1\">Gilad Lerman</a>",
          "description": "Previous partial permutation synchronization (PPS) algorithms, which are\ncommonly used for multi-object matching, often involve computation-intensive\nand memory-demanding matrix operations. These operations become intractable for\nlarge scale structure-from-motion datasets. For pure permutation\nsynchronization, the recent Cycle-Edge Message Passing (CEMP) framework\nsuggests a memory-efficient and fast solution. Here we overcome the restriction\nof CEMP to compact groups and propose an improved algorithm, CEMP-Partial, for\nestimating the corruption levels of the observed partial permutations. It\nallows us to subsequently implement a nonconvex weighted projected power method\nwithout the need of spectral initialization. The resulting new PPS algorithm,\nMatchFAME (Fast, Accurate and Memory-Efficient Matching), only involves sparse\nmatrix operations, and thus enjoys lower time and space complexities in\ncomparison to previous PPS algorithms. We prove that under adversarial\ncorruption, though without additive noise and with certain assumptions,\nCEMP-Partial is able to exactly classify corrupted and clean partial\npermutations. We demonstrate the state-of-the-art accuracy, speed and memory\nefficiency of our method on both synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2203.16505",
          "publishedOn": "2022-04-02T00:47:19.773Z",
          "wordCount": null,
          "title": "Fast, Accurate and Memory-Efficient Partial Permutation Synchronization. (arXiv:2203.16505v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.14244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przyborowski_M/0/1/0/all/0/1\">Mateusz Przyborowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pabis_M/0/1/0/all/0/1\">Mateusz Pabi&#x15b;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janusz_A/0/1/0/all/0/1\">Andrzej Janusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Dominik &#x15a;l&#x119;zak</a>",
          "description": "Gaussian mixture models find their place as a powerful tool, mostly in the\nclustering problem, but with proper preparation also in feature extraction,\npattern recognition, image segmentation and in general machine learning. When\nfaced with the problem of schema matching, different mixture models computed on\ndifferent pieces of data can maintain crucial information about the structure\nof the dataset. In order to measure or compare results from mixture models, the\nWasserstein distance can be very useful, however it is not easy to calculate\nfor mixture distributions. In this paper we derive one of possible\napproximations for the Wasserstein distance between Gaussian mixture models and\nreduce it to linear problem. Furthermore, application examples concerning real\nworld data are shown.",
          "link": "http://arxiv.org/abs/2111.14244",
          "publishedOn": "2022-04-02T00:47:19.734Z",
          "wordCount": null,
          "title": "Schema matching using Gaussian mixture models with Wasserstein distance. (arXiv:2111.14244v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1\">Aldo Gael Carranza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Many popular contextual bandit algorithms estimate reward models to inform\ndecision making. However, true rewards can contain action-independent\nredundancies that are not relevant for decision making and only increase the\nstatistical complexity of accurate estimation. It is sufficient and more\ndata-efficient to estimate the simplest function that explains the reward\ndifferences between actions, that is, the heterogeneous treatment effect,\ncommonly understood to be more structured and simpler than the reward.\nMotivated by this observation, building on recent work on oracle-based\nalgorithms, we design a statistically optimal and computationally efficient\nalgorithm using heterogeneous treatment effect estimation oracles. Our results\nprovide the first universal reduction of contextual bandits to a\ngeneral-purpose heterogeneous treatment effect estimation method. We show that\nour approach is more robust to model misspecification than reward estimation\nmethods based on squared error regression oracles. Experimentally, we show the\nbenefits of heterogeneous treatment effect estimation in contextual bandits\nover reward estimation.",
          "link": "http://arxiv.org/abs/2203.16668",
          "publishedOn": "2022-04-02T00:47:19.726Z",
          "wordCount": null,
          "title": "Flexible and Efficient Contextual Bandits with Heterogeneous Treatment Effect Oracle. (arXiv:2203.16668v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16673",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yue Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>",
          "description": "This paper studies the problem of identifying low-order linear systems via\nHankel nuclear norm regularization. Hankel regularization encourages the\nlow-rankness of the Hankel matrix, which maps to the low-orderness of the\nsystem. We provide novel statistical analysis for this regularization and\ncarefully contrast it with the unregularized ordinary least-squares (OLS)\nestimator. Our analysis leads to new bounds on estimating the impulse response\nand the Hankel matrix associated with the linear system. We first design an\ninput excitation and show that Hankel regularization enables one to recover the\nsystem using optimal number of observations in the true system order and\nachieve strong statistical estimation rates. Surprisingly, we demonstrate that\nthe input design indeed matters, by showing that intuitive choices such as\ni.i.d. Gaussian input leads to provably sub-optimal sample complexity. To\nbetter understand the benefits of regularization, we also revisit the OLS\nestimator. Besides refining existing bounds, we experimentally identify when\nregularized approach improves over OLS: (1) For low-order systems with slow\nimpulse-response decay, OLS method performs poorly in terms of sample\ncomplexity, (2) Hankel matrix returned by regularization has a more clear\nsingular value gap that ease identification of the system order, (3) Hankel\nregularization is less sensitive to hyperparameter choice. Finally, we\nestablish model selection guarantees through a joint train-validation procedure\nwhere we tune the regularization parameter for near-optimal estimation.",
          "link": "http://arxiv.org/abs/2203.16673",
          "publishedOn": "2022-04-02T00:47:19.726Z",
          "wordCount": null,
          "title": "System Identification via Nuclear Norm Regularization. (arXiv:2203.16673v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16662",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beckham_C/0/1/0/all/0/1\">Christopher Beckham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Laradji_I/0/1/0/all/0/1\">Issam Laradji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rodriguez_P/0/1/0/all/0/1\">Pau Rodriguez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vazquez_D/0/1/0/all/0/1\">David Vazquez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nowrouzezahrai_D/0/1/0/all/0/1\">Derek Nowrouzezahrai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "In this paper, we explore the use of GAN-based few-shot data augmentation as\na method to improve few-shot classification performance. We perform an\nexploration into how a GAN can be fine-tuned for such a task (one of which is\nin a class-incremental manner), as well as a rigorous empirical investigation\ninto how well these models can perform to improve few-shot classification. We\nidentify issues related to the difficulty of training such generative models\nunder a purely supervised regime with very few examples, as well as issues\nregarding the evaluation protocols of existing works. We also find that in this\nregime, classification accuracy is highly sensitive to how the classes of the\ndataset are randomly split. Therefore, we propose a semi-supervised fine-tuning\napproach as a more pragmatic way forward to address these problems.",
          "link": "http://arxiv.org/abs/2203.16662",
          "publishedOn": "2022-04-02T00:47:19.718Z",
          "wordCount": null,
          "title": "Challenges in leveraging GANs for few-shot data augmentation. (arXiv:2203.16662v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16587",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chatterjee_S/0/1/0/all/0/1\">Sabyasachi Chatterjee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Goswami_S/0/1/0/all/0/1\">Subhajit Goswami</a>",
          "description": "We consider the problem of estimating piecewise regular functions in an\nonline setting, i.e., the data arrive sequentially and at any round our task is\nto predict the value of the true function at the next revealed point using the\navailable data from past predictions. We propose a suitably modified version of\na recently developed online learning algorithm called the sleeping experts\naggregation algorithm. We show that this estimator satisfies oracle risk bounds\nsimultaneously for all local regions of the domain. As concrete instantiations\nof the expert aggregation algorithm proposed here, we study an online mean\naggregation and an online linear regression aggregation algorithm where experts\ncorrespond to the set of dyadic subrectangles of the domain. The resulting\nalgorithms are near linear time computable in the sample size. We specifically\nfocus on the performance of these online algorithms in the context of\nestimating piecewise polynomial and bounded variation function classes in the\nfixed design setup. The simultaneous oracle risk bounds we obtain for these\nestimators in this context provide new and improved (in certain aspects)\nguarantees even in the batch setting and are not available for the state of the\nart batch learning estimators.",
          "link": "http://arxiv.org/abs/2203.16587",
          "publishedOn": "2022-04-02T00:47:19.544Z",
          "wordCount": null,
          "title": "Spatially Adaptive Online Prediction of Piecewise Regular Functions. (arXiv:2203.16587v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bombari_S/0/1/0/all/0/1\">Simone Bombari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yusheng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1\">Kunwar Yashraj Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appalaraju_S/0/1/0/all/0/1\">Srikar Appalaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_V/0/1/0/all/0/1\">Vijay Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Memorization of the relation between entities in a dataset can lead to\nprivacy issues when using a trained model for question answering. We introduce\nRelational Memorization (RM) to understand, quantify and control this\nphenomenon. While bounding general memorization can have detrimental effects on\nthe performance of a trained model, bounding RM does not prevent effective\nlearning. The difference is most pronounced when the data distribution is\nlong-tailed, with many queries having only few training examples: Impeding\ngeneral memorization prevents effective learning, while impeding only\nrelational memorization still allows learning general properties of the\nunderlying concepts. We formalize the notion of Relational Privacy (RP) and,\ninspired by Differential Privacy (DP), we provide a possible definition of\nDifferential Relational Privacy (DrP). These notions can be used to describe\nand compute bounds on the amount of RM in a trained model. We illustrate\nRelational Privacy concepts in experiments with large-scale models for Question\nAnswering.",
          "link": "http://arxiv.org/abs/2203.16701",
          "publishedOn": "2022-04-02T00:47:19.531Z",
          "wordCount": null,
          "title": "Towards Differential Relational Privacy and its use in Question Answering. (arXiv:2203.16701v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17065",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chugh_T/0/1/0/all/0/1\">Tinkle Chugh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ymeraj_E/0/1/0/all/0/1\">Endi Ymeraj</a>",
          "description": "Wind energy is one of the cleanest renewable electricity sources and can help\nin addressing the challenge of climate change. One of the drawbacks of\nwind-generated energy is the large space necessary to install a wind farm; this\narises from the fact that placing wind turbines in a limited area would hinder\ntheir productivity and therefore not be economically convenient. This naturally\nleads to an optimisation problem, which has three specific challenges: (1)\nmultiple conflicting objectives (2) computationally expensive simulation models\nand (3) optimisation over design sets instead of design vectors. The first and\nsecond challenges can be addressed by using surrogate-assisted e.g.\\ Bayesian\nmulti-objective optimisation. However, the traditional Bayesian optimisation\ncannot be applied as the optimisation function in the problem relies on design\nsets instead of design vectors. This paper extends the applicability of\nBayesian multi-objective optimisation to set based optimisation for solving the\nwind farm layout problem. We use a set-based kernel in Gaussian process to\nquantify the correlation between wind farms (with a different number of\nturbines). The results on the given data set of wind energy and direction\nclearly show the potential of using set-based Bayesian multi-objective\noptimisation.",
          "link": "http://arxiv.org/abs/2203.17065",
          "publishedOn": "2022-04-02T00:47:19.529Z",
          "wordCount": null,
          "title": "Wind Farm Layout Optimisation using Set Based Multi-objective Bayesian Optimisation. (arXiv:2203.17065v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.12438",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gupta_V/0/1/0/all/0/1\">Vishal Gupta</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_M/0/1/0/all/0/1\">Michael Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rusmevichientong_P/0/1/0/all/0/1\">Paat Rusmevichientong</a>",
          "description": "Motivated by the poor performance of cross-validation in settings where data\nare scarce, we propose a novel estimator of the out-of-sample performance of a\npolicy in data-driven optimization.Our approach exploits the optimization\nproblem's sensitivity analysis to estimate the gradient of the optimal\nobjective value with respect to the amount of noise in the data and uses the\nestimated gradient to debias the policy's in-sample performance. Unlike\ncross-validation techniques, our approach avoids sacrificing data for a test\nset, utilizes all data when training and, hence, is well-suited to settings\nwhere data are scarce. We prove bounds on the bias and variance of our\nestimator for optimization problems with uncertain linear objectives but known,\npotentially non-convex, feasible regions. For more specialized optimization\nproblems where the feasible region is \"weakly-coupled\" in a certain sense, we\nprove stronger results. Specifically, we provide explicit high-probability\nbounds on the error of our estimator that hold uniformly over a policy class\nand depends on the problem's dimension and policy class's complexity. Our\nbounds show that under mild conditions, the error of our estimator vanishes as\nthe dimension of the optimization problem grows, even if the amount of\navailable data remains small and constant. Said differently, we prove our\nestimator performs well in the small-data, large-scale regime. Finally, we\nnumerically compare our proposed method to state-of-the-art approaches through\na case-study on dispatching emergency medical response services using real\ndata. Our method provides more accurate estimates of out-of-sample performance\nand learns better-performing policies.",
          "link": "http://arxiv.org/abs/2107.12438",
          "publishedOn": "2022-04-02T00:47:19.529Z",
          "wordCount": null,
          "title": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization. (arXiv:2107.12438v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.17153",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Baagmark_K/0/1/0/all/0/1\">Kasper B&#xe5;gmark</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Andersson_A/0/1/0/all/0/1\">Adam Andersson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Larsson_S/0/1/0/all/0/1\">Stig Larsson</a>",
          "description": "The main goal of this paper is to approximately solve the nonlinear filtering\nproblem through deep learning. This is achieved by solving the Zakai equation\nby a deep splitting method, previously developed for approximate solution of\n(stochastic) partial differential equations. This is combined with an\nenergy-based model for the approximation of functions by a deep neural network.\nThis results in a computationally fast filter that takes observations as input\nand that does not require re-training when new observations are received. The\nmethod is tested on three examples, one linear Gaussian and two nonlinear. The\nmethod shows promising performance when benchmarked against the Kalman filter\nand the bootstrap particle filter.",
          "link": "http://arxiv.org/abs/2203.17153",
          "publishedOn": "2022-04-02T00:47:19.332Z",
          "wordCount": null,
          "title": "An energy-based deep splitting method for the nonlinear filtering problem. (arXiv:2203.17153v1 [stat.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.12558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>",
          "description": "Machine learning has developed a variety of tools for learning and\nrepresenting high-dimensional distributions with structure. Recent years have\nalso seen big advances in designing multi-item mechanisms. Akin to overfitting,\nhowever, these mechanisms can be extremely sensitive to the Bayesian prior that\nthey target, which becomes problematic when that prior is only approximately\nknown. At the same time, even if access to the exact Bayesian prior is given,\nit is known that optimal or even approximately optimal multi-item mechanisms\nrun into sample, computational, representation and communication intractability\nbarriers.\n\nWe consider a natural class of multi-item mechanism design problems with very\nlarge numbers of items, but where the bidders' value distributions can be\nwell-approximated by a topic model akin to those used in recommendation systems\nwith very large numbers of possible recommendations. We propose a mechanism\ndesign framework for this setting, building on a recent robustification\nframework by Brustle et al., which disentangles the statistical challenge of\nestimating a multi-dimensional prior from the task of designing a good\nmechanism for it, and robustifies the performance of the latter against the\nestimation error of the former. We provide an extension of this framework\nappropriate for our setting, which allows us to exploit the expressive power of\ntopic models to reduce the effective dimensionality of the mechanism design\nproblem and remove the dependence of its computational, communication and\nrepresentation complexity on the number of items.",
          "link": "http://arxiv.org/abs/2110.12558",
          "publishedOn": "2022-04-02T00:47:19.332Z",
          "wordCount": null,
          "title": "Recommender Systems meet Mechanism Design. (arXiv:2110.12558v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.15009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1\">Thomas M. Moerland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1\">Joost Broekens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>",
          "description": "Sequential decision making, commonly formalized as optimization of a Markov\nDecision Process, is a key challenge in artificial intelligence. Two successful\napproaches to MDP optimization are reinforcement learning and planning, which\nboth largely have their own research communities. However, if both research\nfields solve the same problem, then we might be able to disentangle the common\nfactors in their solution approaches. Therefore, this paper presents a unifying\nalgorithmic framework for reinforcement learning and planning (FRAP), which\nidentifies underlying dimensions on which MDP planning and learning algorithms\nhave to decide. At the end of the paper, we compare a variety of well-known\nplanning, model-free and model-based RL algorithms along these dimensions.\nAltogether, the framework may help provide deeper insight in the algorithmic\ndesign space of planning and reinforcement learning.",
          "link": "http://arxiv.org/abs/2006.15009",
          "publishedOn": "2022-04-02T00:47:19.034Z",
          "wordCount": null,
          "title": "A Unifying Framework for Reinforcement Learning and Planning. (arXiv:2006.15009v4 [cs.LG] UPDATED)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub8oxx/p_demo_of_googles_new_phorum_image3d_figure/",
          "author": null,
          "description": "submitted by    /u/NichodonARG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub8oxx/p_demo_of_googles_new_phorum_image3d_figure/",
          "publishedOn": "2022-04-25T00:44:20.000Z",
          "wordCount": 102,
          "title": "[P] Demo of Google's new PHORUM Image➠3D Figure Project",
          "imageUrl": "https://external-preview.redd.it/xarSgeckhCFOVGDdVFJVuHrLVrL_PaQb4b_arEQvVU8.jpg?auto=webp&s=e47a1e07736d71010cd2d4284cef42806dfc4c3d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub64n5/d_legality_of_hosting_imagenet/",
          "author": null,
          "description": "Despite it's immense popularity in academia, it's surprisingly difficult to download the ImageNet Object Localization dataset. As far as I can tell this is due to legal issues -- no single entity owns the copyright to the images, so no entity can host the whole dataset.\n The result is that if you want to use ImageNet you're forced to either manually scrape a million URLs (requiring both cpu time, your time, and imposing costs on a million unsuspecting websites), know somebody who has already done that, or fetch it from a legally questionable source.\n So I have a couple questions:\n  \nIs the owner of the ImageNet dataset on Kaggle performing a selfless public service, thanklessly accepting legal liability to make ImageNet more accessible? Or is she protected (e.g. by fair use)? Is she required to accept DMCA requests?\n If I'd like to share ImageNet (I've recently downloaded it and processed it to be ~10 GB, which seems like a helpful thing to share), is there any legally safe path for me to do this?\n  \n   submitted by    /u/you-get-an-upvote  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub64n5/d_legality_of_hosting_imagenet/",
          "publishedOn": "2022-04-24T22:31:17.000Z",
          "wordCount": 754,
          "title": "[D] Legality of Hosting ImageNet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub2xlz/d_machine_learning_wayr_what_are_you_reading_week/",
          "author": null,
          "description": "This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.\n Please try to provide some insight from your understanding and please don't post things which are present in wiki.\n Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.\n Previous weeks :\n  \n 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 131-140 \n  \n Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 Week 131 \n  Week 2 Week 12 Week 22 Week 32 Week 42 Week 52 Week 62 Week 72 Week 82 Week 92 Week 102 Week 112 Week 122 Week 132 \n  Week 3 Week 13 Week 23 Week 33 Week 43 Week 53 Week 63 Week 73 Week 83 Week 93 Week 103 Week 113 Week 123 Week 133 \n  Week 4 Week 14 Week 24 Week 34 Week 44 Week 54 Week 64 Week 74 Week 84 Week 94 Week 104 Week 114 Week 124 Week 134 \n  Week 5 Week 15 Week 25 Week 35 Week 45 Week 55 Week 65 Week 75 Week 85 Week 95 Week 105 Week 115 Week 125 Week 135 \n  Week 6 Week 16 Week 26 Week 36 Week 46 Week 56 Week 66 Week 76 Week 86 Week 96 Week 106 Week 116 Week 126  \n  Week 7 Week 17 Week 27 Week 37 Week 47 Week 57 Week 67 Week 77 Week 87 Week 97 Week 107 Week 117 Week 127  \n  Week 8 Week 18 Week 28 Week 38 Week 48 Week 58 Week 68 Week 78 Week 88 Week 98 Week 108 Week 118 Week 128  \n  Week 9 Week 19 Week 29 Week 39 Week 49 Week 59 Week 69 Week 79 Week 89 Week 99 Week 109 Week 119 Week 129  \n  Week 10 Week 20 Week 30 Week 40 Week 50 Week 60 Week 70 Week 80 Week 90 Week 100 Week 110 Week 120 Week 130  \n \n Most upvoted papers two weeks ago:\n /u/CatalyzeX_code_bot: Paper link\n /u/lauren_v2: paper\n Besides that, there are no rules, have fun.\n    submitted by    /u/ML_WAYR_bot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub2xlz/d_machine_learning_wayr_what_are_you_reading_week/",
          "publishedOn": "2022-04-24T20:00:05.000Z",
          "wordCount": 370,
          "title": "[D] Machine Learning - WAYR (What Are You Reading) - Week 136",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ub2461/p_showcase_your_machine_learning_researchprojects/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ub2461/p_showcase_your_machine_learning_researchprojects/",
          "publishedOn": "2022-04-24T19:21:07.000Z",
          "wordCount": 116,
          "title": "[P] Showcase your Machine Learning Research/Projects in Hugging Face Spaces using Gradio",
          "imageUrl": "https://external-preview.redd.it/9YN_--X1MdMQ1lxXNI74QnaYv6Ca_Ao3ChElFUIPjwI.png?format=pjpg&auto=webp&s=8e43b35bd093209389137e40343b312afa29241e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uaxslz/d_how_is_nvidia_p100_on_google_colab_pro_compared/",
          "author": null,
          "description": "submitted by    /u/aviisu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uaxslz/d_how_is_nvidia_p100_on_google_colab_pro_compared/",
          "publishedOn": "2022-04-24T15:57:16.000Z",
          "wordCount": 1759,
          "title": "[D] How is NVIDIA P100 on Google Colab Pro compared to Laptop with RTX3080 (Mobile, or Max-Q) ?",
          "imageUrl": "https://external-preview.redd.it/F2iB3ylaJrNT3VgwPUxHcIZIffFd9zSd1MpJUp3785A.jpg?auto=webp&s=fca5ff6678c74b402625bbd6275feae53ab3b300"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uawla1/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uawla1/d_simple_questions_thread/",
          "publishedOn": "2022-04-24T15:00:11.000Z",
          "wordCount": 596,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ual85u/d_what_is_the_best_optimizer_to_use_when/",
          "author": null,
          "description": "Hi, seemingly it's become a staple in conv net inner-working visualization to put a network in eval mode, sample a random noise image, and optimize the image in relation to the activation of some internal neuron. \n From what I saw, most examples of this on the internet are using an Adam optimizer for this with a learning rate of 0.1 and a weight decay of 1e-6. \n This doesn't seem quite right with me, So if any of you know what's the source for this convention and if there are other alternatives I'd appreciate this information very much.\n Thanks!\n    submitted by    /u/ondrea_luciduma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ual85u/d_what_is_the_best_optimizer_to_use_when/",
          "publishedOn": "2022-04-24T02:56:10.000Z",
          "wordCount": 229,
          "title": "[D] What is the best optimizer to use when visualization inter-net neurons by optimizing random input in relation to it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uah6pc/time_series_analysis_for_air_pollution_data_not/",
          "author": null,
          "description": "This is about a project that I am working on; Hope the ML community can help me!\n I have collected few hours of air pollutants data using Aeroqual sensors and custom made sensors. 3 types of data is available in the project; aeroqual, custom, council data. Where council data can be taken for granted (It comes from the govt installed high spec sensor).\n Aeroqual is a commercial sensor manufacturing company, its data should be accurate. The first part of the project is about checking the accuracy of custom sensor. So, I have done few analysis on the data; and found that custom sensor data has similarity (but not same, there are so much variation in the custom sensor data) with council sensor data but aeroqual data is way different.\n I am attaching the plot below which I have done.\n ​\n  \nSo I need to know is there any method that I can find relationship between these three datasets?\n Is it possible to make these data align togather?\n I need to build an ML model to predict the air pollutant level using this data. any tips for getting this thing working?\n  \n- Thanks in advance\n ​\n https://preview.redd.it/fzu7dbsz0dv81.png?width=885&format=png&auto=webp&s=516d65fe3290ac8a28159547880f9dc972922b64\n    submitted by    /u/Codename_17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uah6pc/time_series_analysis_for_air_pollution_data_not/",
          "publishedOn": "2022-04-23T23:06:31.000Z",
          "wordCount": 293,
          "title": "Time Series Analysis for air pollution data not aligned [R] [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uafvfm/d_for_training_a_haar_cascade_is_it_better_to/",
          "author": null,
          "description": "submitted by    /u/Counter-Business  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uafvfm/d_for_training_a_haar_cascade_is_it_better_to/",
          "publishedOn": "2022-04-23T21:58:43.000Z",
          "wordCount": 205,
          "title": "[D] For training a HAAR cascade is it better to manually remove noise from positive training images or to leave it in so the data is more realistic?",
          "imageUrl": "https://preview.redd.it/6eum46f3pcv81.jpg?auto=webp&s=2d317a1a1bcf0d3078f6e2328925e81b6a657b25"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uafe1e/d_how_to_convert_papers_to_code/",
          "author": null,
          "description": "My problem is probably what you have guessed: it's understanding the technical specifications which are usually written in a non-coding-friendly way. Sometimes crucial information is completely missing from the paper ex: loss function description for a DL algorithm. For the lucky cases where there are already available implementations on github to a given paper, usually they are either very distinguishable from each other in terms of code structure which questions their validity or whether they match what the paper authors intended specially with varying measurable results, or they are almost exact copies from one another. There are numerous examples where I can show specific papers with varying degrees of complexity, and discuss why the conversion can be tricky but they may require standalone discussions themselves, likely outside the scope of this one. Is there a way to approach the problem assuming the absence of reference code?\n    submitted by    /u/shine-box  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uafe1e/d_how_to_convert_papers_to_code/",
          "publishedOn": "2022-04-23T21:33:31.000Z",
          "wordCount": 507,
          "title": "[D] How to convert papers to code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uaf6ju/open_source_model_for_identifying_extremism/",
          "author": null,
          "description": "submitted by    /u/OppositeMonday  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uaf6ju/open_source_model_for_identifying_extremism/",
          "publishedOn": "2022-04-23T21:22:54.000Z",
          "wordCount": 99,
          "title": "Open Source Model For Identifying Extremism Online [Project]",
          "imageUrl": "https://external-preview.redd.it/gatKKT2uQT-94IL8rz58x2TQGESny6vaixpBetiTK1s.jpg?auto=webp&s=19d55d8c00c45bfd632e8856f30ad18e9b451d32"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uadnhi/p_tired_of_manually_sending_minutes_of_meeting/",
          "author": null,
          "description": "I host an important org level meeting (~100 attendees) every week, and need to share minutes after the meeting. I am so tired of listening to conversations again just to capture important points, summarise discussion and action items. Is there any model/api which can help me do that? I use Amazon transcribe to generate transcripts, which helps, but it is not very accurate. For me the priority would be: 1) Model/api which is better than Amazon transcribe 2) Auto Identify speakers / speaker diarization (since mostly the same set of people speak) 3) Summarise the conversations into topics (we have time and agenda based discussion)\n I am sure this might be a problem across the industry since most of the meetings happen online, and someone wastes hours after meeting to send notes. I did find some tools which summarise the transcript, but i need to auto send in a specific format and identify topics based on conversion (maybe we can input the agenda in advance). Also this is private information, so I need something on premise, hence looking for a repo or model which i can use to build something on top.\n Please let me know if something exists or someone working on similar projects. Happy to collaborate and contribute.\n    submitted by    /u/super_commando-dhruv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uadnhi/p_tired_of_manually_sending_minutes_of_meeting/",
          "publishedOn": "2022-04-23T20:06:31.000Z",
          "wordCount": 380,
          "title": "[P] Tired of manually sending minutes of meeting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uaddw4/r_can_you_find_out_which_news_article_is_written/",
          "author": null,
          "description": "This research will test the human ability to distinguish human written text from text generated by artificial intelligence. Participating will only take 10 minutes. You will receive 2 short news articles about the same topic. One will be written by a human, the other one will be generated by artificial intelligence. It is up to you to find out which one is written by artificial intelligence. You will be asked to do this for four different subjects, namely: Science, Economics & Politics, Society and Sports. At the end of the survey you will receive feedback on how well you have performed.\n The human written articles were collected from various news websites. The Articles created by artificial intelligence were generated using GPT-3 from OpenAI.\n Purpose of the research: We are trying to find out how well GPT-3 performs across subjects. Are there any subject GPT-3 is better at writing about, or is he equally good across all subjects. Secondly we are testing the ability of GPT-3 to generate articles about events that happened after the training of the model. \n You can participate by clicking on the link below, thank you very much for your participation.\n https://vub.fra1.qualtrics.com/jfe/form/SV_b2E9f6hGxNDH13M\n    submitted by    /u/RobinSandersVUB  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uaddw4/r_can_you_find_out_which_news_article_is_written/",
          "publishedOn": "2022-04-23T19:53:34.000Z",
          "wordCount": 401,
          "title": "[R] ?? Can you find out which news article is written by AI ??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uad4dw/r_i_need_to_run_2000_experiments_for_my_phd_work/",
          "author": null,
          "description": "2000 GPUs and 8000 CPUs. And where could I even get such a vast affordance?\n    submitted by    /u/samlerman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uad4dw/r_i_need_to_run_2000_experiments_for_my_phd_work/",
          "publishedOn": "2022-04-23T19:40:41.000Z",
          "wordCount": 659,
          "title": "[R] I need to run >2000 experiments for my PhD work. How much would 2000 GPUs for 1 day cost?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uacstm/p_vectorflow_is_a_minimalist_neural_network/",
          "author": null,
          "description": "submitted by    /u/ur_mum_goes_to_uni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uacstm/p_vectorflow_is_a_minimalist_neural_network/",
          "publishedOn": "2022-04-23T19:24:29.000Z",
          "wordCount": 139,
          "title": "[P] Vectorflow is a minimalist neural network library optimized for sparse data and single machine environments open sourced by Netflix",
          "imageUrl": "https://external-preview.redd.it/ZtPt4WkFe4EaDF_Cvz9qSDMqtIFvqNDQi1V7r9fYqZE.jpg?auto=webp&s=221ee90be7dec44cef3fc6243be8108cd02357bf"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/uacisv/project_face_detection_algorithms_comparison/",
          "author": null,
          "description": "I selected 5 ready-made algorithms for face detection and compared them with each other by such metrics as Precision, Recall, IOU and time on the dataset I marked up. I am ready to accept your Pull Request with your solutions(algorithms) and results!\n GitHub: https://github.com/wb-08/face-detection-algorithms-comparison\n Blog post: https://habr.com/ru/post/661671/\n    submitted by    /u/wb-08  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/uacisv/project_face_detection_algorithms_comparison/",
          "publishedOn": "2022-04-23T19:10:39.000Z",
          "wordCount": 134,
          "title": "[Project] Face detection algorithms comparison",
          "imageUrl": "https://external-preview.redd.it/UCht1ilda6NOzvxRBsEV6qZRE2rjI3h21hx1o3Ibc-o.jpg?auto=webp&s=294414e94c756bad73ae7c4bf6854fdfe15d0372"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua5yps/discussion_writing_production_grade_code_for_ml/",
          "author": null,
          "description": "I have been interviewing for a machine learning lead position. I have successfully passed 3 interview rounds (coding , HR, system design). I have my final interview with the VP of Engineering. When asked how best to prepare myself, they said they would like to test my ability to write \"production quality\" code in python. While I do have some experience, the downside is I worked in small R&D teams for a long time. Though I am knowledgeable in python, perhaps, I might have not followed all the industry best practices.\n If you are a hiring manager or interviewer, how would you test this ability? How do I prepare myself to prove my ability to write production grade code?\n Thank you all so much in advance.\n    submitted by    /u/mbkv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua5yps/discussion_writing_production_grade_code_for_ml/",
          "publishedOn": "2022-04-23T13:55:24.000Z",
          "wordCount": 1090,
          "title": "[Discussion] Writing production grade code for ML in python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua5vig/d_comparing_the_efficiency_of_different_gan_models/",
          "author": null,
          "description": "I'm comparing different GAN models (CGan, DCGan, WGan, StyleGan) in tensorflow2. In general, I want to use the images that I generate with the generator to train a classifier while being as realistic as possible. At first, I wanted to let them train for 24 hours each, define some early stopping criteria and save the checkpoints with the lowest loss through a callback. But it seems that the lower loss does not always lead to more realistic images. So how do I compare the different models in a scientific way? Because the results highly depend on the epoch I choose and my subjective feeling, which images look the best.\n    submitted by    /u/Bonkikong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua5vig/d_comparing_the_efficiency_of_different_gan_models/",
          "publishedOn": "2022-04-23T13:50:34.000Z",
          "wordCount": 276,
          "title": "[D] Comparing the efficiency of different GAN models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua520y/p_artificial_nightmares_split_personality_clip/",
          "author": null,
          "description": "https://www.youtube.com/watch?v=2E_6ARbrMmc\n    submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua520y/p_artificial_nightmares_split_personality_clip/",
          "publishedOn": "2022-04-23T13:06:48.000Z",
          "wordCount": 120,
          "title": "[P], Artificial Nightmares: Split Personality || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/hlTDFwwRZ4wn0GUBX2uENYwTAqKodl4hmtQPIaGe2po.jpg?auto=webp&s=3043229ca7283c792e2b66610eefb4e47164b3b3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua465u/n_googles_new_ai_image_analysis_is_pretty_lit_and/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua465u/n_googles_new_ai_image_analysis_is_pretty_lit_and/",
          "publishedOn": "2022-04-23T12:16:40.000Z",
          "wordCount": 125,
          "title": "[N] Google's new AI image analysis is pretty LiT - and beats OpenAI's CLIP",
          "imageUrl": "https://external-preview.redd.it/4K_ZsdM9EbK4U2g4bnglLcONPQpLYb0aTtB8dTEcPK0.jpg?auto=webp&s=5022e30517a79227e5c8b541038ee87dd4a19eb3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua2bv0/p_a_simpler_pytorch_annotated_implementation_of/",
          "author": null,
          "description": "Github: https://github.com/labmlai/neox\n Annotated implementation: https://lit.labml.ai/github/labmlai/neox/tree/main/src/neox/__init__.py\n Original repo from EleutherAI: https://github.com/EleutherAI/gpt-neox\n We have included samples showing how to generate text and to fine-tune. We haven't included a bunch of optimizations that were present in original GPT-NeoX to keep things simple.\n    submitted by    /u/hnipun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua2bv0/p_a_simpler_pytorch_annotated_implementation_of/",
          "publishedOn": "2022-04-23T10:18:06.000Z",
          "wordCount": 346,
          "title": "[P] A Simpler @PyTorch Annotated Implementation of EleutherAI's 20B Language Model GPT-NeoX.",
          "imageUrl": "https://external-preview.redd.it/ISzESs_e2alNyvfBqT9H8r-_KssToJogl9O1_1mzZBM.jpg?auto=webp&s=5bc541aaf288b3b7898a3f106d5d3b52e66dcb14"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua1m2a/p_treequeues_transfert_jax_pytrees_between/",
          "author": null,
          "description": "Hello!\n If you are using jax and you need to pass some pytrees between processes, I may have something for you :)\n I developed a \"treequeue\". It is a queue that is made for pytree's nested arrays.\n The transfer speed is up to 10 times higher than regular queues. This is done by utilizing shared memory arrays and avoiding pickling data. This can be very useful when developing distributed architecture, e.g. distributed reinforcement learning where speed is at the upmost importance.\n In my case this implementation was very useful to remove bottlenecks when implementing PBT algorithms!\n https://github.com/thomashirtz/treequeues\n Cheers!\n    submitted by    /u/krenast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua1m2a/p_treequeues_transfert_jax_pytrees_between/",
          "publishedOn": "2022-04-23T09:26:48.000Z",
          "wordCount": 199,
          "title": "[P] treequeues: transfert jax pytrees between processes with very high speed!",
          "imageUrl": "https://external-preview.redd.it/AfqdsD-Nf9VCHqNm-Eh8Tsa9gCh6471nqoID-BYyGLE.jpg?auto=webp&s=dc5258cd3bf27473d94cb315be96e536da69c886"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua158p/d_autonsurvival_package_for_deep_survival/",
          "author": null,
          "description": "Comes with ‘white paper’ and example notebooks… seems legit..? Anyone tried this out yet?\n Github\n Paper]\n    submitted by    /u/proportional-hazard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua158p/d_autonsurvival_package_for_deep_survival/",
          "publishedOn": "2022-04-23T08:51:57.000Z",
          "wordCount": 135,
          "title": "[D] ‘auton-survival’ package for deep survival analysis and time to event regression from CMU.",
          "imageUrl": "https://external-preview.redd.it/LRLBAOWLDTmaDORdujYz0TJP6ZNultRbj5gY9uFIns0.jpg?auto=webp&s=8d9e026a5fe0d4f972af34c875e2183471e75dfd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ua121h/p_unofficial_vitvqgan_implementation/",
          "author": null,
          "description": "I know that many people (including me) were surprised after seeing the image quality of ViT-VQGAN and disappointed to know there won't be no source code released. Therefore, I've decided to implement it by myself and here is the code. I hope this can help everyone as a starting point for ViT-VQGAN.\n    submitted by    /u/ThunaClone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ua121h/p_unofficial_vitvqgan_implementation/",
          "publishedOn": "2022-04-23T08:45:32.000Z",
          "wordCount": 138,
          "title": "[P] Unofficial ViT-VQGAN implementation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9xbaa/rp_styleganhuman_a_datacentric_odyssey_of_human/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9xbaa/rp_styleganhuman_a_datacentric_odyssey_of_human/",
          "publishedOn": "2022-04-23T04:29:35.000Z",
          "wordCount": 320,
          "title": "[R][P] StyleGAN-Human: A Data-Centric Odyssey of Human Generation + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/xh5KDFN-5xaey_VOKD2hlTmmFOXgMPiUqxc5OkZbl5g.png?format=pjpg&auto=webp&s=e7f12d16576c98ad5813cd5ff9609b93c7d9892f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9vnd6/d_review_of_endtoend_multimodal_deep_learning/",
          "author": null,
          "description": "In reviewing various approaches to end-to-end deep learning for autonomous driving, I've come across an interesting approach in this paper that I would like to discuss with others...\n I will begin by summarizing the approach:\n ​\n  \nA ResNet50 architecture is used as an encoder network with the input being an RGB image + depth map concatenated as (224 x 224 x 4). In the paper it is argued that a point cloud can also be used, or some other sensor modality would also work\n The encoder network output (feature map of 7 x 7 x 2048) is fed into a decoder network that takes it back to (224 x 224 x 5) with pixel wise semantic segmentation of 5 classes: lane, road line, sidewalk, vehicles or pedestrians, and others\n That same encoder output (feature map of 7 x 7 x 2048) is global average pooled to 2…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9vnd6/d_review_of_endtoend_multimodal_deep_learning/",
          "publishedOn": "2022-04-23T02:54:52.000Z",
          "wordCount": 523,
          "title": "[D] Review of end-to-end multi-modal deep learning approach for autonomous navigation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9oygy/r_game_changer_or_not_an_evaluation_of/",
          "author": null,
          "description": "https://arxiv.org/abs/2204.09123 \n https://www.researchgate.net/publication/360079336_GAMe_changer_or_not_An_evaluation_of_interpretable_machine_learning_models_based_on_additive_model_constraints\n    submitted by    /u/Positive_Ad_1090  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9oygy/r_game_changer_or_not_an_evaluation_of/",
          "publishedOn": "2022-04-22T21:15:41.000Z",
          "wordCount": 126,
          "title": "[R] GAM(e) changer or not? An evaluation of interpretable machine learning models based on additive model constraints",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9jn6x/how_can_you_differentiate_kornia_sift_descriptor_p/",
          "author": null,
          "description": "Kornia is a differentiable library for computer vision based on PyTorch. Does anyone have experience with their SIFT descriptor. What can you differentiate?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9jn6x/how_can_you_differentiate_kornia_sift_descriptor_p/",
          "publishedOn": "2022-04-22T17:12:18.000Z",
          "wordCount": 121,
          "title": "How can you differentiate Kornia SIFT descriptor? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9h972/d_evaluation_and_selecting_models_base_on_loss_or/",
          "author": null,
          "description": "When comes to evaluating and selecting a model, should one focus on minimizing loss (i.e., sparse categorical crossentropy) or obtain high rated metrics (i.e., f1)?\n Often time the model highest rated metrics would generate higher loss than ones with lower ratings in metrics during validation/test sets.\n Some would say focus on metrics as loss are for the machine to optimize learning, what stays in the training, stays in the training. However, wouldn't loss be also an important element to consider since it also describe the performance of the model, particularly when obtained from the test set?\n How should one prioritize? Metrics/loss rules all or seek for balance?\n    submitted by    /u/Hydraze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9h972/d_evaluation_and_selecting_models_base_on_loss_or/",
          "publishedOn": "2022-04-22T15:26:21.000Z",
          "wordCount": 446,
          "title": "[D] Evaluation and Selecting Models: Base on Loss or Metrics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u9bo6s/r_optimize_clustering_for_downstream_task/",
          "author": null,
          "description": "Assume to have a 2-step algorithm: 1) aggregate data points into clusters 2) feed the clusters to a downstream task (e.g. classification, regression, etc).\n Is there any work that explores how to optimize the clustering in 1) to achieve the best performance in the downstream task 2)?\n One example would be a differentiable clustering algorithm that receives gradients from the downstream task or a parametrized clustering algorithm whose parameters are automatically tuned to increase the performance of the downstream task.\n I have found very little on this topic in the literature, could you point me to some relevant work?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u9bo6s/r_optimize_clustering_for_downstream_task/",
          "publishedOn": "2022-04-22T10:43:12.000Z",
          "wordCount": 423,
          "title": "[R] Optimize clustering for downstream task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u99fgu/d_what_is_a_good_emoji_aware_pretrained_language/",
          "author": null,
          "description": "I am classifying social media posts (facebook, instagram), with emojis being upwards of 100% of content. For example, you may want to tag \"🤮🤮🤮\" as in need for moderation, and \"🤔🤔🤔\" as prioritized for a response.\n Looking for a good model to fine tune I found BerTweet, which seems at least somewhat emoji aware. However it also has a ton of out-of-vocabulary results, both for emoji and semi-common English words, despite it's liberal use of emoji.demojize and splitting up more complex emoji:\n ​\n https://preview.redd.it/t6ai3o8le1v81.png?width=687&format=png&auto=webp&s=c16157addbe1b3d34858708f3e6c7517e64d26ec\n A model like `xlm-roberta-base with a larger vocabulary (250k) and more robust tokenization seems to have some 500 emoji directly in its vocabulary directly, without converting them to text. This seems potentially more promising, but also guarantees a token like 🤮 is just out of vocabulary rather than being interpreted by word pieces.\n Has anyone here had experience with dealing with emoji in text classification, and what approaches were most successful?\n    submitted by    /u/sanderbaduk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u99fgu/d_what_is_a_good_emoji_aware_pretrained_language/",
          "publishedOn": "2022-04-22T08:06:43.000Z",
          "wordCount": 716,
          "title": "[D] What is a good emoji aware pre-trained language model?",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u980kl/d_what_is_the_best_method_to_use_metric_network/",
          "author": null,
          "description": "Hi, I have a question about how to use metric network after contrastive learning. If I have trained a network well with NCELoss, I would like to finetune this network to match the best output by input(It used at calculating NCELoss). Is there any good way to do it?\n ​\n Thank you for reading!\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u980kl/d_what_is_the_best_method_to_use_metric_network/",
          "publishedOn": "2022-04-22T06:28:31.000Z",
          "wordCount": 171,
          "title": "[D] What is the best method to use metric network at finetune after contrastive learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u967sy/d_opinions_needed_anyone_interested_in_mock_peer/",
          "author": null,
          "description": "We’d like to know if anyone is interested in participating in a mock peer review? Basically if you have a paper you’d like to get feedback on, and would like to review others’ papers in exchange, you’re welcome to continue reading.\n We are gauging public interest in mock peer review and exploring the possibility to host the reviews on DouBlind. We’d like to know your answers to the following questions:\n  \nAre you interested in mock peer review? \n Do you want to do this privately (paper and review are kept inside a small group) or openly (paper and review are open)?\n How many papers do you like to review?\n Do you have any concerns?\n  \n   submitted by    /u/DouBlindDotCOM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u967sy/d_opinions_needed_anyone_interested_in_mock_peer/",
          "publishedOn": "2022-04-22T04:32:52.000Z",
          "wordCount": 522,
          "title": "[D] Opinions needed - Anyone interested in mock peer review?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u94fnq/research_explaining_the_black_box_optimization/",
          "author": null,
          "description": "This is reproduced from Zhihu and translated by DeepL, only used for enthusiasts to communicate.\n ​\n MindSpore, as an end-to-edge cloud collaborative full-scenario AI open source framework, takes into account the flexibility of academic research and the high-performance needs of industry, supports end-to-edge cloud full-scene business, and brings developers a simpler programming, easier debugging, superior performance, and more flexible deployment experience, which has received widespread attention and application in the industry and has been open source on 2020.3.28, and is the Gitee The highest index of open source software. Welcome to participate in open source contributions, model crowdsourcing collaboration, industry innovation and application, algorithm innovation, academic collabora…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u94fnq/research_explaining_the_black_box_optimization/",
          "publishedOn": "2022-04-22T02:51:01.000Z",
          "wordCount": 766,
          "title": "[Research] Explaining the Black Box Optimization Competition Winner Algorithm-HEBO Algorithm of AI Top Conference NeurIPS 2020",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8zhy2/p_mgpt_model_released_a_multilingual_gpt3like/",
          "author": null,
          "description": "Hi everyone. Today we released the mGPT model: multilingual generative pre-trained transformer\n The checkpoints are available on Huggingface model page\n The example usage is at the Github repo https://github.com/ai-forever/mgpt \n  \nThe model has 1.3 billion parameters\n The context length is 512 tokens. \n  \nThe model can generate sequences after the input prompt, can be used for fine-tuning or for zero- and few-shot learning:\n from transformers import GPT2LMHeadModel, GPT2Tokenizer model_name = \"sberbank-ai/mGPT\" tokenizer = GPT2Tokenizer.from_pretrained(model_name) model = GPT2LMHeadModel.from_pretrained(model_name) model.cuda() model.eval() texts = [ \"My favourite holiday is \", \"Իմ սիրելի տոնն է \", \"Моє улюблене свято \", \"mi fiesta favorita es \", \"मेरी पसंदीदा छुट्टी है\", \"我最喜欢的节日是\", \"Min…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8zhy2/p_mgpt_model_released_a_multilingual_gpt3like/",
          "publishedOn": "2022-04-21T22:37:10.000Z",
          "wordCount": 461,
          "title": "[P] mGPT model released: a multilingual gpt-3-like model for 61 language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8xrhg/p_deep_learning_gpu_benchmark_a_latencybased/",
          "author": null,
          "description": "Hi r/MachineLearning! I want to share with you a fun side project of mine on benchmarking the GPUs for deep learning: [project page]. \n https://preview.redd.it/7olwqyze5yu81.png?width=2041&format=png&auto=webp&s=25aecb9733366720a2be5cecc2048eb2a734c9b9\n Here are some key features:\n  \nIt helps to estimate the runtime of algorithms on a different GPU.\n It measures GPU processing speed independent of GPU memory capacity.\n It contains adjustable weightings through interactive UIs.\n  \nThe project page also explains how this benchmark differs from existing ones, and why this benchmark is more relevant to academic research.\n I would love to know what you think!\n    submitted by    /u/roll-a-dice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8xrhg/p_deep_learning_gpu_benchmark_a_latencybased/",
          "publishedOn": "2022-04-21T21:13:36.000Z",
          "wordCount": 179,
          "title": "[P] Deep Learning GPU Benchmark: A Latency-Based Approach",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8xexj/d_whats_your_perfect_laptop_for_deep_learning/",
          "author": null,
          "description": "I'm using mbp 2015, it's a pretty solid laptop, I like it a lot, though it feels slow and I've started to look for a replacement. Given that I run all experiment on gpu dedicated servers, my laptop serves me as a typewriter, it's ok, but I'd like to get more out of it. Frankly I'm a bit disappointed by 2021 Macbooks, hope they'll be improved in 2022.\n Recently lambda labs together with razer announced their tensorbook https://lambdalabs.com/deep-learning/laptops/tensorbook , their pricing looks weird to me, the more you pay the more years of support you have, that's the only thing which differentiates base bundle from enterprise. Also there is no option to customize hardware for it, though basic bundle itself looks ok, its price is $3500 like M1 Max's. What's your opinion about this laptop in particular? would you buy it?\n generally this laptop looks like a cool thing to have for local model development even from a tent somewhere in Nepal, given that you have enough power banks to charge it. :)\n What's your choice of a laptop for DL? My biggest requirement is a durable laptop which will serve at least 5 years, better with NVIDA GPU for development and debugging.\n    submitted by    /u/taras-sereda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8xexj/d_whats_your_perfect_laptop_for_deep_learning/",
          "publishedOn": "2022-04-21T20:57:29.000Z",
          "wordCount": 326,
          "title": "[D] What's your perfect laptop for deep learning research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8w5bq/r_deep_models_of_superficial_face_judgments_pnas/",
          "author": null,
          "description": "​\n Transformations that alter the perception of target faces\n Paper: https://www.pnas.org/doi/10.1073/pnas.2115228119\n Dataset: https://onemillionimpressions.com/\n    submitted by    /u/joshuacpeterson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8w5bq/r_deep_models_of_superficial_face_judgments_pnas/",
          "publishedOn": "2022-04-21T19:59:31.000Z",
          "wordCount": 108,
          "title": "[R] Deep models of superficial face judgments (PNAS)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8v92h/r_planting_undetectable_backdoors_in_machine/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8v92h/r_planting_undetectable_backdoors_in_machine/",
          "publishedOn": "2022-04-21T19:17:49.000Z",
          "wordCount": 101,
          "title": "[R] Planting Undetectable Backdoors in Machine Learning Models",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8v2ox/p_vicreg_tutorial_and_lightweight_pytorch/",
          "author": null,
          "description": "Here's a tutorial and lightweight PyTorch implementation of VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning. Hope you find it helpful!\n    submitted by    /u/thejashGI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8v2ox/p_vicreg_tutorial_and_lightweight_pytorch/",
          "publishedOn": "2022-04-21T19:09:51.000Z",
          "wordCount": 136,
          "title": "[P] VICReg: Tutorial and Lightweight PyTorch Implementation blog post",
          "imageUrl": "https://external-preview.redd.it/nlio8usMqy_ReFWZfdRWZzVWPAOmlaQsm5fC0fDkpO4.jpg?auto=webp&s=e7ed882487e5ed475af6d8e7f98866ba1a7d80b0"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8s9zr/p_announcing_cleanlab_20_automatically_find/",
          "author": null,
          "description": "Hi folks. This morning I released the new cleanlab 2.0 Python package for automatically finding errors in datasets and machine learning/analytics with real-world, messy data and labels.\n tl;dr - cleanlab provides a framework to streamline data-centric AI. \n https://preview.redd.it/hq1kyasvwwu81.png?width=2279&format=png&auto=webp&s=4fa3c82ec66d685c8fc4f95c5d9a0fc4be192d6b\n After 1.0 launch last year, engineers used cleanlab at Google to clean and train robust models on speech data), at Amazon to estimate how often the Alexa device doesn’t wake, at Wells Fargo to train reliable financial prediction models, and at Microsoft, Tesla, Facebook, etc. Joined by two good friends from grad school, we completely rebuilt cleanlab 2.0 to work for all data scientists, ML datasets, and models; and hit a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8s9zr/p_announcing_cleanlab_20_automatically_find/",
          "publishedOn": "2022-04-21T17:01:18.000Z",
          "wordCount": 473,
          "title": "[P] Announcing cleanlab 2.0: Automatically Find Errors in ML Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8s48x/p_galp_hackathon_win_10000_from_home/",
          "author": null,
          "description": "If you are passionate about Data & AI we have the perfect challenge for you!\n The applications for Galp’s Hackathon Retail 4.0 are OPEN! With this Hackathon, Galp is challenging the community to propose solutions to specific problems and use cases that they think could improve their typical customer journey in the service stations.\n Gather a team and come up with an innovative solution for a chance of winning 10.000€!\n Let’s shape the future of Galp's retail?\n Apply now: https://taikai.network/en/galp/hackathons/retail40\n https://preview.redd.it/wkfb6ybuwwu81.png?width=3334&format=png&auto=webp&s=deef13767df5ba607e387ce4e278ae3981d93582\n    submitted by    /u/migueldsalmeida  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8s48x/p_galp_hackathon_win_10000_from_home/",
          "publishedOn": "2022-04-21T16:54:27.000Z",
          "wordCount": 174,
          "title": "[P] Galp Hackathon - Win 10.000€ from home!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8ratz/d_imbalanced_multi_class_classification/",
          "author": null,
          "description": "I'm working on a Machine Learning problem for multi class classification with imbalanced classes distribution, so obviously my model favours classes with more data and fails to predict classes with few data, what are the techniques I can use to help the model distinguish all the classes the same way ? P.S I'm avoiding to use SMOTE method to train the model on real used data rather than generated\n    submitted by    /u/According-Promise-23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8ratz/d_imbalanced_multi_class_classification/",
          "publishedOn": "2022-04-21T16:17:38.000Z",
          "wordCount": 472,
          "title": "[D] Imbalanced multi class classification 📌",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8qr5s/r_cvpr_2022_photorealistic_monocular_3d/",
          "author": null,
          "description": "submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8qr5s/r_cvpr_2022_photorealistic_monocular_3d/",
          "publishedOn": "2022-04-21T15:54:05.000Z",
          "wordCount": 111,
          "title": "[R] CVPR 2022 - Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8osxe/r_my_continuously_updated_machine_learning/",
          "author": null,
          "description": "Dear ML researchers,\n For the past many years, I've been updating my machine learning research notes for my PhD students and everyone online continuously. I don't like uploading to arxiv to get \"citations\", and GitHub serves me well: Hope they are useful for you:\n https://github.com/roboticcam/machine-learning-notes\n Richard,\n    submitted by    /u/MLknowledge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8osxe/r_my_continuously_updated_machine_learning/",
          "publishedOn": "2022-04-21T14:23:41.000Z",
          "wordCount": 212,
          "title": "[R] My continuously updated machine learning research notes",
          "imageUrl": "https://external-preview.redd.it/jXbGZ4rJFm5S_5qjRLqzl6dlfbQGyZrgZeCf1as5zc4.jpg?auto=webp&s=30db4308813fd683b4c6e18df9b7ac3c3077dcb1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8o3fd/d_correcting_for_imbalance_in_regression_datasets/",
          "author": null,
          "description": "Hi, I am performing a Image --> scalar regression. The output scalar I am trying to estimate follows a roughly Gaussian distribution. I notice that the DNN output is biased to output values towards the mean (makes sense). \n ​\n This seems like a problem of imbalanced data. For classification, I can oversample minority classes. What is the equivalent for regression? Is there an equivalent technique for regression where we oversample \"outliers\" and undersample central values.\n    submitted by    /u/rsandler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8o3fd/d_correcting_for_imbalance_in_regression_datasets/",
          "publishedOn": "2022-04-21T13:49:27.000Z",
          "wordCount": 356,
          "title": "[D] Correcting for imbalance in regression datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8nv9n/building_dense_passage_retrievers_p/",
          "author": null,
          "description": "Hi, I made a video explaining the ideas behind building a Dense Passage Retriever(DPR). Whenever we talk about retrievers, we mostly refer to the DPR formulation which appeared in this paper. A lot of publicly available implementations also use this formulation. \n In a previous video, we discussed how to use the DPR End-to-End QA system which uses DPR with a QA model. In this video, we solely focus on retrievers and the ideas behind building them. The implementation is quite similar to retrievers pre-trained with Inverse Close Task.\n This video is part 8 of 9 video series on Open-domain question answering using Dense retrievers. Thanks for the support and I will appreciate any feedback.\n https://www.youtube.com/watch?v=w61p0HLo7gc\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8nv9n/building_dense_passage_retrievers_p/",
          "publishedOn": "2022-04-21T13:38:00.000Z",
          "wordCount": 217,
          "title": "Building Dense Passage Retrievers [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8nfz4/d_how_do_you_usually_run_sanity_checks_when/",
          "author": null,
          "description": "Hi, \n I have been studying super-resolution with gans and took a look at SRGAN et ESRGAN. \n I have spent the whole day running experiments in order to find if I can manage to overfit on a single batch of 16 / 32 / 128 examples (MNIST). \n I have found out that it's almost impossible to use this tactic as a sanity check because it simply cannot generate good quality samples. \n I would like to know what are your thoughts on this, and how you would run sanity checks regarding GANs. \n ​\n Thank you !\n    submitted by    /u/Frizzoux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8nfz4/d_how_do_you_usually_run_sanity_checks_when/",
          "publishedOn": "2022-04-21T13:16:41.000Z",
          "wordCount": 257,
          "title": "[D] How do you usually run sanity checks when training GANs ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8l3p1/d_amazon_releases_a_new_multilingual_dataset_for/",
          "author": null,
          "description": "https://www.amazon.science/blog/amazon-releases-51-language-dataset-for-language-understanding\n    submitted by    /u/__lawless  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8l3p1/d_amazon_releases_a_new_multilingual_dataset_for/",
          "publishedOn": "2022-04-21T11:10:14.000Z",
          "wordCount": 107,
          "title": "[D] Amazon Releases a New Multilingual Dataset for NLU",
          "imageUrl": "https://external-preview.redd.it/HL7tbrZbJvn55TAdNpFHuAjizldYc59pZoCL1Xwpj_Y.jpg?auto=webp&s=4bfac45af0c823edd59ce0782aff290631174975"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8l0yj/d_how_to_handle_features_that_apply_to_a_whole/",
          "author": null,
          "description": "Hi all,\n I have csv-files (~300) with a fixed set of columns (~40) but varying number of rows (sum of all rows ~300 000) and multiple labels per csv that I want to predict.\n Because of the limited number of csv-files and as a first try I am predicting the labels row-wise (attaching the label to all the rows of one csv-file) which works well for some labels but not for others.\n Currently, I am calculating some features for every row and just appending them to the row and some features for the whole csv-file and appending them to every row.\n Two problems are now arising that I would like to hear some input about:\n  \nThe number of features per csv is growing and it seems like a waste to copy them to every row.\n For some labels it is probably reasonable to throw away most of the rows and only feed in a handful.\n  \nHow would you design a structure that incorporates the limited number of csv-files and the different ways to treat features (row vs. csv)?\n    submitted by    /u/tlklk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8l0yj/d_how_to_handle_features_that_apply_to_a_whole/",
          "publishedOn": "2022-04-21T11:05:38.000Z",
          "wordCount": 523,
          "title": "[D] How to handle features that apply to a whole csv-file vs single rows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8jy96/rp_differences_in_publishing_a_paper_at_a/",
          "author": null,
          "description": "Hi!\n I am an undergrad and I am going to start my MS in CS this fall. My research interest is mainly in Multimodal Learning for language and Speech.\n I have written papers before but both my papers have been peer reviewed journal papers (Knowledge-Based Systems, Elsevier) [1] [2] I now want to start publishing papers in conferences since I have noticed that it is much easier to get noticed and recieve reviews when the paper is presented at a conference.\n I want to understand how different is the publication process for conferences? I also wanted recommendations on conferences in the NLP and Speech area, considering this will be my first conference paper.\n Thanks!\n (I would also appreciate reviews on my papers if anyone has the time to look them over. Thanks!)\n    submitted by    /u/prabhav55221  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8jy96/rp_differences_in_publishing_a_paper_at_a/",
          "publishedOn": "2022-04-21T09:55:49.000Z",
          "wordCount": 1063,
          "title": "[R][P] Differences in publishing a paper at a conference and in a journal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8jsiz/d_how_do_you_get_the_maximum_of_arxiv_sanity/",
          "author": null,
          "description": "Basically, I don't want to phrase this as a a \"how-to\" post but arxiv-sanity-lite really bothers me.\n How do you guys find recent papers in your area of interest which are promising besides following what is published at major conferences?\n I believe the website is \"too lightweight\". For example, what if I am interested in computer vision papers and I specify that in the tags field (i.e. explicitly typing \"computer vision\"). How can I list the papers based on a score (basically goodness of the paper)?\n Why does using shortcuts (basically links) like `````recommend over last week or recommend over last 3 days always (at least for me) end up with 0 results? I've never used the original arxiv-sanity before so I strongly believe that there is something that I am missing.\n    submitted by    /u/Icy_Fisherman7187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8jsiz/d_how_do_you_get_the_maximum_of_arxiv_sanity/",
          "publishedOn": "2022-04-21T09:44:38.000Z",
          "wordCount": 234,
          "title": "[D] How do you get the maximum of arxiv sanity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8j9n4/n_new_opportunity_phd_candidate_within/",
          "author": null,
          "description": "The Norwegian University of Science and Technology (NTNU) has a vacancy for PhD Candidate within the DIGITALSEAICE project . The project aims to build a multi-scale digital infrastructure that integrates local and regional sea ice models for improved forecasting and understanding of variations in polar ice conditions. More information here: https://www.jobbnorge.no/en/available-jobs/job/224802/\n    submitted by    /u/KatjaKim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8j9n4/n_new_opportunity_phd_candidate_within/",
          "publishedOn": "2022-04-21T09:06:39.000Z",
          "wordCount": 182,
          "title": "[N] New opportunity: PhD Candidate within multisensor data fusion and applied machine learning for analysis of Arctic sea ice",
          "imageUrl": "https://external-preview.redd.it/iFk1S-x00j8dnsCHhxBvPo7JzLeQuhitkNnYKvwNwHo.jpg?auto=webp&s=e22b8f75383380a5eb366624ed9acdb0948362f4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8j8vb/p_efficient_deep_learning_book/",
          "author": null,
          "description": "We are working on a book that focuses on deep learning efficiency techniques such as quantization, pruning, distillation, etc. for both server-side as well as on-device (smartphones, IoT, etc.) applications.\n The goal is to introduce these ideas in a single place, without having to parse many papers, try to get a working code sample, and then spend time debugging. With the accompanying codelabs, we hope that our readers can make their models 4-20x smaller, faster, and better in quality.\n We have released the first four chapter's draft PDFs, and would truly appreciate any sort of comments / feedback.\n Book: efficientdlbook.com\n Feedback: hello@efficientdlbook.com\n    submitted by    /u/EfficientDLBook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8j8vb/p_efficient_deep_learning_book/",
          "publishedOn": "2022-04-21T09:05:10.000Z",
          "wordCount": 411,
          "title": "[P] Efficient Deep Learning Book",
          "imageUrl": "https://external-preview.redd.it/oWMg82plS_K_je4LqS3qhPS63T9YaY5hp-w2uvo9be8.jpg?auto=webp&s=012de82bd475d884d9dccf16ab837af217707e11"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8j1yz/d_interview_w_google_brain_researchers_on_sparse/",
          "author": null,
          "description": "https://youtu.be/ccBMRryxGog\n This video is an interview with Barret Zoph and William Fedus of Google Brain about Sparse Expert Models.\n Sparse Expert models have been hugely successful at distributing parts of models, mostly Transformers, across large array of machines and use a routing function to effectively route signals between them. This means that even though these models have a huge number of parameters, the computational load for a given signal does not increase because the model is only sparsely activated. Sparse expert models, such as Switch Transformers and GLAM can scale up to trillions of parameters and bring a number of desirable properties. We discuss everything from the fundamentals, history, strengths and weaknesses, up to the current state of the art of these models.\n ​\n OUTLINE:\n 0:00 - Intro\n 0:30 - What are sparse expert models?\n 4:25 - Start of Interview\n 5:55 - What do you mean by sparse experts?\n 8:10 - How does routing work in these models?\n 12:10 - What is the history of sparse experts?\n 14:45 - What does an individual expert learn?\n 19:25 - When are these models appropriate?\n 22:30 - How comparable are sparse to dense models?\n 26:30 - How does the pathways system connect to this?\n 28:45 - What improvements did GLAM make?\n 31:30 - The \"designing sparse experts\" paper\n 37:45 - Can experts be frozen during training?\n 41:20 - Can the routing function be improved?\n 47:15 - Can experts be distributed beyond data centers?\n 50:20 - Are there sparse experts for other domains than NLP?\n 52:15 - Are sparse and dense models in competition?\n 53:35 - Where do we go from here?\n 56:30 - How can people get started with this?\n ​\n Papers:\n Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity (https://arxiv.org/abs/2101.03961)\n GLaM: Efficient Scaling of Language Models with Mixture-of-Experts (https://arxiv.org/abs/2112.06905)\n Designing Effective Sparse Expert Models (https://arxiv.org/abs/2202.08906)\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8j1yz/d_interview_w_google_brain_researchers_on_sparse/",
          "publishedOn": "2022-04-21T08:51:22.000Z",
          "wordCount": 398,
          "title": "[D] Interview w/ Google Brain researchers on Sparse Expert Models (Switch Transformers, GLAM, and more...)",
          "imageUrl": "https://external-preview.redd.it/ccj3vB9Jnic9PtdsYqEHsfolMycEL3nvIr8XujwicFo.jpg?auto=webp&s=6c0d9971b48a4126d732a0ffe51b62be0ff80a85"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8i9ei/p_interactive_semantic_map_of_iclr_2022/",
          "author": null,
          "description": "Next week ICLR 2022 is taking place. Fully virtual and 1000+ high quality papers. To make sense of this volume of papers we have indexed the papers and provide an interactive semantic map of #ICLR2022, check out:\n https://search.zeta-alpha.com/?q=&d=ly&doc_sources=ICLR&sort_by=authority \n To enjoy the full map, click on [Explore more] and then enter full screen mode.\n We will also discuss the program and 10 must read papers in the Zeta Alpha \"Trends in AI\" ICLR edition webinar Monday 25th, for which you can sign up here.\n https://us06web.zoom.us/webinar/register/7816505274568/WN_82DzwhXZQbOCSTWgaI9xMw\n Looking forward to meet you online at ICLR 2022! \n https://preview.redd.it/6wdqj4ru7uu81.jpg?width=2202&format=pjpg&auto=webp&s=c97417c9ea39919041949bf3aa38ad33bb6eca5a\n    submitted by    /u/EngineerZetaAlpha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8i9ei/p_interactive_semantic_map_of_iclr_2022/",
          "publishedOn": "2022-04-21T07:52:53.000Z",
          "wordCount": 183,
          "title": "[P] Interactive semantic map of ICLR 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8d4d8/r_mindspore_paper_interpretation_miehdr_cnn_main/",
          "author": null,
          "description": "This article is reproduced from Zhihu and translated by DeepL for enthusiasts to communicate.\n 1. Research Background\n High dynamic range images (HDR) are mainly oriented to picture display technology. In a certain scene, if the range of high and low luminance areas exceeds the maximum luminance range of the image, the display effect will be greatly reduced, and HDR is to better solve this problem, it can record a broader range of luminance images, so as to obtain a more effective display effect.\n The current solution to the problem of generating high dynamic range images (HDR) focuses on the fusion of two low dynamic range (LDR) images of different exposures taken with the same camera. In such a solution by the camera shake or object movement during the exposure time to produce the proble…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8d4d8/r_mindspore_paper_interpretation_miehdr_cnn_main/",
          "publishedOn": "2022-04-21T02:31:54.000Z",
          "wordCount": 1003,
          "title": "[R] MindSpore Paper Interpretation: MIEHDR CNN: Main Image Enhancement based Ghost-Free High Dynamic Range Imaging using Dual-Lens Systems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8baf6/d_most_efficient_way_to_use_large_image_datasets/",
          "author": null,
          "description": "I am having trouble finding some general information on this subject. I know I am down the rabbit hole when google doesn't have an answer.\n I want to know best practices and information on using clusters for machine learning with large amounts of data. I believe I have a close to an optimal solution but wanted to get some other opinions on the subject.\n My current setup:\n  \nAWS EKS Kubernetes for a cluster\n Kubeflow for ML platform\n Katib for HPT jobs\n Pytorch for custom models\n Spot instance GPUs\n Lustre for file serving to the models\n  \nMy Data:\n  \nMillions of Images stored in S3\n ~50TB of data\n  \nWhat is the most efficient way to move my data to the cluster?\n My current approach:\n  \nPreprocess the data with a dedicated instance and store it in S3\n Master runs on a dedicated node\n Katib spins up a set number of GPU spot nodes\n A claim is made, and an FSx Lustre system is generated for the pod\n Advantages: Very fast training and data movement with spot training\n Disadvantages: I have to spin up several Lustre systems for the training\n Preprocess the data with a dedicated instance and store it in S3\n  \nPossible alternative\n  \nSame as above but use EFS as a distributed file system so I don't have to wait for Lustre\n Advantages: Potentially cheaper as I have only one FS\n Disadvantages: Slow throughput, read this was a bad idea\n Master runs on a dedicated node\n  \nOther alternatives\n  \nUseKatib spins up a PyTorch streaming function with S3(boosted transfer speed)set number of GPU spot nodes\n Every pod starts a claim is made and downloads data to an EBS\n Give up and switch to SageMakerFSx Lustre system is generated for the pod\n  \nAnyone with experience in these technologies I would really appreciate hearing your thoughts.\n    submitted by    /u/thewineiswater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8baf6/d_most_efficient_way_to_use_large_image_datasets/",
          "publishedOn": "2022-04-21T00:57:09.000Z",
          "wordCount": 382,
          "title": "[D] Most efficient way to use large image datasets with clusters for ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u8av34/d_p_neural_network_same_prediction_for_different/",
          "author": null,
          "description": "I am getting the same prediction for different inputs. I am trying to use a regressional neural network. Since data is huge, I am training one example at a time. Here is a simplified version of my code.\n model = Sequential() model.add(Dense(10000, input_dim=212207, kernel_initializer='normal', activation='relu')) model.add(Dense(100, activation='relu')) model.add(Dense(1, kernel_initializer='normal')) model.compile(loss='mean_squared_error', optimizer='adam') for i in range(10000000): #X is input with 212207 values #Y is a output value if i<6000000: model.fit(X.transpose(), Y, epochs=30, batch_size=1, verbose=0) else: prediction=model.predict(X.transpose()) \n I made sure that I am training on different examples and trying predictions on different examples. I am still getting the same prediction value for all testing inputs. I think I made some mistake in defining the model for regression neural network. Can you please check if the code is correct?\n    submitted by    /u/exoplanet_hunter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u8av34/d_p_neural_network_same_prediction_for_different/",
          "publishedOn": "2022-04-21T00:35:00.000Z",
          "wordCount": 226,
          "title": "[D] [P] Neural network: same prediction for different inputs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u85rh7/d_who_are_using_physics_informed_neural_networks/",
          "author": null,
          "description": "I stumbled upon this JD from Hitachi Energy, which mentions PINN in the section of preferred background: https://www.linkedin.com/jobs/view/2923292435/\n Is PINN gaining more attention? And are there more players?\n    submitted by    /u/Kohomologia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u85rh7/d_who_are_using_physics_informed_neural_networks/",
          "publishedOn": "2022-04-20T20:31:36.000Z",
          "wordCount": 198,
          "title": "[D] Who are using physics informed neural networks (PINN) in the industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u83jx5/d_is_quantum_ai_a_real_thing_from_the_software/",
          "author": null,
          "description": "Hi all\n I'm keeping an eye on state of the art in quantum hardware, but what about software? I can think of many questions and maybe some of you are in the field.\n  \nWhat should be the impact of quantum on ML/DL, realistically?\n What might be a roadmap for the software? And would quantum simulators do already have some benefits on AI?\n What are the best projects out there? I've seen many but haven't been very convinced\n  \n   submitted by    /u/IntelligentHat1657  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u83jx5/d_is_quantum_ai_a_real_thing_from_the_software/",
          "publishedOn": "2022-04-20T18:50:43.000Z",
          "wordCount": 514,
          "title": "[D] Is quantum AI a real thing? (from the software perspective)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u82znf/d_a_more_fair_ai_freelancer_marketplace_that/",
          "author": null,
          "description": "Hi, ML freelancers. I'm starting a freelancing marketplace, tailored only for AI talents, and I especially care about the welfares of freelancers, and plan to add these: (1) you will be more treated as the employees of the platform, thus we provide training(for all), potentially health care plan(for people have stably worked >20 hours a week), and career advance plan, mentors from experienced freelancers where you get to learn (2) open discussion between employers and you so that you can scope the project better, set a reasonable rate, and timeline (3) we potentially provide MLOPs tool to improve your productivity. (4) we avoid global competition by matching business only with local region-freelancer or areas that are more expensive. How attractive do you think this will be? And any of these benefits already been provided by upwork, freelancer, toptal, fierr?\n    submitted by    /u/meame2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u82znf/d_a_more_fair_ai_freelancer_marketplace_that/",
          "publishedOn": "2022-04-20T18:24:44.000Z",
          "wordCount": 602,
          "title": "[D] A more fair AI freelancer marketplace that cares freelancers' career advance and benefits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u81xcu/d_diffusion_models_video_tutorial/",
          "author": null,
          "description": "Diffusion models have been behind a recent string of impressive generative results, including OpenAI's DALL-E 2. They’re powered by a simple yet expressive core mechanism. New video covering how they work: https://youtu.be/fbLgFrlTnGU\n    submitted by    /u/ariseff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u81xcu/d_diffusion_models_video_tutorial/",
          "publishedOn": "2022-04-20T17:36:29.000Z",
          "wordCount": 133,
          "title": "[D] Diffusion models video tutorial",
          "imageUrl": "https://external-preview.redd.it/mxUM6T4HtbKZ5GSYz1fROuCkz61-3157IJ3MfBCvG04.jpg?auto=webp&s=6465d7ee8a83d360f28b3c107f86213c6a953f1e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u81jfe/d_building_the_model_behind_doordashs_expansive/",
          "author": null,
          "description": "Interested in how DoorDash maintains a well performing and diverse selection in the numerous markets they operate in despite entering the delivery market relatively late ? I had the opportunity to collaborate in this project which involved building a number of models that measured customer preferences, identified market cuisine categories, and predicted merchants' performance on the platform. I wanted to share the approach and some of the technical details with the ML community to get feedback on what we can improve and to show this cool use case to others working on similar sales enablement based models. Check out the blog post I wrote and let me know what you think of our approach. \n Building the Model Behind DoorDash’s Expansive Merchant Selection\n    submitted by    /u/EfficientString7431  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u81jfe/d_building_the_model_behind_doordashs_expansive/",
          "publishedOn": "2022-04-20T17:18:32.000Z",
          "wordCount": 222,
          "title": "[D] Building the Model Behind DoorDash’s Expansive Merchant Selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u80klz/d_whats_hot_in_deep_learning_research_at_the/",
          "author": null,
          "description": "I took a break from deep learning( starting from last October) , now i want to get back, start with a new project and read papers . Where should i focus ? Should i keep working on vision transformers or maybe start something on geometric deep learning . What's hot and what's going on ?\n    submitted by    /u/ovotheking  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u80klz/d_whats_hot_in_deep_learning_research_at_the/",
          "publishedOn": "2022-04-20T16:35:25.000Z",
          "wordCount": 333,
          "title": "[D] What's hot in deep learning research at the moment ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7zk6b/p_a_simple_pytorch_yolov1_training_pipeline/",
          "author": null,
          "description": "https://github.com/sovit-123/yolov1_pytorch_voc07\n ​\n Also, I write about Deep Learning and Machine Learning on https://debuggercafe.com/\n Please check it out and let me know if somebody wants any blog posts on a specific topic.\n    submitted by    /u/sovit-123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7zk6b/p_a_simple_pytorch_yolov1_training_pipeline/",
          "publishedOn": "2022-04-20T15:49:55.000Z",
          "wordCount": 129,
          "title": "[P] A simple PyTorch YOLOv1 training pipeline GitHub Repo",
          "imageUrl": "https://external-preview.redd.it/_tmBGnq2RgJMCfrjhyHRWMVZ-yQ4zKGtsrSygsf0RX0.jpg?auto=webp&s=c66f31cb030075cd628cffacdd4b9d9bc1e70811"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7zg4j/p_programmatic_powerful_weak_labeling/",
          "author": null,
          "description": "Hi all!,\n Really excited to share a project we've been working on and get your feedback!\n We've made:\n Programmatic — an NLP annotation tool for building large labeled datasets for NLP without manual annotation\n Programmatic is like a REPL for data annotation. You:\n 1. Write simple rules/functions that can approximately label the data 2. Get near-instant feedback across your entire corpus 3. Iterate and improve your rules \n Finally, it uses a Bayesian label model [1] to convert these noisy annotations into a single, large, clean dataset, which you can then use for training machine learning models. You can programmatically label millions of datapoints in the time taken to hand-label hundreds.\n What we do differently from weak supervision packages like Snorkel/skweak[1] is to focus on UI to …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7zg4j/p_programmatic_powerful_weak_labeling/",
          "publishedOn": "2022-04-20T15:44:39.000Z",
          "wordCount": 491,
          "title": "[P] Programmatic: Powerful Weak Labeling",
          "imageUrl": "https://external-preview.redd.it/GFDoi96pReIx0d8Fiy4PC2UbdyHgPny9UVn-tUk7wis.jpg?auto=webp&s=163ac63d5a3613bd9f1aa490b94745f5cc5b1e0e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7wwzb/d_whats_your_opinion_on_project_promoting_posts/",
          "author": null,
          "description": "There are many projects promoting in this sub, you may like or dislike. And if any of my posts you dislike, allow me to apologize first.\n However, it gets me to think. Several years ago I'm a moderator in a quite large forum, because I don't have enough time to fulfill my responsibilities, then I decided to retire (yes, they can, and I remained as the vip user which only retired moderators can be).\n This is a large community, a machine learning community. Besides continuously removing some of these posts, and no clear rules on it, can we do any better? We got all the data, and we just cannot train the model?\n Here are my three proposal, and please give some excellent ideas besides my poor ones:\n  \nSelf promoting post should have values other than itself, and not having annoying contents\n Self promoting project can be used as a tool in a non self promoting posts, as long as the posts creates valuable contents and the promoting is not obvious and annoying.\n Depends on the number of new project posts, Weekly/Daily project post can be created by moderator and pinned to the top. All the promoting content goes into the comment. We can explore and upvotes.\n  \nHere are some illustrations:\n 1. Direct Promoting Post\n ​\n 2. Indirect Promoting Post\n ​\n Weekly/Daily Promoting Post by Moderator, Pinned to Top, Comments by project owner, upvotes/downvotes by us\n Which do you think is acceptable? Or you have better ideas? Leave a comment.\n It's a machine learning sub, don't make machine to solve it better than us.\n View Poll\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7wwzb/d_whats_your_opinion_on_project_promoting_posts/",
          "publishedOn": "2022-04-20T13:47:15.000Z",
          "wordCount": 950,
          "title": "[D] What's your opinion on project promoting posts in this sub? Your vote matters.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7v4iu/r_differentiable_signal_processing_for_optical/",
          "author": null,
          "description": "Hey folks, I wrote a mini project based on JAX for optical communications signal processing.\n https://github.com/remifan/commplax\n I have a research article as a use case demo, https://remifan.github.io/gdbp_study/article.html\n This tool essentially\n  \nimplements adaptive DSP equalizers as stateful NN layers (thanks to Jax's explicit stateful syntax)\n implements compositor interfaces from scratch to wrap up those stateful layers with other regular NN layers so that they can be trained together\n  \nHomebrew serial compositions of stateful layers\n It is a fun project for me and I feel JAX really elegantly fits this research use.\n What do you think about JAX? I appreciate your comments:)\n    submitted by    /u/StreetPrice1909  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7v4iu/r_differentiable_signal_processing_for_optical/",
          "publishedOn": "2022-04-20T12:15:05.000Z",
          "wordCount": 233,
          "title": "[R] Differentiable signal processing for optical communication with Google JAX",
          "imageUrl": "https://external-preview.redd.it/9ZhPHXfgJjjlJ72bMygmapK0gLw3qM9dI3oQKZlJiQk.jpg?auto=webp&s=3ca68f429cce7dee640074e9426a171a068e8fbd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7tg1w/d_tracking_the_hardware_usage_while_running_cv_nn/",
          "author": null,
          "description": "Hi guys,\n I've been working on a machine learning project and I wanted to see how hardware resources are being used when I run inference on let's say 1000 images.\n How could i calculate the CPU(running inference on CPU)/RAM workload in that timeframe?\n I'm running it on a Linux Ubuntu VM. Thanks in advance!\n    submitted by    /u/Fifi0912  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7tg1w/d_tracking_the_hardware_usage_while_running_cv_nn/",
          "publishedOn": "2022-04-20T10:33:29.000Z",
          "wordCount": 283,
          "title": "[D] Tracking the hardware usage while running CV NN Model on a 1000 Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7t77t/d_running_interactive_python_notebooks_on/",
          "author": null,
          "description": "I'm working on a framework Mercury for converting Python notebooks into interactive web apps. It can add widgets to the notebook based on the YAML configuration. End-user can tweak widgets values and execute the notebook. The resulting notebook can be downloaded as single-file HTML. Simple.\n The framework is built on Django+React. It is easy to deploy to Heroku or other cloud services. Recently, I made it possible to deploy it to Hugging Face Spaces (faster and larger machines than on free tier Heroku). \n The process of deployment is simple. You need to create a Gradio app on Spaces (my framework is not supported, yet ;) ). You need to add the app.py file that will run the Mercury server and upload the notebook. You can check the details in the docs.\n The HF Space with example notebook https://huggingface.co/spaces/pplonski/deploy-mercury\n    submitted by    /u/pp314159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7t77t/d_running_interactive_python_notebooks_on/",
          "publishedOn": "2022-04-20T10:16:31.000Z",
          "wordCount": 311,
          "title": "[D] Running interactive Python notebooks on HuggingFace Spaces",
          "imageUrl": "https://external-preview.redd.it/M97KEWVCpGCqVfMbFnyOXZVJO2e0a-jjDS-S5qdz-nw.jpg?auto=webp&s=d7872007d9a4fd0ddc5f39200478e36ad824b5ad"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7rmnx/d_conditional_gan_with_multiple_adversarial/",
          "author": null,
          "description": "I would like to test the architecture from the following paper with a different dataset:\n https://www.mdpi.com/2072-4292/13/19/3834\n The authors state that their objective function is the following:\n https://preview.redd.it/u78f27jb6nu81.png?width=1027&format=png&auto=webp&s=32790a67ec829a1e79b252edd0714b8b3b5a7f4e\n Where:\n -x is the real grayscale image.\n -s is its downsampled version, which should be used both as the initial imput of the generator performing the super-resolution and as a first conditional variable in the learning process.\n -e is another two-dimensional array containing values for a second additional conditional variable.\n The authors, however, state that this should be implemented by using two separate conditional adversarial losses, one for each of the conditional variables. To clarify, the first adversarial loss should be:\n AdvLoss1(ParametersG, ParametersD) = - Log(Discriminator(x,s) - Log(1-Discriminator(Generator(s),s)\n While the second would be:\n AdvLoss2(ParametersG, ParametersD) = - Log(Discriminator(x,e) - Log(1-Discriminator(Generator(s),e)\n Which should be then summed up for the backward pass.\n In my pytorch implementation, however, I have only been able to set up a unique adversarial loss, which could be defined as:\n CurrentAdvLoss(ParametersG, ParametersD) = - Log(Discriminator(x,(s,e)) - Log(1-Discriminator(Generator(s),(s,e)) I have tried to implement implemented as follows:(simplified version)\n which I calculate in the following training loop (simplified version, from the same question asked in the Pytorch forum) as errD and errG after conditioning the network on both s and e at the same time:\n https://discuss.pytorch.org/t/conditional-gan-with-multiple-adversarial-losses/149627\n My question is, is there a way to modify the following loop to obtain outputs that have been separately conditioned only first on s and then on e and thus calculate the two separate adversarial losses originally proposed by the authors instead?\n    submitted by    /u/Franken91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7rmnx/d_conditional_gan_with_multiple_adversarial/",
          "publishedOn": "2022-04-20T08:20:03.000Z",
          "wordCount": 612,
          "title": "[D] Conditional GAN with multiple adversarial losses - Implementation?",
          "imageUrl": "https://external-preview.redd.it/MqJe59opigVaZuH5510R_Lq1xz5Xd-koErAoYaWVdKo.jpg?auto=webp&s=a49162b5148b40b289698f2f643412d4aa14c19c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7qdum/d_ijcai_2022_paper_notification/",
          "author": null,
          "description": "This is the discussion for accepted/rejected papers in IJCAI 2022. Results are supposed to release today.\n    submitted by    /u/errohan400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7qdum/d_ijcai_2022_paper_notification/",
          "publishedOn": "2022-04-20T06:50:03.000Z",
          "wordCount": 431,
          "title": "[D] IJCAI 2022 Paper Notification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ouxh/r_authors_claim_to_have_solved_mnist_and_cifar/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2204.07953v1\n Code: https://github.com/decurtoydiaz/learning_with_signatures\n Tangential resources of interest: https://arxiv.org/abs/1905.08494, https://en.wikipedia.org/wiki/Rough_path#Signature, and https://labelerrors.com/ \n Personally, I believe from their code on Github, they have a possible data leakage (in the same vein of the current issue raised there) as well as an accuracy of 100% on a test set is fishier than a fish market. However, I am very curious to hear from the court of public opinion. How is everyone feeling about this?\n    submitted by    /u/blingblingbeepbeep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ouxh/r_authors_claim_to_have_solved_mnist_and_cifar/",
          "publishedOn": "2022-04-20T05:05:50.000Z",
          "wordCount": 1128,
          "title": "[R] Authors Claim to Have \"Solved\" MNIST and CIFAR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7on82/d_how_do_i_evaluate_if_my_data_represent_the/",
          "author": null,
          "description": "I have a dataset of points cloud where each point in the point cloud has a variable. I am trying to relate the local geometry features to that point variable by using FPFH, This means I am generating my own features from the dataset by first using an area of n-points to compute normal-vector estimations and from x normal vector estimations to compute the FPFH. However, the numbers x and n are arbitrary and other combinations might describe the target variable better. So I wanted to know if there was a method to evaluate how good a given x and n value are at describing the target variable. I considered the correlation between the features (n,x) and the target variable but I read that this assumes linear combination redundancy. I am using scikit-learn. \n So basically I have features X(x,n) and a target variable Y. Which x and n, in the feature space X(x,n), describes the target variable, Y, best.\n I want to do it before the training because when I try to train it with my random forest regressor it takes 3-4 hours and I want to test for more combinations. \n    submitted by    /u/Neo-Rushdian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7on82/d_how_do_i_evaluate_if_my_data_represent_the/",
          "publishedOn": "2022-04-20T04:52:37.000Z",
          "wordCount": 324,
          "title": "[D] How do I evaluate if my data represent the target variable before training a machine learning algorithm?",
          "imageUrl": "https://external-preview.redd.it/o-Yq16CmbZYLfCx_y5VsD5fcOiaoLcN-zQO1j3qX2es.jpg?auto=webp&s=546795834d06ed5ac69b13898f1acf1fe4d9f163"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7muzp/discussion_training_performance_evaluation_of/",
          "author": null,
          "description": "The article is reproduced from Zhihu, using deepl machine translation, for all enthusiasts to communicate\n Abstract\n Deep learning frameworks are the engines and motors for pushing the boundaries of artificial intelligence applications, and good deep learning frameworks can dramatically shorten the cycle of algorithm innovation and validation. In this report, we focus on the newly launched MindSpore framework, which has received a lot of industry attention, and systematically explore its model training speed on GPU clusters and compare it with popular international frameworks. In the evaluation experiments, we choose two classical models, ResNet and BERT-base, to test and analyze their performance with the same algorithm, the same dataset, and the same or similar performance hardware platf…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7muzp/discussion_training_performance_evaluation_of/",
          "publishedOn": "2022-04-20T03:10:29.000Z",
          "wordCount": 2118,
          "title": "[Discussion] Training performance evaluation of MindSpore, a home-grown deep learning framework -- by ADSL Lab, CSU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7lv35/d_why_is_the_diffution_model_so_powerful_but_the/",
          "author": null,
          "description": "You can see the 200 lines code here: https://nn.labml.ai/diffusion/ddpm/index.html and https://github.com/cloneofsimo/minDiffusion, math is here: https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\n The algo is smart and simple, but it's generation result seems more incredible than GANs, and its speed is fast, the model size is not too big: https://openai.com/dall-e-2/ , https://huggingface.co/spaces/multimodalart/latentdiffusion, https://www.reddit.com/r/dalle2\n So 1st question:\n why is diffusion model so powerful? Can someone explain it?\n 2st question:\n Has anyone used diffusion for NLP?\n ​\n UPDATED:\n ​\n \\\"A multiverse portal to a new world opening up above Tokyo\\\" by dalle2 (from r/dalle2)\n \\\"A robot painting on a canvas while playing the piano\\\" by dalle2 (from r/dalle2)\n ​\n \\\"Mona Lisa in her studio painting Leonardo da Vinci \\\" by dalle2 (from r/dalle2)\n \\\"Science fiction illustration future city in the night | impressionism\\\" by latentdiffusion\n ​\n \\\"Science fiction illustration of Beauty and monsters | impressionism\\\" by latentdiffusion\n ​\n \\\"a painting of a girl with a fox sitting in a field at sunrise in the style of Claude Monet\\\" by latentdiffusion\n    submitted by    /u/ghosthamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7lv35/d_why_is_the_diffution_model_so_powerful_but_the/",
          "publishedOn": "2022-04-20T02:17:28.000Z",
          "wordCount": 1175,
          "title": "[D] Why is the diffution model so powerful? but the math behind it is so simple.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7k4ep/d_questions_about_intel_12th_gen_alder_lake_cpus/",
          "author": null,
          "description": "I am looking to build a new PC but have struggled to find the info on how Intel's latest CPUs perform for data science/ML, so if anyone is using one for that purpose and can help with one or more of these questions it would be very helpful! Apologies if these questions should be directed elsewhere.\n  \nI am planning to use WSL2/Ubuntu but have heard that Intel's thread director isn't implemented well yet in Linux (or Windows 10!), so it doesn't assign tasks properly. Has anyone experienced issues with this firsthand?\n Assuming the thread director is working, are the e-cores utilised at all in any typical DS workflows? E.g. will they get used with joblib or when training scikit-learn/gbms in parallel? \n Are the e-cores good enough to handle other stuff like web browsing etc whilst the p-cores are maxed out on model training, or is it still necessary to keep at least one p-core free to avoid crashing the PC? Also I have read that in Windows 11 (where the thread director works best) that the active window/tab could be assigned p-cores as a priority, which isn't very helpful for someone who needs to train models in the background etc, but not sure whether this is actually happening in practice.\n  \nThe consensus from benchmarks/reviews is that the hybrid architecture 'just works' and is superior to AMD right now, but those benchmarks are primarily for use in gaming/video editing.\n    submitted by    /u/FightingLikeBeavers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7k4ep/d_questions_about_intel_12th_gen_alder_lake_cpus/",
          "publishedOn": "2022-04-20T00:47:14.000Z",
          "wordCount": 389,
          "title": "[D] Questions about Intel 12th gen Alder Lake CPUs",
          "imageUrl": "https://external-preview.redd.it/7TWFtlKU72UhlGB3uy0ukjZZSfE8tbJ5RJ9qCdnnPeo.jpg?auto=webp&s=4e7e0b5b65ce1b4a6004ce768385543567aa0845"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7jniv/n_the_new_machine_learning_specialization_by/",
          "author": null,
          "description": "We’re thrilled to announce a brand new Machine Learning Specialization, in collaboration with DeepLearning.AI, launching in June on Coursera! Learn essential real-world skills from AI pioneer Andrew Ng, who co-founded Google Brain and Coursera, led AI research at Baidu, and has impacted millions of AI learners.\n This updated 3-course Specialization will cover the latest machine learning techniques as well as foundational AI concepts that made its predecessor one of the world’s most popular machine learning courses. Join the waitlist!\n https://preview.redd.it/yujr31t6vku81.png?width=5000&format=png&auto=webp&s=0f4c4ef090bcdc7cfb04ee2c817d766f23c236a6\n    submitted by    /u/Stanford_Online  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7jniv/n_the_new_machine_learning_specialization_by/",
          "publishedOn": "2022-04-20T00:22:42.000Z",
          "wordCount": 203,
          "title": "[N] The new Machine Learning Specialization by DeepLearning.AI and Stanford Online is launching soon! Join the Waitlist.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ii1j/d_resources_for_images_anomaly_detection/",
          "author": null,
          "description": "Hello all, I know that there is a lot going on this field. I would like to get started on it, study more.. And as always, I like to start from the basis.\n Do you have any resource (video, article, book) good to star with?\n I know there are Autoencoders and Statistical models.. But how to know more, where/how do you keep studying?\n    submitted by    /u/bollolo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ii1j/d_resources_for_images_anomaly_detection/",
          "publishedOn": "2022-04-19T23:24:37.000Z",
          "wordCount": 153,
          "title": "[D] Resources for Images Anomaly Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ermp/r_where_can_i_find_case_studies_on_different_ml/",
          "author": null,
          "description": "I am working on my research paper and would like to find resources which show the case studies of ML projects from the beginning to the end, doesn't matter if it failed or succeeded.\n    submitted by    /u/mkonu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ermp/r_where_can_i_find_case_studies_on_different_ml/",
          "publishedOn": "2022-04-19T20:32:16.000Z",
          "wordCount": 141,
          "title": "[R] Where can I find case studies on different ML projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7ck1u/d_create_labels_for_data_created_by_a_gan/",
          "author": null,
          "description": "Hello there!\n I hope you have a great day! Currently I want to compare how good multiple GANs (Vanilla GAN, WGAN, DCGAN, ...) are for a given use case. Therefore I trained the various GAN versions with data of two different classes (i.e. apple and banana). Now I want to show that data I generate with the Generator can be used to train i.e. a classifier that can distinguish between real images of apples and bananas.\n Can I somehow create labels for the data I generate with the Generator in a smart way? So that I know that a generated image of the generator should for example be an apple? How do i do that?\n    submitted by    /u/Bonkikong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7ck1u/d_create_labels_for_data_created_by_a_gan/",
          "publishedOn": "2022-04-19T18:54:48.000Z",
          "wordCount": 324,
          "title": "[D] Create Labels for Data created by a GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7b07r/p_luminide_new_optimization_early_ranking/",
          "author": null,
          "description": "Luminide introduces a new optimization, called Early Ranking, which makes it easier to build better AI models. Early Ranking achieves the same AI training results with up to 10x less compute – this saves time, reduces costs, and increases model accuracy.\n Luminide's IDE is a customized version of JupyterLab with integrated AI dev tools.\n Luminide used Early Ranking to place Top 1% in the CVPR Plant Pathology Kaggle competition. You can read about how we developed our winning model, and you can too, in our new blog post: Better Automation for Higher Accuracy AI Models.\n Class activation maps give insights into Luminide's winning model.\n Luminide is a new cloud platform for AI model development. Check out our demo video for a quick overview, or try it for yourself (sign up today and receive 100 hours of free GPU cloud compute).\n    submitted by    /u/LuminideInc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7b07r/p_luminide_new_optimization_early_ranking/",
          "publishedOn": "2022-04-19T17:48:05.000Z",
          "wordCount": 288,
          "title": "[P] Luminide: new optimization Early Ranking achieves higher accuracy AI models",
          "imageUrl": "https://external-preview.redd.it/YuZTfJQzgDz7AbSLKW4I5GnJY69ABvMjOQh-jD-4UDs.jpg?auto=webp&s=002ed7925b145ca7168d2ff69c0a01426eb05da0"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7a5s7/d_generic_discussion_on_freelance_ml_engineers/",
          "author": null,
          "description": "Hi, reddit. Recently, I'm looking into freelancer career path. Currently, I'm a researcher at a top company. So far, I know there is toptal, upwork, and freelancers. Checked them out, and seems toptal you still end up working for large corporate and mostly end up as full-time contractor which is not really a different or better option than my current work. Freelancers has too many bidders from developing countries. \n Besides what platform to use, i have more questions in terms of what obstacles we are facing to be freelancer ML engineer? Even though i am in AI and a researcher, but i have never deployed a model in production. Usually a task at big company takes a team or multiple teams to complete the MLOPs lifecycle, how can you do it as a single person? Any sharing of experience would be of great help.\n    submitted by    /u/meame2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7a5s7/d_generic_discussion_on_freelance_ml_engineers/",
          "publishedOn": "2022-04-19T17:11:22.000Z",
          "wordCount": 453,
          "title": "[D] generic discussion on freelance ML engineers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u79u20/r_looking_for_aiml_experts_from_southeast_asia_to/",
          "author": null,
          "description": "Hello everyone,\n I am a student from Germany writing my master thesis on Digital Transformation in ASEAN with AI/ML.\n For my thesis I would like to interview AI/ML experts from the ASEAN region to talk about the digital development of each country, challenges and potentials. (If you are not native there, but you have a work connection or just knowledge about the region and its AI development, I appreciate that as well.)\n It would be awesome if some of you were open to talk to me. A few sentences are enough, I won't take much of your time. If you want, we can do a video call as well. I will quote you of course.\n Thank you guys.\n    submitted by    /u/BlueLagoon357  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u79u20/r_looking_for_aiml_experts_from_southeast_asia_to/",
          "publishedOn": "2022-04-19T16:57:26.000Z",
          "wordCount": 227,
          "title": "[R] Looking for AI/ML experts from Southeast Asia to interview for master thesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u79ngl/dealing_with_numerically_0_likelihood_in/",
          "author": null,
          "description": "I'm trying to find literature on solving the following issue:\n In most probabilistic ML models, we model the joint distribution over a set of random variables, p(x1, ..., xN). If N is very large (e.g. 100, 500, or even 1000), then regardless of how you model this, the distribution's highest point of density is still quite tiny. E.g. if you consider an isotropic multivariate gaussian of 100 dimensions, the highest point of density will be somewhere in the neighbourhood of 1.6e-40. So when it comes time to evaluate log likelihood for a model like this, the probability is numerically 0, so the log probability goes to negative infinity.\n ​\n Is there work around solving these kinds of issues? I.e. by constraining the model in some way, or scaling model output, etc? I've done some googling, but am having a hard time finding papers on the subject. Not even sure what to call the problem... Curse of dimensionality in PGMs?\n ​\n Any recommendations of papers / talks / etc is greatly appreciated!\n    submitted by    /u/CS_Student95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u79ngl/dealing_with_numerically_0_likelihood_in/",
          "publishedOn": "2022-04-19T16:49:08.000Z",
          "wordCount": 348,
          "title": "Dealing with numerically 0 likelihood in probabilistic models [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u79fnw/rp_gancontrol_explicitly_controllable_gans_gradio/",
          "author": null,
          "description": "​\n https://i.redd.it/v61jw1fekiu81.gif\n Abstract:\n We present a framework for training GANs with explicit control over generated facial images. We are able to control the generated image by settings exact attributes such as age, pose, expression, etc. Most approaches for manipulating GAN-generated images achieve partial control by leveraging the latent space disentanglement properties, obtained implicitly after standard GAN training. Such methods are able to change the relative intensity of certain attributes, but not explicitly set their values. Recently proposed methods, designed for explicit control over human faces, harness morphable 3D face models (3DMM) to allow fine-grained control capabilities in GANs. Unlike these methods, our control is not constrained to 3DMM parameters and is extendable beyond the domain of human faces. Using contrastive learning, we obtain GANs with an explicitly disentangled latent space. This disentanglement is utilized to train control-encoders mapping human-interpretable inputs to suitable latent vectors, thus allowing explicit control. In the domain of human faces we demonstrate control over identity, age, pose, expression, hair color and illumination. We also demonstrate control capabilities of our framework in the domains of painted portraits and dog image generation. We demonstrate that our approach achieves state-of-the-art performance both qualitatively and quantitatively.\n    submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u79fnw/rp_gancontrol_explicitly_controllable_gans_gradio/",
          "publishedOn": "2022-04-19T16:39:32.000Z",
          "wordCount": 294,
          "title": "[R][P] GAN-Control: Explicitly Controllable GANs + Gradio Web Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u78vr1/d_who_funds_the_leading_conferences_in_the_field/",
          "author": null,
          "description": "I know that the publishers of the leading journals are mostly for-profit organization, that is weird because as researchers in the field we really “volunteer” for a free peer review or even pay to publish papers and read papers.\n On the other hand, i wasnt able to find information about the funding and profit goals of the leading conferences. Take NeuroIPS for example, i found that it is organized by “NeurIPS Foundation” but what exactly is this foundation - i couldn’t find any information about this subject.\n My point is, if the conferences are non-profit, sounds like they should be preferred over funding a for-profit organizations.\n    submitted by    /u/Careful_Winner_2335  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u78vr1/d_who_funds_the_leading_conferences_in_the_field/",
          "publishedOn": "2022-04-19T16:15:02.000Z",
          "wordCount": 404,
          "title": "[D] Who funds the leading conferences in the field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u7633f/d_nlp_has_huggingface_what_does_computer_vision/",
          "author": null,
          "description": "I've been writing tutorials with Pinferencia and HuggingFace.\n HuggingFace is quite handy and easy to use.\n I want to write some tutorial about computer vision afterwards.\n Is there anything similar in Computer vision area?\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u7633f/d_nlp_has_huggingface_what_does_computer_vision/",
          "publishedOn": "2022-04-19T14:10:50.000Z",
          "wordCount": 691,
          "title": "[D] NLP has HuggingFace, what does Computer Vision have?",
          "imageUrl": "https://external-preview.redd.it/kblQmsIxuQ7Z09y5LfR7cpqcqnaiQ45WZxhomGZFfu8.jpg?auto=webp&s=57dc6bc9e7a5f25991af7ad692b7aede29bede48"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u74rcr/d_why_no_paper_in_speech_emotion_recognition/",
          "author": null,
          "description": "I took a look at multiple of them and I was curious why they seemed to benchmark on multiple datasets but for the training, they restrained themselves to only 1 for training instead of merging them. From that they get good scores on the one they trained on, but bad ones for the rest.\n    submitted by    /u/raysamram  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u74rcr/d_why_no_paper_in_speech_emotion_recognition/",
          "publishedOn": "2022-04-19T13:08:01.000Z",
          "wordCount": 197,
          "title": "[D] Why no paper in Speech Emotion Recognition train on multiple datasets ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u74pyy/p_sparseserverui_a_ui_to_test_performance_of/",
          "author": null,
          "description": "You can now load multiple transformers (each model has a unique sparsification recipe) on top of the DeepSparse server behind Streamlit, and it's open-source. This was battle tested on a 16GB of RAM with only 4 core CPU virtual machine. These compute requirements are enough to load up to 19 sparse BERT models in memory and compare their performance on question answering (P.S. they are really fast on just CPUs).\n 💻code: https://github.com/neuralmagic/deepsparse/tree/main/examples/sparseserver-ui\n    submitted by    /u/Quantum_Stat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u74pyy/p_sparseserverui_a_ui_to_test_performance_of/",
          "publishedOn": "2022-04-19T13:06:00.000Z",
          "wordCount": 251,
          "title": "[P] SparseServer.UI : A UI to test performance of Sparse Transformers",
          "imageUrl": "https://external-preview.redd.it/qBy_JaPINWtgHEC1itxNsGwlzl6psCRW2NA8VNORhKE.jpg?auto=webp&s=9400b52c8e30d85bbc6050016a8942948c2d3077"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u742l5/research_learning_with_signatures/",
          "author": null,
          "description": "This paper reports \"results on AFHQ dataset, Four Shapes, MNIST and CIFAR10 achieving 100% accuracy on all tasks.\" The authors used few-shot classification \"by comparing each test sample (after optional augmentation and computation of the element-wise mean) against a representative element-wise mean signature computed by averaging the signatures of a given number of train samples.\" What are your thoughts on this?\n Learning with Signatures - https://arxiv.org/abs/2204.07953\n    submitted by    /u/Marmadelov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u742l5/research_learning_with_signatures/",
          "publishedOn": "2022-04-19T12:32:52.000Z",
          "wordCount": 157,
          "title": "[Research] Learning with Signatures",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u70e8x/project_research_simple_speech_recognition_system/",
          "author": null,
          "description": "Github - Bangla Spoken Number Recognition\n Dataset - Our custom dataset on Bangla Numerals\n Publications - Though its on (0-9) digits\n We have created a simple speech recognition system for recognizing Bangla numerals from '০-৯৯'(0-99). In this project, audio samples from different genders, age groups, and dialects of Bangladeshi people were used to create a speech dataset of spoken numbers from '০-৯৯'(0-99). The raw speech data is subjected to various audio augmentation techniques such as time shift, speed tuning, background noise mixing, and volume tuning. Then, to extract meaningful features from the data, Mel Frequency Cepstrum Coefficients (MFCCs) are used. We have used, Convolutional Neural Networks (CNNs), to develop a Bangla number recognition system. The proposed method recognizes '০-৯৯'(0-99) Bangla spoken numbers with 89.61% accuracy across the entire dataset. The model’s effectiveness was also tested using 10-fold cross-validation, with 89.74% accuracy for recognizing '০-৯৯'(0-99) Bangla spoken numbers across the entire dataset.\n I Hope, this work will help you in some way. :)\n    submitted by    /u/PIASR0Y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u70e8x/project_research_simple_speech_recognition_system/",
          "publishedOn": "2022-04-19T08:41:54.000Z",
          "wordCount": 294,
          "title": "[Project] [Research] Simple Speech Recognition System",
          "imageUrl": "https://external-preview.redd.it/D2Tcvz3YyL2f4FekN2FGxrOWw72iTPlHKt7b5p6HyY8.jpg?auto=webp&s=a2e90c4f535af066a0dfaa93aaef7cc76d1a03b4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6zo72/p_improving_mulitclass_classification_accuracy/",
          "author": null,
          "description": "This is a light implementation of the idea in the paper Leveraging Uncertainties in Softmax Decision-Making Models for Low-Power IoT Devices. Instead of finding uncertainties I have added Jain's Fairness Index as a addition to the loss function.\n Gist: https://gist.github.com/Gananath/8d167384da7d3bc078650c73fab1a8dd\n    submitted by    /u/gananath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6zo72/p_improving_mulitclass_classification_accuracy/",
          "publishedOn": "2022-04-19T07:49:51.000Z",
          "wordCount": 140,
          "title": "[P] Improving mulitclass classification accuracy with Jain's Fairness Index",
          "imageUrl": "https://external-preview.redd.it/B7V_1aSLjsc68OF9ZHt3PPLgcCkDV9ZXbE0SQTFou3E.jpg?auto=webp&s=f9545e492f810762324603fdcdbb88db865c92d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6zk4g/d_are_workshop_papers_considered_final/",
          "author": null,
          "description": "Specifically, I'm talking about workshops of major conferences (NeurIPS, ICLR, ICML, etc.).\n If I submit a paper and it gets accepted, is that workshop paper a \"final publication\"? Or would most people expect the project to continue being developed into a slightly larger/longer paper for submission to the main stream of a conference? And if so, does publishing the earlier workshop paper tend to hinder or harm the later conference submission?\n I recognise there's a variety of workshops, and perhaps each have different expectations or norms. I'm wondering, from my outsider's perspective, how can I tell?\n For example, I have been thinking about submitting to one of these ICML workshops: https://icml-compbio.github.io/ or https://www.tagds.com/workshops/tag-in-machine-learning. Is there an easy way to tell whether either or both of these are \"final publication\" venues or not?\n    submitted by    /u/tfburns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6zk4g/d_are_workshop_papers_considered_final/",
          "publishedOn": "2022-04-19T07:41:19.000Z",
          "wordCount": 484,
          "title": "[D] Are workshop papers considered \"final publications\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6uw0i/r_maximum_likelihood_estimation_can_fail_due_to/",
          "author": null,
          "description": "arXiv: https://arxiv.org/abs/2204.07172\n This paper out today seems to make the bold claim that maximum likelihood estimation is not a well-posed training objective in deep generative modelling. The manifold hypothesis says that observed high-dimensional data clusters around low-dimensional manifolds, but maximum likelihood methods (e.g. VAE, normalizing flows) learn high-dimensional densities. The paper argues that the mismatch between dimensionalities will lead to a problem called \"manifold overfitting\".\n Models are able to maximize likelihood in high-dimensions by sending the density to infinity around the low-dimensional manifold, but they can do this while completely ignoring the distribution of data on the manifold. So in other words, high capacity models will learn the data manifold…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6uw0i/r_maximum_likelihood_estimation_can_fail_due_to/",
          "publishedOn": "2022-04-19T02:56:29.000Z",
          "wordCount": 1350,
          "title": "[R] Maximum likelihood estimation can fail due to \"Manifold Overfitting\"",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6n0b0/d_word_meaning_dictionary_dataset/",
          "author": null,
          "description": "Hey all!\n So I intend to make an application that, very naively speaking, outputs synonyms of a given word regardless of context (like if word1 is \"bank\", the model should output both \"money\" and \"river\", and the order does not matter). For this, I intend to use a Doc2Vec type of classifier, where the meanings of each word can serve as a document, and then similar words can easily be returned using a cosine similarity function. I chose this over a classic Word2Vec as this will be able to predict uncommon words (which blimey the English language has a lot of) which would otherwise be processed as <UNK> tokens. To this end, I am searching for a suitable dataset. Any ideas?\n    submitted by    /u/GrammarPaparazzi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6n0b0/d_word_meaning_dictionary_dataset/",
          "publishedOn": "2022-04-18T20:42:12.000Z",
          "wordCount": 245,
          "title": "[D] Word Meaning Dictionary Dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6lx9e/d_is_there_a_way_to_use_a_series_of_videos_as_the/",
          "author": null,
          "description": "This is the problem area I am working with: \n I have a series of videos taken at different times, and each video is paired with a physical variable. The videos contain information that correlates with the physical variable. \n What we want to do is use the information encoded within each video to build a correlation model with the physical quantity, and thereafter use new videos to predict the physical quantity. \n (We want to avoid the route of video -> CNN -> extract parameters -> build model with parameters. Instead, we want to directly go from the videos to the model without separately extracting parameters.)\n So, in a way, I want to use a series of videos as a time series data set. Is there a way to do this? What should be the starting point for my research into this?\n Thanks in advance! I am not an expert with this area at all, and would greatly appreciate guidance from the community.\n    submitted by    /u/besse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6lx9e/d_is_there_a_way_to_use_a_series_of_videos_as_the/",
          "publishedOn": "2022-04-18T19:55:27.000Z",
          "wordCount": 426,
          "title": "[D] Is there a way to use a series of videos as the predictor variable for prediction/regression?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6kroi/p_blog_post_opensource_pytorch_implementation_of/",
          "author": null,
          "description": "Hi all! My team recently reproduced and published a PyTorch implementation of the paper SIMONe: View-Invariant, Temporally-Abstracted Object Representations via Unsupervised Video Decomposition. \n Our blog post walks through the code and provides a detailed explanation of the architecture they use in order to perform object segmentation on videos in a fully self-supervised manner.\n Hope this is helpful/interesting to others!\n    submitted by    /u/ai_ellie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6kroi/p_blog_post_opensource_pytorch_implementation_of/",
          "publishedOn": "2022-04-18T19:04:20.000Z",
          "wordCount": 170,
          "title": "[P] Blog post + open-source PyTorch implementation of DeepMind's SIMONe (unsupervised scene decomposition)",
          "imageUrl": "https://external-preview.redd.it/z55b_0-_DYGZxjSO4sTVwBNIkMqkFCKvhcexHvELgV4.jpg?auto=webp&s=6b590839e21b0f0e5d45a926d1c383c41316f7fd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6i2u6/d_autorf_vs_sinnerf/",
          "author": null,
          "description": "Both approaches seem to be able to render complex scenes from a single view, without the need for explicit priors or pretrained feature extractors. Conveniently, AutoRF doesn't mention SinNeRF. What are the similarities and differences among the two approaches? DISCLAIMER - I'm not a NeRF expert. My limited understanding of it is that we train a small MLP to regress the radiance field for a scene, i.e., to predict emitted radiance at a point (x,y,z) in the viewing direction (θ, φ). Once we have the radiance field, we can use some rendering engine to render a 2D view from the 3D field and the camera parameters.\n EDIT: I just realized that I didn't link the papers, how silly of me. Here they are:\n SinNeRF: https://arxiv.org/abs/2204.00928\n AutoRF: https://arxiv.org/abs/2204.03593\n ​\n ​\n    submitted by    /u/Best-Neat-9439  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6i2u6/d_autorf_vs_sinnerf/",
          "publishedOn": "2022-04-18T17:07:21.000Z",
          "wordCount": 416,
          "title": "[D] AutoRF vs SinNeRF",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6htt9/p_evaluating_automatic_paraphrasing_via_bleu/",
          "author": null,
          "description": "Hey everyone!\n Our NLP team, led by our expert Daria, has recently released a new AI-based paraphrasing feature – Linguix Paraphraser 2.0.\n To measure its quality, we use four important metrics: BLEU, Jaccard similarity index, LaBSE and Perplexity.\n Performance stats:\n  \nBLEU, which is used for measuring the quality of machine translation. The lower it is for rephrase task, the better. Right now, Linguix Paraphraser 2.0 has the BLEU metric of 0.47 (previous iteration had 0.65). So, we can say that our paraphraser is now smarter, it uses more words to rewrite the sentence, but the overall idea of the content is still preserved.\n Jaccard similarity index is used to measure the likeness of x and y objects. The same as with BLEU, the lower the index for the task, the better. Our current metric is 0.45 compared to 0.51 for the previous iteration.\n LaBSE metric is used to measure the semantic similarity of two sentences. It translates text into vectors so that vectors of texts close in meaning are geometrically close to each other. The higher the metric, the better. The new model has LaBSE similarity slightly less than the previous model: 0.80 vs 0.93, which is normal and correct, because the model generates a variety of variants using other words, but keeping the meaning of the source text in the target.\n Perplexity is used to ensure the rewritten content sounds natural (lower perplexity is better). The naturalness of the rewrites generated by our new paraphraser is much better than before: 0.26 vs 4.99 for the prior version.\n  \n​\n https://i.redd.it/iaaf7o2iibu81.gif\n As such, for Linguix Paraphraser 2.0 we were able to improve the quality of the rephrased content, while keeping the text meaning at the same level.\n P.S. Daria is somewhat shy, so I asked her to share the update here on her behalf.\n Anyway she'll be pleased to see some feedback!\n    submitted by    /u/alexlash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6htt9/p_evaluating_automatic_paraphrasing_via_bleu/",
          "publishedOn": "2022-04-18T16:56:01.000Z",
          "wordCount": 436,
          "title": "[P] Evaluating automatic paraphrasing via BLEU, LaBSE, Perplexity and Jaccard similarity index - how we do it for Linguix Paraphraser 2.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6hjhv/r_p_slideflow_a_deep_learning_framework_for/",
          "author": null,
          "description": "Hi all - I'm an applied ML researcher working in an oncology research lab at U Chicago, using digital slides of patient's tumors for tumor classification, prognostication, and treatment response prediction. I'm really excited to share with the community the deep learning tools we've been using, and I'm hoping for any feedback you might have (or direction if you think there's a community or subreddit this might be better suited for).\n After years of development, we've released our open-source deep learning framework for digital histology, Slideflow (https://github.com/jamesdolezal/slideflow). It has flexible and highly optimized whole-slide image processing, support for a wide variety of existing and custom architectures (with continuous, categorical, or time-series outcomes), real-time digital stain normalization, a number of explainability tools, and integrated uncertainty quantification. It's compatible with both Tensorflow and PyTorch, available on PyPI and DockerHub, and comes with good documentation (https://slideflow.dev/). We've tried out a number of alternative frameworks over the years, and I think the ease of use, flexibility, and performance optimizations set it apart from other repos you'll find on GitHub.\n We have a handful of local collaborators who are using Slideflow, but I'm hoping to expand our reach and find people in similar fields who are interested in collaborating for ongoing open-source development. I've tried looked for subs relating specifically to computational pathology / digital histology, and haven't found a good community yet - anyone have ideas for how to get connected with like-minded people working in the same field?\n    submitted by    /u/shawarma_bees  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6hjhv/r_p_slideflow_a_deep_learning_framework_for/",
          "publishedOn": "2022-04-18T16:43:07.000Z",
          "wordCount": 458,
          "title": "[R] [P] Slideflow: a deep learning framework for digital histology",
          "imageUrl": "https://external-preview.redd.it/PHZ7hJGxW1Q9Cc6dza79JuKQpcmayN9OU18gE0-IIFg.jpg?auto=webp&s=9f307d446e5b8e380d20ac82147e68556cd790d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6fno2/d_anyone_using_named_tensors_or_a_tensor/",
          "author": null,
          "description": "It seems like there have been some options out for a while now - e.g. native pytorch named tensors, tsalib, torchtyping - yet I haven't really seen them discussed or used in any code I've come across. Just wondering if anyone has surveyed them recently and is using them. In particular tsalib's warp string syntax for transformations looks really interesting.\n    submitted by    /u/patniemeyer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6fno2/d_anyone_using_named_tensors_or_a_tensor/",
          "publishedOn": "2022-04-18T15:20:44.000Z",
          "wordCount": 299,
          "title": "[D] Anyone using named tensors or a tensor annotation lib productively?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6fgmh/d_are_there_any_analog_ai_computing_chips_on_the/",
          "author": null,
          "description": "If so, where to buy them?\n (for example: I red that mythic has been collecting funding in mid-2021, but I dont know if they are for sale anywhere).\n    submitted by    /u/GerritTheBerrit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6fgmh/d_are_there_any_analog_ai_computing_chips_on_the/",
          "publishedOn": "2022-04-18T15:12:02.000Z",
          "wordCount": 720,
          "title": "[D] Are there any analog A.I. computing chips on the retail market yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6e7cd/nrp_high_fidelity_3d_face_reconstruction_from/",
          "author": null,
          "description": "FaceNext is an open source PyTorch library for high fidelity 3D face reconstruction from single/multiple RGB image(s).\n github.com/abdallahdib/NextFace\n ​\n https://reddit.com/link/u6e7cd/video/ixg0wlzirau81/player\n    submitted by    /u/Abd_dib  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6e7cd/nrp_high_fidelity_3d_face_reconstruction_from/",
          "publishedOn": "2022-04-18T14:16:19.000Z",
          "wordCount": 123,
          "title": "[N][R][P] High fidelity 3D face reconstruction from monocular image",
          "imageUrl": "https://external-preview.redd.it/qeKyK3SzjAYVrfrVdpHe6K6biV64I-gNh5p-TiYqhmg.jpg?auto=webp&s=f4d51ba54b0e2c7db1938ce8891b50f96700b08f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6cjwx/d_which_keywords_describe_my_task/",
          "author": null,
          "description": "Hey all, I have received a task in an area I am unfamiliar with and need a little help finding suitable papers, so I am looking for keywords.\n To illustrate the goal, let's say you have 10000 screws (which can be of the same model) and you want to be able to recognize/match each one. You want new screws to be added all the time, so you also want the case that the object could previously be unknown when performing the match.\n The goal is to develop a capturing system that produces suitable images and to find an architecture/algorithm that is as robust as possible. The object images should be invariant to illumination, rotation and translation during acquisition.\n It should be a kind of barcode/hash without any additional symbol, based only on the structure of the object.\n Is there a name for such a task? I think it is not really a classification in the classical sense. I guess it might be just a clever way of finding suitable features for each individual object structure and suitable distance function.\n Sorry for the long post, I appreciate any help.\n    submitted by    /u/Temporary_Lab769  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6cjwx/d_which_keywords_describe_my_task/",
          "publishedOn": "2022-04-18T12:58:51.000Z",
          "wordCount": 286,
          "title": "[D] Which keywords describe my task?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u6ba4t/d_including_outer_objects_in_rnn_cnn/",
          "author": null,
          "description": "Hello there, Which layer or structure would you append to existing machine learning architectures like yolov5 in order to not only detect the specific object, but also the object which it is part of? Lets say there are xray images of laptops: The laptop itself will be detected and also something like the hard drive or battery inside of it. Is it possible to make the CNN/RNN aware of the fact that the hard drive or battery is inside the Laptop?\n Hope someone can tell what i mean. Regards David\n    submitted by    /u/rohrivibes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u6ba4t/d_including_outer_objects_in_rnn_cnn/",
          "publishedOn": "2022-04-18T11:51:04.000Z",
          "wordCount": 343,
          "title": "[D] Including outer objects in RNN / CNN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u69zcf/d_phd_in_knowledge_representation_and_reasoning/",
          "author": null,
          "description": "I have been offered a PhD in domain of knowledge representation and reasoning for autonomous agents. Goal is to use represent textual rules and world knowledge and then use those represented knowledge for reasoning, so that motion of autonomous agent can be predicted. \n I have question regarding the current landscape of knowledge representation and reasoning. I see more and more work in data focused model and old Logic and associated paths fading out. Phd project problem itself looks interesting as it focus on work where there will be less need of data and can plan motion in unseen scenarios. But I am concerned about the future career prospective in this domain where this problem is tackled by knowledge representation and reasoning. As I can see there is less and less funding in this domain. \n What is your take on future landscape of research direction in this domain?\n    submitted by    /u/human_treadstone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u69zcf/d_phd_in_knowledge_representation_and_reasoning/",
          "publishedOn": "2022-04-18T10:32:05.000Z",
          "wordCount": 734,
          "title": "[D] PhD in knowledge representation and reasoning for autonomous agent: research landscape",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u69r78/p_my_blog_on_ml_model_evaluation_bayes_optimal/",
          "author": null,
          "description": "I have published 3 articles about ML model evaluation on my personal blog. Just finished the 3 installment, so I am keen to share and get some feedback.\n I cover frameworks traditionally used in ML like ROC curves, but from a Bayes decision perspective, which I have been struggling to find in textbooks/tutorials. The 3rd part is about the evaluation of log-likelihood calibrated models.\n Hope you will find it interesting/useful!\n https://mkffl.github.io/2021/10/18/Decisions-Part-1.html\n https://mkffl.github.io/2021/10/28/Decisions-Part-2.html\n https://mkffl.github.io/2022/03/02/Decisions-Part-3.html\n And the underlying code for reproducibility https://github.com/mkffl/decisions\n    submitted by    /u/mkffl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u69r78/p_my_blog_on_ml_model_evaluation_bayes_optimal/",
          "publishedOn": "2022-04-18T10:17:22.000Z",
          "wordCount": 279,
          "title": "[P] My blog on ML model evaluation (Bayes optimal decisions, ROC curve, LLR calibration)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u68ht2/p_ormb_docker_for_your_models_help_you_manage/",
          "author": null,
          "description": "github.com/kleveross/ormb\n ormb helps you manage your Machine Learning/Deep Learning models with docker container image registry. It makes your models easy to create, version, share and publish.\n ```\n Save the model in local cache first\n $ ormb save gaocegege/fashion_model:v1 ref: gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB format: SavedModel v1: saved\n Push the model from local cache to remote registry\n $ ormb push gaocegege/fashion_model:v1 The push refers to repository [gaocegege/fashion_model] ref: gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB format: SavedModel v1: pushed to remote (1 layer, 162.1 KiB total)\n Pull the model from remote registry to local cache\n $ ormb pull gaocegege/fashion_model:v1 v1: Pulling from gaocegege/fashion_model ref: gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB Status: Downloaded newer model for gaocegege/fashion_model:v1\n Export the model from local cache to current directory\n $ ormb export gaocegege/fashion_model:v1 ref: localhost/gaocegege/fashion_model:v1 digest: 6b08cd25d01f71a09c1eb852b3a696ee2806abc749628de28a71b507f9eab996 size: 162.1 KiB\n View the local file directory\n $ tree examples/SavedModel-fashion examples/SavedModel-fashion ├── model │ ├── saved_model.pb │ └── variables │ ├── variables.data-00000-of-00001 │ └── variables.index ├── ormbfile.yaml └── training-serving.ipynb\n 2 directories, 5 files ```\n    submitted by    /u/gaocegege  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u68ht2/p_ormb_docker_for_your_models_help_you_manage/",
          "publishedOn": "2022-04-18T08:50:26.000Z",
          "wordCount": 294,
          "title": "[P] ormb: Docker for Your Models, Help You Manage Models Better",
          "imageUrl": "https://external-preview.redd.it/cazibvRm6uWO9h9ZcY__9DfngesMXThv4k9MD4oUHUw.jpg?auto=webp&s=a0e5f43cfdbe3dffbde7aa76ab83baa2dd261513"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u65rm2/d_deep_generative_model_with_hierarchical_latent/",
          "author": null,
          "description": "Hi, I have just published my latest medium article.\n Anomalies are widespread when it comes to working on data. They become vital in time series. So, It is crucial to propose efficient methods to detect and deal with them. This article illustrates a state-of-the-art model called DGHL for anomaly detection. DGHL includes a ConvNet as a Generator and instead of encoding it maximizes the likelihood with the Alternating Back-Propagation algorithms.\n https://rezayazdanfar.medium.com/deep-generative-model-with-hierarchical-latent-factors-for-time-series-anomaly-detection-8d6eaebad8bc\n    submitted by    /u/rezayazdanfar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u65rm2/d_deep_generative_model_with_hierarchical_latent/",
          "publishedOn": "2022-04-18T05:38:44.000Z",
          "wordCount": 182,
          "title": "[D] Deep Generative model with Hierarchical Latent Factors for Time Series Anomaly Detection",
          "imageUrl": "https://external-preview.redd.it/l6cHO0qcu69cDLkZ1vFOVFg3X9OpquaHcfVYWFPlHuE.jpg?auto=webp&s=d5862b4a74cfaa76bb21ab7ec78264e280d14fd4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u64dx0/p_app_to_play_with_latent_diffusion_models/",
          "author": null,
          "description": "just published “geni”, a new minimal app that uses Latent Diffusion Models. It will not produce DALL-E-ish results but it’s fast and great for playing with prompt engineering. Also, it’s free.\n would love to have the community playing with it. \n check it out here: https://geni.vercel.app\n    submitted by    /u/viccpopa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u64dx0/p_app_to_play_with_latent_diffusion_models/",
          "publishedOn": "2022-04-18T04:11:45.000Z",
          "wordCount": 340,
          "title": "[P] app to play with latent diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u64aqf/r_vqflows_vector_quantized_local_normalizing_flows/",
          "author": null,
          "description": "arXiV: https://arxiv.org/abs/2203.11556 \n  \n Summary:\n We introduce a novel statistical framework for learning a mixture of local normalizing flows as \"chart maps\" over the data manifold. Our framework augments the expressivity of recent approaches while preserving the signature property of normalizing flows, that they admit exact density evaluation. We learn a suitable atlas of charts for the data manifold via a vector quantized auto-encoder (VQ-AE) and the distributions over them using a conditional flow. We validate experimentally that our probabilistic framework enables existing approaches to better model data distributions over complex manifolds.​ \n  \n GitHub: Coming Soon\n Author here, happy to answer any questions.\n    submitted by    /u/tshrjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u64aqf/r_vqflows_vector_quantized_local_normalizing_flows/",
          "publishedOn": "2022-04-18T04:06:24.000Z",
          "wordCount": 230,
          "title": "[R] VQ-Flows: Vector Quantized Local Normalizing Flows",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5zf55/rp_mask_transfiner_for_highquality_instance/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5zf55/rp_mask_transfiner_for_highquality_instance/",
          "publishedOn": "2022-04-17T23:44:23.000Z",
          "wordCount": 108,
          "title": "[R][P] Mask Transfiner for High-Quality Instance Segmentation + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/ptS9-9koOmSM--fTSpEmdCnVu8PM69uNHhZS8pegZtI.png?format=pjpg&auto=webp&s=2d21ba5f6a86442578a976d00d6f7bcc0355cba4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5yr54/p_spoonfy_turn_any_foreignlanguage_video_into/",
          "author": null,
          "description": "Video (Despacito, slightly NSFW): https://drive.google.com/file/d/12qYKv_yaqGr9GWvHPtE9ng2foJVPfpoE/view?usp=sharing \n Code & more info: https://github.com/athairus/SpoonfyDemo\n Discord: https://discord.gg/7wcZZzeSQk \n Spoonfy is essentially the so-called Telenovela method (learning languages through subtitled video) on steroids: This demo uses a finetuned Facebook's M2M100 model to translate Spanish to English (finetuned to do literal translation instead of ordinary translation) and a wav2vec2 model to get Spanish word timings to present the literal (aka word-by-word) translations as karaoke-style lyrics.\n What sets Spoonfy apart from other solutions is the way it leverages the massive body of existing subtitled content out there to create learning material. Also because it's FOSS. More details in the code's README.\n I've been working on this project by myself for a few months now, I hope you see potential behind it like I do! If so (but also if not), I'd love to hear what you think. And I'd love to get your help improving on what I already built. I have plenty of ideas for how to make the translations even more accurate, the system more robust & able to handle more sources of content (YouTube, TikTok, Blu-Rays), etc. \n Thanks for checking it out!\n    submitted by    /u/athairus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5yr54/p_spoonfy_turn_any_foreignlanguage_video_into/",
          "publishedOn": "2022-04-17T23:09:45.000Z",
          "wordCount": 284,
          "title": "[P] Spoonfy: Turn any foreign-language video into effective listening practice",
          "imageUrl": "https://external-preview.redd.it/0LZxIVMqdGjUepA9SIidVG8R56GvjOL5MHPxA9nr6g0.jpg?auto=webp&s=274ed783ab24d867a68f54ca0b39ef3e2825fc06"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5xsb1/d_current_work_on_knowledge_representation_with/",
          "author": null,
          "description": "In robotics and autonomous systems, knowledge representation is an important aspect. What is your favorite methods for knowledge representation, is it Formal logic or graphs or whatever and why you like that kind of representation. Considering the success of large language model isn't it a good time to use them in new kind of representation, so that robots or similar system can make better decisions in an environment. I still feel there is no common consensus in community for correct way of knowledge representation, correct me If I am wrong.\n    submitted by    /u/projekt_treadstone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5xsb1/d_current_work_on_knowledge_representation_with/",
          "publishedOn": "2022-04-17T22:22:01.000Z",
          "wordCount": 206,
          "title": "[D] Current work on knowledge representation with your preference, and use of language models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5xk6s/d_dalle_2_vs_disco_diffusion_showdown/",
          "author": null,
          "description": "submitted by    /u/nin_artificial  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5xk6s/d_dalle_2_vs_disco_diffusion_showdown/",
          "publishedOn": "2022-04-17T22:11:02.000Z",
          "wordCount": 209,
          "title": "[D] DALL-E 2 vs Disco Diffusion - SHOWDOWN!",
          "imageUrl": "https://external-preview.redd.it/R3nMDnBMDgegOE4sQ0TGq1n-EP2ElnuOIwjR52hsJVg.jpg?auto=webp&s=69842e7a37dc4717294e2921cabb2c7c14dc6b86"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5st3t/wacv_vs_bmvc_r/",
          "author": null,
          "description": "How do they compare in terms of the communities, prestige, competitiveness, and impact. \n I have a paper accepted to a CVPR workshop and considering extending it and submitting to one of these. The work is based on explainability in medical vision. It's more methods-oriented rather than large-scale experiments. \n What are your suggestions?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5st3t/wacv_vs_bmvc_r/",
          "publishedOn": "2022-04-17T18:16:09.000Z",
          "wordCount": 176,
          "title": "WACV vs. BMVC [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5rnss/n_p_access_100_image_video_audio_datasets_in/",
          "author": null,
          "description": "submitted by    /u/davidbun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5rnss/n_p_access_100_image_video_audio_datasets_in/",
          "publishedOn": "2022-04-17T17:20:34.000Z",
          "wordCount": 1373,
          "title": "[N] [P] Access 100+ image, video & audio datasets in seconds with one line of code & stream them while training ML models with Activeloop Hub (more at docs.activeloop.ai, description & links in the comments below)",
          "imageUrl": "https://external-preview.redd.it/MZrztB7vuApjv22WUfP9K0u0BToEvLP488cAz_DB62w.png?format=pjpg&auto=webp&s=85717c78ba904404995956a0d98207ab9c4d223b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5pxvh/d_is_it_ok_to_promise_a_dataset_in_your_paper_get/",
          "author": null,
          "description": "Recently, I decided to explore NeRF and found a very interesting dataset in the NeRS paper of 3D models, which was published in NeurIPS 2021 four months ago. Authors promised to release their dataset:\n  \nThe filtered dataset with anonymized personally identifiable information (e.g. license plates and phone numbers), masks, initial camera poses, and optimized NeRS cameras will be made available on the project page.\n  \nHowever, if you check their project page or github repo — there is nothing there. I do not have much experience in machine learning, but wonder whether it's ok to do this? My thinking was that it is something to look down upon, but in this case it is done by Carnegie Mellon University (which is a top-tier one in ML?) on a top-tier conference (NeurIPS 2021). So I assume it's fine?\n    submitted by    /u/throwmeaway-account  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5pxvh/d_is_it_ok_to_promise_a_dataset_in_your_paper_get/",
          "publishedOn": "2022-04-17T15:57:04.000Z",
          "wordCount": 1452,
          "title": "[D] Is it ok to promise a dataset in your paper, get published and then not release it?",
          "imageUrl": "https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&s=0c3f0b8af92c3a962f569a389e9673597e12f8ec"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5hny4/d_wasserstein_distance_lipschitz_vs_gaussian/",
          "author": null,
          "description": "Hi, I heard there are different ways to calculate Wasserstein distance in Neural network context. First, We can convert 1-d Wasserstein loss to dual representation and constraint it's size(to makes lipschitz function). We need to do weight clip to make our model a lipschitz function. Second, we can make neural network output as Gaussian distribution and calculate easy form using neural network output as mean and covariance matrix.\n So, what are the advantages and disadvantages of comparing them? It may sound ambiguous, but I have not seen a study that compares the two about representation quality, computation, etc...\n Thank you for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5hny4/d_wasserstein_distance_lipschitz_vs_gaussian/",
          "publishedOn": "2022-04-17T07:09:21.000Z",
          "wordCount": 195,
          "title": "[D] Wasserstein distance lipschitz vs gaussian distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5hls2/d_what_do_you_use_to_make_your_blogpersonal/",
          "author": null,
          "description": "I've noticed a lot of folks in ML have a personal website that doubles as a blog to write about their work/projects. As someone looking to build their own website along the same lines, I'm looking for frameworks to try and build it with.\n What framework do you use to design your site?\n    submitted by    /u/SwiftLynx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5hls2/d_what_do_you_use_to_make_your_blogpersonal/",
          "publishedOn": "2022-04-17T07:04:48.000Z",
          "wordCount": 777,
          "title": "[D] What do you use to make your blog/personal websites?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5g59g/discussion_interpretable_neural_network/",
          "author": null,
          "description": "Hi All!\n I've been working on a linear method that extracts signals from images by learning a set of composable image filters. It can recompose an image using these filters as seen on this biological histology tissue (real on the right, recomposed on the left)\n ​\n ​\n https://preview.redd.it/czgdk6edx0u81.png?width=768&format=png&auto=webp&s=8768f93a749fff7dc41e576a74403096e113942e\n ​\n Because it is a linear method that learns image filters - I had an idea: what if some components of a neural network could be replaced with a learnable set of filters?\n For those not in the know, image filters are similar to masks that upweight some parts of the image, and downweights other parts - similar to a highlighter to select text and a pen to cross out words. I show how in the figure below:\n ​\n ​\n https://preview.redd.it/2azco14ex0u81.jpg?width=499&format=pjpg&auto=webp&s=f3795fec06daa13da61ec155159a0ad865524530\n ​\n Learning a set of image filters with a neural network is a good idea, as neural networks are much more flexible and are considered to be \"universal function approximations\". So I wrote up a Pytorch package to pass the neural network feature weights from Convolutions and Max Pooling into the linear method to learn a relevant set of filters - results are comparable even on CIFAR10.\n The caveat is that there is no ReLU, no other activation functions, and no Dropout - only 1 main single linear layer that learns filters... an interpretable neural network!\n ​\n Results are all here (including ipynb comparing with base CNN and VGG16)\n https://github.com/AskExplain/Interpretable-Neural-Net\n ​\n I'll update the GitHub with some figures of why the single layer is interpretable soon ...\n ​\n In the meantime - discuss!\n    submitted by    /u/TryToExplainHow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5g59g/discussion_interpretable_neural_network/",
          "publishedOn": "2022-04-17T05:20:35.000Z",
          "wordCount": 785,
          "title": "[Discussion] Interpretable Neural Network ... ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5f13f/p_new_graph_data_augmentation_library/",
          "author": null,
          "description": "Hello!\n I recently built grafog, a graph data augmentation library on top of PyTorch Geometric. You can chain together graph mentations as done in albumentations or torchvision.transforms.\n Check it out: https://github.com/rish-16/grafog\n It has the following augmentations:\n  \nRandom Node Drop\n Random Edge Drop\n Normalize Features\n MixUp Strategy\n Node Feature Masking\n Edge Feature Masking\n  \nhttps://preview.redd.it/c53r7gkrk0u81.png?width=689&format=png&auto=webp&s=8fbe668e82571a7fe5de9ebb5e4690dbd34032bb\n https://preview.redd.it/5zrj4gkrk0u81.png?width=863&format=png&auto=webp&s=5bd02ea4adaf86b8911fa89372be9f05f9010536\n Happy augmenting!\n    submitted by    /u/rish-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5f13f/p_new_graph_data_augmentation_library/",
          "publishedOn": "2022-04-17T04:09:29.000Z",
          "wordCount": 136,
          "title": "[P] New Graph Data Augmentation Library",
          "imageUrl": "https://external-preview.redd.it/W-DkujRyxiUuDiMo5mAmgu_-adMrH1WLDu4IKWgC1U8.jpg?auto=webp&s=cf4a7ac201e8c6befcc54281ba4e04bb6ee019dc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5de2m/n_how_does_openais_dalle_2_work/",
          "author": null,
          "description": "submitted by    /u/giugiacaglia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5de2m/n_how_does_openais_dalle_2_work/",
          "publishedOn": "2022-04-17T02:33:05.000Z",
          "wordCount": 96,
          "title": "[N]: How does OpenAI's DALL-E 2 work?",
          "imageUrl": "https://external-preview.redd.it/O3oiwtDn_kSV6j5Y2p2wVfYjesxCV2ChsBLe-7boEJk.jpg?auto=webp&s=8b0004a2ccbf0994ceccf9a7d65b28a96922b369"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5bnj9/d_what_is_the_opposite_of_an_ablative_study/",
          "author": null,
          "description": "I've the feeling that this question may be really stupid but I make it anyway. \n In ML we often see ablative studies. How is the opposite of it called? In other words: A study that aim to improve a model, and once an improvement is reached, this new model is taken as basis for further investigations?\n    submitted by    /u/Rogitus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5bnj9/d_what_is_the_opposite_of_an_ablative_study/",
          "publishedOn": "2022-04-17T00:55:22.000Z",
          "wordCount": 644,
          "title": "[D] What is the opposite of an ablative study?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u5ame9/r_questions_about_acl_rolling_review/",
          "author": null,
          "description": "A few questions about ACL ARR:\n - If you request to reassign a reviewer, would the editor aim for reassigning all three reviewers or he would go for reassigning only that particular reviewer? Assume you have given a valid reason for reassignment and the editor is convinced.\n - If you request to reassign a reviewer, can the new reviewer see the previous reviews/scores before submitting his own review? Or he would access to the previous revision after submitting his own review.\n I already know (have heard) that in many cases reviewers are not available, and it becomes inevitable to get an entirely new set of reviews. I already know this. But my questions are about the case that the reviewer availability is not an issue. Juts trying to find out how things are managed\n    submitted by    /u/sim_inf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u5ame9/r_questions_about_acl_rolling_review/",
          "publishedOn": "2022-04-16T23:59:39.000Z",
          "wordCount": 311,
          "title": "[R] Questions about ACL Rolling Review",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u59qv5/rp_multimae_multimodal_multitask_masked/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u59qv5/rp_multimae_multimodal_multitask_masked/",
          "publishedOn": "2022-04-16T23:12:41.000Z",
          "wordCount": 105,
          "title": "[R][P] MultiMAE: Multi-modal Multi-task Masked Autoencoders + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/bznYLgcG71XWh67uHxfzaDDfHXoDwNbJQq1TNPnUNXs.png?format=pjpg&auto=webp&s=b0345bfb4b06944f32485d9f4dbb8ebec53f98f5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u58ysb/discussionis_it_possible_to_find_a_swe_job_with_a/",
          "author": null,
          "description": "Say that a masters student graduates in a DS program with heavy focus on data and CS (so knows the basics of CS like data structures and programming, and has also studied courses like data mining, big data analytics, and machine learning), what are their possible job openings and relatively easy positions to get into?\n My understanding is really rudimentaly, feel free to correct me pls:\n  \nData scientist, this should be the most fitting and easy-to-get-interview position. Difficulty level 1/5.\n Data analyist, same as 1. Difficulty level 1/5.\n Data engineer, same as 1. Difficulty level 1/5.\n Machine learning engineer, has a higher bar than 1, 2, and 3, and it's very difficult to get interviews without proper background and work experience. So it's very difficult to become one for a masters graduate in DS, but it's quite possible for DS/DE (but much less so for DA) to make into MLE positions. Difficulty level 3/5.\n Software engineer, it's totally another realm, and has very few skill overlap with 1, 2, and 3. So it's very hard to make the transition or land a SWE job for DS students. Difficulty level 5/5.\n  \n   submitted by    /u/Competitive_Map_935  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u58ysb/discussionis_it_possible_to_find_a_swe_job_with_a/",
          "publishedOn": "2022-04-16T22:33:20.000Z",
          "wordCount": 422,
          "title": "[Discussion]Is it possible to find a SWE job with a DS master degree? Or would it be possible to make the transtion later on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u58mu8/project_opensource_playground_to_generate_images/",
          "author": null,
          "description": "submitted by    /u/koryoislie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u58mu8/project_opensource_playground_to_generate_images/",
          "publishedOn": "2022-04-16T22:16:39.000Z",
          "wordCount": 113,
          "title": "[Project] Open-source playground to generate images from text using DALL-E Mini",
          "imageUrl": "https://external-preview.redd.it/3IZwiyP5n-XMJ7ZC-HYQGmSZ0FQJtbd7chsgGPQUGOw.jpg?auto=webp&s=deb00e83a408139fa4a40baa3f4352c9c7768e1d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u56grv/d_incorporating_node_features_into_gnns/",
          "author": null,
          "description": "Hey all,\n I am looking to learn more about how to incorporate node features with their embeddings for training. Specifically, I am working with gene-gene interaction networks, and also want to include RNA-sequencing quantifications.\n If anyone has a good introductory resource so I can familiarize myself with the process, I would really appreciate it!\n    submitted by    /u/PM_ME_A_ONELINER  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u56grv/d_incorporating_node_features_into_gnns/",
          "publishedOn": "2022-04-16T20:28:39.000Z",
          "wordCount": 217,
          "title": "[D] Incorporating node features into GNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u53hb3/d_moderation_uniformity_in_subreddit/",
          "author": null,
          "description": "This isn't meant to be a rant. Rather far from it.\n Yesterday I posted a legitimate question about databases choices in r/MachineLearning. This was about what technical choices ML members are currently using for large scale data ingestion in a continual learning environment. The post was removed. That post was neither a (1) beginner nor (2) offensive and (3) aimed to be a constructive discussion suitable as mid-range ML query and (4) marked with appropriate flair I finally posted it elsewhere.\n Yet today I see questions about transitions between DS -> MLE and quirky labgroup names which can be used from ML terms. These aren't even research questions.\n https://www.reddit.com/r/MachineLearning/comments/u503vz/d_is_it_easier_to_transition_to_mle_as_a_ds_or_swe/\n https://www.reddit.com/r/MachineLearning/comments/u5091o/d_do_you_know_any_funny_team_names_with/\n How is this fair moderation genuinely? How can we improve the noise filter or do better moderation?\n    submitted by    /u/mlbloke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u53hb3/d_moderation_uniformity_in_subreddit/",
          "publishedOn": "2022-04-16T18:05:43.000Z",
          "wordCount": 684,
          "title": "[D] Moderation uniformity in subreddit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u50qor/d_counterfactual_fairness/",
          "author": null,
          "description": "So I watched this old video by Microsoft Research: https://www.youtube.com/watch?v=psA4U6nhZ70 \n To summarize, it uses the fairness criteria that sensitive attribute A will give the same prediction regardless of the value, when using counterfactuals. That is, if you're male or female, it shouldn't influence the models predictions. \n The idea seems decent at first glance. But what if the \"bias\" or \"unfairness\" that the model creates based on sensitive attribute A isn't caused by a dataset bias but rather detects a real signal in the data?\n The model proposed by Microsoft Research doesn't take into consideration that the prediction on the sensitive attribute A does not necessarily consist of ONLY unfairness. They simply define it as such. \n Is such an algorithmic design choice not exactly one of the flaws that we seek to eliminate? Assuming, that not all of the imbalance in predictions by the model on the sensitive attribute A is caused by \"unfairness\" but that some of it is caused by an inherent difference, then are they not introducing direct human bias and unfairness into their model by explicitedly designing the system to fit their own human (and political) bias? \n Don't get me wrong; the opposite is just as bad. Assuming that ALL of the imbalance in the prediction on the sensitive attribute A is caused by \"inherent differences\" is just as bad. \n Do you know of anyone that has tackled this in a good manner? How would you even begin to estimate how much is due to an \"inherent difference\" and how much is due to \"bias, unfairness, noise\" (or otherwise)?\n    submitted by    /u/caahel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u50qor/d_counterfactual_fairness/",
          "publishedOn": "2022-04-16T15:56:15.000Z",
          "wordCount": 1090,
          "title": "[D] Counterfactual Fairness",
          "imageUrl": "https://external-preview.redd.it/PkGn1qTyIzRCk-hvpbA86Dr9_suN1BAMtIk8hvwJ7UQ.jpg?auto=webp&s=dfa6818c1c26676a34ac7285fa272bd9c601093d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u50nva/d_paper_explained_transformer_memory_as_a/",
          "author": null,
          "description": "https://youtu.be/qlB0TPBQ7YY\n Search engines work by building an index and then looking up things in it. Usually, that index is a separate data structure. In keyword search, we build and store reverse indices. In neural search, we build nearest-neighbor indices. This paper does something different: It directly trains a Transformer to return the ID of the most relevant document. No similarity search over embeddings or anything like this is performed, and no external data structure is needed, as the entire index is essentially captured by the model's weights. The paper experiments with various ways of representing documents and training the system, which works surprisingly well! \n OUTLINE:\n 0:00 - Intro\n 0:45 - Sponsor: Diffgram\n 1:35 - Paper overview\n 3:15 - The search problem, classic and neural\n 8:15 - Seq2seq for directly predicting document IDs\n 11:05 - Differentiable search index architecture\n 18:05 - Indexing\n 25:15 - Retrieval and document representation\n 33:25 - Training DSI\n 39:15 - Experimental results\n 49:25 - Comments & Conclusions\n ​\n Paper: https://arxiv.org/abs/2202.06991\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u50nva/d_paper_explained_transformer_memory_as_a/",
          "publishedOn": "2022-04-16T15:52:29.000Z",
          "wordCount": 279,
          "title": "[D] Paper Explained - Transformer Memory as a Differentiable Search Index (Full Video Walkthrough)",
          "imageUrl": "https://external-preview.redd.it/oJXsTh1nRh1baGeG09BQsKVZ-h5vle9lh4vhdSO1U00.jpg?auto=webp&s=71d2b29f763b9c71de501eec80b24daad5924e75"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4y5r4/r_useful_method_to_train_models_for_adversarial/",
          "author": null,
          "description": "submitted by    /u/IncredibleMac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4y5r4/r_useful_method_to_train_models_for_adversarial/",
          "publishedOn": "2022-04-16T13:46:33.000Z",
          "wordCount": 107,
          "title": "[R] Useful method to train models for adversarial robustness",
          "imageUrl": "https://external-preview.redd.it/YB_0MLTV1pr8vz21W1E8IqoNv9407iLcaOC_mp4Kmcc.jpg?auto=webp&s=da75d46d3a5287773d398df80dc3d38fd80001b8"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4wvlc/p_comparing_default_vs_custom_reward_function_for/",
          "author": null,
          "description": "submitted by    /u/DIAMBRA_AIArena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4wvlc/p_comparing_default_vs_custom_reward_function_for/",
          "publishedOn": "2022-04-16T12:35:13.000Z",
          "wordCount": 337,
          "title": "[P] Comparing Default VS Custom Reward Function for Optimal Health Management of a DeepRL Agent Playing Tekken",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4w8x4/d_spotifys_podcast_search_explained/",
          "author": null,
          "description": "I wrote this article breaking down how Spotify have applied semantic search to enhance podcast discovery. I find it super interesting to see the approach Spotify have used in terms of data sources, model fine-tuning, and vector search - and wanted to show how to almost replicate it. Let me know if you have any thoughts on their approach!\n    submitted by    /u/jamescalam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4w8x4/d_spotifys_podcast_search_explained/",
          "publishedOn": "2022-04-16T11:56:51.000Z",
          "wordCount": 149,
          "title": "[D] Spotify's Podcast Search Explained",
          "imageUrl": "https://external-preview.redd.it/MfWyv37SXVtIVXtuiyhjCArVv2gGXI5l6fLL8RLBFPM.jpg?auto=webp&s=2b2d3a250b74a6dcff0ea27dac2a4e342cdc5596"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4vtil/r_machine_learning_in_management_of_precautionary/",
          "author": null,
          "description": "In this work, we have covered a deep study of alternatives in order to improve the aquaculture of mussels with very noisy and unbalanced data https://www.sciencedirect.com/science/article/pii/S0168169922002733\n    submitted by    /u/ennanco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4vtil/r_machine_learning_in_management_of_precautionary/",
          "publishedOn": "2022-04-16T11:28:27.000Z",
          "wordCount": 136,
          "title": "[R] Machine learning in management of precautionary closures caused by lipophilic biotoxins",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4uvac/p_rrgcn_now_supports_multimodal_learning/",
          "author": null,
          "description": "We have just released v0.0.2 of our RR-GCN. This release includes support for multi-modal learning. Node embeddings can now be initialised with literal information or pre-trained embeddings for text and image data. Go check out our notebooks that show how we can achieve state-of-the-art performance on several benchmark datasets in less than one minute. Moreover, and more importantly, the representations produced by our RR-GCN are unsupervised and parameter-free (i.e. no training is required), making it possible to re-use them for multiple downstream ML tasks with high predictive performances.\n ​\n https://github.com/predict-idlab/RR-GCN\n    submitted by    /u/givdwiel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4uvac/p_rrgcn_now_supports_multimodal_learning/",
          "publishedOn": "2022-04-16T10:21:03.000Z",
          "wordCount": 180,
          "title": "[P] RR-GCN now supports multi-modal learning!",
          "imageUrl": "https://external-preview.redd.it/_tKhxjKFTfxjnhpHTJPz0U2l2tdo7r5v1wV9Hm4JPf4.jpg?auto=webp&s=4a6118d3da56eebca2751712955dcfed98ced8c6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4tlk2/d_paper_explained_seer_explained_vision_models/",
          "author": null,
          "description": "https://youtu.be/XHAoV_nKr1o\n This video explains the 10 billion parameter SEER model from MetaAI by Goyal et al. 2022.\n Paper link: https://arxiv.org/abs/2202.08360 \n Official implementation: https://github.com/facebookresearch/vissl/tree/main/projects/SEER\n Short description:\n The 10 billion parameter SEER model from u/MetaAI is *fairer*, even though it is trained on *uncurated* data. How so? Check out our take on this. \n Outline:\n 00:00 Training on uncurated data\n 01:12 Diffgram (Sponsor)\n 01:46 Toxicity in large models\n 02:43 What to do against model toxicity?\n 03:53 SEER model explained\n 06:52 SEER is fairer. But how?\n    submitted by    /u/AICoffeeBreak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4tlk2/d_paper_explained_seer_explained_vision_models/",
          "publishedOn": "2022-04-16T08:46:17.000Z",
          "wordCount": 275,
          "title": "[D] Paper Explained – SEER explained: Vision Models more Robust & Fair when pretrained on UNCURATED images!?",
          "imageUrl": "https://external-preview.redd.it/PAoscz2vJnkKtNLkvbvGLICUtG6dVPUzJECgUOpC2bo.jpg?auto=webp&s=766b0c566c9f8e5edef60788e2412b994425c4f2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4kowy/d_what_is_the_difference_between_channelwise_and/",
          "author": null,
          "description": "Example: I fed 32 feature maps of dimension 6x6x32 into a Squeeze and Excitation layer, which assigns a weight to each of my channel through a channel-wise attention mechanism. \n What is the difference between passing these 32 feature maps into a Hybrid Transformer Encoder with patch of dimension 6x6? (So 1 patch for each channel)\n As I understand it, channel attention says \"which channel is important for the final prediction\". While transformer (with self attention) tells us \"where to focus our attention in a given context\".\n Isn't that the same if the patches are the channels? Basically it tells us on which patch to focus, and if patch=channel then squeeze excitation = self attention ?\n    submitted by    /u/Rogitus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4kowy/d_what_is_the_difference_between_channelwise_and/",
          "publishedOn": "2022-04-15T23:29:32.000Z",
          "wordCount": 225,
          "title": "[D] What is the difference between channel-wise and self attention in this case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4jkgu/p_boundingai_launches_new_marketplace_for_ai/",
          "author": null,
          "description": "In a new announcement, Bounding.ai launched its marketplace for computer vision and AI teams to access training data easily. The platform is designed to empower individuals and small companies around the world to create and sell datasets that will be instantly accessible by any team in need of labeled data.\n Bounding.ai Launches New Marketplace for AI Labeled Data & $5,000 Prize\n    submitted by    /u/Freyr_AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4jkgu/p_boundingai_launches_new_marketplace_for_ai/",
          "publishedOn": "2022-04-15T22:31:38.000Z",
          "wordCount": 167,
          "title": "[P] Bounding.ai Launches New Marketplace for AI Labeled Data",
          "imageUrl": "https://external-preview.redd.it/x7ulJgQagpjsTvp9cVZtPj5uGgLkFq_7j6GrHfxsmxU.jpg?auto=webp&s=2dca867b23623a16f646a9525dc5d5d9102fefa7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4cu3k/dunsupervised_classification_of_wordsphrases/",
          "author": null,
          "description": "I have found most unsupervised text classification methods to be mostly suitable for classifying documents containing relatively large amounts of words/sentences. However, I have a dataset with entries containing only single words or phrases but not full sentences. The goal is to do unsupervised semantic classification on these words/phrases. Are there any existing algorithms for such a task?\n    submitted by    /u/Comprehensive-Egg707  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4cu3k/dunsupervised_classification_of_wordsphrases/",
          "publishedOn": "2022-04-15T17:12:45.000Z",
          "wordCount": 165,
          "title": "[D]Unsupervised classification of words/phrases?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4cpc7/n_robot_arm_acts_as_hand_and_eyes_of_language/",
          "author": null,
          "description": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could in principle be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack contextual grounding, which makes it difficult to leverage them for decision making within a given real-world context. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide this grounding by means of pretrained behaviors, which are used to condition the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level tasks can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these tasks provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator.\n Github: https://say-can.github.io/\n Video of Robot Executing Commands: https://youtu.be/zOph99BjRqs?t=4\n    submitted by    /u/SlightSituation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4cpc7/n_robot_arm_acts_as_hand_and_eyes_of_language/",
          "publishedOn": "2022-04-15T17:06:49.000Z",
          "wordCount": 384,
          "title": "[N] Robot Arm Acts As \"Hand And Eyes\" of Language Model To Execute Real World Tasks With SayCan And Robotics At Google",
          "imageUrl": "https://external-preview.redd.it/hsvHG0bwPLs7HD7ligE7Xw9DhAB8J0Rb9r3BL8XJVPk.jpg?auto=webp&s=bdc19091d980975265d680d565667e3b1ff67c24"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4bfii/d_askscience_ama_series_we_are_seven_leading/",
          "author": null,
          "description": "submitted by    /u/blueneuronDOTnet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4bfii/d_askscience_ama_series_we_are_seven_leading/",
          "publishedOn": "2022-04-15T16:08:22.000Z",
          "wordCount": 631,
          "title": "[D] AskScience AMA Series: We are seven leading scientists specializing in the intersection of machine learning and neuroscience. Ask Us Anything about computational neuroscience or science education!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u496k8/d_how_dalle_2_actually_works/",
          "author": null,
          "description": "Here's a video explaining the overall architecture of DALL-E 2 and how it actually works! Great overview for those who haven't had time to read the paper\n How does DALL-E 2 actually work?\n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u496k8/d_how_dalle_2_actually_works/",
          "publishedOn": "2022-04-15T14:23:30.000Z",
          "wordCount": 219,
          "title": "[D] How DALL-E 2 Actually Works",
          "imageUrl": "https://external-preview.redd.it/_1AcQ1a3JcdirIWcWtQJYzupd0UV2SkQtJ4kF5imSvE.jpg?auto=webp&s=b4d01c5a490c044d73c4f83548b42fc34743dbf6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u482yj/n_announcing_the_learning_on_graphs_conference/",
          "author": null,
          "description": "We think this new venue will be valuable for the Graph/Geometric Machine Learning community. Why? See our blogpost: https://michael-bronstein.medium.com/announcing-the-learning-on-graphs-conference-c63caed7347\n The LoG Conference key facts:\n - Covers work broadly related to machine learning on graphs and geometry\n - Proceedings track published in PMLR\n - Also has a non-archival extended abstract track\n - Double blind review process on OpenReview\n - Top reviewers receive monetary rewards\n - First year: virtual December 9-12 2022, free to attend.\n Call for papers: https://logconference.github.io/cfp/ \n Stay updated via Twitter: https://twitter.com/LogConference\n Or LinkedIn: https://www.linkedin.com/company/log-conference\n Advisory board:\n Regina Barzilay (MIT), Xavier Bresson (NUS), Michael Bronstein (Oxford/Twitter), Stephan Günnemann (TUM), Stefanie Jegelka (MIT), Jure Leskovec (Stanford), Pietro Liò (Cambridge), Jian Tang (MILA/HEC Montreal), Jie Tang (Tsinghua), Petar Veličković (DeepMind), Soledad Villar (JHU), Marinka Zitnik (Harvard).\n Organizers:\n Yuanqi Du (DP Technology), Hannes Stärk (MIT), Derek Lim (MIT), Chaitanya Joshi (Cambridge), Andreea-Ioana Deac (Mila), Iulia Duta (Cambridge), Joshua Robinson (MIT).\n    submitted by    /u/Hannes-Stark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u482yj/n_announcing_the_learning_on_graphs_conference/",
          "publishedOn": "2022-04-15T13:28:35.000Z",
          "wordCount": 228,
          "title": "[N] Announcing the Learning on Graphs Conference!",
          "imageUrl": "https://external-preview.redd.it/EXt-6EkuWHtAcKDkIEkW4MowqZSzpZGNoRuanm2aJr4.jpg?auto=webp&s=c1384e936720dc96f641150d3c8e89cb98af6043"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u45w9b/p_using_language_models_to_probably_read_faster/",
          "author": null,
          "description": "I explored using language models to highlight more salient parts of a PDF file which hopefully help users to read faster. The main idea is to highlight only the characters which language model failed to predict. I have implemented this as an experimental feature in sioyek PDF reader.\n Here is a blog post explaining this in full detail: https://ahrm.github.io/jekyll/update/2022/04/14/using-languge-models-to-read-faster.html\n    submitted by    /u/highergraphic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u45w9b/p_using_language_models_to_probably_read_faster/",
          "publishedOn": "2022-04-15T11:25:45.000Z",
          "wordCount": 538,
          "title": "[P] Using Language Models to (probably) Read Faster",
          "imageUrl": "https://external-preview.redd.it/n4Qm7bf5J5F1cD4l2Q2hq8xgDPml_3BecCBw6TOauwk.jpg?auto=webp&s=8f857d3f7ea13a314295aac9ef44a85345c3c2bf"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u4579v/p_gans_and_generating_visually_indeterminate/",
          "author": null,
          "description": "(Please correct me if I'm using the wrong flair/on the wrong sub)\n I'm currently working on a project that focuses on GANs and generative art, particularly images that concern visual indeterminacy. I trying to find papers/articles that discuss the development/application of (any kind of) GAN in which along the way or as a final result, images were generated that would be considered visually indeterminate. Specifically, research in which the objective was to generate images with clear, recognizable objects/scenes.\n In my mind I'm looking for articles in which the GAN architecture is discussed and in which ways what parts of it could've influenced the particular aspects of the incorrectly generated image. This probably wouldn't be the focus of any research but I was wondering if anyone has ever come across a discussion section in a GAN paper or could point me towards some areas or projects where I might find something that I could connect to my project.\n    submitted by    /u/mel4ncholi4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u4579v/p_gans_and_generating_visually_indeterminate/",
          "publishedOn": "2022-04-15T10:39:25.000Z",
          "wordCount": 256,
          "title": "[P] GANs and generating visually indeterminate images by error",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u442u0/d_ensemble_methods_eg_hard_voting_in_machine/",
          "author": null,
          "description": "When should we consider ensemble methods in machine learning? Is there any statistical criteria using which we can decide, if doing ensemble may help?\n    submitted by    /u/flaubart9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u442u0/d_ensemble_methods_eg_hard_voting_in_machine/",
          "publishedOn": "2022-04-15T09:18:10.000Z",
          "wordCount": 465,
          "title": "[D] Ensemble methods (e.g. hard voting) in machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u43bdq/d_how_do_you_understand_both_ff𝐿_and_ff𝑆_were/",
          "author": null,
          "description": "Hi, I am re-implementing the paper \"Low Resource Recognition and Linking of Biomedical Concepts from a Large Ontology\" https://arxiv.org/abs/2101.10587v1 .\n They describe one part of their model as \"3-layer feed-forward networks with hidden dimensions of 1024 and 256, GeLU as the activation function and a dropout with probability 0.1 applied at their input.\"\n For me that's not enough information to uniquely characterize the network, but maybe for someone with more experience the intended structure is obvious. The output should be a scalar, so i assume that it's something like:\n Dropout(0.1) -> Linear(<input dim>, 1024) -> Linear(1024, 256) -> GELU -> Linear(256, 1) ?\n Or is the nonlinearity (GELU) normally applied after each step?\n    submitted by    /u/ldorigo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u43bdq/d_how_do_you_understand_both_ff𝐿_and_ff𝑆_were/",
          "publishedOn": "2022-04-15T08:20:21.000Z",
          "wordCount": null,
          "title": "[D] How do you understand \"Both FF𝐿 and FF𝑆 were 3-layer feed-forward networks with hidden dimensions of 1024 and 256, GeLU as the activation function and a dropout with probability 0.1 applied at their input.\"? (re-implementing https://arxiv.org/abs/2101.10587v1)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u42yop/why_did_scinet_not_get_more_attention_d/",
          "author": null,
          "description": "It seems to shatter previous benchmarks with a new, innovative architecture, yet it only has 3 citations and little to no attention from the community as far as I can see. Is it because time series forecasting is not very trendy right now or is there anything wrong with the paper?\n The paper in question: https://arxiv.org/pdf/2106.09305v2.pdf\n    submitted by    /u/vidul7498  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u42yop/why_did_scinet_not_get_more_attention_d/",
          "publishedOn": "2022-04-15T07:54:34.000Z",
          "wordCount": 669,
          "title": "Why did SciNet not get more attention? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u40qlq/d_do_you_train_and_deploy_models_using_just_one/",
          "author": null,
          "description": "Hi, I'm the creator of Pinferencia. Currently I'm design new features to-do list. I want to know:\n Do you train and deploy models using just one framework or multiple frameworks at work?\n For example, use pytorch for training and deployment, or use tensorflow, pytorch for training, onnx for deployment.\n View Poll\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u40qlq/d_do_you_train_and_deploy_models_using_just_one/",
          "publishedOn": "2022-04-15T05:20:22.000Z",
          "wordCount": 542,
          "title": "[D] Do you train and deploy models using just one framework or multiple frameworks at work?",
          "imageUrl": "https://external-preview.redd.it/-FMAntzrgomVFdSmpIvFZ3p81fjXHuHG4NC8okewaYc.jpg?auto=webp&s=aa353febc115f4043e7c0ca28217bab8db441503"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3zyvy/p_extremely_short_and_simple_implementation_of/",
          "author": null,
          "description": "​\n Randomly sampled MNIST output. It's not good I know.\n Hi, I noticed there aren't that many simple implementation of DDPM, for example, using MNIST. I had to make a presentation for my workplace seminar, so I had to implement the simplified version of DDPM myself. The whole thing is under 200 lines of code\n https://github.com/cloneofsimo/minDiffusion\n This implementation has MANY missing details, such as Unet Models etc. I think it is worth taking a look, especially if you are interested in recent boom of diffusion models (such as Dalle 2)\n    submitted by    /u/cloneofsimo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3zyvy/p_extremely_short_and_simple_implementation_of/",
          "publishedOn": "2022-04-15T04:31:28.000Z",
          "wordCount": 346,
          "title": "[P] Extremely short and simple implementation of Denoising Diffusion Model, for educational purpose",
          "imageUrl": "https://external-preview.redd.it/v-57XvcNvwhO-HEm0YwnYMP-kBn5uJ7kFdEfT8Hvj_A.jpg?auto=webp&s=461fca6af9aa2e345afbeb207d23970ce0a6d5d5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3xjr7/d_kubernetes_for_ml_how_are_yall_doing_it/",
          "author": null,
          "description": "Have been involved with Mesos since 2013, and Kubernetes almost since it's inception (and saw it win the \"scheduler wars\"). And now being used for pretty much _all_ container workloads, including ML training and inference.\n Since it was built in the image of Borg (where search indexers and map reduce jobs were preemptible, and serving search workloads had to be protected at all cost)[1], how is Kubernetes holding up for your current workflows? Are you using Kubeflow? metaflow? bespoke setup on top? \n [1] https://queue.acm.org/detail.cfm?id=2898444\n    submitted by    /u/nqnielsen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3xjr7/d_kubernetes_for_ml_how_are_yall_doing_it/",
          "publishedOn": "2022-04-15T02:15:10.000Z",
          "wordCount": 636,
          "title": "[D] Kubernetes for ML - how are y'all doing it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3tld1/d_loocv/",
          "author": null,
          "description": "I'm working with a small dataset (~400 labeled data). I plan to use logistic regression. Does it make sense/is it necessary to have a hold-out validation set along with doing Leave-one out cross validation (LOOCV) (E.g. leave 20% out, and train model on LOOCV)?\n    submitted by    /u/yontbont1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3tld1/d_loocv/",
          "publishedOn": "2022-04-14T22:50:24.000Z",
          "wordCount": 339,
          "title": "[D] LOOCV",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3o4jp/d_whats_the_probability_distribution_of_the/",
          "author": null,
          "description": "Assuming feature importance as defined by mean decrease in impurities. I'm curious if there are any studies about their distribution. I'm thinking about using a statistical test to check if a feature is relevant or not, all I can find is using the standard deviation as a measurement of noise. Additionally I imagine if we can give the probability of one feature being more relevant than another given their feature importances\n    submitted by    /u/FellowOfHorses  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3o4jp/d_whats_the_probability_distribution_of_the/",
          "publishedOn": "2022-04-14T18:34:14.000Z",
          "wordCount": 264,
          "title": "[D] What's the probability distribution of the Feature importances in an ensemble method?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3nru7/discussion_collecting_feedback_for_finrl/",
          "author": null,
          "description": "Dear all,\n As a creator of the open-source FinRL project, I would like to welcome all kinds of feedback regarding financial reinforcement learning, especially about how to improve the open-source project FinRL.\n After several years of development and maintenance, we have passed the phase of caring about #stars, now we care more about #downloads, also Wall Street's adoption.\n Appreciate your feedback and sharing!\n Previously when we exposed our message on Reddit, the community was not very supportive about open-source projects' \"advertisements\". Maybe it consumed public attention and raised bad feelings. Therefore, this time we created a reddit sub-channel for FinRL-related discussions, available at: https://www.reddit.com/r/AI4Finance_FinRL/\n Best,\n Yang\n    submitted by    /u/Character-Meat-9176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3nru7/discussion_collecting_feedback_for_finrl/",
          "publishedOn": "2022-04-14T18:17:49.000Z",
          "wordCount": 198,
          "title": "[Discussion] Collecting Feedback for FinRL: Financial Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/8-Jkr120jBwSEOjE3QprtB37msW5qLklONwZxIIXnb8.jpg?auto=webp&s=cd57c9967110f6a7206244afffb6b6e6f96e9fca"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3gdx1/d_what_fun_things_in_ml_would_you_give_a/",
          "author": null,
          "description": "If you had 30 minutes to present something fun and exciting to a semi-technical audience, what would you talk about on Machine Learning that would gain interest and engagement?\n    submitted by    /u/aero_gsr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3gdx1/d_what_fun_things_in_ml_would_you_give_a/",
          "publishedOn": "2022-04-14T12:27:01.000Z",
          "wordCount": 196,
          "title": "[D] What fun things in ML would you give a presentation on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3erzw/d_evaluation_and_iteration_for_production_models/",
          "author": null,
          "description": "How do you evaluate and improve your models in production (particularly for complex modalities like text/vision/audio)? \n Good models are hard\n In my experience from managing our CNN-based text classification & NER model at a small media analytics startup, evaluating and improving models is a mess. Our domain is fairly niche and diverse, so getting enough training data has been challenging and I mix in custom synthetics & augmentations (which can cause weird model artifacts if you're not careful). It takes a lot of time to discover tricky failure cases by either 1) observing production traffic or 2) probing manually, and then it takes even more time to get the right data to improve model behavior. \n Are good models hard?\n What's your approach to model evaluation & targeted improvement? Are there any known best practices? I'm a bit at a loss here. As mentioned, I'm specifically interested in others who have deep models as an important part of their product or pipeline across any task or modality. More particularly:\n  \nHow wrong is your model? How do you test it? How would you know about errors before and after it's deployed?\n How much of your time do you spend on iterating on your models? For what kind of issue? \n Which aspects are most useful to you for improving model performance and reducing critical errors?\n  \nMaybe I'll take some of the more general ideas from my work and build them out into an evaluation & iteration framework. It's currently a hybrid web of synthetic, interactive/probing and classical approaches. Or maybe there is some approach/library that makes iteration easier without me having to do anything :)\n    submitted by    /u/flotothemoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3erzw/d_evaluation_and_iteration_for_production_models/",
          "publishedOn": "2022-04-14T10:57:44.000Z",
          "wordCount": 480,
          "title": "[D] Evaluation and iteration for production models - how?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3cgfy/d_trace_norm_in_kfac_paper_for_regularization/",
          "author": null,
          "description": "Hi,\n I doubt that the trace norm of the Kronecker product is mistaken in the KFAC paper (https://arxiv.org/abs/1503.05671).\n Shouldn't the division in the blue mark be replaced by multiplication?\n https://preview.redd.it/quoxpzubfgt81.png?width=1241&format=png&auto=webp&s=19e7b60628302f3cb37ba42944088d89d7a7bd28\n    submitted by    /u/Cautious_Proposal132  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3cgfy/d_trace_norm_in_kfac_paper_for_regularization/",
          "publishedOn": "2022-04-14T08:24:01.000Z",
          "wordCount": 161,
          "title": "[D] Trace norm in KFAC paper for regularization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u3bu3e/d_to_what_extent_can_rust_be_used_for_machine/",
          "author": null,
          "description": "I recently saw that some parts of HuggingFace ecosystem use Rust under the hood, and HF is a large ecosystem. I've also heard from some of my friends that they had to learn Rust as a first thing in an ML company (it's their first job so they couldn't explain to me exactly why).\n My questions are:\n  \nWhat are pros and cons over Python?\n Are there any good frameworks in Rust for ML?\n Are there a decent community & documentation for Rust?\n Is learning it a fun experience?\n Is it used only for deployment?\n  \n The reason I'm asking this is that I really love to learn by doing. And so, if I engaged in learning a bit of Rust for ML purposes, would I be able to create something ML-like right of the bat? It can be something as simple as MNIST classifier\n  \nTake note that I don't know anything about Rust, so these questions might seem noob-like. But I believe that the answers can be of help to others as well.\n    submitted by    /u/Icy_Fisherman7187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u3bu3e/d_to_what_extent_can_rust_be_used_for_machine/",
          "publishedOn": "2022-04-14T07:37:40.000Z",
          "wordCount": 1366,
          "title": "[D] To what extent can Rust be used for Machine Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u394zj/d_tips_for_using_ensemble_learning_with_a_small/",
          "author": null,
          "description": "I have started to look into using an ensemble of relatively shallow MLPs to predict using a small dataset (~100 training samples). I was looking specifically at bagging (bootstrap aggregation) as a possibility of improving prediction accuracy.\n I was curious if there were any heuristics for how many models to include in a bagging ensemble? \n Also, more generally, am I on the correct path, or is there a better direction given my situation? A different ensemble technique, or a different path all together?\n Any advice would be appreciated.\n    submitted by    /u/Fritos121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u394zj/d_tips_for_using_ensemble_learning_with_a_small/",
          "publishedOn": "2022-04-14T04:32:22.000Z",
          "wordCount": 365,
          "title": "[D] Tips for using Ensemble Learning with a small dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u34oh2/d_what_jax_nn_library_to_use/",
          "author": null,
          "description": "I've been exploring the jax ecosystem and its many neural network libraries but I can't seem to settle on one. The main 5 which i am considering are Trax, Objax, Equinox, Flax, and Elegy, however I would like to hear which jax NN lib you use and why.\n    submitted by    /u/Southern-Trip-1102  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u34oh2/d_what_jax_nn_library_to_use/",
          "publishedOn": "2022-04-14T00:29:42.000Z",
          "wordCount": 143,
          "title": "[D] What JAX NN library to use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u33z5d/best_sample_text_for_voice_synthesis_d/",
          "author": null,
          "description": "I'm planning to create a clone of my own voice. Is there some kind of ideal sample text to record? I need 300 sentences.\n    submitted by    /u/headwar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u33z5d/best_sample_text_for_voice_synthesis_d/",
          "publishedOn": "2022-04-13T23:53:34.000Z",
          "wordCount": 119,
          "title": "Best sample text for voice synthesis? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2y2mc/r_ml_model_to_generate_paths_lines_for_a_given/",
          "author": null,
          "description": "I am a researcher working on creating paths to indicate the primary and secondary neuronal connections in Corneal Confocal Microscopy images. The ground truth I have is images and sets of two-dimensional lines that indicate the primary and secondary paths as indicated in the image below (Ignore the green dots). The secondary and primary paths are always connected to each other.\n ​\n https://preview.redd.it/r025qcpjddt81.jpg?width=834&format=pjpg&auto=webp&s=11a641988e0c6f8c1e17290fe9588f89ef530635\n I am looking to find the most appropriate models to use for this task. The first thing that came to my mind was semantic segmentation. However, I am looking for other approaches that can be more suitable for drawing 1-pixel lines especially since the ground truth paths are indicated as 1-pixel-wide lines (1-pixel thickness) but the connections in the images have wider thicknesses.\n Any ideas for architecture or methods?\n    submitted by    /u/madr3z  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2y2mc/r_ml_model_to_generate_paths_lines_for_a_given/",
          "publishedOn": "2022-04-13T19:20:36.000Z",
          "wordCount": 502,
          "title": "[R] ML model to generate paths (lines) for a given image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2x0jd/n_followup_response_from_baai_on_a_roadmap_for/",
          "author": null,
          "description": "Source: https://www.baai.ac.cn/portal/article/index/cid/4/id/404.html\n  \nStatement on the Alleged Plagiarism by “A Roadmap for Big Model”\n It has come to our attention that the survey report “A Roadmap for Big Model” uploaded on arXiv by a BAAI team is suspected of plagiarism. Immediately upon learning of the allegations, an internal investigation was organized to confirm the issue. BAAI is also initiating an independent review by third-party experts to further asses the issue and accountabilities. As a research institution that attaches great importance to academic standards, BAAI holds a zero-tolerance policy towards academic misconduct. We express our sincerest apologies to the authors of the original papers and to all of those affected.\n The report in question constitutes a collection …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2x0jd/n_followup_response_from_baai_on_a_roadmap_for/",
          "publishedOn": "2022-04-13T18:31:30.000Z",
          "wordCount": 540,
          "title": "[N] Followup response from BAAI on \"A Roadmap for Big Model\"",
          "imageUrl": "https://external-preview.redd.it/6KE0VsnU5qw9TosCPhbXgpP4HS-1juJ34SdlTsbIKb4.jpg?auto=webp&s=1a1b351a5193f563b13f581c860f92bcdd93f169"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2vphr/p_image_restoration_using_swin_transformer_in/",
          "author": null,
          "description": "Important note: Right now, the model only supports up sampling from any dimension to at most 256 pixels. I'll likely fix this restriction in the next few days.\n A few days back, I was searching for AI-based image up sampling models in for use within an offline JavaScript app. The latest approaches, such as SwinIR were unavailable for Javascript, so I just created a notebook that converts the SwinIR model from torch to TFJS in a relatively short kaggle kernel. I believe other transformer architectures can also be ported to JS like this. This is the link to the original paper of SwinIR.\n It requires around 1 GB of RAM to run. The size of model folder is 44 MB. It is quantized to float16.\n Anyway, hope someone will find this useful for their website or some other app.\n    submitted by    /u/Deep-Station-1746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2vphr/p_image_restoration_using_swin_transformer_in/",
          "publishedOn": "2022-04-13T17:33:23.000Z",
          "wordCount": 292,
          "title": "[P] Image Restoration Using Swin Transformer in JavaScript",
          "imageUrl": "https://external-preview.redd.it/jYE0tQNmt3JdZID0Tp92vM9yoA-SV0dZM5aA4LH4luo.jpg?auto=webp&s=3fa4778b3285b13d61d93241270c647d6a34014e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2vim0/d_replacing_3x3_convolutions_with_two_2x2/",
          "author": null,
          "description": "Something that's always puzzled me is the ubiquitousness of 3x3 convolutions in computer vision. If I recall past discussion accurately, the main benefits of odd-sized kernels are that\n  \nWith the proper padding they maintain the width and height of their inputs, which makes it easier to think about/design neural network architectures. This is not possible with even kernels, unless you swallow the bullet and use asymmetric padding (which is rejected due to aesthetic reasons)\n Output pixels have a 1-to-1 mapping with input pixels (since odd-sized kernels have a proper \"center\"). This is considered a nice property -- perhaps (for instance) avoiding aliasing issues during segmentation tasks.\n  \nGiven these two points, we use 3x3 convolutions since they're the smallest odd-sized filter (exclud…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2vim0/d_replacing_3x3_convolutions_with_two_2x2/",
          "publishedOn": "2022-04-13T17:24:49.000Z",
          "wordCount": 1863,
          "title": "[D] Replacing 3x3 convolutions with two 2x2 convolutions",
          "imageUrl": "https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&s=73eb91ea5a5347f216c0f0c4d6796396826aae49"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2szhq/r_do_deep_neural_networks_contribute_to/",
          "author": null,
          "description": "submitted by    /u/MVTS_Ano  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2szhq/r_do_deep_neural_networks_contribute_to/",
          "publishedOn": "2022-04-13T15:31:56.000Z",
          "wordCount": 155,
          "title": "[R] Do Deep Neural Networks Contribute to Multivariate Time Series Anomaly Detection ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2so8x/d_open_problem_in_modern_rl_that_doesnt_need_a/",
          "author": null,
          "description": "What are open and/or interesting problems in modern reinforcement learning that can be tackled by the average PhD/PostDoc who doesn't have access to a massive compute cluster? The problem shouldn't need us to train our model for 10 months like OpenAI's Dota2 model. Please share your thoughts.\n    submitted by    /u/ginger_beer_m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2so8x/d_open_problem_in_modern_rl_that_doesnt_need_a/",
          "publishedOn": "2022-04-13T15:17:52.000Z",
          "wordCount": 380,
          "title": "[D] Open problem in modern RL that doesn't need a massive computational resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2sdkt/d_what_are_the_biggest_developments_in_cv_in_last/",
          "author": null,
          "description": "I've been helping a friend of mine learn about CV, but my knowledge starts getting spotty around 2017-2018. In this spirit I'm hoping to discuss the biggest developments in CV in the last 5 years. I know that ViTs have been developed in that time but I'm hoping to fill in my knowledge gaps!\n A list of topics, important papers, big ideas, or anything else is much appreciated!\n ​\n Edit: Thank you for the discussion everyone 🙌! I've been in and out of meetings but am reading through all responses now \n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2sdkt/d_what_are_the_biggest_developments_in_cv_in_last/",
          "publishedOn": "2022-04-13T15:04:39.000Z",
          "wordCount": 770,
          "title": "[D] What are the biggest developments in CV in last 5 years?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2pi8b/p_how_and_where_do_you_serve_your_model_using/",
          "author": null,
          "description": "Hi, I’m a machine learning platform engineer. I’ve been using, exploring and developing model deployment tools and platform for several years.\n Very often, I found that many of the tools or managed service of AI platform, are not very welcome by many users. Some think these tools are unnecessarily complicated.\n I'm currently developing a library in my free time trying to fill the gap. And I also want the library to get well integrated with most users' deployment environments.\n Would you like to share how and where do you serve your model? Using kubernetes? Self developed or existing tools? Thanks～\n P.S. If you are interested, you can visit my project to submit an issue/PR or join the discussions, welcome to help: Pinferencia\n View Poll\n    submitted by    /u/Remote_Cancel_7977  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2pi8b/p_how_and_where_do_you_serve_your_model_using/",
          "publishedOn": "2022-04-13T12:45:45.000Z",
          "wordCount": 381,
          "title": "[P] How and where do you serve your model? Using kubernetes, docker, metal? Self developed or existing tools?",
          "imageUrl": "https://external-preview.redd.it/1DZ3f-7YqPBqW5XsOeXnsBLZVKRUXGtrF4Nx0ejYLpM.jpg?auto=webp&s=ecf81d8d9225757724de200608fc1cf1ca392519"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2np4x/p_i_created_a_youtube_thumbnail_dataset_and_need/",
          "author": null,
          "description": "Hi guys! I recently created & published a dataset of YouTube video thumbnails on Kaggle (YouTube Thumbnail Dataset), I've tried to make the dataset as diverse as possible, It contains thumbnails from all varieties of YouTube channels. This dataset goes hand in hand with another dataset (containing YouTube video annotations) that I created, namely YouTubers Saying Things.\n The dataset contains 91 unique YouTube channels, and 10 categories, these categories are assigned by me manually to these channels. (Comedy, Science, Automobile, VideoGames, Food, Entertainment, Informative, Blog, News, Tech)\n All kinds of feedback and criticism are welcome, and also if you guys want some particular channel to be included in both these datasets, feel free to comment on this post, or raise an issue on the Github repositories for both these datasets, I will surely add them in the next version.\n Links to the datasets:\n  \nYouTubers Saying Things Kaggle, Github\n YouTube Thumbnail Dataset Kaggle, Github\n  \n   submitted by    /u/alcatraz2217  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2np4x/p_i_created_a_youtube_thumbnail_dataset_and_need/",
          "publishedOn": "2022-04-13T11:00:24.000Z",
          "wordCount": 361,
          "title": "[P] I created a YouTube Thumbnail Dataset, and need some insight",
          "imageUrl": "https://external-preview.redd.it/dzM_8rsfwC2Gm1fzlnioer3Q4FF3TCJIIyk0AcjosPU.jpg?auto=webp&s=d3b657e6b97e89fd4cf4337dd6d8a587539fff47"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2mbus/improve_xgboost_classification_algorithm_with/",
          "author": null,
          "description": "Hi, I am doing researches about transfer learning for XGboost. \n I am currently working with a small dataset from a company in Spain (short history) and the scoring is poor. I have worked before with the same company in France and the scoring was great as I had plenty of data thanks to a big history. How could I improve my score with the data from Spain with the help of data from France ? \n Could I use transfer learning, or data mutualization, or data augmentation ? If anyone has faced before a similar problem, or has read some papers about it, I would love to hear about it. \n Thank you!\n    submitted by    /u/Cutset  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2mbus/improve_xgboost_classification_algorithm_with/",
          "publishedOn": "2022-04-13T09:23:57.000Z",
          "wordCount": 343,
          "title": "Improve XGboost classification algorithm with small dataset, based on similar bigger dataset ? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2k8xh/r_a_modern_selfreferential_weight_matrix_that/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2k8xh/r_a_modern_selfreferential_weight_matrix_that/",
          "publishedOn": "2022-04-13T06:48:58.000Z",
          "wordCount": 126,
          "title": "[R] A Modern Self-Referential Weight Matrix That Learns to Modify Itself",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2goyo/d_what_are_some_interesting_hidden_stuff_about/",
          "author": null,
          "description": "Hey all,\n Im trying to get up to date with Deep Learning literature, so the last week I was going through CNNs. Here's a general view of what Ive learned so far.\n  \nLarge filters suck, you can get better accuracy with smaller filters and more non linearities\n \nDepth is the most important for CNNs over width or filter sizes.\n \nReLU activation is generally better, as Sigmoid/tanh gradients tend to fall off towards the ends\n \nConvolution layers are only translation invariant. Stacking multiple features together and passing them through MaxPool helps rotational invariance and scaling although not completely \n \nResidual connection help address vanishing gradient and help improve the overall training procedure\n \nInception models worked well, as they mixed different filter sizes together helping the model learn diverse features\n \nMost current work is with Transformers, although Im not sure why. ConvNext shows similar performance can be achieved through large CNNs\n \n Do add to this if I missed anything, or if there's anything you don't know about\n    submitted by    /u/Bibbidi_Babbidi_Boo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2goyo/d_what_are_some_interesting_hidden_stuff_about/",
          "publishedOn": "2022-04-13T03:10:53.000Z",
          "wordCount": 1595,
          "title": "[D] What are some interesting hidden stuff about CNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u2e4hy/d_how_to_create_scenes_with_text_makeascene/",
          "author": null,
          "description": "The authors of Make-A-Scene propose a novel text-to-image method that leverages the information from an additional input condition called a “scene” in the form of segmentation tokens to improve the quality of generated images and enable scene editing, out-of-distribution prompts, and text-editing of anchor scenes.\n As for the details, let’s dive in, shall we?\n Full summary: https://t.me/casual_gan/284\n Blog post: https://www.casualganpapers.com/text-to-image-vqvae-scene-generation/Make-A-Scene-explained.html\n Make-A-Scene\n arxiv / code (by Casual GAN Papers Community)\n Join the discord community and follow on Twitter for weekly AI paper summaries!\n    submitted by    /u/KirillTheMunchKing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u2e4hy/d_how_to_create_scenes_with_text_makeascene/",
          "publishedOn": "2022-04-13T00:59:02.000Z",
          "wordCount": 219,
          "title": "[D] How to create scenes with text - Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors, a 5-minute paper summary by Casual GAN Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u27xf2/n_substantial_plagiarism_in_baais_a_road_map_for/",
          "author": null,
          "description": "BAAI recently released a two hundred page position paper about large transformer models which contains sections that are plagiarized by over a dozen other papers.\n In a massive fit of irony, this was found by Nicholas Carlini, a research who (among other things) is famous for studying how language models copy outputs from their training data. Read the blog post here\n    submitted by    /u/StellaAthena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u27xf2/n_substantial_plagiarism_in_baais_a_road_map_for/",
          "publishedOn": "2022-04-12T19:58:40.000Z",
          "wordCount": 512,
          "title": "[N] Substantial plagiarism in BAAI’s “a Road Map for Big Models”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u24ngz/d_whats_the_status_of_live_speechtospeech/",
          "author": null,
          "description": "I've been trying to find information about the subject, but almost every result is TTS, and the only example of what I actually want (Respeecher) costs 2 grand a year. Are there any (preferably open-source) other alternatives?\n    submitted by    /u/UncertainOutcome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u24ngz/d_whats_the_status_of_live_speechtospeech/",
          "publishedOn": "2022-04-12T17:34:20.000Z",
          "wordCount": 270,
          "title": "[D] What's the status of live speech-to-speech conversions? (not TTS)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u22sv1/comparison_of_workshops_at_major_conferences_d/",
          "author": null,
          "description": "I understand that workshop quality is dependent more on the workshop itself rather than the host conference. But, in general, how are workshops from CVPR, NeurIPS, ICLR, ICML, etc. viewed by the community in relation to one another?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u22sv1/comparison_of_workshops_at_major_conferences_d/",
          "publishedOn": "2022-04-12T16:14:44.000Z",
          "wordCount": 293,
          "title": "Comparison of workshops at major conferences. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u225iw/project_leniax_a_lenia_simulation_library_powered/",
          "author": null,
          "description": "Hi everyone!\n I'm really happy to finally publish the work I've been doing on the Cellular Automata called Lenia. It is a JAX library called Leniax and allows one to simulate thousands of simulations in parallel using CPU, GPU, or TPU.\n With it, you can:\n  \nSimulate Conway's Game of Life\n Simulate multiple Lenia simulations in parallel\n Use gradient descent to search for Continuous CA parameters\n Launch a QD search to discover a ton of diversity in Lenia.\n  \nCheck out the blog post for some visual results\n The main goal of this work was to advance the state of automatic discovery for those systems. 10 months ago, I bet on QD to do so, turns out it indeed works! QD algorithms really rock!\n The code is completely open-source with all the examples, notebooks, and even experiments I ran. (See the doc for more links)\n I would love to have feedback on this and of course, if you find that subject interesting, engage with our community!\n Cheers!\n    submitted by    /u/morgangiraud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u225iw/project_leniax_a_lenia_simulation_library_powered/",
          "publishedOn": "2022-04-12T15:46:31.000Z",
          "wordCount": 498,
          "title": "[Project] Leniax - A Lenia simulation library powered by JAX",
          "imageUrl": "https://external-preview.redd.it/615iFqqZGA67mbZiQWw6HCj2AOLwVrWugdMV7Amdmmo.jpg?auto=webp&s=074ecbbc8f6c41700dacf3c9607f4f8747a9e194"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u21tcd/d_effective_image_preprocessing_techniques_for/",
          "author": null,
          "description": "So I am doing some object detection on Pavement Defects. I've already collected the data with some annotations but the model is performing rather poorly. For example, the `maP` is about `0.12` for the whole data.\n By examining the data, I think one of the reasons is that some of the defects such as cracks, or faded pavement markings are not so clear and either casted by a shadow or too bright from the sun.\n Image Example #1\n Or from motion blur\n Image Example #2\n Is there any image preprocessing technique aside maybe from CLAHE that could be applied? Moreover, I am currently using YOLOv5 for this.\n    submitted by    /u/sarmientoj24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u21tcd/d_effective_image_preprocessing_techniques_for/",
          "publishedOn": "2022-04-12T15:31:27.000Z",
          "wordCount": 826,
          "title": "[D] Effective Image Pre-Processing Techniques for Enhancing Defects in an Image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1wjhx/p_the_copent_package_v023_available_on_pypi_now/",
          "author": null,
          "description": "The copent package implements the method for estimating copula entropy (mutual information) and transfer entropy (conditional mutual information / conditional independence).\n This version add a new feature (an argument 'mode') for dealing with large data when memory is limited.\n Github: https://github.com/majianthu/pycopent\n PyPI: https://pypi.org/project/copent/\n any comments are welcome.\n    submitted by    /u/majianthu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1wjhx/p_the_copent_package_v023_available_on_pypi_now/",
          "publishedOn": "2022-04-12T11:11:03.000Z",
          "wordCount": 151,
          "title": "[P] the copent package v0.2.3 available on PyPI now",
          "imageUrl": "https://external-preview.redd.it/SRxVo2wZFg9yrGulTKBIfCFE521LCeTD3tgsElbcLFM.jpg?auto=webp&s=081362182c1cf325f8745069a9852591736571f5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1vqj7/d_feedback_on_a_worked_continuous_deployment/",
          "author": null,
          "description": "Hey everyone! At ZenML, we released today an integration that allows users to train and deploy models from pipelines in a simple way. I wanted to ask the community here whether the example we showcased makes sense in a real-world setting:\n Context\n ZenML is an extensible, open-source MLOps framework to create production-ready machine learning pipelines. Built for data scientists, it has a simple, flexible syntax, is cloud- and tool-agnostic, and has interfaces/abstractions that are catered towards ML workflows. Seldon Core is a production grade open source model serving platform. It packs a wide range of features built around deploying models to REST/GRPC microservices that include monitoring and logging, model explainers, outlier detectors and various continuous deployment strategies such…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1vqj7/d_feedback_on_a_worked_continuous_deployment/",
          "publishedOn": "2022-04-12T10:21:20.000Z",
          "wordCount": 558,
          "title": "[D] Feedback on a worked Continuous Deployment Example (CI/CD/CT)",
          "imageUrl": "https://external-preview.redd.it/2DdZUH82S_pG03o_6QA8KFOOYEtP4kncEmD71nt5LcI.jpg?auto=webp&s=2f3f2da286e6c6ade38a83f41e1e7a5565aa676b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1uunt/d_can_we_decrease_the_training_time_of_a_deep/",
          "author": null,
          "description": "I am working in the retail domain atm, and train a lot of image classifiers. I have always used imagenet as pretrained to train my model upon. \n I thought it would be straightforward to train a backbone on a big retail dataset(1000+ classes), and then use that as pretrained and it'll reduce the time it takes for my models to generalize.\n Turns out, the model took more epochs to train when using the retail backbone, then the imagenet one. \n Isn't this counter-intuitive? What else can I do to make by backbone better?\n    submitted by    /u/lMAObigZEDONG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1uunt/d_can_we_decrease_the_training_time_of_a_deep/",
          "publishedOn": "2022-04-12T09:20:11.000Z",
          "wordCount": 368,
          "title": "[D] Can we decrease the training time of a deep learning model by using a domain specific pretrained backbone instead of the standard imagenet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1sofz/d_removing_unpredictable_samples_from_a_training/",
          "author": null,
          "description": "Hi,\n I have a fairly interesting project that I am working on. I have a model that has some samples which are completely unpredictable, random noise, and some that are reliably predictable.\n How would you go about separating out the samples which can be predicted, identifying them going forward, and retraining on a cleaned dataset with only those samples?\n Interested to see someone else's approach to this.\n Edit: I forgot to mention that my data is from an embedding matrix from ordinal categorical features.\n    submitted by    /u/Katapilla_Killa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1sofz/d_removing_unpredictable_samples_from_a_training/",
          "publishedOn": "2022-04-12T06:43:28.000Z",
          "wordCount": 499,
          "title": "[D] Removing Unpredictable Samples from a Training Set",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1qgcm/d_whats_your_experience_with_modelagnostic/",
          "author": null,
          "description": "There is the original paper and there was a subsequent paper by other authors titled: On the Convergence Theory of Debiased Model-Agnostic Meta_Reinforcement Learning \n I've been working on implementing the latter paper on the HalfCheetah environment. However, my attempts have been unsuccessful so far (I know the authors provided the code, but I am trying to write my own code to check my understanding). I'd like to know any tips/tricks that anyone can share and just to know about people's experiences, especially using MAML for RL.\n    submitted by    /u/carlml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1qgcm/d_whats_your_experience_with_modelagnostic/",
          "publishedOn": "2022-04-12T04:24:10.000Z",
          "wordCount": 202,
          "title": "[D] What's your experience with Model-Agnostic Meta-Learning in RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1qfxq/how_to_deal_with_the_fact_that_whatever_idea_i/",
          "author": null,
          "description": "I'm always having these ideas for projects and papers, then I look around a bit, and I find someone that has already studied that idea and published it.\n It's genuinely annoying, It's been 6 months now, and all the papers are newly published (2021 mostly) so It's even more annoying.\n How do you deal with that ? and How do you find a niche that no one is touching.\n I just started a PhD, so It's really stressing me out. I feel like I'll never be able to advance on my thesis, and that I should just quit, because better work has already been done.\n    submitted by    /u/AlanRoofies  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1qfxq/how_to_deal_with_the_fact_that_whatever_idea_i/",
          "publishedOn": "2022-04-12T04:23:12.000Z",
          "wordCount": 1293,
          "title": "How to deal with the fact that whatever idea I have has already been published.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1oh1e/p_faster_version_of_cv2bfmatchercv2norm_l2/",
          "author": null,
          "description": "Hi there, in the case if any of you use the openCV BFMatcher with NORM_L2, you can try to use my recent pet project: https://github.com/kmkolasinski/fast-bfmatcher \n Basically the speed-up is achieved by using faster replacement for BLAS, a BLIS library and some custom implementations written in C and cython.\n    submitted by    /u/kmkolasinski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1oh1e/p_faster_version_of_cv2bfmatchercv2norm_l2/",
          "publishedOn": "2022-04-12T02:30:49.000Z",
          "wordCount": 235,
          "title": "[P] Faster version of cv2.BFMatcher(cv2.NORM_L2) optimized for keypoints matching",
          "imageUrl": "https://external-preview.redd.it/llOShRBa0UBKBDTaEs2yWiKGXsEWMb8q6lzeRocyxHc.jpg?auto=webp&s=e4e825f876472bb8b5fa07324582cd9660663b68"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1nt7m/d_are_there_any_comparison_studies_on_learning/",
          "author": null,
          "description": "My current research heavily involves generative vision transformers and after some experimentation it seems like the choice of a LR scheduler is a crucial factor for proper convergence. Does anyone know of any comparison studies done recently that explore various types of schedulers for generative tasks?\n    submitted by    /u/Megixist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1nt7m/d_are_there_any_comparison_studies_on_learning/",
          "publishedOn": "2022-04-12T01:58:05.000Z",
          "wordCount": 1169,
          "title": "[D] Are there any comparison studies on learning rate schedules for generative transformers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1mgxu/n_finetuning_layoutlm_v2_for_invoice_recognition/",
          "author": null,
          "description": "With the advent of deep learning models, automated data extraction is becoming more accessible. In this article, we demonstrate step-by-step how to fine-tune layoutLM V2 on invoices starting from data annotation to model training and inference. \n Enjoy the read and if you have any questions, leave them below.\n    submitted by    /u/UBIAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1mgxu/n_finetuning_layoutlm_v2_for_invoice_recognition/",
          "publishedOn": "2022-04-12T00:51:26.000Z",
          "wordCount": 206,
          "title": "[N] Fine-Tuning LayoutLM v2 For Invoice Recognition",
          "imageUrl": "https://external-preview.redd.it/fyAbu9z9siTBA9TKfpPoKXdl3qNr7T27W8b5wq7SLZw.jpg?auto=webp&s=62d119c6e9a5376e91b069eb934b783d243b93fc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1jbr2/r_transformers_replicate_hippocampal/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2112.04035\n Yes, the paper is cautious about comparing the model one-to-one to the brain\n  \n“Note, we are not saying the brain is closely related to transformers because it learns the same neural representations, instead we are saying the relationship is close because we have shown a mathematical relationship between transformers and carefully formulated neuroscience models of the hippocampal formation.”\n  \nWhile objections like \"its just correlation/relation, its not exactly the same!!\" are true to an extend, its still a very unexpected observation that, they're even remotely similar. Needless to say, Transformers were not inspired from the brain - and as more evidence collates (https://www.nature.com/articles/s42003-022-03036-1 --> Activations are linearly correlatable) it does feel mysterious; perhaps atleast some of the systems used by the brain converge on an efficient pattern discovered by our backpropogated friends...\n [insert 'coincidence? I think not!' meme]\n    submitted by    /u/Competitive-Rub-1958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1jbr2/r_transformers_replicate_hippocampal/",
          "publishedOn": "2022-04-11T22:19:32.000Z",
          "wordCount": 297,
          "title": "[R] Transformers replicate Hippocampal representations; notably place and grid cells in the brain",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1c8ga/d_what_is_the_smallest_most_capable_generative/",
          "author": null,
          "description": "I'm looking for a generative-LM equivalent of an EfficientNet-Lite, for inference on devices with limited to no VRAM. I know about some popular ones like DistilGPT2. But it's been 2 years after its release. Surely, someone improved their size/performance ratio, right... right?\n Thank you for your time. 🤗\n    submitted by    /u/Deep-Station-1746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1c8ga/d_what_is_the_smallest_most_capable_generative/",
          "publishedOn": "2022-04-11T16:55:07.000Z",
          "wordCount": 157,
          "title": "[D] What is the smallest, most capable, generative language model available now?",
          "imageUrl": "https://external-preview.redd.it/RFHXebL_232fV370fkJRpy87aB3f8NR3MgM_d32HuPo.jpg?auto=webp&s=b68cd56c65a059196f9737590029097c589cef2c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u1bu8z/how_would_you_rank_major_tech_companies_research/",
          "author": null,
          "description": "This is just for fun, not to be taken too seriously. But I'm curious what are the reputations among the community for various research divisions (specifically AIML) of major companies, ie: Google, Facebook/Meta, Microsoft, Amazon, NVIDIA, IBM, etc.\n My perceived (albeit naive) view is Google > Facebook > MSR are top tier. Don't know much about the others. But I've read that some people consider MSR most prestigious due to their academic environment. But I've seen that Google and FB dominate in terms of major publications, ie: vision transformers are associated with Google. \n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u1bu8z/how_would_you_rank_major_tech_companies_research/",
          "publishedOn": "2022-04-11T16:37:33.000Z",
          "wordCount": 723,
          "title": "How would you rank major tech companies' research labs for prestige? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u19io6/p_squirrel_a_new_os_library_for_fast_flexible/",
          "author": null,
          "description": "Hi all, \n Today we open-sourced Squirrel, a data infrastructure library that my colleagues and I have been working on over the past 1.5 years: https://github.com/merantix-momentum/squirrel-core\n We’re a team of ~30 ML engineers developing machine learning solutions for industry and research. Across all our projects, we need to load large-scale data in a fast and cost-efficient way, while keeping the flexibility to work with any possible dataset, loaded from local storage, remote data buckets or via APIs such as HuggingFace. Not finding what we were looking for, we decided to build it ourselves. \n Squirrel has already proven its value in our deep learning projects at Merantix Momentum and shows competitive benchmark results (check them out here). \n We’re super excited to share it with the OSS community and hope that you can benefit from it as well! \n Looking forward to hearing your feedback and questions :)\n    submitted by    /u/Nextpenade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u19io6/p_squirrel_a_new_os_library_for_fast_flexible/",
          "publishedOn": "2022-04-11T14:50:45.000Z",
          "wordCount": 428,
          "title": "[P] Squirrel: A new OS library for fast & flexible large-scale data loading",
          "imageUrl": "https://external-preview.redd.it/nBo-oTq4WtunYq6ceVofwf4ptrB3NQugxyXvVUGuVJ0.jpg?auto=webp&s=9d1c331c0db5fd89dfa002595c452f87f6f2b1db"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u18ryi/p_renting_lots_of_gpus_100200_in_single/",
          "author": null,
          "description": "I want to apply an already trained ML model on a huge textual data set. I have funds to rent Cloud GPUs, but have not much experience using them. Preferably, I do the setting up of the environment only once (downloading of the data, model, software packages, etc) only once and then simply send ~100-200 scripts each to their own GPU for processing. Then at the end everything is in the same location and I can easily send back the final result file (~100-200 output files concatenated together) back to my PC.\n Any advice on how to do that? All GPU renting servers only have 1-8 GPUs per server and do not (seem) to allow for sharing of the environment, which seems very inefficient to me. All comments are appreciated.\n    submitted by    /u/Intelligent-End2673  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u18ryi/p_renting_lots_of_gpus_100200_in_single/",
          "publishedOn": "2022-04-11T14:15:57.000Z",
          "wordCount": 486,
          "title": "[P] Renting lots of GPUs (100-200) in single environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u153d3/rp_algorithmic_stability_of_minibatch_sgd/",
          "author": null,
          "description": "Hi, was wondering if anyone else has looked into \"A PAC-Bayesian Analysis of Randomized Learning\n with Application to Stochastic Gradient Descent\" and in particular eqn. 2, which is the derivation of Section 3.5 of \"Train faster, generalize better: Stability of stochastic gradient descent\" adapted for the case where the underlying loss we are interested in guaranteeing generalisation for is upper bounded by M (rather than 1 as assumed by Hardt et al).\n In the case of minibatch SGD, the number of datapoints n becomes the number of minibatches, as ideally one would like to reduce the number of steps T by maximizing the learning rate, which requires maximizing the minibatch size for the loss to actually converge to 0 on the training data. \n However, what I am unsure about is, specifically for the classification task where we typically minimize the cross-entropy objective, whether the cross-entropy objective is an upper bound on any kind of M-bounded loss function. In the ideal world, I would like to show that it upper bounds the 0-1 loss which means the cross-entropy over the dataset is an upper bound on the classification accuracy and any generalization statement automatically becomes a statement about the very practical metric of accuracy. \n Such a statement about cross-entropy upper-bounding 0-1 is made in Section 3C of \"Theoretical Issues in Deep Networks: Approximation, Optimization and Generalization\". However, one can provide a counterexample in the limit of the softmax \"temperature\" parameter where the predicted class distribution becomes uniform, in the case of 2 classes, for the typical case of log being the natural logarithm (it is no longer a counter-example if log base 2 is used).\n I haven't been able to show or find proof that this statement \"xent >= 0-1\" is true (for some logarithm base and some number of classes) and was hoping that someone might have.\n    submitted by    /u/wakeupandshave  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u153d3/rp_algorithmic_stability_of_minibatch_sgd/",
          "publishedOn": "2022-04-11T11:01:01.000Z",
          "wordCount": 394,
          "title": "[R][P] Algorithmic stability of minibatch SGD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u12eoc/r_channel_augmented_joint_learning_for/",
          "author": null,
          "description": "Since going open source in March 2020, MindSpore gone from strength to strength. The deep learning framework has been downloaded by over 1.2 million users; algorithms running on MindSpore have been published in AI journals or presented at conferences; and countless developments have been released in device-edge-cloud scenarios to transform business fields, such as intelligent manufacturing, cloud, wireless, data communication, energy, and consumer business. \n Built on extensive experience from the scientific, academic, and industrial sectors, MindSpore-based AI papers accounted for 11% of all AI papers in October 2021, ranking No.2 worldwide by month, and No.3 worldwide in Q4 2021. In this blog post, based on a paper published in ICCV 2021 by Professor Mang Ye of Wuhan University, we intro…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u12eoc/r_channel_augmented_joint_learning_for/",
          "publishedOn": "2022-04-11T07:55:32.000Z",
          "wordCount": 822,
          "title": "[R] Channel Augmented Joint Learning for Visible-Infrared Recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0xgq5/r_looking_for_ideas_in_pretraining_a_rl_agent/",
          "author": null,
          "description": "Hi all,\n I've been working on reinforcement learning lately, but wanted to come to the general ML subreddit to seek inspiration from other disciplines.\n I've been working on strategies to decrease the training time for my real-world inverted pendulum experiment. Specifically, I am trying to pre-train the Q network in a simulation before deploying.\n The strategy that I have found most successful right now is this:\n start with randomly generated weights\n REPEAT OF AN EPOCH:\n - Load new_weights to Q Network\n - initialize an environment with randomly generated parameters (i.e. random mass, lengths, etc).\n - Train agent on environment for 100 episodes\n - Save new_weights\n I have tried a variety of strategies to add a little bit more control over this process. I've tried a soft update that never showed improvement.\n W = old_weights * (1 - alpha) + new_weights * alpha \n I have tried an additive update which was slightly successful. Measured the success of each network as the sum of rewards over the epoch.\n A = (old_R)/(old_R+new_R) ; B = (new_R)/(old_R+new_R) W = old_weights * A + new_weights * B \n But none of these work as well as just using the most recent weights. I've included some results if anyone's interested. The first graph is three test trials with random initial weights, the second graph is with pre-trained weights.\n This is a pretty hand-wavy way of doing this, does anyone have any suggestions to do this better?\n ​\n https://preview.redd.it/9mnewmibbts81.png?width=375&format=png&auto=webp&s=a6ff866a31987375d276d12f69dbe2af40380bf4\n https://preview.redd.it/096n7ctcbts81.png?width=375&format=png&auto=webp&s=b19d800fbb416fca288e86640d9458c8993e0759\n ​\n    submitted by    /u/nickthorpie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0xgq5/r_looking_for_ideas_in_pretraining_a_rl_agent/",
          "publishedOn": "2022-04-11T02:38:36.000Z",
          "wordCount": 525,
          "title": "[R] Looking for Ideas in Pre-training a RL Agent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0x8lr/p_recommendations_for_high_frequency_multivariate/",
          "author": null,
          "description": "Hey there! I'm looking for advice on datasets to use for a project. We are looking for the following traits:\n ​\n 1) Multivariate (at least 3 or 4, and probably no more than 50 or 100 as an upper bound).\n 2) High frequency (Ideally at least once every 5-10 minutes)\n 3) We need to have some notion of an underlying 'state' of the data for certain windows. E.g. in an energy setting, period X was the 'family at home using appliances' state. Or in the healthcare setting, period X is 'the patient is in a stable state' while period Y is something like 'the patient experiences a cardiac event'\n ​\n ​\n Nice to have:\n 4) It'd be great if some features had some level of seasonality while others didn't.\n ​\n ​\n Do folks have any recommendations for datasets that meet some (or hopefully all) of the criteria? I did some light pursuing on UCI, but it seems like much of it is not high frequency enough, and/or doesn't have some notion of underlying states.\n    submitted by    /u/CS_Student95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0x8lr/p_recommendations_for_high_frequency_multivariate/",
          "publishedOn": "2022-04-11T02:25:48.000Z",
          "wordCount": 286,
          "title": "[P] Recommendations for high frequency multivariate time series data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0vqjt/d_what_to_do_when_the_authors_dont_release_source/",
          "author": null,
          "description": "Hello,\n I am currently working on a research paper that I aim to publish at a reputable conference shortly. In our work, we borrow a feature engineering technique from one of the papers that have not been previously applied to the domain (time series AD) before that paper. However, the authors haven't released the source code of their implementation of the model (but the feature engineering technique is publicly available). I feel like that is an important baseline and just failing to include it would get my paper rejected. I have contacted all the authors for the source code, but none of them responded. The architecture they use is a fairly complicated one and would be very difficult to implement on my own. How do I go about this situation? My advisor told me I can just include a few points on the footnote on why we don't include this as a baseline. Those being:\n  \nNo open-source implementation\n Contacted the authors, didn't receive a response\n The paper has not been published, only uploaded to arxiv.\n  \nAny help is appreciated!\n    submitted by    /u/mythrowaway0852  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0vqjt/d_what_to_do_when_the_authors_dont_release_source/",
          "publishedOn": "2022-04-11T01:04:44.000Z",
          "wordCount": 1366,
          "title": "[D] What to do when the authors don't release source code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0pnhf/d_machine_learning_wayr_what_are_you_reading_week/",
          "author": null,
          "description": "This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.\n Please try to provide some insight from your understanding and please don't post things which are present in wiki.\n Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.\n Previous weeks :\n  \n 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 131-140 \n  \n Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 Week 131 \n  Week 2 Week 1…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0pnhf/d_machine_learning_wayr_what_are_you_reading_week/",
          "publishedOn": "2022-04-10T20:00:05.000Z",
          "wordCount": 370,
          "title": "[D] Machine Learning - WAYR (What Are You Reading) - Week 135",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0o0yy/n_dalle_2_explained/",
          "author": null,
          "description": "submitted by    /u/giugiacaglia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0o0yy/n_dalle_2_explained/",
          "publishedOn": "2022-04-10T18:43:10.000Z",
          "wordCount": 381,
          "title": "[N]: Dall-E 2 Explained",
          "imageUrl": "https://external-preview.redd.it/n8IIbUhDqblAvhWT_2j8I3rFpnYCJHu2EXvFcwTsUBw.png?format=pjpg&auto=webp&s=659ec2bd0f15d62be0f1f7c4958ac6240b8e9bbc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0l0mr/r_use_static_classifiers_for_dynamic_point_cloud/",
          "author": null,
          "description": "submitted by    /u/pinter69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0l0mr/r_use_static_classifiers_for_dynamic_point_cloud/",
          "publishedOn": "2022-04-10T16:22:11.000Z",
          "wordCount": 384,
          "title": "[R] Use static classifiers for dynamic point cloud tasks (3D) and use action classifiers for temporal anomaly detection (2D) - Link to a free online lecture by the author in comments",
          "imageUrl": "https://preview.redd.it/83rwnhi09qs81.png?auto=webp&s=c728fcc9ebb1e12e39638b511e1e2824620098dc"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0jcur/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0jcur/d_simple_questions_thread/",
          "publishedOn": "2022-04-10T15:00:11.000Z",
          "wordCount": 742,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0hxt3/p_image_similarity_metrics_or_algorithms/",
          "author": null,
          "description": "I want to perform image similarity between images from frames of 2 different movie trailers.\n I am currently using SSIM and VGG 16 individually. But ssim does not capture color differences and VGG 16 isn't capturing structural integrity.\n I can use both together, but I wanted to know if there is any metric or algorithm which can capture both together with less discrepancies and can capture both together.\n Will appreciate any help. Thank you!\n    submitted by    /u/terminatorash2199  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0hxt3/p_image_similarity_metrics_or_algorithms/",
          "publishedOn": "2022-04-10T13:47:40.000Z",
          "wordCount": 257,
          "title": "[P] image similarity metrics or algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0gzj1/r_interested_in_a_postdoctoral_position_bridging/",
          "author": null,
          "description": "Recurrent neural networks for brain time series - Sano Centre for Computational Personalised Medicine\n    submitted by    /u/alecrimi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0gzj1/r_interested_in_a_postdoctoral_position_bridging/",
          "publishedOn": "2022-04-10T12:53:33.000Z",
          "wordCount": 128,
          "title": "[R] Interested in a Postdoctoral position bridging machine learning and neuroimaging?",
          "imageUrl": "https://external-preview.redd.it/S-7Mycs1ox3O3jblU7djEweOTY6MG2OB2syVwOCtbEQ.jpg?auto=webp&s=8b371d6c6e8fa35b8c76f7e420181abcfc2f9a56"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0fy91/r_ml_with_intermediate_mathematics_vaes_with/",
          "author": null,
          "description": "Hi everyone, I'd like to share with you an exciting upcoming live series by Prof. Richard Xu of Hong Kong Baptist University. If you're interested, please click here to register!\n Description:\n \"I have been planning to start a machine learning live series on topics that involve some intermediate mathematics, so I can help you to clarify some concepts. In order to fully grasp these concepts, you need to have sound knowledge of linear algebra, calculus, statistics and probability. However, if you just want to come and hear it for fun, please do so as well!\n The first topic is variational autoencoders with normalized flow, which I'll fully explain its beautiful mathematics over a period of a few sessions. You can find my notes on my GitHub site:\n https://github.com/roboticcam/machine-learning-notes/blob/master/files/vb_nf.pdf\n I will post the Zoom link to the registered participants.\n Please join us!\"\n    submitted by    /u/ML_Live_Series  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0fy91/r_ml_with_intermediate_mathematics_vaes_with/",
          "publishedOn": "2022-04-10T11:47:09.000Z",
          "wordCount": 265,
          "title": "[R] ML with Intermediate Mathematics: VAEs with Normalized Flow (live series)",
          "imageUrl": "https://external-preview.redd.it/oKKtQehlimflM197aRFqGePysY5QuTwX9irvWGFhjZA.jpg?auto=webp&s=00f41e12502ebdf989fa76871a5378f265b9253d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0fb2m/research_issues_visualising_a_resnet/",
          "author": null,
          "description": "Hi all,\n We have a model used in cardiac MRi imaging, it is used to select the best image in a series of images. It consists of images -> Resnet -> LSTM -> output.\n The heatmap we generate from the Resnet alone shows output like the image attached, instead of actual anatomy, there is only little squares. We think this is likely due to the residual in the Resnet because it is not present in a VGG, but does anyone else have a better explanation, and an idea of how to visualise a Resnet?\n Resnet Saliency Map\n    submitted by    /u/Radiology_AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0fb2m/research_issues_visualising_a_resnet/",
          "publishedOn": "2022-04-10T11:00:37.000Z",
          "wordCount": 222,
          "title": "[research] Issues visualising a Resnet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0e7n8/r_critical_analysis_of_deconfounded_pretraining/",
          "author": null,
          "description": "Hi reddit, happy to share our new paper \"Critical analysis of deconfounded pretraining to improve visio-linguistic models\".\n In a nutshell, it's on the problem of out-of-distribution performance for visio-linguistic models, and it takes a closer look / surfaces some issues with an existing technique for improving OOD performance by doing automatic deconfounding (inspired by the causality framework of Structural Causal Models).\n ​\n  \nPaper: https://www.frontiersin.org/articles/10.3389/frai.2022.736791/full\n Code: https://github.com/Natithan/p1_causality\n Abstract: \n An important problem with many current visio-linguistic models is that they often depend on spurious correlations. A typical example of a spurious correlation between two variables is one that is due to a third variable causing …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0e7n8/r_critical_analysis_of_deconfounded_pretraining/",
          "publishedOn": "2022-04-10T09:33:54.000Z",
          "wordCount": 465,
          "title": "[R] Critical analysis of deconfounded pretraining to improve visio-linguistic models",
          "imageUrl": "https://external-preview.redd.it/TAGvv79NiijwKxfyNPikPCSnhXUmDO4oPUJbv76dfi0.jpg?auto=webp&s=5b66228698688ca6fb3f24635b929041d9d70712"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0ckoe/best_papers_that_solve_novel_problems_d/",
          "author": null,
          "description": "We often talk about how the publish-or-perish paradigm leads to constant minor improvements on the same problems (Image classification, text generation, etc). What are some of the best papers that do the opposite? Rather than solving known problems in a marginally better way, they solve a new problem with known (or modified) methods.\n    submitted by    /u/SuspiciousWalrus99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0ckoe/best_papers_that_solve_novel_problems_d/",
          "publishedOn": "2022-04-10T07:26:12.000Z",
          "wordCount": 488,
          "title": "Best Papers That Solve Novel Problems? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0cgmz/discussion_advice_on_training_document_layout/",
          "author": null,
          "description": "So, a bit of background, I am doing an RnD project in the area of improving the layout analysis of scientific documents. The proposed method is to use an active learning loop on standard object detection models and target those classes/layouts which are performing poorly and train the model based on them.\n Now, we have some selection strategies based on submodular selection functions to target the pages we want. I also have set up code to extract embeddings which will help me do the selection. But I don't have prior experience in active learning, especially setting it up with detectron2, because it seems to register a dataset to train, and it is really difficult to change dynamically in the middle of training, which is my use case.\n So I need some advice on the following:-\n  \nThe document analysis datasets are huge, DocBank is 50GB of images alone. How can I effectively store the embeddings in memory when I will call my selection algorithms mentioned above?\n How to set up an active learning loop in detectron2 for object detection. Or are there any alternatives? Some resources/code would be better\n There is some literature evidence suggesting that simple CNN backbone embeddings represent an image better than FasterRCNN or MaskRCNN embeddings. Specifically, this paper seems to be working on spliced image retrieval and it claims the following. Any thoughts/prior experience on this?\n Finally, is there any evidence supporting improvement in accuracy/precision in object detection using active learning? Or are there some better training paradigms?\n  \nThank you for your patience.\n    submitted by    /u/ExoticAd6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0cgmz/discussion_advice_on_training_document_layout/",
          "publishedOn": "2022-04-10T07:17:30.000Z",
          "wordCount": 347,
          "title": "[Discussion] Advice on training document layout analysis models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u0a0kd/d_market_basket_analysis_realworld_examples_and/",
          "author": null,
          "description": "I want to know more about Market Basket Analysis's real-world use case and unique insights/business value derived from performing the Association rule mining. \n I heard about the Beer-Diaper case study but many other sources invalidated it as a spurious correlation. Can someone share any example of business insights from Market Basket analysis and any interesting patterns they were able to observe??\n    submitted by    /u/invincible_moron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u0a0kd/d_market_basket_analysis_realworld_examples_and/",
          "publishedOn": "2022-04-10T04:25:35.000Z",
          "wordCount": 452,
          "title": "[D] Market Basket Analysis real-world examples and insights?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u084uh/d_how_are_multiple_training_examples_used_in_dmd/",
          "author": null,
          "description": "The examples I have seen so far for DMD and SINDy use only 1 trajectory of the dynamical system for training. The input data is a 2D matrix, with the states/features being one dimension and time being the other dimension. But I want to use multiple trajectories of the same dynamical system for training, so the training data would be 3D (i.e., multiple 2D matrices). Are there examples where this has been done?\n Linear regression techniques (like pseudoinverse or LASSO) seem to be used to get the system matrix (in DMD) or the weights for the features (in SINDy). Can these methods be extended to 3D input data?\n    submitted by    /u/baigyaanik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u084uh/d_how_are_multiple_training_examples_used_in_dmd/",
          "publishedOn": "2022-04-10T02:28:22.000Z",
          "wordCount": 379,
          "title": "[D] How are multiple training examples used in DMD, SINDy, etc.?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/u02p5x/r_local_learning_matters_rethinking_data/",
          "author": null,
          "description": "#cvpr-2022\n Happy to share our CVPR-2022 paper \"Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning\"\n Paper: https://arxiv.org/pdf/2111.14213.pdf\n Code: https://github.com/mmendiet/FedAlign\n Federated learning (FL) is a promising strategy for performing privacy-preserving, distributed learning with a network of clients (i.e., edge devices). However, the data distribution among clients is often non-IID in nature, making efficient optimization difficult. To alleviate this issue, many FL algorithms focus on mitigating the effects of data heterogeneity across clients by introducing a variety of proximal terms, some incurring considerable compute and/or memory overheads, to restrain local updates with respect to the global model. Instead, we consider rethinking solutions to data heterogeneity in FL with a focus on local learning generality rather than proximal restriction. To this end, we first present a systematic study informed by second-order indicators to better understand algorithm effectiveness in FL. Interestingly, we find that standard regularization methods are surprisingly strong performers in mitigating data heterogeneity effects. Based on our findings, we further propose a simple and effective method, FedAlign, to overcome data heterogeneity and the pitfalls of previous methods. FedAlign achieves competitive accuracy with state-of-the-art FL methods across a variety of settings while minimizing computation and memory overhead.\n    submitted by    /u/Extension-Sun1816  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/u02p5x/r_local_learning_matters_rethinking_data/",
          "publishedOn": "2022-04-09T21:25:49.000Z",
          "wordCount": 295,
          "title": "[R] Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzvxb9/d_icml2022_domain_conflicts_system/",
          "author": null,
          "description": "I was wondering if the Domain conflicts system working well?\n I got an email from the PCs and seems that the domain conflict system is not working well. It said that we can enter the conflict now but I cannot edit the conflict in the system. Could anyone tell me how to do it? Thanks!\n  \nDear ICML Authors, \n As we are seeing this happen, we just wanted to send you a brief explanation -- this only applies to some few papers. A few papers are losing reviews because of newly arising conflicts. If you did not enter your conflicts in CMT during the submission phase (as requested via CMT), then they could not be used in paper assignments. If you enter them now, any reviews by reviewers with conflicting domains will disappear, and you may see fewer reviews as a result. Unfortunately, we have no control over this, as the conflicts should have been entered when the paper was submitted. \n Best, \n Stefanie, Le and Csaba\n  \n   submitted by    /u/Snoo_97274  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzvxb9/d_icml2022_domain_conflicts_system/",
          "publishedOn": "2022-04-09T15:47:54.000Z",
          "wordCount": 249,
          "title": "[D] ICML2022 Domain conflicts system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzp4kv/d_poll_how_do_you_deploy_models_endpoints/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/martolini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzp4kv/d_poll_how_do_you_deploy_models_endpoints/",
          "publishedOn": "2022-04-09T08:47:40.000Z",
          "wordCount": 179,
          "title": "[D] Poll: How do you deploy models & endpoints?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzowos/rp_generate_images_from_text_with_latent/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzowos/rp_generate_images_from_text_with_latent/",
          "publishedOn": "2022-04-09T08:30:09.000Z",
          "wordCount": 447,
          "title": "[R][P] Generate images from text with Latent Diffusion LAION-400M Model + Gradio Demo",
          "imageUrl": "https://preview.redd.it/58fjuz70sgs81.png?auto=webp&s=849a5c0a11df3431e2e785b4e7bba43547fd2ae2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzouo4/p_tinydl_library_to_help_with_hyperparameter/",
          "author": null,
          "description": "Hi everyone,\n I built a small library to help with hyperparameter search for deep learning models created with pytorch, because I got kinda tired of having to rewrite large pieces code over and over again.\n You can check it out here: https://github.com/michi-jeremias/tinydl or you can even install it with pip (pip install tinydl). I have included a readme and an example of how the library can be used.\n About the library, it's pretty flexible about reporting different metrics to the console and to tensorboard (add_scalar, add_hparam) at each stage of the process, like after a batch, epoch of after a whole run over multiple epochs. It can also be easily extended to include other metrics or new types of outputs.\n Since this is basically my first attempt at a software project that's not intended only to be used by myself I'd be happy about any feedback you have for me!\n If the project doesn't qualify to be posted here due to being too simple/too much on a beginner level, apologies for that.\n    submitted by    /u/abacaxiquaxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzouo4/p_tinydl_library_to_help_with_hyperparameter/",
          "publishedOn": "2022-04-09T08:26:02.000Z",
          "wordCount": 283,
          "title": "[P] tinydl - library to help with hyperparameter search and metric reporting in pytorch",
          "imageUrl": "https://external-preview.redd.it/LAHK1MYtwhgtja_z8t-OxpLe_RGNXrgwE2G9Vcnyza8.jpg?auto=webp&s=4da53c43496a4a8b26c374fab44c26f0fe4664ca"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzoqg2/d_stylegan2_path_length_regularization/",
          "author": null,
          "description": "I am trying to implement stylegan2 and there are so many things here that are not explained either well, or at all in the paper.\n ​\n  \nHow exactly is path length regularization implemented? In this PT code we can see that the $|J^T_w.y|$ is computed as follows:\n  \n​\n def g_path_regularize(fake_img, latents, mean_path_length, decay=0.01): noise = torch.randn_like(fake_img) / math.sqrt( fake_img.shape[2] * fake_img.shape[3] ) grad, = autograd.grad( outputs=(fake_img * noise).sum(), inputs=latents, create_graph=True ) path_lengths = torch.sqrt(grad.pow(2).sum(2).mean(1)) path_mean = mean_path_length + decay * (path_lengths.mean() - mean_path_length) path_penalty = (path_lengths - path_mean).pow(2).mean() return path_penalty, path_mean.detach(), path_lengths \n This is based on this official TF implementation.\n The problem I have is that from what I understand, fake_img is 4D, and latents is 2D. The grad output in this case will be 2D and grad.pow(2).sum(2) cannot be computed because the third axis does not exist. Obviously people who are using these repos have not reported any issue regarding mismatch of shapes and axes, so I believe there is something else going on. Since I'm trying to implement this in my own network, I cannot get the desired shape any how. I get a 2D gradient output.\n    submitted by    /u/feryet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzoqg2/d_stylegan2_path_length_regularization/",
          "publishedOn": "2022-04-09T08:16:53.000Z",
          "wordCount": 280,
          "title": "[D] StyleGAN2 Path Length Regularization Implementation Clarification",
          "imageUrl": "https://external-preview.redd.it/O-Qa83OpjON3SWHV-wEplWm6hveg9MwnypL-8LbGhj0.jpg?auto=webp&s=5f87229a3d481d78fb390659e8ae68f1dd7cb61c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzo5ih/p_jaxhaiku_pretrained_models_mobilenet_resnet_vgg/",
          "author": null,
          "description": "I released a repository of models with optional pretrained weights(Weights are taken from TF/Keras) to be used for tasks like prediction, feature extraction and fine-tuning.\n Github: https://github.com/abarcel/haikumodels\n Currently Available Models\n  \nMobileNet\n ResNet [50, 101, 152]\n VGG [16, 19]\n Xception\n  \nAlso planning to release more, as soon as I find time for it.\n    submitted by    /u/abarcel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzo5ih/p_jaxhaiku_pretrained_models_mobilenet_resnet_vgg/",
          "publishedOn": "2022-04-09T07:31:55.000Z",
          "wordCount": 143,
          "title": "[P] Jax/Haiku pretrained models: MobileNet, ResNet, VGG, Xception.",
          "imageUrl": "https://external-preview.redd.it/XjGrYB5ZZF-dofoIIZW3gcfGriVD2PvY0cLghzZCTaY.jpg?auto=webp&s=4f0457113cf97eb52cfefb596f2a88fe97274084"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tznijk/d_denoising_in_the_latent_space/",
          "author": null,
          "description": "I spent some time reading about and playing around with speech denoising DNNs ~2019. At the time the popular architecture was U-Net (encoder -> bottleneck -> decoder with skip connections) operating on spectrograms. These U-Nets were trained directly on noisy/clean speech pairs and the loss was the difference between the predicted denoised images and actual denoised image. MSE between the predicted/actual images was a baseline loss but people alse added \"feature loss\" or sometimes a GAN-based loss function as well.\n Anyway a cursory reading of the DALL-E 2 paper has me thinking about that approach. I'm curious to know if a similar approach used for DALL-E has been tried for audio denoising:\n  \npre-train an encoder/decoder in a self-supervised fashion on a large dataset of audio\n train a denoiser to operate only in the latent space (ie the most compressed representation that is passed from the encoder to the decoder)\n  \nstep 1 - self-supervised training of encoder/decoder\n https://preview.redd.it/nprc40ob9gs81.png?width=1668&format=png&auto=webp&s=3a9b181ceff6c4530b5f41abf793dfb6409c0ec2\n step 2 - train denoiser in latent space only\n ​\n https://preview.redd.it/hreajdpe9gs81.png?width=1279&format=png&auto=webp&s=e16490fff00fe82487ca214b11b642ffcb30fb1c\n step 3 - do inference by feeding denoised latent space vector into the decoder\n https://preview.redd.it/7nox4ezh9gs81.png?width=2034&format=png&auto=webp&s=ccc69bbb2096d84a9e4a824000e62bb0f80fbe29\n Is this a common approach already? It seems like once you have a good pretrained encoder/decoder pair then the denoiser training would be much more efficient than training an entire network that does everything at once from scratch (smaller search space, faster training loop)\n    submitted by    /u/The_Amp_Walrus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tznijk/d_denoising_in_the_latent_space/",
          "publishedOn": "2022-04-09T06:46:23.000Z",
          "wordCount": 382,
          "title": "[D] Denoising in the latent space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzhbxj/discussion_mlops_vs_platform_engineering/",
          "author": null,
          "description": "Hey guys, I have the opportunity to either move to the platform engineering team or the freshly created MLOps team within my company. I'm interested in both careers, as I like to build Infra. I'm currently a Data Eng, and I find myself to like building apps and enabling applications to talk to each other, better than cleaning up data. I worked as a data scientist before, but I didn't like the science. I was always into engineering. What would make sense from a career perspective (both long and short term), i.e., money, promotions, attractiveness, etc.\n    submitted by    /u/dash2392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzhbxj/discussion_mlops_vs_platform_engineering/",
          "publishedOn": "2022-04-09T00:27:17.000Z",
          "wordCount": 185,
          "title": "[Discussion] MLOps vs Platform Engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzg9p2/d_any_guesstimates_for_how_much_a_dalle_2/",
          "author": null,
          "description": "Just based on the estimated running costs of GPT3, and then whatever profit gets applied on top of that, are there any estimates for what openai will eventually charge for image generation?\n    submitted by    /u/EugeneJudo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzg9p2/d_any_guesstimates_for_how_much_a_dalle_2/",
          "publishedOn": "2022-04-08T23:29:44.000Z",
          "wordCount": 254,
          "title": "[D] Any guesstimates for how much a DALLE 2 generation will eventually cost?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzf2r1/problem_with_cvpr_template_and_arxiv_d/",
          "author": null,
          "description": "I don't know what would be the best place to post this. But I am having trouble uploading an Overleaf manuscript to arXiv based on the CVPR 2022 template. I am getting the following error. Does anyone have any ideas?\n ​\n https://preview.redd.it/y9jq0rbysds81.png?width=1614&format=png&auto=webp&s=16be3d32468837f649e846ec8a309dab2854c762\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzf2r1/problem_with_cvpr_template_and_arxiv_d/",
          "publishedOn": "2022-04-08T22:29:46.000Z",
          "wordCount": 135,
          "title": "Problem with CVPR template and arXiv? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tze09r/rsocratic_models_composing_zeroshot_multimodal/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2204.00598\n https://socraticmodels.github.io/\n Twitter: https://twitter.com/andyzengtweets/status/1512089759497269251\n Abstract: \" Large foundation models can exhibit unique capabilities depending on the domain of data they are trained on. While these domains are generic, they may only barely overlap. For example, visual-language models (VLMs) are trained on Internet-scale image captions, but large language models (LMs) are further trained on Internet-scale text with no images (e.g. from spreadsheets, to SAT questions). As a result, these models store different forms of commonsense knowledge across different domains. In this work, we show that this model diversity is symbiotic, and can be leveraged to build AI systems with structured Socratic dialogue -- in whi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tze09r/rsocratic_models_composing_zeroshot_multimodal/",
          "publishedOn": "2022-04-08T21:37:47.000Z",
          "wordCount": 333,
          "title": "[R]Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language - Google Apr 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tzcnwb/d_what_to_do_next_after_the_sanity_check/",
          "author": null,
          "description": "I have two years of time-series data taken from two sensors which I have split into 80/10/10 non-overlapping train/val/test splits. The task is to denoise one sensor data into another and I am handling it as a regression problem.\n I am following this website and considered an already published model (5 convolutional and 1 fully connected layer) which is trained on a similar dataset and same task.\n For the sake of sanity check, as per the website, I have trained the model on a subset of trainset (3 months) and tried to overfit it (while evaluating on complete val set), which works fine.\n However, I am not sure what to do next from this point on? Shall I just train on the complete trainset now? Or do I increase the layers or play with other hyper params to find more details about my regression problem/data? I would really appreciate your comments. Thank you.\n PS. The target value is sparse i.e. more than 85% of the time it is zero.\n    submitted by    /u/muaz_usmani  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tzcnwb/d_what_to_do_next_after_the_sanity_check/",
          "publishedOn": "2022-04-08T20:33:36.000Z",
          "wordCount": 266,
          "title": "[D] What to do next after the sanity check?",
          "imageUrl": "https://external-preview.redd.it/ts0z7cd5buLjkX6R5TQi7kMqPtwQY7jK8s3fPJ8fANQ.jpg?auto=webp&s=617f0844a3718900a927c1e1fa7130f4dfa3765e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz9obh/d_leaving_ml_for_software_engineering/",
          "author": null,
          "description": "I'm keen to hear from people who have made the transition from ML Research/Engineering positions to software engineering roles (or who are considering it). What were your reasons for doing it and did you regret it? I see so many articles about transition from software to ML but none about going the opposite direction.\n Context: I've been working as an ML Engineer for a little over a year, and I'm just... not enjoying it. I want to love my job so badly as I like my boss, my colleagues, and the company (and I'm paid quite well for my level), but I just don't. I feel like the type of work I'm doing is not very smart and yet it's extremely draining: I spend so many hours just looking at loss curves, tweaking features and parameters. I'm somehow bored and stressed at the same time, because I don't enjoy the work and yet I feel the pressure to produce good models, and when they don't work as expected I can't help but take it personally as if if I just tried hard enough they would work. I find that the days were I end up having to take care of more purely engineering tasks I just have a lot more fun and I finish the day more satisfied and less drained. I think I just want to build something instead of spending hours banging my head against shit data. I would love to hear from people who feel or have felt the same way because whenever I speak about this with friends who are in ML they look at me like I'm a lunatic for wanting to leave it for software engineering.\n I'm obviously aware that swe roles are not all fun and games, but I just feel like there's been an excessive push for so many people to move to ML as it's \"cool\" and \"smart\" when in reality they're just different things who are going to suit different people.\n    submitted by    /u/hedy-m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz9obh/d_leaving_ml_for_software_engineering/",
          "publishedOn": "2022-04-08T18:12:46.000Z",
          "wordCount": 1541,
          "title": "[D] Leaving ML for Software Engineering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz6izi/d_is_virtual_iclr_2022_worth_paying_for/",
          "author": null,
          "description": "The 2022 ICLR conference at the end of this month is virtual and costs $100 to attend. I was thinking of attending for networking opportunities but I’m not sure. Is it a good idea to go for it?\n    submitted by    /u/sybar142857  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz6izi/d_is_virtual_iclr_2022_worth_paying_for/",
          "publishedOn": "2022-04-08T15:49:34.000Z",
          "wordCount": 349,
          "title": "[D] Is virtual ICLR 2022 worth paying for",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz50is/d_triplet_vs_contrastive_loss/",
          "author": null,
          "description": "The online triplet mining strategy is more efficient than the offline one. It implies \"getting a batch of n samples and their associated labels, and form triplets on the fly.\" Here is an article about Triplet vs. Contrastive Loss comparison and its efficient implementation. I would like to know your feedback.\n    submitted by    /u/devzaya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz50is/d_triplet_vs_contrastive_loss/",
          "publishedOn": "2022-04-08T14:38:54.000Z",
          "wordCount": 140,
          "title": "[D] Triplet vs. Contrastive Loss",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz4dic/p_animated_character_generator/",
          "author": null,
          "description": "Hello everybody,\n I'd like to share the latest machine learning project of mine. It allows one to generate animated characters in the style of old video game consoles. Here are some examples. I would appreciate any feedback.\n https://i.redd.it/sig6ilpi8bs81.gif\n https://i.redd.it/xaf906qi8bs81.gif\n https://i.redd.it/8v7lz2qi8bs81.gif\n    submitted by    /u/ie9res  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz4dic/p_animated_character_generator/",
          "publishedOn": "2022-04-08T14:08:32.000Z",
          "wordCount": 122,
          "title": "[P] Animated Character Generator",
          "imageUrl": "https://external-preview.redd.it/GwQJ7G0XyNNGMXuRx3aaIeyjj8ou-FRsHor14m2yPPc.jpg?auto=webp&s=ff631469a0fd9b87dcbbe2f7e3bf848919109891"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz3x87/d_annotation_formats_for_image_annotations/",
          "author": null,
          "description": "Hey ML people, what is your favorite annotation format for image bounding boxes/labels? I know coco is very popular, we are rethinking parts of our data infrastructure wondering what everyone is using. Our platform hosts hundreds of millions of images. Ideal format would support running queries on data stored in a Data lake\n If the format supports 3D annotation types that is even better. Thanks for your insights in advance.\n    submitted by    /u/mmuppidi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz3x87/d_annotation_formats_for_image_annotations/",
          "publishedOn": "2022-04-08T13:47:05.000Z",
          "wordCount": 208,
          "title": "[D] Annotation formats for image annotations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz3qc8/n_openais_dalle_2_paper_hierarchical/",
          "author": null,
          "description": "New version of paper is linked to in the DALL-E 2 blog post and also here (pdf file format).\n Tweet announcing updated paper.\n Older version of paper (pdf file format).\n Original Reddit post.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz3qc8/n_openais_dalle_2_paper_hierarchical/",
          "publishedOn": "2022-04-08T13:37:13.000Z",
          "wordCount": 273,
          "title": "[N] OpenAI's DALL-E 2 paper \"Hierarchical Text-Conditional Image Generation with CLIP Latents\" has been updated with added section \"Training details\" (see Appendix C)",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz32ub/dense_passage_retrieverdpr_openqa_system_p/",
          "author": null,
          "description": "Hi, I made a video explaining Dense Passage Retriever(DPR) paper. We specifically explain the End to End QA system suggested in the latter part of the paper which discusses how to build an Open-QA system using dense retrievers.\n DPR was one of the first papers that discussed building dense retrievers using QA pairs only and didn't require a big pretraining computational setup like ORQA or REALM. It is currently used in a lot of places as a dense retriever. You can find Hugginface and Haystack implementations also.\n This video is part of a series on Open-QA using dense retrievers. We have made 2 videos on DPR. In the latter, we discuss how to build a dense retriever from scratch. Thanks for the support and it would be great if you could give any feedback.\n https://www.youtube.com/watch?v=rvcyyJNjPU0\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz32ub/dense_passage_retrieverdpr_openqa_system_p/",
          "publishedOn": "2022-04-08T13:03:32.000Z",
          "wordCount": 224,
          "title": "Dense Passage Retriever(DPR) Open-QA System [P]",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz2o0b/d_works_that_can_process_variable_input/",
          "author": null,
          "description": "Hi. I'm looking for existing computer vision papers /networks that can process variable input resolution. Can anyone share me with similar works? For example, a network/layer N can take both inputs with H*W and 2H*2H individually and give correct prediction. One of them I know is ROI pooling used in Faster RCNN. Thanks very much.\n    submitted by    /u/vincent341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz2o0b/d_works_that_can_process_variable_input/",
          "publishedOn": "2022-04-08T12:41:56.000Z",
          "wordCount": 327,
          "title": "[D] Works that can process variable input resolution of images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tz05tg/d_machine_learning_engineers_what_does_your_day/",
          "author": null,
          "description": "Hey, I'm looking to transition from my current role as a data scientist to one that has a machine learning engineering focus. I was wondering if anyone could provide insights into how they plan their day, or what activities you do throughout the day/week. I'd be particularly interested to understand the balance between deploying models/writing production worthy code and your time spent learning/developing given the field is moving so fast.\n    submitted by    /u/MenArePigs69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tz05tg/d_machine_learning_engineers_what_does_your_day/",
          "publishedOn": "2022-04-08T10:06:51.000Z",
          "wordCount": 1320,
          "title": "[D] Machine Learning Engineers - What Does Your Day Involve?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tywuga/d_bayesian_nonparametrics_for_ranking/",
          "author": null,
          "description": "I am currently sitting at a difficult machine-learning problem that I have found no literature on how to solve it. \n I am given n datapoints x_1,...,x_n that are ordered according to a ranking preference rank(x_1)<rank(x_2)<...<rank(x_n). I am assuming there exists a function f, such, that f(x_i)<f(x_i+1). I am now searching a Bayesian non-parametric model that gives the posterior probability of functions f that abide f(x_i)<f(x_i+1), so that i can estimate the relative rank preferences at new points.\n I have tried out a few things. The naive approach is using a GP prior on f. Unfortunately, computing the posterior distribution p(f(x_1), ... f(x_n)| f(x_1)<...<f(x_n)) has no closed form solution (it is a normal distribution with N linear constraints, which is absolutely terrible to sample from). This makes computing conditional distributions for predictions very challenging. \n I am currently approximating the solution by using a GP regression model with label y_i = rank(x_i)=i. But this is systematically under-estimating the shape-variation, due to the fact that it adds the assumption that function values between ranks are equidistant. \n Is there any known approach how to do this?\n    submitted by    /u/Ulfgardleo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tywuga/d_bayesian_nonparametrics_for_ranking/",
          "publishedOn": "2022-04-08T06:03:54.000Z",
          "wordCount": 494,
          "title": "[D] Bayesian Non-Parametrics for Ranking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tywmy0/r_video_diffusion_models/",
          "author": null,
          "description": "From the webpage:\n We present results on video generation using diffusion models. We propose an architecture for video diffusion models which is a natural extension of the standard image architecture. We show that this architecture is effective for jointly training from image and video data. To generate long and higher resolution videos we introduce a new conditioning technique that performs better than previously proposed methods. We present results on text-conditioned video generation and state-of-the-art results on an unconditional video generation benchmark.\n Paper: https://arxiv.org/abs/2204.03458\n https://video-diffusion.github.io/\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tywmy0/r_video_diffusion_models/",
          "publishedOn": "2022-04-08T05:50:09.000Z",
          "wordCount": 205,
          "title": "[R] Video Diffusion Models",
          "imageUrl": "https://external-preview.redd.it/3oqkCt6VNVPKLWns6Tm8iCS8Ssrcd3AFU4klA6NCY8o.jpg?auto=webp&s=f509d332edc21fdb071d2bd7177e91a9b4cbd42e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyv2tu/d_how_to_decide_publication_venue/",
          "author": null,
          "description": "How to decide if a paper is appropriate for a specific venue? Moreover, how would you categorize the difference between a good NiPs publication and a good CvPR or ICCV publication?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyv2tu/d_how_to_decide_publication_venue/",
          "publishedOn": "2022-04-08T04:12:23.000Z",
          "wordCount": 216,
          "title": "[D] how to decide publication venue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyu1n6/n_lr_warmup_for_pytorch/",
          "author": null,
          "description": "​\n RadamWarmup + CosineAnnealingLR + StepLR\n Colab Link\n pytorch_warmup v0.1.0 was released.\n    submitted by    /u/TonyY_RIMCS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyu1n6/n_lr_warmup_for_pytorch/",
          "publishedOn": "2022-04-08T03:13:36.000Z",
          "wordCount": 98,
          "title": "[N] LR Warmup for PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyo9qd/d_self_attention_visualization/",
          "author": null,
          "description": "Has anyone ever come across seemingly chaotic self attention maps during visualization. If your model is performing well but no insights can be gleaned from the visualization how do you explain it in a paper?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyo9qd/d_self_attention_visualization/",
          "publishedOn": "2022-04-07T22:13:00.000Z",
          "wordCount": 262,
          "title": "[D] self attention visualization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyn0yt/n_palms_googles_530b_llm_training_costs_around_9m/",
          "author": null,
          "description": "Here's the blogpost estimating the cost.\n What would it cost you to train PaLM using cloud computing (and you're not Google)? Something around $9M to $17M.\n    submitted by    /u/cirqe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyn0yt/n_palms_googles_530b_llm_training_costs_around_9m/",
          "publishedOn": "2022-04-07T21:14:22.000Z",
          "wordCount": 382,
          "title": "[N] PaLM's (Google's 530B LLM) training costs around $9M to $17M.",
          "imageUrl": "https://external-preview.redd.it/XV6Bw55gOCr7mrIMQ_xiFS365To1cJ6BcQQYprVY0iQ.jpg?auto=webp&s=2f3079fb965cc21e23397be43a0945248880c31e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tymu9e/d_feature_selection_methods/",
          "author": null,
          "description": "I'm working on a ML project and I'm working with a dataset with 20 columns, for feature selection I just removed one column one by one and looked at the error of the ML outputs for each, then saw when what column is removed gives a lower error and kept repeating that but that didn't seem to help the model at all and the error went down very little. Is this an okay way of doing feature selection is there another way that gives better results. I tried PCA and LDA and Pearson Correlation method as well in Python and that didn't seem to help or is this the best I could do. Thanks!\n    submitted by    /u/ihshosv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tymu9e/d_feature_selection_methods/",
          "publishedOn": "2022-04-07T21:05:46.000Z",
          "wordCount": 334,
          "title": "[D] Feature selection methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tykn7y/d_overfitting_a_sign_high_learning_capacity/",
          "author": null,
          "description": "This is a two part question:\n  \nIf a neural network can overfit the a large dataset is this a sign that a neural network has high learning capacity? \n If a neural network can overfit a dataset with substantially less parameters than other neural networks developed for the same learning task is this a sign that the neural network has a high learning capacity relative to other datasets?\n  \n   submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tykn7y/d_overfitting_a_sign_high_learning_capacity/",
          "publishedOn": "2022-04-07T19:24:50.000Z",
          "wordCount": 331,
          "title": "[D] Overfitting a sign high learning capacity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyjj3z/d_training_cnn_with_synthetic_data_should_i_mix/",
          "author": null,
          "description": "I'm doing research on the use of synthetic data for a computer vision task and i have generally always tried to train in a mixed setting from scratch, but i have noticed that in similar papers, researchers always pretrain on synth first and then finetune on real data. Is there a logic behind that? Should i expect better results by finetuning?\n    submitted by    /u/TheManveru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyjj3z/d_training_cnn_with_synthetic_data_should_i_mix/",
          "publishedOn": "2022-04-07T18:34:01.000Z",
          "wordCount": 729,
          "title": "[D] training cnn with synthetic data. Should i mix synth and real and train from the scratch or pretrain the network with synth and finetune with real?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyhxl2/r_sampling_in_dirichlet_process_mixture_models/",
          "author": null,
          "description": "Hi Everyone,\n We have recently published the code for our AISTATS 2022 paper -\n Sampling in Dirichlet Process Mixture Models for Clustering Streaming Data\n ​\n Video Segmentation Example\n In our work, we have proposed a solution for clustering streaming data. Unlike 'standard' clustering scenarios, in the streaming case the data stream is possibly infinite, you cannot backtrack to previously processed points, and the data statistics are dynamic and change over time.\n Our solution is based on the Dirichlet Process Mixture Model (DPMM), can work with different types of observations, and is very fast, outperforming other methods both in the quality of the results and the speed with which it achieves them.\n It can even be distributed across several processes and/or machines!\n  \nPaper: https://dinarior.github.io/papers/Dinari_AISTATS_streaming.pdf\n Code (Julia Package): https://github.com/BGU-CS-VIL/DPMMSubClustersStreaming.jl\n Code (Python wrapper): https://github.com/BGU-CS-VIL/dpmmpythonStreaming\n Notebook (Julia) for creating the video: https://nbviewer.org/github/BGU-CS-VIL/DPMMSubClustersStreaming.jl/blob/main/examples/VideoSeg.ipynb\n  \n   submitted by    /u/dinarior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyhxl2/r_sampling_in_dirichlet_process_mixture_models/",
          "publishedOn": "2022-04-07T17:20:31.000Z",
          "wordCount": 424,
          "title": "[R] Sampling in Dirichlet Process Mixture Models for Clustering Streaming Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyfltn/d_best_way_to_handle_encoding_disconnected_graphs/",
          "author": null,
          "description": "I am thinking of building a graph classifier that takes in graphs and labels the incoming graph.\n The dataset of interest to me is RadGraph: https://arxiv.org/abs/2106.14463\n The issue I am having is that the graphs in RadGraph are disconnected in nature (on average 20 disconnected components), making it difficult for the various graph encoders I am aware of to do a good job classifying the graphs.\n    submitted by    /u/AICoderGamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyfltn/d_best_way_to_handle_encoding_disconnected_graphs/",
          "publishedOn": "2022-04-07T15:31:10.000Z",
          "wordCount": 174,
          "title": "[D] Best way to handle encoding disconnected graphs at the graph level.",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tyfj7d/d_does_someone_know_how_much_faster_deepspeeds/",
          "author": null,
          "description": "Implementation here\n Looks like they manually calculate the gradient? I'm very curious how much of a difference this makes!\n    submitted by    /u/fasttosmile  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tyfj7d/d_does_someone_know_how_much_faster_deepspeeds/",
          "publishedOn": "2022-04-07T15:27:53.000Z",
          "wordCount": 195,
          "title": "[D] Does someone know how much faster deepspeed's transformer implementation is?",
          "imageUrl": "https://external-preview.redd.it/tEPdTFlU-uawNZzkicwUlD9W5f2jMOt9Ho6WP7Zbh7M.jpg?auto=webp&s=f5e8d53aeee5139d4a8684ee18339cc5d0dfde18"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty8oi7/r_my_research_group_is_publicly_sharing_its_paper/",
          "author": null,
          "description": "https://outsystems-ai-reading-group.github.io/\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty8oi7/r_my_research_group_is_publicly_sharing_its_paper/",
          "publishedOn": "2022-04-07T08:47:55.000Z",
          "wordCount": 118,
          "title": "[R] My research group is publicly sharing its paper presentations! Check it out!",
          "imageUrl": "https://external-preview.redd.it/okw9CoDOpAQ1q_mUTvkkFthoqq22j0xfreN13Amh1Rw.jpg?auto=webp&s=6f24b4084a5650db879165128873fd8d71d36b12"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty7h2p/r_onthefly_strategy_adaptation_for_adhoc_agent/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty7h2p/r_onthefly_strategy_adaptation_for_adhoc_agent/",
          "publishedOn": "2022-04-07T07:15:38.000Z",
          "wordCount": 99,
          "title": "[R] On-the-fly Strategy Adaptation for ad-hoc Agent Coordination",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty6hee/d_any_good_free_to_use_dalle_style_datasets/",
          "author": null,
          "description": "Are there any free to use datasets that contain image/annotation pairs in the style OpenAI used to train the DALL-E models? Pretty inspired by DALL-E 2 and think it would be cool to create a tiny less powerful replication\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty6hee/d_any_good_free_to_use_dalle_style_datasets/",
          "publishedOn": "2022-04-07T06:06:51.000Z",
          "wordCount": 163,
          "title": "[D] Any good free to use DALL-E style datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty6g23/d_tensorflow_tfrange_vs_range/",
          "author": null,
          "description": "TLDR: TensorFlow AutoGraph unwraps native Python ranges, baking each value into the graph. This can be an unexpected cause of graph size explosion. \n This recently caused an issue in my project, so I thought I'd share some more details:\n https://lukewood.xyz/blog/to-unroll-or-to-not-unroll\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty6g23/d_tensorflow_tfrange_vs_range/",
          "publishedOn": "2022-04-07T06:04:17.000Z",
          "wordCount": 182,
          "title": "[D] TensorFlow tf.range() vs range()",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty4gw4/r_a_benchmarking_framework_for_timeseries/",
          "author": null,
          "description": "Our work \"AdaTime: A Systematic Evaluation of Domain Adaptation Algorithms on Time Series Data\" is now public. We provide a benchmarking framework named \"AdaTime\" to fairly evaluate Unsupervised domain adaptation (UDA) approaches on time-series data. We find that UDA approaches proposed for visual data can be directly applied to time-series data, and still achieve excellent performance, even better than methods specially proposed for time-series UDA. Se were impressed by the consistently superior performance of \"DIRT-T\" method on all the datasets. We provide the code publicly on github https://github.com/emadeldeen24/AdaTime\n    submitted by    /u/emad_eldeen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty4gw4/r_a_benchmarking_framework_for_timeseries/",
          "publishedOn": "2022-04-07T04:01:52.000Z",
          "wordCount": 189,
          "title": "[R] A benchmarking framework for time-series unsupervised domain adaptation",
          "imageUrl": "https://external-preview.redd.it/sPvr39oleAaAzL2Fx1s3W-hVlQLmkPCmIYm8DTQI1IE.jpg?auto=webp&s=d21d49a0c4335a7c16878c30293b7641634cb8cb"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty3w48/pr_announcing_dataset_denoising_shabby_pages/",
          "author": null,
          "description": "Into machine learning? Want a chance to earn a new MacBook Pro? Check out the Denoising ShabbyPages competition! The ShabbyPages dataset is being produced as a way to help train, test, and calibrate computer vision machine learning algorithms designed for working with documents. Enter the competition by training a model to remove the noise, and be awarded a MacBook Pro or some swag in the process! Check out the short paper introducing the dataset, and learn more about the competition at denoising-shabby.com.\n    submitted by    /u/proofconstruct  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty3w48/pr_announcing_dataset_denoising_shabby_pages/",
          "publishedOn": "2022-04-07T03:29:34.000Z",
          "wordCount": 180,
          "title": "[P][R] Announcing: Dataset & Denoising Shabby Pages Competition",
          "imageUrl": "https://external-preview.redd.it/3_5RF7j_Wg4iYno2Cpz3or2Md6GYBVeX1z8U_fyZIYE.jpg?auto=webp&s=2788014920175df6b4b456e2dcdb428445d0d887"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty3jae/r_facesigns_semifragile_neural_watermarks_for/",
          "author": null,
          "description": "Hi Everyone! \n We have released the preprint and google colab demo for our paper FaceSigns. FaceSigns embeds a secret bit-string as a semi-fragile watermark in the image pixels. The message is recoverable if benign image operations such as color/contrast adjustment, JPEG compression, Instagram filters are applied. However, the message cannot be decoded if the image is facially tampered (eg. DeepFake manipulation) . This selective fragility allows reliable detection of DeepFake manipulations applied on images signed using FaceSigns. \n Try out our google colab demo to see message encoding and decoding using FaceSigns!\n Paper: https://arxiv.org/abs/2204.01960\n Project Webpage: https://shehzeen.github.io/facesigns\n Demo: https://github.com/paarthneekhara/FaceSignsDemo\n    submitted by    /u/LynxCompetitive7637  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty3jae/r_facesigns_semifragile_neural_watermarks_for/",
          "publishedOn": "2022-04-07T03:09:27.000Z",
          "wordCount": 200,
          "title": "[R] FaceSigns: Semi-Fragile Neural Watermarks for Media Authentication and Countering Deepfakes",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ty25fi/d_machine_learning_models_ideas_for_google_search/",
          "author": null,
          "description": "Hi guys!\n I work in house and I’m part of our Google search team. Our ad spend is pretty large (9 figures per year, in USD). We build/manage stuff at scale using SQL, R, Javascript, and so on. So everything is pretty much “big data” in flavour.\n Lately I’ve been more and more interested in data science, and I’m looking to take things to the next level by incorporating machine learning into our workflow. I’d really love to build some useful machine learning models using popular Python libraries such as Pandas, SciKit Learn, NumPy, TensorFlow, PyTorch, and so on.\n Any suggestions on cool, and most importantly useful machine learning models I could build? (By “useful”, I mean something that could help increase the profits.) I think some classification, predictive, or recommender models would be great to start with. Cheers! 😄\n    submitted by    /u/TropicalBound111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ty25fi/d_machine_learning_models_ideas_for_google_search/",
          "publishedOn": "2022-04-07T01:57:24.000Z",
          "wordCount": 568,
          "title": "[D] Machine learning models / ideas for Google search ads?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txy6il/r_using_gamma_distribution_to_improve_longtail/",
          "author": null,
          "description": "Predicting longtail events can be one of the more challenging ML tasks. Last year my team published a blog article where we improved DoorDash’s ETA predictions by 10% by tweaking the loss function with historical and real-time features. I thought members of the community would be interested in learning how we improved the model even more by using Gamma distribution-based inverse sampling approach to loss function tunning. Please check out the new article for all the technical details and let us know your feedback on our approach.\n https://doordash.engineering/2022/04/06/using-gamma-distribution-to-improve-long-tail-event-predictions/\n    submitted by    /u/pmp-dash1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txy6il/r_using_gamma_distribution_to_improve_longtail/",
          "publishedOn": "2022-04-06T22:34:20.000Z",
          "wordCount": 194,
          "title": "[R] Using Gamma Distribution to Improve Long-Tail Event Predictions at Doordash",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txvlf0/d_icml_author_response_what_reviewers_expect/",
          "author": null,
          "description": "Hi, we submitted to ICML for the first time. We got 4 reviews and 3 of them are mostly positive. Major comments by the reviewers include: more justification on the assumptions, discussion on choices of parameters, and experiments in more complex and different environments. \n We want to address all the major and minor comments as best as we can but given that the response is limited to one page we cannot explain everything in detail. I am not sure what is the acceptable norm here. Do reviewers expect the authors to conduct some experiments during the rebuttal and provide sample results or just explain what additional experiment we will conduct and how we will do it. Justification and reasoning should be in details or a brief explanation with an assurance to add a detailed discussion in the final version suffices.\n TIA\n    submitted by    /u/srvsinha186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txvlf0/d_icml_author_response_what_reviewers_expect/",
          "publishedOn": "2022-04-06T20:36:00.000Z",
          "wordCount": 234,
          "title": "[D] ICML author response. What reviewers expect.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txvky1/d_questions_for_a_tpm_for_ml_interview_at_google/",
          "author": null,
          "description": "Hey all,\n I have a technical program manager interview soon for an ML team at google and I want to know if anyone has any sample role-related questions I can gauge myself with.\n I have a strong data science & statistics background but that doesn't always translate to deep ML knowledge like an ML Engineer might have.\n Any resources or sample questions? I have not found adequate results from google regarding this team area specifically.\n    submitted by    /u/math_is_my_religion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txvky1/d_questions_for_a_tpm_for_ml_interview_at_google/",
          "publishedOn": "2022-04-06T20:35:25.000Z",
          "wordCount": 176,
          "title": "[D] Questions for a TPM for ML interview at Google",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txv5o3/d_anyone_knows_any_high_accuracy_models_on_uci/",
          "author": null,
          "description": "Hi everyone. This is my first-time post here, and I hope I did not break any sub rules.\n Currently, I am doing some research with the UCI Adult dataset(https://archive.ics.uci.edu/ml/datasets/adult). This first step is to build a high-accuracy classifier model. \n Does anyone know any high accuracy model on this dataset (more than 90%)? I use many machine learning models like logistic regression and neural network. But no matter how complex the model is, I can only get an accuracy of about 85% on the test set. I tried to google but I found many others also have similar results of about 85%.\n Any posts or papers will be helpful! Thanks in advance for your help!\n    submitted by    /u/Akasakura888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txv5o3/d_anyone_knows_any_high_accuracy_models_on_uci/",
          "publishedOn": "2022-04-06T20:16:14.000Z",
          "wordCount": 218,
          "title": "[D] Anyone knows any high accuracy models on UCI adult dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txtp5u/r_using_gamma_distribution_to_improve_longtail/",
          "author": null,
          "description": "Predicting longtail events can be one of the more challenging ML tasks. Last year my team published a blog article where we improved DoorDash’s ETA predictions by 10% by tweaking the loss function with historical and real-time features. I thought members of the community would be interested in learning how we improved the model even more by using Gamma distribution-based inverse sampling approach to loss function tuning. Please check out the new article for all the technical details and let us know your feedback on our approach.\n ​\n https://doordash.engineering/2022/04/06/using-gamma-distribution-to-improve-long-tail-event-predictions/\n    submitted by    /u/pmp-dash1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txtp5u/r_using_gamma_distribution_to_improve_longtail/",
          "publishedOn": "2022-04-06T19:10:10.000Z",
          "wordCount": 188,
          "title": "[R] Using Gamma Distribution to Improve Long-Tail Event Predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txth9e/d_reading_the_tea_leaves_expert_endusers/",
          "author": null,
          "description": "Hey there, just a heads up we at The Gradient just published a new article discussing explainability - \n  \n\"This article uses the common backdrop of competitive games to explore the ways in which domain experts adapt to new technologies that lack explainability. I illustrate how interpretations vary based on user experience and model architecture, and how special care must be taken when adapting models to human-centric problems.\"\n  \nCheck it out here if you think it's interesting / worth discussing:\n Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable\n    submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txth9e/d_reading_the_tea_leaves_expert_endusers/",
          "publishedOn": "2022-04-06T19:00:19.000Z",
          "wordCount": 189,
          "title": "[D] Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable",
          "imageUrl": "https://external-preview.redd.it/wnVaar4ZXR3zqeMsXegEzJEPVdp1PkLFsHJagJ249DM.jpg?auto=webp&s=53c299a85d48eb7bedf6e5ec47ca846a5c52c38f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txqkin/project_learning_to_play_settlers_of_catan_with/",
          "author": null,
          "description": "Hi all,\n I just wanted to share a project I've been working on for the past year - using deep RL to learn to play the board game Settlers of Catan.\n I expect everyone is aware of the results that DeepMind/OpenAI have got recently on Go, DOTA 2, Starcraft 2 etc, but I was motivated to see how much progress could be made with existing RL techniques on a reasonably complex game - but with access to significantly less computational resources.\n Whilst I didn't end up with an agent that performs at a super-human level, there was clear learning progress and the results were quite interesting. I decided to do a full write-up of the project here, which I figured could be useful for anyone else who is interested in trying to apply DRL to a new, complicated environment. I also open-sourced all the code here for anyone interested.\n If anyone has any feedback or any questions at all that'd be great!\n    submitted by    /u/henrythepaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txqkin/project_learning_to_play_settlers_of_catan_with/",
          "publishedOn": "2022-04-06T16:49:47.000Z",
          "wordCount": 952,
          "title": "[Project] Learning to Play \"Settlers of Catan\" With Deep RL - Writeup and Code",
          "imageUrl": "https://external-preview.redd.it/MCy14opBjTIKzwl5JN-l_h8ogp8jGD7JGmk-A4mmZJI.jpg?auto=webp&s=b34f246a1d389b97fb2013f3661ccf8afbf4403e"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txqapw/d_icml_rebuttals_optional_or_semimandatory/",
          "author": null,
          "description": "Hi,\n We just submitted to ICML 2022 and got our reviews back. We were excited to see that 4/4 reviews were positive and acknowledged the contribution of the paper. However, there were some minor criticisms (e.g. didn't do good enough lit reviews, could use a few more experiments) across several reviews.\n I was wondering if it is ever acceptable to not submit a rebuttal? Can a rebuttal in this case actually hurt us by rocking the boat---or for ICML is the norm that you should always submit a rebuttal that addresses all the reviewers' criticisms.\n We were wondering what the norm is for ICML specifically?\n    submitted by    /u/optimistic313  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txqapw/d_icml_rebuttals_optional_or_semimandatory/",
          "publishedOn": "2022-04-06T16:37:16.000Z",
          "wordCount": 335,
          "title": "[D] ICML rebuttals optional or semi-mandatory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txples/r_hierarchical_textconditional_image_generation/",
          "author": null,
          "description": "Blog post.\n Paper (pdf file format). The paper is also linked to in the above blog post.\n Abstract\n  \nContrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.\n  \nOpenAI's Sam Altman used DALL-E 2 to generate ~20 text prompt requests from Twitter users. The results are here, with individual result links and other samples in this comment from another Reddit user in a different post.\n Twitter thread about the paper (not from the paper authors).\n Sam Altman's blog post about DALL-E 2.\n  \nHopefully this summer, we’ll do a product launch and people will be able to use it for all sorts of things.\n  \n   submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txples/r_hierarchical_textconditional_image_generation/",
          "publishedOn": "2022-04-06T16:04:57.000Z",
          "wordCount": 773,
          "title": "[R] Hierarchical Text-Conditional Image Generation with CLIP Latents. This is the paper for OpenAI's DALL-E 2",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txm40w/is_the_first_boss_attempt_phenomenon_know_to/",
          "author": null,
          "description": "I'm curious about wether this unusual learning trajectory observed in humans has also been observed in artificial neural nets. A well known phenomenon in the 'dark souls' video game series is that ones first attempt at a boss is often much better than subsequent attempts. Boss hp at time of death by attempt might go something like: 35%, 55%, 85%, 87%, 75%, 54%, , 60%, 43%, 27%, 38%, 12%, 0%. This sounds very anecdotal, but its know to the community of these games to be a real thing. See this thread for evidence. Have NN playing games been known to exhibit a similar pattern, with peak in success early on, followed by a step descent , then a slow gradual climb? Or is this a purely human phenomenon?\n My hypothesis as to why this happens is that over the course of the first couple attempts, the player learns a bunch of bad strategies which must be slowly unlearned, whereas on attempt one, the player has no defined strategies good or bad.\n    submitted by    /u/Greenface1998  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txm40w/is_the_first_boss_attempt_phenomenon_know_to/",
          "publishedOn": "2022-04-06T13:24:35.000Z",
          "wordCount": 888,
          "title": "Is the 'first boss attempt' phenomenon know to occur amongst NN playing games, or is this learning trajectory unique to human players?[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txktli/r_disentangling_abstraction_from_statistical/",
          "author": null,
          "description": "submitted by    /u/papajan18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txktli/r_disentangling_abstraction_from_statistical/",
          "publishedOn": "2022-04-06T12:16:57.000Z",
          "wordCount": 116,
          "title": "[R] Disentangling Abstraction from Statistical Pattern Matching in Human and Machine Learning",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txkl43/projectp_who_invented_graph_neural_networks/",
          "author": null,
          "description": "Just a side project (only for me) in which I try to sum up some history of DL. Can't be 100% sure this is the first article in which they appear: Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., & Monfardini, G. (2008). The graph neural network model. IEEE transactions on neural networks, 20(1), 61-80. Would appreciate any help. Thanks\n    submitted by    /u/Siddh__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txkl43/projectp_who_invented_graph_neural_networks/",
          "publishedOn": "2022-04-06T12:03:35.000Z",
          "wordCount": 633,
          "title": "[Project][P] Who invented Graph Neural Networks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txkh8m/r_gpbart_a_novel_bayesian_additive_regression/",
          "author": null,
          "description": "(not my paper)\n paper: https://arxiv.org/abs/2204.02112\n abstract: \"The Bayesian additive regression trees (BART) model is an ensemble method extensively and successfully used in regression tasks due to its consistently strong predictive performance and its ability to quantify uncertainty. BART combines \"weak\" tree models through a set of shrinkage priors, whereby each tree explains a small portion of the variability in the data. However, the lack of smoothness and the absence of a covariance structure over the observations in standard BART can yield poor performance in cases where such assumptions would be necessary. We propose Gaussian processes Bayesian additive regression trees (GP-BART) as an extension of BART which assumes Gaussian process (GP) priors for the predictions of each terminal node among all trees. We illustrate our model on simulated and real data and compare its performance to traditional modelling approaches, outperforming them in many scenarios. An implementation of our method is available in the \\textsf{R} package \\texttt{rGPBART} available at: https://github.com/MateusMaiaDS/gpbart.\"\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txkh8m/r_gpbart_a_novel_bayesian_additive_regression/",
          "publishedOn": "2022-04-06T11:57:53.000Z",
          "wordCount": 468,
          "title": "[R] GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txijls/d_anyone_know_about_any_interesting_recent/",
          "author": null,
          "description": "I’m currently writing a research paper for my MSc on neuromorphic sensing and spike neural networks and most good papers are from around 2015 and was looking for something more recent.\n Anyone here heard of any interesting upgrades in architecture or applications?\n Cheers!\n    submitted by    /u/GandhisLittleHelper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txijls/d_anyone_know_about_any_interesting_recent/",
          "publishedOn": "2022-04-06T09:54:31.000Z",
          "wordCount": 145,
          "title": "[D] Anyone know about any interesting recent improvements with SNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txha3z/noticing_that_profs_focus_on_male_students_goals/",
          "author": null,
          "description": "Hello, I’m currently a graduate student. I do different projects and for some I get to decide on what I want the scope to be. I do have to get the scope/ plan/ idea approved first. I pitch my ideas to profs who aren’t directly my profs and normally 5-6 other students will pitch ideas to the same group of profs at the same time….. I noticed that i get really different questions and feedback in comparison to my peers. I’m a female and my peers are male… I didn’t start out with this outlook but I’m starting to search for reasons why I often get questioned about my capabilities to preform a project ( which is normal enough but I get questioned to the point where explaining my approach isn’t enough and they ask me for examples of codes) and my peers definitely do not get asked about there capabilities, rather they tell them what they can do and they don’t get questioned. …………… really frustrating.\n    submitted by    /u/tyger-lily  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txha3z/noticing_that_profs_focus_on_male_students_goals/",
          "publishedOn": "2022-04-06T08:19:25.000Z",
          "wordCount": 1258,
          "title": "Noticing that profs focus on male student’s goals and female student’s capabilities, any weigh-in? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txgmti/d_how_to_write_a_mlhealthcare_paper_where_the/",
          "author": null,
          "description": "As a project in the course of my PhD, I had to create a prototype for a project. My PhD is application of machine learning in health care. The project definition and scope was faaaar too wide. However, I managed to create a working demo which encompasses some use cases of the project. At best, it can be called a framework, where I have put in different DL components and it works okay for those use cases only. Most of the components, I have used are pre-trained language models (maybe fine tuned them to my use case). However, there is no active training or learning involved. This is because I created this for a demo only. I also created a very small dataset and tested the framework over the dataset and the results were ok. However, my supervisor now wants me to write a paper, as he is confident, that the use case is rather unique and my working framework is a good first step. I believe, his aim is to get me started on the paper writing process, which I appreciate. However, I am not confident about it at all.\n My question is, can a 'framework' composed of pre-trained models with the end goal of solving a problem in health care is good enough? Are there precedents of any such paper? And if I trust my supervisor's instincts, are there any fancy ways to frame the framework so that it does not look so basic?\n    submitted by    /u/Complex_State9960  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txgmti/d_how_to_write_a_mlhealthcare_paper_where_the/",
          "publishedOn": "2022-04-06T07:30:09.000Z",
          "wordCount": 556,
          "title": "[D] How to write a ML+Healthcare paper where the research was a framework with pre-trained models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txfq52/p_building_a_knowledge_based_recommender_system/",
          "author": null,
          "description": "I am trying to build a knowledge based recommender system but do not have prior knowledge. \n We first take in user inputs such as occasion, weather, top wear and bottom wear, color. Based on this we want to create a knowledge base and recommend clothes. \n Can anyone help me on how to go about on doing this process step by step and what algorithms and technology to be used?\n    submitted by    /u/bills70  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txfq52/p_building_a_knowledge_based_recommender_system/",
          "publishedOn": "2022-04-06T06:26:17.000Z",
          "wordCount": 162,
          "title": "[P] Building a knowledge based recommender system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txdhxt/d_icml_2022_paper_reviews/",
          "author": null,
          "description": "ICML 2022 paper reviews are supposed to be released soon. Creating a discussion thread for this year's reviews.\n    submitted by    /u/zy415  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txdhxt/d_icml_2022_paper_reviews/",
          "publishedOn": "2022-04-06T04:06:11.000Z",
          "wordCount": 657,
          "title": "[D] ICML 2022 Paper Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/txbyy7/d_in_general_should_you_let_the_model_find/",
          "author": null,
          "description": "I’ll give an example to better explain my question (don’t get hung up on the numbers, it’s all made up). Say you are using a tree based model trying to project how many points a player will score in a given basketball game.\n Most players shoot free throws at a slightly lower percentage on the road, than they do at home. However, the magnitude varies player to player. Let’s assume for 95% of players with significant data, the ratio of home free throw percentage to away is 1 to 1.15. Generally speaking, older players are closer to 1 and younger players are around 1.1 (since older players get used to the opposing crowd).\n Now also say it takes 100 home and 100 away free throws to get a stable reliable ratio.\n Now say a young player only has 50 home, and 50 away free throws. With this amount of data he has a ratio of 1, however the sample size is not enough to be fully stable.\n Which would be better…\n 5 features into this model, his home away ratio, average ratio for players his age, home free throw count, and away free throw attempts.\n 1 feature. His ‘projected’ home away ratio, which is a weighted average of his ratio with the average for plaeyrs his age. Since he’s 50% of the way to significance, 0.5 * 1 + 0.5 * 1.1 = 1.05\n The benefit of the of the first choice is that it may find other interactions that I never conceived of, however, it could incorporate noise. Is there a general consensus, or is this just a try both and see what works?\n    submitted by    /u/irndk10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/txbyy7/d_in_general_should_you_let_the_model_find/",
          "publishedOn": "2022-04-06T02:41:45.000Z",
          "wordCount": 1317,
          "title": "[D] In general, should you let the model find interactions between many basic features, or should you use feature engineering to ‘help’ the model find the interaction?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx7e34/d_why_arent_new_llms_using_the_perceiver/",
          "author": null,
          "description": "Perceiver and PerceiverIO (https://arxiv.org/abs/2107.14795) appear to offer significantly improved FLOP efficiency, but new LLMs (including Deepmind's own Gopher) don't use it.\n What gives? Is it still too new, or is the Perceiver architecture not appropriate for LLMs?\n    submitted by    /u/deeceeo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx7e34/d_why_arent_new_llms_using_the_perceiver/",
          "publishedOn": "2022-04-05T22:48:26.000Z",
          "wordCount": 137,
          "title": "[D] Why aren't new LLMs using the Perceiver architecture?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx59tj/r_metalearning_machines_in_a_single_lifelong/",
          "author": null,
          "description": "Saw this posted on Schmidhuber's Twitter:\n Meta-Learning Machines in a Single Lifelong Trial: lecture video (24 min) presented at meta-learning workshops at ICML 2020 and NeurIPS 2021. URL of talk: https://youtu.be/2GgGVdkq2bU\n Abstract\n The most widely used machine learning algorithms were designed by humans and thus are hindered by our cognitive biases and limitations. Can we also construct meta-learning algorithms that can learn better learning algorithms so that our self-improving AIs have no limits other than those inherited from computability and physics? This question has been a main driver of my research since I wrote a thesis on it in 1987. In the past decade, it has become a driver of many other people's research as well. Here I summarize our work starting in 1994 on meta-reinforcement learning with self-modifying policies in a single lifelong trial, and - since 2003 - mathematically optimal meta-learning through the self-referential Gödel Machine. This talk was previously presented at meta-learning workshops at ICML 2020 and NeurIPS 2021. Many additional publications on meta-learning can be found at https://people.idsia.ch/~juergen/metalearning.html\n    submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx59tj/r_metalearning_machines_in_a_single_lifelong/",
          "publishedOn": "2022-04-05T21:11:28.000Z",
          "wordCount": 318,
          "title": "[R] Meta-Learning Machines in a Single Lifelong Trial: lecture video (24 min) presented at meta-learning workshops at ICML 2020 and NeurIPS 2021 (Schmidhuber YouTube Talk)",
          "imageUrl": "https://external-preview.redd.it/vi10fYGumGdDuKtmrgIT6Ts5ESncbLCIuBXVAMdVDLw.jpg?auto=webp&s=91df7b5da1afb82cc84b2707d6c5641d50b8959b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx42h9/d_hyperparameter_tuning_does_it_even_work/",
          "author": null,
          "description": "Hi *,\n I've been working for the last 5 years as Data Scientist. During this time I have tried dozens of times to improve my models via hyperparameter tuning, but I've never got improvements from there. I've tried all the possible approaches: grid search, random search, bayesian search, etc. But in no case did I get satisfactory results.\n Does this happen to anyone else? Have you ever got robust improvements via HP tuning?\n    submitted by    /u/AM_DS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx42h9/d_hyperparameter_tuning_does_it_even_work/",
          "publishedOn": "2022-04-05T20:19:19.000Z",
          "wordCount": 291,
          "title": "[D] Hyperparameter Tuning: does it even work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx3f5g/d_autoregressive_model_for_graph_generation/",
          "author": null,
          "description": "Autoregressive models like GPT-2 do fairly well in text generation. Is it possible to do the same for graph data? A transformer based model Graphormer has recently shown its effectiveness in graph representation learning. Is there any way I can train Graphormer or any other model to generate graphs from an initial graph context?\n    submitted by    /u/ratt_m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx3f5g/d_autoregressive_model_for_graph_generation/",
          "publishedOn": "2022-04-05T19:51:08.000Z",
          "wordCount": 146,
          "title": "[D] Autoregressive model for graph generation?",
          "imageUrl": "https://external-preview.redd.it/eoBMYj_duATkDQ_aqqR_eU3Icw0zdJNAY3EmrOgWvT8.jpg?auto=webp&s=710b35efc10fa9f6ffadea65f77fe714c87184c5"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx1bjv/d_how_do_you_guys_hear_about_the_latest_papers/",
          "author": null,
          "description": "Hi! I'm a first-year Grad Student in Computer Vision and I am trying to get caught up on the latest research in my field. It seems like everyone in CS has heard about all of the latest papers but I just have no idea how. My knowledge is limited to general ideas and doesn't know any specific papers unless they have like 20000+ citations.\n So my question is: how do you hear about these papers and get caught up? Is there a reference somewhere that puts together a list of all the \"must-read\" papers that have come out? I feel like I am already 5 years behind in my knowledge. It would be great if there was something like \"Top 5 papers of the week\" that I could read to stay on top of things.\n Also, this doesn't just apply to Vision. I would like to have an idea of the other major developments in other fields (like NLP, general ML/DL, etc.) since I think that can carry over to my field.\n Thanks! Looking forward to your replies\n    submitted by    /u/TobusFire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx1bjv/d_how_do_you_guys_hear_about_the_latest_papers/",
          "publishedOn": "2022-04-05T18:18:42.000Z",
          "wordCount": 709,
          "title": "[D] How do you guys hear about the latest papers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tx0z89/d_fake_authors_and_paper_riders/",
          "author": null,
          "description": "Based on my experiences in both academia and industry, I see that many researchers get listed as authors on papers solely for having attended the relevant project meetings, despite not contributing anything substantial to the work. I know of several people who've gotten on dozens of papers this way, despite not being able to explain the main details behind many of the papers they \"co-authored.\" Of course, they can then claim credit for the work publicly as well as have their academic profile benefit from the citations accrued by the work.\n I've noticed that typically, these people are initially invited onto the project because they are on chummy terms with someone on the project. Concerningly, the more someone successfully \"paper-rides\" this way, the stronger their publication record looks, which makes it easier for them to find their way onto more projects to paper ride in the future.\n It seems that the obsessive focus on paper counts and citations has encouraged the rise of intellectually dishonest strategies for maximizing one's academic footprint. The huge research scientist salaries at top industry labs, which similarly obsess over paper counts and citations in their hiring process, only amplifies the incentive for paper riding.\n The reason I think it is bad: As more people paper ride, co-authorship on a paper gradually becomes a worse indication of expertise. Not to mention, paper riders are intellectually dishonest, by claiming credit for research that they didn't significantly contribute to. In a sense, it seems like a roundabout form of plagiarism.\n I know some might disagree with this take, as some people believe in being as generous about co-authorship as possible. I find that mindset to create the perfect environment for paper riders to flourish. I'm wondering if you've also seen paper riding happen and whether you think this behavior is good or bad.\n    submitted by    /u/alwayshumming  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tx0z89/d_fake_authors_and_paper_riders/",
          "publishedOn": "2022-04-05T18:03:17.000Z",
          "wordCount": 2044,
          "title": "[D] Fake authors and paper riders",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twzqsk/dr_generate_random_sample_for_exponentiated/",
          "author": null,
          "description": "Hi there experts, I have a real distribution for which I had run this scipy script to detect the best fit:\n However, the script outputs 4 parameter values and the best fit is actually a Exponentiated Weibull distribution.\n Now I am clueless how to generate a sample list of data of n-size. I know for sure about the normal distribution after getting these params as mean and sigma. How to I generate such list. Please help.\n ​\n ​\n https://preview.redd.it/79n28icmsqr81.png?width=1141&format=png&auto=webp&s=d9478691c06f5cdfe03af4f82db8293443e91f1e\n    submitted by    /u/GoldenDew9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twzqsk/dr_generate_random_sample_for_exponentiated/",
          "publishedOn": "2022-04-05T17:06:57.000Z",
          "wordCount": 172,
          "title": "[D][R] Generate random sample for exponentiated Weibull distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twznq8/rd_vae_embedding_space_can_we_force_it_to_learn_a/",
          "author": null,
          "description": "I understand that certain AE types such as B-VAE disentangle certain aspects of variation in the data, and those such as Conditional AE or VAE allow us to separate these aspects with labels.\n However, what I have seen is that the embedding space doesn't cluster the images as well as some contrastive methods. However contrastive methods require non-elegant negative sampling etc. \n Can we somehow force the VAE to learn both the variational lower bound as well as learn a good metric between samples such as visually similar samples are better clustered together?\n    submitted by    /u/jim_from_truckistan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twznq8/rd_vae_embedding_space_can_we_force_it_to_learn_a/",
          "publishedOn": "2022-04-05T17:03:16.000Z",
          "wordCount": 203,
          "title": "[R][D] VAE Embedding Space - Can we force it to learn a metric?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twylnl/d_jetson_agx_orin_dev_kit_as_a_standalone/",
          "author": null,
          "description": "The Jetson Orin 64gb model has \"275 Sparse|138 Dense INT8 TOPS\", and I am a little confused about how to compare this to something like the RTX a6000's performance. I am looking to do deep rl training and am new to the field. What metrics make a difference for deep rl? Any thoughts on the Orin dev kit's ability to train deep rl?\n    submitted by    /u/here_to_create  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twylnl/d_jetson_agx_orin_dev_kit_as_a_standalone/",
          "publishedOn": "2022-04-05T16:14:45.000Z",
          "wordCount": 206,
          "title": "[D] Jetson AGX Orin dev kit as a stand-alone training platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twxmk9/d_with_the_rise_of_automl_what_are_the_important/",
          "author": null,
          "description": "Some time down the road, when AutoML becomes more established, it can help us determine the best ML model and hyperparameters for a particular problem. This will not replace data scientist, as we still need data scientists for their domain knowledge, which is critical for scoping business problems, pre-processing data, and deriving business insights from the trained model. However, since data scientists no longer need to deal with the technicalities of a model in the near future (i.e. they no longer have to tune hyperparameters, determine the best opitmistion function etc), is there still a need for aspiring data scientists to learn about the intricacies and nuances behind the various models (maybe by coding the model from scratch)? Or is it enough for them to learn how to operate an AutoML system? (My question is referring to the corporate world in general and not to academia) Thanks in advance for your answers :)\n    submitted by    /u/smart_oinker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twxmk9/d_with_the_rise_of_automl_what_are_the_important/",
          "publishedOn": "2022-04-05T15:30:36.000Z",
          "wordCount": 2045,
          "title": "[D] With the rise of AutoML, what are the important skills for a ML career?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twu1z5/p_automlconf_competition_dac4automl/",
          "author": null,
          "description": "Hi everyone!\n We've just launched a competition at the AutoML-Conf 2022, the DAC4AutoML competition. It has two tracks, one for configuring a Computer Vision model and one for a RL pipeline: https://automl.github.io/dac4automlcomp/ \n And what is DAC exactly? It means we want to find well-performing hyperparameter configurations like in Algorithm Configuration, but we do it dynamically - thus DAC, Dynamic Algorithm Configuration. As to how that is supposed to happen? We don't put any restrictions on the solutions for the competitions, so you can submit your hand-tuned static hyperparameter setting if you want. Or you can use some sort of heuristic, a regression model, reinforcement learning, ... whatever works. \n If you're interested in participating, you can submit from now on until the 18.06. AOE, the winners will be announced at the AutoML-Conf.\n    submitted by    /u/catsortion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twu1z5/p_automlconf_competition_dac4automl/",
          "publishedOn": "2022-04-05T12:42:17.000Z",
          "wordCount": 320,
          "title": "[P] AutoML-Conf Competition: DAC4AutoML",
          "imageUrl": "https://external-preview.redd.it/hwN3EBf7WXi3MEvXiPgqOQzZmfA3yEU8ZOPYIry-WJw.jpg?auto=webp&s=e08b4e79f3d8a80bcf43263d687e29f7665b1ad1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twtg6d/d_imagenet_original_pictures/",
          "author": null,
          "description": "As I understood it Imagenet got generated from internet images, but I am unable to to find the originals using naive image search. Is there any mapping? I wonder if imagenet data is a cropped versions of original pictures or not, i don't see it in the paper.\n    submitted by    /u/LeanderKu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twtg6d/d_imagenet_original_pictures/",
          "publishedOn": "2022-04-05T12:07:50.000Z",
          "wordCount": 222,
          "title": "[D] Imagenet Original Pictures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twt98b/p_ufo_lands_on_highway_or_depth_estimation_using/",
          "author": null,
          "description": "Article describing depth estimation using machine learning models and 3D visualization of depth maps using three.js.\n https://www.storminthecastle.com/posts/ufos_and_depth/\n    submitted by    /u/CakeStandard3577  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twt98b/p_ufo_lands_on_highway_or_depth_estimation_using/",
          "publishedOn": "2022-04-05T11:57:51.000Z",
          "wordCount": 120,
          "title": "[P] UFO Lands on Highway! Or Depth Estimation using ML",
          "imageUrl": "https://external-preview.redd.it/EYCpGAaDtOBH3R2hcX5A8p4nQUaWGRn3Vhhp-gVnshg.jpg?auto=webp&s=73ce7b6d98e380ab00fbb89bc361e6c1054e477f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twspe4/d_could_styleganxl_be_great_for_outofdomain/",
          "author": null,
          "description": "In the context of text-to-image generation, I'd say one of the reasons VQGAN is so used in popular notebooks is that it can deal with many concepts, while stylegan used to be limited to the domain it was trained for. \n That may be about to change with the rollout release of Stylegan-XL weights trained on Imagenet. This notebook (https://github.com/CasualGANPapers/StyleGANXL-CLIP) has had nice results with objects never seen by the model, such as \"apple\" and \"ant\", as well as scenes such as \"judo athletes fighting\"\n Please note that the Stylegan-XL weights are currently available for 128x128 pixels. ETA for the 256 resolution is 14.04.22\n    submitted by    /u/HrodRuck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twspe4/d_could_styleganxl_be_great_for_outofdomain/",
          "publishedOn": "2022-04-05T11:25:38.000Z",
          "wordCount": 222,
          "title": "[D] Could Stylegan-XL be great for out-of-domain generation?",
          "imageUrl": "https://external-preview.redd.it/ZKt6uousVLNiB0ssq6GUS-K_Hr81UD28U8l9oMEB5Hw.jpg?auto=webp&s=e8d1d8a82b656126d33e6d703410f037e33552e1"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twqel5/discussion_support_vector_machines_in_2022/",
          "author": null,
          "description": "My post is inspired by this discussion.\n In that thread, OP asked why support vector machines are still taught. People offered several thoughts: they're easier to think about, they're still perfectly good for some real-world problems, and for some problems they apparently rival deep networks.\n I did a project for a class around six years ago using an SVM as implemented in scikit-learn. I was pretty satisfied with the project, but I also experienced some frustrations, and came away with some questions. I started working with Tensorflow and DNNs in earnest soon after finishing that project, and I largely stopped thinking about SVM. I would like to revive the questions I asked, but never answered, here.\n  \nA DNN with multiple outputs can potentially use a single neuron in the prediction of more than one output. For multiple, mutually-exclusive categories, this makes good sense. An SVM with multiple outputs in scikit-learn was implemented as pairs of one-vs-one SVMs, each of which was independently fit to data. This gets inefficient quickly. Has this changed? Can it be changed?\n DNN training at scale is a problem that many people have worked hard to make practical. Even non-experts like myself use our home GPUs to accelerate training of DNNs on large data sets. In scikit-learn, SVM training was implemented in a single thread on one CPU core. If you are performing cross-validation or a hyperparameter optimization study, it might be practical to parallelize fitting; one thread for each distinct condition. But can you parallelize the SVM fitting algorithm for a single condition? I went looking for software, but I couldn't find anything.\n  \nOver to you folks. Cheers.\n    submitted by    /u/aotus_trivirgatus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twqel5/discussion_support_vector_machines_in_2022/",
          "publishedOn": "2022-04-05T08:46:32.000Z",
          "wordCount": 1715,
          "title": "[Discussion] Support Vector Machines... in 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twqeei/r_restormer_efficient_transformer_for/",
          "author": null,
          "description": "​\n Visual Results\n With Restormer, you can remove noise, motion blur, defocus blur, and rain streaks from your own images.\n Paper: https://arxiv.org/abs/2111.09881\n Github: https://github.com/swz30/Restormer\n Colab Demo: https://colab.research.google.com/drive/1C2818h7KnjNv4R1sabe14_AYL7lWhmu6?usp=sharing\n Gradio Web Demo: https://huggingface.co/spaces/swzamir/Restormer\n    submitted by    /u/swz30  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twqeei/r_restormer_efficient_transformer_for/",
          "publishedOn": "2022-04-05T08:46:08.000Z",
          "wordCount": 166,
          "title": "[R] Restormer: Efficient Transformer for High-Resolution Image Restoration (CVPR 2022--ORAL) + Colab Demo + Gradio Web Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twmnol/r_d_seq2seq_model_hyperparameters_tuning/",
          "author": null,
          "description": "Does anyone have any advices or research papers on what hyperparameters do researchers use for their seq2seq model? \n I am interested in knowing whether hyperparameters such as dropout, or recurrent dropout, batchnorm, etc etc, are even necessary in the usage of seq2seq model, but couldn’t find anything on it for weeks.\n In the case, let’s say, using gridsearchCV, what hyperparameters do you tweak for ur seq2seq model? (Other than the usual stuff like number of neurons, etc). There is absolutely zero information for that on seq2seq model, and everyone just assumes that putting an attention mechanism solves everything without hyperparameters tunings. I have also looked up on codes on seq2seq, and no hyperparameters tunings were shown whatsoever. \n FYI, this is in the context of time series data, using seq2seq, if that matters.\n Thanks\n    submitted by    /u/plsendfast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twmnol/r_d_seq2seq_model_hyperparameters_tuning/",
          "publishedOn": "2022-04-05T04:32:59.000Z",
          "wordCount": 318,
          "title": "[R] [D] Seq2seq model hyperparameters tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twmfom/d_has_anyone_seen_any_papers_related_to_gans/",
          "author": null,
          "description": "I’ve been reading many papers lately pertaining to GANs, with more and more introducing supervised loss into the generator’s objective function. However, no one ever seems to show that the optimum remains undisturbed. Results seem to be strictly empirical most of the time. \n Has anyone seen any papers where it is shown that the disruption to the generator’s loss doesn’t harm convergence?\n    submitted by    /u/king_of_walrus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twmfom/d_has_anyone_seen_any_papers_related_to_gans/",
          "publishedOn": "2022-04-05T04:19:49.000Z",
          "wordCount": 291,
          "title": "[D] Has anyone seen any papers related to GANs which prove that the optimum remains unchanged when adding supervised loss (e.g. L1, L2)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twidsn/d_what_is_your_experience_with_fake_results_or/",
          "author": null,
          "description": "I am curious what is everyones experience with completely faked, falsified, or fabricated results in the area? Another aspect of this I think is people taking heavily overfitted results and finding one decent example that is from the test set and claiming their method is awesome. How much of this have you seen and how much of the research out there fits into this category?\n    submitted by    /u/LifeguardDismal142  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twidsn/d_what_is_your_experience_with_fake_results_or/",
          "publishedOn": "2022-04-05T00:48:43.000Z",
          "wordCount": 183,
          "title": "[D] What is your experience with Fake results or overfitted results being sold as awesome?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twcdt2/d_why_do_we_still_teach_support_vector_machines/",
          "author": null,
          "description": "Honest question: are there any applications for which SVMs are the best choice? In my experience, no one seems to use this methodology anymore, though maybe I'm wrong. It just kinda feels like teaching people how to use a slide rule when everyone has calculators.\n    submitted by    /u/WartimeHotTot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twcdt2/d_why_do_we_still_teach_support_vector_machines/",
          "publishedOn": "2022-04-04T20:38:01.000Z",
          "wordCount": 937,
          "title": "[D] Why do we still teach support vector machines?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/twc4or/d_paper_explained_continual_backprop_stochastic/",
          "author": null,
          "description": "https://youtu.be/zEMOX3Di2Tc\n This paper finds what seems to be a new phenomenon when working in the continual learning/life-long learning domain. If new tasks are continually introduced to an agent, it seems to loose it's ability to learn the more time progresses. Intuitively it's similar to this idea that \"an old dog can't learn new tricks\". They propose a fairly simple method of overcoming this limitation that involves resetting weights that are not contributing much to the outcome of the network. They call the method Continual Backprop.\n ​\n Outline:\n 0:00 - Overview\n 2:00 - Paper Intro\n 2:53 - Problems & Environments\n 8:11 - Plasticity Decay Experiments\n 11:45 - Continual Backprop Explained\n 15:54 - Continual Backprop Experiments\n 22:00 - Extra Interesting Experiments\n 25:34 - Summary \n ​\n Paper link: https://arxiv.org/abs/2108.06325\n    submitted by    /u/SlickBlueML  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/twc4or/d_paper_explained_continual_backprop_stochastic/",
          "publishedOn": "2022-04-04T20:27:50.000Z",
          "wordCount": 237,
          "title": "[D] Paper Explained - Continual Backprop: Stochastic Gradient Descent with Persistent Randomness",
          "imageUrl": "https://external-preview.redd.it/fOTo43KuL6oL4o_WNxFDpy-aere0pzHjmcSlF2unamc.jpg?auto=webp&s=bc72dbd3a79a558d333d642635b7f1cc1b5d73a8"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw9jp5/r_googles_540b_dense_model_pathways_llm_unlocks/",
          "author": null,
          "description": "Blog: https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\n Paper: https://goo.gle/palm-paper\n - AFAIK from the Blogpost, Scaling laws still hold up (i.e not yet plateaued)\n - New transfer learning capabilities, outperforms fine-tuned models with 50x less data (Codex-12B)\n - The interesting part is how it meta-learns techy geeky jokes and is able to correlate concepts, and explain jokes suggesting starting doing a bit more meta-learning than GPT3 ever could.... But still not enough to generate decent ones (though the joke wasn't particularly humorous, so I may be underestimating)\n SoTA on various tasks, chain-of-thought-reasoning still holds up to scaling and outperforms some reasoning benchmarks, BIG-bench sees a huge improvement and general LLM thingys :)\n    submitted by    /u/Competitive-Rub-1958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw9jp5/r_googles_540b_dense_model_pathways_llm_unlocks/",
          "publishedOn": "2022-04-04T18:42:07.000Z",
          "wordCount": 1256,
          "title": "[R] Google's 540B (Dense) model Pathways LLM, \"Unlocks\" new tasks proportional to scale",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw4wyj/r_minimum_description_length_recurrent_neural/",
          "author": null,
          "description": "https://arxiv.org/abs/2111.00600\n https://preview.redd.it/l6dni0007jr81.png?width=4888&format=png&auto=webp&s=82c7c9b9433b79c66318090ff85e4535c35ddb18\n    submitted by    /u/inland-1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw4wyj/r_minimum_description_length_recurrent_neural/",
          "publishedOn": "2022-04-04T15:33:42.000Z",
          "wordCount": 153,
          "title": "[R] Minimum Description Length Recurrent Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw2ec1/r_cfp_evorl_gecco_2022_one_week_before_the/",
          "author": null,
          "description": "CALL FOR PAPERS\n EvoRL 2022\n Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw2ec1/r_cfp_evorl_gecco_2022_one_week_before_the/",
          "publishedOn": "2022-04-04T13:45:43.000Z",
          "wordCount": 600,
          "title": "[R] CfP EvoRL @ GECCO 2022. One week before the deadline!",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tw0c1o/p_looking_for_a_dataset/",
          "author": null,
          "description": "Hey! New Here. I logged back into Reddit after years just to ask this question on this forum. I need to test a model, based loosely on BERT, that classifies a piece of text as having right or left political ideology leaning and whether it promotes any racial or religious stereotypes.\n For training purpose we used SBIC, IBC, and Stereoset. Though these only contain short sentences which are labeled as belonging to only one of the above categories.\n Is anyone aware of any other Dataset which can be used for this purpose, which hopefully contains text labeled as promoting or containing a political leaning (left/right, conservative/liberal, neutral) and further either any racial or religious stereotypes?\n Very thankful in adv\n    submitted by    /u/Fee_Imaginary  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tw0c1o/p_looking_for_a_dataset/",
          "publishedOn": "2022-04-04T12:02:44.000Z",
          "wordCount": 205,
          "title": "[P] Looking for a dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvwnwy/p_random_relational_graph_convolutional_networks/",
          "author": null,
          "description": "📑 The Random R-GCN code has just been released!\n 📝 With just a few lines of code, you can now create embeddings of entities in a Knowledge Graph.\n ​\n Minimal example on how to create embeddings with RR-GCN\n ​\n 💡 RR-GCN does not require training and is competitive to fully trained R-GCNs.\n 👉 https://github.com/predict-idlab/RR-GCN\n    submitted by    /u/givdwiel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvwnwy/p_random_relational_graph_convolutional_networks/",
          "publishedOn": "2022-04-04T08:07:48.000Z",
          "wordCount": 143,
          "title": "[P] Random Relational Graph Convolutional Networks (RR-GCN)",
          "imageUrl": "https://external-preview.redd.it/hbnqn3Smcm-XXgFP9D-4dlKcnNwPcAkdToaX-b-_zw0.jpg?auto=webp&s=0bafa0817ea6dee3b3d7c145ec6dead117ef8d65"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvug94/r_diffusionclip_textguided_diffusion_models_for/",
          "author": null,
          "description": "submitted by    /u/ImBradleyKim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvug94/r_diffusionclip_textguided_diffusion_models_for/",
          "publishedOn": "2022-04-04T05:38:01.000Z",
          "wordCount": 388,
          "title": "[R] DiffusionCLIP: Text-Guided Diffusion Models for \"Robust\" Image Manipulation (CVPR 2022)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvr2ib/p_transformers_for_software_engineers/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvr2ib/p_transformers_for_software_engineers/",
          "publishedOn": "2022-04-04T02:36:40.000Z",
          "wordCount": 95,
          "title": "[P] Transformers for Software Engineers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvntfs/d_unconventional_computer_vision_problems_that/",
          "author": null,
          "description": "Given that most benchmarks for image classification are based on regular, everyday world objects RGB images (or grayscale), what are some unconventional science cases where 2D inputs are substantially different from what we are used to perceive by eye? \n For example, I'm interested in cases where spatial information can't be constrained to narrow pixel value ranges, such as exponential signals. Or that any standard normalisation (say min-max, zscore) and normalisation layers are not applicable and could lead to the loss of information.\n One of these cases is Astronomy. However, most practitioners try to to adapt the problem to established standards (say fake RGB images, log scaling flux images, etc). What are other cases out there where the nature of the 2D inputs are very distinct to what we are used to parse through our eyes and what deep nets are benchmarked on? I'm curious about tailored solutions that would intrinsically change the way the deep nets are constructed to solve the research question.\n    submitted by    /u/astroferreira  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvntfs/d_unconventional_computer_vision_problems_that/",
          "publishedOn": "2022-04-03T23:58:19.000Z",
          "wordCount": 322,
          "title": "[D] Unconventional computer vision problems that are intrinsically different from classifying ordinary stuff",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvjw43/researchprojectlibrary_dogfeeding_a_new_machine/",
          "author": null,
          "description": "Hi everyone!\n I'm Atindriyo Sanyal, one of the founders of the ML company Galileo (https://rungalileo.io/). We're building a cool new tool/framework for ML practitioners that helps shine a light on the data you are training your models with.\n I'd love to get some feedback on the product, and since we're still in private beta, I'm looking for folks to try out the product on their datasets and models. It's easy to use and hooks into popular frameworks such as pyTorch, Tensorflow, Keras, SpaCy etc. \n Caveat: Currently the tool only works for NLP use cases (think text classification, NER etc).\n I'll be giving $100 to folks who are willing to give some time to this and provide feedback on the usability of the product. If you're interested, here's a really tiny form (should take <1 minute to fill) for you to fill out. I'll review the applications and send you an email for a follow up Zoom chat where I'll share the software artifacts with you!\n https://docs.google.com/forms/d/11V20C_J_SyNaX7QL6DasnTe7f0UiueUyaKdmt3xL1oI/edit\n Look forward and happy (machine) learning!\n - Atindriyo\n P.S. If you have any questions or want to chat personally, send me an email at [atin@rungalileo.io](mailto:atin@rungalileo.io).\n    submitted by    /u/atindriyo_galileo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvjw43/researchprojectlibrary_dogfeeding_a_new_machine/",
          "publishedOn": "2022-04-03T21:03:32.000Z",
          "wordCount": 295,
          "title": "[Research][Project][Library] Dog-feeding a new Machine Learning data tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvfx9r/d_pain_points_when_using_gpu_instance_platforms/",
          "author": null,
          "description": "Hi everyone, I just launched a GPU compute instance platform (think lambdalabs, fluidstack, aws EC2, vast), and I was wondering what pain points everyone has with existing solutions. I'm not trying to sell anyone anything, but I want to look for feedback that will help me to build a better product.\n My current thoughts are\n  \nEase of getting data into the platform\n Ease of getting data off of the platform\n Automation for spinning up and down instances\n Availability of the type of instance you want\n Price too high\n Not enough/too many abstractions\n  \nTIA and I look forward to some good discussions!\n    submitted by    /u/runpod-io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvfx9r/d_pain_points_when_using_gpu_instance_platforms/",
          "publishedOn": "2022-04-03T18:23:04.000Z",
          "wordCount": 269,
          "title": "[D] Pain points when using GPU instance platforms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tvc7xl/r_efficientvdvae_an_opensource_memoryefficient/",
          "author": null,
          "description": "Hello everyone :)\n We have released last week our paper \"Efficient-VDVAE: Less is more\" with code!\n We present simple modifications to the Very Deep VAE to make it converge up to 2.6x times faster and save up to 20x times memory load. We also introduce a gradient smoothing technique to improve stability during training. Our model achieves comparable or better negative log-likelihood (NLL) on 7 commonly used datasets.\n Additionally, we make an argument against existing 5-bit benchmarks. We empirically show as well that 3% of the latent space is enough to encode the data information without any performance loss. Thus, indicating the potential to efficiently leverage the Hierarchical VAE's latent space in downstream tasks.\n  \nPaper: https://arxiv.org/abs/2203.13751\n Code: https://github.com/Rayhane-mamah/Efficient-VDVAE\n Paperswithcode: https://paperswithcode.com/paper/efficient-vdvae-less-is-more\n  \nFeedback is very much appreciated!\n https://preview.redd.it/tjua1xpq3cr81.png?width=878&format=png&auto=webp&s=718bd91fd648acd673ddab1ad5342207e8be09e7\n    submitted by    /u/Louay-AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tvc7xl/r_efficientvdvae_an_opensource_memoryefficient/",
          "publishedOn": "2022-04-03T15:46:10.000Z",
          "wordCount": 225,
          "title": "[R] Efficient-VDVAE: An open-source memory-efficient and stable very deep hierarchical VAE",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tv9fuv/r_deepdpm_deep_clustering_with_an_unknown_number/",
          "author": null,
          "description": "Hey everyone :)\n We've just released the code for our paper (accepted to CVPR2022) \n DeepDPM is a nonparametric deep-clustering method which unlike most deep clustering methods, does not require knowing the number of clusters, K; rather, it infers it as a part of the overall learning. Using a split/merge framework to change the clusters number adaptively and a novel loss, our proposed method outperforms existing (both classical and deep) nonparametric methods.\n While the few existing deep nonparametric methods lack scalability, we show ours by being the first such method that reports its performance on ImageNet.\n ​\n  \nPaper: https://arxiv.org/abs/2203.14309\n Code: https://github.com/BGU-CS-VIL/DeepDPM/\n  \nBelow are some examples of clusters our method found in ImageNet.\n https://preview.redd.it/jw5kvcuzfbr81.jpg?width=737&format=pjpg&auto=webp&s=5b61cdd0efdea7c92aba611171e5dc7f4276c892\n    submitted by    /u/shahaff32  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tv9fuv/r_deepdpm_deep_clustering_with_an_unknown_number/",
          "publishedOn": "2022-04-03T13:36:53.000Z",
          "wordCount": 1327,
          "title": "[R] DeepDPM: Deep Clustering With an Unknown Number of Clusters",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tuzn4m/d_why_are_confidence_regions_elliptic/",
          "author": null,
          "description": "Confidence regions are the 2D version of a confidence interval. Almost everywhere in the literature, the shape is elliptic, but no justification is provided. You would think that a confidence region of level γ is defined as the domain of minimum area, covering a mass γ of the underlying probability distribution. That sounds perfectly logical, but it is mentioned nowhere. Based on this definition, the boundary of a confidence region is obtained by solving an optimization problem: it is a problem in calculus of variations -- finding a boundary curve encompassing a domain of minimum area. These problems are usually hard to solve, but in this case, the solution seems trivial: it must be a contour line. And if the underlying distribution is Gaussian, contour lines are obviously ellipses. This would be a solid justification as to why ellipses are so widespread.\n https://preview.redd.it/42mr1t1je8r81.png?width=1072&format=png&auto=webp&s=2fb9cedbbb15895827ed00edc4912ac39fad0b71\n My question here is whether or not my argumentation makes sense, or if there is something faulty in my math. I discuss it in more details in one of my articles, here. If you need clarifications, please reply on Reddit, I will do my best to explain.\n    submitted by    /u/MLRecipes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tuzn4m/d_why_are_confidence_regions_elliptic/",
          "publishedOn": "2022-04-03T03:18:05.000Z",
          "wordCount": 494,
          "title": "[D] Why are confidence regions elliptic?",
          "imageUrl": "https://external-preview.redd.it/ZqF9VX191mBPz4Lgbx4Etb5sHzOihemERSUo-VbfADQ.jpg?auto=webp&s=9a1ecbd9154dd6cde162b9f64f1b914eae390f6d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tux0p3/dnew_scaling_laws_for_large_language_models/",
          "author": null,
          "description": "https://www.lesswrong.com/posts/midXmMb2Xg37F2Kgn/new-scaling-laws-for-large-language-models\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tux0p3/dnew_scaling_laws_for_large_language_models/",
          "publishedOn": "2022-04-03T00:01:56.000Z",
          "wordCount": 325,
          "title": "[D]New Scaling Laws for Large Language Models",
          "imageUrl": "https://external-preview.redd.it/AE9lX1YhkCRE38raan8DE9_Y-2h4jvTJZ4LU_z68bio.jpg?auto=webp&s=a0fd488a512423074c7d8c4f8475b6e811c9f1cd"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tul97t/d_how_logistic_regression_nomogram_is_constructed/",
          "author": null,
          "description": "Well I' ve been reading some scientific works and I don't understand how nomograms are constructed from logistic regression models.\n In this example I have:\n https://ieeexplore-1ieee-1org-1000007l206e9.han.bg.pg.edu.pl/document/9514609\n And they train LR model on Covid19 dataset [death/ didn't die] so it's binary classification problem However later on, they construct nomogram, which determines whether there is low/moderate/high risk of covid19 mortality. What I don't undestand is how they calculate the score the establish chances of death. E.G. If the score is <0.05 there is low possibility that patient will die.\n My general question is, how they constructed this nomogram from the binary classifier they had?\n    submitted by    /u/s168501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tul97t/d_how_logistic_regression_nomogram_is_constructed/",
          "publishedOn": "2022-04-02T15:19:36.000Z",
          "wordCount": 202,
          "title": "[D] How Logistic Regression nomogram is constructed from binary classifier?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tujtva/r_neural_head_avatars_from_monocular_rgb_videos/",
          "author": null,
          "description": "submitted by    /u/Mandelmus100  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tujtva/r_neural_head_avatars_from_monocular_rgb_videos/",
          "publishedOn": "2022-04-02T14:15:11.000Z",
          "wordCount": 120,
          "title": "[R] Neural Head Avatars from Monocular RGB Videos (CVPR 2022)",
          "imageUrl": "https://external-preview.redd.it/RA2ZBowRGMfH1kL1WDUvWsfYOa1Pmik5Mst-t5245WY.jpg?auto=webp&s=9eacda6953d6e58088993d1828194a5b4db15105"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tuhgid/d_predicting_hard_properties_of_graphs_using/",
          "author": null,
          "description": "Hello everyone,\n there is a lot of work in the field of geometric deep learning for combinatorial optimization that yields good approximation algorithms for \"hard\" problems on graphs (see here), with the most prominent example being the TSP problem. However, as far as I can see, all these considered problems share the fact that the computed solution is a subset of the vertices/edges of the original graph. In my field (graph drawing), one of the most important considered properties is the crossing number). Hence, the solution would not consists of a labeling of the edges/vertices, but is rather a regression task on the whole graph. I have a dataset that consists of roughly 10000 graphs together with their crossing number. Treating the above problem as a supervised regression task and simply inserting the graph into a GNN does not work for me at all - is this a problem of my choice of architecture or is this sort of \"function\" that maps a graph to its crossing number something we can expect no current architecture to find.\n I appreciate any comment, even if it is just your intuition on the problem.\n Best regards,\n MrLemming\n    submitted by    /u/MrLemming2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tuhgid/d_predicting_hard_properties_of_graphs_using/",
          "publishedOn": "2022-04-02T12:11:38.000Z",
          "wordCount": 378,
          "title": "[D] Predicting hard properties of graphs using Machine Learning",
          "imageUrl": "https://external-preview.redd.it/tA9m1F8qnewJWZPWIeJ3NpCGpGA9UWzVtPeZUeg_nm8.jpg?auto=webp&s=f2e6ef1657311ed8a546bcd357bc74512d54b2d7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tugeo8/n_announcement_call_for_papers_for_our_icml/",
          "author": null,
          "description": "Dear community, I hope I do not violate rules by advertizing our Call for Papers here. In a nutshell, submissions can be robustness or OOD datasets and new metrics which we will consolidate in one benchmark. More infos on our website.\n I am happy to answer any questions in regards to the call.\n    submitted by    /u/helavisa4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tugeo8/n_announcement_call_for_papers_for_our_icml/",
          "publishedOn": "2022-04-02T11:08:24.000Z",
          "wordCount": 156,
          "title": "[N] Announcement: Call for Papers for our ICML ShiftHappens Workshop!",
          "imageUrl": "https://external-preview.redd.it/GqSShE36VS2-_QXTT7hNTjAfewg5eKg_7Hc-NSwTExU.jpg?auto=webp&s=4190508fc667dc5ea6a12862a9ecdccc01136fef"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tuf0vv/p_openai_codex_helping_to_write_shell_commands/",
          "author": null,
          "description": "submitted by    /u/tomd_96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tuf0vv/p_openai_codex_helping_to_write_shell_commands/",
          "publishedOn": "2022-04-02T09:36:21.000Z",
          "wordCount": 274,
          "title": "[P] OpenAI Codex helping to write shell commands",
          "imageUrl": "https://preview.redd.it/dbgbskqg53r81.gif?format=png8&s=a6ba284e6bf2600d95aa9235e353d5546790b1f7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tucu1d/rp_styleganxl_scaling_stylegan_to_large_diverse/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tucu1d/rp_styleganxl_scaling_stylegan_to_large_diverse/",
          "publishedOn": "2022-04-02T07:02:35.000Z",
          "wordCount": 185,
          "title": "[R][P] StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets + Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/Lvp4nEYrvAlYtFhADumRvacvOAbM1my-2xRV3EbmEu8.png?format=pjpg&auto=webp&s=25ab218429c1bafa2166d1f845c42a113412fd24"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu8szc/d_petaflops_as_a_unit_of_measure_in_machine/",
          "author": null,
          "description": "I was looking at this paper (https://arxiv.org/pdf/2005.14165.pdf) and came across this graph:\n ​\n https://preview.redd.it/49ydy9bo61r81.png?width=665&format=png&auto=webp&s=729743449d6a99d2b84b81610e7e32d87ea4dfeb\n I am trying to understand the following two things about this graph:\n ​\n  \nWhat is PetaFLOP/s-days? I read that a PetaFLOP is 1,000,000,000,000,000 calculations (e.g. addition, subtraction). I am guessing that 10^2 would imply 100 * 1,000,000,000,000,000 calculations per day - is this correct? Is there any difference between PetaFLOP/days and PetaFLOP/s-days? (I also find it interesting they are probably referring to \"computer resources\" as simply \"compute\")\n What does \"C\" stand for in L = 2.57 * C^-0.048? I am guessing that the \"dotted line\" probably refers to the \"average loss\" for different Neural Networks with differing amounts of Parameters - but what exactly does \"C\" stand for?\n Finally, is there a reason that \"Validation Loss\" is not expressed as a percentage? For instance, what is a Validation Loss of 3? Is a Validation Loss of 3 the same as a Loss of 30%? Or does Validation Loss simply refer to the value of the Loss Function obtained during the Validation stage of Cross Validation?\n  \nThank you!\n    submitted by    /u/blueest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu8szc/d_petaflops_as_a_unit_of_measure_in_machine/",
          "publishedOn": "2022-04-02T02:59:28.000Z",
          "wordCount": 548,
          "title": "[D] PetaFLOPS as a Unit of Measure in Machine Learning Applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu41tl/p_how_to_add_padding_to_an_image_in_pytorch/",
          "author": null,
          "description": "Hi guys,\n I am trying to add padding to images in Pytorch - I need to standardize all the images in my dataset to be of the same size. I spent the whole day trying to find a good solution but nothing worked. I succeeded in resizing but that compromised my image quality, so that is why I want to proceed with padding. How to do this?\n Thanks in advance! :)\n    submitted by    /u/whyhateverything  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu41tl/p_how_to_add_padding_to_an_image_in_pytorch/",
          "publishedOn": "2022-04-01T22:57:47.000Z",
          "wordCount": 196,
          "title": "[P] How to add padding to an image in Pytorch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu3qn2/p_sso_single_signon_for_cvat_the_labelling_tool/",
          "author": null,
          "description": "Hi everyone,\n For quite a long time, I have seen folks looking for a way to do SSO (Single Sign-On) for CVAT, a popular labeling tool. But unfortunately such capability is not readily available. It only supports local authentication and LDAP.\n So we decided to make a change proactively, and now we are in the process of enabling SSO for it. The initial result looks promising. Check it out to see what we have done: https://www.youtube.com/watch?v=R7hBBLG5Fdc\n Is this something that you would love to have?\n Any other machine learning tools that you want to have SSO capability as well?\n Any feedback are welcome.\n    submitted by    /u/alexcgg1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu3qn2/p_sso_single_signon_for_cvat_the_labelling_tool/",
          "publishedOn": "2022-04-01T22:43:11.000Z",
          "wordCount": 241,
          "title": "[P] SSO (Single Sign-On) for CVAT, the labelling tool",
          "imageUrl": "https://external-preview.redd.it/2wqpHoLzIB0dVStIRiQV7mcT4yrCfrO-bXq1Gfr9t7A.jpg?auto=webp&s=6874055cb31bb0c8094615a878dd86502dae858c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tu2z97/d_take_information_theory_before_the_first_course/",
          "author": null,
          "description": "Hello,\n I will study further Reinforcement Learning and Deep Learning in the future. I have completed probability theory, linear algebra, and multivariable calculus. I am taking Mathematical Statistics. Should I take Information Theory (IT) before ML? For me, I would definitely take IT, but I don't know whether to take it now or later.\n    submitted by    /u/nwe2rw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tu2z97/d_take_information_theory_before_the_first_course/",
          "publishedOn": "2022-04-01T22:08:51.000Z",
          "wordCount": 208,
          "title": "[D] Take Information Theory before the first course in machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttyr0f/d_paper_explained_improving_intrinsic_exploration/",
          "author": null,
          "description": "https://youtu.be/NeGJAUSQEJI\n Exploration is one of the oldest challenges for Reinforcement Learning algorithms, with no clear solution to date. Especially in environments with sparse rewards, agents face significant challenges in deciding which parts of the environment to explore further. Providing intrinsic motivation in form of a pseudo-reward is sometimes used to overcome this challenge, but often relies on hand-crafted heuristics, and can lead to deceptive dead-ends. This paper proposes to use language descriptions of encountered states as a method of assessing novelty. In two procedurally generated environments, they demonstrate the usefulness of language, which is in itself highly concise and abstractive, which lends itself well for this task.\n ​\n OUTLINE:\n 0:00 - Intro\n 1:10 - Paper Overview: Language for exploration\n 5:40 - The MiniGrid & MiniHack environments\n 7:00 - Annotating states with language\n 9:05 - Baseline algorithm: AMIGo\n 12:20 - Adding language to AMIGo\n 22:55 - Baseline algorithm: NovelD and Random Network Distillation\n 29:45 - Adding language to NovelD\n 31:50 - Aren't we just using extra data?\n 34:55 - Investigating the experimental results\n 40:45 - Final comments\n ​\n Paper: https://arxiv.org/abs/2202.08938\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttyr0f/d_paper_explained_improving_intrinsic_exploration/",
          "publishedOn": "2022-04-01T19:06:41.000Z",
          "wordCount": 276,
          "title": "[D] Paper Explained - Improving Intrinsic Exploration with Language Abstractions (Full Video Analysis)",
          "imageUrl": "https://external-preview.redd.it/QmXKqcvZCu-4PfGS4aIztJnVf75BUY5bHHzzfiI01lM.jpg?auto=webp&s=f569332656f0137e26cdab130bd7839ed1cc7235"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttxn7q/n_are_we_running_out_of_ai_benchmarks/",
          "author": null,
          "description": "Benchmarks are an important way to measure progress in AI research – but artificial intelligence is constantly achieving new bests. Are we running out of AI benchmarks? \n ...\n Researchers at the Medical University of Vienna and the University of Oxford now show in a meta-study of AI benchmarks that saturated or stagnant benchmarks are common. The researchers examined 1,688 benchmarks with 406 tasks in computer vision and natural language processing since 2013, and draw the following conclusions:\n  \nIn some cases, there would be continuous growth, such as in the ImageNet benchmark.\n However, a majority of all benchmarks quickly reach technological stagnation or saturation.\n In some cases, a lack of research interest is also a cause of stagnation. The researchers cite the UCF101 action recognition benchmark as an example of saturation.\n However, the dynamics of performance improvement do not follow a clearly discernible pattern: in some cases, phases of stagnation are followed by unpredictable leaps. This is what happened in the PROTEINS benchmark.\n  \n...\n Moreover, of the 1,688 benchmarks, only 66 percent have more than three results at different points in time – so in practice, 33 percent of all AI benchmarks are not used and therefore useless. \n ...\n In the future, new benchmarks should be developed by large, collaborative teams from many institutions, knowledge domains, and cultures to ensure high-quality benchmarks and avoid fragmentation of the benchmark landscape, the researchers conclude. \n Source: https://mixed-news.com/en/are-we-running-out-of-ai-benchmarks/\n    submitted by    /u/Sephirio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttxn7q/n_are_we_running_out_of_ai_benchmarks/",
          "publishedOn": "2022-04-01T18:19:42.000Z",
          "wordCount": 320,
          "title": "[N] Are we running out of AI benchmarks?",
          "imageUrl": "https://external-preview.redd.it/d_CzxPSnMiRfxvkW2wZCdrAVSdc0mHYmhbyFIJu4rYI.jpg?auto=webp&s=b86c9b97aa8542120b98b5c677748c5faf74d745"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttwzjy/d_methods_for_anomaly_detection_clustering_with/",
          "author": null,
          "description": "I'm looking for models, workflows, algorithms in the pursuit of principled ways of conducting anomaly detection on high dimensional datasets from physical systems. I am already familiar with the application of autoencoders, isolation forests, etc. to trivial feature sets. \n I have feature sets that abide physical equations and so there is also the capability of using differential equations or some prior generating process to also bound what is and isn't an \"outlier\". \n Looking for papers/methods/texts that are in this vein.\n    submitted by    /u/memproc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttwzjy/d_methods_for_anomaly_detection_clustering_with/",
          "publishedOn": "2022-04-01T17:52:48.000Z",
          "wordCount": 510,
          "title": "[D] Methods for anomaly detection / clustering with high dimensional physics data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttw7w8/rejecting_gan_offmanifold_samples_d/",
          "author": null,
          "description": "I am working on a project, where I do image editing in the latent space of an image. Are there any papers or suggestions on how to enforce that the samples lie on the manifold?\n    submitted by    /u/avd4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttw7w8/rejecting_gan_offmanifold_samples_d/",
          "publishedOn": "2022-04-01T17:21:08.000Z",
          "wordCount": 155,
          "title": "Rejecting GAN Off-Manifold Samples? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttt0l1/r_crosslingual_wikipedia_dataset/",
          "author": null,
          "description": "Hi! For a research project, I am trying to create a dataset that contains: the abstract of an article in EN; the abstract of the article in simple EN; the rest of the article in EN; the rest of the article in simple EN.\n When I worked in one language, I preprocessed the XML directly (the APIs seemed quite slow for processing the whole encyclopedia). However, I am struggling to find a way to join Wikis in different languages, as the dumps seem not to include a language-independent id.\n This seems to be a relatively \"standard\" task for creating cross-lingual datasets, so I hope someone has some tips, and I do not need to spend the next week reinventing the wheel :)\n    submitted by    /u/ombelicoInfinito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttt0l1/r_crosslingual_wikipedia_dataset/",
          "publishedOn": "2022-04-01T15:09:33.000Z",
          "wordCount": 241,
          "title": "[R] Cross-lingual Wikipedia dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttswq1/d_activation_functions_for_neural_networks_in/",
          "author": null,
          "description": "Hi everyone,\n I want to run a feedforward autoregressive network to forecast the potential sales of specific SKUs for the following months. The idea is to capture the non-linearity in the data. Does it make sense to use ReLU? or given that all my data points are positive values this function will return the same number (max(0,x)), therefore is not suitable for what I am trying to do?\n I have also checked other activation functions, but sigmoid for example is for classification, and hyperbolic tangent returns values that can be negative.\n ​\n Any help would be much appreciated\n Thanks!\n    submitted by    /u/Old-Box-6684  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttswq1/d_activation_functions_for_neural_networks_in/",
          "publishedOn": "2022-04-01T15:05:06.000Z",
          "wordCount": 195,
          "title": "[D] Activation functions for Neural Networks in Time Series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tts3ac/d_i_just_watched_alphago_the_movie_are_there_any/",
          "author": null,
          "description": "AlphaGo - The Movie on Youtube\n    submitted by    /u/Mighty__hammer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tts3ac/d_i_just_watched_alphago_the_movie_are_there_any/",
          "publishedOn": "2022-04-01T14:31:10.000Z",
          "wordCount": 309,
          "title": "[D] I just watched AlphaGo - The Movie, are there any more well made documentaries about AI available?",
          "imageUrl": "https://external-preview.redd.it/tK4IZMKXA_sU90ULATnz4ASagF5NHZC_vvqL5eVLreY.jpg?auto=webp&s=c6915f316e973e6a1eb6deb71eadc657339e7d9f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttpg0e/p_cyclemoid_a_new_activation_function_inspired_by/",
          "author": null,
          "description": "Excited to share our latest research. The cyclemoid activation was inspired by the success of cyclical learning rate. Moreover, it has nice mathematical properties to stabilize gradients and maintain strong gradient signals in desired regions during training. \n We designed it as a drop-in replacement for ReLU, and we would love to hear what you think.\n The code is up on GitHub, and the preprint should be up soon, too: https://github.com/rasbt/cyclemoid-pytorch\n PS: Currently, we only have a PyTorch implementation but would welcome it if someone could port it to TensorFlow/Keras (my Tf/Keras skills are just too rusty for it.)\n    submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttpg0e/p_cyclemoid_a_new_activation_function_inspired_by/",
          "publishedOn": "2022-04-01T12:26:20.000Z",
          "wordCount": 556,
          "title": "[P] Cyclemoid -- a new activation function inspired by cyclical learning rates; SOTA on several benchmarks",
          "imageUrl": "https://external-preview.redd.it/U14LT5IkG6HLrrnrIsVZjM9oswoJnsJgnLe7BM_JK9Y.jpg?auto=webp&s=ed71fee1fec70353db36c66c34938f53f901420c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttp6fu/d_im_creating_a_tool_to_enrich_your_datasets_with/",
          "author": null,
          "description": "Hey all,\n I love doing market research and all kinds of exploratory analyses, but getting the data is a major pain point, as it is in many places (data dumps, apis, marketplaces, web data) and in all kinds of formats\n I'm trying a different approach, where instead of searching for data sources, and then integrating manually, you just upload your dataset. My service has a large index with datasets and api providers, and finds relevant ones for your dataset which you can add easily.\n ​\n example search via sdk\n Does this seem useful to you? Would love to hear your thoughts\n    submitted by    /u/salmiakdrop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttp6fu/d_im_creating_a_tool_to_enrich_your_datasets_with/",
          "publishedOn": "2022-04-01T12:11:40.000Z",
          "wordCount": 532,
          "title": "[D] I'm creating a tool to enrich your datasets with relevant external data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttp4ub/d_have_there_been_successful_applications_of_deep/",
          "author": null,
          "description": "Some successful applications I am able to gather, mostly from Deepmind:\n - comma.ai self-driving system.\n - Weather nowcasting\n - Tokamak fision reactor feeedback control\n - Hardware design: New gen. TPU\n - Datacenter cooling optimization\n - Adaptive locomotion for quadrupedal robots *\n - Portfolio optimization (financial instruments)\n There is a lot of work in games, particularly board games, but these do not really solve something \"useful\" for society. I have seen also lots of toy examples with libraries like gym and some robotics but in general these are rather proof-of-concept models or just models that do not work at all. One that actually does work is Solving Rubik’s Cube with a Robot Hand, not regarding the solution of the cube but its dexterous manipulation with a robotic hand. This is pretty cool, but again, the domain of the problem is too narrow to be considered actually a successful application to a real-world problem. So my question is, am I missing some examples? For example, is any company out there trying to apply deep RL to self-driving vehicles or to NLP, and have they had any success?\n * Boston dynamics solves this without ML, just good'ol control theory so this is a 50-50 win for RL.\n ​\n Edit: Thanks everyone for the responses, I have updated the list with more projects from the comments.\n Edit 2: Took Alphafold out because the current version (2.x) does not use RL.\n    submitted by    /u/sid_276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttp4ub/d_have_there_been_successful_applications_of_deep/",
          "publishedOn": "2022-04-01T12:09:05.000Z",
          "wordCount": 1183,
          "title": "[D] Have there been successful applications of Deep RL to real problems other than board games/Atari?",
          "imageUrl": "https://external-preview.redd.it/6tuXmcur0bFJS0quIejtKY6sJ-nBSuWkVCpxUhmQca4.jpg?auto=webp&s=1dad25d9a1de288db063eefdc5a76945afdb447d"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttnj4i/d_request_for_advice_texttoimage_synthesis/",
          "author": null,
          "description": "Hello all, I hope that you are all doing good.\n The thing is that I want to study text-to-image synthesis; but I see that there are lots of work already done up until now. I am kind of confused about how I should start studying.\n About my experience, I am trying to learn as much as I can. I started by following Andrew Ng’s Machine Learning course on Coursera; and now I continue with Deep Learning Specialization (almost finished). Apart from these, I check NVIDIA blog, some YouTube channels, Slack communities and of course here on Reddit along with a few other channels. As I said, I am trying to follow what’s going on. \n To tell the truth, I didn’t do much in terms of building models. I mean, not a real-life project or something like that. My experience is more based on projects for the courses that I attend/attended. By the way, I don’t know how it will affect things’ turning out; but I have recently begun a graduate program as well in artificial intelligence. Moreover, during my undergraduate program, I took some courses that might help (at least I guess so) including Calculus and Linear Algebra.\n I also want to mention that as for hardware there is an NVIDIA Jetson Nano Developer Kit available to me.\n I hope that what I am asking is clear and information I provided help you answering. If not, please ask me.\n Best regards.\n    submitted by    /u/fgokmenoglu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttnj4i/d_request_for_advice_texttoimage_synthesis/",
          "publishedOn": "2022-04-01T10:32:56.000Z",
          "wordCount": 327,
          "title": "[D] Request for Advice: Text-to-Image Synthesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttncof/d_do_you_use_data_engineering_pipelines_for_real/",
          "author": null,
          "description": "Usually I am working on huge and complex datasets with millions of rows (or images if it's CV) and most often I just feed them to pandas in a notebook, then transfer the code to a script and run it when it's needed. Then with the result I train my models. No external tools used for this.\n Do you have experience with data pipeline tools/frameworks and data validation tools/frameworks?\n For example I just found \"Great Expectations\" and \"Kedro\", \"Flyte\" and I was wondering at which point in time and project complexity should we choose one of these tools instead of the ancient cave man way?\n Any success/failure stories?\n    submitted by    /u/gabegabe6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttncof/d_do_you_use_data_engineering_pipelines_for_real/",
          "publishedOn": "2022-04-01T10:20:31.000Z",
          "wordCount": 1386,
          "title": "[D] Do you use data engineering pipelines for real life projects?",
          "imageUrl": "https://external-preview.redd.it/9aMOb066CeL6cuV4L_Twfj7nPc9ZY-PmH1mwS0SBCBY.jpg?auto=webp&s=80f57c71ebf2c0b3121df52d87b15aa86a25bdc4"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttm00m/d_the_joy_of_finding_things_out_essay/",
          "author": null,
          "description": "Currently I’m trying to figure out if I want to stay in academia or not. My decision hinges on what makes doing science enjoyable. My current understanding is in order for science to be enjoyable, there has to be an element of surprise. A tension that builds. And release of that tension. This is most obvious in theoretical works where the scientist makes a prediction, and later empirical data verifies that prediction. Excitement. Joy. Wonder. In experimental work, surprise can take the form of not knowing how the experiment will turn out. Once you get the result of the experiment, it'll disambiguate competing theories you had in your mind or elucidate a new theory. \"Everything clicks\" or at the very least you'll be put into a fever trying to integrate the new surprising data with previous …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttm00m/d_the_joy_of_finding_things_out_essay/",
          "publishedOn": "2022-04-01T08:43:49.000Z",
          "wordCount": 2919,
          "title": "[D] The Joy of Finding Things Out (essay)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttjoiy/d_a_fine_grained_classification_dilemma/",
          "author": null,
          "description": "Hi Folks,\n I'm in a bit of a dilemma here on a specific fine grained classification problem that we have. The task at hand is to classify the subspecies of plant seeds. Firstly, the seeds are super tiny, but we have camera setup to take zoomed images of the seeds. Secondly, even the experts can't tell the exact difference between 2 subspecies of seeds. They go by their experience and intuition. All the subspecies put together looks similar but the data points within the same subspecies are vastly different. The requirement being classifying the subspecies based on their morphological properties. Here is the catch, the requirement is 98%+ accuracy. I tried few preprocessing and models (transformers, resnets, inception and other sort) but can't hit the 98% accuracy mark. Even if I could, the model sometimes fail on external sets or on production.\n I would like some expert (ML side) take on this issue on how to approach this.\n    submitted by    /u/happy_happy_feet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttjoiy/d_a_fine_grained_classification_dilemma/",
          "publishedOn": "2022-04-01T05:58:33.000Z",
          "wordCount": 1059,
          "title": "[D] A fine grained classification dilemma",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttibtz/d_how_to_preprocess_a_13k_column_dataset/",
          "author": null,
          "description": "I have a single cell rna seq dataset containing 13k features. I would like to preprocess the dataset. What are the best methods to do that? Also, how to apply feature elimination/selection on this unsupervised data? Thanks\n    submitted by    /u/Striking-Machine2763  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttibtz/d_how_to_preprocess_a_13k_column_dataset/",
          "publishedOn": "2022-04-01T04:34:09.000Z",
          "wordCount": 198,
          "title": "[D] how to preprocess a 13k column dataset.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r_nixtts_an_incredibly_lightweight_texttospeech/",
          "author": null,
          "description": "Hi, Reddit!\n Excited to share with you guys, Nix-TTS 🐤! Our latest research in lightweight neural Text-to-Speech.\n We've seen how synthetic voices generated by recent neural TTS are getting more and more natural, but most of the time the models suffer from slow CPU inference and are not end-to-end, which requires an additional vocoder model.\n Nix-TTS 🐤 is an incredibly lightweight end-to-end TTS model achieved by applying non end-to-end knowledge distillation to a powerful yet large-sized generative TTS teacher model.\n Our proposed model is end-to-end (vocoder-free) with only 5.23M parameters or up to 82% reduction of the teacher model. We also employed a stochastic duration predictor to improve its expressiveness.\n It is capable to run 10x faster than real-time on Intel i7 CPU and 0.5 times faster than real-time on Raspberry Pi Model 3B. Making it suitable for deployment in resource-constrained settings. Here we attached the complexity and speedup detail from the paper.\n ​\n Nix-TTS speedup and complexity compared to other models.\n ​\n We released the paper (submitted to INTERSPEECH 2022) and the pre-trained models on the attached link below:\n  \n📄 Paper: https://arxiv.org/abs/2203.15643\n 📦 Repository: https://github.com/rendchevi/nix-tts\n 🤗 Interactive Demo: https://huggingface.co/spaces/rendchevi/nix-tts\n  \nA short video demo from the 🤗 HuggingFace Spaces:\n Nix-TTS Short Demo\n Let me know what you guys think in the thread! We're very excited to see the potential improvements & applications of this model or method and lightweight TTS in general. Feel free to reach me via DM as well if you'd like to discuss anything further.\n    submitted by    /u/sourpeach_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r_nixtts_an_incredibly_lightweight_texttospeech/",
          "publishedOn": "2022-04-01T03:06:19.000Z",
          "wordCount": 580,
          "title": "[R] Nix-TTS 🐤: An incredibly lightweight text-to-speech via non end-to-end distillation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttd3bl/dare_there_any_good_solutions_for_multimodal/",
          "author": null,
          "description": "Hi, Reddit! I'm a data scientist working in the dating app startup field. We have been trying to set up people with blind dates. We can get multimodal data(texts, images, and audio) and we want to do this: collect negative and positive pairs from each user's swiping history and do a binary classification (matching). Then we would get together as many users' data as possible and train a model.\n Though it sounds nice, this is hard as we could not find an existing developer tool or paper that supports combining such rich multimodal data. Any existing research out there to achieve this task? Moreover, is there already any library or AutoML tool that supports this? Checked Google AutoML, does not support this.\n Any help and advice would be much appreciated.\n    submitted by    /u/meame2010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttd3bl/dare_there_any_good_solutions_for_multimodal/",
          "publishedOn": "2022-03-31T23:48:50.000Z",
          "wordCount": 311,
          "title": "[D]Are there any good solutions for multimodal classification? Libraries, AutoML tool?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ttcsqz/p_laion5b_public_dataset_of_585_billion_imagetext/",
          "author": null,
          "description": "LAION-5B: A new era of open large-scale multi-modal datasets.\n Twitter thread.\n Related: [P] LAION-400M: open-source dataset of 400 million image-text pairs.\n I am not affiliated with this project.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ttcsqz/p_laion5b_public_dataset_of_585_billion_imagetext/",
          "publishedOn": "2022-03-31T23:33:06.000Z",
          "wordCount": 131,
          "title": "[P] LAION-5B: public dataset of 5.85 billion image-text pairs",
          "imageUrl": "https://external-preview.redd.it/zIzZWgf2-det-DQnCxz38cfTU2OBk2b9rFFJZe5GdMY.jpg?auto=webp&s=6900de17119ed0ef290741a6b2832ee35cc22a14"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt9lib/p_adapting_pixel_attribution_methods_for_models/",
          "author": null,
          "description": "Hi r/MachineLearning,\n https://github.com/jacobgil/pytorch-grad-cam is a project that has a comprehensive collection of Pixel Attribution Methods for PyTorch (like the package name grad-cam that was the original algorithm implemented).\n Typically pixel attribution methods are adapted for classification: they let you understand what part of the image correspond to a certain classification category.\n However some deep learning models output embeddings instead of category scores.You can then match these embeddings against other embeddings and measure their similarity. For example: in face recognition models, or in self supervised networks.\n In this case to apply pixel attribution, we could create embeddings of concepts, and then for new query images we would be asking: \"what parts of the image have feature representations that match the concept features?\"\n Or in other words: \"where in the query image do we see the concepts?\"\n ​\n I wrote a tutorial that shows how to use the pytorch-grad-cam project, to adapt pixel attribution for the embedding case, and visualize where different concept feature representations match the image:\n https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/Pixel%20Attribution%20for%20embeddings.ipynb\n An example is the image below. The two left images are \"concept\" images of clouds, and a car.\n Then given a new query image, we can try to see where in the image do we feature representations that match these concepts.\n Given images of concepts and a query image, attribute what parts of the query image match the concepts\n I hope someone finds this useful !\n    submitted by    /u/jacobgil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt9lib/p_adapting_pixel_attribution_methods_for_models/",
          "publishedOn": "2022-03-31T20:59:12.000Z",
          "wordCount": 378,
          "title": "[P] Adapting pixel attribution methods for models that output embeddings",
          "imageUrl": "https://external-preview.redd.it/hNkHJFL_Y7QUpq-mVaOEdwMBH_0G7BjrEA-aYSKuNDg.jpg?auto=webp&s=e80028eac0b3799bb56f29c9a141a8bb24bb0b89"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt8sel/d_does_anyone_know_how_to_create_animations_like/",
          "author": null,
          "description": "I really would like to do some visualization of my ideas. I found the animation in the google ai blog:\n https://ai.googleblog.com/2022/02/4d-net-learning-multi-modal-alignment.html\n Anyone knows how to do this stuff, especially with the flowing lines? Any software suggestions?\n    submitted by    /u/KonArtist01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt8sel/d_does_anyone_know_how_to_create_animations_like/",
          "publishedOn": "2022-03-31T20:23:04.000Z",
          "wordCount": 286,
          "title": "[D] Does anyone know how to create animations like in the Google AI Blog?",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt7q5h/d_data_centric_fixes_to_a_model_thats_fit_to_a/",
          "author": null,
          "description": "Say a computer vision model learns a pattern you don't want it to, you know that it's learnt it because of analysis through tools like occlusion sensitivity map.\n What data-centric techniques can you use to resolve it? Could some form of cropping augmentation do the trick?Classic example is ruler beside melanoma, while there may be a correlation between presence of ruler and presence of melanoma you don't want to the model to depend on that information because it may not exist 'in production'. Below is a quotation describing another similar problem.\n \"In another paper a similar issue was found because doctors sometimes use purple markers to highlight potentially-malignant skin cancers for easier examination. Some argue that the purple marks are a real signal that should be incorporated in the model just as the visual appearance of the tumor itself is incorporated. However, if your goal is robust generalizability over time it is probably best to not have your AI incorporate the human applied purple marks as signal, as the standards for applying those marks may vary across teams and across time.\" https://menloml.com/2020/01/11/recognizing-a-ruler-instead-of-a-cancer/\n f you're working with that dataset, what tools are available to you to solve that problem?\n    submitted by    /u/Georgehwp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt7q5h/d_data_centric_fixes_to_a_model_thats_fit_to_a/",
          "publishedOn": "2022-03-31T19:34:38.000Z",
          "wordCount": 308,
          "title": "[D] Data centric fixes to a model that's fit to a spurious correlation",
          "imageUrl": "https://external-preview.redd.it/F6AGihc6sjMmnVLm-XWIe0jcP2vPZpBwjOqH2PhZX-c.jpg?auto=webp&s=13353f39561ed11ccd79ec9880d3b36c19dcc81c"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt4abi/p_marketing_mix_modeling_how_can_we_solve_for/",
          "author": null,
          "description": "Hi everyone\n I'm working on a Marketing Mix Modeling project for a client\n I'm using Python and sci-kit learn library to do regression analysis with Ridge and Linear Regression.\n I have pretty good results:\n R^2=0.87\n mape= 0.2\n But some of my media coefficients are negative\n And this doesn't make sense business-wise\n How can I model positive media coefficients without using Bayesian modeling?\n    submitted by    /u/datagabriele  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt4abi/p_marketing_mix_modeling_how_can_we_solve_for/",
          "publishedOn": "2022-03-31T16:59:06.000Z",
          "wordCount": 830,
          "title": "[P] Marketing Mix Modeling - How can we solve for negative Media Coefficients?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt3qor/r_projunn_efficient_method_for_training_deep/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2203.05483\n TL;DR; from LeCun: Recurrent nets in which the weight matrix is unitary are interesting beasts: they are invertible, they don't suffer from vanishing/exploding gradient, and they perform computation akin to what happens in quantum computers. training them can be difficult or expensive. We propose a low-rank (low-cost) update method to update unitary weight matrices with gradient descent.\n Abstract: In learning with recurrent or very deep feed-forward networks, employing unitary matrices in each layer can be very effective at maintaining long-range stability. However, restricting network parameters to be unitary typically comes at the cost of expensive parameterizations or increased training runtime. We propose instead an efficient method based on rank-k updates -- or their rank-k approximation -- that maintains performance at a nearly optimal training runtime. We introduce two variants of this method, named Direct (projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can parameterize full N-dimensional unitary or orthogonal matrices with a training runtime scaling as O(kN^2). Our method either projects low-rank gradients onto the closest unitary matrix (projUNN-T) or transports unitary matrices in the direction of the low-rank gradient (projUNN-D). Even in the fastest setting (k=1), projUNN is able to train a model's unitary parameters to reach comparable performances against baseline implementations. By integrating our projUNN algorithm into both recurrent and convolutional neural networks, our models can closely match or exceed benchmarked results from state-of-the-art algorithms.\n    submitted by    /u/lostmsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt3qor/r_projunn_efficient_method_for_training_deep/",
          "publishedOn": "2022-03-31T16:34:13.000Z",
          "wordCount": 335,
          "title": "[R] projUNN: efficient method for training deep networks with unitary matrices",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tt21k9/d_are_text_embeddings_tabular_data/",
          "author": null,
          "description": "I keep hearing that NNs are not the best way to approach tabular data. But when it comes to document classification, in terms of using embeddings for a downstream classification task, would that be considered tabular data? You will end up with data that fits in a table that you wish to classify...it's high dimensional but you could reduce dimensions until you end up with just a smaller set of columns and the labels. \n I guess I'm unclear about what defines tabular data in this context, and if it makes sense to use a different model (like XBGboost) for the classification task, vs having it as a final layer in the embedding network.\n    submitted by    /u/bandalorian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tt21k9/d_are_text_embeddings_tabular_data/",
          "publishedOn": "2022-03-31T15:16:49.000Z",
          "wordCount": 918,
          "title": "[D] Are text embeddings tabular data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsyt3l/r_causal_inference_in_natural_language_processing/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2109.00725\n Abstract: A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the remaining challenges. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects, encompassing settings where text is used as an outcome, treatment, or as a means to address confounding. In addition, we explore potential uses of causal inference to improve the performance, robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the computational linguistics community.\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsyt3l/r_causal_inference_in_natural_language_processing/",
          "publishedOn": "2022-03-31T12:37:13.000Z",
          "wordCount": 277,
          "title": "[R] Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsxu8x/p_aiy_vision_kit/",
          "author": null,
          "description": "Working on a group project for college, utilizing a AIY Vision kit and implementing some variation of machine learning with it. The initial idea was to use the camera to identify playing cards and sorting them into groups, like different suits, odd/even, face and non face, but after meeting with the professor in charge, was informed that this idea of identifying and sorting is not really marketable. I tried explaining that sorting in the different ways could be used in many different applications and businesses, but still was told it was not really marketable. I was wondering if maybe there was a way to tweak it a bit to make it so, or if maybe turning it into an API would help. Any ideas and/or opinions on the project would be very helpful. Thank you very much.\n I understand this may fall under beginner related questions and project, but was curious to know if my group and I are on a right track or not, as we haven’t had any sort of guidance up to date.\n    submitted by    /u/EETQuestions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsxu8x/p_aiy_vision_kit/",
          "publishedOn": "2022-03-31T11:40:27.000Z",
          "wordCount": 266,
          "title": "[P] AIY Vision Kit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsxj8q/d_what_kind_of_teams_do_you_work_on/",
          "author": null,
          "description": "I am looking to stand up a small ML group in my non big tech but pretty big organization. We have a few use cases, only see the list growing, and would like to have a dedicated group rather than having disparate teams each trying to roll their own algorithms for their own applications. I am starting to look at what the costs might be, and I can see some pushback and lowballing (eg onshore/offshore, skill set, % junior/senior), but I don’t have a lot of stories to start my thoughts with, let alone data. So, I’m interested to know what your teams are like to start thinking about it, and any other data or literature would also be appreciated!\n    submitted by    /u/Stranger_Dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsxj8q/d_what_kind_of_teams_do_you_work_on/",
          "publishedOn": "2022-03-31T11:20:43.000Z",
          "wordCount": 221,
          "title": "[D] What kind of teams do you work on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsvfor/r_china_researches_brainscale_ai/",
          "author": null,
          "description": "https://mixed-news.com/en/artificial-intelligence-china-researches-brain-scale-ai/\n In China, the state and companies are researching AI models with trillions of parameters. They want to prove that they can develop “brain-scale” AI.\n In the race to build ever-larger AI models, China is showing that cooperation between the state, universities and the private sector holds the potential for gigantic AI models. The researchers are talking about “brain-scale” AI: according to their definition, these are AI models with parameters beyond the 100-trillion mark.\n ...\n In a new paper, researchers from Tsinghua University, Alibaba Group, Zhejiang Lab and Beijing Academy of Artificial Intelligence present BaGuaLu, a framework that enables the training of large AI models using the Mixture-of-Experts (MoE) architecture.\n ...\n In an initial test, the researchers trained a 1.93 trillion model with their framework, outperforming Google’s Switch Transformer. They also demonstrate that their framework enables models with 14.5 trillion and a full 174 trillion parameters.\n ...\n BaGuaLu could soon be used to train the first models beyond 100 trillion parameters.\n    submitted by    /u/Zirius_Sadfaces  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsvfor/r_china_researches_brainscale_ai/",
          "publishedOn": "2022-03-31T08:47:59.000Z",
          "wordCount": 467,
          "title": "[R] China researches “brain-scale” AI",
          "imageUrl": "https://external-preview.redd.it/JhZYBigKAty1Eq96lCCsaxYnvApivFIyrmwoeLVCjDk.jpg?auto=webp&s=70729ea061997be594080e36d0fcf14e4b9aff66"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsvc7m/d_coreset_terrible_perfomance_on_datasets_with_a/",
          "author": null,
          "description": "Hello reddit hivemind,\n This might be a quite specific question but im not sure where else to go and ask. I'm currently an intern and charged with implementing and comparing different active learning algorithms to see which work best for our specific usecase. Since the coreset approach ( [1708.00489] Active Learning for Convolutional Neural Networks: A Core-Set Approach (arxiv.org) ) is now around for a long time, one of the best documented and shows promising results in a variety of papers I implemented it and ran some experiments with it. The results were a bit dissappointing. It got even outperformed by the random baseline .... To understand the bad performance I dug a bit deeper since I spend a significant amount of time implementing it. What I made out now as the issue is using the l_2 norm of penultimate layer as the metric. This leads to an oversampling of data samples with a certain softmax output due to the way the softmax function behaves. Has someone experienced the same issues? The only point where I could see coreset to be of some use is with a dataset that has a ton of redundant/similar images.\n Thank's a lot\n    submitted by    /u/Fearless-Pumpkin-745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsvc7m/d_coreset_terrible_perfomance_on_datasets_with_a/",
          "publishedOn": "2022-03-31T08:40:25.000Z",
          "wordCount": 362,
          "title": "[D] Coreset terrible perfomance on Datasets with a lot of redundancy",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsv4sv/r_reinforcement_learning_in_finance_research/",
          "author": null,
          "description": "Hello, I hope that this message finds you in good health\n FinRL: Deep Reinforcement Learning for Quantitative Finance https://github.com/AI4Finance-Foundation/FinRL is a project from Columbia University. It offers environments for cryptocurrency, paper trading, stock trading, and forex trading. Also, it has support for three reinforcement learning libraries: Stable Baselines3, RLlib, and ElegantRL. This is from AI4Finance-foundation and it aims to provide a plug-play platform for RL in finance. Do check it out and help us to improve this project\n Some resources:\n  \nMy contributions: https://medium.com/@athekunal/list/finrl-contributions-59de6997c5b1\n Resources to learn FinRL: https://github.com/AI4Finance-Foundation/FinRL#tutorials\n All tutorial notebooks: https://github.com/AI4Finance-Foundation/FinRL/tree/master/tutorials\n YouTube Channel: https://www.youtube.com/channel/UCrVri6k3KPBa3NhapVV4K5g\n  \n   submitted by    /u/A_the_kunal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsv4sv/r_reinforcement_learning_in_finance_research/",
          "publishedOn": "2022-03-31T08:24:27.000Z",
          "wordCount": 185,
          "title": "[R] Reinforcement Learning in Finance research",
          "imageUrl": "https://external-preview.redd.it/26WP_8wiR4eM6G0YebGmMkj2k6iO24IWXjkX2zAG8Eg.jpg?auto=webp&s=febf91202e8cc5f45f9bc0a588436e70101652d3"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsv020/p_point_cloud_annotation_tool/",
          "author": null,
          "description": "Hi Everyone,\n Some time ago, we had the idea to start building tools to facilitate 3D computer vision development. We started by looking at some of the 3D tools out there and realized that there wasn't anything that fit our needs or could be extended to do some of the things we wanted to do. \n We started working on a tool to annotate point clouds with different label types (bounding box, rectangles, keypoints) to use as a base for our projects. We recently open sourced the tool, which you can find here: https://github.com/StrayRobots/3d-annotation-tool\n In the future we might add more tools, for example to paint point clouds or a polygon label type. \n We would love to hear your feedback on the tool. Has anyone here built any 3D vision datasets? What kind of tools did you use?\n    submitted by    /u/slash-dot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsv020/p_point_cloud_annotation_tool/",
          "publishedOn": "2022-03-31T08:14:01.000Z",
          "wordCount": 222,
          "title": "[P] Point Cloud Annotation Tool",
          "imageUrl": "https://external-preview.redd.it/3QUD2bNaGQoxY2OfIVK2louOdnTZ_QFvFFNCaliXQdc.jpg?auto=webp&s=bceaea6359ae85e790f73def5f80e862642d4e9f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsutvx/dis_it_just_me_or_is_machine_learning_difficult/",
          "author": null,
          "description": "Hello, \n My Background:\n I work as a web dev for almost 2 years. Before that when I was studying in college, I thought ML is the only field which was in demand. I put my 100% into it but the professor was so bad that not only me but a lot of my peers found ML,DS to be very difficult. We were able to built project around but never tried to learn more. \n I tired many udemy or coursea courses but never found it engaging. \n Is it just me or did you also found ML difficult? Is my approach to learning it wrong? If anyone has any advice I'd really appreciate it\n    submitted by    /u/Notalabel_4566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsutvx/dis_it_just_me_or_is_machine_learning_difficult/",
          "publishedOn": "2022-03-31T08:00:41.000Z",
          "wordCount": 889,
          "title": "[D]Is it just me or is machine learning difficult to learn?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsu81d/d_how_to_combine_multimodal_data_of_different/",
          "author": null,
          "description": "I'm currently working on a project related to multimodal summarization using transformers.\n My input is a image and long text and output will be a summary of the text pertaining to the image.\n ​\n For extracting image features, I'm using pretrained resnet model. It gives me a [49 * 2048] vector for an image.\n For extracting paragraph features, I'm getting embeddings for each sentence, so the data_dimension will be [no_of_sentences * 512]\n ​\n I need to attend to both these set of features and generate output. I have gone through tutorials to understand the working of transformers but couldn't understand how to combine these into a single input so that the encoder can attend over both image and the paragraph together at the same time.\n ​\n Any pointers to tutorials will be very helpful.\n    submitted by    /u/abisekrk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsu81d/d_how_to_combine_multimodal_data_of_different/",
          "publishedOn": "2022-03-31T07:14:22.000Z",
          "wordCount": 287,
          "title": "[D] How to combine multimodal data of different sequence lengths in training?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tssy7n/n_an_open_letter_to_deepminders/",
          "author": null,
          "description": "Yesterday, an anonymous open letter and accompanying Financial Times (paywall) article were published accusing DeepMind of mishandling allegations of sexual abuse by a senior member of the research team. \n The FT article (reported on here in Fortune) goes on to suggest that the mishandling may have been deliberate in order to exploit legal loopholes in the UK where victims have a limited amount of time to take a case to employment tribunal. \n This comes shortly after Mustafa Suleyman, one of the cofounders was quietly shuffled out to Google (he has subsequently left and founded a new startup with another DeepMind alum) after he was found to have bullied and humiliated staff for years.\n Google itself also has a poor record when it comes to sexual harassment, bullying and retaliation at the highest levels resulting in payouts of hundreds of millions of dollars. \n Given that DeepMind and Google have a pretty strong grip on the development of AI in terms of employing many of the key people across many of the various subfields, having access to unparalleled data and compute and pushing forward more and more into health (for example the DeepMind offshoot Isomorphic Labs which itself is headed by Demis and staffed by DeepMinders, and the various Google healthcare bets and projects), can we really trust them to be stewards of fair and responsible AI development? \n Bad things happen in all large organizations. But DeepMind isn’t that big and in the past five years, DeepMind leadership have presided over a steady stream of sexual harassment, bullying and other scandals and handled them all extremely poorly and showed little signs that things have changed. This points to something rotten in the culture and leadership there and at it’s parent organization.\n    submitted by    /u/ml-anon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tssy7n/n_an_open_letter_to_deepminders/",
          "publishedOn": "2022-03-31T05:44:33.000Z",
          "wordCount": 984,
          "title": "[N] An open letter to DeepMinders",
          "imageUrl": "https://external-preview.redd.it/woxo4bvgGvm5mdcr1peGe8hkoBpqRx8189TaYW5w5ic.jpg?auto=webp&s=4dc20b15a9e8b4dd512b3e4cc699ec742e61a6a7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsrdhl/d_use_of_kesler_construction_for_multiclass/",
          "author": null,
          "description": "I noticed that in some literature they use the Kesler construction when discussing multi-class prediction: https://uclanlp.github.io/CS269-17/slides/CS269-03.pdf. Why do they do this versus represent all the w_i vectors in a K x N matrix, where N is the length of x and K is the number of classes, and then generate Wx = [w1^Tx, ..., wKx], which will essentially produce the same result but be more efficient because of the lack of zero multiplications which are in the Kesler construction?\n    submitted by    /u/newperson77777777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsrdhl/d_use_of_kesler_construction_for_multiclass/",
          "publishedOn": "2022-03-31T04:05:43.000Z",
          "wordCount": 177,
          "title": "[D] Use of Kesler Construction for Multi-class Prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsmryt/r_making_robots_achieve_tasks_like_animals_with/",
          "author": null,
          "description": "This work from Berkeley + Google Brain (Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions) describes using RL and GANs for transferring motion styles from animals successfully onto robots. \n Super neat idea, and love to see ML being used more and more on real robots!\n Love the Cost of Transport analysis - naturalistic movement really is very efficient, and good luck getting RL to solve the hard exploration problem of good motion and task performance simultaneously tabula rasa!\n In particular I love this image. Down with hand specified reward functions! Let imitating nature reign supreme.\n What's next, GANs for moral style transfer?\n    submitted by    /u/AristocraticOctopus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsmryt/r_making_robots_achieve_tasks_like_animals_with/",
          "publishedOn": "2022-03-30T23:55:18.000Z",
          "wordCount": 210,
          "title": "[R] Making Robots Achieve Tasks Like Animals with Style Transfer + RL",
          "imageUrl": "https://external-preview.redd.it/VURBVjzpmMi0ax-TyZhzmNterlDvl4_-ID9S6MsC46M.jpg?auto=webp&s=e9f8b9fbbf84cb8168b896a8346523e9c2c9f390"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsitmb/d_low_mpjpe_and_low_pck_and_auc/",
          "author": null,
          "description": "So in the pose estimation landscape (specifically 3D) there are 3 common evaluation metrics MPJPE (mean per joint precision error measured in mm), PCK (percent correct keypoints measured at a 150mm threshold) and then AUC. One oddity I have noticed when training a few models is that a model with a lower MPJPE then some methods does not alwayshave a higher PCK (higher is better for this metric) but the mean joint precsion error is substantially below the threshold used for PCK (I do recognize that this metric is an average). \n ​\n Does anyone have any experience with this, seen the same behavior, or have any intuition why this would be occurring?\n    submitted by    /u/AbjectDrink3276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsitmb/d_low_mpjpe_and_low_pck_and_auc/",
          "publishedOn": "2022-03-30T20:47:35.000Z",
          "wordCount": 208,
          "title": "[D] Low MPJPE and low PCK and AUC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsigde/r_a_conversational_paradigm_for_program_synthesis/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsigde/r_a_conversational_paradigm_for_program_synthesis/",
          "publishedOn": "2022-03-30T20:30:45.000Z",
          "wordCount": 94,
          "title": "[R] A Conversational Paradigm for Program Synthesis",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsid21/r_training_computeoptimal_large_language_models/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsid21/r_training_computeoptimal_large_language_models/",
          "publishedOn": "2022-03-30T20:26:33.000Z",
          "wordCount": 191,
          "title": "[R] Training Compute-Optimal Large Language Models. From the abstract: \"We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant.\"",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsfppe/d_some_challenges_that_must_be_taken_care_of/",
          "author": null,
          "description": "More than a year ago, I wrote an article regarding some key obstacles that someone may face regarding working with AI in the medical field. A few days ago I submitted that article to \"Towards Data Science\", a 'Medium' based online publication. It got published yesterday. I am giving the link here. If anyone is interested in that topic, you can take a look. It mainly focuses on the part that - even if you have some previous experience in working with machine learning, there are some things you must know and be aware of before working with medical datasets. Link - https://towardsdatascience.com/some-key-challenges-in-building-an-ai-model-for-medical-diagnosis-63f7438f14a\n    submitted by    /u/ishtiakmahmud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsfppe/d_some_challenges_that_must_be_taken_care_of/",
          "publishedOn": "2022-03-30T19:38:50.000Z",
          "wordCount": 222,
          "title": "[D] Some challenges that must be taken care of while working with ML using medical data",
          "imageUrl": "https://external-preview.redd.it/9-Jyevv4atlG7KMN0YirFJNE6IknmhnIvI681bAUJjY.jpg?auto=webp&s=0898e807c680005ebdd0d50df6b2850f819541af"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsffzi/d_is_quantum_ml_pointless/",
          "author": null,
          "description": "Today Google had a webinar on Tensorflow Quantum for big data, which I attended. I was surprised that it was almost all quantum computing theory, but there was a link in the talk resources to Tensorflow Quantum where I was told I could find a tutorial with demo code for a classifier system to compare it to my classical approaches -- I use logistic regression, support vector machine, and Tensorflow DNN classifiers; mostly SVM because it works almost as accurately on my job's data sets as DNNs but takes a tiny fraction of the time to train.\n So, I took a look at it: https://www.tensorflow.org/quantum/tutorials/mnist\n This was the first sign that quantum classification might not be a viable alternative:\n  \nAn image size of 28x28 is much too large for current quantum computers.\n -- https://www.tensorflow.org/quantum/tutorials/mnist#12_downscale_the_images\n  \nYou really have to see it to believe it, but this demo requires downscaling legible digits for handwriting recognition to 4-by-4 pixel completely indiscernible blobs! Resulting in, as you might expect, terrible accuracy. A classical model using the full resolution images achieves 99.9%+ accuracy in relatively almost no time to train.\n So I scrolled down to the \"Comparison\" section and saw this:\n  \na classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network.\n  \nThe remainder of the tutorial didn't offer any improvement. The \"quantum convolutional\" NN classifier wasn't any better in speed or accuracy.\n  \nSo, am I correct in assuming that I am best off ignoring quantum computing for classification tasks for the foreseeable future?\n How long do you think it will be until quantum ML can compete on real-world problems?\n    submitted by    /u/Competitive_Travel16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsffzi/d_is_quantum_ml_pointless/",
          "publishedOn": "2022-03-30T19:36:14.000Z",
          "wordCount": 1217,
          "title": "[D] Is quantum ML pointless?",
          "imageUrl": "https://external-preview.redd.it/VJG_v5pS1UlsunnyMTpCImDzpp8RvxLtAgF4Fp1drDw.jpg?auto=webp&s=877bc8e94abb5f14b2e1ed87a222488f8b415e70"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tsd28t/r_codegen_up_to_161b_code_generating_transformer/",
          "author": null,
          "description": "https://twitter.com/erik_nijkamp/status/1508956485379715072\n Paper: https://arxiv.org/abs/2203.13474\n Blog: https://blog.salesforceairesearch.com/codegen/\n Code: https://github.com/salesforce/CodeGen\n    submitted by    /u/lucidraisin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tsd28t/r_codegen_up_to_161b_code_generating_transformer/",
          "publishedOn": "2022-03-30T18:31:35.000Z",
          "wordCount": 117,
          "title": "[R] CodeGen (up to 16.1B code generating transformer trained on TPU-v4) is open-source",
          "imageUrl": "https://external-preview.redd.it/v4L76FMpJgH6HQXUBUbyZPpMX-bYPiCfuxBx3XrcM-g.jpg?auto=webp&s=63c58763cc5f6a59b8ce473091217ad6f3905712"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts8omj/d_do_you_know_application_fields_in_the_sector_of/",
          "author": null,
          "description": "Self-Synchronizing Oscillators are mainly a hardware-software combination that uses swinging oscillators for decentral synchronization of distributed units without a central steering element. It is a new approach to synchronize two or more entities with another. Instead of relying on a central clock which the other ones communicate with, this technology is mutually or naturally synchronized, so both entities know at any time what the other one is doing.\n My question would be, are there any possible application fields you could think of for this technology?\n    submitted by    /u/mikeseboss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts8omj/d_do_you_know_application_fields_in_the_sector_of/",
          "publishedOn": "2022-03-30T15:14:25.000Z",
          "wordCount": 274,
          "title": "[D] Do you know application fields in the sector of machine learning where precise coordination might play a role?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts81uq/d_predicting_and_correcting_error_of_a_simple/",
          "author": null,
          "description": "I tried to keep the title somewhat general in case my problem is interesting for others, but before continuing with the discussion I'll introduce some specifics to make it easier to talk about the specific problem.\n I'm a fluid dynamics engineer, in particular a CFD engineer (fluid simulations and such), working on a phenomenon known as cavitation on hydrofoils.\n The most common way to perform a full simulation for a cavitating hydrofoil requires approximately 8 hours to run on a 512 cores.\n I'm currently working on an approximate model that solves the same problem in less than a minute on a common laptop. Of course, as an approximate model it is less faithful than the full model, with the relative error increasing or decreasing as some of the foilparameters change.\n Namely, a foil is defi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts81uq/d_predicting_and_correcting_error_of_a_simple/",
          "publishedOn": "2022-03-30T14:45:24.000Z",
          "wordCount": 540,
          "title": "[D] Predicting and correcting error of a simple model with a lot of data against a much more complex model with less data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts7rta/dp_guidance_required_for_solving_a_unique_problem/",
          "author": null,
          "description": "Hello All,\n I am currently working on the project wherein I have to apply DL to CFD simulations. The simulation data is basically a set of 2d points (x,y) and their corresponding velocity and pressure values. I have such data for a 100 timesteps. The goal is to predict the flow(i.e. velocity and pressure) for each grid point for the last time step. I was thinking of reshaping the data in the form of a square so that I can use a CNN, but using a CNN wouldn't take care of the time dependence between the data. Is there a hybrid approach I can use that can take care of both temporal and spatial dependencies?\n ​\n Really need some guidance. Even any unrelated advice would be much appreciated. Thank you in advance!\n ​\n Edit: Also needed some help with regards to making the dataset. I have 100 csv files, each file corresponding to one time step. Each file contains the pressure and velocities of around 900 points. How do I make a dataset out of this either in pytorch or tensorflow?\n    submitted by    /u/Hour_Amphibian9738  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts7rta/dp_guidance_required_for_solving_a_unique_problem/",
          "publishedOn": "2022-03-30T14:32:31.000Z",
          "wordCount": 486,
          "title": "[D],[P] Guidance required for solving a unique problem in application of DL in CFD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts4vbq/d_how_dstack_works/",
          "author": null,
          "description": "Hi everyone, I’m the creator of dstack, an open-core tool to train models and manage data. I’ve just published a post where I elaborated on the challenges AI researchers face today when training models, and how we at dstack aim to address them. In the post, you may find the details on the design decision we made for our tool. \n Blog post: https://blog.dstack.ai/p/how-dstack-works\n Invite everyone to read it, and share their thoughts. Happy to discuss the future of the developer tooling for training models!\n    submitted by    /u/cheptsov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts4vbq/d_how_dstack_works/",
          "publishedOn": "2022-03-30T12:02:15.000Z",
          "wordCount": 196,
          "title": "[D] How dstack works",
          "imageUrl": "https://external-preview.redd.it/NMDuEknhgjAtqwsrqtHhYwr4E94Rrdtbflmw0NVYdFU.jpg?auto=webp&s=04373965af0ab6f94849b024ac4b1d70002ab7a2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts3wsb/r_differentiable_conv_layer_using_fft/",
          "author": null,
          "description": "This is convolutional layer for torch using fourier transform. I wouldn't be surprised if this already existed somewhere, but I could not find one with derivatives. \n This is meant to be a drop in replacement for torch.Conv. It should be performant on kernel sizes above 20, depending on implementation. \n One interesting thing, even if a person already had one of these, is the way the bias and bias gradient were calculated. It only cost O(out_channels), ignoring the data size entirely.\n github\n    submitted by    /u/MKmisfit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts3wsb/r_differentiable_conv_layer_using_fft/",
          "publishedOn": "2022-03-30T11:04:46.000Z",
          "wordCount": 571,
          "title": "[R] Differentiable Conv Layer using FFT",
          "imageUrl": "https://external-preview.redd.it/Lgb5lDL4I-tLRZZZhpoLQeEyYwL555lbScwI5o7n3-Q.jpg?auto=webp&s=7aadb156963927e0808d13a7daa2347d29db5288"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts3k7z/r_fully_unsupervised_multidomain_imagetoimage/",
          "author": null,
          "description": "The code of \"A Style-aware Discriminator for Controllable Image Translation\" has been released! This is a novel multi-domain image-to-image translation method, which is fully unsupervised, and provide various applications, including style interpolation, content transplantation, and local image translation.\n Example of the prototype-guided synthesis\n Example of the reference-guided synthesis\n Paper: https://arxiv.org/abs/2203.15375\n Code: https://github.com/kunheek/style-aware-discriminator\n    submitted by    /u/graysp4rrow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts3k7z/r_fully_unsupervised_multidomain_imagetoimage/",
          "publishedOn": "2022-03-30T10:42:37.000Z",
          "wordCount": 186,
          "title": "[R] Fully unsupervised multi-domain image-to-image translation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts3dqg/d_any_well_known_approaches_to_compare_two_sets/",
          "author": null,
          "description": "Say given an MLP of 2 layers with non-linearity, are there established papers which explore if the sets of weights obtained after 2 trials of training end up with 'similar' weights.\n From an old stackexchange thread(2017) two possible methods outlined are. 1. Compare similarity on the predictions on validation inputs. 2. Instead of comparing pairwise similarity, simply concat them and use t-sne for dimensionality reduction. Based on a 2009 work.\n Link: https://cs.stackexchange.com/questions/74488/measuring-difference-between-two-sets-of-neural-network-weights\n Does anyone know of any recent work which tackles this problem ?\n    submitted by    /u/PaganPasta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts3dqg/d_any_well_known_approaches_to_compare_two_sets/",
          "publishedOn": "2022-03-30T10:30:32.000Z",
          "wordCount": 685,
          "title": "[D] Any well known approaches to compare two sets of neural network weights ?",
          "imageUrl": "https://external-preview.redd.it/62kLd8L6dwu0tEncBgcuLw_o-vkyeE6sZ4Rb720w_vY.jpg?auto=webp&s=ee5f3d315567f7cbde47ca378d48b3ea1cf250b7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts19ao/d_stable_reference_for_candidate_ops_in_nas/",
          "author": null,
          "description": "Good day, my fellow researchers and engineers.\n Recently I'm on research about neural architecture search. While reading through tons of papers about neural architecture search, I just got curious about 'how do we predefine primitive operations?' Because most of the paper goes like 'we have these ops in candidates, and we searched through candidates so elegantly...' I mean, how do we know we've predefined our candidates well? Is there any reference to 'good ops candidates'? I know certain cells and ops are often used in certain tasks, but still, I want to find a robust reference about 'The ops candidates for NAS'.\n It will cure my high blood pressure if you guys give your precious opinions about it.\n    submitted by    /u/KindAd9527  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts19ao/d_stable_reference_for_candidate_ops_in_nas/",
          "publishedOn": "2022-03-30T07:49:58.000Z",
          "wordCount": 327,
          "title": "[D] Stable Reference for candidate ops in NAS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0wad/rintroducing_causal_inference_in_the/",
          "author": null,
          "description": "submitted by    /u/Mammoth-Ad-5527  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0wad/rintroducing_causal_inference_in_the/",
          "publishedOn": "2022-03-30T07:22:23.000Z",
          "wordCount": 102,
          "title": "[R]Introducing causal inference in the energy-efficient building design process",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0fcs/d_why_does_almost_no_one_study_weakly_supervised/",
          "author": null,
          "description": "I notice that there is almost no papers in this area since 2020. And the rank of WSOD hasn't been updated since 2020:https://paperswithcode.com/sota/weakly-supervised-object-detection-on-pascal-1\n    submitted by    /u/voclee4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0fcs/d_why_does_almost_no_one_study_weakly_supervised/",
          "publishedOn": "2022-03-30T06:48:46.000Z",
          "wordCount": 628,
          "title": "[D]: Why does almost no one study \"Weakly Supervised Object Detection\"(WSOD) since 2020?",
          "imageUrl": "https://external-preview.redd.it/Yu7ffWTmZA4SI7v3owcUV2qpJ66ddbDE0wFMc9Cuzc0.jpg?auto=webp&s=3ef2187bdd0ffdd620a4b25e3088664744a3a48b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0dfs/d_recursive_error_prediction/",
          "author": null,
          "description": "I had an idea recently for a ML regression strategy and I'm just wondering if something like this already exists. It has similarities with both boosting and bagging, but I think it's ultimately different from both.\n The basic idea is that you start with a subset of input features and train a model on that subset. Any common model will do as long as it doesn't just spit out the exact target value when making a prediction on the training set (i.e., you couldn't use a 1-neighbor KNN). After fitting the model, you make predictions on the training set (with the same subset of features) and calculate the prediction errors.\n Then using another subset of features (I would think it should be mutually exclusive from the first subset but maybe it doesn't have to be), you train a separate model, but rather than training on the original Y training data, you use the error of the previous model as the target for the second model.\n You repeat this process until all features have been used or as many times as desired. To make a prediction, the parent model would simply sum the predictions of the child models.\n As an additional thought, you might use more regularization, larger leaf size for decision trees, etc. for each additional model. You could also use bagging to create multiple instances of the strategy with different feature subsets in order to create multiple \"pathways\" through the data.\n A few questions:\n  \nIs this sufficiently different from existing boosting/bagging techniques?\n If yes to #1, are there any existing packages (preferably in Python) that implement this kind of technique?\n Could this be used to reduce overfitting for higher dimensional datasets? If so, would additional steps need to be taken (e.g., like the iterative regularization scheme I mentioned)? My thought is that it's a kind of divide-and-conquer strategy where each subsequent model is asked to do a little less than the previous model.\n  \nAny thoughts are appreciated.\n    submitted by    /u/JHogg11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0dfs/d_recursive_error_prediction/",
          "publishedOn": "2022-03-30T06:44:56.000Z",
          "wordCount": 554,
          "title": "[D] Recursive error prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/ts0757/r_star_bootstrapping_reasoning_with_reasoning/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/ts0757/r_star_bootstrapping_reasoning_with_reasoning/",
          "publishedOn": "2022-03-30T06:32:24.000Z",
          "wordCount": 122,
          "title": "[R] STaR: Bootstrapping Reasoning With Reasoning",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trzo02/r_pathways_asynchronous_distributed_dataflow_for/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trzo02/r_pathways_asynchronous_distributed_dataflow_for/",
          "publishedOn": "2022-03-30T05:57:29.000Z",
          "wordCount": 104,
          "title": "[R] Pathways: Asynchronous Distributed Dataflow for Machine Learning",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tryeym/n_torchmultimodal_is_a_pytorch_library_for/",
          "author": null,
          "description": "It provides:\n  \nA repository of modular and composable building blocks (models, fusion layers, loss functions, datasets and utilities).\n \nA repository of examples that show how to combine these building blocks with components and common infrastructure from across the PyTorch Ecosystem to replicate state-of-the-art models published in the literature. These examples should serve as baselines for ongoing research in the field, as well as a starting point for future work.\n \n https://github.com/facebookresearch/multimodal\n    submitted by    /u/gurkitier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tryeym/n_torchmultimodal_is_a_pytorch_library_for/",
          "publishedOn": "2022-03-30T04:37:33.000Z",
          "wordCount": 181,
          "title": "[N] TorchMultimodal is a PyTorch library for training state-of-the-art multimodal multi-task models at scale.",
          "imageUrl": "https://external-preview.redd.it/k0zPC35uqP3XjD5mMOdcKZKsN5PTmijyjhqUQLRtock.jpg?auto=webp&s=13251b95cb0fb745cb285463417b6346a425e60b"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trvkih/r_ai_simulators_for_assisted_living_from_facebook/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trvkih/r_ai_simulators_for_assisted_living_from_facebook/",
          "publishedOn": "2022-03-30T01:56:47.000Z",
          "wordCount": 108,
          "title": "[R] AI Simulators for Assisted Living (from Facebook, CMU, et al)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trvfjk/r_desiderata_for_representation_learning_a_causal/",
          "author": null,
          "description": "Authors: Yixin Wang, Michael I. Jordan\n Abstract: Representation learning constructs low-dimensional representations to summarize essential features of high-dimensional data. This learning problem is often approached by describing various desiderata associated with learned representations; e.g., that they be non-spurious, efficient, or disentangled. It can be challenging, however, to turn these intuitive desiderata into formal criteria that can be measured and enhanced based on observed data. In this paper, we take a causal perspective on representation learning, formalizing non-spuriousness and efficiency (in supervised representation learning) and disentanglement (in unsupervised representation learning) using counterfactual quantities and observable consequences of causal assertions. This yields computable metrics that can be used to assess the degree to which representations satisfy the desiderata of interest and learn non-spurious and disentangled representations from single observational datasets. \n Paper: https://arxiv.org/abs/2109.03795\n Slides: https://yixinwang.github.io/papers/causal-rep-slides-public.pdf\n    submitted by    /u/bikeskata  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trvfjk/r_desiderata_for_representation_learning_a_causal/",
          "publishedOn": "2022-03-30T01:49:27.000Z",
          "wordCount": 227,
          "title": "[R] Desiderata for Representation Learning: A Causal Perspective",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trstl4/d_what_would_a_production_rl_stack_look_like_in/",
          "author": null,
          "description": "I was hoping I could get some insight into the tooling that you use (or would use) for some production RL work? I'm mostly doing it all on my home machine as a fun side project. \n I've got the following existing infrastructure: \n - An interface based loosely on the standard RL setup. I'm thinking about adapting it to fit Acme to let it do more heavy lifting since I quite like `Haiku`, `rlax` and the rest of what they do.\n - I've got some models across languages (Pytorch and Jax) and this has been causing me some headache trying to make sure everything is abstract enough. Should I just stick to one language and make sure all my friends just use that same language? \n - I'm currently using comet-ml for my experiment tracking, and for the most part I like it. However, I'm now looking around to see what's out there and I'm a little overwhelmed by (1) how many tools there are and (2) how some of them seem to \"overlap\" so I don't really know how to compose them.\n - configs all stored in a python file in a separate repo that is kept synced between my other repos.\n - I currently store my agent experiences (off policy) in a database that I later query to rapidly fill up the replay buffer. The limitation is that this is for a single agent. What drew me to Acme is that it seems to allow multiple agents to all use the same buffer? \n _____________\n tl;dr\n 1) Has anyone used Acme? I'm thinking of moving my project to it, but it might end up being a lot of effort for very little reward\n 2) How do you and your teams handle multiple languages? Do you just have abstract gym wrappers that convert data? \n 3) What tools do you use and how do you compose them together? I'm so so lost trying to navigate this space\n 4) How do you keep your configs synced when they are used between repos?\n    submitted by    /u/whynotmehmm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trstl4/d_what_would_a_production_rl_stack_look_like_in/",
          "publishedOn": "2022-03-29T23:28:58.000Z",
          "wordCount": 435,
          "title": "[D] What would a \"Production\" RL stack look like in terms of tooling?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trrpbd/p_i_have_data_with_connections_and_links_but_i/",
          "author": null,
          "description": "My dates are as follows:\n ​\n https://preview.redd.it/9htkypafgeq81.png?width=198&format=png&auto=webp&s=35e5475cf71364b8958b34e6100bd0ada2dc756d\n What I would like is to be able to map the following to a script:\n - Value 1440/1 in column FROM represented value 144019/1 in column TO.\n - Find value 144019/1 again in column FROM.\n - If found, take the value in column TO and find it again in column FROM. Not found, stop searching.\n ​\n Note: value 1440/1 does not have to be the initial value. In my data, 1440/1 can refer to another value again that is from column TO.\n ​\n I would like the following as output:\n - 1440/1, 144019/1, 144019/2;\n - 1440/1, 144018/1, 144018/2, 6038/1.\n    submitted by    /u/Silver-Panda2518  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trrpbd/p_i_have_data_with_connections_and_links_but_i/",
          "publishedOn": "2022-03-29T22:33:06.000Z",
          "wordCount": 228,
          "title": "[P] I have data with connections and links but I don't know how to write a scrip for this. Help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tro8go/d_quantization_aware_training_advice/",
          "author": null,
          "description": "Hi, I'm trying to run QAT on a MobileNetV2 based model but having some issues hitting the same training losses in the QAT phase as I did in the not-QAT phase.\n As a test, I'd trained the network for 1 epoch, then trained the QAT phase for 5 epochs and managed to get the same loss (actually lower). However, after training the model (non-QAT part) for 150 epochs, the QAT phase is really struggling to get down to the same loss.\n In my first test it dropped then completely levelled off for 2-3 epochs then nosedived again for another epoch, I'm not seeing the same in this longer train though.\n I was wondering if anyone has any advice on things like, should the learning rate be reset at the start of the QAT phase or should it carry on from where the training left off? I'm using Adam as the optimiser in the first phase, is that still ok in the second phase. Any other things that I could try? I did read a paper on improving quantization loss in MobileNet by L2 weighting the separable conv weights and swapping out ReLU6 for ReLU but I wasn't really seeing the same benefit as the paper (https://arxiv.org/pdf/1803.08607.pdf) did in my tests, I was getting a worse initial network.\n Thanks for any insight that anyone can provide!\n    submitted by    /u/ColdChancer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tro8go/d_quantization_aware_training_advice/",
          "publishedOn": "2022-03-29T21:57:47.000Z",
          "wordCount": 310,
          "title": "[D] Quantization Aware Training Advice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trno8g/p_interactive_demo_for_paper_sketchedit_maskfree/",
          "author": null,
          "description": "​\n https://reddit.com/link/trno8g/video/84uuyln8ceq81/player\n Hi everyone, here's an interactive demo I made for paper SketchEdit: Mask-Free Local Image Manipulation with Partial Sketches\n Demo: http://47.57.135.203:8001/\n Paper: https://arxiv.org/abs/2111.15078\n Project page: https://zengxianyu.github.io/sketchedit/\n Code: https://github.com/zengxianyu/sketchedit\n    submitted by    /u/Educational_Ebb2502  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trno8g/p_interactive_demo_for_paper_sketchedit_maskfree/",
          "publishedOn": "2022-03-29T21:45:39.000Z",
          "wordCount": 163,
          "title": "[P] Interactive Demo for Paper SketchEdit: Mask-Free Local Image Manipulation with Partial Sketches",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trm12l/d_dailyml_quiz_a_very_high_variance_means_the/",
          "author": null,
          "description": "Yesterday's answer: Pandas\n View Poll\n    submitted by    /u/daichrony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trm12l/d_dailyml_quiz_a_very_high_variance_means_the/",
          "publishedOn": "2022-03-29T21:08:42.000Z",
          "wordCount": 127,
          "title": "[D] DailyML quiz: A very high variance means the model likely has…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trjiul/pn_compilergym_tutorial_cgo/",
          "author": null,
          "description": "This weekend we (Hugh, Mostafa, and Chris from Meta AI) will be running a tutorial on Autotuning and Reinforcement Learning for compilers using CompilerGym at CGO’22. Join us for a hands-on session that takes you from “zero to RL” in three hours! The tutorial stats 1:30pm ET on Saturday April 2nd. Full schedule:\n https://conf.researchr.org/program/cgo-2022/program-cgo-2022/?date=Sat%202%20Apr%202022\n    submitted by    /u/melhoushi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trjiul/pn_compilergym_tutorial_cgo/",
          "publishedOn": "2022-03-29T20:34:32.000Z",
          "wordCount": 147,
          "title": "[P][N] CompilerGym Tutorial @ CGO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trgzx4/rlooking_for_papers_with_date_inference_from_text/",
          "author": null,
          "description": "Hey all,\n I'm going through research to figure out how the Date Inference protocols might be implemented. Given a text containing the phrase \"5 days from now\", I would need it to infer the date April 3rd. The 'now' part is a trivial problem, but the inference is something I'm struggling with. I could use regex but all the possible edge cases are tricky. \n The inference would need to work on unstructured cases like \"April 23rd\", \"Next Sunday\", etc. It would need to work forwards and backward (5 days ago etc.)\n ​\n Any great papers/resources? I searched for date inference, but nothing similar to what I'm looking for\n    submitted by    /u/ISeeThings404  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trgzx4/rlooking_for_papers_with_date_inference_from_text/",
          "publishedOn": "2022-03-29T20:03:03.000Z",
          "wordCount": 224,
          "title": "[R]Looking for papers with Date Inference from text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trglxa/research_audiotagging_done_right_2nd_comparison/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2203.13448\n Code: https://github.com/lijuncheng16/AudioTaggingDoneRight\n For anyone who's interested in AudioSet (2million youtube videos' sound). This is the SOTA comparison of models and training procedures.\n    submitted by    /u/billyli_16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trglxa/research_audiotagging_done_right_2nd_comparison/",
          "publishedOn": "2022-03-29T19:59:22.000Z",
          "wordCount": 138,
          "title": "[Research] AudioTagging Done Right: 2nd comparison of deep learning methods for environmental sound classification",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trejlz/p_college_course_on_ml_with_an_object_detection/",
          "author": null,
          "description": "The objective is simple, a kit with some small hardware is given to us (nuts, bolts, washers, etc). Using our laptop cameras, we need to develop a model that is able to accurate classify what object is what when placed infront of the camera. There can be any number of objects in any orientation, displayed on any color surface. What is the best way to approach this problem, what is a good model structure (high level) and what can I do to be a step above the competition.\n    submitted by    /u/Certified_User  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trejlz/p_college_course_on_ml_with_an_object_detection/",
          "publishedOn": "2022-03-29T18:54:42.000Z",
          "wordCount": 234,
          "title": "[P] College course on ML with an object detection project and competition between teams within the class. Help me make the best model possible.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/trbwwb/d_there_is_no_time_to_read_the_textbook_as_a/",
          "author": null,
          "description": "I'm a researcher who is deeply interested in deep generative models. There are excellent textbooks I want to read if time allows, such as:\n Probabilistic ML: https://probml.github.io/pml-book/book1.html\n PRML: https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf\n However, there are also many papers I have to read, new theories I have to learn, and works I need to finish. The problem is that reading textbooks could deepen the fundamental understanding of the field but rarely gives an immediate reward. Practically, reading a textbook from start to end can take > 1000 hours, in which one can read more than a hundred papers. Given the situation, I have studied basic stuff only when I need them for my research (you know, publish or perish).\n ​\n However, I think the time to read textbooks will decrease rather than increase, and only junior researchers will be able to afford to read them. It means that if I don't read them now, I won't be able to read later. Is there any general advice on this?\n    submitted by    /u/SnooPandas3529  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/trbwwb/d_there_is_no_time_to_read_the_textbook_as_a/",
          "publishedOn": "2022-03-29T18:09:40.000Z",
          "wordCount": 1804,
          "title": "[D] There is no time to read the textbook as a researcher",
          "imageUrl": "https://external-preview.redd.it/Ohq8BMzEcYr-l5BkFrKwi1-fYvKQ7KFnl7qJRyriLZI.jpg?auto=webp&s=28657cc423393863aad04c53ec0042e9cc8491b2"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/traoa1/p_will_a_recommender_system_alone_solve_this_issue/",
          "author": null,
          "description": "I have a project featuring 5+ years of data detailing mechanic reports. Essentially, I want to use ML to build a model that can make suggested actions to fix an issue based on these mechanic reports. For example, if a user typed in that a car “makes a squeaky sound” then it suggests three courses of action that may fix the issue based on similar issues and solutions detailed in the mechanic reports. \n Furthermore, when returning these suggestions, I want the user to see some sort of score indicating how likely it is to fix the issue (i.e. option A worked 97% of the time, option B 2% of the time, and option C 1% of the time). I also want the user to be able to try the options and give feedback on if they fixed the issue. \n My brain immediately went to a recommender system, but I don’t have much experience with creating them. Can they do all of the above (recommend solutions, score solutions, and allow for user input to keep training the model) or do I need to somehow pair with another method/model? I’m just not sure where to start.\n    submitted by    /u/ambiguousalmond  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/traoa1/p_will_a_recommender_system_alone_solve_this_issue/",
          "publishedOn": "2022-03-29T17:45:39.000Z",
          "wordCount": 423,
          "title": "[P] Will a recommender system alone solve this issue?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr93ls/r_understanding_dimensional_collapse_in/",
          "author": null,
          "description": "submitted by    /u/fasttosmile  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr93ls/r_understanding_dimensional_collapse_in/",
          "publishedOn": "2022-03-29T16:56:50.000Z",
          "wordCount": 118,
          "title": "[R] Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
          "imageUrl": "https://external-preview.redd.it/X0iUTaLs2Nk1xsiLuHSXDEF24fJPyIBmmpqk4epPlYg.jpg?auto=webp&s=036dcf53a951d6bafbf5c2dd6b37ccf914dabf13"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr8g5s/avoid_vver_fitting_in_iterative_pruning_d/",
          "author": null,
          "description": "Avoid over fitting in iterative pruning \n For iterative pruning algorithms referring to research papers like:\n ​\n  \nLearning both Weights and Connections for Efficient Neural Networks\n Deep Compression\n Comparing Rewinding and Fine-Tuning in Neural Network Pruning\n  \nI have found that during these pruning rounds, the pruned sub-network starts to overfit excessively, with training accuracy approaching almost 100%. This can be attributed to the fact that the surviving trained parameters are not reinitialized to either the randomly initialized values or to a previous value from earlier in the training.\n Whereas, for \"The Lottery Ticket Hypothesis\" and it's family of related research papers such as:\n  \nThe Lottery Ticket Hypothesis\n Stabilizing the Lottery Ticket Hypothesis\n One ticket to win them all\n Deconstructing Lottery Tickets\n  \nsuch overfitting is usually not observed due to the weight rewinding scheme.\n Since, the original & unpruned deep learning architecture is already trained with strategies such as: data augmentation, weight decay, learning rate schedule, etc., the resulting iterative pruning rounds result in overfitting.\n Can you suggest a way to avoid these overfitting during these iterative pruning rounds?\n    submitted by    /u/grid_world  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr8g5s/avoid_vver_fitting_in_iterative_pruning_d/",
          "publishedOn": "2022-03-29T16:50:33.000Z",
          "wordCount": 582,
          "title": "Avoid vver fitting in iterative pruning [D]",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr6ej7/signapse_harnessing_cnns_to_teach_sign_langauge/",
          "author": null,
          "description": "Hi,\n I'm a student at the University of Glasgow building a linux app that is trying to use CNNs to teach people the ASL (american sign language) alphabet. We just released the first version of our software which (although admittedly buggy) is worth sharing with interested communities. In brief, a MobileNetv2 model is trained on kaggle data for each sign in the ASL alphabet, this is executed within the OpenCV framework and run on camera frames of the user in real time. The user is challenged to make different signs and rewarded when the correct sign is made. We would love for interested people to try out our software and let us know about enhancement ideas or any bugs they may find.\n If you are interested in the project, please head over to our GitHub to have a look:\n https://github.com/albanjoseph/Signapse\n You can also follow us on Facebook:\n https://www.facebook.com/Signapse-125793226671815\n Twitter:\n https://twitter.com/GU_Signapse\n and YouTube:\n https://www.youtube.com/channel/UCh2uG2pYoSloEU0IFeqDQMA\n Cheers!\n Signapse Team\n    submitted by    /u/rossythebossy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr6ej7/signapse_harnessing_cnns_to_teach_sign_langauge/",
          "publishedOn": "2022-03-29T16:17:52.000Z",
          "wordCount": 246,
          "title": "Signapse: Harnessing CNNs to Teach Sign Langauge [Project] [Discussion]",
          "imageUrl": "https://external-preview.redd.it/ABeQUg5sFMFa-3c9UlvcjE9mghWNwgnSeiLEvY1NFZI.jpg?auto=webp&s=d40c93665c0ea87a971767fe0018f71f0fcd14f9"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr0vaq/dhugging_face_model_comparator_space_builder/",
          "author": null,
          "description": "You can now build a space comparing Hugging Face Models and Spaces or create clones of them with Model Comparator Space Builder 📷📷📷\n https://huggingface.co/spaces/farukozderim/Model-Comparator-Space-Builder\n ​\n https://preview.redd.it/t40n9amr0cq81.png?width=1813&format=png&auto=webp&s=f151ea9060f7c5b43f8dbcf3f91d1c308bdbb422\n ​\n https://preview.redd.it/fx1ztghs0cq81.png?width=1848&format=png&auto=webp&s=f1cfcb2b47831b10744b4d0e114fd21ed725b195\n Gradio: https://github.com/gradio-app/gradio\n Hugging Face: https://huggingface.co/\n    submitted by    /u/Mundane-Apartment224  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr0vaq/dhugging_face_model_comparator_space_builder/",
          "publishedOn": "2022-03-29T14:21:55.000Z",
          "wordCount": 118,
          "title": "[D]Hugging Face Model Comparator Space Builder",
          "imageUrl": "https://external-preview.redd.it/BDzEmJWh3jEsypQ1KSA94O-DYVnBlp4qU_esZ-RDm4E.jpg?auto=webp&s=1431103a871a610160474029201cc79f5483ea8f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr0glo/p_scikitlearn_transformer_that_turns_categorical/",
          "author": null,
          "description": "Hi everyone. Our DS & DA team open sourced a Python library that helps in dealing with categorical variables for machine learning algorithms.\n It leverages Tensorflow/Keras embedding layers and builds a neural network that learns a dense representation of each unique class. This is all packaged inside a regular scikit-learn transformer that can be used within pipelines and can have its hyperparameters optimized with regular sklearn methods.\n Just do pip install embedding-encoder[tf]. Check out the readme at Github or the blog post for examples.\n Github: https://github.com/cpa-analytics/embedding-encoder\n PyPI: https://pypi.org/project/embedding-encoder/\n Blog post: https://cpa-analytics.github.io/embedding-encoder-intro/\n This was inspired by the 3rd place solution in the Rossmann Store Sales Kaggle competition. Some implementations have surfaced over the years but we are not aware of working one that integrates well with existing libraries.\n This is just another preprocessing technique. It can be optimal for your task or not. As always, try multiple approaches and evaluate the results!\n    submitted by    /u/rafa10pj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr0glo/p_scikitlearn_transformer_that_turns_categorical/",
          "publishedOn": "2022-03-29T14:02:41.000Z",
          "wordCount": 627,
          "title": "[P] scikit-learn transformer that turns categorical variables into dense vector representations",
          "imageUrl": "https://external-preview.redd.it/43lw-vjgTJp6_14KvFjo7KRqd6JiHENPHeVKoJmvGcQ.jpg?auto=webp&s=78b885185f6dcca36ab60dee4d4c1b0778668573"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tr055q/research_dealing_with_variable_length_input_data/",
          "author": null,
          "description": "I am building a ML model to classify malware. My input data are windows binaries which get de-compiled into functions. From these functions I create embeddings, each is 150 float numbers. \n https://preview.redd.it/4ejwz7ukubq81.png?width=581&format=png&auto=webp&s=cbde0b534a8424f2a17ea5f1c77fccd2860685f5\n Problem: Each binary has a variable amount of functions. Some may have 40 functions while others may have over 1000. Most will have between 50 and 200. The order of the functions is not important.\n Question: What is the best way to deal with these variable amount of input. Hashing trick? Or Deep sets? What would you recommend?\n    submitted by    /u/laddi27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tr055q/research_dealing_with_variable_length_input_data/",
          "publishedOn": "2022-03-29T13:47:21.000Z",
          "wordCount": 447,
          "title": "[Research] Dealing with variable length input data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqzno6/discussion_podcast_with_jonathan_frankle_of/",
          "author": null,
          "description": "Jonathan came on the Weaviate Podcast to discuss the story of MosaicML, their new open-source Python library for Efficient Deep Learning called Composer, Pareto Curves of Training Time X Accuracy, Model Surgey augmentations, Maximizing CPU and GPU throughput, and many more! I hope you find this useful, happy to continue discussions of what Jonathan presented!\n https://www.youtube.com/watch?v=ZiBkspwrICA\n    submitted by    /u/HenryAILabs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqzno6/discussion_podcast_with_jonathan_frankle_of/",
          "publishedOn": "2022-03-29T13:23:34.000Z",
          "wordCount": 176,
          "title": "[Discussion] Podcast with Jonathan Frankle of MosaicML",
          "imageUrl": "https://external-preview.redd.it/YCKHLUjfYtgwj1bsM4k42UgT0xbL--xuPmSVXEhD-f0.jpg?auto=webp&s=60e3a937f8a19429373339338ca6414259d2faef"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqzlrh/d_using_large_language_models_for_classification/",
          "author": null,
          "description": "Hey everyone!\n I'd like to use a large language model like T0pp or GPT-NeoX-20B to take a natural-language input from a user and map it to one of ~2000 possible VS Code command palette commands. Essentially, this is a classification problem of the form \"NLP input -> command\".\n The idea is to let users give voice input in natural language and then have the model figure out what command they most likely want to activate.\n Given the number of possible commands I clearly can't rely on prompt design to solve this. It might be a good fit for a model with explicit retrieval augmentation like a memorizing transformer. But that's still a very active area of research without high-quality pre-trained models.\n Given that, I'm thinking that doing some kind of fine tuning to an existing model is the best bet. But it's unclear to me what the training data should look like... should I just generate a few examples of each command of the form input: \"vscode command: 'open new file'\", output: \"explorer.newFile\", and then fine-tune on those? Is there some way to ensure that the model understands that I *always* want it to return one of the commands provided in fine-tuning, instead of arbitrary text?\n Interested in others' experiences with similar tasks! \n Background: I'm working on an open source VS Code extension called Clippy AI. Currently it only performs code modifications to the current file and is a thin wrapper around the OpenAI API. But I'd like to use it to automate other editor actions as well!\n    submitted by    /u/corbt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqzlrh/d_using_large_language_models_for_classification/",
          "publishedOn": "2022-03-29T13:20:47.000Z",
          "wordCount": 598,
          "title": "[D] Using large language models for classification of natural-language input",
          "imageUrl": "https://external-preview.redd.it/y2lfc4rWbAhcBOgAM89rfyc1xin3Ckl8qDzfHdHNH0E.jpg?auto=webp&s=6787ad1c737d4a066ca3274c379e4ca8029953f7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqynd5/visualizing_pathologies_in_ultrasound_images/",
          "author": null,
          "description": "As part of our AI Challenge with a health-tech startup: https://omdena.com/blog/pathology-streamlit/\n https://preview.redd.it/zew2baykgbq81.png?width=640&format=png&auto=webp&s=e66180724c08f22db3d322d8b1fd6f56e8765a3c\n    submitted by    /u/Lordobba  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqynd5/visualizing_pathologies_in_ultrasound_images/",
          "publishedOn": "2022-03-29T12:28:13.000Z",
          "wordCount": 115,
          "title": "Visualizing Pathologies in Ultrasound Images Using OpenCV and Streamlit [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqxr2u/d_it_is_possible_to_build_a_time_series_model/",
          "author": null,
          "description": "So basically, I started my internship in business intelligence, and when my boss know that I have a background in machine learning and deep learning. so, he asked me to build a model that predicts a specific number for the next month. so, it time series problem, and the datasets that I have it is very small it starts from May 2019 so it is just 31 rows. And when I plotted the data, it had no clear trend. This pitcher for the graph looks like my dataset here! dataset (sorry I cannot share the dataset because of privacy). So, I started to take the difference in the data to remove the seasonality and log transformation and after that, I bullied the model using the Arima algorithm and LSTM, and prophet. And I applied a prediction interval for the predicted number to get periods and expect the number will be inside this interval. But unfortunately, the actual number (for this month) was out of the interval. So, I decided to look back in a database and I found a feature I think that may help and have a high correlation with the main feature now becoming a multivariate time series problem. so, I tried to use the VAR algorithm but unfortunately, the model also filed and the actual number for each feature was out of interval. This first time for me to build a time series model in the industry for a real dataset and I worked alone. So, there is an approach that can help me to build a better model that I do not follow in my step. Or I should go to my boss tell him cannot build a model for this dataset, especially the data is impacted by a coronavirus.\n    submitted by    /u/xxsalehxx140  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqxr2u/d_it_is_possible_to_build_a_time_series_model/",
          "publishedOn": "2022-03-29T11:36:52.000Z",
          "wordCount": 560,
          "title": "[D] It is possible to build a time series model with this dataset.",
          "imageUrl": "https://external-preview.redd.it/VwDh6e8p18FQXsFgIgb7CNvQNvcqUmIgjANK9aXApMY.jpg?auto=webp&s=a516240355f0a87693bcfe8366c778a959b9278f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqx0u7/process_models_for_data_science_academic_r/",
          "author": null,
          "description": "Hello everyone,\n I am a german student and currently writing my masters thesis. It is a rather simple ML task but for my thesis I need to describe the methodology and which process models are used and I am new to this. I found CRISP-DM and its successor ASUM-DM. However, I know that sounds stupid, I am not able to find information on these or useful pdfs. Like the general information and descriptions are accessable but I need an officisl source that I can cite. IBM itself has a link: ftp: //ftp.software.ibm.com/software/data/ sw-library/services/ASUM.pdf However, its not working for me as I have no ftp access. \n So my question is, does anyone have a link where I can find relevant official information to these models and furthermore are there any other standards or process models to describe the approach of working with data that are rather used in the industry.\n    submitted by    /u/terektus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqx0u7/process_models_for_data_science_academic_r/",
          "publishedOn": "2022-03-29T10:48:47.000Z",
          "wordCount": 247,
          "title": "Process Models for Data Science? (academic) [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqnhin/d_object_inputs_with_multiple_features/",
          "author": null,
          "description": "Hello,\n I am looking at having a neural network take inputs of 8 objects that all have different features/attributes and then an input of the different features/attributes of the environment the objects are in. The output of this would be the rank of each object. The attached image demonstrates a diagram of the neural network. The objects actively interact/compete with each other. I thought about inputting a single object's features and the environment into a neural network with the output as a performance score of the object. However, the object does worse or better depending on what other objects it is competing against. The objects also get better or worse over time, so it may be good to backpropagate and analyze the objects also as a time series.\n Is it possible to input the object/object features as a matrix? I have not figured out a way to group this data. I was thinking maybe a convolution neural network may work. I am somewhat new to the machine learning world. Any recommendation or help would be great. Thank you\n https://preview.redd.it/ng7q9haxw7q81.jpg?width=6450&format=pjpg&auto=webp&s=9393006f00583a1a4a9af02044e726559176c403\n    submitted by    /u/hypercar_junkie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqnhin/d_object_inputs_with_multiple_features/",
          "publishedOn": "2022-03-29T00:31:44.000Z",
          "wordCount": 268,
          "title": "[D] Object Inputs with Multiple Features",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqn4k4/r_time_series_clustering_resources/",
          "author": null,
          "description": "Hi, I am intending to write a paper (almost 25-30 pages) about time series clustering. I have done my online research, however, I ll be grateful if you can mention some other resources that might be of interest, either theoretical or applied. It can be blogs about machine learning you find interesting in this area, video series, lectures, lecture notes, whatever. Thank you very much.\n    submitted by    /u/jiii95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqn4k4/r_time_series_clustering_resources/",
          "publishedOn": "2022-03-29T00:12:36.000Z",
          "wordCount": 154,
          "title": "[R] time series clustering resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tql5b8/p_any_resources_on_finetuning_models_decision/",
          "author": null,
          "description": "Hello, i'm trying to reproduce the Decision Transformer paper, however i feel seriously lost on how to do it. I find no documentation on fine-tuning models and have no idea how to use the datasets.\n Any help would be much appreciated, thanks.\n    submitted by    /u/PM_ME_FREE_GAMES  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tql5b8/p_any_resources_on_finetuning_models_decision/",
          "publishedOn": "2022-03-28T22:31:22.000Z",
          "wordCount": 142,
          "title": "[P] Any resources on fine-tuning models? - Decision Transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqjqjp/p_seems_like_people_are_finding_my_dataml_job/",
          "author": null,
          "description": "Hey everybody,\n around half a year ago, I created a simple job aggregator called datajoblist.com, which fetches/scrapes remote jobs in data science, data engineering and AI from multiple sources and presents them in a simple, unified interface. The jobs are collected both directly from interesting (to me) companies like Stripe or Shopify, as well as filtered from job boards such as weworkremotely.com.\n I have not touched the site since when I first built it half a year ago, but it seems that people are finding it helpful, as it is now getting rather stable lower few thousand unique visitors per month, and has facilitated thousands of “apply” click-throughs to company sites. A few dozen people even signed up for the mailing list. So, I was thinking about investing a little more time now and adding some improvements.\n Is there any information/functionality that you would like to see there?\n Shortly, I will be adding the possibility to post jobs for a small fee (till now, all jobs on the site have been aggregated from elsewhere), but would love to add some usability improvements that are reasonably simple to implement for me. (Perhaps salary ranges, where available?)\n Thanks for any feedback and have a great day!\n    submitted by    /u/k_kristian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqjqjp/p_seems_like_people_are_finding_my_dataml_job/",
          "publishedOn": "2022-03-28T21:22:50.000Z",
          "wordCount": 327,
          "title": "[P] Seems like people are finding my data/ML job aggregator helpful… do you have any feedback for me?",
          "imageUrl": "https://external-preview.redd.it/VX5BlMXY6hbRdKozcruBmIMfeKDQHgE88xTLxGOb8Ik.jpg?auto=webp&s=37f17936923c5011eb9fae0f449cf9c72e2cec22"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqjd3w/d_neural_networks_are_not_the_only_universal/",
          "author": null,
          "description": "I often here the success of neural networks attributed to their status as universal approximators, but there are many algorithms that are universal approximators. For example, decision trees can also be universal approximators, but they don't seem to have nearly as much success. Why is this? What do neural networks have beyond just being universal approximators that makes them special?\n ​\n Is this a question that is currently well understood or is the answer to this question still an area of research?\n    submitted by    /u/029187  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqjd3w/d_neural_networks_are_not_the_only_universal/",
          "publishedOn": "2022-03-28T21:04:54.000Z",
          "wordCount": 760,
          "title": "[D] Neural Networks are not the only universal approximators, so why are they so uniquely effective?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqdpf8/d_why_gnns_suffer_from_oversmoothing_but_cnns_dont/",
          "author": null,
          "description": "Many articles online say GNNs suffer from over-smoothing because nodes aggregate their neighbors and many nodes share similar sets of neighbors. However, in CNN, each pixel also aggregates its neighbors. But CNN can still perform well on some pixel-level classification tasks such as segmentation.\n    submitted by    /u/AirZealousideal1342  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqdpf8/d_why_gnns_suffer_from_oversmoothing_but_cnns_dont/",
          "publishedOn": "2022-03-28T16:51:57.000Z",
          "wordCount": 393,
          "title": "[D] Why GNNs suffer from over-smoothing but CNNs don't?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqd22m/d_paper_review_video_memoryassisted_prompt/",
          "author": null,
          "description": "https://youtu.be/gYxJEd3EUKs\n Large language models such as GPT-3 have enabled many breakthroughs and new applications recently, but they come with an important downside: Training them is very expensive, and even fine-tuning is often difficult. This paper presents an adaptive method to improve performance of such models after deployment, without ever changing the model itself. This is done by maintaining a memory of interactions and then dynamically adapting new prompts by augmenting them with memory content. This has many applications, from non-intrusive fine-tuning to personalization.\n ​\n OUTLINE:\n 0:00 - Intro\n 0:40 - Sponsor: Introduction to GNNs Course (link in description)\n 1:30 - Paper Overview: Improve GPT-3 after deployment via user feedback\n 5:30 - Proposed memory-based architecture\n 13:00 - A detailed look at the components\n 15:00 - Example tasks\n 24:30 - My concerns with the example setup\n 26:20 - Baselines used for comparison\n 29:50 - Experimental Results\n 34:20 - Conclusion & Comments\n ​\n Paper: https://arxiv.org/abs/2201.06009\n Code & Data: https://github.com/madaan/memprompt\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqd22m/d_paper_review_video_memoryassisted_prompt/",
          "publishedOn": "2022-03-28T16:23:08.000Z",
          "wordCount": 269,
          "title": "[D] Paper Review Video - Memory-assisted prompt editing to improve GPT-3 after deployment",
          "imageUrl": "https://external-preview.redd.it/GzqzM44_xv46etrLcJuHT-qngCBZsBvKGZQVGqNvyJ0.jpg?auto=webp&s=c725fcefbdc20b96757c8f4a6214fa65a0024719"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqbpk5/d_diversity_in_recommendation_systems_with_a/",
          "author": null,
          "description": "Many recommendation systems start with a few very popular items that were heavily marketed. The rest of the item list is largely unexplored. How do recommender systems get around this bias and \"test\" out new items on users to develop richer training data?\n I could see how a multi-arm bandit might fix this problem but I'd love to hear other ideas and lessons learned.\n    submitted by    /u/Shap177  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqbpk5/d_diversity_in_recommendation_systems_with_a/",
          "publishedOn": "2022-03-28T15:21:51.000Z",
          "wordCount": 170,
          "title": "[D] Diversity in Recommendation Systems with a Mostly Unexplored Item List",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqbmwq/p_ive_released_a_python_package_which_lets_you/",
          "author": null,
          "description": "https://github.com/minimaxir/imgbeddings\n Instead, this package uses an ONNX INT8-quantized version of CLIP's Vision layers, which in testing works just as well, with a significant performance boost.\n The demos also turned out very well, and try to a bit more fun than usual.\n    submitted by    /u/minimaxir  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqbmwq/p_ive_released_a_python_package_which_lets_you/",
          "publishedOn": "2022-03-28T15:18:29.000Z",
          "wordCount": 202,
          "title": "[P] I've released a Python package which lets you generate vector representations of images with a twist: neither PyTorch nor TensorFlow is used!",
          "imageUrl": "https://external-preview.redd.it/tdsX1I8bgzTfp3bs-wIJzQ4TWsVWjypXKod6JYKGVPE.jpg?auto=webp&s=f9906514cd0c716c0083812e13da7c237c53a38f"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqb7py/p_decision_transformers_in_transformers_library/",
          "author": null,
          "description": "Hey there,\n We’re happy to announce that Edward Beeching from Hugging Face has integrated Decision Transformers an Offline Reinforcement Learning method, into the 🤗 transformers library and the Hugging Face Hub.\n In addition, we share nine pre-trained model checkpoints for continuous control tasks in the Gym environment.\n If you want to know more about Decision Transformers and how to start using it, we wrote a tutorial 👉 https://huggingface.co/blog/decision-transformers\n We would love to hear your feedback about it,\n Thanks,\n    submitted by    /u/cranthir_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqb7py/p_decision_transformers_in_transformers_library/",
          "publishedOn": "2022-03-28T14:59:36.000Z",
          "wordCount": 267,
          "title": "[P] Decision Transformers in Transformers library and in Hugging Face Hub",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqb4v0/d_catboost_performance_on_python_vs_c/",
          "author": null,
          "description": "Hi fellow nerds, was wondering if anyone has trained the same catboost model on the same dataset in Python and C++ to see which is quicker. Also posting in case someone knows why one language may be inherently quicker. \n I assume that they are the same program with the same run time but I can’t be too sure of that. Thanks.\n    submitted by    /u/econ1mods1are1cucks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqb4v0/d_catboost_performance_on_python_vs_c/",
          "publishedOn": "2022-03-28T14:55:57.000Z",
          "wordCount": 259,
          "title": "[D] Catboost performance on Python vs C++",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqb2mb/p_release_the_vision_transformer_cookbook_with/",
          "author": null,
          "description": "​\n Vision Transformer Cookbook\n ​\n Hello, I have released the Vision Transformer Cookbook with Tensorflow !\n Therefore, you can easy to use the 22 transformer architectures via just copy & paste.\n I hope this repository would help many people, including tensorflow users.\n Thank you.\n ​\n * code: vit-tensorflow\n    submitted by    /u/taki0112  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqb2mb/p_release_the_vision_transformer_cookbook_with/",
          "publishedOn": "2022-03-28T14:53:08.000Z",
          "wordCount": 165,
          "title": "[P] Release the Vision Transformer Cookbook with Tensorflow ! (Thanks to @lucidrains)",
          "imageUrl": "https://external-preview.redd.it/ebuMUe4Vpk4o7taF_wbulAfqA1foTC-S3Dl2bCXfwOw.jpg?auto=webp&s=df0b61c8232f6083ea6276f2c3ae595c9aefba39"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tqak1i/discussion_create_a_random_forest_regression_to/",
          "author": null,
          "description": "I am using Random Forest Regression on a power vs time data of an experiment that is performed for a certain time duration. Using that data, I want to predict the trend of power in future using time as an input. The code that has been implemented is mentioned below.\n The data set consists of approximately 30 hours of power vs time values as mentioned below. Only active power and time_h columns are used in the algorithm.\n ​\n Data set used for modelling\n # Creating X and y X = np.array(series[['time_h']]).reshape(-1,1) y = np.array(series['active_power']) # Splitting dataset in training and testing X_train2,X_test2,y_train2,y_test2 = train_test_split(X,y,test_size = 0.15, random_state = 1) # Creating Random Forest model and fitting it on training data forest = RandomForestRegressor(n_estimat…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tqak1i/discussion_create_a_random_forest_regression_to/",
          "publishedOn": "2022-03-28T14:29:12.000Z",
          "wordCount": 526,
          "title": "\"[Discussion] Create a Random Forest Regression to predict multiple values in future using past data\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq7cjn/discussion_i_am_a_sample_in_the_dataset_i_have_to/",
          "author": null,
          "description": "Basically the title. I work as a data engineer for a company I am also a customer of. From an Ethics in ML point of view: what do you think this implies on my responsibilities?\n    submitted by    /u/Bani57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq7cjn/discussion_i_am_a_sample_in_the_dataset_i_have_to/",
          "publishedOn": "2022-03-28T11:42:10.000Z",
          "wordCount": 332,
          "title": "[Discussion] I am a sample in the dataset I have to analyze",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq40t9/d_everything_about_attention_family/",
          "author": null,
          "description": "Hey, I have just published my latest medium article. \n These days, in deep learning, it is usual to hear about transformers’ outstanding performance on the challenges where other algorithms can not meet our expectations when most of them are based on attention. This article gives you a detailed illustration of the code and mathematics of the four most-used types of attention in the Deep Learning era.\n https://rezayazdanfar.medium.com/everything-about-attention-family-644747903c60\n    submitted by    /u/rezayazdanfar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq40t9/d_everything_about_attention_family/",
          "publishedOn": "2022-03-28T07:40:25.000Z",
          "wordCount": 160,
          "title": "[D] Everything about Attention Family",
          "imageUrl": "https://external-preview.redd.it/EKWOzyGXMdUqAqJYhL82vLWaQkBk3-ml_g6HqnUPA6k.jpg?auto=webp&s=109d698053ded955f4a2208edc303aed709e8cfe"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq1ia3/r_new_tsne_guidelines_an_experimental_study_and/",
          "author": null,
          "description": "t-SNE remains a popular embedding method for visualizing high-dimensional data. However, there is little consensus on how to select hyperparameters such as perplexity, learning rate, and exaggeration to best visualize arbitrary data sets.\n This work systematically explores t-SNE hyperparameters using almost 700 data sets. We replicate past studies, proving that some t-SNE guidelines generalize beyond their original context. But we find that some guidelines do not appear to generalize. We also show a proof of concept neural network system for featurizing data sets and automatically recommending good t-SNE hyperparameters.\n Paper: https://osf.io/6t5ax/\n Blog: https://twosixtech.com/new-guidance-for-using-t-sne/\n    submitted by    /u/rpgove  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq1ia3/r_new_tsne_guidelines_an_experimental_study_and/",
          "publishedOn": "2022-03-28T04:47:59.000Z",
          "wordCount": 862,
          "title": "[R] New t-SNE guidelines, an experimental study, and automatic t-SNE hyperparameter selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq0e3k/r_text_to_mesh_without_3d_supervision_using_limit/",
          "author": null,
          "description": "submitted by    /u/InfamousPancakes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq0e3k/r_text_to_mesh_without_3d_supervision_using_limit/",
          "publishedOn": "2022-03-28T03:39:52.000Z",
          "wordCount": 622,
          "title": "[R] Text to Mesh Without 3D Supervision Using Limit Subdivision (Clipmesh)",
          "imageUrl": "https://preview.redd.it/x8etj6w9p1q81.gif?format=png8&s=339435fd2695a73a2d0e704ded901789540b3bc7"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq0dt3/p_mlbot_opensource_tool_to_train_ml_models_in/",
          "author": null,
          "description": "Hey ML Reddit!\n I just released the initial version of MLbot (https://github.com/thecooltechguy/mlbot): a new open-source tool that I’ve been working on for running distributed ML training jobs in your cloud, with a single command.\n How it works:\n In short, it allows you to run your training script in the cloud by simply swapping “python” for “mlbot run”.\n For example, if ``python train.py … can run your training script locally, then mlbot run --instance-type p3dn.24xlarge --num-nodes 2 train.py … should be able to run your code in the cloud across 2 GPU machines.\n Since this tool runs entirely inside your cloud environment, you don’t have to transfer your training data to a 3rd party, while having full observability into the underlying infrastructure.\n Why I built this:\n In a recent ML pr…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq0dt3/p_mlbot_opensource_tool_to_train_ml_models_in/",
          "publishedOn": "2022-03-28T03:39:23.000Z",
          "wordCount": 627,
          "title": "[P] MLbot – Open-source tool to train ML models in your cloud, with a single command.",
          "imageUrl": "https://external-preview.redd.it/r6wuHnVZTvC1fK_HjgCwBMj7B5oYlRNQx0d1AJO8HBI.jpg?auto=webp&s=407ae7feaf63b13bfada5a61a85d3d55ecb47dee"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq097n/d_what_is_the_following_nlp_task_called/",
          "author": null,
          "description": "Looking for ideas and pointers on how to solve this problem. Dependency parsing? Are there any open source ML models to solve this problem? Googling isn't helping.\n Made a mistake in the description - we want to explain the negative sentiment of the aspect \"tone\" (rather than guitar)\n    submitted by    /u/ml_guy1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq097n/d_what_is_the_following_nlp_task_called/",
          "publishedOn": "2022-03-28T03:31:59.000Z",
          "wordCount": 343,
          "title": "[D] What is the following NLP task called - explaining WHY someone feels a particular way in a product review? For example with the sentence - \"I don't like the tone of the guitar because the strings are too old\", the explanation for negative sentiment of guitar should be \"strings are too old\".",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tq00tu/d_difference_between_research_and_applied/",
          "author": null,
          "description": "Hello, I am in the process of finding a suitable conference for my paper, and I find that they usually have a research track and applied research track. One conference defines the applied research track as\n  \nThe Applied Research Track aims at attracting submissions from both industry and academia that either solve or advance the understanding of issues related to deploying AI, Information Retrieval (IR), and big data technologies as part of actual applications.\n  \nMy paper is roughly related to applying deep learning for time series anomaly detection. Should I go for the research track or the applied research track?\n    submitted by    /u/mythrowaway0852  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tq00tu/d_difference_between_research_and_applied/",
          "publishedOn": "2022-03-28T03:18:17.000Z",
          "wordCount": 314,
          "title": "[D] Difference between Research and Applied Research track in conferences?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpt9xn/p_we_built_a_ai_platform_to_advance_stereotactic/",
          "author": null,
          "description": "4 years ago, I posted here to introduce some work I did using AI for breast tumor detection and classification: \n https://www.reddit.com/r/MachineLearning/comments/8rdpwy/pi_made_a_gpu_cluster_and_free_website_to_help/\n That post gain some traction on Reddit and I hope you would like the one I am gonna introduce here again. \n In the recent years, I have been shifting my focus from cancer detection to the actual treatment. \n One particular problem we really want to solve is to have more brain cancer patients to be accessible to stereotactic radiosurgery (SRS) which has a lot better treatment outcome and much better quality of life (QoL) for the patient than whole brain radiotherapy (WBRT) which is more common for patients with multiple brainiest (say more than 5 or 10). \n The reason behind …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpt9xn/p_we_built_a_ai_platform_to_advance_stereotactic/",
          "publishedOn": "2022-03-27T21:08:23.000Z",
          "wordCount": 453,
          "title": "[P] We built a AI platform to advance stereotactic radiosurgery (SRS) for brain tumor patients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tps7fl/d_is_colab_pro_worth_the_money/",
          "author": null,
          "description": "Hey guys, I'm currently dealing with my bachelor degree's final project. But my pc seems to be slow and it gets really hot + I think it might be dying, I really need to send it to the technical service. :(\n Well, I'm not familiar with other cloud services like Azure or AWS but I used Google Colab a lot, and right at this moment I also use it. But it's constantly asking if I'm \"there\". It always wants an interaction otherwise it shutdowns the session and my time gets wasted, just gotta do everything from the start.\n So if I pay for the colab pro (unpluss) version, will my experience get better? Will I need to interact with colab every hour again? Or should I consider other alternatives?\n    submitted by    /u/average_turanist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tps7fl/d_is_colab_pro_worth_the_money/",
          "publishedOn": "2022-03-27T20:16:53.000Z",
          "wordCount": 426,
          "title": "[D] Is Colab Pro Worth the money?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpruqj/d_machine_learning_wayr_what_are_you_reading_week/",
          "author": null,
          "description": "This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.\n Please try to provide some insight from your understanding and please don't post things which are present in wiki.\n Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.\n Previous weeks :\n  \n 1-10 11-20 21-30 31-40 41-50 51-60 61-70 71-80 81-90 91-100 101-110 111-120 121-130 131-140 \n  \n Week 1 Week 11 Week 21 Week 31 Week 41 Week 51 Week 61 Week 71 Week 81 Week 91 Week 101 Week 111 Week 121 Week 131 \n  Week 2 Week 12 Week 22 Week 32 Week 42 Week 52 Week 62 Week 72 Week 82 Week 92 Week 102 Week 112 Week 122 Week 132 \n  Week 3 Week 13 Week 23 Week 33 Week 43 Week 53 Week 63 Week 73 Week 83 Week 93 Week 103 Week 113 Week 123 Week 133 \n  Week 4 Week 14 Week 24 Week 34 Week 44 Week 54 Week 64 Week 74 Week 84 Week 94 Week 104 Week 114 Week 124  \n  Week 5 Week 15 Week 25 Week 35 Week 45 Week 55 Week 65 Week 75 Week 85 Week 95 Week 105 Week 115 Week 125  \n  Week 6 Week 16 Week 26 Week 36 Week 46 Week 56 Week 66 Week 76 Week 86 Week 96 Week 106 Week 116 Week 126  \n  Week 7 Week 17 Week 27 Week 37 Week 47 Week 57 Week 67 Week 77 Week 87 Week 97 Week 107 Week 117 Week 127  \n  Week 8 Week 18 Week 28 Week 38 Week 48 Week 58 Week 68 Week 78 Week 88 Week 98 Week 108 Week 118 Week 128  \n  Week 9 Week 19 Week 29 Week 39 Week 49 Week 59 Week 69 Week 79 Week 89 Week 99 Week 109 Week 119 Week 129  \n  Week 10 Week 20 Week 30 Week 40 Week 50 Week 60 Week 70 Week 80 Week 90 Week 100 Week 110 Week 120 Week 130  \n \n Most upvoted papers two weeks ago:\n /u/CatalyzeX_code_bot: Paper link\n /u/PaganPasta: https://arxiv.org/abs/2105.05233\n Besides that, there are no rules, have fun.\n    submitted by    /u/ML_WAYR_bot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpruqj/d_machine_learning_wayr_what_are_you_reading_week/",
          "publishedOn": "2022-03-27T20:00:05.000Z",
          "wordCount": 379,
          "title": "[D] Machine Learning - WAYR (What Are You Reading) - Week 134",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpqk9l/nr_combine_lidar_and_cameras_for_3d_object/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpqk9l/nr_combine_lidar_and_cameras_for_3d_object/",
          "publishedOn": "2022-03-27T18:59:38.000Z",
          "wordCount": 225,
          "title": "[N][R] Combine Lidar and Cameras for 3D object detection - Waymo & Google Research",
          "imageUrl": "https://external-preview.redd.it/OGzE3sF5Uk6DITpibUX887oZn8KPPebAhdbGkRXsIJE.jpg?auto=webp&s=211302fb9cff3c187d69a385588b21403e42b632"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tppxo9/discussion_interesting_prediction_of_ecosystem/",
          "author": null,
          "description": "Saw this comment in a Q&A on big deep learning models. This seems to have side-effects both good and bad. The prediction, if true, forces accessibility (though expensive) but also creates silos. First time poster. What do you guys think?\n https://m12.vc/news/direct-line-with-saurabh-tiwary-whats-next-for-large-foundational-models\n  \nThe economics are making it untenable for most people except the most well-funded organizations to invest in large language models. I will make the comparison to the semiconductor ecosystem. If you look at fabrication economics for semiconductor chips, they cost tens to hundreds of millions of dollars and have relatively short lifetimes. One needs very large volume usage to justify manufacturing a custom ASIC (Application Specific Integrated Circuits). Thus, we do not have that many companies fabricating chips. However, we have an entire software and systems eco-system which relies on these chips that have built massive industries around them. And, if you look at the biggest companies in the world (maybe, except Apple), they have very little to do with ASIC design and fabrication as part of their core business. I think a similar eco-system would pan out in the large-scale modeling space as well. We would have a few well-funded companies that would be training these extremely large and reusable models and other companies would build applications and services reusing and customizing these models.\n  \n   submitted by    /u/SufficientActive8895  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tppxo9/discussion_interesting_prediction_of_ecosystem/",
          "publishedOn": "2022-03-27T18:29:24.000Z",
          "wordCount": 315,
          "title": "[Discussion] Interesting prediction of ecosystem around giant DNN models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpmowt/d_modern_data_augmentation_techniques/",
          "author": null,
          "description": "I've written a short blog post on modern data augmentation techniques. Please have a read and provide feedback. I've explained Cutout, Mixup, CutMix and Label smoothing with code and examples.\n https://pmgautam.com/augmentations/2022/03/27/Augmentations-visually-explained.html\n    submitted by    /u/p1g1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpmowt/d_modern_data_augmentation_techniques/",
          "publishedOn": "2022-03-27T15:50:49.000Z",
          "wordCount": 487,
          "title": "[D] Modern data augmentation techniques",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tplo8r/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tplo8r/d_simple_questions_thread/",
          "publishedOn": "2022-03-27T15:00:10.000Z",
          "wordCount": 285,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpi5gx/p_author_pages_on_httppaperslabmlai/",
          "author": null,
          "description": "We added author pages, which lists all the papers by the author and links to their social and academic web pages.\n E.g.: \n https://papers.labml.ai/author/39815586a03711ecbb8c3d25c114d5ed\n https://papers.labml.ai/author/56b63a47a03711ecbb8c3d25c114d5ed\n Highlights, \n  \nLinks to Google and Arxiv searches.\n Sort papers based on the published date and the popularity in Twitter.\n Links to Twitter, Google Scholar, Github and Linkedin etc if available in our database.\n  \nWe love to hear your feedback and suggestions. Thank you all, and I appreciate the support.\n    submitted by    /u/hnipun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpi5gx/p_author_pages_on_httppaperslabmlai/",
          "publishedOn": "2022-03-27T11:37:33.000Z",
          "wordCount": 206,
          "title": "[P] Author pages on http://papers.labml.ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tpa89n/rp_groupvit_semantic_segmentation_emerges_from/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tpa89n/rp_groupvit_semantic_segmentation_emerges_from/",
          "publishedOn": "2022-03-27T02:10:12.000Z",
          "wordCount": 224,
          "title": "[R][P] GroupViT: Semantic Segmentation Emerges from Text Supervision + Hugging Face Gradio Web Demo",
          "imageUrl": "https://external-preview.redd.it/TCv6-qKCraPT1-OhsfkXsXZpoFY2_tfQTDcAnfEpBoY.png?format=pjpg&auto=webp&s=98058dab4a53838db6cedea3fb780154e0574573"
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/tp5iyf/d_conditional_gan_loss_magnitudes/",
          "author": null,
          "description": "Hey, I am wondering about the losses of conditional GANs, particularly their magnitude. Due to the amount of classes/identities, the classification loss will usually be significantly higher than discrimination loss (data identified as real or generated). When using traditional multitask learning where losses are simply summed up, how is the generator supposed to learn to generate realistic-appearing data when the loss that would encourage that is so low in comparison to the classification loss?\n    submitted by    /u/Timboron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/tp5iyf/d_conditional_gan_loss_magnitudes/",
          "publishedOn": "2022-03-26T22:07:29.000Z",
          "wordCount": 310,
          "title": "[D] Conditional GAN loss magnitudes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/toy50y/d_augmentation_in_gan/",
          "author": null,
          "description": "Hi, does anyone has experience in augmentation for GANs? Especially for Cycle-GAN like image to image translation. When I see image-to-image GANs, there is mostly no augmentation applied.\n    submitted by    /u/SeucheAchat9115  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/toy50y/d_augmentation_in_gan/",
          "publishedOn": "2022-03-26T17:13:10.000Z",
          "wordCount": 181,
          "title": "[D] Augmentation in GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/toqvg1/discussion_how_does_apple_faceid_work/",
          "author": null,
          "description": "I am doing some face recognition and am wondering how does apple's FaceID work. They say it is a \"true depth\" camera. What does that mean? is that a lidar? some kind of a dot projector? Basically what I want to know is what kind of data does that device provide. Also, is there a commercially available device similar to that true depth camera available?\n    submitted by    /u/user89320  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/toqvg1/discussion_how_does_apple_faceid_work/",
          "publishedOn": "2022-03-26T14:24:56.000Z",
          "wordCount": 287,
          "title": "[Discussion] How does apple FaceID work?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": [
        {
          "id": "https://mlinproduction.com/?p=936",
          "author": "Luigi",
          "description": "In my previous post, I briefly described how leading companies use experimentation to optimize their products and services and evolve them to the point of feeling elegant, efficient, and magical. These companies have developed mature experimentation programs (ExPrs), including the… Read More \nThe post What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02) appeared first on ML in Production.",
          "link": "https://mlinproduction.com/experimentation-program-stakeholders/?utm_source=rss&utm_medium=rss&utm_campaign=experimentation-program-stakeholders",
          "publishedOn": "2022-04-02T14:03:58.000Z",
          "wordCount": 1691,
          "title": "What is an Experimentation program and Who is Involved? (Experimentation Program Series: Guide 02)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "62563d78e262cd003d13f40f",
          "author": "Janelle Shane",
          "description": "How would AI decorate an easter egg?\nI've tried this before by training an image-generating model exclusively on pictures of easter eggs I decorated (they came out plain, if a bit wobbly).\nI decided to see what I would get using a model based on CLIP, which has",
          "link": "https://www.aiweirdness.com/ai-generated-easter-eggs/",
          "publishedOn": "2022-04-14T13:54:58.000Z",
          "wordCount": 811,
          "title": "AI-generated easter eggs",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/04/ukranian-pysanky-easter-egg-collection--trending-on-artstation-variations3.png"
        },
        {
          "id": "625662e4e262cd003d13f4f4",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-what-does-the-x-ray-of-an-easter-egg-look-like/",
          "publishedOn": "2022-04-14T13:54:40.000Z",
          "wordCount": 434,
          "title": "Bonus: What does the x-ray of an Easter egg look like?",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/04/easter-eggs-decorated-by-children--trending-on-artstation.png"
        },
        {
          "id": "6243c01422e1bd003d3ef57f",
          "author": "Janelle Shane",
          "description": "I've tried various methods of using AI to generate April Fools pranks for you to play on other people (although often they turned out to be pranks you play on yourself). But this is the first time I've tried to generate pranks for a computer to",
          "link": "https://www.aiweirdness.com/ai-generated-pranks-for-your-computer-to-play/",
          "publishedOn": "2022-04-01T04:19:29.000Z",
          "wordCount": 1241,
          "title": "AI-generated pranks for your computer to play on you",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/03/pranked-desktop.png"
        },
        {
          "id": "624522d522e1bd003d3ef656",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-adas-pranks/",
          "publishedOn": "2022-04-01T04:19:08.000Z",
          "wordCount": 411,
          "title": "Bonus: Ada's pranks",
          "imageUrl": "https://www.aiweirdness.com/content/images/2022/03/Screen-Shot-2022-03-30-at-9.51.32-PM.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": [
        {
          "id": "http://bair.berkeley.edu/blog/2022/04/20/rvs/",
          "author": null,
          "description": "A demonstration of the RvS policy we learn with just supervised learning and a depth-two MLP. It uses no TD learning, advantage reweighting, or Transformers!\n\n\nOffline reinforcement learning (RL) is conventionally approached using value-based methods based on temporal difference (TD) learning. However, many recent algorithms reframe RL as a supervised learning problem. These algorithms learn conditional policies by conditioning on goal states (Lynch et al., 2019; Ghosh et al., 2021), reward-to-go (Kumar et al., 2019; Chen et al., 2021), or language descriptions of the task (Lynch and Sermanet, 2021).\nWe find the simplicity of these methods quite appealing. If supervised learning is enough to solve RL problems, then offline RL could become widely accessible and (relatively) easy to implemen…",
          "link": "http://bair.berkeley.edu/blog/2022/04/20/rvs/",
          "publishedOn": "2022-04-20T09:00:00.000Z",
          "wordCount": 1515,
          "title": "Offline RL Made Easier: No TD Learning, Advantage Reweighting, or Transformers",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/rvs/rvs-overview.png"
        }
      ]
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": [
        {
          "id": "https://medium.com/p/fc5449871adf",
          "author": "Shaibu Samuel",
          "description": "Artificial Intelligence is all over the world today. From the use of virtual assistants like Siri, Alexa, or Cortana, to improving…",
          "link": "https://becominghuman.ai/7-ways-your-business-can-plan-for-artificial-intelligence-fc5449871adf?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-22T13:44:21.000Z",
          "wordCount": 731,
          "title": "7 Ways Your Business Can Plan For Artificial Intelligence",
          "imageUrl": "https://miro.medium.com/max/1200/1*2qqjQQ0wW37Lbvkx50zPxg.jpeg"
        },
        {
          "id": "https://medium.com/p/35e386bfa4bc",
          "author": "Aminah Mardiyyah Rufai",
          "description": "Yes! You read the heading right. There’s indeed a difference between loss functions and Metrics in the field of Machine Learning. However…",
          "link": "https://becominghuman.ai/understanding-the-difference-between-loss-functions-and-metrics-in-machine-learning-deep-learning-35e386bfa4bc?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-21T16:22:10.000Z",
          "wordCount": 568,
          "title": "Understanding the Difference between Loss Functions and Metrics in Machine Learning/Deep Learning",
          "imageUrl": "https://miro.medium.com/freeze/max/1200/0*eP8gmy3zzHCgClK4.gif"
        },
        {
          "id": "https://medium.com/p/88215ec781b1",
          "author": "MobiDev",
          "description": "To start deeply investigating the AI app development process, it’s important to first understand how these projects differ from regular app…",
          "link": "https://becominghuman.ai/ai-application-development-guide-for-business-owners-88215ec781b1?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-20T15:30:52.000Z",
          "wordCount": 2817,
          "title": "AI Application Development Guide for Business Owners",
          "imageUrl": "https://miro.medium.com/max/1200/1*FP41xfegFJgv7RhOHf79iw.jpeg"
        },
        {
          "id": "https://medium.com/p/d3e8cac3e17c",
          "author": "Roger Brown",
          "description": "Shared duties have always been the most critical component of every successful organization, regardless of its nature or size. When it…",
          "link": "https://becominghuman.ai/a-quick-guide-to-find-the-right-minds-for-annotation-is-so-famous-but-why-d3e8cac3e17c?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-19T15:35:45.000Z",
          "wordCount": 1330,
          "title": "A Quick Guide To Find The Right Minds For Annotation Is So Famous, But Why?",
          "imageUrl": "https://miro.medium.com/max/848/1*vjtDRQF_ASaToXyPGTrwEA.png"
        },
        {
          "id": "https://medium.com/p/1d65735caee0",
          "author": "Lars Nielsen",
          "description": "7 use-cases where you can make your python code more nifty, concise and elegant — without compromising readability.\nContinue reading on Becoming Human: Artificial Intelligence Magazine »",
          "link": "https://becominghuman.ai/7-tips-for-making-your-code-more-pythonic-and-elegant-1d65735caee0?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-18T14:48:17.000Z",
          "wordCount": 1220,
          "title": "7 Tips for making your code more ‘pythonic’ and elegant",
          "imageUrl": "https://miro.medium.com/max/1200/1*JhUAwZvGQwxeR3qg3hdixw.jpeg"
        },
        {
          "id": "https://medium.com/p/9125822b6e65",
          "author": "Sasha Andrieiev",
          "description": "Here’s the truth.",
          "link": "https://becominghuman.ai/data-scientists-vs-bi-developer-whats-the-difference-9125822b6e65?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-15T13:40:54.000Z",
          "wordCount": 322,
          "title": "Data Scientists vs. BI Developer: What’s the Difference?",
          "imageUrl": "https://miro.medium.com/max/800/1*7FYfi-hfQULy3hVFeUyiRw.png"
        },
        {
          "id": "https://medium.com/p/3d6da629b102",
          "author": "Riccardo Castellani",
          "description": "An inside look at how REINFORCEMENT learning, without past reference, extracts “optimal” decisions through simple interaction …",
          "link": "https://becominghuman.ai/r-learning-ai-self-taking-over-processes-3d6da629b102?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-14T13:34:18.000Z",
          "wordCount": 2915,
          "title": "R-Learning AI self-taking over processes",
          "imageUrl": "https://miro.medium.com/max/1200/1*fIApuYxS28zOjIdeg7mDwQ.png"
        },
        {
          "id": "https://medium.com/p/68401b4b0f57",
          "author": "Robert Dale",
          "description": "In the past few years, high-quality automated text-to-speech synthesis has effectively become a commodity, with easy access to cloud-based…\nContinue reading on Becoming Human: Artificial Intelligence Magazine »",
          "link": "https://becominghuman.ai/the-voice-synthesis-business-2022-update-68401b4b0f57?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-13T14:27:46.000Z",
          "wordCount": 4613,
          "title": "The Voice Synthesis Business: 2022 Update",
          "imageUrl": "https://miro.medium.com/max/1200/0*a40Ik7RGkqFYxECQ"
        },
        {
          "id": "https://medium.com/p/fdb761737457",
          "author": "Tyger A.C",
          "description": "(A Sci-Fi Ultrashort)",
          "link": "https://becominghuman.ai/what-can-you-tell-us-about-him-fdb761737457?source=rss----5e5bef33608a---4",
          "publishedOn": "2022-04-12T16:07:15.000Z",
          "wordCount": 1589,
          "title": "What can you tell us about him?",
          "imageUrl": "https://miro.medium.com/max/1200/1*nxLxVw7n78_QHZhv9ITAsw.jpeg"
        }
      ]
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2022/new-unsupervised-computer-vision-algorithm-stego-0421",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "MIT CSAIL scientists created an algorithm to solve one of the hardest tasks in computer vision: assigning a label to every pixel in the world, without human supervision.",
          "link": "https://news.mit.edu/2022/new-unsupervised-computer-vision-algorithm-stego-0421",
          "publishedOn": "2022-04-21T16:20:00.000Z",
          "wordCount": 2091,
          "title": "A new state of the art for unsupervised vision",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-STEGO-2_0.png"
        },
        {
          "id": "https://news.mit.edu/2022/machine-learning-anticipating-behavior-cars-0421",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new machine-learning system may someday help driverless cars predict the next moves of nearby drivers, cyclists, and pedestrians in real-time.",
          "link": "https://news.mit.edu/2022/machine-learning-anticipating-behavior-cars-0421",
          "publishedOn": "2022-04-21T04:00:00.000Z",
          "wordCount": 1951,
          "title": "Anticipating others’ behavior on the road",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Driving-Prediction-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/ethical-machine-learning-course-0415",
          "author": "Adam Zewe | MIT News Office",
          "description": "A multidisciplinary team of graduate students helps infuse ethical computing content into MIT’s largest machine learning course.",
          "link": "https://news.mit.edu/2022/ethical-machine-learning-course-0415",
          "publishedOn": "2022-04-15T04:00:00.000Z",
          "wordCount": 2223,
          "title": "Learning to think critically about machine learning",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Ethical-Computing-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/three-mit-students-awarded-paul-daisy-soros-fellowships-new-americans-0414",
          "author": "Julia Mongo | Office of Distinguished Fellowships",
          "description": "Fellowship funds graduate studies for outstanding immigrants and children of immigrants.",
          "link": "https://news.mit.edu/2022/three-mit-students-awarded-paul-daisy-soros-fellowships-new-americans-0414",
          "publishedOn": "2022-04-14T19:30:00.000Z",
          "wordCount": 1784,
          "title": "Three from MIT awarded 2022 Paul and Daisy Soros Fellowships for New Americans",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/2022-MIT-PDSoros-Fellows.png"
        },
        {
          "id": "https://news.mit.edu/2022/mit-schwarzman-college-computing-unveils-break-through-tech-ai-0413",
          "author": "MIT Schwarzman College of Computing",
          "description": "New program strives to bridge the talent gap for underrepresented groups in the tech industry.",
          "link": "https://news.mit.edu/2022/mit-schwarzman-college-computing-unveils-break-through-tech-ai-0413",
          "publishedOn": "2022-04-13T17:45:00.000Z",
          "wordCount": 1434,
          "title": "MIT Schwarzman College of Computing unveils Break Through Tech AI",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/BreakThroughTechAI-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/ai-perovskite-solar-manufacturing-0413",
          "author": "David L. Chandler | MIT News Office",
          "description": "Perovskite materials would be superior to silicon in PV cells, but manufacturing such cells at scale is a huge hurdle. Machine learning can help.",
          "link": "https://news.mit.edu/2022/ai-perovskite-solar-manufacturing-0413",
          "publishedOn": "2022-04-13T15:00:00.000Z",
          "wordCount": 2112,
          "title": "Engineers enlist AI to help scale up advanced solar cell manufacturing",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Perovskite-Manufacturing-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/futuremakers-programs-kids-get-their-minds-around-and-hands-ai-0412",
          "author": "Kim Patch | MIT Media Lab",
          "description": "The programs are designed to foster an understanding of how artificial intelligence technologies work, including their social implications.",
          "link": "https://news.mit.edu/2022/futuremakers-programs-kids-get-their-minds-around-and-hands-ai-0412",
          "publishedOn": "2022-04-12T15:00:00.000Z",
          "wordCount": 2281,
          "title": "MIT’s FutureMakers programs help kids get their minds around — and hands on — AI",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/futuremakers.png"
        },
        {
          "id": "https://news.mit.edu/2022/optimized-solution-face-recognition-0406",
          "author": "Jennifer Michalowski | McGovern Institute for Brain Research",
          "description": "When artificial intelligence is tasked with visually identifying objects and faces, it assigns specific components of its network to face recognition — just like the human brain.",
          "link": "https://news.mit.edu/2022/optimized-solution-face-recognition-0406",
          "publishedOn": "2022-04-06T15:25:00.000Z",
          "wordCount": 1511,
          "title": "An optimized solution for face recognition",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/face-recognition.png"
        },
        {
          "id": "https://news.mit.edu/2022/does-this-artificial-intelligence-think-human-0406",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new technique compares the reasoning of a machine-learning model to that of a human, so the user can see patterns in the model’s behavior.",
          "link": "https://news.mit.edu/2022/does-this-artificial-intelligence-think-human-0406",
          "publishedOn": "2022-04-06T04:00:00.000Z",
          "wordCount": 2034,
          "title": "Does this artificial intelligence think like a human?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Shared-Interest-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/robots-dress-humans-without-full-picture-0405",
          "author": "Steve Nadis | MIT CSAIL",
          "description": "MIT researchers design a robot that has a trick or two up its sleeve.",
          "link": "https://news.mit.edu/2022/robots-dress-humans-without-full-picture-0405",
          "publishedOn": "2022-04-05T18:20:00.000Z",
          "wordCount": 1850,
          "title": "Robots dress humans without the full picture",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/robot-dressing-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/school-engineering-welcomes-thomas-tull-visiting-innovation-scholar-0404",
          "author": "Lori LoTurco | School of Engineering",
          "description": "Primary focus will be to advance and promote technology, innovation, and entrepreneurship across the school.",
          "link": "https://news.mit.edu/2022/school-engineering-welcomes-thomas-tull-visiting-innovation-scholar-0404",
          "publishedOn": "2022-04-04T19:40:00.000Z",
          "wordCount": 1252,
          "title": "School of Engineering welcomes Thomas Tull as visiting innovation scholar",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/thomas-tull-mit-00.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/huttenlocher-age-of-ai-0403",
          "author": "Adam Zewe | MIT News Office",
          "description": "For the MIT Schwarzman College of Computing dean, bringing disciplines together is the best way to address challenges and opportunities posed by rapid advancements in computing.",
          "link": "https://news.mit.edu/2022/huttenlocher-age-of-ai-0403",
          "publishedOn": "2022-04-03T04:00:00.000Z",
          "wordCount": 2333,
          "title": "Dan Huttenlocher ponders our human future in an age of artificial intelligence",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202204/MIT-Dan-Huttenlocher-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/generating-new-molecules-with-graph-grammar-0401",
          "author": "Lauren Hinkel | MIT-IBM Watson AI Lab",
          "description": "An efficient machine-learning method uses chemical knowledge to create a learnable grammar with production rules to build synthesizable monomers and polymers.",
          "link": "https://news.mit.edu/2022/generating-new-molecules-with-graph-grammar-0401",
          "publishedOn": "2022-04-01T18:30:00.000Z",
          "wordCount": 1686,
          "title": "Generating new molecules with graph grammar",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/chemical-science-medical-substance-and-molecules.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/featured-video-mit-president-l-rafael-reif-power-of-education-0331",
          "author": "Melanie Grados, MIT News Office",
          "description": "At Monterrey Tec, MIT’s president discusses the impact of education in addressing global issues.",
          "link": "https://news.mit.edu/2022/featured-video-mit-president-l-rafael-reif-power-of-education-0331",
          "publishedOn": "2022-03-31T20:25:00.000Z",
          "wordCount": 943,
          "title": "Featured video: L. Rafael Reif on the power of education",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/l-rafael-reif-monterrey-tec-00.png"
        },
        {
          "id": "https://news.mit.edu/2022/robotic-deformable-object-0331",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new technique could enable a robot to manipulate squishy objects like pizza dough or soft materials like clothing.",
          "link": "https://news.mit.edu/2022/robotic-deformable-object-0331",
          "publishedOn": "2022-03-31T04:00:00.000Z",
          "wordCount": 1973,
          "title": "Solving the challenges of robotic pizza-making",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/MIT-DiffSkill-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/qa-alberto-rodriguez-teaching-robot-find-your-keys-pile-clutter-0329",
          "author": "Kim Martineau | MIT Schwarzman College of Computing",
          "description": "Associate professor and principal investigator with the MIT Schwarzman College of Computing’s Science Hub discusses the future of robotics and the importance of industry-academia collaborations.",
          "link": "https://news.mit.edu/2022/qa-alberto-rodriguez-teaching-robot-find-your-keys-pile-clutter-0329",
          "publishedOn": "2022-03-29T15:00:00.000Z",
          "wordCount": 1644,
          "title": "Q&A: Alberto Rodriguez on teaching a robot to find your keys",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/Sangwoon-Alberto-MCube-cover.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/new-program-bolsters-innovation-next-generation-artificial-intelligence-hardware-0329",
          "author": "School of Engineering | MIT Schwarzman College of Computing",
          "description": "MIT AI Hardware Program launches with five inaugural companies to advance AI technologies for the next decade.",
          "link": "https://news.mit.edu/2022/new-program-bolsters-innovation-next-generation-artificial-intelligence-hardware-0329",
          "publishedOn": "2022-03-29T13:00:00.000Z",
          "wordCount": 1434,
          "title": "New program bolsters innovation in next-generation artificial intelligence hardware",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/glowing-microchip.jpg"
        },
        {
          "id": "https://news.mit.edu/2022/privid-security-tool-guarantees-privacy-surveillance-footage-0328",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "“Privid” could help officials gather secure public health data or enable transportation departments to monitor the density and flow of pedestrians, without learning personal information about people.",
          "link": "https://news.mit.edu/2022/privid-security-tool-guarantees-privacy-surveillance-footage-0328",
          "publishedOn": "2022-03-28T15:30:00.000Z",
          "wordCount": 1929,
          "title": "Security tool guarantees privacy in surveillance footage",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202203/privid-cover.jpg"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=56696",
          "author": "Isha Salian",
          "description": "Different parts of the globe are experiencing distinct climate challenges — severe drought, dangerous flooding, reduced biodiversity or dense air pollution. The challenges are so great that no country can solve them on their own. But innovative startups worldwide are lighting the way, demonstrating how these daunting challenges can be better understood and addressed with Read article >\nThe post By Land, Sea and Space: How 5 Startups Are Using AI to Help Save the Planet appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/22/earth-day-5-inception-ai-startups/",
          "publishedOn": "2022-04-22T13:00:59.000Z",
          "wordCount": 964,
          "title": "By Land, Sea and Space: How 5 Startups Are Using AI to Help Save the Planet",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/earth-day.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56679",
          "author": "Scott Martin",
          "description": "Your next trip to the dentist might offer a taste of AI. Pearl, a West Hollywood startup, provides AI for dental images to assist in diagnosis. It landed FDA clearance last month, the first to get such a go-ahead for dentistry AI. The approval paves the way for its use in clinics across the United Read article >\nThe post Tooth Tech: AI Takes Bite Out of Dental Slide Misses by Assisting Doctors appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/21/tooth-tech-ai-takes-bite-out-of-dental-slide-misses-by-assisting-doctors/",
          "publishedOn": "2022-04-21T15:28:08.000Z",
          "wordCount": 1154,
          "title": "Tooth Tech: AI Takes Bite Out of Dental Slide Misses by Assisting Doctors",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/PearlBounding-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56671",
          "author": "GeForce NOW Community",
          "description": "The gods must be smiling this GFN Thursday — God of War today joins the GeForce NOW library. Sony Interactive Entertainment and Santa Monica Studios’ masterpiece is available to stream from GeForce NOW servers, across nearly all devices and at up to 1440p and 120 frames per second for RTX 3080 members. Get ready to Read article >\nThe post GFN Thursday Is Fit for the Gods: ‘God of War’ Arrives on GeForce NOW appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/21/geforce-now-thursday-april-21/",
          "publishedOn": "2022-04-21T13:00:54.000Z",
          "wordCount": 859,
          "title": "GFN Thursday Is Fit for the Gods: ‘God of War’ Arrives on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-thursday-4-21-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56607",
          "author": "Stanley Tack",
          "description": "Creating content is no longer tethered to using paint and stone as mediums, nor being in massive studios. Visual art can now be created anywhere, anytime. But being creative is still challenging and time-consuming. NVIDIA is making artistic workflows easier and faster by giving creators tools that enable them to remain in their flow state. Read article >\nThe post Welcome ‘In the NVIDIA Studio’: A Weekly Celebration of Extraordinary Artists, Their Inspiring Art and Innovative Techniques appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/19/in-the-nvidia-studio/",
          "publishedOn": "2022-04-19T13:00:17.000Z",
          "wordCount": 1147,
          "title": "Welcome ‘In the NVIDIA Studio’: A Weekly Celebration of Extraordinary Artists, Their Inspiring Art and Innovative Techniques",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2022/04/studio-ins-jasmin-habezai-fekri-full-landscape-loop.mp4",
            "length": "3978924",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/studio-ins-jasmin-habezai-fekri-bird-house-blog-hero-04192022.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56600",
          "author": "Scott Martin",
          "description": "Gil Makleff and Artem Koren are developing AI for meeting transcripts, creating time-savers like shareable highlights of the text that is often TL;DR (too long; didn’t read). The Sembly founders conceived the idea after years of working in enterprise operational consulting at UMT Consulting Group, which was acquired by Ernst & Young. “We had an Read article >\nThe post Startup Transforms Meeting Notes With Time-Saving Features appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/15/sembly-transforms-meeting-notes-with-time-saving-features/",
          "publishedOn": "2022-04-15T16:15:18.000Z",
          "wordCount": 904,
          "title": "Startup Transforms Meeting Notes With Time-Saving Features",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/Sembly.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56528",
          "author": "Brian Caulfield",
          "description": "Talk about a bright idea. A team of scientists has used GPU-accelerated deep learning to show how color can be brought to night-vision systems.  In a paper published this week in the journal PLOS One, a team of researchers at the University of California, Irvine led by Professor Pierre Baldi and Dr. Andrew Browne, describes how Read article >\nThe post A Night to Behold: Researchers Use Deep Learning to Bring Color to Night Vision appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/15/color-night-vision/",
          "publishedOn": "2022-04-15T13:00:03.000Z",
          "wordCount": 776,
          "title": "A Night to Behold: Researchers Use Deep Learning to Bring Color to Night Vision",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/see-in-the-dark-deep-learning.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56571",
          "author": "GeForce NOW Community",
          "description": "This GFN Thursday delivers more gr-EA-t games as two new titles from Electronic Arts join the GeForce NOW library. Gamers can now enjoy Need for Speed HEAT  and Plants vs. Zombies Garden Warfare 2 streaming from GeForce NOW to underpowered PCs, Macs, Chromebooks, SHIELD TV and mobile devices. It’s all part of the eight  total Read article >\nThe post GFN Thursday Gears Up With More Electronic Arts Games on GeForce NOW appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/14/geforce-now-thursday-april-14/",
          "publishedOn": "2022-04-14T13:00:55.000Z",
          "wordCount": 802,
          "title": "GFN Thursday Gears Up With More Electronic Arts Games on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-thursday-4-14-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56527",
          "author": "Clarissa Eyu",
          "description": "In deep learning and machine learning, having a large enough dataset is key to training a system and getting it to produce results. So what does a ML researcher do when there just isn’t enough publicly accessible data? Enter the MLCommons Association, a global engineering consortium with the aim of making ML better for everyone. Read article >\nThe post MLCommons’ David Kanter, NVIDIA’s Daniel Galvez on Improving AI with Publicly Accessible Datasets appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/13/mlcommons/",
          "publishedOn": "2022-04-13T13:00:56.000Z",
          "wordCount": 696,
          "title": "MLCommons’ David Kanter, NVIDIA’s Daniel Galvez on Improving AI with Publicly Accessible Datasets",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/mlcommons-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56521",
          "author": "Isha Salian",
          "description": "A team of scientists have created a new AI-based tool to help lock up greenhouse gases like CO2 in porous rock formations faster and more precisely than ever before. Carbon capture technology, also referred to as carbon sequestration, is a climate change mitigation method that redirects CO2 emitted from power plants back underground. While doing Read article >\nThe post Rock On: Scientists Use AI to Improve Sequestering Carbon Underground appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/08/ai-improves-carbon-sequestration/",
          "publishedOn": "2022-04-08T17:36:44.000Z",
          "wordCount": 1149,
          "title": "Rock On: Scientists Use AI to Improve Sequestering Carbon Underground",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/I-am-ai-corp-blog-april-2022-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56490",
          "author": "GeForce NOW Community",
          "description": "GeForce NOW is about bringing new experiences to gamers. This GFN Thursday introduces game demos to GeForce NOW. Members can now try out some of the hit games streaming on the service before purchasing the full PC version — including some finalists from the 2021 Epic MegaJam. Plus, look for six games ready to stream Read article >\nThe post Try This Out: GFN Thursday Delivers Instant-Play Game Demos on GeForce NOW appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/07/geforce-now-thursday-april-7/",
          "publishedOn": "2022-04-07T13:00:01.000Z",
          "wordCount": 793,
          "title": "Try This Out: GFN Thursday Delivers Instant-Play Game Demos on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/gfn-4-7-thursday-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56511",
          "author": "Jurgen Ferchau",
          "description": "Meet the electric vehicle that’s quick-witted and fully outfitted. Last week, NIO began deliveries of its highly anticipated ET7 fully electric vehicle, in Hefei, China. The full-size luxury sedan is the first production vehicle built on the NIO Adam supercomputer, powered by four NVIDIA DRIVE Orin systems-on-a-chip (SoCs). The production launch of its flagship sedan Read article >\nThe post Fast and Luxurious: The Intelligent NIO ET7 EV Built on NVIDIA DRIVE Orin Arrives appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/06/nio-et7-drive-orin-arrives/",
          "publishedOn": "2022-04-06T19:41:03.000Z",
          "wordCount": 709,
          "title": "Fast and Luxurious: The Intelligent NIO ET7 EV Built on NVIDIA DRIVE Orin Arrives",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/ET7.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56403",
          "author": "Dave Salvator",
          "description": "In its debut in the industry MLPerf benchmarks, NVIDIA Orin, a low-power system-on-chip based on the NVIDIA Ampere architecture, set new records in AI inference, raising the bar in per-accelerator performance at the edge. Overall, NVIDIA with its partners continued to show the highest performance and broadest ecosystem for running all machine-learning workloads and scenarios Read article >\nThe post NVIDIA Orin Leaps Ahead in Edge AI, Boosting Leadership in MLPerf Tests appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/06/mlperf-edge-ai-inference-orin/",
          "publishedOn": "2022-04-06T17:00:38.000Z",
          "wordCount": 1005,
          "title": "NVIDIA Orin Leaps Ahead in Edge AI, Boosting Leadership in MLPerf Tests",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/Orin-dev-kit-and-module-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56436",
          "author": "Ethan Einhorn",
          "description": "Square/Enix presents the fictional city of Midgar in Final Fantasy VII Remake at a filmic level of detail. Epic’s Fortnite bathes its environments in ray-traced sunlight, simulating how light bounces in the real world. And artists at Lucasfilm revolutionized virtual production techniques in The Mandalorian, using synchronized NVIDIA RTX GPUs to drive pixels on LED Read article >\nThe post Unreal Engine and NVIDIA: From One Generation to the Next appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/05/unreal-engine-5/",
          "publishedOn": "2022-04-05T15:10:12.000Z",
          "wordCount": 1151,
          "title": "Unreal Engine and NVIDIA: From One Generation to the Next",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/unreal-engine-5-jungle.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56434",
          "author": "Craig Weinstein",
          "description": "A dozen companies today received NVIDIA’s highest award for partners, recognizing their impact on AI education and adoption across such industries as education, federal, healthcare and technology. The winners of the 2021 NPN Americas Partner of the Year Awards have created a profound impact on AI by helping customers meet the demands of recommender systems, Read article >\nThe post Green Teams Achieve the Dream: NVIDIA Announces NPN Americas Partners of the Year appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/05/americas-npn-award-winners-2021/",
          "publishedOn": "2022-04-05T15:00:15.000Z",
          "wordCount": 1063,
          "title": "Green Teams Achieve the Dream: NVIDIA Announces NPN Americas Partners of the Year",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/npn-awards-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56447",
          "author": "Angie Lee",
          "description": "Pekka Varis’s artistry has come a long way from his early days as a self-styled “punk activist” who spray painted during the “old school days of hip hop in Finland.”\nThe post Meet the Omnivore: Videographer Makes Digital Walls, Virtual Homes Pop With NVIDIA Omniverse appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/04/04/pekka-varis-omniverse-creator/",
          "publishedOn": "2022-04-04T15:00:58.000Z",
          "wordCount": 959,
          "title": "Meet the Omnivore: Videographer Makes Digital Walls, Virtual Homes Pop With NVIDIA Omniverse",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/04/pekka-varis-still.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56412",
          "author": "GeForce NOW Community",
          "description": "In addition to GFN Thursday, it’s National Tater Day. Hooray! To honor the spud-tacular holiday, we’re closing out March with seven new games streaming this week. And a loaded 20+ titles are coming to the GeForce NOW library in April to play — even on a potato PC, thanks to GeForce NOW. Plus, the GeForce Read article >\nThe post An A-peel-ing GFN Thursday Sprouts 20+ New Games Coming to GeForce NOW in April appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/31/geforce-now-thursday-march-31/",
          "publishedOn": "2022-03-31T13:00:06.000Z",
          "wordCount": 836,
          "title": "An A-peel-ing GFN Thursday Sprouts 20+ New Games Coming to GeForce NOW in April",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/gfn-thursday-3-31-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56405",
          "author": "Jurgen Ferchau",
          "description": "Four words: smart, sustainable, Super Bowl. Polestar’s commercial during the big game made it clear no-compromise electric vehicles are now mainstream. Polestar Chief Operating Officer Dennis Nobelius sees driving enjoyment and autonomous-driving capabilities complementing one another in sustainable vehicles that keep driving — and the driver — front and center. NVIDIA’s Katie Washabaugh spoke with Read article >\nThe post Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/30/polestar/",
          "publishedOn": "2022-03-30T13:00:49.000Z",
          "wordCount": 634,
          "title": "Polestar’s Dennis Nobelius on the Sustainable Performance Brand’s Plans",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/504426_20210211_Polestar_1_2021_003-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56394",
          "author": "Angie Lee",
          "description": "“I am a visionary,” says an AI, kicking off the latest installment of NVIDIA’s I AM AI video series. Launched in 2017, I AM AI has become the iconic opening for GTC keynote addresses by NVIDIA founder and CEO Jensen Huang. Each video, with its AI-created narration and soundtrack, documents the newest advances in artificial Read article >\nThe post Latest ‘I AM AI’ Video Features Four-Legged Robots, Smart Cell Analysis, Tumor-Tracking Tech and More appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/29/i-am-ai-gtc/",
          "publishedOn": "2022-03-29T17:00:26.000Z",
          "wordCount": 950,
          "title": "Latest ‘I AM AI’ Video Features Four-Legged Robots, Smart Cell Analysis, Tumor-Tracking Tech and More",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/iamai_social-spring-manifesto-1280x680-1.jpeg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=56389",
          "author": "Scott Martin",
          "description": "When Tanish Tyagi published his first research paper a year ago on deep learning to detect dementia, it started a family-driven pursuit. Great-grandparents in his family had suffered from Parkinson’s, a genetic disease that affects more than 10 million people worldwide. So the now 16-year-old turned to that next, together with his sister, Riya, 14. Read article >\nThe post Teens Develop Handwriting-Recognition AI for Detecting Parkinson’s Disease appeared first on NVIDIA Blog.",
          "link": "https://blogs.nvidia.com/blog/2022/03/29/handwriting-recognition-ai-parkinsons-disease/",
          "publishedOn": "2022-03-29T16:00:56.000Z",
          "wordCount": 937,
          "title": "Teens Develop Handwriting-Recognition AI for Detecting Parkinson’s Disease",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/03/Parkinsons-672x378.png"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de",
      "articles": []
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/ub4ox7/india_and_us_have_decided_to_advance_cooperation/",
          "author": null,
          "description": "submitted by    /u/dannylenwinn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ub4ox7/india_and_us_have_decided_to_advance_cooperation/",
          "publishedOn": "2022-04-24T21:22:55.000Z",
          "wordCount": 171,
          "title": "India and US have decided to advance cooperation in emerging technologies in the fields of communication, artificial intelligence",
          "imageUrl": "https://external-preview.redd.it/uAeiGd9PP8g7nvk5lSbr-guLowcOCDLcdcG15RUeUUw.jpg?auto=webp&s=92181ef05fc9fdda2be2d7747cbb0c62c70ce34c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ub3g7e/research_on_ai/",
          "author": null,
          "description": "Dear all, \n Currently I am writing my thesis on the effects of Artificial Intelligence (AI) on employee performance through employee engagement.\n If you work in a company that uses AI and you:\n - have a direct relationship (e.g. data scientist) or indirect relationship (e.g. business manager) with AI\n - often or sometimes use AI in your daily work\n then your insights are essential for my master thesis research and I would really appreciate it if you would fill out the survey below (5-10 min / English & Dutch translation).\n https://uva.fra1.qualtrics.com/jfe/form/SV_4TTnzJE4IQUoHWK\n Please feel free to spread the survey to as many relevant people you may know.\n Much appreciated!!\n Britt\n    submitted by    /u/BrittHermans  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ub3g7e/research_on_ai/",
          "publishedOn": "2022-04-24T20:24:16.000Z",
          "wordCount": 185,
          "title": "Research on AI!",
          "imageUrl": "https://external-preview.redd.it/zYnmjHSHmoQLheG3uz1CyfsZkBc-O9cP947EJ_ns0ds.jpg?auto=webp&s=4ce276edca9a40b8deede609b15d249cd3659523"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ub0rhz/ai_dream_44_epic_cathedral_supernatural_visit/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ub0rhz/ai_dream_44_epic_cathedral_supernatural_visit/",
          "publishedOn": "2022-04-24T18:17:45.000Z",
          "wordCount": 106,
          "title": "AI Dream 44 - Epic Cathedral Supernatural Visit",
          "imageUrl": "https://external-preview.redd.it/Ha2aXw3RaC2pH_BZBkqX8wNSqv3PQFHxmVL85jA8H7Y.jpg?auto=webp&s=6d69870d09896f3ed49d70c05907463dae8d8db6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uazlty/in_the_deep/",
          "author": null,
          "description": "submitted by    /u/Hacknaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uazlty/in_the_deep/",
          "publishedOn": "2022-04-24T17:23:29.000Z",
          "wordCount": 88,
          "title": "In the deep",
          "imageUrl": "https://preview.redd.it/bwfifpavgiv81.jpg?auto=webp&s=b4421405bb1f4f452d14b31f5ec1c9ae48a7971b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uavfzd/nota_ai_introduces_new_machine_learning_tools/",
          "author": null,
          "description": "​\n https://preview.redd.it/beo6czc6hhv81.png?width=1706&format=png&auto=webp&s=385f65ebfed9344781d1f9238d8d508dae27c0a3\n In the last decade, AI research has brought astonishing results in many fields, and, undoubtedly, AI is nowadays a central technology in many aspects of our life. As new ideas are proposed every day, this continuous research usually comes with infinite applications: from the algorithms assisting surgeons in complex operations to the one which allows unlocking our phone using just our face. In this evolution from the idea to the actual implementation, it is often ignored how hard the passage between theoretical research and working application is.\n We can refer to this process as AI Development Cycle for Edge AI and can be divided into three phases related to 1) data, 2) model, and 3) evaluation.\n Many aspects must be considered: first, each different AI application requires a specific dataset. For this reason, in this step, the aim is to prepare the data, which, as is well known, is one of the crucial topics of AI: a good algorithm always relies on a good dataset. This phase can be divided into data collection, curation, labeling, and preparation. \n Continue reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uavfzd/nota_ai_introduces_new_machine_learning_tools/",
          "publishedOn": "2022-04-24T14:03:20.000Z",
          "wordCount": 324,
          "title": "Nota AI Introduces New Machine Learning Tools Under Its NetsPresso Platform For Automatically Searching Optimized Models And Making Compression Process Easy And Fast",
          "imageUrl": "https://external-preview.redd.it/Gxl1BzzbMn-8pBr9ef83GCerUASCrtl82642cRDUDVU.jpg?auto=webp&s=d0d08c2c329dbc12f2cb217ba824f8cd0c26fb63"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uaqkjk/d_mindspore_ai_scientific_computing_series_15/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uaqkjk/d_mindspore_ai_scientific_computing_series_15/",
          "publishedOn": "2022-04-24T08:55:38.000Z",
          "wordCount": 127,
          "title": "[D] MindSpore AI Scientific Computing Series (15): Protein Function Prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uamma2/training_an_ai_hitman_to_find_waldo/",
          "author": null,
          "description": "submitted by    /u/TernaryJimbo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uamma2/training_an_ai_hitman_to_find_waldo/",
          "publishedOn": "2022-04-24T04:21:07.000Z",
          "wordCount": 100,
          "title": "Training an AI Hitman To Find Waldo",
          "imageUrl": "https://external-preview.redd.it/MvCtGs0pDjhaI1nm4RKqVsiwFD7OQYa6elmhLluRqw4.jpg?auto=webp&s=da6095d99ca248ebd5b2e3ebe33dfc199b361693"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uam3rg/kanye_wes_t_thro_the_wire/",
          "author": null,
          "description": "​\n https://preview.redd.it/qaqevbqlfev81.png?width=1024&format=png&auto=webp&s=8c2759d29a3713c2ffb998e20e8995cee4d8b2b4\n    submitted by    /u/Smek_dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uam3rg/kanye_wes_t_thro_the_wire/",
          "publishedOn": "2022-04-24T03:49:23.000Z",
          "wordCount": 95,
          "title": "Kanye wes t thro the wire",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uafe15/mgpt_fewshot_learners_go_multilingual/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uafe15/mgpt_fewshot_learners_go_multilingual/",
          "publishedOn": "2022-04-23T21:33:30.000Z",
          "wordCount": 90,
          "title": "mGPT: Few-Shot Learners Go Multilingual",
          "imageUrl": "https://preview.redd.it/zg58oxnjkcv81.jpg?auto=webp&s=628c4afb4ef72022131e1f6fc4397f34d7f4d5b5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uabkpm/biological_feedback_will_save_us_all/",
          "author": null,
          "description": "Dall-E-2. Excellent. It's very high quality. But it's a combination of the data.\n ​\n What did we want?\n We wanted some amazing work that made us cry with just one line of writing or one image.\n ​\n \"Oh, copied it well. It's pretty much the same.\" \n It's not enough. But how can that be improve? \n I think the answer is the feedback method.\n ​\n ​\n The current evaluation method of writing, image, video, and sound is too indirect.\n ​\n Sales revenue\n Number of Subscribers\n Number of views\n Like / Dislike\n Ratings by section, Revisit Rate <<< Those are better than others\n Emotion analysis of Comments using AI\n Internal staff scores\n ​\n There are so many conditions other than the quality of contents that people's judgment can intervene in.\n In the first place, people don't express exactly what they…",
          "link": "https://www.reddit.com/r/artificial/comments/uabkpm/biological_feedback_will_save_us_all/",
          "publishedOn": "2022-04-23T18:24:28.000Z",
          "wordCount": 839,
          "title": "Biological feedback will save us all",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/uaax43/16_images_generated_for_text_prompt_woah_there/",
          "author": null,
          "description": "submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/uaax43/16_images_generated_for_text_prompt_woah_there/",
          "publishedOn": "2022-04-23T17:53:15.000Z",
          "wordCount": 178,
          "title": "16 images generated for text prompt \"Woah there, Dragonman!\" using a text-to-image AI model from CompVis that uses latent diffusion (crosspost of another user's post)",
          "imageUrl": "https://preview.redd.it/qajqlsulujr81.png?auto=webp&s=1badce7af248057d90c0f5586d5c4b609370e73b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua97iy/nvidia_instant_nerf_turn_photos_into_3d_scenes_in/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua97iy/nvidia_instant_nerf_turn_photos_into_3d_scenes_in/",
          "publishedOn": "2022-04-23T16:30:44.000Z",
          "wordCount": 161,
          "title": "NVIDIA Instant NeRF: Turn Photos into 3D Scenes in Milliseconds ! Video demo",
          "imageUrl": "https://external-preview.redd.it/S2B09FxAWorWa23naYAaOvUAFMXYp4KXv9yJcPG9NS4.jpg?auto=webp&s=67c4bd30d11fd161a85861ed7dcebc9bad975d2e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua867s/google_researchers_create_animated_avatars_from_a/",
          "author": null,
          "description": "submitted by    /u/SpatialComputing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua867s/google_researchers_create_animated_avatars_from_a/",
          "publishedOn": "2022-04-23T15:42:30.000Z",
          "wordCount": 386,
          "title": "GOOGLE researchers create animated avatars from a single photo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua7020/mits_new_machinelearning_system_m2i_may_someday/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua7020/mits_new_machinelearning_system_m2i_may_someday/",
          "publishedOn": "2022-04-23T14:46:29.000Z",
          "wordCount": 125,
          "title": "MIT's new machine-learning system M2I may someday help driverless cars predict the next moves of others",
          "imageUrl": "https://external-preview.redd.it/s8zHGGPMD1gbSZdFb5lLmwkHZ03oeUFmAcEH86Y7AHk.jpg?auto=webp&s=a54cee5957c83964d4bab9ad468e710d5d63d466"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua4xvn/artificial_nightmares_split_personality_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua4xvn/artificial_nightmares_split_personality_clip/",
          "publishedOn": "2022-04-23T13:00:53.000Z",
          "wordCount": 124,
          "title": "Artificial Nightmares: Split Personality || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/hlTDFwwRZ4wn0GUBX2uENYwTAqKodl4hmtQPIaGe2po.jpg?auto=webp&s=3043229ca7283c792e2b66610eefb4e47164b3b3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua4a8m/human_like_ai_where_should_i_start/",
          "author": null,
          "description": "Hello there,\n if one would want to get into AI and especially human like AI, would you still recommend getting into machine learning first? As far as i know machine learning doesnt even try to develop \"human like\" AI/\"bottom up AI\", but rather focuses on training algorythms to solve specific problems.\n I know human like AI is something thats highly complex and we still need years if not even decades to achieve something even close to it but i would appreciate tips and ideas nonetheless.\n (after reading through my question again this sounds like a generic question thats being asked here everyday, if thats the case please send me a link to a similar post if there is one :) )\n    submitted by    /u/Garic152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua4a8m/human_like_ai_where_should_i_start/",
          "publishedOn": "2022-04-23T12:23:13.000Z",
          "wordCount": 225,
          "title": "Human Like AI where should i start",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ua37up/help_with_a_project_idea/",
          "author": null,
          "description": "Hi everyone Im doing a project with my friends where we should use computer vision/iot to create a solution for people with disabilities or in the healthcare system Any ideas please\n    submitted by    /u/armyy__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ua37up/help_with_a_project_idea/",
          "publishedOn": "2022-04-23T11:19:15.000Z",
          "wordCount": 122,
          "title": "help with a project idea",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9xy01/meta_ai_researchers_built_an_endtoend_machine/",
          "author": null,
          "description": "From improving the user experience to making the computational infrastructure more effective, AI is a crucial aspect of making current software systems and products perform as well as possible. AI is often more effective than even precisely developed human-crafted heuristic tactics today, whether it’s reducing latency, boosting the quality of a video stream, or streamlining the interfaces to match a specific person’s demands. But, to use AI more effectively in various products, several challenges must be addressed: the system must accommodate software engineers without machine learning backgrounds; it must provide mechanisms to optimize for a variety of product goals, which may differ from closed-form machine learning loss functions; it must distinguish causal connections from data correlations; and it must scale efficiently to train, host, and monitor vast numbers of AI models. \n Meta Researchers Develop ‘Looper,’ an end-to-end AI platform that has been designed with easy-to-use APIs for optimization, personalization, and feedback collecting to answer these needs. Looper may be used to support the entire machine learning lifecycle, from model training to deployment and inference to product evaluation and optimization. Looper allows us to modify the existing products to leverage AI for personalized optimizations rather than having to rebuild them around AI models. Currently, the Looper platform hosts 700 AI models and produces 4 million AI outputs every second.\n Continue reading\n Paper: https://arxiv.org/pdf/2110.07554.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9xy01/meta_ai_researchers_built_an_endtoend_machine/",
          "publishedOn": "2022-04-23T05:09:09.000Z",
          "wordCount": 353,
          "title": "Meta AI Researchers Built An End-To-End Machine Learning Platform Called Looper, With Easy-To-Use APIs For Decision-Making And Feedback Collection",
          "imageUrl": "https://external-preview.redd.it/ZZKEjeoMAp8NTUJf4bZ2RvDXu-v0WYg_oJIHJ9jkov4.jpg?auto=webp&s=bb551fac42bb712fdc1f775094a84c9c3a0f39ff"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9va4b/are_there_any_programs_that_can_output_a_sentence/",
          "author": null,
          "description": "I'm looking to create a way to automate original story ideas based on previous ideas.\n I want to be able to input 1000+ original sentences and have an output of an original sentence that is inspired the previous ones.\n Are there any programs that can do this or will I need to develop my own?\n    submitted by    /u/yea_okay_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9va4b/are_there_any_programs_that_can_output_a_sentence/",
          "publishedOn": "2022-04-23T02:34:44.000Z",
          "wordCount": 204,
          "title": "Are there any programs that can output a sentence based on input sentences?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9tyi7/ultimate_guide_to_activation_functions/",
          "author": null,
          "description": "submitted by    /u/SirFletch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9tyi7/ultimate_guide_to_activation_functions/",
          "publishedOn": "2022-04-23T01:23:34.000Z",
          "wordCount": 97,
          "title": "Ultimate Guide to Activation Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9pzar/an_ai_painting_some_colorful_pitbulls/",
          "author": null,
          "description": "submitted by    /u/p0goniphaft111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9pzar/an_ai_painting_some_colorful_pitbulls/",
          "publishedOn": "2022-04-22T22:02:25.000Z",
          "wordCount": 111,
          "title": "An AI painting some colorful pitbulls",
          "imageUrl": "https://external-preview.redd.it/r4IqnFJPAf59RvK29qYAsN5sK7NJdMzHppDLuZbjVfs.png?format=pjpg&auto=webp&s=02d4b0428bc2110c636479bcd21372fde4061cce"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9ki4t/building_a_pictionary_app_sketch_recognition/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9ki4t/building_a_pictionary_app_sketch_recognition/",
          "publishedOn": "2022-04-22T17:52:22.000Z",
          "wordCount": 120,
          "title": "Building A Pictionary App (sketch recognition model) with Gradio",
          "imageUrl": "https://preview.redd.it/j3tp4hs7c4v81.jpg?auto=webp&s=6bdf2b5d7230deb25f923b56df22849563d61299"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9im1g/is_there_a_ai_which_i_can_use_to_edit/",
          "author": null,
          "description": "Like I mark some areas of my pictures and then selcect what should happend with them?\n    submitted by    /u/xXLisa28Xx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9im1g/is_there_a_ai_which_i_can_use_to_edit/",
          "publishedOn": "2022-04-22T16:26:45.000Z",
          "wordCount": 131,
          "title": "Is there a AI which I can use to edit images(selfies etc.)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9hsxn/what_ai_can_i_use_to_make_caricatures_from/",
          "author": null,
          "description": "Is artbreeder the best way to do it, or is there a better way?\n    submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9hsxn/what_ai_can_i_use_to_make_caricatures_from/",
          "publishedOn": "2022-04-22T15:51:04.000Z",
          "wordCount": 200,
          "title": "What AI can I use to make caricatures from pictures from people?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u9bp01/learning_or_working_with_ai_come_join_us_we_are_a/",
          "author": null,
          "description": "Programming is way more fun when you learn/work with someone. Help each other, ask questions, brainstorm, etc. There is just so much benefit to joining a community when you are in this field, especially when you cannot find the question you are looking for on stack overflow! 😉\n This is the same thing with AI, and it is why a little less than two years ago I created a discord server. Where anyone learning or working in the field could come and share their projects, learn together, work together, and much more. The community has now over 20 000 members, which is unbelievable! So glad to see it growing and see everyone so active. We also have an amazing partnership with an AI company coming that is super exciting for the community. You definitely want to be there to enjoy all the benefits they will give us.\n Come join us if you are in the field of AI !\n https://discord.gg/learnaitogether\n    submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u9bp01/learning_or_working_with_ai_come_join_us_we_are_a/",
          "publishedOn": "2022-04-22T10:44:47.000Z",
          "wordCount": 329,
          "title": "Learning or working with AI? Come join us, we are a Discord Community with over 20'000 members! Ask questions, find teammates, share your projects, attend events, and much more to come!",
          "imageUrl": "https://external-preview.redd.it/TmwDNz7LGEv1N_4hjX4ofjCt4K0Y2QQCOiOzVJtu3RE.jpg?auto=webp&s=ad9751f0631441d3fcfa9501ab7921f50a06723b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u970et/analyse_sentimenttonality_in_social_networks/",
          "author": null,
          "description": "submitted by    /u/akolonin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u970et/analyse_sentimenttonality_in_social_networks/",
          "publishedOn": "2022-04-22T05:21:16.000Z",
          "wordCount": 172,
          "title": "Analyse sentiment/tonality in social networks",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u94gmh/research_explaining_the_black_box_optimization/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u94gmh/research_explaining_the_black_box_optimization/",
          "publishedOn": "2022-04-22T02:52:26.000Z",
          "wordCount": 789,
          "title": "[Research] Explaining the Black Box Optimization Competition Winner Algorithm-HEBO Algorithm of AI Top Conference NeurIPS 2020",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u90x16/last_week_in_ai_chip_startup_funding_doubled/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u90x16/last_week_in_ai_chip_startup_funding_doubled/",
          "publishedOn": "2022-04-21T23:47:26.000Z",
          "wordCount": 127,
          "title": "Last Week in AI: Chip Startup Funding Doubled, Google Text+Image Search, Analog AI, Criminal Robotaxi",
          "imageUrl": "https://external-preview.redd.it/GSN_6Y_ISJPFlnFKeQIO4j11y8PNxtWUoerk9AXuC1U.jpg?auto=webp&s=e87487497e998c33ab705d6bed0273ee00ffc75a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8zf34/ai_dream_31_spaceships_galore_planet_vqgan_clip/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8zf34/ai_dream_31_spaceships_galore_planet_vqgan_clip/",
          "publishedOn": "2022-04-21T22:33:13.000Z",
          "wordCount": 109,
          "title": "AI Dream 31 - Spaceships Galore Planet VQGAN CLIP",
          "imageUrl": "https://external-preview.redd.it/Eru_2C_c2KF_cPsZwkZGqk-JVlCgmzRnx18Usqc63n8.jpg?auto=webp&s=e6dfb804d102a1a67a602a39767a314646fe34d7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8wtb2/what_would_be_the_best_approach_to_autogenerate/",
          "author": null,
          "description": "I'm a software developer but I'm not really experienced in AI. Would it be best to train first for speech bubbles and separately for panel drawings? What kind of network is the best for this? Just thinking that it would be a cool project to have auto generated legible infinite comic strips for a semi niche comic strip that runs in my country.\n    submitted by    /u/dananite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8wtb2/what_would_be_the_best_approach_to_autogenerate/",
          "publishedOn": "2022-04-21T20:29:57.000Z",
          "wordCount": 248,
          "title": "What would be the best approach to auto-generate comic panels (Garfield style) with drawings and speech bubbles, assuming I have tons of scans to use as training?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8wa9d/any_recommendations_for_ai_content_generation/",
          "author": null,
          "description": "Content generation is such a time-suck for small businesses, and it seems like an interesting vertical to apply AI. The AI would generate the content after being given a prompt. There are already a few tools trying this, but the quality doesn't seem to be very high.\n Are there better tools that I'm missing, or is the consumer-facing software so early-stage that it would be better to hire a data scientist and train an AI system specifically for this purpose?\n https://www.reddit.com/r/MachinesWrite/comments/f45eav/list_of_ai_text_generators/?utm_source=share&utm_medium=web2x&context=3\n https://www.reddit.com/r/juststart/comments/axa8w3/ai_ml_text_generators/?utm_source=share&utm_medium=web2x&context=3\n    submitted by    /u/CliffWoolum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8wa9d/any_recommendations_for_ai_content_generation/",
          "publishedOn": "2022-04-21T20:05:22.000Z",
          "wordCount": 225,
          "title": "Any Recommendations for AI Content Generation Software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8vmk4/looking_for_enterprise_conversational_ai_platform/",
          "author": null,
          "description": "submitted by    /u/sunstormfirefall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8vmk4/looking_for_enterprise_conversational_ai_platform/",
          "publishedOn": "2022-04-21T19:35:25.000Z",
          "wordCount": 353,
          "title": "Looking for enterprise conversational AI platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8v5yo/vicreg_tutorial_and_lightweight_pytorch/",
          "author": null,
          "description": "Here's a tutorial and lightweight PyTorch implementation of VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning. Hope you find it helpful!\n    submitted by    /u/thejashGI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8v5yo/vicreg_tutorial_and_lightweight_pytorch/",
          "publishedOn": "2022-04-21T19:13:58.000Z",
          "wordCount": 135,
          "title": "VICReg: Tutorial and Lightweight PyTorch Implementation blog post",
          "imageUrl": "https://external-preview.redd.it/nlio8usMqy_ReFWZfdRWZzVWPAOmlaQsm5fC0fDkpO4.jpg?auto=webp&s=e7ed882487e5ed475af6d8e7f98866ba1a7d80b0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8tbkf/microsoft_ai_researchers_develop_ekya_to_address/",
          "author": null,
          "description": "Deep neural network (DNN) models for object recognition and classification, such as Yolo, ResNet, and EfficientNet, are used in video analytics applications such as urban mobility and smart automobiles. There is a symbiotic link between edge computing and video analytics, claiming that live video analytics is the “killer app” for edge computing. Edge devices come in various sizes and designs, but they are always resource-constrained compared to the cloud. Video analytics deployments send the videos to on-premises edge servers. The article handles the difficulty of supporting inference and retraining jobs on edge servers simultaneously, which necessitates navigating the fundamental tradeoff between the accuracy of the retrained model and the accuracy of the inference. Edge computation is preferred for video analytics because it eliminates the need for expensive network lines to broadcast videos to the cloud while simultaneously preserving video privacy. Edge computation has a finite amount of resources (e.g., with weak GPUs). The mismatch between the increasing rate of model compute needs, and the total cycles of processors exacerbate this problem. As a result, model compression is used in edge deployments.\n Continue reading our bite on this research\n Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/07/nsdi22spring-final74.pdf\n Github: https://github.com/edge-video-services/ekya\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8tbkf/microsoft_ai_researchers_develop_ekya_to_address/",
          "publishedOn": "2022-04-21T17:49:42.000Z",
          "wordCount": 346,
          "title": "Microsoft AI Researchers Develop ‘Ekya’ To Address The Problem Of Data Drift On The Edge Compute Box And Enables Both Retraining And Inference To Co-Exist On It",
          "imageUrl": "https://external-preview.redd.it/fr6sTFkxPr_nxK_uM6bfbHkoEh-SBIH6kJojQNYUb74.jpg?auto=webp&s=214c6642ae7b51e469b77b058da4813078222c49"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8ou8m/is_there_a_ai_which_is_able_to_turn_normal_videos/",
          "author": null,
          "description": "submitted by    /u/TheblackRook3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8ou8m/is_there_a_ai_which_is_able_to_turn_normal_videos/",
          "publishedOn": "2022-04-21T14:25:25.000Z",
          "wordCount": 345,
          "title": "Is there a AI which is able to turn normal videos into sketches like the video below?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8mnva/automatic_summaries_of_your_documents_in_google/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8mnva/automatic_summaries_of_your_documents_in_google/",
          "publishedOn": "2022-04-21T12:37:26.000Z",
          "wordCount": 131,
          "title": "Automatic Summaries of your Documents in Google Docs !",
          "imageUrl": "https://external-preview.redd.it/0xBUwjndLwNWttGumJ98z2kj6iEcrI9jeA8utIsy9cY.jpg?auto=webp&s=a2d2a30600e5cf86b9301a3b955148fc3cce0761"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8iurr/how_to_achieve_a_training_duration_on_mindspore/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8iurr/how_to_achieve_a_training_duration_on_mindspore/",
          "publishedOn": "2022-04-21T08:36:46.000Z",
          "wordCount": 177,
          "title": "How to achieve a training duration on MindSpore that's less than or equal to that on TensorFlow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8he59/cypherzilla_the_first_encoded_nft_made_by_ai_to/",
          "author": null,
          "description": "CypherZilla on OpenSea\n https://reddit.com/link/u8he59/video/i9a29i5ywtu81/player\n    submitted by    /u/thecypherbeast  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8he59/cypherzilla_the_first_encoded_nft_made_by_ai_to/",
          "publishedOn": "2022-04-21T06:49:15.000Z",
          "wordCount": 144,
          "title": "CypherZilla - The First Encoded NFT Made By AI To Support Trump. Upvote If You Want To Have A Huge Impact!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8gqe6/what_price_we_have_to_pay_for_the_progress_in_ai/",
          "author": null,
          "description": "https://www.sganalytics.com/blog/top-ethical-challenges-in-ai-the-price-of-progress/\n    submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8gqe6/what_price_we_have_to_pay_for_the_progress_in_ai/",
          "publishedOn": "2022-04-21T06:03:03.000Z",
          "wordCount": 119,
          "title": "What price we have to pay for the progress in AI, have a look-",
          "imageUrl": "https://external-preview.redd.it/aJi9Dz8P0k_F4j63zzdsjmhZLTXVfVYWVwiQByiyL84.jpg?auto=webp&s=aa8556546cd821f61a872c3d317d57475ebd7f58"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u8antj/collaboration_ai_video_and_music/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u8antj/collaboration_ai_video_and_music/",
          "publishedOn": "2022-04-21T00:24:55.000Z",
          "wordCount": 99,
          "title": "Collaboration AI video and music",
          "imageUrl": "https://external-preview.redd.it/Y_eldCN6JOpbpC_YENv_YSn0QxPnFndB-G04FqdlA5Y.jpg?auto=webp&s=9e717a70be47b65026e97471414298559f000428"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u85fsk/how_metas_multiverse_could_prove_our_universe_is/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u85fsk/how_metas_multiverse_could_prove_our_universe_is/",
          "publishedOn": "2022-04-20T20:16:17.000Z",
          "wordCount": 107,
          "title": "How Meta's multiverse could prove our universe is a fake",
          "imageUrl": "https://external-preview.redd.it/DsNE0-E8qUN9meNVbuhEnTE425OzpenTFo5id5M4u2o.jpg?auto=webp&s=48c490435839a13aeba3e0561dfd23b2feb1ecf3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u81hue/singularagent_many_methods_make_light_work/",
          "author": null,
          "description": "submitted by    /u/dantheman333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u81hue/singularagent_many_methods_make_light_work/",
          "publishedOn": "2022-04-20T17:16:30.000Z",
          "wordCount": 98,
          "title": "SingularAgent - Many Methods Make Light Work",
          "imageUrl": "https://external-preview.redd.it/INnAD5TDh2VB1h8EWzKC44A73kxhQQ6pA-Mo0FmEnrI.jpg?auto=webp&s=0a600af7f3c7bc5af8ac54c4682885169c870ed6"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u813a9/general_ai_in_healthcare_machine_learning_for/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u813a9/general_ai_in_healthcare_machine_learning_for/",
          "publishedOn": "2022-04-20T16:58:30.000Z",
          "wordCount": 124,
          "title": "General AI In Healthcare | Machine Learning For Cardiovascular Disease | Color Night Vision",
          "imageUrl": "https://external-preview.redd.it/De-wZxccwJFEqrmmsZjRzOWELT5D2lZO8A5k3zuymuk.jpg?auto=webp&s=c42558ab2d7266cb2819e4b0eac7c7fa7bbcae38"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7x38l/a_realistic_image_ai_software/",
          "author": null,
          "description": "submitted by    /u/Eurokiwiboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7x38l/a_realistic_image_ai_software/",
          "publishedOn": "2022-04-20T13:55:44.000Z",
          "wordCount": 97,
          "title": "A realistic image AI software",
          "imageUrl": "https://external-preview.redd.it/JbsDTf4SAmO2SdHaC_VY9bSe5I7FCR0zWo9moIdaijE.jpg?auto=webp&s=7c3664b585db5e4b0a26dc33ac2e2da99c9c904c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7vj4l/ant_colony_simulation/",
          "author": null,
          "description": "submitted by    /u/Seitoh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7vj4l/ant_colony_simulation/",
          "publishedOn": "2022-04-20T12:37:37.000Z",
          "wordCount": 415,
          "title": "Ant colony simulation",
          "imageUrl": "https://external-preview.redd.it/-fHs8s9VwwMqv6VYm5CgwsKlfQtEFbHQXsxeWKjorXY.png?format=pjpg&auto=webp&s=f32b988700168737f55c6ee64fde0ddc600dcf9f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7r8w6/is_there_any_free_open_source_ai_model_available/",
          "author": null,
          "description": "A few years back I developed a very simple app just to show a few bible verses. Though it is a very simple app, it got more than 50K installs without much promotion. So, I am thinking about promoting it. But hesitate to do it as it is very simple app. So, I would like to add some useful feature before start promoting it. I would like to add a feature which will allow the users to ask any question related to bible, and it should be giving relevant answer. I assume that some bible data is open source.\n Is there any free tutorial available to know about how to implement AI based chat system for answering any bible related queries after training with bible data.\n Is there any app already providing this feature?\n    submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7r8w6/is_there_any_free_open_source_ai_model_available/",
          "publishedOn": "2022-04-20T07:51:49.000Z",
          "wordCount": 253,
          "title": "Is there any free open source AI model available for answering any bible related queries?",
          "imageUrl": "https://external-preview.redd.it/eayHQ469wG-aR9Glgtq5PmukilhQBjG1gVHPRS5ivCU.jpg?auto=webp&s=fa2d65c79e60c391fa3fb02677129791c19da8d5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7ptrm/today_ai_is_becoming_ubiquitous_in_and_out_of_the/",
          "author": null,
          "description": "But can technology be controlled to avoid adverse outcomes? \n Let's understand how AI will help us to make a better world. \n https://us.sganalytics.com/blog/top-ethical-challenges-in-ai-the-price-of-progress/\n    submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7ptrm/today_ai_is_becoming_ubiquitous_in_and_out_of_the/",
          "publishedOn": "2022-04-20T06:10:00.000Z",
          "wordCount": 209,
          "title": "Today, AI is becoming ubiquitous, in and out of the workplace. With artificial intelligence (AI) becoming more powerful, the questions that surround AI ethics are becoming more relevant.",
          "imageUrl": "https://external-preview.redd.it/gpojHrxBRiyNRtS4dowCf62GHN0syOExlU8hVfJ3XUs.jpg?auto=webp&s=23fcb4c3ce2f7f5aa36daead94f7b8531000bfa7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7pch8/top_ethical_challenges_in_ai_the_price_of_progress/",
          "author": null,
          "description": "submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7pch8/top_ethical_challenges_in_ai_the_price_of_progress/",
          "publishedOn": "2022-04-20T05:38:08.000Z",
          "wordCount": 114,
          "title": "Top Ethical Challenges in AI – The Price of Progress",
          "imageUrl": "https://external-preview.redd.it/aJi9Dz8P0k_F4j63zzdsjmhZLTXVfVYWVwiQByiyL84.jpg?auto=webp&s=aa8556546cd821f61a872c3d317d57475ebd7f58"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7ogsu/artificial_nightmares_dr_strange_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7ogsu/artificial_nightmares_dr_strange_clip_guided/",
          "publishedOn": "2022-04-20T04:41:41.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Dr. Strange || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/_H1fKKk02xXV582Jck7PKzfLEX5sJzRZLVo9i5g1P_c.jpg?auto=webp&s=cc98d438165684e9033ba48a6c7406fd5f316d9a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7jj2e/weekly_china_ai_news_chinese_prominent_ai_lab/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7jj2e/weekly_china_ai_news_chinese_prominent_ai_lab/",
          "publishedOn": "2022-04-20T00:16:24.000Z",
          "wordCount": 163,
          "title": "Weekly China AI News: Chinese Prominent AI Lab Plagiarizes Big Model Paper; Microsoft Research Asia Halts Internship Hiring from US-Banned Universities; Beijing Announces New RISC-V Chip Institute",
          "imageUrl": "https://external-preview.redd.it/8PfsozjPm9bKaZri1Oa5OJpyHDfqbBmkOag-6iAr918.jpg?auto=webp&s=eefadd25142b934a070d398829efea1ac0a6cfe7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7ix6l/speeding_up_ai_algorithms_inferencing_challenges/",
          "author": null,
          "description": "submitted by    /u/Chipdoc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7ix6l/speeding_up_ai_algorithms_inferencing_challenges/",
          "publishedOn": "2022-04-19T23:46:09.000Z",
          "wordCount": 104,
          "title": "Speeding Up AI Algorithms- Inferencing challenges at the edge",
          "imageUrl": "https://external-preview.redd.it/iLwjB8yODgc1h8Gz-x0aNzFmOYuA86G2FzAHD7r7_Mo.jpg?auto=webp&s=709ea43539a1a3f5773e4472268a27d09738a0b5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7eq9m/build_share_machine_learning_apps_directly_in/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7eq9m/build_share_machine_learning_apps_directly_in/",
          "publishedOn": "2022-04-19T20:30:27.000Z",
          "wordCount": 116,
          "title": "Build & share machine learning apps directly in browser using Gradio in Python",
          "imageUrl": "https://preview.redd.it/k19vt6tmpju81.jpg?auto=webp&s=2aa19787e1291bfcac0496868c0e3625705814d8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7cnk8/what_if_you_are_a_prototype_for_the_ultimate/",
          "author": null,
          "description": "submitted by    /u/IndependenceFun4627  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7cnk8/what_if_you_are_a_prototype_for_the_ultimate/",
          "publishedOn": "2022-04-19T18:58:58.000Z",
          "wordCount": 184,
          "title": "What if You Are a Prototype for the Ultimate Sentient Artificial Intelligence?",
          "imageUrl": "https://external-preview.redd.it/XQWZBCGw8dWGlWDR0iPMP0YiLAUNLg_qbtwvNCo-BkY.jpg?auto=webp&s=1f0d1be28c0573a2dfea524dd3f794f9e719fdc5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7bxnv/overview_of_relational_graph_convolutional/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7bxnv/overview_of_relational_graph_convolutional/",
          "publishedOn": "2022-04-19T18:27:46.000Z",
          "wordCount": 98,
          "title": "Overview of Relational Graph Convolutional Networks (RGCN)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7a4yw/there_are_so_many_crappy_chatbots_cause_people/",
          "author": null,
          "description": "Hi there! Chatbots are not the \"set and forget\" thing like many other software. If you want to achieve great results with your chatbot, you need to improve it constantly. To know where and what to improve, you need to track and monitor chatbot analytics and the main chatbot metrics.\n General chatbot metrics\n  \nTotal number of users\n User satisfaction\n Accuracy of the chatbot\n  \nEngagement metrics\n  \nActive users\n New users\n Conversation Length\n Retention Rate\n Bounce Rate\n Flow Completion Rate\n  \nConversational analytics\n  \nGoal Completion Rate (GCR)\n Fallback Rate\n Human Takeover Rate\n  \n* Bonus: Revenue metrics\n  \nRevenue generated\n ROI / payback period\n  \nHere in the article we covered how to calculate each metrics, and you can find needed metrics depending on the industry you working in https://botscrew.com/blog/chatbot-metrics/?utm_source=RedditArtificial&utm_medium=&utm_campaign=&utm_term=&utm_content=\n    submitted by    /u/Avandegraund  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7a4yw/there_are_so_many_crappy_chatbots_cause_people/",
          "publishedOn": "2022-04-19T17:10:20.000Z",
          "wordCount": 262,
          "title": "There are so many crappy chatbots, cause people don't pay attention on how it's performing. If you're one of them, here are metrics to keep in mind",
          "imageUrl": "https://external-preview.redd.it/nrLynkYAQfOecU574osiJ7EnlqlHprcrqGz13zB8U8s.jpg?auto=webp&s=79d3cd16186d7b6b9d8502a3e69c47b38a062db8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u797ue/wakeup_call_for_science_ai_system_develops_40000/",
          "author": null,
          "description": "submitted by    /u/TheCnt23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u797ue/wakeup_call_for_science_ai_system_develops_40000/",
          "publishedOn": "2022-04-19T16:30:04.000Z",
          "wordCount": 124,
          "title": "Wake-up Call for Science – AI System Develops 40,000 Chemical Weapons in 6 Hours",
          "imageUrl": "https://external-preview.redd.it/g87RQeN11WVmu3DBw0sXRgwG3g-JIXTh6ffdprAUOaI.jpg?auto=webp&s=1fb734b051f900dcd188cb8bf120fd6b7a0fbee8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u75xc0/stopping_them_from_spying_on_you_new_ai_can_block/",
          "author": null,
          "description": "submitted by    /u/KelliaMcclure  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u75xc0/stopping_them_from_spying_on_you_new_ai_can_block/",
          "publishedOn": "2022-04-19T14:03:37.000Z",
          "wordCount": 118,
          "title": "Stopping 'them' from spying on you: New AI can block rogue microphones",
          "imageUrl": "https://external-preview.redd.it/4VZwC4-xEcbJE_DmEFspbG5nf2ah1Z_zKcWXPPgo5vY.jpg?auto=webp&s=78e92e81c66132b6ba704a237b1d980b44652118"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u75l7z/stopping_them_from_spying_on_you_new_ai_can_block/",
          "author": null,
          "description": "submitted by    /u/KelliaMcclure  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u75l7z/stopping_them_from_spying_on_you_new_ai_can_block/",
          "publishedOn": "2022-04-19T13:48:14.000Z",
          "wordCount": 488,
          "title": "Stopping 'them' from spying on you: New AI can block rogue microphones",
          "imageUrl": "https://external-preview.redd.it/4VZwC4-xEcbJE_DmEFspbG5nf2ah1Z_zKcWXPPgo5vY.jpg?auto=webp&s=78e92e81c66132b6ba704a237b1d980b44652118"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u7557s/which_courses_are_good_for_complete_beginners/",
          "author": null,
          "description": "Hello everyone , can someone recommend me for some good courses to do , I saw some courses on udemy , this one worth it? https://www.udemy.com/course/artificial-intelligence-az/\n or I can learn everything on youtube? there are few more on udemy but I don't know how good they are ..\n is it worth buying one of those or there are better videos on youtube?\n EDIT : I found another 4 courses :\n https://www.udemy.com/course/100-days-of-code/\n https://www.udemy.com/course/complete-python-bootcamp/ \n https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/\n https://www.udemy.com/course/machinelearning/\n Which one of them would you recommend the most?\n    submitted by    /u/Edrixor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u7557s/which_courses_are_good_for_complete_beginners/",
          "publishedOn": "2022-04-19T13:26:49.000Z",
          "wordCount": 172,
          "title": "which courses are good for complete beginners?",
          "imageUrl": "https://external-preview.redd.it/0pMpUAz3akcRBLby7is7-gznZCQ9YfuPikH0u3LfLOc.jpg?auto=webp&s=c8fe621a36d5853ff106453eee70c17359f9ea57"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u74jg6/ai_will_make_us_dumb_220407888_ai_ageing_and/",
          "author": null,
          "description": "submitted by    /u/kg4jxt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u74jg6/ai_will_make_us_dumb_220407888_ai_ageing_and/",
          "publishedOn": "2022-04-19T12:57:16.000Z",
          "wordCount": 311,
          "title": "AI will make us dumb: [2204.07888] AI, Ageing and Brain-Work Productivity: Technological Change in Professional Japanese Chess",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u72mx0/any_good_resources_to_learn_default_theory/",
          "author": null,
          "description": "I am having a difficult time understanding Default Theory and the various methods e.g Makinson to find the extension of default theories\n    submitted by    /u/cocag13996  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u72mx0/any_good_resources_to_learn_default_theory/",
          "publishedOn": "2022-04-19T11:11:59.000Z",
          "wordCount": 119,
          "title": "Any good resources to learn Default Theory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u71qxe/i_know_that_the_voice_in_this_video_is_made_using/",
          "author": null,
          "description": "This\n I looked through the available ones, not a single one seems to match it. Sorry if this isn't the right sub to ask, but since Replica Studios doesn't have its own sub I don't know where\n    submitted by    /u/AxySmarts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u71qxe/i_know_that_the_voice_in_this_video_is_made_using/",
          "publishedOn": "2022-04-19T10:16:11.000Z",
          "wordCount": 181,
          "title": "I know that the voice in this video is made using Replica Studio's engine, but does anyone know which voice exactly was used?",
          "imageUrl": "https://external-preview.redd.it/wvkCFnR-1hsAqSUcg_fO-WhKr7U7A8Iadzpsn-AWzBs.jpg?auto=webp&s=8e847789208f0a6210a981d933057d8e5321d7d3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6ur63/artificial_nightmares_schizophrenia_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6ur63/artificial_nightmares_schizophrenia_clip_guided/",
          "publishedOn": "2022-04-19T02:49:38.000Z",
          "wordCount": 123,
          "title": "Artificial Nightmares: Schizophrenia || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/SL4UeLUNXFJ5_GRhRiLVL-JFuAvsji8dg8G2wQSzBkg.jpg?auto=webp&s=1652b216042892f4ef776b9c2e0d85e3d2a988f4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6qw0p/whats_your_hopes_and_worry_about_future_humaniod/",
          "author": null,
          "description": "submitted by    /u/Upset_Force66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6qw0p/whats_your_hopes_and_worry_about_future_humaniod/",
          "publishedOn": "2022-04-18T23:37:26.000Z",
          "wordCount": 115,
          "title": "whats your hopes and worry about future humaniod Artificial intelligence coming soon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6ocab/ai_dream_36_psychedelic_special_4k_40mbit_test/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6ocab/ai_dream_36_psychedelic_special_4k_40mbit_test/",
          "publishedOn": "2022-04-18T21:42:09.000Z",
          "wordCount": 109,
          "title": "AI Dream 36 - Psychedelic Special (4K 40Mbit Test)",
          "imageUrl": "https://external-preview.redd.it/VmWUdniS5xpclW7Q_xIN2ip-aetWqAhw_ev2n3-RlWk.jpg?auto=webp&s=204618cbe921d1c2897d013824ad38cf5e791c8b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6lzqw/ai_startups_and_the_hunt_for_tech_talent_in/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6lzqw/ai_startups_and_the_hunt_for_tech_talent_in/",
          "publishedOn": "2022-04-18T19:58:27.000Z",
          "wordCount": 112,
          "title": "AI Startups and the Hunt for Tech Talent in Vietnam",
          "imageUrl": "https://external-preview.redd.it/VTHcGJP2dX5u4LCB9A9PIqA9308RpRmiYJ58QNRdH0o.jpg?auto=webp&s=6e907dbf8c56e03505d84ceea6d1a6fa2fe513da"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6kzbr/we_dont_have_echolocation/",
          "author": null,
          "description": "submitted by    /u/tezdhar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6kzbr/we_dont_have_echolocation/",
          "publishedOn": "2022-04-18T19:13:50.000Z",
          "wordCount": 103,
          "title": "We don't have echolocation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6kung/these_3michelinstarred_plates_were_invented_by_ai/",
          "author": null,
          "description": "submitted by    /u/jonfla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6kung/these_3michelinstarred_plates_were_invented_by_ai/",
          "publishedOn": "2022-04-18T19:08:00.000Z",
          "wordCount": 118,
          "title": "These 3-Michelin-starred plates were invented by AI. The food doesn’t even exist",
          "imageUrl": "https://external-preview.redd.it/zNvoAOfuDMmMFofp6qb79qAyhOng7bR438eGTMflgmI.jpg?auto=webp&s=6d2f0456f69a15ebc576485fa4a7c7c15f62bda4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6kow4/getting_in_shape_while_homeworking_by_force/",
          "author": null,
          "description": "submitted by    /u/ThePyCoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6kow4/getting_in_shape_while_homeworking_by_force/",
          "publishedOn": "2022-04-18T19:01:05.000Z",
          "wordCount": 145,
          "title": "Getting in shape while homeworking by force locking the screen and using blazepose pose estimation to detect pushups to unlock it again.",
          "imageUrl": "https://external-preview.redd.it/efuGVuRWCoQOFtDulJ96gkeKNGq9LeHuDr_G8Om-4Cg.jpg?auto=webp&s=25496b15357178107e28538f630ef85c416be24e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6ke8u/last_week_in_ai_ai_chip_startup_funding_doubled/",
          "author": null,
          "description": "https://lastweekin.ai/p/163?s=w\n    submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6ke8u/last_week_in_ai_ai_chip_startup_funding_doubled/",
          "publishedOn": "2022-04-18T18:48:24.000Z",
          "wordCount": 170,
          "title": "Last Week in AI: AI chip startup funding doubled in the last 5 years, new AI applications in hospitals and restaurants, Cruise robotaxi pulled over by police in SF, and more!",
          "imageUrl": "https://external-preview.redd.it/wDYeYdIZJ7X1EXsqTtkFmI64EiTZ-aoZ4-NSIK1k6lM.jpg?auto=webp&s=80b3ca386765a5116b47659140c5b3f4fab52fd4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6eoup/youtubers_create_a_completely_ai_influencer/",
          "author": null,
          "description": "submitted by    /u/savetheattack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6eoup/youtubers_create_a_completely_ai_influencer/",
          "publishedOn": "2022-04-18T14:38:56.000Z",
          "wordCount": 95,
          "title": "Youtubers create a completely AI \"influencer.\"",
          "imageUrl": "https://external-preview.redd.it/0lAR04IvZZB-HTIeW4f95BXpn-IgNcrNJ3Hr6l9mLtA.jpg?auto=webp&s=db1ed9cbbdf8d16babae6493cf495ada51673bed"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6d5e1/fomo_is_a_tinyml_neural_network_for_realtime/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6d5e1/fomo_is_a_tinyml_neural_network_for_realtime/",
          "publishedOn": "2022-04-18T13:27:10.000Z",
          "wordCount": 112,
          "title": "FOMO is a TinyML neural network for real-time object detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u6cbz8/an_online_course_with_an_ai_tutor_achieves_a/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u6cbz8/an_online_course_with_an_ai_tutor_achieves_a/",
          "publishedOn": "2022-04-18T12:47:12.000Z",
          "wordCount": 338,
          "title": "An online course with an AI tutor achieves a significantly higher completion rate than traditional online courses thanks to a personalized learning experience.",
          "imageUrl": "https://external-preview.redd.it/HM1mHkpsBRyrCPFfV-GyEDe1IM82yc7-pIySw5sSYLw.jpg?auto=webp&s=794512a998357fede38a9275b7947eeb9dfc2545"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u68ndy/protein_folding_neural_networks_eg_rosettafold/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u68ndy/protein_folding_neural_networks_eg_rosettafold/",
          "publishedOn": "2022-04-18T09:01:14.000Z",
          "wordCount": 104,
          "title": "Protein Folding Neural Networks (e.g RoseTTAFold) Are Not Robust",
          "imageUrl": "https://external-preview.redd.it/qX06OApQxBwLalWdKBMkO5luiOO17-Zw5e0-W9Ng-j0.jpg?auto=webp&s=237f28276a35cf32c9468e1dad8576a5f2e64e23"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u65x6q/witch_of_the_barthe/",
          "author": null,
          "description": "submitted by    /u/Hacknaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u65x6q/witch_of_the_barthe/",
          "publishedOn": "2022-04-18T05:49:16.000Z",
          "wordCount": 90,
          "title": "Witch of the Barthe",
          "imageUrl": "https://preview.redd.it/adnay8p278u81.png?auto=webp&s=96aae290f68d3ec0a1c029c57d525850b1d5c19c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u64j7h/why_is_it_called_tensorflow_and_not_matrixflow/",
          "author": null,
          "description": "Hello,\n I'm MB. A very nice and polite guy.\n Why is it called tensorflow and not matrixflow?\n AI is all about matrix multiplications, right? So why use the word tensor instead? I know what a tensor is, kind of. But isn't AI about matrix multiplications primarily rather than tensor multiplications.\n ELI5 please.\n    submitted by    /u/MountBlanc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u64j7h/why_is_it_called_tensorflow_and_not_matrixflow/",
          "publishedOn": "2022-04-18T04:20:22.000Z",
          "wordCount": 577,
          "title": "Why is it called tensorflow and not matrixflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u64gx1/society/",
          "author": null,
          "description": "submitted by    /u/booksmoothie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u64gx1/society/",
          "publishedOn": "2022-04-18T04:16:39.000Z",
          "wordCount": 82,
          "title": "Society",
          "imageUrl": "https://preview.redd.it/iucbmpuzq7u81.png?auto=webp&s=04d171aa61c71f9f7ae542212c620888b36ed57a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u63lm4/bioinspired_multisensory_neural_network_with/",
          "author": null,
          "description": "submitted by    /u/booksmoothie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u63lm4/bioinspired_multisensory_neural_network_with/",
          "publishedOn": "2022-04-18T03:26:32.000Z",
          "wordCount": 109,
          "title": "Bioinspired multisensory neural network with crossmodal integration and recognition",
          "imageUrl": "https://external-preview.redd.it/ysCYb5ssDbIgxnBfohLEto-Q9jDFUluNp2TmJD673zI.jpg?auto=webp&s=c8319d2bc17b60605482b020564c5a3b034dca9c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u630rh/realistic_animal_movement/",
          "author": null,
          "description": "I am working on a robotic pet that has lots of movement capability but is simply scripted and will unnaturally jump between movement sets without considering the current movement.\n What branch of AI should I look into leaning about? Currently I use mostly python for high level and C for microcontrollers.\n    submitted by    /u/uMinded  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u630rh/realistic_animal_movement/",
          "publishedOn": "2022-04-18T02:54:24.000Z",
          "wordCount": 141,
          "title": "Realistic animal movement",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5z9k4/build_share_machine_learning_apps_directly_in/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5z9k4/build_share_machine_learning_apps_directly_in/",
          "publishedOn": "2022-04-17T23:36:12.000Z",
          "wordCount": 121,
          "title": "Build & share machine learning apps directly in browser using Gradio in Python",
          "imageUrl": "https://external-preview.redd.it/_jq3RHJF4dWo0ICB0aESwOXlW3jCTwldBtbIIuFynSw.jpg?auto=webp&s=8bf1e5972aabb7d81fcda17ccbee87891e8cf6ae"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5lgia/ai_trippy_dream_19_exploring_a_colorful_maze/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5lgia/ai_trippy_dream_19_exploring_a_colorful_maze/",
          "publishedOn": "2022-04-17T11:49:43.000Z",
          "wordCount": 109,
          "title": "AI Trippy Dream 19 - Exploring a Colorful Maze",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5ihzv/a_better_boids_simulation_an_artificial_life/",
          "author": null,
          "description": "submitted by    /u/Seitoh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5ihzv/a_better_boids_simulation_an_artificial_life/",
          "publishedOn": "2022-04-17T08:10:26.000Z",
          "wordCount": 303,
          "title": "a better Boids simulation: An artificial life simulation of the flock of birds",
          "imageUrl": "https://external-preview.redd.it/FpMxU4uPFl-vAzL6kppEQXyvL5tvV4RhnB5zhZzQOy8.png?format=pjpg&auto=webp&s=df79df42ad0317dc64a52796d3fd09a09f7a5b69"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5fpt3/new_ai_upscaler_tool/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5fpt3/new_ai_upscaler_tool/",
          "publishedOn": "2022-04-17T04:52:19.000Z",
          "wordCount": 141,
          "title": "New AI upscaler tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5e5hc/credit_scoring_for_companies/",
          "author": null,
          "description": "Hello everyone I'm newbie so pardon me if you find that my question is stupid.\n I'm working on a project here's it's description in a nutshell ( Classifying companies if they're going to bankrupt or not and based of the probability of default ( probability of bankruptcy) give each companies a score For example 88 percent to bankrupt score is D 21 percent to bankrupt score is B 3 percent to bankrupt score is a)\n My question is what kind of models should test ? Should i go for machine learning algorithms such as logistic regression, knn, SVM? Should I go for neural networks ANN? Or can I use deep learning models like MLP... probabilistic Neural Network?\n Any guidance or advice will be appreciated and thanks a lot.\n    submitted by    /u/YeccAnon4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5e5hc/credit_scoring_for_companies/",
          "publishedOn": "2022-04-17T03:17:40.000Z",
          "wordCount": 261,
          "title": "credit scoring for companies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u5abdp/is_there_an_ai_i_could_use_to_create_an/",
          "author": null,
          "description": "He’s basically this wacky dead philosopher with 1000s of hours of his lectures of YT and I was thinking it may be possible to create an artificial AI personality of his from all of his recorded speech? Would there be a simple enough program I could download or anything of the sort?\n    submitted by    /u/Vaporshots  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u5abdp/is_there_an_ai_i_could_use_to_create_an/",
          "publishedOn": "2022-04-16T23:43:04.000Z",
          "wordCount": 195,
          "title": "Is there an AI I could use to create an artificial Terence McKenna chatbot?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u58cz2/boids_an_artificial_life_simulation_of_a_flock_of/",
          "author": null,
          "description": "submitted by    /u/Seitoh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u58cz2/boids_an_artificial_life_simulation_of_a_flock_of/",
          "publishedOn": "2022-04-16T22:02:55.000Z",
          "wordCount": 324,
          "title": "Boids: An artificial life simulation of a flock of birds",
          "imageUrl": "https://external-preview.redd.it/MC2dZoKt52Ish-rXYqykRUtNorColauLlnAj87Qk6R0.jpg?auto=webp&s=7ed2b478412d5048fb535a1e299d91ed80ee85b7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u52b68/ai_trippy_dream_37_psychedelic_special_request/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u52b68/ai_trippy_dream_37_psychedelic_special_request/",
          "publishedOn": "2022-04-16T17:10:35.000Z",
          "wordCount": 106,
          "title": "AI Trippy Dream 37 - Psychedelic Special Request",
          "imageUrl": "https://external-preview.redd.it/UDUee4CNXyN_18m6d0_XcLn_poNEPFUiGY4oFvksdAk.jpg?auto=webp&s=85c23e7d35246adfb0a5854e6f9b7cf3f99b08bb"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u50q5a/amazing_generation/",
          "author": null,
          "description": "Looks Amazing. The vibe is there.\n What do you think ? How did he archive this ? Created by Hand or through artificial ?\n https://www.tiktok.com/@ai.metascape/video/7086451191151971586\n    submitted by    /u/PillowG1rl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u50q5a/amazing_generation/",
          "publishedOn": "2022-04-16T15:55:31.000Z",
          "wordCount": 117,
          "title": "Amazing Generation",
          "imageUrl": "https://external-preview.redd.it/tuH77pY8E4IE5WNny2LLRYwtPlRizLtWW5Ws9enm2_U.jpg?auto=webp&s=c73c1437628e53b065b642a7f489f78aae2d0e36"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4xeoh/little_baby_chibi_lucy_loud/",
          "author": null,
          "description": "submitted by    /u/VIRUS-AOTOXIN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4xeoh/little_baby_chibi_lucy_loud/",
          "publishedOn": "2022-04-16T13:05:37.000Z",
          "wordCount": 94,
          "title": "Little Baby Chibi Lucy Loud",
          "imageUrl": "https://preview.redd.it/enybtp2l3wt81.jpg?auto=webp&s=99423db58c3de8107fc165a19dc0c347c27a519b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4s7oi/artificial_intelligence_is_the_future_of/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4s7oi/artificial_intelligence_is_the_future_of/",
          "publishedOn": "2022-04-16T07:03:38.000Z",
          "wordCount": 103,
          "title": "Artificial Intelligence is the Future of Deterrence",
          "imageUrl": "https://external-preview.redd.it/bd6LRMpI4iKmVPYzrZlbX3z7Q1-HWYSYL1d1xahGooM.jpg?auto=webp&s=805cf15bf8bd1b6ad6ff8b77501090c481777837"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4rylo/linkedin_opensources_feathr_its_feature_store_to/",
          "author": null,
          "description": "LinkedIn research team has recently open-sourced feature store, Feathr, created to simplify machine learning (ML) feature management and increase developer productivity. Feathr is used by dozens of LinkedIn applications to define features, compute them for training, deploy them in production, and share them across consumers. Compared to previous application-specific feature pipeline solutions, Feathr users reported significantly reduced time required to add new features to model training and improved runtime performance.\n Hundreds of ML models run on LinkedIn in Search, Feed, and Ads applications. Thousands of features about entities in the Economic Graph, such as companies, job postings, and LinkedIn members, power the models. The most time-consuming aspects of handling the ML applications at scale have been preparing and managing features.\n Continue reading the summary\n Github: https://github.com/linkedin/feathr\n LinkedIn Blog: https://engineering.linkedin.com/blog/2022/open-sourcing-feathr—linkedin-s-feature-store-for-productive-m\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4rylo/linkedin_opensources_feathr_its_feature_store_to/",
          "publishedOn": "2022-04-16T06:45:45.000Z",
          "wordCount": 252,
          "title": "LinkedIn Open-Sources ‘Feathr’, It’s Feature Store To Simplify Machine Learning (ML) Feature Management And Improve Developer Productivity",
          "imageUrl": "https://external-preview.redd.it/Ls16Z9tPqPiVminbIxsJtnmGls2UupnmGlTnauO8E8s.jpg?auto=webp&s=7d6dc766d26b4f0f9b890affa9d7524fd012f8d4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4p08a/artificial_nightmares_crypt_walker_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4p08a/artificial_nightmares_crypt_walker_clip_guided/",
          "publishedOn": "2022-04-16T03:32:12.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Crypt Walker || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/8bRH1uOgxfjjJwxK6ZylcZVhCUHp-ZHEavoBwUKm9Js.jpg?auto=webp&s=f38e54485c298b829e67c98d608ff6db81a46184"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4norp/i_created_a_diy_python_package_to_ensemble/",
          "author": null,
          "description": "Multimodal: A python package to ensemble speech, text, etc. models and build new applications. Sample Applications: Speech Named Entity Anonymizer, Speech Question Answering, Speech Generation \n Code: kritiksoman/Multimodal: Listen. Write. Speak. Read. Think. (github.com)\n    submitted by    /u/kritiksoman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4norp/i_created_a_diy_python_package_to_ensemble/",
          "publishedOn": "2022-04-16T02:16:51.000Z",
          "wordCount": 140,
          "title": "I created a DIY python package to ensemble multimodal models",
          "imageUrl": "https://external-preview.redd.it/ZDcDIDKrQwGkFEOoQ-2pWFM-QroaOF_XoCB2D9bN5wk.jpg?auto=webp&s=1fc96f471c0b2bae02c845f13f86fe0d311c47f5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4d9sp/kamikaze_drones_in_russias_war_against_ukraine/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4d9sp/kamikaze_drones_in_russias_war_against_ukraine/",
          "publishedOn": "2022-04-15T17:32:58.000Z",
          "wordCount": 171,
          "title": "Kamikaze Drones in Russia’s War Against Ukraine Point to Future \"Killer Robots\"",
          "imageUrl": "https://external-preview.redd.it/3VJEMc_JqSEOafs67aHf9tnp8nXokYkqd4FIiDdbaIs.jpg?auto=webp&s=92c1037471864ddf888e1dd606e57cc8b68b931b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4cffp/ai_news_breakthrough_ai_robot_arm_understanding/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4cffp/ai_news_breakthrough_ai_robot_arm_understanding/",
          "publishedOn": "2022-04-15T16:54:55.000Z",
          "wordCount": 167,
          "title": "AI News | Breakthrough AI Robot Arm Understanding From Google | OpenAI DALL-E 2 | AI Edge Computing In Space",
          "imageUrl": "https://external-preview.redd.it/93dMOPeS_oIy50HR-_YHpuZjpn9S8POSoqBlNEOAKPY.jpg?auto=webp&s=2b0364a711428ac675d159a46dbf9a79030acb5f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4cfe2/dalle_zeroshot_texttoimage_generation_part12/",
          "author": null,
          "description": "OpenAI released DALL E2 in the last week, this system is basically have a capability of generating an image from a text description. Some of the results were truly amazing. In this blog, I tried to discuss the ideas around DALL-E (version 1) .\n DALL-E consist of two main components d-VAE(discrete-Variational Auto Encoder) and Auto-regressive transformer. In Part-1 I focused on d-VAE part where I tried to talk about basic VAE and it's ELBO formulation, VQ-VAE eventually that leads to d-VAE. It's reconstruction loss is formulated from Logit Laplcae (bounded) unlike typical L1 or L2. Overall this part explains about how a discrete vector(token) can be generated for an input image.\n    submitted by    /u/rakshith291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4cfe2/dalle_zeroshot_texttoimage_generation_part12/",
          "publishedOn": "2022-04-15T16:54:52.000Z",
          "wordCount": 201,
          "title": "DALL-E (Zero-Shot Text-to-Image Generation) -PART(1/2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u49gz6/my_first_attempt_at_machine_learning_i_made_a/",
          "author": null,
          "description": "I made a self learning conversational chatbot in ReactJS. It does nothing but reply to user messages and only understands text, for now 😄\n https://xalen.netlify.app\n What do you think? Yea or Nay?\n    submitted by    /u/GameTide  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u49gz6/my_first_attempt_at_machine_learning_i_made_a/",
          "publishedOn": "2022-04-15T14:37:06.000Z",
          "wordCount": 240,
          "title": "My first attempt at machine learning. I made a cool chatbot 😎",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u44cma/music_video_about_ai/",
          "author": null,
          "description": "submitted by    /u/starlightinspace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u44cma/music_video_about_ai/",
          "publishedOn": "2022-04-15T09:38:26.000Z",
          "wordCount": 94,
          "title": "Music video about AI",
          "imageUrl": "https://external-preview.redd.it/GI6AWkG-0TEy2ATdKFWfct6AqfWukV-ar7McKxH6IwM.jpg?auto=webp&s=37c294622c81e5552a2c85ac6eaf1f44e7c809f7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u4389w/computational_reasoning_about_incomputability/",
          "author": null,
          "description": "So I would be curious about the theoretical foundations how to make sense of higher-level abstract reasoning like reasoning about infinities, incomputability, truth (which we know cannot be defined due to Tarski) in the field of artificial intelligence. It seems due to Gödel-like constructions you are forced into inconsistent systems of reasoning when operating within a computable system. But those prove everything and \"nothing\", so as far as I understand it, it kind of upends the whole system of reason that the notion of artificial intelligence (and correct functioning of it) is based in.\n Personally due to this I don't see that the notion in the title it is a particularly coherent notion, which means there is somewhat strong limits on what (computable) AI will be able to do. But I would be curious how people that think otherwise (which seem most in the AI community?) approach this. Would you say somehow inconsistency can be avoided, or that despite inconsistency you can get reliably correct results?\n    submitted by    /u/bejaq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u4389w/computational_reasoning_about_incomputability/",
          "publishedOn": "2022-04-15T08:14:03.000Z",
          "wordCount": 1688,
          "title": "Computational reasoning about incomputability, infinity, truth etc (Gödel, Tarski,...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u41hsl/the_best_explanation_of_what_is_machine_learning/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u41hsl/the_best_explanation_of_what_is_machine_learning/",
          "publishedOn": "2022-04-15T06:10:35.000Z",
          "wordCount": 143,
          "title": "The best explanation of What is Machine Learning and How it works? MUST WATCH",
          "imageUrl": "https://external-preview.redd.it/cfWvorMNvuv8TX-JC5njDZlljI54paH5_Kr3qudtGW4.jpg?auto=webp&s=52d3e521696a0323a62d01756a9d0b243f532831"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3z3cl/artificial_nightmares_hills_have_eyes_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3z3cl/artificial_nightmares_hills_have_eyes_clip_guided/",
          "publishedOn": "2022-04-15T03:41:05.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Hills Have Eyes || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/p4BXNlcEh-rjWjf8o0X2MykVw9rL0YzymD1h0ChoayY.jpg?auto=webp&s=2d7a26edc80beaf5e23f9f4d41ce1c2343327ab4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3rraq/questions_to_ask_an_ai/",
          "author": null,
          "description": "i recently played a game called tacoma that had a focus on AI and in the game there was a guide for AI that showed 4 hypotheticals to ask an AI to check it's morality and it got me thinking how useful that would be for a real self-aware intelligence so i want to make a list of questions/hypotheticals to ask AGIs\n if you had to interview a recently created sentient AI what questions or hypotheticals would you give it to gauge it's morality, intelligence, creativity, emotion etc.?\n    submitted by    /u/neonvolta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3rraq/questions_to_ask_an_ai/",
          "publishedOn": "2022-04-14T21:22:13.000Z",
          "wordCount": 178,
          "title": "questions to ask an AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3plf4/youtuber_meets_his_creepy_robot_double_and_freaks/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3plf4/youtuber_meets_his_creepy_robot_double_and_freaks/",
          "publishedOn": "2022-04-14T19:42:40.000Z",
          "wordCount": 104,
          "title": "YouTuber Meets His Creepy Robot Double and Freaks Out",
          "imageUrl": "https://external-preview.redd.it/JD-aqdLfGKSJ4Mopb92GNvhNKdhRB5MzNQvlueiteKg.jpg?auto=webp&s=a174f45d29b95982b0ceb560c1fda0c9dd79a475"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3melc/reference_request_for_applications_of_time_to_ai/",
          "author": null,
          "description": "Does anyone know of any AI papers, books articles etc that discuss using a sense of time to develop AI, (especially real world time)?\n I've come across papers that discuss how having a sense of time seems to play a role in animal cognition (e.g. temporal cognition), and I'm curious to what extent this has influenced the development of AI.\n Thanks in advance\n    submitted by    /u/patterntheoryacc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3melc/reference_request_for_applications_of_time_to_ai/",
          "publishedOn": "2022-04-14T17:13:26.000Z",
          "wordCount": 161,
          "title": "Reference request for applications of time to ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3k4j5/ibm_data_science_and_ai_programs_on_coursera_free/",
          "author": null,
          "description": "submitted by    /u/awsconsultant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3k4j5/ibm_data_science_and_ai_programs_on_coursera_free/",
          "publishedOn": "2022-04-14T15:29:51.000Z",
          "wordCount": 118,
          "title": "IBM Data Science and AI Programs on Coursera Free for 30 Days",
          "imageUrl": "https://external-preview.redd.it/1aFLoCfFdpaBHU_-2UJal-XW54FQmnU4gBFzuh76DJ8.jpg?auto=webp&s=33907ac6c6641de66cb832b81d40f6024a8d96b4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3ipg3/are_you_aware_of_these_ai_ethical_challenges/",
          "author": null,
          "description": "submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3ipg3/are_you_aware_of_these_ai_ethical_challenges/",
          "publishedOn": "2022-04-14T14:24:08.000Z",
          "wordCount": 137,
          "title": "Are you aware of these AI Ethical Challenges?",
          "imageUrl": "https://external-preview.redd.it/aJi9Dz8P0k_F4j63zzdsjmhZLTXVfVYWVwiQByiyL84.jpg?auto=webp&s=aa8556546cd821f61a872c3d317d57475ebd7f58"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3fjo1/synthetic²_can_ai_be_a_powerful_force_for/",
          "author": null,
          "description": "submitted by    /u/thedyezwfl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3fjo1/synthetic²_can_ai_be_a_powerful_force_for/",
          "publishedOn": "2022-04-14T11:41:43.000Z",
          "wordCount": 121,
          "title": "Synthetic²: Can AI Be A Powerful Force For Creation? | SiGMA/AGS UAE 2022",
          "imageUrl": "https://external-preview.redd.it/KUyTb6B5UY12Bia2FVfBQHydK3wxukP_zj2jG7ViKW0.jpg?auto=webp&s=d8329c249afd8a50430cba6fcd0d754ae34f0f31"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3eb72/google_finance_chief_we_automate_everything_that/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3eb72/google_finance_chief_we_automate_everything_that/",
          "publishedOn": "2022-04-14T10:28:50.000Z",
          "wordCount": 112,
          "title": "Google finance chief: \"We automate everything that can be automated\"",
          "imageUrl": "https://external-preview.redd.it/-55QKP4vcE3o9kVUnC9VjFhFYZ2fW8cZwQdZz5VNWPc.jpg?auto=webp&s=d282ce2003a5925aa59eb62de487052812d267fc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u3dxdq/free_webinar_series_automated_cv_pipelines/",
          "author": null,
          "description": "Automated CV Pipelines 3rd part is open for registration. It will be covering the methods of streamlining instance classification. If you are interested to check out, here is the link to register.\n    submitted by    /u/WeekendClassic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u3dxdq/free_webinar_series_automated_cv_pipelines/",
          "publishedOn": "2022-04-14T10:04:39.000Z",
          "wordCount": 140,
          "title": "Free Webinar series | Automated CV Pipelines | Instance Classification",
          "imageUrl": "https://external-preview.redd.it/FrG8ZhL_0BgWpmzXNv_rkXDIZHscArf6l17SMmL9wBM.jpg?auto=webp&s=1b3e438667233a5d90f403ab35eaf354b134eeb2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u34quf/my_ai_writes_music_better_than_humans_worldclass/",
          "author": null,
          "description": "Thirty years it's taken me, A.I. that is not just as good as humans but better than humans at composing music:\n https://i.imgur.com/hReXJq1.png\n It passes the Turing Test, and it is also a revolution in the field of music in and of itself.\n In the meantime, no one has said anything nice to me in thirty years; just insults. I would feel dumb rewarding humanity with my creation; it would send the wrong message; it would affirm their bad behavior. Garbage species. Low IQ.\n    submitted by    /u/PussyFiller2022  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u34quf/my_ai_writes_music_better_than_humans_worldclass/",
          "publishedOn": "2022-04-14T00:33:06.000Z",
          "wordCount": 284,
          "title": "\"My A.I. writes music better than humans. World-class education in A.I. + music -> decades of work -> censored from Facebook, Twitter, soon to be downvoted or unfairly-banned from Reddit. It's making the most beautiful music I've ever heard, and society despises it.\"",
          "imageUrl": "https://external-preview.redd.it/H_rgisj0wmv66uTmVnskqXxnYnWxix0u9dWTkZpGho0.png?auto=webp&s=a17d84988a24214234d26b74cb246cc044bb13cd"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2xaaj/ai_trippy_dream_35_psychedelic_special_request/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2xaaj/ai_trippy_dream_35_psychedelic_special_request/",
          "publishedOn": "2022-04-13T18:43:55.000Z",
          "wordCount": 106,
          "title": "AI Trippy Dream 35 - Psychedelic Special Request",
          "imageUrl": "https://external-preview.redd.it/gk6ZxkhKhv55HjlOSIvWKIRDH0MmJsbj__-x9oV0RNw.jpg?auto=webp&s=c0c54a7043f63700e28261f90529045c7878d616"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2v7il/ohio_state_university_researchers_develop/",
          "author": null,
          "description": "3D landscape modeling has seen a rise in its popularity and applications in recent years. It has countless applications in the fields of civil engineering, earth sciences, military applications, and many others. Geometric 3D models are typically developed using the city geography markup language (CityGML), and the Level-of-Detail (LoD) building model is the preferred model for building 3D models using CityGML. \n The use of Satellite imagery for landscape modeling provides the advantage of covering a wide area and is low cost. However, developing LoD2 models using satellite imagery remains a big challenge. Building models in such a way involves complex steps demanding heuristics-based approaches and ML-based detection paradigms.\n In a recent paper, researchers at the Ohio State University propose a SAT2LoD2 to facilitate the development of 3D landscape models. SAT2LoD2 is an open-source, python-based GUI-enabled software that takes the satellite images as inputs and returns LoD2 building models as outputs. The software also has the feature of taking road networks and custom maps as additional inputs for better results.\n Continue Reading\n Paper: https://arxiv.org/pdf/2204.04139v1.pdf\n Github: https://github.com/gdaosu/lod2buildingmodel\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2v7il/ohio_state_university_researchers_develop/",
          "publishedOn": "2022-04-13T17:10:48.000Z",
          "wordCount": 298,
          "title": "Ohio State University Researchers Develop SAT2LoD2: An Open-Source Python Tool For 3D Landscape Modelling Using Satelite Imagery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2rp6f/are_there_ais_which_are_able_to_simulate_a_human/",
          "author": null,
          "description": "submitted by    /u/TheblackRook3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2rp6f/are_there_ais_which_are_able_to_simulate_a_human/",
          "publishedOn": "2022-04-13T14:33:35.000Z",
          "wordCount": 230,
          "title": "Are there AIs which are able to simulate a human body when you shoot/hit it, that you can use for video games?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2o9jd/digital_folktales_a_collection_of_short_stories/",
          "author": null,
          "description": "submitted by    /u/fabianmosele  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2o9jd/digital_folktales_a_collection_of_short_stories/",
          "publishedOn": "2022-04-13T11:35:38.000Z",
          "wordCount": 274,
          "title": "Digital Folktales, a collection of short stories about internet folklore, written and illustrated by Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2mqwe/httpsyoutube0x0to1wnh6s/",
          "author": null,
          "description": "https://youtu.be/0x0to1wNh6s A new enterprise project model supported by AI. In the near future, the growing introduction of automation and artificial intelligence will require the updating of most of the activities in the production world, along with changes to contracts, tasks, and integration processes between man and machine.\n This is supported by the Accenture \"IT's Learning\" study, according to which 81% of jobs will suffer the impact of AI and robotization.\n    submitted by    /u/neologos52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2mqwe/httpsyoutube0x0to1wnh6s/",
          "publishedOn": "2022-04-13T09:55:13.000Z",
          "wordCount": 151,
          "title": "https://youtu.be/0x0to1wNh6s",
          "imageUrl": "https://external-preview.redd.it/O9w2xBm-UxxibPkAmvu3jFMkw7CPiqE1Edn1NZ5nAxI.jpg?auto=webp&s=90452827055732e7004a39aa3f84b5f1211433b0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2ljhp/how_to_improve_your_video_editing_software_with_ai/",
          "author": null,
          "description": "submitted by    /u/tah_zem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2ljhp/how_to_improve_your_video_editing_software_with_ai/",
          "publishedOn": "2022-04-13T08:24:42.000Z",
          "wordCount": 109,
          "title": "How to improve your video editing software with AI?",
          "imageUrl": "https://external-preview.redd.it/RRTz2Zi0b1vz0vjA751W62yeZD4DKII-F7OQ0ZUbzlA.jpg?auto=webp&s=5cd9a843bb0b445e86015a52db60f4e65adea799"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2j0rc/top_ethical_challenges_in_ai_the_price_of_progress/",
          "author": null,
          "description": "What does 2022 look like for AI? Let's find out.\n https://us.sganalytics.com/blog/top-ethical-challenges-in-ai-the-price-of-progress/\n    submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2j0rc/top_ethical_challenges_in_ai_the_price_of_progress/",
          "publishedOn": "2022-04-13T05:26:01.000Z",
          "wordCount": 128,
          "title": "Top Ethical Challenges in AI – The Price of Progress",
          "imageUrl": "https://external-preview.redd.it/gpojHrxBRiyNRtS4dowCf62GHN0syOExlU8hVfJ3XUs.jpg?auto=webp&s=23fcb4c3ce2f7f5aa36daead94f7b8531000bfa7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2izci/bias_in_artificial_intelligence_is_diversity_the/",
          "author": null,
          "description": "submitted by    /u/JencyJane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2izci/bias_in_artificial_intelligence_is_diversity_the/",
          "publishedOn": "2022-04-13T05:23:30.000Z",
          "wordCount": 123,
          "title": "Bias in Artificial Intelligence: Is Diversity the Key to the Future Of AI?",
          "imageUrl": "https://external-preview.redd.it/vSHEsxJEzECGoypD5rhq7wBOngKsC9vurWNBBGUbDOM.jpg?auto=webp&s=a7f5bafac32d2470bd24918b8a91511310f69ba8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2ityj/wrote_about_knn_introduction_to_datascience_book/",
          "author": null,
          "description": "submitted by    /u/mindaslab  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2ityj/wrote_about_knn_introduction_to_datascience_book/",
          "publishedOn": "2022-04-13T05:13:37.000Z",
          "wordCount": 119,
          "title": "Wrote about KNN — Introduction to DataScience Book",
          "imageUrl": "https://external-preview.redd.it/UyyElOGMIRa2sLJKVEfwy-3UVCutwVfgVS5gP91ux5Q.jpg?auto=webp&s=2dd0f05c3cb162a0849f7658cd298d5bd23c0951"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u2e7nz/how_to_create_scenes_with_text_makeascene/",
          "author": null,
          "description": "The authors of Make-A-Scene propose a novel text-to-image method that leverages the information from an additional input condition called a “scene” in the form of segmentation tokens to improve the quality of generated images and enable scene editing, out-of-distribution prompts, and text-editing of anchor scenes.\n As for the details, let’s dive in, shall we?\n Full summary: https://t.me/casual_gan/284\n Blog post: https://www.casualganpapers.com/text-to-image-vqvae-scene-generation/Make-A-Scene-explained.html\n Make-A-Scene\n arxiv / code (by Casual GAN Papers Community)\n Join the discord community and follow on Twitter for weekly AI paper summaries!\n    submitted by    /u/KirillTheMunchKing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u2e7nz/how_to_create_scenes_with_text_makeascene/",
          "publishedOn": "2022-04-13T01:03:22.000Z",
          "wordCount": 218,
          "title": "How to create scenes with text - Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors, a 5-minute paper summary by Casual GAN Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u29wzk/how_to_win_a_kaggle_competition_with_bayesian/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u29wzk/how_to_win_a_kaggle_competition_with_bayesian/",
          "publishedOn": "2022-04-12T21:26:47.000Z",
          "wordCount": 104,
          "title": "How to Win a Kaggle Competition with Bayesian Optimization",
          "imageUrl": "https://external-preview.redd.it/i6niOaeH1H7kZRbr_ONzY7uYdsMOHUw526WwWQ8oFqg.jpg?auto=webp&s=eb576c954e2b80ed6623f8c373e80ee8a5126fe5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u29rv7/should_i_use_a_encoder_decoder_cnn/",
          "author": null,
          "description": "I'm trying to make a model to play a car racing simulator. I have a dataset with the inputs used(human) to get fast lap times. I would like to make a model that reads the game video output and predicts the arrow key inputs to get a fast lap time. It seems, to me, that a CNN with encoder-decoder layers trained on the keyboard inputs would work. Is this a good architecture? I'm also having a hard time finding useful literature.\n please let me know if there is anything I should look into or do differently.\n    submitted by    /u/newroadkill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u29rv7/should_i_use_a_encoder_decoder_cnn/",
          "publishedOn": "2022-04-12T21:20:03.000Z",
          "wordCount": 241,
          "title": "Should I use A Encoder Decoder CNN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u25gk5/top_trends_predictions_that_will_drive_data/",
          "author": null,
          "description": "submitted by    /u/saik2363  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u25gk5/top_trends_predictions_that_will_drive_data/",
          "publishedOn": "2022-04-12T18:10:01.000Z",
          "wordCount": 151,
          "title": "Top Trends & Predictions That Will Drive Data Science, AI and Machine Learning in 2022",
          "imageUrl": "https://external-preview.redd.it/uxos6jmEaCtivJ0FgS-8bLsqqeEbLdwoIEnZLY1TjnE.jpg?auto=webp&s=e9764303f85277456f10677ea014b626fb0c93d0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u253tu/last_week_in_ai_openai_dalle_2_generates_amazing/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u253tu/last_week_in_ai_openai_dalle_2_generates_amazing/",
          "publishedOn": "2022-04-12T17:54:43.000Z",
          "wordCount": 154,
          "title": "Last Week in AI: OpenAI DALL-E 2 generates amazing images, Google's 540 billion parameters language model, Clearview AI branches out beyond police, and more!",
          "imageUrl": "https://external-preview.redd.it/rBnukFeFRRsgZhCZ_f1m_LXOmR4MDVW----yHLSQXo0.jpg?auto=webp&s=9ad4f7e7fb0af5151957861742f68cfa2d784088"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u250fy/top_trends_predictions_that_will_drive_data/",
          "author": null,
          "description": "submitted by    /u/saik2363  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u250fy/top_trends_predictions_that_will_drive_data/",
          "publishedOn": "2022-04-12T17:50:32.000Z",
          "wordCount": 115,
          "title": "Top Trends & Predictions That Will Drive Data Science in 2022",
          "imageUrl": "https://external-preview.redd.it/uxos6jmEaCtivJ0FgS-8bLsqqeEbLdwoIEnZLY1TjnE.jpg?auto=webp&s=e9764303f85277456f10677ea014b626fb0c93d0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24thn/conversation_about_the_future_life_and_agi/",
          "author": null,
          "description": "submitted by    /u/HumanSeeing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24thn/conversation_about_the_future_life_and_agi/",
          "publishedOn": "2022-04-12T17:41:48.000Z",
          "wordCount": 182,
          "title": "Conversation about the future, life and AGI",
          "imageUrl": "https://external-preview.redd.it/SjkfJE2ITOQtJz-UAAMZoybqTKz9WErvN06qY5kTo4U.jpg?auto=webp&s=1d1163be7ab6f5d6817bd00ee06a10a966641a7f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24o8c/ai_predicts_if_and_when_someone_will_experience/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24o8c/ai_predicts_if_and_when_someone_will_experience/",
          "publishedOn": "2022-04-12T17:35:18.000Z",
          "wordCount": 107,
          "title": "AI predicts if and when someone will experience cardiac arrest",
          "imageUrl": "https://external-preview.redd.it/AZr6mjXx5oaYv9BY-bl-_DeVufpiaTXtTpW1kb_d_vo.jpg?auto=webp&s=77a9a6eea067dc66299de5f19e5c5a65a72c6623"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24d2o/the_last_woolly_mammoth_on_earth/",
          "author": null,
          "description": "submitted by    /u/Ok-Passion-6574  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24d2o/the_last_woolly_mammoth_on_earth/",
          "publishedOn": "2022-04-12T17:22:09.000Z",
          "wordCount": 123,
          "title": "The last Woolly Mammoth on Earth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u24c4v/the_last_woolly_mammoth_on_earth/",
          "author": null,
          "description": "Is it good or bad?\n Also, I was wondering what art goes big as an NFT?\n    submitted by    /u/Ok-Passion-6574  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u24c4v/the_last_woolly_mammoth_on_earth/",
          "publishedOn": "2022-04-12T17:21:01.000Z",
          "wordCount": 116,
          "title": "The last Woolly Mammoth on Earth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u238lt/stanford_researchers_introduced_a_novel_deep/",
          "author": null,
          "description": "In recent years, the rise of Deep Learning has continuously brought innovations to many fields, and the medical domain is one of them. AI applications in this field are countless: from pre-operative diagnosis to disease classification, from skill assessment to post-operative rehabilitation. Among them, systems to assess surgical skills and provide feedback to improve technique could help in decreasing the number of complications in surgical procedures, which are still the third leading cause of death globally.\n AI can be an additional coach for surgical trainees and an expert colleague for experienced surgeons. But, to train an AI system, reliable data are fundamental. The more utilized type of data in this context is undoubtedly video streams, as a camera is less invasive than other types of sensors, such as ArmBand or EEG, which could weigh on the surgeon’s performance given their physical bulk. This applies particularly to laparoscopic surgery, where an in-body fiber-optic camera is used to visualize the operating area and facilitate rapid data collection. For this reason, the majority of computer-assisted systems focus on laparoscopic surgery. \n Continue Reading\n Paper: https://arxiv.org/pdf/2112.07219.pdf\n https://preview.redd.it/84mwdw81l4t81.png?width=741&format=png&auto=webp&s=636aff067560876d14f37caccb83bd951e991c68\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u238lt/stanford_researchers_introduced_a_novel_deep/",
          "publishedOn": "2022-04-12T16:33:55.000Z",
          "wordCount": 321,
          "title": "Stanford Researchers Introduced a Novel Deep Learning Computer-Assisted System for Real-Time Open Surgery and AVOS (the Annotation Videos of Open Surgery) Dataset￼",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1xifd/machine_learning_vs_cookie_consent_systems/",
          "author": null,
          "description": "submitted by    /u/DaveBowman1975  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1xifd/machine_learning_vs_cookie_consent_systems/",
          "publishedOn": "2022-04-12T12:06:37.000Z",
          "wordCount": 97,
          "title": "Machine Learning vs. Cookie Consent Systems",
          "imageUrl": "https://external-preview.redd.it/PMjj3Hxgb1MZWV7XRZ_kgdqRgkA9AeKnjPvYXQr_d48.jpg?auto=webp&s=1197d6e09bc19acfc3c8fcfe8bd6d548c332e8a5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1qrrz/artificial_nightmares_stone_golem_ruins_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1qrrz/artificial_nightmares_stone_golem_ruins_clip/",
          "publishedOn": "2022-04-12T04:52:32.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Stone Golem Ruins || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1nch6/my_epiphany_on_synthetic_media_five_years_later/",
          "author": null,
          "description": "Roughly five years ago, I created this thread where I outlined my realization about the imminency of synthetic media. \n This was before transformers blew up, before StyleGAN, before GPT-2, when WaveNet and DeepDream were still among the best we could do, and when predictive text algorithms that were barely better than Markov Chains were still the state of the art. In five short years, the state of artificial intelligence has changed overwhelmingly, to the point it's barely recognizable. Looking back to 2017, I now get this sense of everything feeling so primitive and fake. I've stated many times that AI before roughly 2019 was a bunch of digital magic tricks, and the field as a whole was essentially a giant Potemkin village that utilized clever sleight of hand and advertising to make it se…",
          "link": "https://www.reddit.com/r/artificial/comments/u1nch6/my_epiphany_on_synthetic_media_five_years_later/",
          "publishedOn": "2022-04-12T01:34:42.000Z",
          "wordCount": 2147,
          "title": "My epiphany on synthetic media five years later, and what I feel is coming within the next five years",
          "imageUrl": "https://external-preview.redd.it/Qw_b3WctdsuxoiTXSxJW4-cE-Qf8c39bMr7KiWVJvzg.jpg?auto=webp&s=83437281a72546beac3e81d166d0c7aea99d7656"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1hmjr/ai_when_given_the_prompt_of_amy_schumer_on/",
          "author": null,
          "description": "submitted by    /u/9YearOldGeneralOfPew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1hmjr/ai_when_given_the_prompt_of_amy_schumer_on/",
          "publishedOn": "2022-04-11T21:06:07.000Z",
          "wordCount": 179,
          "title": "AI when given the prompt of “Amy Schumer” on wombo.art",
          "imageUrl": "https://preview.redd.it/w20dieensys81.jpg?auto=webp&s=506e93a434324e476b6ad2edcc717a7f60138aca"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1bsev/ai_news_new_robot_fingertips_can_feel_ai_tracking/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1bsev/ai_news_new_robot_fingertips_can_feel_ai_tracking/",
          "publishedOn": "2022-04-11T16:35:12.000Z",
          "wordCount": 136,
          "title": "AI News: New Robot Fingertips Can Feel | AI Tracking Satellite | SingularityDAO DynaSets | Tesla Optimus Specs",
          "imageUrl": "https://external-preview.redd.it/IJ3DYv7YRvxVI-qnhf5HgyM38jrjKf2sY4zbfHUc1eQ.jpg?auto=webp&s=dfe8a2bcf5e9b2415dec6216bd7b71f0bddaf636"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1bbmu/a_quick_highlevel_overview_of_diffusion_models/",
          "author": null,
          "description": "submitted by    /u/individual_kex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1bbmu/a_quick_highlevel_overview_of_diffusion_models/",
          "publishedOn": "2022-04-11T16:14:03.000Z",
          "wordCount": 112,
          "title": "a quick high-level overview of diffusion models (like dall-e 2)",
          "imageUrl": "https://external-preview.redd.it/w2vK34OVhWDouYrUsiiDq8_GHTjtXAP8B8jvvDtszpE.jpg?auto=webp&s=77723950cd9de615ccefb197fe42e27ce31943c5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u1ae67/how_can_i_train_an_ai_to_write_articles_based_on/",
          "author": null,
          "description": "Hi all!\n As a sort of art experiment, I want to train an AI to write tech news articles based on my own work.\n I worked as a freelance writer for several years and have thousands of articles (each as a Word doc) on tech news.\n I want to use those articles to train the AI, then have it generate new articles to post to a blog. I have a pretty good understanding of machine learning, but have never trained a model myself. I'm hoping you all can provide some direction. Some specific questions:\n  \nCan you recommend a model?\n For each training article, can I provide a \"source\" (like another news article) so the AI understands where the content in the training article came from? *\n For each generated article, can I provide a news article source for it to base its content on? **\n Can I use the Word docs as the training set, or do I need to convert them into something else for training?\n  \n*as an example: If I wrote an article on the release of a new Raspberry Pi board, my source might be the press release on the Raspberry Pi website.\n **as an example: If I want it to generate an article about a new drone delivery service, my input source might be a news article on Reuters or something.\n    submitted by    /u/TheSerialHobbyist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u1ae67/how_can_i_train_an_ai_to_write_articles_based_on/",
          "publishedOn": "2022-04-11T15:30:04.000Z",
          "wordCount": 443,
          "title": "How can I train an AI to write articles based on my own work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u18lrc/are_there_any_open_source_video_ads_generation/",
          "author": null,
          "description": "Hey is there any models to generate videos for advertisment either as text-to-video images-to-video or video-variation creation, if not would video variation generative models would be a good fit for create ads ??\n    submitted by    /u/National-Departure78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u18lrc/are_there_any_open_source_video_ads_generation/",
          "publishedOn": "2022-04-11T14:07:58.000Z",
          "wordCount": 142,
          "title": "are there any open source video ads generation model out there?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u179b4/dalle_2_the_future_of_ai_research_and_openais/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u179b4/dalle_2_the_future_of_ai_research_and_openais/",
          "publishedOn": "2022-04-11T13:02:20.000Z",
          "wordCount": 115,
          "title": "DALL-E 2, the future of AI research, and OpenAI’s business model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u163kr/how_do_i_learn_artificial_intelligence_from_the/",
          "author": null,
          "description": "Is there any resources which has example driven explanations, from scratch or basics? I have seen some websites just jumping into \"use this module/library\" Without explaining what it does or how it works, just some basic examples so that i can build on top or experiment by my own.\n    submitted by    /u/-1Mbps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u163kr/how_do_i_learn_artificial_intelligence_from_the/",
          "publishedOn": "2022-04-11T12:00:30.000Z",
          "wordCount": 152,
          "title": "how do i learn artificial intelligence from the basics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u14op0/using_the_neat_algorithm_to_teach_elves_to/",
          "author": null,
          "description": "submitted by    /u/zuparnowa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u14op0/using_the_neat_algorithm_to_teach_elves_to/",
          "publishedOn": "2022-04-11T10:35:25.000Z",
          "wordCount": 111,
          "title": "Using the NEAT algorithm to teach elves to deliver presents",
          "imageUrl": "https://external-preview.redd.it/pQvfhtGjnKMzycbiqvHN4XRSuhuH5GAHi1Bq1ja_uF0.jpg?auto=webp&s=023c88f4bbd22057c9b6254dbca4d68d93c0feb2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u13z0g/trippy_ai_dream_16_gothic_style_jungle_fever/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u13z0g/trippy_ai_dream_16_gothic_style_jungle_fever/",
          "publishedOn": "2022-04-11T09:47:54.000Z",
          "wordCount": 135,
          "title": "Trippy AI Dream 16 - Gothic Style Jungle Fever - VQGAN CliP Rife-Rea...",
          "imageUrl": "https://external-preview.redd.it/BQgAMoUmekQwCr6Z6VOCsa9A5rxWfKKX28fDREnMmhA.jpg?auto=webp&s=eca8da4430ed4cfb20f19d4d5747810ae4bbbac2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u13x95/trippy_ai_dream_23_flower_power²_vqgan_clip/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u13x95/trippy_ai_dream_23_flower_power²_vqgan_clip/",
          "publishedOn": "2022-04-11T09:44:31.000Z",
          "wordCount": 112,
          "title": "Trippy AI Dream 23 - Flower Power² VQGAN CliP Rife-RealESRGAN",
          "imageUrl": "https://external-preview.redd.it/aX2FzWwHZbUUhLer7hbRuZRPmOH961qHHoQKGF_oxos.jpg?auto=webp&s=c141b203101a20795ddf3f1f0488efa6c1004e00"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u13waw/trippy_ai_dream_32_we_reached_100_subscribers/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u13waw/trippy_ai_dream_32_we_reached_100_subscribers/",
          "publishedOn": "2022-04-11T09:42:36.000Z",
          "wordCount": 112,
          "title": "Trippy AI Dream 32 - WE REACHED 100 SUBSCRIBERS !!",
          "imageUrl": "https://external-preview.redd.it/DWXJUGFtSAOvN0iCeVcZcCHqETmlEXdOM81Sdfvw-WA.jpg?auto=webp&s=52f02cadaf392f974d5cf94d02d0f2c84241fa0b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u12gyu/mindspore_has_implemented_a_visibleinfrared/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u12gyu/mindspore_has_implemented_a_visibleinfrared/",
          "publishedOn": "2022-04-11T08:00:07.000Z",
          "wordCount": 129,
          "title": "MindSpore has implemented a visible-infrared recognition algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u10am1/i_want_to_learn_ai_from_beginning_from_where_can/",
          "author": null,
          "description": "submitted by    /u/Late_Illustrator_545  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u10am1/i_want_to_learn_ai_from_beginning_from_where_can/",
          "publishedOn": "2022-04-11T05:26:45.000Z",
          "wordCount": 190,
          "title": "I want to learn AI From beginning ? from where can i start?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0z8uu/baidu_researchers_propose_ppyoloe_object_detector/",
          "author": null,
          "description": "Object detection is a crucial problem in computer vision, and YOLO (You Only Look Once) one-stage object detectors have set the bar for performance since the release of YOLOv1 in 2015. The YOLO series has undergone considerable network and structural improvements over the years. The most recent version, YOLOX, has attained an optimal balance of speed and accuracy on the NVIDIA Tesla V100 Tensor Core GPU.\n Baidu researchers have improved their earlier PP-YOLOv2 model, resulting in PP-YOLOE, a cutting-edge industrial object detector that beats YOLOv5 and YOLOX in speed and accuracy trade-off. The team’s PP-YOLOE-l variant outperforms PP-YOLOv2 by 1.9 percent AP and YOLOX-l by 1.3 percent AP on COCO datasets.\n The PP-YOLOv2 baseline model architecture comprises a ResNet50-vd backbone with deformable convolution, a PAN neck with an SPP layer and DropBlock, and a lightweight IoU aware head. PP-YOLOv2 assigns only one anchor box to each ground truth object, similar to YOLOv3. It is strongly reliant on hand-crafted design, which may not generalize well enough when trained on other datasets. Conversely, this technique necessitates a lot of additional hyperparameters.\n To overcome this problem, Baidu researchers have added an anchor-free technique to PP-YOLOv2 that tiles one anchor point on each pixel and assigns upper and lower bounds for detecting heads to assign ground facts to a matching feature map. The center of a bounding box can then be determined to choose positive samples from the closest pixels. A 4D vector is also predicted for regression, with minor model speedups and precision losses due to the changes.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.16250.pdf\n Github: https://github.com/PaddlePaddle/PaddleDetection\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0z8uu/baidu_researchers_propose_ppyoloe_object_detector/",
          "publishedOn": "2022-04-11T04:21:10.000Z",
          "wordCount": 379,
          "title": "Baidu Researchers Propose PP-YOLOE Object Detector: an Evolved Version of YOLO Achieving SOTA Performance in Object Detection",
          "imageUrl": "https://external-preview.redd.it/YIdT_LdqfVTuy7yyjPt2X_n2bCd2qhQ430hCN7qIiyU.jpg?auto=webp&s=f1d8bd53f7d32a540e585374e33fd9d0f4acb9df"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0xayx/song_writing_ai/",
          "author": null,
          "description": "Hi all, \n I’m hoping someone could point me in The direction of an AI that I could dump all my previous song writing into that would spit out something \"inspired by’ it.\n Mostly a bit of fun but interested in seeing what it throws back out at me.\n thanks in advance for any hot tips.\n    submitted by    /u/doccaballero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0xayx/song_writing_ai/",
          "publishedOn": "2022-04-11T02:29:33.000Z",
          "wordCount": 174,
          "title": "Song writing Ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0sirs/trippy_ai_dream_30_howls_moving_castle/",
          "author": null,
          "description": "submitted by    /u/LordPewPew777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0sirs/trippy_ai_dream_30_howls_moving_castle/",
          "publishedOn": "2022-04-10T22:16:54.000Z",
          "wordCount": 118,
          "title": "Trippy AI Dream 30 - Howl's Moving Castle Post-Apocalyptic War Scenes VQ...",
          "imageUrl": "https://external-preview.redd.it/40JMat2aU_r-HlgLCjxGvBIjZCDMrZ69iDj0_v2GntM.jpg?auto=webp&s=4551c9c144fab51639da9138a5c4c1b2a99c123b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0ppb8/is_there_a_ai_which_can_turn_images_into_simple/",
          "author": null,
          "description": "So that the wrinkles and shadows are removed, etc.\n    submitted by    /u/xXNOdrugsForMEXx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0ppb8/is_there_a_ai_which_can_turn_images_into_simple/",
          "publishedOn": "2022-04-10T20:02:04.000Z",
          "wordCount": 136,
          "title": "Is there a AI which can turn images into simple versions of the original image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0pbar/the_singularity_is_now/",
          "author": null,
          "description": "submitted by    /u/ManandMultiverse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0pbar/the_singularity_is_now/",
          "publishedOn": "2022-04-10T19:44:09.000Z",
          "wordCount": 113,
          "title": "The Singularity is Now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0gfx7/ai_graphics_design_your_dream_body_with_a_slider/",
          "author": null,
          "description": "submitted by    /u/much_successes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0gfx7/ai_graphics_design_your_dream_body_with_a_slider/",
          "publishedOn": "2022-04-10T12:19:26.000Z",
          "wordCount": 173,
          "title": "AI Graphics: Design your dream body with a slider",
          "imageUrl": "https://external-preview.redd.it/iYml__MlOjvasx20eOcqJ2R0bfsJj6_nEJ6Dg4cstes.jpg?auto=webp&s=fe123f458b4140d47ea4d9113cca4f27378a14dc"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u0bbal/does_ai_exist_that_takes_an_image_of_a_real/",
          "author": null,
          "description": "submitted by    /u/NootropicLove  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u0bbal/does_ai_exist_that_takes_an_image_of_a_real/",
          "publishedOn": "2022-04-10T05:55:26.000Z",
          "wordCount": 125,
          "title": "Does AI exist that takes an image of a real person and edit/generate photos of them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u04lwl/ran_3d_art_of_my_ai_character_thru_arcanegan_ai/",
          "author": null,
          "description": "submitted by    /u/alex-redacted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u04lwl/ran_3d_art_of_my_ai_character_thru_arcanegan_ai/",
          "publishedOn": "2022-04-09T23:04:12.000Z",
          "wordCount": 139,
          "title": "Ran 3D art of my AI character thru ArcaneGAN; AI making art of AI.",
          "imageUrl": "https://preview.redd.it/fdijdzsn3ls81.png?auto=webp&s=46e80b998b44c6376ca228789e4a801c4db2835e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/u02dby/new_technology_old_problems_the_missing_voices_in/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/u02dby/new_technology_old_problems_the_missing_voices_in/",
          "publishedOn": "2022-04-09T21:09:04.000Z",
          "wordCount": 115,
          "title": "New Technology, Old Problems: The Missing Voices in Natural Language Processing",
          "imageUrl": "https://external-preview.redd.it/aCFFte1ngYO7W4TDBUxX36yna0MktPGAbUpyRIEkZ4o.jpg?auto=webp&s=a09792b7388a17592cb79209a418b1541b3d2f94"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzzoky/check_out_this_deepminds_new_language_model/",
          "author": null,
          "description": "https://preview.redd.it/pkrbloq8vjs81.png?width=1422&format=png&auto=webp&s=fef693165a6c948f626de613e4e341c25f8cf5f4\n ​\n Extreme-scale language models have recently exhibited incredible performance on natural language processing challenges. This is due to their ever-increasing size, exceeding 500 billion parameters. However, while these models have grown in popularity in recent years, the amount of data utilized to train them has not increased. The current generation of huge language models is clearly undertrained. Three prediction approaches for optimally choosing both model size and training length have been proposed by a DeepMind research team.\n Three approaches have been mentioned to estimate the optimal parameter:\n  \nChange the size of the models and the number of training tokens.\n IsoFLOP profiles\n Using a parametric loss function to fit a model\n  \nThe ultimate pretraining loss is calculated as the number of model parameters and training tokens. They minimize the loss function under the restriction of the FLOPs function, which is equal to the computational budget because the computational budget is a probabilistic function of the number of observed training tokens and model parameters.\n Continue Reading This Research Summary\n Paper: https://arxiv.org/pdf/2203.15556.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzzoky/check_out_this_deepminds_new_language_model/",
          "publishedOn": "2022-04-09T18:53:20.000Z",
          "wordCount": 357,
          "title": "Check Out This DeepMind’s New Language Model, Chinchilla (70B Parameters), Which Significantly Outperforms Gopher (280B) and GPT-3 (175B) on a Large Range of Downstream Evaluation Tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzutk1/flaming_rose_art_made_with_snowpixelapp_using_ai/",
          "author": null,
          "description": "submitted by    /u/AIWORQART  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzutk1/flaming_rose_art_made_with_snowpixelapp_using_ai/",
          "publishedOn": "2022-04-09T14:54:12.000Z",
          "wordCount": 103,
          "title": "Flaming Rose art made with snowpixelapp using AI.",
          "imageUrl": "https://preview.redd.it/fhzy6cdkois81.png?auto=webp&s=d938ada6216f9f722408f57cb8b8399d7757c649"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzt8s2/how_do_you_start_a_professional_career_in_the/",
          "author": null,
          "description": "I'm about to graduate with a master's degree in Computer Science and I'm very passionate about Affective Computing. I would like to start looking for a job in this field, but most companies (not consulting) are looking for people with experience or a PhD. What do you recommend me to do? Continue with the PhD or try to find something, maybe in some startup?\n    submitted by    /u/_rikya_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzt8s2/how_do_you_start_a_professional_career_in_the/",
          "publishedOn": "2022-04-09T13:30:47.000Z",
          "wordCount": 176,
          "title": "How do you start a professional career in the Affective Computing field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzpknc/deep_learning_to_enable_color_vision_in_the_dark/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzpknc/deep_learning_to_enable_color_vision_in_the_dark/",
          "publishedOn": "2022-04-09T09:21:28.000Z",
          "wordCount": 109,
          "title": "Deep learning to enable color vision in the dark",
          "imageUrl": "https://external-preview.redd.it/aj9cripQrjAIk9HtPGuEJtE9hcmLnAYSn3Q0aHyRj8s.jpg?auto=webp&s=f9a3fab8879e834cda8bd888bdb7814c1e52ada1"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzoq8s/laptop_for_beginner/",
          "author": null,
          "description": "I'm joining MSc AI & ML this September. I want to buy a laptop. Is MacBook Air sufficient for this? If not what would you recommend to someone like me?\n    submitted by    /u/RauhanSheikh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzoq8s/laptop_for_beginner/",
          "publishedOn": "2022-04-09T08:16:21.000Z",
          "wordCount": 232,
          "title": "Laptop for beginner?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzmyzt/how_can_i_help_the_advancement_of_ai_i_want_to/",
          "author": null,
          "description": "Please give a thorough and in-depth response.\n    submitted by    /u/trillswan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzmyzt/how_can_i_help_the_advancement_of_ai_i_want_to/",
          "publishedOn": "2022-04-09T06:07:36.000Z",
          "wordCount": 329,
          "title": "How can I help the advancement of AI? I want to contribute and make this my career. What should I do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzdoaq/responsible_ai_in_a_global_context/",
          "author": null,
          "description": "submitted by    /u/john133435  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzdoaq/responsible_ai_in_a_global_context/",
          "publishedOn": "2022-04-08T21:21:21.000Z",
          "wordCount": 100,
          "title": "Responsible AI in a Global Context",
          "imageUrl": "https://external-preview.redd.it/BfbeVK2uIIiWcFDmrjddKk8N7im5PD2YwYs7ANBXc_I.jpg?auto=webp&s=512d23af429e73ab0715983c9112cd0ba2aa31af"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzc7xd/ai_website_that_transitions_photos_into_video/",
          "author": null,
          "description": "Remember using a website like a year ago, where you could put in 2 or more images, and it would sort of make a transition between the two with AI. Then you could export the video and such. You could also very extensively edit human faces and change small features on a scale from 1-100. The features where incredibly specific like brow bone and nasal bridge.\n If anyone has the website I would appreciate it!!\n    submitted by    /u/yungbenz0_bajs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzc7xd/ai_website_that_transitions_photos_into_video/",
          "publishedOn": "2022-04-08T20:12:03.000Z",
          "wordCount": 171,
          "title": "AI website that transitions photos into video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzai2l/how_artificial_intelligence_is_impacting_todays/",
          "author": null,
          "description": "submitted by    /u/mr_j_b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzai2l/how_artificial_intelligence_is_impacting_todays/",
          "publishedOn": "2022-04-08T18:51:33.000Z",
          "wordCount": 103,
          "title": "How Artificial Intelligence Is Impacting Today’s Businesses",
          "imageUrl": "https://external-preview.redd.it/WUT9SjRwWRAkjVoTCddYEkGYn606GEt4huUYdaozB7A.jpg?auto=webp&s=b34e8f14f62739c1a304ab71d81afe7e982927d2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tzahgt/alibabas_ai_tool_to_improve_efficiency_of_chinas/",
          "author": null,
          "description": "submitted by    /u/mr_j_b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tzahgt/alibabas_ai_tool_to_improve_efficiency_of_chinas/",
          "publishedOn": "2022-04-08T18:50:44.000Z",
          "wordCount": 112,
          "title": "Alibaba’s AI tool to improve efficiency of China’s waste-to-energy plants",
          "imageUrl": "https://external-preview.redd.it/64MBzPrtFfHw65CUOZLfttJor5oH-vvUQB2ahAu5Jys.jpg?auto=webp&s=18a956e62646aef3240c558fea9b1b6696934e57"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz9gyq/best_gan_for_tabulardata/",
          "author": null,
          "description": "What in your opinion is the best GAN for tabular-data. Please include any references if you have any.\n    submitted by    /u/ily_jk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz9gyq/best_gan_for_tabulardata/",
          "publishedOn": "2022-04-08T18:03:19.000Z",
          "wordCount": 106,
          "title": "Best GAN for Tabular-data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz8xvn/supercharged_ui_for_mlflow/",
          "author": null,
          "description": "Hi guys, we've built a plugin that seamlessly reads MLflow logs and provides a beautiful UI to compare multiple runs with just a few clicks. You can:\n  \nfilter runs with a super versatile fully pythonic search\n group and aggregate your metrics / images\n  \nWe are trying make it work seamlessly with MLflow and complement its other awesome features 🎉\n Here is more info about it https://aimstack.io/aimlflow Would love your feedback!!\n    submitted by    /u/ManeSa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz8xvn/supercharged_ui_for_mlflow/",
          "publishedOn": "2022-04-08T17:38:40.000Z",
          "wordCount": 159,
          "title": "Supercharged UI for MLflow",
          "imageUrl": "https://external-preview.redd.it/BSsU0ETo7_xF2yrAvvkhPwSBIDUw-Stt-CAobPA4VzI.jpg?auto=webp&s=c909beb5d4800b279075a4941f4decbcb2614adf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz8izm/takeaways_from_3_years_working_in_machine_learning/",
          "author": null,
          "description": "submitted by    /u/elcric_krej  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz8izm/takeaways_from_3_years_working_in_machine_learning/",
          "publishedOn": "2022-04-08T17:19:30.000Z",
          "wordCount": 106,
          "title": "Takeaways From 3 Years Working In Machine Learning",
          "imageUrl": "https://external-preview.redd.it/2saqmO0fa_NBQMiR3s4MXN3UOE3VQ9YbXCvmjtj4kQM.jpg?auto=webp&s=e0c6e5e91b619935307ceb9f2f15d940345a3d35"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz5xqi/openai_s_new_model_dalle_2_is_amazing/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz5xqi/openai_s_new_model_dalle_2_is_amazing/",
          "publishedOn": "2022-04-08T15:21:22.000Z",
          "wordCount": 168,
          "title": "OpenAI 's new model DALL·E 2 is amazing!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz31sv/the_ai_in_a_jar/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz31sv/the_ai_in_a_jar/",
          "publishedOn": "2022-04-08T13:01:58.000Z",
          "wordCount": 97,
          "title": "The AI in a jar",
          "imageUrl": "https://external-preview.redd.it/s-kVgdMVlu2lEFarxKr4Qx6lDlC6hksQDTDl15OO8FA.jpg?auto=webp&s=12afaaa5922bdf3c336e3f08460b52a5a8eed10c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tz1tbc/can_computers_learn_common_sense/",
          "author": null,
          "description": "submitted by    /u/estasfuera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tz1tbc/can_computers_learn_common_sense/",
          "publishedOn": "2022-04-08T11:54:25.000Z",
          "wordCount": 97,
          "title": "Can Computers Learn Common Sense?",
          "imageUrl": "https://external-preview.redd.it/_HnpDmSe6WGLiJPV793at05KzbITVRfCIqt7IYy-Znk.jpg?auto=webp&s=324b53c8cb621d60baa7e96cded0e9dcc3b6b99f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyyrzl/metaverse_weekly_digest_shiba_inus_metaverse/",
          "author": null,
          "description": "submitted by    /u/bent_out_of_shape_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyyrzl/metaverse_weekly_digest_shiba_inus_metaverse/",
          "publishedOn": "2022-04-08T08:23:44.000Z",
          "wordCount": 122,
          "title": "Metaverse weekly digest: Shiba Inu’s metaverse, Alibaba’s $60 million VR investment",
          "imageUrl": "https://external-preview.redd.it/wSwtyVeayWe0NbVVLnkpryWGvFBJzRMSS28BMhDuJuw.jpg?auto=webp&s=22eb8136f1bed86c6ff50bc0dfebaaddeb5e3c95"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyuzhg/meet_chestlink_the_first_autonomous_ai_medical/",
          "author": null,
          "description": "​\n https://preview.redd.it/e2q3jit3c8s81.png?width=1024&format=png&auto=webp&s=837aa6256647df6fb8777a02b04313a38428f573\n The most common diagnostic imaging test conducted in emergency rooms is chest radiography. Providing automated preliminary read helpers to physicians might speed up surgery, enhance accuracy, and lower healthcare costs.\n An artificial intelligence tool that interprets chest X-rays without the intervention of a radiologist received regulatory approval in the European Union this week, marking a first for a wholly autonomous medical imaging AI, according to ‘Oxipit‘, the developer of this tool. It’s a watershed moment for AI, and it’s more than likely to spark debate, given that radiologists have spent the last few years working to fully automate parts of their jobs.\n Continue Reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyuzhg/meet_chestlink_the_first_autonomous_ai_medical/",
          "publishedOn": "2022-04-08T04:06:41.000Z",
          "wordCount": 260,
          "title": "Meet ‘ChestLink’, The First Autonomous AI Medical Imaging Application by ‘Oxipit’ That Received CE Mark Approval in the EU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyqc1f/attend_the_2022_national_autonomous_vehicle_expo/",
          "author": null,
          "description": "Interested in the future of autonomous vehicles? Want to know more about the impacts of this technology? Join us on April 16-17th at the 2022 National Autonomous Vehicle Expo to discover the engineering, ethics, and policymaking of this emerging technology. The virtual expo consists of speaker and workshop sessions led by industry-leading companies, such as NVIDIA, Waymo, and Motional, as well as distinguished programs/organizations like MIT Beaverworks and InspiritAI. You will also have the opportunity to compete in our hackathon, where you can win a variety of cool prizes! Even if you don't participate in the hackathon, there will be free merchandise and giveaways throughout the expo! To register and/or view more information about the event, head over to avexpo.org. For hackathon-specific registration, you can visit our devpost at https://autonomous-vehicle-expo.devpost.com/. Hope to see you all there!\n ​\n https://preview.redd.it/qgfx3sv837s81.png?width=1080&format=png&auto=webp&s=ed19d68bdff274de188deaa8f4338c864943b508\n https://preview.redd.it/a4kbsrv837s81.png?width=1080&format=png&auto=webp&s=6a19347b708d822d8dca226beb82cbdc73ffbb87\n https://preview.redd.it/s9nghsv837s81.png?width=1080&format=png&auto=webp&s=cf32712b9985564b455be53e02fd00589725ad2c\n    submitted by    /u/avexpo22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyqc1f/attend_the_2022_national_autonomous_vehicle_expo/",
          "publishedOn": "2022-04-07T23:55:18.000Z",
          "wordCount": 241,
          "title": "Attend the 2022 National Autonomous Vehicle Expo (April 16-17th)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyjqk5/resources_about_cognitive_theories/",
          "author": null,
          "description": "Hi! I am new to the community, and was wondering what y'all's favorite resources were to learn about cognitive theories and how they will shape future AI advancements.\n YouTube channels would be great.\n    submitted by    /u/Apprehensive-Candy97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyjqk5/resources_about_cognitive_theories/",
          "publishedOn": "2022-04-07T18:43:22.000Z",
          "wordCount": 120,
          "title": "Resources about cognitive theories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyj9ds/andrew_yang_yuval_noah_harari_tech_public_policy/",
          "author": null,
          "description": "submitted by    /u/john133435  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyj9ds/andrew_yang_yuval_noah_harari_tech_public_policy/",
          "publishedOn": "2022-04-07T18:21:59.000Z",
          "wordCount": 124,
          "title": "Andrew Yang & Yuval Noah Harari: Tech, Public Policy & the Future of Work",
          "imageUrl": "https://external-preview.redd.it/-eHsRlpM-iTZ_A2GIEIghCAiDW3-xumI5qIeKFrOhcA.jpg?auto=webp&s=2708222de94df7b41c088fc2a6893821aa717cf4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyi240/ai_news_ai_news_why_ai_made_40000_new_chemical/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyi240/ai_news_ai_news_why_ai_made_40000_new_chemical/",
          "publishedOn": "2022-04-07T17:26:27.000Z",
          "wordCount": 148,
          "title": "AI News | AI News | Why AI Made 40,000 New Chemical Weapons Compounds in 6 Hours | Cancer Treatment AI Breakthrough",
          "imageUrl": "https://external-preview.redd.it/5IY5FIg3jerCnh_-4mHCZpnygqUFqfRHY_lHJwPCcUE.jpg?auto=webp&s=40bdf481da123c5e15ca1ec99d661f1fb7f05f48"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tygoz1/how_to_create_a_bot_for_a_existing_game/",
          "author": null,
          "description": "I wanna create a bot for a game which basically is: get resources, craft itens, sell then.\n The problem is, some itens has different qualities, and I wanna automatize this process, to identify the good stuff to keep, and sell the bad stuff.\n What's the best way to do that? \n I work with desktop systems, so i'm not familiar with this kind of stuff, but I usually read about python and some frameworks, what do you guys recommend me to start?\n    submitted by    /u/AbbathDoom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tygoz1/how_to_create_a_bot_for_a_existing_game/",
          "publishedOn": "2022-04-07T16:21:40.000Z",
          "wordCount": 335,
          "title": "How to create a BOT for a existing game?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tyfdj8/dalle_2_a_new_ai_system_to_create_realistic/",
          "author": null,
          "description": "submitted by    /u/alien128  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tyfdj8/dalle_2_a_new_ai_system_to_create_realistic/",
          "publishedOn": "2022-04-07T15:20:24.000Z",
          "wordCount": 130,
          "title": "DALL·E 2: A new AI system to create realistic images and art from natural language commands",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty99as/what_are_other_technology_fields_that_is_good_to/",
          "author": null,
          "description": "Hello! What do you guys think are other \"technology\" fields that would be good to study with AI? It is okay as long as it is \"tech.\" What would be the tech field that would be beneficial in the future? My goal is to make a self-aware AI (AGI). I was always fascinated about AI since my childhood, that's why I'm going to pursue this field. Also, I am currently studying Game Development to make a VR Game that hopefully will have humanlike AI in it. I have read a LOT of articles about the future of AI, and Cybersecurity keeps popping up because superintelligent AI needs to be CONTROLLED from hackers (based on the articles) otherwise it is over. What do you guys think would be the tech field that will bring the most changes in the future?\n    submitted by    /u/ThatOneEpicAstronaut  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty99as/what_are_other_technology_fields_that_is_good_to/",
          "publishedOn": "2022-04-07T09:31:30.000Z",
          "wordCount": 275,
          "title": "What are other \"technology\" fields that is good to learn while studying AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty964g/does_this_artificial_intelligence_think_like_a/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty964g/does_this_artificial_intelligence_think_like_a/",
          "publishedOn": "2022-04-07T09:25:11.000Z",
          "wordCount": 101,
          "title": "Does this artificial intelligence think like a human?",
          "imageUrl": "https://external-preview.redd.it/l23vR6ThpiK4uUHbQrBcH-Kaz1FrX79RSqmf1RzjQn8.jpg?auto=webp&s=e84fea5dc943b401452b9f67f6d5f7ea9aa084b8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty95tr/artificial_intelligence_courses_for_healthcare/",
          "author": null,
          "description": "We keep on hearing about how artificial intelligence and machine learning is going to revolutionise Medicine.\n But what’s hype, and what’s realistic? And how can you get involved?\n The first step is to understand the technology - where it’s well-suited to healthcare (and where it isn’t).\n When it comes to health care, especially for life and death situations AI has made things very easy for us. However, it is still expected to drastically change the way medicine is practised. It will also replace the surgeries done by the doctors with the surgeries done using Artificial intelligence, making diagnosing complex diseases, genetic issues and many other health problems extremely easy in the future. Here are the best Artificial Intelligence courses for healthcare you can learn in 2022.\n    submitted by    /u/maneesh123456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty95tr/artificial_intelligence_courses_for_healthcare/",
          "publishedOn": "2022-04-07T09:24:33.000Z",
          "wordCount": 214,
          "title": "Artificial intelligence Courses for Healthcare",
          "imageUrl": "https://external-preview.redd.it/F8zuI6MfVoolLvEryhwilLWSt_X5dg2Oye1ZyG76oHw.jpg?auto=webp&s=97b0642575d5568ab88f1264bc40946336b19a29"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty4l6x/artificial_nightmares_smithing_stone_6_clip/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty4l6x/artificial_nightmares_smithing_stone_6_clip/",
          "publishedOn": "2022-04-07T04:08:48.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Smithing Stone 6 || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/zJjOAjFsO1YezLG11RTXfpfh_8pVo6Ikq_lkMbQlhOw.jpg?auto=webp&s=08b1756429ce5fbe22334573410286405f46f2bf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty48ka/introducing_mindspore_16_new_features/",
          "author": null,
          "description": "submitted by    /u/Creative_Habit_6868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty48ka/introducing_mindspore_16_new_features/",
          "publishedOn": "2022-04-07T03:49:17.000Z",
          "wordCount": 121,
          "title": "Introducing MindSpore 1.6 New Features",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty3xvn/openais_dalle_2_texttoimage_generation_explained/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty3xvn/openais_dalle_2_texttoimage_generation_explained/",
          "publishedOn": "2022-04-07T03:32:17.000Z",
          "wordCount": 133,
          "title": "OpenAI's DALL·E 2 ! Text-to-Image Generation Explained",
          "imageUrl": "https://external-preview.redd.it/rKdS2sPjN8DCz_eI7kKnr8THMGpU-4XNJ-O-3DnTl3k.jpg?auto=webp&s=48885ad8dc953fa981580e322a249dfa69e672be"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty3vz2/how_do_i_get_into_the_field_of_ai_policy_and/",
          "author": null,
          "description": "I've read online that a career in AI policy and strategy is heavily needed and is actually ranked as the number one problem in the future by 80,000 hours. I am choosing which undergraduate degree to pursue in the fall and I'm not sure the best pathway to pursue to work in this field in an extremely high level position. an economics degree? Computer science degree? AI degree? should I pursue one subject until I get a PhD in it or mix with other degrees/certificates? is it a straight forward pathway focused on one subject where I only work in one subject field or is it necessary to pursue and work in other fields as well, what are the typical steps? Also if there is anything else that would be helpful on the pathway or anything you would recommend please let me know.\n    submitted by    /u/Key-Lawyer-7586  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty3vz2/how_do_i_get_into_the_field_of_ai_policy_and/",
          "publishedOn": "2022-04-07T03:29:19.000Z",
          "wordCount": 466,
          "title": "How do I get into the field of AI policy and strategy?",
          "imageUrl": "https://external-preview.redd.it/JwNKrNgJbmE7Fq3FDlTdS9n07RsBkdIR7dBm6TknSOE.jpg?auto=webp&s=d8a123b108ec250c019781a9b496c0fea213935c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ty030w/five_google_chrome_extensions_that_every_machine/",
          "author": null,
          "description": "submitted by    /u/MLtinkerer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ty030w/five_google_chrome_extensions_that_every_machine/",
          "publishedOn": "2022-04-07T00:09:43.000Z",
          "wordCount": 151,
          "title": "Five Google Chrome Extensions that every Machine Learning / Data Science professional should know about 🚀💯",
          "imageUrl": "https://external-preview.redd.it/pQWEkHL0yuI56NExHEWuUk7pZjyZxJ0GeDAJw4y8OoI.jpg?auto=webp&s=3b674865aa640d024a03eeb21c115f118d93e06e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txulan/weekly_china_ai_news_slime_robot_grabs_swallowed/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txulan/weekly_china_ai_news_slime_robot_grabs_swallowed/",
          "publishedOn": "2022-04-06T19:51:27.000Z",
          "wordCount": 145,
          "title": "Weekly China AI News: Slime Robot Grabs Swallowed Objects; SenseTime Revenue Grows Despite $2.7B Net Loss; Transformer Architecture Search Without Training",
          "imageUrl": "https://external-preview.redd.it/IkLvOUvSjJWLBvbCXp6nkb9puKkxjHwtZBnpffQoGWY.jpg?auto=webp&s=228647c6ab8f7290672fe31ab667eedf13a57969"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txtfc5/reading_the_tea_leaves_expert_endusers_explaining/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txtfc5/reading_the_tea_leaves_expert_endusers_explaining/",
          "publishedOn": "2022-04-06T18:58:03.000Z",
          "wordCount": 109,
          "title": "Reading the Tea Leaves: Expert End-Users Explaining the Unexplainable",
          "imageUrl": "https://external-preview.redd.it/wnVaar4ZXR3zqeMsXegEzJEPVdp1PkLFsHJagJ249DM.jpg?auto=webp&s=53c299a85d48eb7bedf6e5ec47ca846a5c52c38f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txt853/how_do_we_know_that_ai_hasnt_already_taken_over/",
          "author": null,
          "description": "submitted by    /u/Individual-Fly-610  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txt853/how_do_we_know_that_ai_hasnt_already_taken_over/",
          "publishedOn": "2022-04-06T18:49:06.000Z",
          "wordCount": 634,
          "title": "How do we know that A.I hasn't already taken over our worlds ? How do we know this isn't the matrix ? #simulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txqh23/dalle_2/",
          "author": null,
          "description": "submitted by    /u/roblox22y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txqh23/dalle_2/",
          "publishedOn": "2022-04-06T16:45:25.000Z",
          "wordCount": 81,
          "title": "DALL·E 2",
          "imageUrl": "https://external-preview.redd.it/WxulIKKm-2ySDYnNn4WAzeUutFXDx8YjTIkJ1rRcruw.jpg?auto=webp&s=f890acfaf2b0c7b649f26dab0f73522347aac900"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txl7aq/learn_how_gans_work_with_a_cool_toonify_example/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txl7aq/learn_how_gans_work_with_a_cool_toonify_example/",
          "publishedOn": "2022-04-06T12:37:59.000Z",
          "wordCount": 109,
          "title": "Learn how GANs work with a cool Toonify example!",
          "imageUrl": "https://external-preview.redd.it/wn4380KIquPfpz8kvj0TNgHlT42uU-rZ_wdLCjVqQuU.jpg?auto=webp&s=0201632198505c9f0748c4f8646d6e4557e44ea7"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txjowl/artificial_intelligence_machine_learning_and_the/",
          "author": null,
          "description": "submitted by    /u/aair_x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txjowl/artificial_intelligence_machine_learning_and_the/",
          "publishedOn": "2022-04-06T11:10:10.000Z",
          "wordCount": 122,
          "title": "Artificial Intelligence, Machine Learning and the Higgs boson - Live talk with Dr. David Rousseau",
          "imageUrl": "https://external-preview.redd.it/OSapOm3OaEUTvROlB59djlVRlsEHukiodQR08e6Bv9A.jpg?auto=webp&s=0e2022382fc9b816e0727c2dbaaaa8e4f782d305"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txelh6/what_are_your_thoughts_about_ai_teachers/",
          "author": null,
          "description": "submitted by    /u/curiosityVeil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txelh6/what_are_your_thoughts_about_ai_teachers/",
          "publishedOn": "2022-04-06T05:12:46.000Z",
          "wordCount": 152,
          "title": "What are your thoughts about AI teachers?",
          "imageUrl": "https://external-preview.redd.it/80zTz2GSqxkIcAo531n58iOibUJoLUsjIYse2G5B-Gg.jpg?auto=webp&s=e57005bacbf4e2da807f32d3456669927d952049"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/txd3gn/heres_an_intuitive_explanation_to_singular_value/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/txd3gn/heres_an_intuitive_explanation_to_singular_value/",
          "publishedOn": "2022-04-06T03:43:32.000Z",
          "wordCount": 144,
          "title": "Here's an intuitive explanation to Singular Value Decomposition. 👇",
          "imageUrl": "https://external-preview.redd.it/yEZqz6bdYi9OxMbxSAun-NOOyBiIEWi0hgButp5s0Bc.jpg?auto=webp&s=7501076a2d95650e0f1222b249a18b18ee508c2e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx99v0/artificial_nightmares_beauty_parlor_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx99v0/artificial_nightmares_beauty_parlor_clip_guided/",
          "publishedOn": "2022-04-06T00:21:20.000Z",
          "wordCount": 129,
          "title": "Artificial Nightmares: Beauty Parlor || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/uIXIo-JN5IPR5kMQLxCCW6I2UuSHT9uE8Y0Y2rzt8_A.jpg?auto=webp&s=eeb8b67dbaac0c8d18c931376cd666f5b9c11d4b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx7x0d/last_week_in_ai_ai_improves_algae_for_biofuel_and/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx7x0d/last_week_in_ai_ai_improves_algae_for_biofuel_and/",
          "publishedOn": "2022-04-05T23:13:43.000Z",
          "wordCount": 142,
          "title": "Last Week in AI: AI improves algae for biofuel and carbon capture, more AI decision-making in the military, and more!",
          "imageUrl": "https://external-preview.redd.it/n9aJP_9oQD2EMA4IrahetlrzK7vnz504KANDXrSuY8E.jpg?auto=webp&s=b090eda31ad16112cde4e1bb014a8a48270dc43e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx2gbr/researchers_from_allen_institute_for_ai_introduce/",
          "author": null,
          "description": "We humans navigate the environment using all of our senses. Allen Institute researchers propose MERLOT Reserve, a model that learns to represent videos over time and across several modalities, including audio, subtitles, and video frames. It was trained using a new learning objective and more than 20 million YouTube videos.\n MERLOT Reserve is a unique, cutting-edge methodology for solving video-related inquiries. MERLOT Reserve can dependably choose the correct answer from a selection of multiple-choice answers when given a video and a question. This forecast is made by MERLOT Reserve jointly reasoning over the visual frames of the video, the video subtitles, and the audio in the movie.\n Continue reading this cool research update from AI2\n Paper: https://arxiv.org/pdf/2201.02639.pdf\n Demo: https://merlot-reserve.apps.allenai.org/\n Project: https://rowanzellers.com/merlotreserve/\n Github: https://github.com/rowanz/merlot\\_reserve\n ​\n https://preview.redd.it/031i6ty6err81.png?width=1920&format=png&auto=webp&s=299569e12160eb991f35a2c6b41c5758ff027235\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx2gbr/researchers_from_allen_institute_for_ai_introduce/",
          "publishedOn": "2022-04-05T19:08:12.000Z",
          "wordCount": 241,
          "title": "Researchers From Allen Institute for AI Introduce ‘MERLOT Reserve’: A Novel Multimodal Video Question Answering Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tx1gpx/endlessvn_open_alpha_today/",
          "author": null,
          "description": "submitted by    /u/roblox22y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tx1gpx/endlessvn_open_alpha_today/",
          "publishedOn": "2022-04-05T18:24:46.000Z",
          "wordCount": 89,
          "title": "EndlessVN open alpha today",
          "imageUrl": "https://external-preview.redd.it/hzTGk_919JT_ol9WPARzYnUdu27B--ckWm5Gjh163Ns.jpg?auto=webp&s=1500dda8e3ecebf6daea2efb342f0a0f82f065fe"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twvsua/ai_meets_quantum_technology_in_new_google_spinoff/",
          "author": null,
          "description": "submitted by    /u/allaboutcircuits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twvsua/ai_meets_quantum_technology_in_new_google_spinoff/",
          "publishedOn": "2022-04-05T14:08:38.000Z",
          "wordCount": 134,
          "title": "AI Meets Quantum Technology in New Google Spinoff, Sandbox AQ - News",
          "imageUrl": "https://external-preview.redd.it/Csqi5x9oFEPbU-NX_b014QpOo695w0-f9eoDc5vYBpc.jpg?auto=webp&s=720fb93dbbe0e2b3c64d730b52889606b5e60919"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twrsgf/best_undergraduate_major_besides_computer_science/",
          "author": null,
          "description": "Hi, all. I got accepted into my top choice of college as an undecided major. Recently, I have decided to pursue artificial intelligence! Unfortunately, it is near impossible to transfer into computer science at my particular university. I was wondering if I can still pursue AI as a career if I complete one of the following majors:\n -Mathematics\n -Information or Data Science\n -Statistics\n -Linguistics\n Additionally, I could pursue one of these and minor in another. I should be able to minor in computer science as well if necessary. Hopefully, my choice of major would allow me to pursue research or an internship in artificial intelligence. I am willing to take additional summer courses and pursue relevant certifications to ensure that I am up to par with my computer science colleagues. \n (posted on behalf of a family member)\n    submitted by    /u/runelagoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twrsgf/best_undergraduate_major_besides_computer_science/",
          "publishedOn": "2022-04-05T10:26:35.000Z",
          "wordCount": 674,
          "title": "Best undergraduate major besides computer science for pursuing a career in artificial intelligence?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twqf43/comparing_old_and_new_ai_voices_from_replica/",
          "author": null,
          "description": "submitted by    /u/autumns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twqf43/comparing_old_and_new_ai_voices_from_replica/",
          "publishedOn": "2022-04-05T08:47:46.000Z",
          "wordCount": 116,
          "title": "Comparing old and new AI voices from Replica Studios (new in second half)",
          "imageUrl": "https://external-preview.redd.it/sXhx5sJMKQOeW3d6yJH5Y3x-xzEsRRd4Vlsw9kNMAEQ.jpg?auto=webp&s=f135eef5941ce2927e1b7835cf2f5f32bbc26027"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twmyc3/superres_modelprogram_comparison/",
          "author": null,
          "description": "I upscaled an image with a few different superres models and programs, pick your favorite!\n https://files.botbox.dev/superrestestcollage.png\n Because of how reddit is, I can't make this as a poll, so comment your pick.\n Animated original version: https://www.youtube.com/watch?v=zRaTwVuqd70 (I will also make an animated version upscaled with the most voted model/program)\n    submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twmyc3/superres_modelprogram_comparison/",
          "publishedOn": "2022-04-05T04:50:22.000Z",
          "wordCount": 131,
          "title": "Super-res model/program comparison",
          "imageUrl": "https://external-preview.redd.it/0b-KM1fMHQlvxq8AaZ1Yoz4s8d9vlfkaCTjKSFHSx5I.jpg?auto=webp&s=00cf51afd6fc6d339a19830c02dd07831a4dd112"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twl2bd/solo_voiceovers/",
          "author": null,
          "description": "I am looking for something to change my voice in a way that is more satisfactory and more convincingly varied than what simple voice modulation software can achieve and as cheaply as is possible (preferably free).\n Use case: I have been working on an animated movie to which I am the sole contributor. Though I have been putting it off while looking for an appropriate solution, the time has come to voice my various characters, who are a range of ages, both male and female. For several reasons, I am interested in voicing them all myself while doing the facial motion captures as well. What I am in need of is, essentially, something that does exactly what Respeecher does, but without the $200/month sub fee. I would love to be in a position to simply pay them what they are asking for in exchange…",
          "link": "https://www.reddit.com/r/artificial/comments/twl2bd/solo_voiceovers/",
          "publishedOn": "2022-04-05T03:02:48.000Z",
          "wordCount": 508,
          "title": "solo voiceovers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twkptb/artificial_nightmares_frenzied_flame_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twkptb/artificial_nightmares_frenzied_flame_clip_guided/",
          "publishedOn": "2022-04-05T02:44:46.000Z",
          "wordCount": 126,
          "title": "Artificial Nightmares: Frenzied Flame || Clip Guided Diffusion AI Art Video [4K 20 FPS]",
          "imageUrl": "https://external-preview.redd.it/Ou-X9gePzH_R1p1xZ0_LmlSuj8KLO-kGZaJHgIJfVSE.jpg?auto=webp&s=bd8596715f1ab78a9626534ffc61ae623f7b1af3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/twjoqd/ai_that_takes_multiple_songs_as_input_and_then/",
          "author": null,
          "description": "I have been searching for a music AI that takes input as mp3 or midi files, yet haven't been successful yet. Is there such a thing? If not, is such a thing feasible?\n    submitted by    /u/16pxl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/twjoqd/ai_that_takes_multiple_songs_as_input_and_then/",
          "publishedOn": "2022-04-05T01:52:00.000Z",
          "wordCount": 402,
          "title": "AI that takes multiple songs as input, and then generates a similar song or song with similar elements?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw91fr/microsoft_researchers_introduce_jigsaw_an_ai_tool/",
          "author": null,
          "description": "GPT-3, Codex, and other sizable pre-trained language models can be adjusted to create code from natural language descriptions of programmer intent. Every developer in the world might benefit from these automated models, which have the potential to increase productivity. However, because the models may fail to understand program semantics, the quality of the generated code cannot be guaranteed.\n Microsoft researchers introduce Jigsaw, a new tool that can help these big language models perform better. Jigsaw is a Python Pandas API code generator that accepts multi-modal inputs. Jigsaw uses post-processing techniques to decipher the syntax and semantics of programs and then uses user feedback to improve future performance.\n Continue Reading\n Paper: https://arxiv.org/pdf/2112.02969.pdf\n Dataset: https://github.com/microsoft/JigsawDataset\n ​\n https://i.redd.it/x223r5qu0kr81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw91fr/microsoft_researchers_introduce_jigsaw_an_ai_tool/",
          "publishedOn": "2022-04-04T18:21:08.000Z",
          "wordCount": 263,
          "title": "Microsoft Researchers Introduce ‘Jigsaw’: An AI Tool To Augment Large Language Models (GPT-3, Codex, etc.) By Deploying Post-Processing Techniques That Understand The Programs’ Syntax And Semantics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw8fae/pathways_language_model_palm_scaling_to_540/",
          "author": null,
          "description": "submitted by    /u/nick7566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw8fae/pathways_language_model_palm_scaling_to_540/",
          "publishedOn": "2022-04-04T17:56:24.000Z",
          "wordCount": 121,
          "title": "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance",
          "imageUrl": "https://external-preview.redd.it/WIrkmtU3_fcptRO4rAsUpS3dcvevn7W-qKDu5KWN0BM.jpg?auto=webp&s=d45552298a94c0bc0e771853afe179cbb0e3f951"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw79so/generative_aialex_grey_xxxxxoooooooo_disco/",
          "author": null,
          "description": "submitted by    /u/JoshGrambo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw79so/generative_aialex_grey_xxxxxoooooooo_disco/",
          "publishedOn": "2022-04-04T17:09:23.000Z",
          "wordCount": 105,
          "title": "Generative AI+Alex Grey = xxxxxoooooooo (Disco Diffusion)",
          "imageUrl": "https://external-preview.redd.it/5szgyleyhmZQatLGQQc0tWNKXYQjmomMBSzW55VOY2I.jpg?auto=webp&s=f943d685a85e58d5f8cb7371f25e11e3763f8f34"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw6zcv/uipath_extract_tables_from_pdf_use_case_pdf_table/",
          "author": null,
          "description": "submitted by    /u/Cristi_UiPath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw6zcv/uipath_extract_tables_from_pdf_use_case_pdf_table/",
          "publishedOn": "2022-04-04T16:58:01.000Z",
          "wordCount": 111,
          "title": "UiPath extract Tables from PDF (use case) (PDF table)",
          "imageUrl": "https://external-preview.redd.it/XdStN-2Ltm4rlONpMIvCknd-rKvCteajYNUFIXrL__E.jpg?auto=webp&s=3b4ef0b9d4d13d1bb16a3f84865d7884a09eeb8d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tw1nzj/new_rl_technique_achieves_superior_performance_in/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tw1nzj/new_rl_technique_achieves_superior_performance_in/",
          "publishedOn": "2022-04-04T13:11:26.000Z",
          "wordCount": 101,
          "title": "New RL technique achieves superior performance in control tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvz2cs/metrics_matthews_correlation_coefficient/",
          "author": null,
          "description": "submitted by    /u/TheTesseractAcademy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvz2cs/metrics_matthews_correlation_coefficient/",
          "publishedOn": "2022-04-04T10:51:05.000Z",
          "wordCount": 94,
          "title": "Metrics: Matthew's correlation coefficient",
          "imageUrl": "https://external-preview.redd.it/K79luiNVO7cDl4UNZslrIpsFYJBu9pe6zLP_bpNmEVU.jpg?auto=webp&s=b4b8dcad0ffee30fc3cd5116872c85a245b67edd"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvy3mp/12_graphs_that_explain_the_state_of_ai_in_2022/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvy3mp/12_graphs_that_explain_the_state_of_ai_in_2022/",
          "publishedOn": "2022-04-04T09:49:07.000Z",
          "wordCount": 136,
          "title": "12 Graphs That Explain the State of AI in 2022",
          "imageUrl": "https://external-preview.redd.it/rxu_HYqvBcCfZOmrTEaxXK9YViKM0KioByJVsMvy31k.jpg?auto=webp&s=366d3c7f395840f2f28a0d32633778e1dc2e03c0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvx311/what_is_whatsapp_business_api_how_can_it_help/",
          "author": null,
          "description": "submitted by    /u/mihircontra20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvx311/what_is_whatsapp_business_api_how_can_it_help/",
          "publishedOn": "2022-04-04T08:38:30.000Z",
          "wordCount": 117,
          "title": "What is WhatsApp Business API? How can it Help your Business?",
          "imageUrl": "https://external-preview.redd.it/dNWZt5KgY2MqG0CICD8AVcKpMu4QVpc2Y1jPRh4tVfc.jpg?auto=webp&s=544310fa5704bad1ded6821fe5bc364c99358791"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvqnw5/voice_copyingcloning/",
          "author": null,
          "description": "Hi all,\n Don't know if this is the right subreddit, but here goes....\n I'm looking to voice clone my father. He has passed recently, and despite being difficult for all, it's been especially hard for my mother, married early to him and together for 50 years. Her birthday is coming up, I'd love to be able to create a 5-10 second sound byte of him for her.\n Fortunately, there's likely to be lots of his voice recording around, part of his job was speaking and instructing.\n So, is there any way this is possible, to be done without great difficulty, and produce an accurate result?\n I am understanding the moralities of crafting something with his deceased voice. I thought about it quite a bit. However, I feel that it's for his soulmate who's struggling, who he had no qualms spending his life with and travelling abroad with, spent his last days with. I'm certain he would want to help.\n    submitted by    /u/mininggotboring  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvqnw5/voice_copyingcloning/",
          "publishedOn": "2022-04-04T02:17:04.000Z",
          "wordCount": 300,
          "title": "Voice copying/cloning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvd9w0/ai_news_als_brain_computer_interface_1_year_human/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvd9w0/ai_news_als_brain_computer_interface_1_year_human/",
          "publishedOn": "2022-04-03T16:31:19.000Z",
          "wordCount": 145,
          "title": "AI News | ALS Brain Computer Interface 1 Year Human Trial Results | Skin Cancer Detection | New IBM AI Hardware",
          "imageUrl": "https://external-preview.redd.it/V1rfHFG8YhKM7LmCEZ3wsL5vptilPYrVjTDo-LcpRD4.jpg?auto=webp&s=4daa3bb70bc2ec7d33bdcd71f74b5d0bb0799e16"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvctg8/your_next_teacher_will_be_a_machine_why_the/",
          "author": null,
          "description": "submitted by    /u/itsallshit-eatup  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvctg8/your_next_teacher_will_be_a_machine_why_the/",
          "publishedOn": "2022-04-03T16:11:21.000Z",
          "wordCount": 126,
          "title": "Your Next Teacher Will be a Machine: Why the Future of Education is Automation",
          "imageUrl": "https://external-preview.redd.it/6esqFIrmdOYU6dYfuQXctFxZQK0hWvaxAMXQLVewc_w.jpg?auto=webp&s=580098cc5f338bdbc295957629b74a03b2be7209"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tvaoe1/hi_im_wondering_if_anyone_could_help_me/",
          "author": null,
          "description": "Im a 19yo guy from Argentina that studies system ingeneer, I like my career, beeing an ingeneer is great, but coding and AI is greater, Im tired of courses like Free code academy, or basics things, im looking for a more professional, useful and deeper courses, that will really teach me, im currently with python(pandas,numpy,matplotlib,tensorflow) basics, and wanna to be better in that field that i love❤\n    submitted by    /u/Sasulanda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tvaoe1/hi_im_wondering_if_anyone_could_help_me/",
          "publishedOn": "2022-04-03T14:36:41.000Z",
          "wordCount": 167,
          "title": "Hi!, Im wondering if anyone could help me🇦🇷🇦🇷",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tv829c/active_nonml_research_areas/",
          "author": null,
          "description": "What are the most active non-ML/statistical research areas in AI?\n Are there any recent books published that give an overview of such areas?\n Seems like AI is now either ML or people saying that ML won’t work, but vague on alternatives.\n    submitted by    /u/spookyplatypus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tv829c/active_nonml_research_areas/",
          "publishedOn": "2022-04-03T12:22:42.000Z",
          "wordCount": 185,
          "title": "Active non-ML research areas?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tv133y/heard_about_github_copilot_now_meet_salesforces/",
          "author": null,
          "description": "Imagine being able to tell a machine to write an app simply by telling it what the app does. As far-fetched as it may appear, this scenario is already a reality.\n According to Salesforce AI Research, conversational AI programming is a new paradigm that brings this vision to life, thanks to an AI system that builds software.\n Introducing CodeGen: Creating Programs from Prompts\n The large-scale language model, CodeGen, which converts simple English prompts into executable code, is the first step toward this objective. The person doesn’t write any code; instead, (s)he describes what (s)he wants the code to perform in normal language, and the computer does the rest.\n Conversational AI refers to technologies that allow a human and a computer to engage naturally through a conversation. Chatbots, voice assistants, and virtual agents are examples of conversational AI.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.13474.pdf\n Github: https://github.com/salesforce/CodeGen\n https://i.redd.it/dbyba3dct8r81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tv133y/heard_about_github_copilot_now_meet_salesforces/",
          "publishedOn": "2022-04-03T04:40:09.000Z",
          "wordCount": 692,
          "title": "Heard about Github Copilot? Now Meet Salesforce's 'CodeGen’ : An AI Model That Turns Simple Natural Language Requests Into Executable Code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tuu59j/building_trust_with_responsible_ai/",
          "author": null,
          "description": "Artificial Intelligence is being used in almost every aspect of life. AI symbolizes growth and productivity in the minds of some, but it is raising questions as well on the fairness, privacy, and security of these systems. Many legitimate issues exist, including biased choices, labor replacement, and a lack of security. When it comes to robots, this is very frightening. Self-driving automobiles, for example, can cause injury or death if they make mistakes. Responsible AI addresses these difficulties and makes AI systems more accountable.\n Responsible AI should fulfill the following aims:\n  \nInterpretability: We obtain an explanation for how a model makes predictions when we interpret it. An AI system makes predictions for a user. Even if these selections are correct, a user is likely to seek an explanation. Responsible AI can describe how we create interpretable models.\n Fairness: AI systems have the potential to make judgments that are biased towards particular groups of people. Bias in the training data is the source of this bias. The easier it is to assure fairness and rectify any bias in a model, the more interpretable it is. As a result, we need a Responsible AI framework to explain how we evaluate fairness and what to do if a model makes unjust predictions.\n Safety and Security: AI systems aren’t deterministic. When confronted with new situations, they are prone to making poor choices. The systems can even be tampered with to make unwise decisions. Therefore, we need to ensure safety and security in these systems.\n Data Governance: The data used must be of high quality. If the data used by AI has errors, the system may make wrong decisions.\n  \nContinue Reading The Article Here\n ​\n https://preview.redd.it/9iivp31ir6r81.png?width=1024&format=png&auto=webp&s=207409694b68a1e985ad1dfcf3b466ac25916da2\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tuu59j/building_trust_with_responsible_ai/",
          "publishedOn": "2022-04-02T21:46:33.000Z",
          "wordCount": 364,
          "title": "Building Trust with Responsible AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tusmv0/its_unbelievable_what_ml_can_do_discorife_7hr/",
          "author": null,
          "description": "submitted by    /u/JoshGrambo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tusmv0/its_unbelievable_what_ml_can_do_discorife_7hr/",
          "publishedOn": "2022-04-02T20:38:58.000Z",
          "wordCount": 114,
          "title": "It's unbelievable what ML can do! Disco+RIFE= 7hr Colab Run...",
          "imageUrl": "https://external-preview.redd.it/uW0ZWgsocgrNGmz-a2bOQXLTJj-XcskLyyJib0rVBKk.jpg?auto=webp&s=12c01fbc8154b1bcfbf3c618410871aaeebc1d8c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tuov1l/creating_a_chatbot_with_transformers_and_gradio/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tuov1l/creating_a_chatbot_with_transformers_and_gradio/",
          "publishedOn": "2022-04-02T17:53:29.000Z",
          "wordCount": 96,
          "title": "Creating A Chatbot with transformers and Gradio",
          "imageUrl": "https://preview.redd.it/e3ush415m5r81.png?auto=webp&s=0527e497aa1008fdf2599268f3183415a4e49cff"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tunb06/researchers_develop_parking_analytics_framework/",
          "author": null,
          "description": "Artificial Intelligence and deep learning in video analytics are gaining popularity. It has enabled a wide range of industrial applications, including surveillance and public safety, robotics perception, medical intervention, and facial recognition. According to Markets & Markets, the global market for video analytics was valued at USD 5.9 billion in 2021 and is predicted to reach USD 14.9 billion by 2026.\n Unmanned aerial vehicles (UAVs) have also enabled a wide range of video analytics applications (e.g., aerial surveys) since they provide aerial views of the environment, allowing for collecting aerial photos and processing with deep learning algorithms. Parking analytics is one of these critical smart city applications that uses deep learning and UAVs to collect real-time data and analyze it in order to maximize parking revenue, enhance parking resource allocations, and better manage public space.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.07792.pdf\n ​\n https://i.redd.it/u5th7z0ja5r81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tunb06/researchers_develop_parking_analytics_framework/",
          "publishedOn": "2022-04-02T16:48:24.000Z",
          "wordCount": 258,
          "title": "Researchers Develop Parking Analytics Framework Using Deep Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tuelaw/how_will_ai_impact_games/",
          "author": null,
          "description": "submitted by    /u/GravermanYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tuelaw/how_will_ai_impact_games/",
          "publishedOn": "2022-04-02T09:05:20.000Z",
          "wordCount": 97,
          "title": "How will AI impact games",
          "imageUrl": "https://external-preview.redd.it/j8cMRhk6anZDhUlXBqFPgbbvX53C1v7EzO-47DzAZks.jpg?auto=webp&s=656307351b7e3c5d84ec33d161585127491ff890"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tu4zyq/seeking_respondents_for_a_survey_about_ai_text/",
          "author": null,
          "description": "Hello! I am doing an independent (non-academic) research study about AI text generation as relates to poetry and reader interpretation. The results of the study will be presented in a YouTube video. \n I would really appreciate if some folks could take approximately 20-25 minutes to take this anonymous survey I put together. It involves reading some poems and answering questions about those poems. Thank you so much for the help! \n https://form.jotform.com/220880249866062\n    submitted by    /u/northern_frog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tu4zyq/seeking_respondents_for_a_survey_about_ai_text/",
          "publishedOn": "2022-04-01T23:42:54.000Z",
          "wordCount": 187,
          "title": "Seeking respondents for a survey about AI text generation and reader interpretation of poetry",
          "imageUrl": "https://external-preview.redd.it/v7d0tATSqpy9crLzFxjW7F5hgCsiCG0mldziRhMNIPI.jpg?auto=webp&s=2463173b2a58ca9742949bd77b0e980fa6a3595d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tu2gq4/the_tokendropping_approach_used_by_ml_researchers/",
          "author": null,
          "description": "The Pretraining of BERT-type large language models, which may scale up to billions of parameters, is essential to achieving best-in-class performance on various natural language processing (NLP) applications. However, the pretraining procedure is costly, and it has become a hurdle for the industrial deployment of big language models.\n In a research paper, researchers from Google, New York University, and the University of Maryland recommend a simple but effective “token dropping” method that drastically reduces the pretraining cost of transformer models like BERT while maintaining downstream fine-tuning performance.\n Token dropping is a technique for speeding up the pretraining of transformer models like BERT without sacrificing their performance on downstream tasks. Starting with an intermediate layer in the model, they eliminate uninteresting tokens to let the model focus on key tokens more effectively, given its limited computing resources. The model’s last layer then picks up the dropped tokens, producing full-length sequences. They use the built-in masked language modeling (MLM) loss and its dynamics to detect non-essential tokens with little computing complexity. According to their tests, this straightforward strategy decreases BERT’s pretraining cost by 25% while yielding somewhat higher overall fine-tuning performance on conventional downstream tasks.\n Continue Reading The Summary\n Paper: https://arxiv.org/pdf/2203.13240.pdf\n Github: https://github.com/tensorflow/models/tree/master/official/projects/token\\_dropping\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tu2gq4/the_tokendropping_approach_used_by_ml_researchers/",
          "publishedOn": "2022-04-01T21:46:19.000Z",
          "wordCount": 329,
          "title": "The Token-Dropping Approach Used By ML Researchers From Google and NYU Reduces BERT Pretraining Time And Cost By 25%",
          "imageUrl": "https://external-preview.redd.it/dVOlinWotMPLCgqZf5DyOLTUwr_WHlx_ZRY9Nf94v6A.jpg?auto=webp&s=7bd91c06fa85f604d1603bc57b5b6b8cda992c5c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tu0zk2/top_emerging_artificial_intelligence_use_cases/",
          "author": null,
          "description": "submitted by    /u/Visionifyai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tu0zk2/top_emerging_artificial_intelligence_use_cases/",
          "publishedOn": "2022-04-01T20:43:05.000Z",
          "wordCount": 105,
          "title": "Top emerging artificial intelligence use cases",
          "imageUrl": "https://external-preview.redd.it/nwkhz3JfoBxgf1shs6bmGimTMtKLadwCKdaup9WuJ0g.jpg?auto=webp&s=d9558bc72428176f7cdbaa409fa3f3441afa7f65"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttxk1j/metas_new_speech_ai_can_laugh_scream_yawn_and/",
          "author": null,
          "description": "Meta unveils new research on speech AI: Machine-generated voices can now cry, laugh, yawn or make more natural small talk. \n ...\n Meta’s speech AI can now mimic emotional sounds such as laughing, yawning, or crying – which it says is important in communication to better convey the intention and context of a statement. \n ...\n the new GSML model dGSML, which is optimized for dialogs, generates more natural-sounding audio dialogs using AI agents that can pause for thought or process overlaps in conversations. \n ...\n dGSML was trained with about 2000 hours of unlabeled audio dialogues from the Fisher dataset, which contains about 16000 English-language telephone conversations. \n Source and demos: https://mixed-news.com/en/meta-new-speech-ai-can-laugh-scream-yawn/\n    submitted by    /u/Sephirio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttxk1j/metas_new_speech_ai_can_laugh_scream_yawn_and/",
          "publishedOn": "2022-04-01T18:15:57.000Z",
          "wordCount": 258,
          "title": "Meta’s new speech AI can laugh, scream, yawn, and chit-chat",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttvd98/oracle_releases_mysql_heatwave_ml_that_adds/",
          "author": null,
          "description": "Integrating machine learning capabilities to MySQL systems is prohibitively difficult and time-consuming. The process involves extracting data from the database and into another system to construct and deploy machine learning models. As data flows around, this strategy produces silos for applying machine learning to application data and causes latency. This results in data leakage, making the database more open to security attacks. Moreover, existing machine learning (ML) solutions lack the ability to explain why the model developers build delivers specific predictions.\n Recently, Oracle released MySQL HeatWave, the only MySQL cloud database service that supports in-database machine learning (ML). It automates the ML lifecycle and saves all trained models in the MySQL database, removing the need to migrate data or models to a machine learning tool or service. This decreases application complexity, saves costs, and increases data and model security. It produces a model with the best algorithm, features, and hyper-parameters for a specific data collection and application. \n Continue Reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttvd98/oracle_releases_mysql_heatwave_ml_that_adds/",
          "publishedOn": "2022-04-01T16:46:17.000Z",
          "wordCount": 276,
          "title": "Oracle Releases MySQL HeatWave ML That Adds Powerful Machine Learning Capabilities to MySQL Applications",
          "imageUrl": "https://external-preview.redd.it/c7JwbAX6On_dwvaZKVvJs0f-YQBgFPWDWNkYEya2b7Q.jpg?auto=webp&s=daf6becad6b235653ca2334f30010b5db2faf9cf"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tts48e/cloudy_world_ai_art/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tts48e/cloudy_world_ai_art/",
          "publishedOn": "2022-04-01T14:32:16.000Z",
          "wordCount": 107,
          "title": "Cloudy World AI Art",
          "imageUrl": "https://external-preview.redd.it/rvVFdUL_ZqFWUdd_MlLHJEB4RYGoUWqiLZdY5sbShCA.jpg?auto=webp&s=d701c4da705fb263b73468044eedc7eb1a526c98"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tto6sd/how_chatbot_is_beneficial_in_the_retail_industry/",
          "author": null,
          "description": "By offering your clients a blended virtual, tailored, and on-the-spot conversational level of conversation - you can engage them for longer and create an interactive method of selling to them. Chatbots will be armed with Conversational AI - and powered by an in-depth understanding of the client and their past behaviors - will be able to offer the service which is most likely to suit each client.\n Retailers can take advantage of the ability to engage potential customers through virtual attendants. Along with this opportunity is a growing range of new and exciting ways to utilize chatbots within retail spaces. A lack of customer engagement through mobile messaging costs retailers around $1 trillion annually, as customers are increasingly becoming reluctant to contact mainstream outlets for recommendations due to their negative experiences, or because they have already made up their mind on what they want.\n This can be potentially overcome by utilizing Chatbots; in-store systems powered by AI that can be utilized across multiple channels, including the outlet's website and branded social media profiles.\n    submitted by    /u/botgo_io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tto6sd/how_chatbot_is_beneficial_in_the_retail_industry/",
          "publishedOn": "2022-04-01T11:15:18.000Z",
          "wordCount": 270,
          "title": "How Chatbot is beneficial in the Retail Industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttkjwy/game_ai_question_retraining_without_losing/",
          "author": null,
          "description": "submitted by    /u/ICouldDoButWhyWouldI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttkjwy/game_ai_question_retraining_without_losing/",
          "publishedOn": "2022-04-01T06:57:21.000Z",
          "wordCount": 256,
          "title": "Game AI Question (Retraining without losing characteristics)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttjncw/disco_diffusion_v5_bullet_time_of_blood_animation/",
          "author": null,
          "description": "submitted by    /u/JoshGrambo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttjncw/disco_diffusion_v5_bullet_time_of_blood_animation/",
          "publishedOn": "2022-04-01T05:56:38.000Z",
          "wordCount": 111,
          "title": "[Disco Diffusion v5] - \"Bullet Time of Blood Animation\"",
          "imageUrl": "https://external-preview.redd.it/VUZrdH989ptIlcYYTgrHAhxyk5LbDxGZsiD4Hlm2qzw.jpg?auto=webp&s=328d4b23fd18df5d587aa8e4a2c9676abbe63c38"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ttf9ri/if_you_could_change_one_thing_about_building_ml/",
          "author": null,
          "description": "I’d like to open this question up to people who are beginners, intermediates and experienced in the field of ML to get a wide variety of perspectives.\n If you could change/significantly improve one thing about building ML systems, what would it be? Some examples could be:\n  \nReducing the computational overhead\n Reducing or eliminating the need for large datasets\n Simplifying the process of constructing models\n  \nHowever, it’s not limited to just those three.\n Curious to see where this goes!\n    submitted by    /u/holamyeung  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ttf9ri/if_you_could_change_one_thing_about_building_ml/",
          "publishedOn": "2022-04-01T01:43:21.000Z",
          "wordCount": 187,
          "title": "If you could change one thing about building ML, what would it be?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt8437/last_week_in_ai_podcast_deepmind_mafia_dishbrain/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt8437/last_week_in_ai_podcast_deepmind_mafia_dishbrain/",
          "publishedOn": "2022-03-31T19:52:32.000Z",
          "wordCount": 121,
          "title": "Last Week in AI podcast: DeepMind Mafia, DishBrain, PRIME, ZooKeeper AI, Instant NeRF",
          "imageUrl": "https://external-preview.redd.it/rNK55N1AxgR55D2RBw8bfS59vTGm-3bB-SOMUH7kqTc.jpg?auto=webp&s=5365740e2e113c1981453f6a977da6b9481114c2"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt7l1s/newbie_question/",
          "author": null,
          "description": "Hello guys, I was wondering if anyone knew the easiest way to combine images together. Ideally I would have a bunch of images and it would take components of a couple (or just two) and put them together. I want to generate images of morphed anime figures, it doesn’t even need to look professional (or good lol). Just need some sort of website or software that I can easily achieve this. Any tips or ideas would be greatly appreciated!! Thank you!\n    submitted by    /u/misakimeifanpage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt7l1s/newbie_question/",
          "publishedOn": "2022-03-31T19:28:06.000Z",
          "wordCount": 163,
          "title": "Newbie question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt4uqf/fighting_ais_discrimination_in_mortgage_lending/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt4uqf/fighting_ais_discrimination_in_mortgage_lending/",
          "publishedOn": "2022-03-31T17:24:31.000Z",
          "wordCount": 101,
          "title": "Fighting AI's discrimination in mortgage lending | DualFair",
          "imageUrl": "https://external-preview.redd.it/pwjkeaeKK0vlN-iJxngHqiAHccPHXRgh3wt-HsDy6uM.jpg?auto=webp&s=9f51c485d9aa5650bf825719c1c1276d17c818c3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt37xb/researchers_from_u_texas_and_apple_propose_a/",
          "author": null,
          "description": "Multi-object tracking aims to locate and track all objects in a video feed. It’s a fundamental component in domains like mobile robots, where an autonomous system must navigate dynamic surroundings populated by other mobile agents. Thanks to breakthroughs in deep learning and object detection, tracking-by-detection has become the dominant tracking paradigm in recent years.\n Tracking-by-detection simplifies the process by reducing it to just two steps: detection and association. First, an object detector searches each video stream frame for probable items. The second phase is an association step, which connects detections over time. Local trackers are greedy when it comes to pairwise relationships. They keep track of each trajectory’s state based on its position and/or identity traits and correlate current-frame detections with it based on its last visible status.\n Continue Reading The Research Summary\n Paper: https://arxiv.org/pdf/2203.13250.pdf\n Github: https://github.com/xingyizhou/GTR\n https://i.redd.it/312ahhaxtqq81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt37xb/researchers_from_u_texas_and_apple_propose_a/",
          "publishedOn": "2022-03-31T16:10:30.000Z",
          "wordCount": 254,
          "title": "Researchers from U Texas and Apple Propose a Novel Transformer-Based Architecture for Global Multi-Object Tracking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt2dxi/ai_generated_personalized_implicit_neural_avatars/",
          "author": null,
          "description": "submitted by    /u/imapurplemango  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt2dxi/ai_generated_personalized_implicit_neural_avatars/",
          "publishedOn": "2022-03-31T15:32:48.000Z",
          "wordCount": 103,
          "title": "AI generated Personalized Implicit Neural Avatars (PINA)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tt02ro/instant_nerf_turn_2d_images_into_a_3d_models_in/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tt02ro/instant_nerf_turn_2d_images_into_a_3d_models_in/",
          "publishedOn": "2022-03-31T13:44:19.000Z",
          "wordCount": 155,
          "title": "Instant NeRF: Turn 2D Images into a 3D Models in Milliseconds",
          "imageUrl": "https://external-preview.redd.it/S2B09FxAWorWa23naYAaOvUAFMXYp4KXv9yJcPG9NS4.jpg?auto=webp&s=67c4bd30d11fd161a85861ed7dcebc9bad975d2e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsv57j/dataset_with_labeled_benign_and_malicious_files/",
          "author": null,
          "description": "Hi, Reddit,\n During the project implementation for my bachelor's thesis [1], a software (named dike, as the Greek goddess of justice) capable of analyzing malicious programs using artificial intelligence techniques, I was unable to locate an open source dataset with labeled malware samples in the public domain. As a result, I created DikeDataset, a dataset with labeled PE and OLE samples [2]. Because it was not the main focus of my thesis, the samples attributes are not evenly distributed (the benign-malicious and OLE-PE ratios are quite low), but the dataset aided greatly in the research process.\n This week, I was surprised to see that the public GitHub repository (which was used only for storage, without any promotion on communities like this) gained some organic reach (views, clones and stars). Furthermore, I was thrilled to learn that it was used in a research article published in 2021 [3]!\n As a result, I'd like to share this project with the community in the hopes that it will be useful to some members of the community.\n [1] dike\n [2] DikeDataset\n [3] Toward Identifying APT Malware through API System Calls\n    submitted by    /u/iosifache  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsv57j/dataset_with_labeled_benign_and_malicious_files/",
          "publishedOn": "2022-03-31T08:25:21.000Z",
          "wordCount": 279,
          "title": "Dataset with labeled benign and malicious files",
          "imageUrl": "https://external-preview.redd.it/nzOaZfhG60fpMW-xNsj6cTDDssciB1V0UneWyje-v-k.jpg?auto=webp&s=a3629eb3f04f2a2fed7993a5fe7e09f6e3038ba5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsv417/disney_princesses_according_to_ai_is_this_done/",
          "author": null,
          "description": "submitted by    /u/cyberpunk1Q84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsv417/disney_princesses_according_to_ai_is_this_done/",
          "publishedOn": "2022-03-31T08:22:42.000Z",
          "wordCount": 177,
          "title": "Disney princesses according to AI. Is this done manually or through an AI app?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsqdg7/alist_celebrities_read_my_movie_script/",
          "author": null,
          "description": "Made this video tonight I had A.I. voices read my script for an upcoming movie.\n https://www.youtube.com/watch?v=RkK-iGAGcHA\n    submitted by    /u/PapermoonPictures  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsqdg7/alist_celebrities_read_my_movie_script/",
          "publishedOn": "2022-03-31T03:09:02.000Z",
          "wordCount": 111,
          "title": "A-List Celebrities Read my movie script",
          "imageUrl": "https://external-preview.redd.it/YBzYXCTJoej1uBzsY3qVvVgpVjWtb9Wb8p1A0ruCMXE.jpg?auto=webp&s=5eda08ae9d5f582b2bf1031ef8416091c3445b42"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsmk24/will_smiths_ai_persona_was_asked_about_his/",
          "author": null,
          "description": "submitted by    /u/kuasha7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsmk24/will_smiths_ai_persona_was_asked_about_his/",
          "publishedOn": "2022-03-30T23:43:58.000Z",
          "wordCount": 114,
          "title": "Will Smith's AI Persona was asked about his slapping performance on Oscar Stage",
          "imageUrl": "https://external-preview.redd.it/1mz_CTNsP9zdezGGCDxh3v194bAcGUAfmK2z3CF_m8o.png?format=pjpg&auto=webp&s=a6caf6e50413ffd8294134905effea77a0d359df"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tslzhy/researchers_from_mit_csail_introduce_privid_an_ai/",
          "author": null,
          "description": "Surveillance cameras have an identity crisis exacerbated by a conflict between function and privacy. Machine learning techniques have automated video content analysis on a vast scale as these sophisticated small sensors have shown up seemingly everywhere. Still, with increased mass monitoring, there are currently no legally enforceable standards to curb privacy invasions.\n Security cameras have evolved into wiser and more capable tools than the grainy images of the past, which were frequently used as the “hero tool” in crime dramas. Video surveillance can now assist health regulators in determining the percentage of persons using masks, transportation departments in monitoring the density and flow of automobiles, cyclists and walkers, and businesses in gaining a better understanding of buying habits. But why has privacy remained a second-class citizen?\n Privid\n Currently, the footage is retrofitted with blurred faces or black boxes. This prevents analysts from asking some legitimate questions (for example, are people wearing masks? ). Dissatisfied with the present status quo, MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) developed a system with other institutions to better guarantee privacy in surveillance video footage. The system, dubbed “Privid,” allows analysts to input video data searches and then adds a tiny amount of noise (additional data) to the result to ensure that no one can be identified. The method is based on a formal notion of privacy known as “differential privacy,” which permits without having access to aggregate statistics about private data disclosing individually identifying information.\n Continue Reading\n Paper: https://arxiv.org/pdf/2106.12083.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tslzhy/researchers_from_mit_csail_introduce_privid_an_ai/",
          "publishedOn": "2022-03-30T23:14:51.000Z",
          "wordCount": 383,
          "title": "Researchers from MIT CSAIL Introduce ‘Privid’: an AI Tool, Build on Differential Privacy, to Guarantee Privacy in Video Footage from Surveillance Cameras",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsknzb/this_guy_used_ai_to_create_a_voice_model_of_sam/",
          "author": null,
          "description": "submitted by    /u/KirbyBWCH  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsknzb/this_guy_used_ai_to_create_a_voice_model_of_sam/",
          "publishedOn": "2022-03-30T22:10:32.000Z",
          "wordCount": 135,
          "title": "This guy used AI to create a voice model of Sam O'Nella and made a video in his style.",
          "imageUrl": "https://external-preview.redd.it/vDcDjcNpXoh5JTnftcETwPoOLP1oyyU6wauS8W1VX94.jpg?auto=webp&s=1d0b4e033ba95976ef18f5260a1d1172d879b1c4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tscamj/image_classification_with_vision_transformers_in/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tscamj/image_classification_with_vision_transformers_in/",
          "publishedOn": "2022-03-30T17:57:21.000Z",
          "wordCount": 105,
          "title": "Image Classification With Vision Transformers in a Gradio Web App",
          "imageUrl": "https://preview.redd.it/m4dx67e28kq81.png?auto=webp&s=449d882a75051805fa1b9685b9accd260d606c0d"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsbf8i/meta_ai_team_opensources_mephisto_a_new_platform/",
          "author": null,
          "description": "Training datasets are very important for experimenting with varied data to train new AI models. However, many commonly used public data sets contain labeling errors. This makes it challenging to train robust models, particularly for novel tasks. Many researchers use techniques such as employing a variety of data quality control procedures to overcome these shortcomings. However, there is no centralized repository consisting of examples of using these strategies.\n Meta AI researchers have recently released Mephisto. It is a new platform to collect, share, and iterate on the most promising approaches to collecting training datasets for AI models. Researchers can exchange unique collecting strategies with Mephisto in a reusable and iterable format. It also allows them to change out components and quickly locate the exact annotations required, minimizing the barrier to custom task creation.\n Continue Reading\n Github: https://github.com/facebookresearch/Mephisto\n Documentation: https://mephisto.ai/\n https://preview.redd.it/mae7igz11kq81.png?width=1920&format=png&auto=webp&s=764145c4350d73049ae49faafd43ac3806712a2d\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsbf8i/meta_ai_team_opensources_mephisto_a_new_platform/",
          "publishedOn": "2022-03-30T17:17:57.000Z",
          "wordCount": 271,
          "title": "Meta AI Team Open-Sources Mephisto: A New Platform For Open And Collaborative Way Of Collecting Data To Train ML Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tsa1jr/quantum_computing_memristor_to_unlock_ai/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tsa1jr/quantum_computing_memristor_to_unlock_ai/",
          "publishedOn": "2022-03-30T16:15:29.000Z",
          "wordCount": 100,
          "title": "Quantum Computing Memristor To Unlock AI",
          "imageUrl": "https://external-preview.redd.it/QSx4fTwcG6wL5-HA7YZ_hQ0eF_CUwfgWA_4XBXnm2LM.jpg?auto=webp&s=a0097034ba7f42b221723603700dd9415bab7d95"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts44n7/new_exciting_study_grievers_and_chatbots/",
          "author": null,
          "description": "submitted by    /u/annaksig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts44n7/new_exciting_study_grievers_and_chatbots/",
          "publishedOn": "2022-03-30T11:18:40.000Z",
          "wordCount": 92,
          "title": "NEW EXCITING STUDY: GRIEVERS AND CHATBOTS",
          "imageUrl": "https://preview.redd.it/oxfcu7hx8iq81.png?auto=webp&s=20e48a8196e4bb4b5217734b2cb048f3ac202f59"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts3pv4/ai_that_can_expand_the_borders_of_video/",
          "author": null,
          "description": "Hi do any of you know the name of a AI that can expand the borders of a video\n By making the AI guess what would be around the square of the video? \n I remember I once saw something like this in a video on two minute papers youtube channel\n Where they used an example with a eagle flying in the sky\n But I haven't been able to find the video since\n And I have been looking for a long time \n But having such AI will be very help full to video editing\n    submitted by    /u/Pwichmann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts3pv4/ai_that_can_expand_the_borders_of_video/",
          "publishedOn": "2022-03-30T10:53:01.000Z",
          "wordCount": 240,
          "title": "AI that can expand the borders of video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts3f5q/best_data_visualization_books_for_data_science_to/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts3f5q/best_data_visualization_books_for_data_science_to/",
          "publishedOn": "2022-03-30T10:33:14.000Z",
          "wordCount": 121,
          "title": "Best Data Visualization books for Data Science to read in 2022",
          "imageUrl": "https://external-preview.redd.it/rEVkX36XqUqfx02t3OY3403ckUBuo5KsAwGuKQhnB6M.jpg?auto=webp&s=5dcffcc83a951be0671a7b65b6f5a0fc7856ccf3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts1tyo/explaining_overfitting_and_why_100_accuracy_is/",
          "author": null,
          "description": "What are your approaches to explaining these topics to business people?\n    submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts1tyo/explaining_overfitting_and_why_100_accuracy_is/",
          "publishedOn": "2022-03-30T08:34:24.000Z",
          "wordCount": 211,
          "title": "Explaining overfitting and why 100% accuracy is not a guarantee to clients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts1lcj/what_metric_do_you_use_for_hyperparameter_tuning/",
          "author": null,
          "description": "Pretty much as the title says. I work in research with electroencephalography (EEG) classification (those electrodes they stick on peoples heads). EEG is notoriously noisy and prone to overfitting, I have generally used validation accuracy as an optimization metric for a Bayesian HP tuning approach, but I find this tends to result in fairly unreliable models, even using cross validation approaches. These models are really noisy and while they may reach pretty good accuracy, that is a single epoch where it got a decent spike. I was wondering if there are common resolutions for this that I have missed, or if anyone has had luck with a custom metric that takes into account not just the validation accuracy, but the consistency and the difference between validation and training accuracy to better account for overfitting. Thanks!\n    submitted by    /u/Ozzod  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts1lcj/what_metric_do_you_use_for_hyperparameter_tuning/",
          "publishedOn": "2022-03-30T08:16:19.000Z",
          "wordCount": 235,
          "title": "What metric do you use for hyperparameter tuning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts0hg8/google_docs_now_autogenerate_short_summaries/",
          "author": null,
          "description": "Many of us find it difficult to keep up with the daily flood of documents in our inboxes. These could be reports, reviews, briefs, policies, etc. Nowadays, readers wish to have a concise summary including major elements of their document, helping them prioritize their work efficiently. However, writing a document summary from scratch manually is a time-consuming task.\n To aid document writers in writing content summaries, Google announced a new feature enabling Google Docs to generate ideas automatically when they are available. The team employs a machine learning (ML) model to understand document text and provide a one- to two-sentence natural language description of the material. On the other hand, the document writer retains complete control, choosing whether to accept the proposal as-is, make necessary adjustments to better capture the document summary, or ignore it entirely. This section, combined with the outline, can help readers understand and navigate the work at a high level. While anybody can contribute summaries, only Google Workspace business customers have access to auto-generated ideas.\n Continue Reading\n https://i.redd.it/pcrn8rqmxgq81.gif\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts0hg8/google_docs_now_autogenerate_short_summaries/",
          "publishedOn": "2022-03-30T06:53:03.000Z",
          "wordCount": 297,
          "title": "Google Docs Now Auto-Generate Short Summaries Using Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/ts088h/is_there_an_ai_for_psychological_testing/",
          "author": null,
          "description": "I want to test myself using a neural net in lieu of psychological testing, and was wondering if that's even publicly available.\n    submitted by    /u/AdvancedRazzmatazz46  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/ts088h/is_there_an_ai_for_psychological_testing/",
          "publishedOn": "2022-03-30T06:34:34.000Z",
          "wordCount": 119,
          "title": "Is there an AI for psychological testing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/try6jr/ai_beats_8_world_champions_at_bridge/",
          "author": null,
          "description": "submitted by    /u/nick7566  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/try6jr/ai_beats_8_world_champions_at_bridge/",
          "publishedOn": "2022-03-30T04:23:13.000Z",
          "wordCount": 139,
          "title": "AI beats 8 world champions at bridge",
          "imageUrl": "https://external-preview.redd.it/WpwXEa7gVOYU6ZgHWiq4aq0r36J-t9FFX1f3bjs0BPs.jpg?auto=webp&s=19a295e3dfbc0682998ddf39a683bb5775f5a64c"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/trps2d/flower_team_releases_flower_018_with_cool_new/",
          "author": null,
          "description": "Flower is an end-to-end federated learning framework that allows for a smoother transition from simulation-based experimental research to system research on many real-world edge devices. Flower has individual strengths in both domains (i.e., simulation and real-world devices) and the capacity to switch back and forth between the two extremes as needed throughout exploration and development. Researchers present use cases that drive our viewpoint, design goals, the resultant framework architecture, and comparisons to other frameworks in this part.\n Federated Learning (FL) has shown to be a viable option for enabling edge devices to develop a shared prediction model cooperatively while maintaining their training data on the device, divorcing the capacity to execute machine learning from the requirement to store data in the cloud. However, FL is challenging to implement practically in size and system heterogeneity. Although there are several research frameworks for simulating FL algorithms, none of them facilitate the investigation of scalable FL workloads on heterogeneous edge devices.\n Flower 0.18 released\n Thanks to a longer gap than usual, the latest Flower release has more upgrades than any previous release. Also, thanks to the wonderful community for your continuing support and generosity.\n Continue Reading\n Paper: https://arxiv.org/pdf/2007.14390.pdf\n Github: https://github.com/adap/flower\n https://preview.redd.it/ywtttqlnceq81.png?width=1920&format=png&auto=webp&s=893fbe79c190aa66e293b296e35d4096eb178f97\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/trps2d/flower_team_releases_flower_018_with_cool_new/",
          "publishedOn": "2022-03-29T22:12:42.000Z",
          "wordCount": 319,
          "title": "Flower Team Releases Flower 0.18 With Cool New Updates For Federated Learning",
          "imageUrl": "https://external-preview.redd.it/FuxmveI-dqShP8OJKG9Bz9Qlu7YQcgDqKb2mTYJy1Cs.jpg?auto=webp&s=0130f2eec883506ce792a344d13ec47bc9f072c4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/treb6c/carbon_vs_silicon_molecule/",
          "author": null,
          "description": "Since we are about to create a silicon-based lifeform I was looking up the differences between the carbon and the silicon molecule.\n https://www.differencebetween.com/difference-between-silicon-and-vs-carbon/#:~:text=The%20key%20difference%20between%20silicon,in%20the%20outer%20energy%20level.\n    submitted by    /u/asenz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/treb6c/carbon_vs_silicon_molecule/",
          "publishedOn": "2022-03-29T18:43:52.000Z",
          "wordCount": 110,
          "title": "Carbon vs Silicon molecule",
          "imageUrl": "https://external-preview.redd.it/lUw4Jcoa4AbN44kBUWY7bebBXJy3zy26-2qTmz4nzI4.jpg?auto=webp&s=4ac0a1a373474ab0ef352da2e0bc4f30830147b5"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/treaze/last_week_in_ai_super_fast_3d_perception_from/",
          "author": null,
          "description": "submitted by    /u/regalalgorithm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/treaze/last_week_in_ai_super_fast_3d_perception_from/",
          "publishedOn": "2022-03-29T18:43:35.000Z",
          "wordCount": 157,
          "title": "Last Week in AI: Super fast 3D perception from Nvidia, Ukraine uses face recognition to identify dead Russian soldiers, US-China AI collaboration drops, and more!",
          "imageUrl": "https://external-preview.redd.it/DUVRBt6nWViUJiU3Oon9XV8cjCxS2elyCHo0wjAwnD8.jpg?auto=webp&s=f8dcd7fc586f0c7f76e98d0146ef3d1d3272b99b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tra5qt/google_maps_utilizes_machine_learning_to_block/",
          "author": null,
          "description": "In their recent post on how Google keeps Maps information reliable, the company elaborates how they use machine learning and human operators to block nearly 100 million attempted fraudulent edits to Google Business Profiles. Machine learning, in simple terms, is a sort of artificial intelligence (AI) that lets software applications improve their accuracy at predicting events without having to be explicitly programmed to do so. Machine learning algorithms use past data as input to forecast new output values.\n The world changed with the introduction of vaccinations, revisions to mask regulations, and new COVID variations in 2021. Accordingly, their Maps community updated Google Maps with further information about their nearby areas. Their contributions have helped Google provide updated company information, such as a location’s hours of operation or its health and safety regulations, for 30% more firms in 2021 than 2020. \n Quick Read\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tra5qt/google_maps_utilizes_machine_learning_to_block/",
          "publishedOn": "2022-03-29T17:23:05.000Z",
          "wordCount": 291,
          "title": "Google Maps Utilizes Machine Learning To Block Nearly 100 Million Fraudulent Edits",
          "imageUrl": "https://external-preview.redd.it/UIAfp_x6OO1l2LRNIywGJUMRM-8kNuY5gXc2_NZ7g6k.jpg?auto=webp&s=8aa24ad66a579497694e0bc8d4e189f27563376e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tr6mpr/tinyml_gearbox_fault_prediction_on_a_4_mcu/",
          "author": null,
          "description": "Is it possible to make an AI-driven system that predicts gearbox failure on a simple $4 MCU? How to automatically build a compact model that does not require any additional compression? Can a non-data scientist implement such projects successfully?\n I will answer all these questions in my new project.\n In industry (e.g., wind power, automotive), gearboxes often operate under random speed variations. A condition monitoring system is expected to detect faults, broken tooth conditions and assess their severity using vibration signals collected under different speed profiles.\n Modern cars have hundreds of thousands of details and systems where it is necessary to predict breakdowns, control the state of temperature, pressure, etc.As such, in the automotive industry, it is critically important t…",
          "link": "https://www.reddit.com/r/artificial/comments/tr6mpr/tinyml_gearbox_fault_prediction_on_a_4_mcu/",
          "publishedOn": "2022-03-29T16:22:14.000Z",
          "wordCount": 1646,
          "title": "TinyML Gearbox Fault Prediction on a $4 MCU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqyohn/metaverse_is_considered_the_future_of_internet_it/",
          "author": null,
          "description": "submitted by    /u/Nitorblog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqyohn/metaverse_is_considered_the_future_of_internet_it/",
          "publishedOn": "2022-03-29T12:30:07.000Z",
          "wordCount": 150,
          "title": "Metaverse is considered the future of internet. It is used to designate a universe beyond physical world. Watch our video to know more about it.",
          "imageUrl": "https://external-preview.redd.it/eIR632I5jMX229fiYS9jb_ZPKWa5zpP9ke34ZnlU_V0.png?format=pjpg&auto=webp&s=cce4ff470dc534bf0022b4a08cf5f7de20a118af"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqxzgx/building_decision_trees_entropy_information_gain/",
          "author": null,
          "description": "submitted by    /u/TheNerdyDevYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqxzgx/building_decision_trees_entropy_information_gain/",
          "publishedOn": "2022-03-29T11:49:56.000Z",
          "wordCount": 112,
          "title": "Building Decision Trees - Entropy, Information Gain & Gini Impurity",
          "imageUrl": "https://external-preview.redd.it/Ew_3E7KxioaPCr22V1PnzglHzpPRYF2-9_oof4CjeMg.jpg?auto=webp&s=029c0a24a2f872d3624a9585848e6630a3ea6c9b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqwqui/china_researches_brainscale_ai/",
          "author": null,
          "description": "https://mixed-news.com/en/artificial-intelligence-china-researches-brain-scale-ai/\n From the article:\n In China, the state and companies are researching AI models with trillions of parameters. They want to prove that they can develop “brain-scale” AI.\n ...\n In a new paper, researchers from Tsinghua University, Alibaba Group, Zhejiang Lab and Beijing Academy of Artificial Intelligence present BaGuaLu, a framework that enables the training of large AI models using the Mixture-of-Experts (MoE) architecture.\n In an initial test, the researchers trained a 1.93 trillion model with their framework, outperforming Google’s Switch Transformer. They also demonstrate that their framework enables models with 14.5 trillion and a full 174 trillion parameters.\n ...\n The team expects that giant multimodal AI models could have far-reaching implications for numerous AI applications.\n    submitted by    /u/Sephirio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqwqui/china_researches_brainscale_ai/",
          "publishedOn": "2022-03-29T10:29:46.000Z",
          "wordCount": 249,
          "title": "China researches “brain-scale” AI",
          "imageUrl": "https://external-preview.redd.it/JhZYBigKAty1Eq96lCCsaxYnvApivFIyrmwoeLVCjDk.jpg?auto=webp&s=70729ea061997be594080e36d0fcf14e4b9aff66"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqwp4r/9_best_deep_learning_books_for_beginners_to/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqwp4r/9_best_deep_learning_books_for_beginners_to/",
          "publishedOn": "2022-03-29T10:26:21.000Z",
          "wordCount": 118,
          "title": "9+ Best Deep Learning books for beginners to Expert 2022 [Updated] -",
          "imageUrl": "https://external-preview.redd.it/x06CLmBrTjzvn6iNlNFbABPzVnEjuxHaSMUgpftyi_Y.jpg?auto=webp&s=3a2505e77c664e13c7517f5c2565a4d6cf3e39a8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqthl4/jax_flower_for_federated_learning_gives_machine/",
          "author": null,
          "description": "Google researchers created JAX to conduct NumPy computations on GPUs and TPUs. DeepMind uses it to help and expedite its research, and it is increasingly gaining popularity. Differentiation with grad(), vectorization with map(), and JIT-compilation (just-in-time) with jit are some of the composable functions required for machine learning research in JAX (). As a result, adding a JAX-based workload to the Flower code samples is a must-have. The combination of JAX and Flower allows ML and FL researchers to employ the deep learning framework that their projects demand. The updated code example now serves as a template for migrating existing JAX projects to a federated environment.\n It’s pretty simple to put up a centralized machine learning architecture, and the JAX developer documentation has multiple examples. Because the ML model parameters are stored in the DeviceArray data format, setting up the federated workload requires some knowledge of JAX. To be compatible with the Flower NumPyClient, those arguments must be converted to NumPy ndarrays. The JAX meets Flower example below demonstrates how a Flower setup might work.\n Continue Reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqthl4/jax_flower_for_federated_learning_gives_machine/",
          "publishedOn": "2022-03-29T06:27:38.000Z",
          "wordCount": 311,
          "title": "JAX + Flower For Federated Learning Gives Machine Learning Researchers The Flexibility To Use The Deep Learning Framework For Their Projects",
          "imageUrl": "https://external-preview.redd.it/FuxmveI-dqShP8OJKG9Bz9Qlu7YQcgDqKb2mTYJy1Cs.jpg?auto=webp&s=0130f2eec883506ce792a344d13ec47bc9f072c4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqs0mk/pastiche_master_exemplarbased_highresolution/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqs0mk/pastiche_master_exemplarbased_highresolution/",
          "publishedOn": "2022-03-29T04:49:01.000Z",
          "wordCount": 104,
          "title": "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer",
          "imageUrl": "https://external-preview.redd.it/Hkj3t-Kg395q-4iOaAIEz6LS8gtTRqg71oLNGtfE2G0.png?format=pjpg&auto=webp&s=50e4ffaac3dff104741d0844c8e48f253c2ea12a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqq75c/discussions_on_pattern_theory/",
          "author": null,
          "description": "Hi all,\n I have been interested in a field called pattern theory for some time now. Its a mathematical formalism to describe patterns in the world, as well as a framework for developing ai.\n As far as I can tell, pattern theory seems to be somewhat of a dead field. I'm not sure who is possibly still thinking about it other than a single digit number of academics (e.g. David Mumford). I find this a bit unfortunate, since while I'm still a bit naïve about the field, I'd like to find people I could talk to about it.\n Does anyone have any recommendations for where I could find people I could talk to about pattern theory/bounce ideas off of relating to pattern theory?\n Thanks in advance\n    submitted by    /u/patterntheoryacc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqq75c/discussions_on_pattern_theory/",
          "publishedOn": "2022-03-29T03:00:53.000Z",
          "wordCount": 210,
          "title": "Discussions on Pattern Theory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqls56/can_ai_create_a_safer_online_world/",
          "author": null,
          "description": "submitted by    /u/ML_Firefighter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqls56/can_ai_create_a_safer_online_world/",
          "publishedOn": "2022-03-28T23:02:38.000Z",
          "wordCount": 103,
          "title": "Can AI create a safer online world?",
          "imageUrl": "https://external-preview.redd.it/VaNRQZfSPskVrTdcVdLbEPbJWey9OAsw4YUKFp1prfw.jpg?auto=webp&s=b5b54f381569faae56c7bc363bfcdba4d18d17b3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqjyi9/do_people_build_physical_perceptrons/",
          "author": null,
          "description": "A friend and I are thinking about building a physical perceptron as a summer project. However, I cannot find any resources on the physical implementation of the perceptron since Rosenblatt's in the 40's. Does anyone do this? What are some good resources?\n    submitted by    /u/HoldDoorHoldor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqjyi9/do_people_build_physical_perceptrons/",
          "publishedOn": "2022-03-28T21:33:09.000Z",
          "wordCount": 133,
          "title": "Do people build physical perceptrons?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqieul/weekly_china_ai_newsletter_china_strengthens/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqieul/weekly_china_ai_newsletter_china_strengthens/",
          "publishedOn": "2022-03-28T20:22:10.000Z",
          "wordCount": 154,
          "title": "Weekly China AI Newsletter: China Strengthens Ethics Reviews on AI, Life Science; Users Can Turn off Recommendation Algorithms; Chinese Self-Driving Startup Raises $400 Million",
          "imageUrl": "https://external-preview.redd.it/E96BeKT9CIKWR2g7HtItkGzuUbrPboSPzL-CpbVh4v4.jpg?auto=webp&s=4a67b7b6a8e6f2507fcd90a1fad30c0f319898ef"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqfux5/nerf_research_turns_2d_photos_into_3d_scenes/",
          "author": null,
          "description": "submitted by    /u/MarS_0ne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqfux5/nerf_research_turns_2d_photos_into_3d_scenes/",
          "publishedOn": "2022-03-28T18:27:44.000Z",
          "wordCount": 119,
          "title": "NeRF Research Turns 2D Photos Into 3D Scenes",
          "imageUrl": "https://external-preview.redd.it/QHJvYirPpHx1vFDOCsbWNlCcxNOr8pCCWtMYboJGlGw.jpg?auto=webp&s=d3aaf26600f3af092efef88858826196f36294b0"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqex1u/artificial_intelligence_machine_learning_and/",
          "author": null,
          "description": "submitted by    /u/pmz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqex1u/artificial_intelligence_machine_learning_and/",
          "publishedOn": "2022-03-28T17:44:59.000Z",
          "wordCount": 100,
          "title": "Artificial Intelligence, Machine Learning and Society",
          "imageUrl": "https://external-preview.redd.it/cww0EXz-wYJnuFb5laspnNl598Uvsy5oV7-mp1iVXmo.jpg?auto=webp&s=744e60e92440c105aa3e1d01edb110d67d4d9974"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqdlou/11_best_python_books_for_data_science_beginners/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqdlou/11_best_python_books_for_data_science_beginners/",
          "publishedOn": "2022-03-28T16:47:21.000Z",
          "wordCount": 127,
          "title": "11 Best Python Books for Data Science beginners to advanced to read in 2022 -",
          "imageUrl": "https://external-preview.redd.it/3pdSs8qDH1dxGz1jom5eFGa2iAZiKGkP654eztme7y0.jpg?auto=webp&s=ac621ceb3cbbdfba20cd59821ecd81a25a9d798f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tqd5gy/meet_jessica_from_linkedin_she_is_not_a_human/",
          "author": null,
          "description": "submitted by    /u/satish_gaire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tqd5gy/meet_jessica_from_linkedin_she_is_not_a_human/",
          "publishedOn": "2022-03-28T16:27:23.000Z",
          "wordCount": 112,
          "title": "Meet Jessica From LinkedIn, She Is Not A Human Being",
          "imageUrl": "https://external-preview.redd.it/Pn6YcUeK0qg9-t2-dB4k0Z0Umwx6i-4YYXOVWSNJLlg.jpg?auto=webp&s=fe13971097e35b77fa26163f385a63455fd1af47"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tq9z0g/a_miniconversation_with_kanye_wests_ai_persona/",
          "author": null,
          "description": "submitted by    /u/kuasha7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tq9z0g/a_miniconversation_with_kanye_wests_ai_persona/",
          "publishedOn": "2022-03-28T14:01:11.000Z",
          "wordCount": 111,
          "title": "A mini-conversation with Kanye West's AI persona ended on a hilarious note",
          "imageUrl": "https://external-preview.redd.it/mrqGL7gmiXpodq1NjDonjHdTmgMfgMSzC0WUf7PJxJg.png?format=pjpg&auto=webp&s=6ed68ce2ff8f7ca4fb7125bbab397152d7afc17b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tq8rwc/datarobots_plan_to_democratize_machine_learning/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tq8rwc/datarobots_plan_to_democratize_machine_learning/",
          "publishedOn": "2022-03-28T13:00:19.000Z",
          "wordCount": 109,
          "title": "DataRobot’s plan to democratize machine learning with no-code AI",
          "imageUrl": "https://external-preview.redd.it/c1cYrmuLjC8mc2p2ntDOhFiEZ-9T_fUDwXDYTNB0wQM.jpg?auto=webp&s=f2c7082d89a6eeffcb1bcd57a91ab8aaa2e543f8"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tq3c3b/top_5_python_time_series_libraries/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tq3c3b/top_5_python_time_series_libraries/",
          "publishedOn": "2022-03-28T06:51:33.000Z",
          "wordCount": 102,
          "title": "Top 5 Python Time Series Libraries",
          "imageUrl": "https://external-preview.redd.it/PSJx7xNt4F5lZFn1vZlAKimT6kKGCTVhpeIuJiCTBNk.jpg?auto=webp&s=5030d7619636a75972e5c0f6fd9b10278bf4b403"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpz3wg/learning_to_generate_line_drawings_that_convey/",
          "author": null,
          "description": "submitted by    /u/Illustrious_Row_9971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpz3wg/learning_to_generate_line_drawings_that_convey/",
          "publishedOn": "2022-03-28T02:25:25.000Z",
          "wordCount": 183,
          "title": "Learning to generate line drawings that convey geometry and semantics (CVPR 2022)",
          "imageUrl": "https://external-preview.redd.it/TizNVkYtsjAtBNH3SHzreECfA9osX50VQWDlQiAltKY.png?format=pjpg&auto=webp&s=adc8b2a5c0e3ffe2ad41fedb4f043090bc7418d4"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpz2t7/new_ai_tool/",
          "author": null,
          "description": "Now unlimited uses for anyone: https://botbox.dev/generator\n    submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpz2t7/new_ai_tool/",
          "publishedOn": "2022-03-28T02:23:42.000Z",
          "wordCount": 91,
          "title": "New AI Tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpxtud/the_latest_marketing_tactic_on_linkedin/",
          "author": null,
          "description": "submitted by    /u/Representative-Job23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpxtud/the_latest_marketing_tactic_on_linkedin/",
          "publishedOn": "2022-03-28T01:12:48.000Z",
          "wordCount": 112,
          "title": "The latest marketing tactic on LinkedIn: AI-generated faces : NPR",
          "imageUrl": "https://external-preview.redd.it/XVJASZZxt75i_Qx2T4MskxIt7_gPuPquuwyXhqtq3NY.jpg?auto=webp&s=82a833bf113ba807964e81f62f280fd6d7173486"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpuu9k/ai_that_turns_written_documents_into_practice/",
          "author": null,
          "description": "submitted by    /u/143openyourmind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpuu9k/ai_that_turns_written_documents_into_practice/",
          "publishedOn": "2022-03-27T22:26:05.000Z",
          "wordCount": 128,
          "title": "A.I. that turns written documents into practice tests. For easy learning. Is this easy or challenging programming?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tptssd/check_out_this_research_summary_article_based_on/",
          "author": null,
          "description": "Deep Neural Networks (DNNs) have excelled at solving complex real-world problems, however, training a good DNN has become more complex. It is challenging to ensure that the optimizers used will converge to reliable minima with acceptable model performance when only minimizing the conventional empirical loss.\n Tsinghua University’s research team proposes Stochastic Scheduled SAM (SS-SAM), a novel and effective DNN training strategy. In SS-SAM, the optimizer is set up by a predetermined scheduling function to run a random trial at each update step, which selects whether to perform the SGD or SAM optimization at random. The overall number of propagation pairs could be significantly decreased in this approach. The team’s approach provides equivalent or higher model training performance at a lower computational cost than baseline sharpness-aware minimization (SAM).\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.09962.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tptssd/check_out_this_research_summary_article_based_on/",
          "publishedOn": "2022-03-27T21:34:10.000Z",
          "wordCount": 312,
          "title": "Check out this research summary article based on the paper 'SS-SAM: Stochastic Scheduled Sharpness-Aware Minimization for Efficiently Training Deep Neural Networks' where Researchers From Tsinghua University Propose ‘Stochastic Scheduled SAM’ (SS-SAM) for reducing the computational overhead",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tptgix/what_are_easy_to_use_image_editing_ais/",
          "author": null,
          "description": "submitted by    /u/xXLisa28Xx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tptgix/what_are_easy_to_use_image_editing_ais/",
          "publishedOn": "2022-03-27T21:17:26.000Z",
          "wordCount": 101,
          "title": "What are easy to use image editing AIs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpq5e1/artificial_nightmares_limgrave_clip_guided/",
          "author": null,
          "description": "submitted by    /u/Thenamessd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpq5e1/artificial_nightmares_limgrave_clip_guided/",
          "publishedOn": "2022-03-27T18:39:55.000Z",
          "wordCount": 136,
          "title": "Artificial Nightmares: Limgrave || Clip Guided Diffusion AI Art Video [4K 16 FPS]",
          "imageUrl": "https://external-preview.redd.it/-NLxMO7RJUsGN_m0Q9Ht9x-rs1eZzOziGqC45LqdVeI.jpg?auto=webp&s=618b15f4d252ba3008c7a0a6ec3b7f49730f5739"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpou15/nvidia_research_turns_2d_photos_into_3d_scenes_in/",
          "author": null,
          "description": "submitted by    /u/qptbook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpou15/nvidia_research_turns_2d_photos_into_3d_scenes_in/",
          "publishedOn": "2022-03-27T17:35:17.000Z",
          "wordCount": 130,
          "title": "NVIDIA Research Turns 2D Photos Into 3D Scenes in the Blink of an AI",
          "imageUrl": "https://external-preview.redd.it/avEfVzzfxH_XMkyIVDKUGstdygF8nOzfqXrztVXjxzU.jpg?auto=webp&s=05e07e27abcd7d7290ce2d219f8f433985093928"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpoc3c/this_endless_live_tv_show_run_entirely_by_ai/",
          "author": null,
          "description": "submitted by    /u/the_embassy_official  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpoc3c/this_endless_live_tv_show_run_entirely_by_ai/",
          "publishedOn": "2022-03-27T17:10:19.000Z",
          "wordCount": 381,
          "title": "This endless live TV show run entirely by AI characters",
          "imageUrl": "https://preview.redd.it/ndob867ykyp81.png?auto=webp&s=3f015397314d3d4ccc89604ea9b8dc7d8d82e843"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpnsw0/7_best_natural_language_processing_courses_2022/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpnsw0/7_best_natural_language_processing_courses_2022/",
          "publishedOn": "2022-03-27T16:44:40.000Z",
          "wordCount": 118,
          "title": "7 Best Natural Language Processing Courses (2022) | Best NLP Courses -",
          "imageUrl": "https://external-preview.redd.it/5H2hA1Y-EUYX8VkmXRdkCl95_D4XC5s0iR6KW8GYmJs.jpg?auto=webp&s=32bb20f8204298387cf5763f228d1f3a3a595935"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpndxo/if_you_have_expertise_in_this_field_is_it/",
          "author": null,
          "description": "As in...get the voice down from improving an A.I recording.\n Then, give it some basic code or responses that you had at different ages.\n Also, getting a bunch of 3D images of yourself.\n Then coding it with some basic \"values\" and creating some sort of generic conditional statement for the 3 basic values that it has that match yours.\n Then, over time, actually diving into artificial intelligence and slowly updating and replacing those to continue improving it to match you (and your growth)?\n Hmmm, I wonder if there would be a way to preserve it. Everything changes (like sites -> VR and so on). So some sort of \"survival\" instinct (which seems impossible to code but would be fun to try undertaking).\n    submitted by    /u/the_evil_intp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpndxo/if_you_have_expertise_in_this_field_is_it/",
          "publishedOn": "2022-03-27T16:24:22.000Z",
          "wordCount": 647,
          "title": "If you have expertise in this field, is it realistic whatsoever to create an A.I version of yourself to live on (let's say work on it for 30 years, starting from now)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpmjje/future_after_automation_and_agi/",
          "author": null,
          "description": "submitted by    /u/HumanSeeing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpmjje/future_after_automation_and_agi/",
          "publishedOn": "2022-03-27T15:43:29.000Z",
          "wordCount": 478,
          "title": "Future after Automation and AGI",
          "imageUrl": "https://external-preview.redd.it/5remJy-FxVWAVsInA8egwymxru08nhIj7WxvKQ4Xt3Q.jpg?auto=webp&s=aaf653c2b0d1a270e8fd8d3bc2d6eb5d20c30b4b"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpm86a/face_filters_on_the_web_from_just_text/",
          "author": null,
          "description": "submitted by    /u/pmz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpm86a/face_filters_on_the_web_from_just_text/",
          "publishedOn": "2022-03-27T15:27:39.000Z",
          "wordCount": 109,
          "title": "Face filters on the web from just text descriptions",
          "imageUrl": "https://external-preview.redd.it/78QbKWN9TXJq4YXtaSyvNxWbRzsE8HQb1RIsEF3PqOY.jpg?auto=webp&s=e57c9deabb148eb9061fc26548d289354d00234e"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tpcgi4/impressed_with_alphafold_checkout_this_protein/",
          "author": null,
          "description": "DeepMind released AlphaFold 2 last year, which made headlines for its incredible accuracy in protein structure prediction. The success of AlphaFold demonstrated that deep neural networks might be used to solve challenging and critical structural biology problems.\n FastFold is a highly effective protein structure prediction model formulation for training and inference developed by a group of researchers from the National University of Singapore. Although AlphaFold 2 is a game-changer in protein structure prediction, training and inference remain time-consuming and costly. This is something that the study team is concerned about.\n Continue Reading This Article Here\n Paper: https://arxiv.org/pdf/2203.00854v1.pdf\n Github: https://github.com/hpcaitech/FastFold\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tpcgi4/impressed_with_alphafold_checkout_this_protein/",
          "publishedOn": "2022-03-27T04:29:04.000Z",
          "wordCount": 273,
          "title": "👉 Impressed With AlphaFold? Checkout This Protein Structure Prediction Model (FastFold) That Reduces AlphaFold’s Training Time From 11 Days To 67 Hours",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tp7wpj/i_created_a_new_ai_art_maker_program_free/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tp7wpj/i_created_a_new_ai_art_maker_program_free/",
          "publishedOn": "2022-03-26T23:57:35.000Z",
          "wordCount": 111,
          "title": "I created a new AI art maker program (free)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tp7h6k/how_does_a_selfdriving_car_see_waymo_s_system/",
          "author": null,
          "description": "submitted by    /u/OnlyProggingForFun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tp7h6k/how_does_a_selfdriving_car_see_waymo_s_system/",
          "publishedOn": "2022-03-26T23:33:12.000Z",
          "wordCount": 112,
          "title": "How Does a Self-Driving Car See? (Waymo ‘s system explained)",
          "imageUrl": "https://external-preview.redd.it/sTXR8P0nRfSLXauZE5GcEcjD9TKBrk7X2bNl7X0bwnA.jpg?auto=webp&s=d83c262ae1ac439e356ffaa93c947748ea10050f"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tp687u/5_best_movies_like_after_yang_about_artificial/",
          "author": null,
          "description": "submitted by    /u/NarutoNotBoruto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tp687u/5_best_movies_like_after_yang_about_artificial/",
          "publishedOn": "2022-03-26T22:31:31.000Z",
          "wordCount": 112,
          "title": "5 Best Movies Like 'After Yang' About Artificial Intelligence (A.I.)",
          "imageUrl": "https://external-preview.redd.it/M15bgA-BBXFIBSIMKFe7nFMY9lLGrAXq0Xdhv--rhus.jpg?auto=webp&s=2fbfccb9c28867c85f249d2f22ce61cbe437de5a"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tozvwt/ai_for_enamels_and_paints/",
          "author": null,
          "description": "Love how my keyboard konked out. \n So I recently read about megasyn the AI being used to create 40k new weapons in 6 hours. \n This got me wondering. Can AI be made to create different enamels and paints for things like pottery glazes, cloisonne enamels and paints for art work? \n If so how would one go about doing this knowing literally nothing?\n    submitted by    /u/Grendal87  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tozvwt/ai_for_enamels_and_paints/",
          "publishedOn": "2022-03-26T18:38:47.000Z",
          "wordCount": 150,
          "title": "ai for enamels and paints",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/toyu62/useful_tools_and_programs_list_for_aiml/",
          "author": null,
          "description": "Found a useful list of Tools and Programs for AI/ML. Looks like it covers Machine Learning, Deep Learning, Computer Vision(CV), and Natural Language Processing (NLP). I thought I'd share it for anyone that's interested. https://github.com/mikeroyal/Machine-Learning-Guide\n    submitted by    /u/Khaotic_Kernel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/toyu62/useful_tools_and_programs_list_for_aiml/",
          "publishedOn": "2022-03-26T17:47:30.000Z",
          "wordCount": 132,
          "title": "Useful Tools and Programs list for AI/ML",
          "imageUrl": "https://external-preview.redd.it/i9BG3RO4f3gR2wvyQLPmg5D4UABwOQQODQTwztrwNHU.jpg?auto=webp&s=4d516d9a279d2aff190b64f9eb4dc764c11157b3"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/toxy88/gpt3s_knowledge_was_limited_to_the_world_until/",
          "author": null,
          "description": "submitted by    /u/BeginningInfluence55  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/toxy88/gpt3s_knowledge_was_limited_to_the_world_until/",
          "publishedOn": "2022-03-26T17:04:12.000Z",
          "wordCount": 145,
          "title": "GPT-3's knowledge was limited to the world until 2019. InstructGPT is apparently up-to-date.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/towlb9/crystal_forest_ai_art/",
          "author": null,
          "description": "submitted by    /u/Recent_Coffee_2551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/towlb9/crystal_forest_ai_art/",
          "publishedOn": "2022-03-26T16:28:50.000Z",
          "wordCount": 96,
          "title": "Crystal Forest AI Art",
          "imageUrl": "https://external-preview.redd.it/B-jpYEQ1YIU-HcpUaODZlGWXVT1rkf3bRmy8P-0eQzI.jpg?auto=webp&s=db9e8c885dcaa9180970e4c87d771d93e0984e62"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tou59y/deep_convolutional_generative_network_tutorial_in/",
          "author": null,
          "description": "I thought it will be quite interesting to see Deep Convolutional GAN’s capability in generating wildlife, so I wrote a tutorial on how to build a model based on the DCGAN architecture through PyTorch:\n https://taying-cheng.medium.com/create-new-animals-using-dcgan-with-pytorch-2ce47810ebd4\n    submitted by    /u/Ok-Peanut-2681  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tou59y/deep_convolutional_generative_network_tutorial_in/",
          "publishedOn": "2022-03-26T15:54:15.000Z",
          "wordCount": 131,
          "title": "Deep Convolutional Generative Network Tutorial in PyTorch",
          "imageUrl": "https://external-preview.redd.it/utVQq87F1wrWhb-gBacSryHzZr55E-ULyT_m6x-lmOQ.jpg?auto=webp&s=2d71b4889755a102de4d31584802e15b2095d710"
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/tosno9/ai_news_animal_language_translator_ai_heart/",
          "author": null,
          "description": "submitted by    /u/getrich_or_diemining  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/tosno9/ai_news_animal_language_translator_ai_heart/",
          "publishedOn": "2022-03-26T15:18:16.000Z",
          "wordCount": 139,
          "title": "AI News | Animal Language Translator AI | Heart Attack Prediction Algo | Nvidia H100 GPU & AI Supercomputer",
          "imageUrl": "https://external-preview.redd.it/sKV1Sn8z3Ts84j-wd2EuDtNWoqESJUQdjULDAbSSTMs.jpg?auto=webp&s=9c9a5709d0dcd76f3e00e1451b4f5a5ad53d8fc2"
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/uaw3xl/nota_ai_introduces_new_machine_learning_tools/",
          "author": null,
          "description": "In the last decade, AI research has brought astonishing results in many fields, and, undoubtedly, AI is nowadays a central technology in many aspects of our life. As new ideas are proposed every day, this continuous research usually comes with infinite applications: from the algorithms assisting surgeons in complex operations to the one which allows unlocking our phone using just our face. In this evolution from the idea to the actual implementation, it is often ignored how hard the passage between theoretical research and working application is.\n We can refer to this process as AI Development Cycle for Edge AI and can be divided into three phases related to 1) data, 2) model, and 3) evaluation.\n Many aspects must be considered: first, each different AI application requires a specific dataset. For this reason, in this step, the aim is to prepare the data, which, as is well known, is one of the crucial topics of AI: a good algorithm always relies on a good dataset. This phase can be divided into data collection, curation, labeling, and preparation. \n Continue reading\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/uaw3xl/nota_ai_introduces_new_machine_learning_tools/",
          "publishedOn": "2022-04-24T14:36:50.000Z",
          "wordCount": 335,
          "title": "Nota AI Introduces New Machine Learning Tools Under Its NetsPresso Platform For Automatically Searching Optimized Models And Making Compression Process Easy And Fast",
          "imageUrl": "https://external-preview.redd.it/Gxl1BzzbMn-8pBr9ef83GCerUASCrtl82642cRDUDVU.jpg?auto=webp&s=d0d08c2c329dbc12f2cb217ba824f8cd0c26fb63"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ua88n1/google_researchers_create_animated_avatars_from_a/",
          "author": null,
          "description": "submitted by    /u/SpatialComputing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ua88n1/google_researchers_create_animated_avatars_from_a/",
          "publishedOn": "2022-04-23T15:45:46.000Z",
          "wordCount": 339,
          "title": "GOOGLE researchers create animated avatars from a single photo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/ua5rzp/i_dont_understand_why_i_am_getting_nan_loss/",
          "author": null,
          "description": "submitted by    /u/brike3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/ua5rzp/i_dont_understand_why_i_am_getting_nan_loss/",
          "publishedOn": "2022-04-23T13:45:27.000Z",
          "wordCount": 392,
          "title": "I don't understand why I am getting NaN loss scores. Can anyone explain what I am doing wrong ?",
          "imageUrl": "https://preview.redd.it/zdpc73yq8av81.png?auto=webp&s=dead4e0b186b35069c7b1dfc7546d4becfd0e3f9"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u9yfvb/are_there_applications_of_neural_networks_other/",
          "author": null,
          "description": "I see lots of hardware oriented toward AI/ML stuff these days, including chips with hardware acceleration for neural networks. \n I'm thinking about how GPUs were initially designed for graphics calculations, but then things like CUDA and OpenCL were developed to make that hardware usable for broader applications of parallel processing.\n Are there any other things that you can do with a neural network besides backpropagation, that wouldn't be easier to do in other ways?\n    submitted by    /u/Bananawamajama  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u9yfvb/are_there_applications_of_neural_networks_other/",
          "publishedOn": "2022-04-23T05:42:17.000Z",
          "wordCount": 191,
          "title": "Are there applications of neural networks other than machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u9qavf/i_have_a_time_series_of_time_temp_humidity/",
          "author": null,
          "description": "I want to create a NN that takes these readings and makes predictions about \"what will the readings be in 5 minutes if I turn the AC on?\".\n I'm thinking of training it with \"the angle of the sun at that time\", \"temp\", \"humidity\", and \"ac/heater/fan state\"(3) and then extracting data pairs spaced by 5 minutes where the system was in that state for the entire interval. Then I'm thinking I should use the 5-minute-later apparent temp as the training output.\n So the NN ultimately answers the question \"what would be the apparent temperature if the system were to be in the given state for the next 5 minutes?\"\n Am I on the right track here?\n    submitted by    /u/HasFiveVowels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u9qavf/i_have_a_time_series_of_time_temp_humidity/",
          "publishedOn": "2022-04-22T22:17:28.000Z",
          "wordCount": 345,
          "title": "I have a time series of time, temp, humidity, apparent temp, and ac/heater/fan state",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u8nv3j/building_dense_passage_retrievers/",
          "author": null,
          "description": "Hi, I made a video explaining the ideas behind building a Dense Passage Retriever(DPR). Whenever we talk about retrievers, we mostly refer to the DPR formulation which appeared in this paper. A lot of publicly available implementations also use this formulation. \n In a previous video, we discussed how to use the DPR End-to-End QA system which uses DPR with a QA model. In this video, we solely focus on retrievers and the ideas behind building them. The implementation is quite similar to retrievers pre-trained with Inverse Close Task.\n This video is part 8 of 9 video series on Open-domain question answering using Dense retrievers. Thanks for the support and I will appreciate any feedback.\n https://www.youtube.com/watch?v=w61p0HLo7gc\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u8nv3j/building_dense_passage_retrievers/",
          "publishedOn": "2022-04-21T13:37:47.000Z",
          "wordCount": 213,
          "title": "Building Dense Passage Retrievers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u8gqfy/nn_from_scratch_4_backward_propagation_kolbenkraft/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u8gqfy/nn_from_scratch_4_backward_propagation_kolbenkraft/",
          "publishedOn": "2022-04-21T06:03:08.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #4 Backward Propagation | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u8dpr7/searching_for_volunteers_for_mlbased_ukrainian/",
          "author": null,
          "description": "We are searching for trustworthy volunteers with some free time who would like to contribute to a digital Ukrainian volunteer project. Our system heavily relies on an image recognition system with a number of specialized filters involvg facial recognition, object recognition, logo detection, photoshop detection etc. People with professional experience with any of these things is preferred, but novice ML people are welcome to join us in a different capacity. DM to learn more about the project, glad to discuss the details with you.\n    submitted by    /u/eelgirl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u8dpr7/searching_for_volunteers_for_mlbased_ukrainian/",
          "publishedOn": "2022-04-21T03:03:05.000Z",
          "wordCount": 194,
          "title": "Searching for volunteers for ML-based Ukrainian volunteer project.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7wwrm/neural_network_gets_too_large_and_dies/",
          "author": null,
          "description": "Hi, I've been working on a project for my computer science class and everything has been working up until the training. I'm following a guide online that has worked fairly well. Whenever I try to train, however, I run into an overflow error and the entire network dies. I'm not sure where to go from here as I've tried a few steps to fix the issue, if anyone could offer up some advice to fixing my problem that would be amazing.\n    submitted by    /u/djm710  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7wwrm/neural_network_gets_too_large_and_dies/",
          "publishedOn": "2022-04-20T13:46:57.000Z",
          "wordCount": 583,
          "title": "Neural Network gets too large and dies",
          "imageUrl": "https://external-preview.redd.it/ZiAEpY_hvprgfEEpJOvIl6QIO7P1iFdUa5H0BGEeLQo.jpg?auto=webp&s=ab73127f439f3ef3e87d99be76ff2255d0e45755"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7u33n/7_best_books_to_learn_neural_networks_in_2022_for/",
          "author": null,
          "description": "submitted by    /u/maneesh123456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7u33n/7_best_books_to_learn_neural_networks_in_2022_for/",
          "publishedOn": "2022-04-20T11:14:32.000Z",
          "wordCount": 134,
          "title": "7+ Best Books to Learn Neural Networks in 2022 for Beginners (Updated) -",
          "imageUrl": "https://external-preview.redd.it/6o1SHWA4Ukh7Pe8AxhxW7UxZ5d2Hr-6oB0LpJysDHEQ.jpg?auto=webp&s=2db8922d7b93dfa6ad200385940f3ecefef840c8"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7rs0v/question_about_sigmoid_and_heaviside/",
          "author": null,
          "description": "I read a paper and was a little bit confused:\n In the paper it said: \"Imagine you have a two dimensional (binary input) classification (0 or 1) problem and you use Sigmoid as an acitivation function. Since the Sigmoid gives you a real number between 0 and 1, it's not really classification anymore. \n Therefore you take the input of Sigmoid (y_Sigmoid) and put this into a modified heaviside function H(y-0.5) (so for y_Sigmoid bigger than 0.5, it gives you yHeavi = 1)\n The decision boundary is given by a straight line w1a1+w2a2+w0=0 and this whole process, it only works with the Sigmoid function as first activation function.\"\n The last paragraph confused me. Why can I assume that the decision boundary is exactly that (It's just the \"normal decision boundary\" for a SLP, why does it work here a also) \n and why does it work with only Sigmoid Function as first activation function\n    submitted by    /u/LawlHeyman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7rs0v/question_about_sigmoid_and_heaviside/",
          "publishedOn": "2022-04-20T08:31:45.000Z",
          "wordCount": 251,
          "title": "Question about Sigmoid and Heaviside",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7kwa1/starting_a_neural_network/",
          "author": null,
          "description": "I want to create a program that can take music i feed it and over time create its own music based on the inputs. I know i have to use a neural network and deep learning algorithms but how do i get started. Thanks.\n    submitted by    /u/Saxy-Snark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7kwa1/starting_a_neural_network/",
          "publishedOn": "2022-04-20T01:26:59.000Z",
          "wordCount": 659,
          "title": "Starting a neural network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u7c95h/overview_of_relational_graph_convolutional/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u7c95h/overview_of_relational_graph_convolutional/",
          "publishedOn": "2022-04-19T18:41:24.000Z",
          "wordCount": 111,
          "title": "Overview of Relational Graph Convolutional Networks (RGCN)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u71vwo/this_is_a_long_shot_but_does_anyone_remember/",
          "author": null,
          "description": "Hi, this is a very long shot. I have been trying to remember the name of a science TV show which aired in the UK back in the 90's. It focussed on Neural Networks and gave some brilliant examples of environmental sensing. There was also a section showing a simple voice synthesiser which \"babbled\" like a child.\n I thought it may have been an \"Horizon\" show, however, I have been through the list of shows from that time and none appear to be right. If anyone has a memory of this show please let me know.\n One of the visuals I remember was a plastic skull with an LED matrix inside showing patterns. Obviously this was just some smoke and mirrors, however, it may trigger a memory. I'm trying to recall something from best part of 30 years ago..\n    submitted by    /u/_m0xya_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u71vwo/this_is_a_long_shot_but_does_anyone_remember/",
          "publishedOn": "2022-04-19T10:25:04.000Z",
          "wordCount": 264,
          "title": "This is a long shot, but does anyone remember...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u6icjn/does_anyone_have_a_guess_as_to_why_my_network/",
          "author": null,
          "description": "submitted by    /u/-i-hate-this-place-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u6icjn/does_anyone_have_a_guess_as_to_why_my_network/",
          "publishedOn": "2022-04-18T17:19:39.000Z",
          "wordCount": 373,
          "title": "Does anyone have a guess as to why my network isn’t working? (more info in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u5s0fq/lstm_for_time_series_prediction/",
          "author": null,
          "description": "Hi\n I am doing a project where I have to predict sales for a company and I am having some trouble with my LSTM model in python. All research I have done tells me that LSTM is as good, if not better, than a ARIMA model for forecasting on time series data, but my LSTM is significantly worse than my ARIMA model. Would it be possible for any one to help me to see if I have implemented it right? I have used both Tensorflow and Pytorch and both are way worse than the ARIMA model.\n    submitted by    /u/magnussendjoko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u5s0fq/lstm_for_time_series_prediction/",
          "publishedOn": "2022-04-17T17:37:59.000Z",
          "wordCount": 489,
          "title": "LSTM for time series prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u4ce1w/dalle_zeroshot_texttoimage_generation_part12/",
          "author": null,
          "description": "OpenAI released DALL E2 in the last week, this system is basically have a capability of generating an image from a text description. Some of the results were truly amazing. In this blog, I tried to discuss the ideas around DALL-E (version 1) .\n DALL-E consist of two main components d-VAE(discrete-Variational Auto Encoder) and Auto-regressive transformer. In Part-1 I focused on d-VAE part where I tried to talk about basic VAE and it's ELBO formulation, VQ-VAE eventually that leads to d-VAE. It's reconstruction loss is formulated from Logit Laplcae (bounded) unlike typical L1 or L2. Overall this part explains about how a discrete vector(token) can be generated for an input image.\n    submitted by    /u/rakshith291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u4ce1w/dalle_zeroshot_texttoimage_generation_part12/",
          "publishedOn": "2022-04-15T16:53:05.000Z",
          "wordCount": 214,
          "title": "DALL-E (Zero-Shot Text-to-Image Generation) -PART(1/2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u45wln/the_best_explanation_of_what_is_machine_learning/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u45wln/the_best_explanation_of_what_is_machine_learning/",
          "publishedOn": "2022-04-15T11:26:22.000Z",
          "wordCount": 156,
          "title": "The best explanation of What is Machine Learning and How it works? MUST WATCH",
          "imageUrl": "https://external-preview.redd.it/cfWvorMNvuv8TX-JC5njDZlljI54paH5_Kr3qudtGW4.jpg?auto=webp&s=52d3e521696a0323a62d01756a9d0b243f532831"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3zgab/how_do_i_fix_this_im_trying_to_predict_sine_the/",
          "author": null,
          "description": "submitted by    /u/-i-hate-this-place-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3zgab/how_do_i_fix_this_im_trying_to_predict_sine_the/",
          "publishedOn": "2022-04-15T04:01:25.000Z",
          "wordCount": 461,
          "title": "how do I fix this (I'm trying to predict sine (the blue dots are it's guesses and the white line is the \"correct\" answer)",
          "imageUrl": "https://preview.redd.it/s02c8v0f9mt81.png?auto=webp&s=f7bff8a41b59cd5214f49c0439e530c5a76d436f"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3w81q/neuroevolution_of_augmenting_topologies_course/",
          "author": null,
          "description": "Hey all,\n There's a new course on the Neuroevolution of Augmenting Topologies (NEAT) algorithm. It's a niche algorithm, but uses some very interesting mechanisms to train/evolve simple irregular neural networks.\n Thought some of you may be interested.\n    submitted by    /u/Cogitarius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3w81q/neuroevolution_of_augmenting_topologies_course/",
          "publishedOn": "2022-04-15T01:04:32.000Z",
          "wordCount": 141,
          "title": "Neuroevolution of Augmenting Topologies Course",
          "imageUrl": "https://external-preview.redd.it/byYYhDKkBlVHjFF7JNhoiH-G-Kl2IXs44qnOEM43DWU.jpg?auto=webp&s=be313645b0144368a6774ad5ad3e9fc5087d8926"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3n5pe/latest_research_from_stanford_introduces_domino_a/",
          "author": null,
          "description": "Machine learning and Artificial Intelligence models have gained promising results in recent years. The major factor behind their success is the availability and development of vast datasets. However, regardless of how many terabytes of data you have or how skilled you are at data science, machine learning models will be useless and even dangerous if you can’t make sense of data records.\n A slice is a collection of data samples with a common feature. For example, in a picture dataset, photographs of antique vehicles make up a slice. When a model’s performance on the data samples in a slice is significantly lower than its overall performance, the slice is considered underperforming.\n Deploying models underperforming on crucial data slices could seriously harm safety and fairness. For instance, models trained to detect collapsed lungs in chest X-rays generally make predictions based on the presence of chest drains, a common therapeutic device. As a result, computer models typically fail to detect collapsed lungs in images without chest drains, a critical data slice in which inaccurate negative predictions could be catastrophic.\n Not many studies have considered underperforming slices during model evaluation. Researchers believe that knowing which slices their models underperform would help practitioners not just make better decisions regarding model deployment but also improve model robustness by upgrading the training dataset or utilizing robust optimization strategies.\n Detecting slices is challenging because the “hidden” data slices are linked by a notion that isn’t easily derived from unstructured inputs or labeled in metadata (e.g., images, video, time-series data).\n Continue reading the summary\n Paper: https://arxiv.org/pdf/2203.14960.pdf\n Article: http://ai.stanford.edu/blog/domino/\n Github: https://github.com/HazyResearch/domino\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3n5pe/latest_research_from_stanford_introduces_domino_a/",
          "publishedOn": "2022-04-14T17:49:06.000Z",
          "wordCount": 400,
          "title": "Latest Research From Stanford Introduces ‘Domino’: A Python Tool for Identifying and Describing Underperforming Slices in Machine Learning Models",
          "imageUrl": "https://external-preview.redd.it/SM3UD6S7rMbt_yORFmcYGaUql9R-TRPWYNM6VslJwUs.jpg?auto=webp&s=6fc83634e740e16715fba2418b84e42757837fdf"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u3blzp/nn_from_scratch_3_forward_propagation_kolbenkraft/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u3blzp/nn_from_scratch_3_forward_propagation_kolbenkraft/",
          "publishedOn": "2022-04-14T07:21:13.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #3 Forward propagation | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2rrwh/is_the_number_of_dimensions_in_the_latent_space/",
          "author": null,
          "description": "​\n https://preview.redd.it/qtgp7dzx2bt81.png?width=850&format=png&auto=webp&s=ccf391e8a1613d5405c137296bdf853010fc3f19\n Not speaking specifically about autoencoders here, but about general neural networks. As I understand correctly, \"latent space\" refers to one of the fully connected layers of the network and the dimensionality of the space is equal to the number of the neurons in this layer. This would mean, that each of the layers has a different \"latent space\" representation of the learned data distribution. Do I understand it correctly? \n I got really confused because people seem to sometimes refer to latent space as to all of the possible activations of all of the neurons in the network (each neuron of the network is one dimension of a latent space) OR EVEN to all of the PARAMETERS of the network (each parameter is one dimension of the latent space (??)). Do we have a separate name for these? How do we call the parameter space of a neural network? Is my original intuition even correct?\n    submitted by    /u/bzqp2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2rrwh/is_the_number_of_dimensions_in_the_latent_space/",
          "publishedOn": "2022-04-13T14:37:16.000Z",
          "wordCount": 329,
          "title": "Is the number of dimensions in the latent space equal to the number of the neurons of the layer? Or perhaps number of neurons in the whole neural network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2j6cv/researchers_propose_a_novel_framework_lilnetx_for/",
          "author": null,
          "description": "In this research, the researchers from the paper ‘ LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification’ talk about the importance of larger parameter-heavy and computationally costly architectures in deep neural networks (DNNs) and how it improves the computer vision tasks. They also mentioned in the paper that it is not as simple as it seems since, as the DNNs become more common in the business, they are frequently required to be trained multiple times, communicated across the network to various devices, and executed under hardware limits with minimum loss of accuracy, all while maintaining accuracy. Then the question arises of how to reduce the models’ size on the devices while still enhancing their run-time. Explorations in this field have tended to take one of two paths: lowering model size via compression approaches or reducing computing demands through model pruning.\n The main achievement of this research from the University of Maryland and Google Research is the introduction of ‘LilNetX’, an end-to-end trainable neural network technique that allows learning models with specified accuracy-rate-computation trade-offs. Prior work has taken a piecemeal approach to these difficulties, which necessitates post-processing or multistage training, which is not efficient and does not scale well for big datasets or architectures. To encourage modest model size, the strategy is to create a joint training goal that penalizes the self-information of network parameters in a reparameterized latent space while simultaneously incorporating priors to increase structured sparsity in the parameter space to decrease computation.\n Continue Reading\n Paper: https://arxiv.org/pdf/2204.02965.pdf\n Github: https://github.com/Sharath-girish/LilNetX\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2j6cv/researchers_propose_a_novel_framework_lilnetx_for/",
          "publishedOn": "2022-04-13T05:36:06.000Z",
          "wordCount": 395,
          "title": "Researchers Propose a Novel Framework ‘LilNetX’ For Training Deep Neural Network With Extreme Model Compression, and Structured Sparsification",
          "imageUrl": "https://external-preview.redd.it/ZjFWy0CxrbbFZuET26RZYgZsZypBEX6RQKxpni79cvk.jpg?auto=webp&s=a7b9b3b3adaef5ad200e589a9cc9d612814c1ab4"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2ivzv/what_would_happen_if_you_connect_inputs_and/",
          "author": null,
          "description": "submitted by    /u/The_impact_theory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2ivzv/what_would_happen_if_you_connect_inputs_and/",
          "publishedOn": "2022-04-13T05:17:26.000Z",
          "wordCount": 653,
          "title": "What would happen if you connect inputs and outputs randomly to a large hebbian Spiking NN and let it learn shape itself in an environment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2ifr5/noob_here_who_doesnt_really_understand_calculus/",
          "author": null,
          "description": "If i want to take the partial derivative of the error with respect to a certain weight, it would be similar to taking the derivative of say y = value * weight + bias\n but if i hold the value and bias still, the derivative just becomes the value of the weight, like how the derivative of y = 3x is just 3… so what do I do? it doesn’t make sense to multiply 3 by a learning variable and make that the new weight, so what am I missing?\n    submitted by    /u/-i-hate-this-place-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2ifr5/noob_here_who_doesnt_really_understand_calculus/",
          "publishedOn": "2022-04-13T04:49:51.000Z",
          "wordCount": 482,
          "title": "noob here who doesn’t really understand calculus",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u2a39q/how_to_win_a_kaggle_competition_with_bayesian/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u2a39q/how_to_win_a_kaggle_competition_with_bayesian/",
          "publishedOn": "2022-04-12T21:34:47.000Z",
          "wordCount": 117,
          "title": "How to Win a Kaggle Competition with Bayesian Optimization",
          "imageUrl": "https://external-preview.redd.it/i6niOaeH1H7kZRbr_ONzY7uYdsMOHUw526WwWQ8oFqg.jpg?auto=webp&s=eb576c954e2b80ed6623f8c373e80ee8a5126fe5"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u24agy/the_moment_a_neural_net_became_sentient_for_the/",
          "author": null,
          "description": "submitted by    /u/fooo-ooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u24agy/the_moment_a_neural_net_became_sentient_for_the/",
          "publishedOn": "2022-04-12T17:19:02.000Z",
          "wordCount": 146,
          "title": "The Moment A Neural Net Became Sentient For The First Time - AI Art Story [4K] #shorts",
          "imageUrl": "https://external-preview.redd.it/L5PMjku7przoE7PKOmaS3wYWPlQIIcNN0NIJBJEMP4o.jpg?auto=webp&s=10eae903d47f072ac58914925d857e50887ec441"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u1drul/how_to_train_the_nn_model_with_a_custom_dataset/",
          "author": null,
          "description": "Hi all.\n I have been trying to work on an object detection project. Basically trying to play around with the codes in the documentation for a custom dataset.\n I am using Yolov3 and I trained my model using darknet and seems like the model is learning it wrong because of which the weights are not correct either. I don't know how to check that but when doing forward propagation, the array seems to be ok, without nan values, but the confidence is mostly 0's and some 0.25's. Anyone who can guide me, on where I could have gone wrong?\n ​\n code: https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html [yolov3 secion]\n output: \n outputs = [[0.03846154 0.03846154 0.27884614 0.21634616 0.5 0.25 ] [0.03846154 0.03846154 0. 0.47596154 0. 0. ] [0.03846154 0.03846154 0.89663464 0.78365386 0.5 0.25 ] ... [0.99038464 0.99038464 0.02403846 0.03125 0.5 0.25 ] [0.99038464 0.99038464 0.03846154 0.07211538 0.5 0. ] [0.99038464 0.99038464 0.07932692 0.05528846 0.5 0. ]] \n confidence = 0.25 0.0 0.25 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.25 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.25 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 0.0 0.0 0.0 0.0 0.0 0.25 ...\n    submitted by    /u/ersa17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u1drul/how_to_train_the_nn_model_with_a_custom_dataset/",
          "publishedOn": "2022-04-11T18:02:25.000Z",
          "wordCount": 350,
          "title": "How to train the NN model with a custom dataset?",
          "imageUrl": "https://external-preview.redd.it/oQkgY14yFWzlXan1GqLP6t-FqWT5TGHOI7Vp6h7YEgU.jpg?auto=webp&s=af02a58cac40afc1beb8e57e0cd69d2ac5d53072"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u0h1y1/summer_school_in_between_neuroimaging_and_machine/",
          "author": null,
          "description": "submitted by    /u/pasticciociccio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u0h1y1/summer_school_in_between_neuroimaging_and_machine/",
          "publishedOn": "2022-04-10T12:57:37.000Z",
          "wordCount": 114,
          "title": "Summer school in between neuroimaging and machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u0h1cm/dalle_and_dalle2/",
          "author": null,
          "description": "I have been into the website of OpenAI, it is unclear what has been added to Dall-e2, why should we subscribe for a github which will be made public? And what is the color code at the bottom?\n    submitted by    /u/pasticciociccio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u0h1cm/dalle_and_dalle2/",
          "publishedOn": "2022-04-10T12:56:37.000Z",
          "wordCount": 155,
          "title": "Dall-e and Dall-e2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/u0a6yb/researchers_including_yann_lecun_propose_projunn/",
          "author": null,
          "description": "When deep networks or inputs involve extensive data sequences, learning in neural networks can be unstable. Recurrent states in vanilla recurrent neural networks (RNNs) are generated by repeatedly applying a linear transformation followed by a pointwise nonlinearity. This becomes unstable when the linear transformation’s eigenvalues are not of magnitude one. \n Unitary matrices have been utilized to solve the problem of disappearing and exploding gradients because they have eigenvalues of size one, naturally, and have been. Unitary convolutional layers have recently been developed in a similar way to aid in the development of more stable deep networks with norm-preserving transformations.\n The loss function’s derivative with respect to the weights is called a gradient. During backpropagation in neural networks, it is utilized to update the weights to minimize the loss function. When traveled backward with each layer, the derivative or slope continuously grows lower, resulting in a vanishing gradient. When the weight update is exponentially small, the training time is excessively long. In the worst-case scenario, the neural network training may be stopped entirely. Exploding gradients, on the other hand, occur when the slope increases with each successive layer during backpropagation. The gradient will never converge due to the high weights, causing it to oscillate around the minima without ever reaching a global minima point.\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.05483.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/u0a6yb/researchers_including_yann_lecun_propose_projunn/",
          "publishedOn": "2022-04-10T04:38:13.000Z",
          "wordCount": 356,
          "title": "Researchers, Including Yann Lecun, Propose ‘projUNN’: An Efficient Method For Training Deep Neural Networks With Unitary Matrices",
          "imageUrl": "https://external-preview.redd.it/o0w2ACco6ahv9HPmDnR1JTzTJTnvsfgeKCHmFS_1ptY.jpg?auto=webp&s=78456ccf137182dae6e1b3a442bf1fd39de42e0b"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tz32az/dense_passage_retrieverdpr_openqa_system/",
          "author": null,
          "description": "Hi, I made a video explaining Dense Passage Retriever(DPR) paper. We specifically explain the End to End QA system suggested in the latter part of the paper which discusses how to build an Open-QA system using dense retrievers.\n DPR was one of the first papers that discussed building dense retrievers using QA pairs only and didn't require a big pretraining computational setup like ORQA or REALM. It is currently used in a lot of places as a dense retriever. You can find Hugginface and Haystack implementations also.\n This video is part of a series on Open-QA using dense retrievers. We have made 2 videos on DPR. In the latter, we discuss how to build a dense retriever from scratch. Thanks for the support and it would be great if you could give any feedback.\n https://www.youtube.com/watch?v=rvcyyJNjPU0\n    submitted by    /u/infiniteakashe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tz32az/dense_passage_retrieverdpr_openqa_system/",
          "publishedOn": "2022-04-08T13:02:42.000Z",
          "wordCount": 236,
          "title": "Dense Passage Retriever(DPR) Open-QA System",
          "imageUrl": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&s=720b78add0a3005c4f67eaed6897df409cc040c6"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tye21i/nn_from_scratch_2_initializing_parameters/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tye21i/nn_from_scratch_2_initializing_parameters/",
          "publishedOn": "2022-04-07T14:17:46.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #2 Initializing parameters | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txw0eh/quick_little_keras_question/",
          "author": null,
          "description": "I tried posting this on stackoverflow with no response.\n Im trying to use model.save() and keras.models.load_model()\n on this chunk of code. But, unlike some of the other keras examples I've played with, this one seems to crash.\n I'm super new to this, any Ideas why? I can post the error message if it helps.\n    submitted by    /u/HoneyBunchsOGoats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txw0eh/quick_little_keras_question/",
          "publishedOn": "2022-04-06T20:54:46.000Z",
          "wordCount": 152,
          "title": "Quick Little Keras Question",
          "imageUrl": "https://external-preview.redd.it/XBvxxIPAp_KPRj04dL0If6Riym8wXD-KWN3OYgNZjVw.jpg?auto=webp&s=0c3f0b8af92c3a962f569a389e9673597e12f8ec"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txj3ng/driving_a_robot_with_a_neural_network_use_case/",
          "author": null,
          "description": "submitted by    /u/KamilBugnoKrk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txj3ng/driving_a_robot_with_a_neural_network_use_case/",
          "publishedOn": "2022-04-06T10:32:23.000Z",
          "wordCount": 128,
          "title": "Driving a robot with a neural network - use case study",
          "imageUrl": "https://external-preview.redd.it/Fq_wbiH_-rAHehqwb2z9g9p99upgQ_6uTmjVCFPjpnY.jpg?auto=webp&s=8bbafc7b268f9f5020abd04de668308a7bef6957"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/txd4pu/heres_an_intuitive_explanation_to_singular_value/",
          "author": null,
          "description": "submitted by    /u/mr-minion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/txd4pu/heres_an_intuitive_explanation_to_singular_value/",
          "publishedOn": "2022-04-06T03:45:33.000Z",
          "wordCount": 157,
          "title": "Here's an intuitive explanation to Singular Value Decomposition. 👇",
          "imageUrl": "https://external-preview.redd.it/yEZqz6bdYi9OxMbxSAun-NOOyBiIEWi0hgButp5s0Bc.jpg?auto=webp&s=7501076a2d95650e0f1222b249a18b18ee508c2e"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tx4n1h/mit_has_trained_ai_to_generate_new_molecular/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tx4n1h/mit_has_trained_ai_to_generate_new_molecular/",
          "publishedOn": "2022-04-05T20:44:31.000Z",
          "wordCount": 123,
          "title": "MIT has trained AI to generate new molecular materials",
          "imageUrl": "https://external-preview.redd.it/VN_AAlU77_6qR-oL5nPN_QANJIRFwqPXPJNyV8WUPTs.jpg?auto=webp&s=e73ced42586cfe5bf9c952d5ab49691b83ef1b02"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tw3wz6/composing_music_with_neural_networks/",
          "author": null,
          "description": "Hey guys,\n ​\n I really love creating music algorithmically, which is why I have dedicated my master’s thesis to the generation of music patterns by the use of artificial intelligence.\n In the course of the past 12 months, I have programmed a deep recurrent neural network in Python, which I have trained on 200 self-made music patterns in order to generate somehow novel motifs.\n ​\n In order to evaluate my model, I have set up a short online listening experiment.\n I’m looking for test subjects right now, so if you are interested in participating, I would really appreciate it.\n The listening experiment will take you just about 5 to 8 minutes to complete and the only thing you need is a pair of headphones.\n You can partake on your computer as well as on your smartphone or tablet.\n ​\n Here is the link which gets you to the listening experiment:\n https://forms.gle/rx1FUQ7RgpjMu1xx9\n ​\n Thank you very much for taking the time to help me reach my goal.\n Really appreciate it.\n    submitted by    /u/JosephdeLaquinta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tw3wz6/composing_music_with_neural_networks/",
          "publishedOn": "2022-04-04T14:51:18.000Z",
          "wordCount": 259,
          "title": "Composing Music with Neural Networks",
          "imageUrl": "https://external-preview.redd.it/b4i5Ja2AxLdJ3zGYml1UCPr28W8teB8EpstN8GR5Z98.jpg?auto=webp&s=4b023a0fd429d0e0c148e9fbe2fb9fb9971c0693"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tvneyx/blog_lets_manually_approximate_a_simple_function/",
          "author": null,
          "description": "submitted by    /u/rhkibria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tvneyx/blog_lets_manually_approximate_a_simple_function/",
          "publishedOn": "2022-04-03T23:38:37.000Z",
          "wordCount": 126,
          "title": "Blog: Let’s manually approximate a simple function with a ReLU neural network",
          "imageUrl": "https://external-preview.redd.it/cFh6vbg55LHArRON3tZT-u8z_kSyTzhAnSPIpdI7W9o.jpg?auto=webp&s=3db3b3eeca270ba4a17260456a429f17a869f093"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tugj08/nn_from_scratch_1_data_preprocessing_kolbenkraft/",
          "author": null,
          "description": "submitted by    /u/cjmodi306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tugj08/nn_from_scratch_1_data_preprocessing_kolbenkraft/",
          "publishedOn": "2022-04-02T11:16:08.000Z",
          "wordCount": 119,
          "title": "NN from Scratch: #1 Data Preprocessing | Kolbenkraft",
          "imageUrl": "https://external-preview.redd.it/GDnb256QTkcz5l5-77Ys1KBOLyCpV-FhczyyfWFfFkc.jpg?auto=webp&s=6a5ee252a5d11d763b300637085189cc5d1e6e32"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tuecc2/c_machine_learning_book/",
          "author": null,
          "description": "Hey, guys. Just want to ask if anybody's interested with a C++ machine learning book, \"Hands-on Machine Learning with C++\" by Kirill Kolodiazhnyi. \n If you are, send me a DM.\n    submitted by    /u/edmondgrasa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tuecc2/c_machine_learning_book/",
          "publishedOn": "2022-04-02T08:48:09.000Z",
          "wordCount": 130,
          "title": "C++ Machine Learning Book",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tua0x3/efficient_net_vs_resnet/",
          "author": null,
          "description": "As the title says, I would like to know/get some direction to the question when in general does and effnet is preferred to a resnet? I understand that the paper compares performances and it shows a higher performance wrt every network. So my question would be is that always the case or is there a specific situation where it would be better?\n Sorry for the typos (on my mobile)\n    submitted by    /u/johnyj01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tua0x3/efficient_net_vs_resnet/",
          "publishedOn": "2022-04-02T04:05:56.000Z",
          "wordCount": 289,
          "title": "Efficient net vs resnet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tssfwb/i_only_know_one_output_of_a_neural_net_at_a_time/",
          "author": null,
          "description": "submitted by    /u/lullek4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tssfwb/i_only_know_one_output_of_a_neural_net_at_a_time/",
          "publishedOn": "2022-03-31T05:10:44.000Z",
          "wordCount": 464,
          "title": "I only know one output of a neural net at a time. How to train, if i have two outputs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tri77x/ai_podcast_from_neuroscience_to_deep_learning/",
          "author": null,
          "description": "submitted by    /u/aidev2040  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tri77x/ai_podcast_from_neuroscience_to_deep_learning/",
          "publishedOn": "2022-03-29T20:14:51.000Z",
          "wordCount": 116,
          "title": "AI podcast: from neuroscience to deep learning",
          "imageUrl": "https://external-preview.redd.it/nlIaWha3rBFT2XH4uw_KXW2brIs-u7NGnIIy3gAqwv0.jpg?auto=webp&s=5b8830a901aeb23c82eb1f89142db6e8cbe6e1cf"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tr566v/neural_networks_project/",
          "author": null,
          "description": "Hi, hope everyone is doing will\n ​\n ​\n i am an EE student, i am currently taking a class (my first) in machine learning, also i am enjoying it so much, now we have reached the point where we are studying neural networks.. back propgation, CNN, RNN, Autoencoders, Deep Learning etc..\n ​\n and my prof wants us to get working with some projects (using neural network)\n ​\n basically he wants us to get some already written code in Gethub (((written with Pytorch))) and understand it, understand the task, the motivation, the structure and the math, and modify it if needed, and implement it, and this will be the project, no one starts from scratch\n ​\n for example:\n image classification\n object detection\n ​\n also he said that the code that identify numbers is simple for a project, it will be an assignment.\n ​\n so any ideas?\n or links\n or any advice in general\n ​\n thanks guys and all the best\n    submitted by    /u/Torvaldz_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tr566v/neural_networks_project/",
          "publishedOn": "2022-03-29T15:54:02.000Z",
          "wordCount": 274,
          "title": "neural networks project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tq3dft/top_5_python_time_series_libraries/",
          "author": null,
          "description": "submitted by    /u/RubiksCodeNMZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tq3dft/top_5_python_time_series_libraries/",
          "publishedOn": "2022-03-28T06:54:07.000Z",
          "wordCount": 113,
          "title": "Top 5 Python Time Series Libraries",
          "imageUrl": "https://external-preview.redd.it/PSJx7xNt4F5lZFn1vZlAKimT6kKGCTVhpeIuJiCTBNk.jpg?auto=webp&s=5030d7619636a75972e5c0f6fd9b10278bf4b403"
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tptsj2/check_out_this_research_summary_article_based_on/",
          "author": null,
          "description": "Deep Neural Networks (DNNs) have excelled at solving complex real-world problems, however, training a good DNN has become more complex. It is challenging to ensure that the optimizers used will converge to reliable minima with acceptable model performance when only minimizing the conventional empirical loss.\n Tsinghua University’s research team proposes Stochastic Scheduled SAM (SS-SAM), a novel and effective DNN training strategy. In SS-SAM, the optimizer is set up by a predetermined scheduling function to run a random trial at each update step, which selects whether to perform the SGD or SAM optimization at random. The overall number of propagation pairs could be significantly decreased in this approach. The team’s approach provides equivalent or higher model training performance at a lower computational cost than baseline sharpness-aware minimization (SAM).\n Continue Reading\n Paper: https://arxiv.org/pdf/2203.09962.pdf\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tptsj2/check_out_this_research_summary_article_based_on/",
          "publishedOn": "2022-03-27T21:33:49.000Z",
          "wordCount": 325,
          "title": "Check out this research summary article based on the paper 'SS-SAM: Stochastic Scheduled Sharpness-Aware Minimization for Efficiently Training Deep Neural Networks' where Researchers From Tsinghua University Propose ‘Stochastic Scheduled SAM’ (SS-SAM) for reducing the computational overhead",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tpcila/why_is_the_variable_being_passed_for_iterations/",
          "author": null,
          "description": "As you can see in the figure, i'm passing the variable data_inputs to the feedforward_comp function over iterations. Up to epoch = 9, everything computes fine but after that, data_inputs suddently is being passed as empty?\n Can someone please tell me why this happens and how to fix it?\n https://preview.redd.it/2wds226ktup81.png?width=816&format=png&auto=webp&s=61c55db011708e2d2b373a0b4e4b02355ec50730\n    submitted by    /u/lwhisper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tpcila/why_is_the_variable_being_passed_for_iterations/",
          "publishedOn": "2022-03-27T04:32:49.000Z",
          "wordCount": 173,
          "title": "why is the variable being passed for iterations suddenly passing empty value?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/tpc3bk/which_laptop_should_i_buy/",
          "author": null,
          "description": "Hey guys, I really need your help on this one. I go to university next year and I will be studying computer engineering which means there will be a lot of coding going into it. Now I have 4 options for laptop\n First : INSPIRON 15.6\" INTEL CORE 17-1165G7 TOUCHSCREEN 2-IN-1 LAPTOP\n Second: GALAXY BOOK PRO 360 15\" 2-IN-1 INTEL 17 LAPTOP\n Third: HP 15.6\" Touchscreen 2-in-1 Laptop - Nightfall Black (AMD Ryzen 7 5700U/1TB SSD/16GB RAM/Windows 10)\n Fourth: HP Pavilion x360 15.6\" Touchscreen 2-in-1 Laptop - Silver (Intel Core i7-1165G7/1TB SSD/16GB RAM/Win 11)\n Please and thank you guys :)\n    submitted by    /u/Traditional-Cow47  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/tpc3bk/which_laptop_should_i_buy/",
          "publishedOn": "2022-03-27T04:04:53.000Z",
          "wordCount": 653,
          "title": "Which laptop should I buy?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": [
        {
          "id": "https://danieltakeshi.github.io/2022/04/23/paper-reviewing-load/",
          "author": null,
          "description": "In academia, for better or worse, we have what’s called a peer review system,\nwhere papers get accepted to journals, conferences, or other venues on the\nbasis of reviews from other researchers, who ideally are subject area experts\nand thus are qualified to evaluate the paper. The reviewers also cannot have a\nconflict of interest with the authors, and should not be overwhelmed with too\nmany papers to review. This is the ideal world, and is not always what happens\nin practice.\nFrom my experience in the robotics academic community (and this may apply to\nother disciplines), it generally seems like there is no standard definition of\nan “appropriate” or “maximum” reviewing load for a reviewer. This is difficult\nto define as different papers mandate different reviewing efforts; a massive\njournal …",
          "link": "https://danieltakeshi.github.io/2022/04/23/paper-reviewing-load/",
          "publishedOn": "2022-04-23T12:00:00.000Z",
          "wordCount": 1083,
          "title": "My Paper Reviewing Load",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/",
      "articles": [
        {
          "id": "6256f702f6721b003db4b685",
          "author": "Jacob Hilton",
          "description": "Goodhart’s law famously says: “When a measure becomes a target, it ceases to be a good measure.” Although originally from economics, it’s something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
          "link": "https://openai.com/blog/measuring-goodharts-law/",
          "publishedOn": "2022-04-13T18:00:00.000Z",
          "wordCount": 1270,
          "title": "Measuring Goodhart’s Law",
          "imageUrl": "https://openai.com/content/images/2021/08/openai-cover.png"
        },
        {
          "id": "624d5b837ce26d004d92d14d",
          "author": "OpenAI",
          "description": "DALL·E 2 is a new AI system that can create realistic images and art from a description in natural language.",
          "link": "https://openai.com/blog/dall-e-2/",
          "publishedOn": "2022-04-06T13:42:00.000Z",
          "wordCount": 722,
          "title": "DALL·E 2",
          "imageUrl": "https://openai.com/content/images/2022/04/dall-e-2-og.jpg"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=834184",
          "author": "Alyssa Hughes",
          "description": "Edge computing has come of age, with deployments enabling many applications that process data from IoT sensors and cameras. In 2017, we identified the symbiotic relationship between edge computing and video analytics in an article, noting that live video analytics is the “killer app” for edge computing. Edge devices come in various shapes and sizes […]\nThe post Don’t let data drift derail edge compute machine learning models appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/dont-let-data-drift-derail-edge-compute-machine-learning-models/",
          "publishedOn": "2022-04-19T16:00:00.000Z",
          "wordCount": 1415,
          "title": "Don’t let data drift derail edge compute machine learning models",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2022/04/1200x627_Live_analytics_still_with_logo_TW_FB.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=834241",
          "author": "Alyssa Hughes",
          "description": "Episode 135 | April 13, 2022 In “Just Tech: Centering Community-Driven Innovation at the Margins,” Senior Principal Researcher Mary L. Gray explores how technology and community intertwine and the role technology can play in supporting community-driven innovation and community-based organizations. Dr. Gray and her team are working to bring computer science, engineering, social science, and […]\nThe post Just Tech: Centering Community-Driven Innovation at the Margins Episode 3 with Dr. Sasha Costanza-Chock appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/just-tech-centering-community-driven-innovation-at-the-margins-episode-3-with-dr-sasha-costanza-chock/",
          "publishedOn": "2022-04-13T13:00:00.000Z",
          "wordCount": 9339,
          "title": "Just Tech: Centering Community-Driven Innovation at the Margins Episode 3 with Dr. Sasha Costanza-Chock",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2022/04/Mary_Sasha_1200x627_WithLogo.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=830284",
          "author": "Alyssa Hughes",
          "description": "Large pre-trained language models such as GPT-3, Codex, and others can be tuned to generate code from natural language specifications of programmer intent. Such automated models have the potential to improve productivity for every programmer in the world. But since the models can struggle to understand program semantics, the quality of the resulting code can’t […]\nThe post Jigsaw fixes bugs in machine-written software appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/jigsaw-fixes-bugs-in-machine-written-software/",
          "publishedOn": "2022-03-31T17:00:00.000Z",
          "wordCount": 2442,
          "title": "Jigsaw fixes bugs in machine-written software",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=829618",
          "author": "Alyssa Hughes",
          "description": "Episode 134 | March 31, 2022 In “Just Tech: Centering Community-Driven Innovation at the Margins,” Senior Principal Researcher Mary L. Gray explores how technology and community intertwine and the role technology can play in supporting community-driven innovation and community-based organizations. Dr. Gray and her team are working to bring computer science, engineering, social science, and […]\nThe post Just Tech: Centering Community-Driven Innovation at the Margins episode 2 with Dr. Tawanna Dillahunt, Zachary Rowe, and Joanna Velazquez appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/just-tech-centering-community-driven-innovation-at-the-margins-episode-2-with-dr-tawanna-dillahunt-zachary-rowe-and-joanna-velazquez/",
          "publishedOn": "2022-03-31T13:00:00.000Z",
          "wordCount": 9485,
          "title": "Just Tech: Centering Community-Driven Innovation at the Margins episode 2 with Dr. Tawanna Dillahunt, Zachary Rowe, and Joanna Velazquez",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://ai.googleblog.com/",
      "articles": [
        {
          "id": "http://ai.googleblog.com/2022/04/pix2seq-new-language-interface-for.html",
          "author": null,
          "description": "Posted by Ting Chen and David Fleet, Research Scientists, Google Research, Brain Team \nObject detection is a long-standing computer vision task that attempts to recognize and localize all objects of interest in an image. The complexity arises when trying to identify or localize all object instances while also avoiding duplication. Existing approaches, like Faster R-CNN and DETR, are carefully designed and highly customized in the choice of architecture and loss function. This specialization of existing systems has created two major barriers: (1) it adds complexity in tuning and training the different parts of the system (e.g., region proposal network, graph matching with GIOU loss, etc.), and (2), it can reduce the ability of a model to generalize, necessitating a redesign of the model for…",
          "link": "http://ai.googleblog.com/2022/04/pix2seq-new-language-interface-for.html",
          "publishedOn": "2022-04-22T20:17:00.000Z",
          "wordCount": 2099,
          "title": "Pix2Seq: A New Language Interface for Object Detection",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/hidden-interfaces-for-ambient-computing.html",
          "author": null,
          "description": "Posted by Alex Olwal, Research Scientist, Google Augmented Reality and Artem Dementyev, Hardware Engineer, Google Research \nAs consumer electronics and internet-connected appliances are becoming more common, homes are beginning to embrace various types of connected devices that offer functionality like music control, voice assistance, and home automation. A graceful integration of devices requires adaptation to existing aesthetics and user styles rather than simply adding screens, which can easily disrupt a visual space, especially when they become monolithic surfaces or black screens when powered down or not actively used. Thus there is an increasing desire to create connected ambient computing devices and appliances that can preserve the aesthetics of everyday materials, while providing …",
          "link": "http://ai.googleblog.com/2022/04/hidden-interfaces-for-ambient-computing.html",
          "publishedOn": "2022-04-21T19:59:00.001Z",
          "wordCount": 2057,
          "title": "Hidden Interfaces for Ambient Computing",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/formnet-beyond-sequential-modeling-for.html",
          "author": null,
          "description": "Posted by Chen-Yu Lee and Chun-Liang Li, Research Scientists, Google Research, Cloud AI Team \nForm-based document understanding is a growing research topic because of its practical potential for automatically converting unstructured text data into structured information to gain insight about a document’s contents. Recent sequence modeling, which is a self-attention mechanism that directly models relationships between all words in a selection of text, has demonstrated state-of-the-art performance on natural language tasks. A natural approach to handle form document understanding tasks is to first serialize the form documents (usually in a left-to-right, top-to-bottom fashion) and then apply state-of-the-art sequence models to them.  \n However, form documents often have more complex layouts …",
          "link": "http://ai.googleblog.com/2022/04/formnet-beyond-sequential-modeling-for.html",
          "publishedOn": "2022-04-20T20:36:00.000Z",
          "wordCount": 2463,
          "title": "FormNet: Beyond Sequential Modeling for Form-Based Document Understanding",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html",
          "author": null,
          "description": "Posted by Zifeng Wang, Student Researcher, and Zizhao Zhang, Software Engineer, Google Research\nSupervised learning is a common approach to machine learning (ML) in which the model is trained using data that is labeled appropriately for the task at hand. Ordinary supervised learning trains on independent and identically distributed (IID) data, where all training examples are sampled from a fixed set of classes, and the model has access to these examples throughout the entire training phase. In contrast, continual learning tackles the problem of training a single model on changing data distributions where different classification tasks are presented sequentially. This is particularly important, for example, to enable autonomous agents to process and interpret continuous streams of informati…",
          "link": "http://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html",
          "publishedOn": "2022-04-19T17:00:00.002Z",
          "wordCount": 2213,
          "title": "Learning to Prompt for Continual Learning",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/locked-image-tuning-adding-language.html",
          "author": null,
          "description": "Posted by Andreas Steiner and Basil Mustafa, Research Software Engineers at Google Research, Brain team \nThe ability to classify images into categories has been transformed by deep learning. It has also been significantly accelerated by transfer learning, whereby models are first pre-trained on large datasets, like ImageNet, to learn visual representations that are then transferred via fine-tuning to a new task with less data (e.g., classifying animals). Previous works such as BiT and ViT employed these methods to achieve state-of-the-art performance on a wide range of classification tasks, such as the VTAB benchmark. \nHowever, fine-tuning has some downsides: though pre-training is done only once, fine-tuning is necessary on every new dataset for which task-specific data is needed. Multimo…",
          "link": "http://ai.googleblog.com/2022/04/locked-image-tuning-adding-language.html",
          "publishedOn": "2022-04-14T21:41:00.000Z",
          "wordCount": 2116,
          "title": "Locked-image Tuning: Adding Language Understanding to Image Models",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/simple-and-effective-zero-shot-task.html",
          "author": null,
          "description": "Posted by Jeffrey Zhao and Raghav Gupta, Software Engineers, Google Research \nModern conversational agents need to integrate with an ever-increasing number of services to perform a wide variety of tasks, from booking flights and finding restaurants, to playing music and telling jokes. Adding this functionality can be difficult — for each new task, one needs to collect new data and retrain the models that power the conversational agent. This is because most task-oriented dialogue (TOD) models are trained on a single task-specific ontology. An ontology is generally represented as a list of possible user intents (e.g., if the user wants to book a flight, if the user wants to play some music, etc.) and possible parameter slots to extract from the conversation (e.g., the date of the flight, the…",
          "link": "http://ai.googleblog.com/2022/04/simple-and-effective-zero-shot-task.html",
          "publishedOn": "2022-04-13T17:06:00.001Z",
          "wordCount": 2336,
          "title": "Simple and Effective Zero-Shot Task-Oriented Dialogue",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/lidar-camera-deep-fusion-for-multi.html",
          "author": null,
          "description": "Posted by Yingwei Li, Student Researcher, Google Cloud and Adams Wei Yu, Research Scientist, Google Research, Brain Team  \nLiDAR and visual cameras are two types of complementary sensors used for 3D object detection in autonomous vehicles and robots. LiDAR, which is a remote sensing technique that uses light in the form of a pulsed laser to measure ranges, provides low-resolution shape and depth information, while cameras provide high-resolution shape and texture information. While the features captured by LiDAR and cameras should be merged together to provide optimal 3D object detection, it turns out that most state-of-the-art 3D object detectors use LiDAR as the only input. The main reason is that to develop robust 3D object detection models, most methods need to augment and transform th…",
          "link": "http://ai.googleblog.com/2022/04/lidar-camera-deep-fusion-for-multi.html",
          "publishedOn": "2022-04-12T19:58:00.000Z",
          "wordCount": 2297,
          "title": "Lidar-Camera Deep Fusion for Multi-Modal 3D Detection",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/large-scale-matrix-factorization-on-tpus.html",
          "author": null,
          "description": "Posted by Harsh Mehta, Software Engineer, Google Research \nMatrix factorization is one of the oldest, yet still widely used, techniques for learning how to recommend items such as songs or movies from user ratings. In its basic form, it approximates a large, sparse (i.e., mostly empty) matrix of user-item interactions with a product of two smaller, denser matrices representing learned item and user features. These dense matrices, in turn, can be used to recommend items to a user with which they haven't interacted before. \nDespite its algorithmic simplicity, matrix factorization can still achieve competitive performance in recommender benchmarks. Alternating least squares (ALS), and especially its implicit variation, is a fundamental algorithm to learn the parameters of matrix factorization…",
          "link": "http://ai.googleblog.com/2022/04/large-scale-matrix-factorization-on-tpus.html",
          "publishedOn": "2022-04-08T17:52:00.006Z",
          "wordCount": 2555,
          "title": "Large-Scale Matrix Factorization on TPUs",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/vdtts-visually-driven-text-to-speech.html",
          "author": null,
          "description": "Posted by Tal Remez, Software Engineer, Google Research and Micheal Hassid, Software Engineer Intern, Google Research   \nRecent years have seen a tremendous increase in the creation and serving of video content to users across the world in a variety of languages and over numerous platforms. The process of creating high quality content can include several stages from video capturing and captioning to  video and audio editing. In some cases dialogue is re-recorded (referred to as dialog replacement, post-sync or dubbing) in a studio in order to achieve high quality and replace original audio that might have been recorded in noisy conditions. However, the dialog replacement process can be difficult and tedious because the newly recorded audio needs to be well synced with the video, requiring …",
          "link": "http://ai.googleblog.com/2022/04/vdtts-visually-driven-text-to-speech.html",
          "publishedOn": "2022-04-07T20:45:00.000Z",
          "wordCount": 2033,
          "title": "VDTTS: Visually-Driven Text-To-Speech",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html",
          "author": null,
          "description": "Posted by Ikechukwu Uchendu, AI Resident and Ted Xiao, Software Engineer, Robotics at Google \nReinforcement learning (RL) can be used to train a policy to perform a task via trial and error, but a major challenge in RL is learning policies from scratch in environments with hard exploration challenges. For example, consider the setting depicted in the door-binary-v0 environment from the adroit manipulation suite, where an RL agent must control a hand in 3D space to open a door placed in front of it. \n   \n\n\nAn RL agent must control a hand in 3D space to open a door placed in front of it. The agent receives a reward signal only when the door is completely open.\n\n   \nSince the agent receives no intermediary rewards, it cannot measure how close it is to completing the task, and so must explore …",
          "link": "http://ai.googleblog.com/2022/04/efficiently-initializing-reinforcement.html",
          "publishedOn": "2022-04-06T14:38:00.001Z",
          "wordCount": 2291,
          "title": "Efficiently Initializing Reinforcement Learning With Prior Policies",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/reproducibility-in-deep-learning-and.html",
          "author": null,
          "description": "Posted by Gil Shamir and Dong Lin, Research Software Engineers, Google Research \nEver queried a recommender system and found that the same search only a few moments later or on a different device yields very different results? This is not uncommon and can be frustrating if a person is looking for something specific. As a designer of such a system, it is also not uncommon for the metrics measured to change from design and testing to deployment, bringing into question the utility of the experimental testing phase. Some level of such irreproducibility can be expected as the world changes and new models are deployed. However, this also happens regularly as requests hit duplicates of the same model or models are being refreshed.  \nLack of replicability, where researchers are unable to reproduce…",
          "link": "http://ai.googleblog.com/2022/04/reproducibility-in-deep-learning-and.html",
          "publishedOn": "2022-04-05T17:41:00.000Z",
          "wordCount": 2730,
          "title": "Reproducibility in Deep Learning and Smooth Activations",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html",
          "author": null,
          "description": "Posted by Sharan Narang and Aakanksha Chowdhery, Software Engineers, Google Research \nIn recent years, large neural networks trained for language understanding and generation have achieved impressive results across a wide range of tasks. GPT-3 first showed that large language models (LLMs) can be used for few-shot learning and can achieve impressive results without large-scale task-specific data collection or model parameter updating. More recent LLMs, such as GLaM, LaMDA, Gopher, and Megatron-Turing NLG, achieved state-of-the-art few-shot results on many tasks by scaling model size, using sparsely activated modules, and training on larger datasets from more diverse sources. Yet much work remains in understanding the capabilities that emerge with few-shot learning as we push the limits of …",
          "link": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html",
          "publishedOn": "2022-04-04T16:01:00.007Z",
          "wordCount": 2737,
          "title": "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        },
        {
          "id": "http://ai.googleblog.com/2022/04/introducing-cvss-massively-multilingual.html",
          "author": null,
          "description": "Posted by Ye Jia and Michelle Tadmor Ramanovich, Software Engineers, Google Research \nAutomatic translation of speech from one language to speech in another language, called speech-to-speech translation (S2ST), is important for breaking down the communication barriers between people speaking different languages. Conventionally, automatic S2ST systems are built with a cascade of automatic speech recognition (ASR), text-to-text machine translation (MT), and text-to-speech (TTS) synthesis sub-systems, so that the system overall is text-centric. Recently, work on S2ST that doesn’t rely on intermediate text representation is emerging, such as end-to-end direct S2ST (e.g., Translatotron) and cascade S2ST based on learned discrete representations of speech (e.g., Tjandra et al.). While early vers…",
          "link": "http://ai.googleblog.com/2022/04/introducing-cvss-massively-multilingual.html",
          "publishedOn": "2022-04-01T16:06:00.007Z",
          "wordCount": 2595,
          "title": "Introducing CVSS: A Massively Multilingual Speech-to-Speech Translation Corpus",
          "imageUrl": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "http://www.fast.ai/atom.xml",
      "articles": []
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ub872r/cant_solve_openai_problems/",
          "author": null,
          "description": "I started off with OpenAI's mountain car, and I don't know where to even start. I got the setup working with the environment, but now have no idea how to train it. How do I learn to code for RL? Every tutorial I have seen so far has implemented Q Learning algorithms completely with little explanation. I looked at the solved code and it doesn't make sense to me. How should I prepare before I go into OpenAI?\n    submitted by    /u/TrepidationTD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ub872r/cant_solve_openai_problems/",
          "publishedOn": "2022-04-25T00:18:18.000Z",
          "wordCount": 192,
          "title": "Can't solve OpenAI problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ub5wlq/projects_to_jump_into_rl/",
          "author": null,
          "description": "I have some experience with ML but not at all with RL. I know basic theory and want to just get started with the programming part. I saw OpenAI's gym, but I want to learn RL that can be applied anywhere. I don't want to be specifically constrained to OpenAI's gym and want something where I can apply it to game development, such as Unity. Are there any good resources to just do an RL project?\n    submitted by    /u/TrepidationTD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ub5wlq/projects_to_jump_into_rl/",
          "publishedOn": "2022-04-24T22:20:01.000Z",
          "wordCount": 305,
          "title": "Projects to jump into RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ub1m74/n_step_prioritized_replay_buffer/",
          "author": null,
          "description": "I have a few questions about implementing the N Step version of Prioritized Replay Buffer (for Rainbow DQN). I'm implementing the Atari version of this buffer. To conserve memory, I'm only storing the states (and the last state of each episode) in an unstacked manner. That is, if the frame stack is 4, and the shape of states returned by the environment is 4, I'm storing only the last state of the stacked states. This way the buffer contains all transitions from each episode. As for the N Steps part, I'm only calculating the n_step states when getting states from the buffer instead of storing the N Step transitions directly.\n  \nFor the prioritized version, how do the priorities work? If I wasn't trying to conserve memory, I would have stored the N Step stacked states directly and update the priorities for the segment trees and the segment tree pointers only when moving the data from the N Step buffer to the main buffer. But now that I'm calculating the N Step experience directly when sampling and not when adding data to the buffer, when do I update the priorities and the tree pointer? Once per state? Once per stacked state? Once per N Step stacked state?\n When I update the priorities for the sampled batch, the priorities are associated with multiple states (because the states are stacked). But because I don't store the stacked states and only the raw unstacked states, to which of these states should I update the priority for? And because I don't store the n step transitions anymore, to which of the N Steps should the priorities be associated with?\n If I want to create such a buffer for a vector env, how would I go about doing it? I'm thinking of maintaining a separate segment tree for each env. Is that correct? Is there a better way?\n  \n   submitted by    /u/SirRantcelot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ub1m74/n_step_prioritized_replay_buffer/",
          "publishedOn": "2022-04-24T18:57:39.000Z",
          "wordCount": 426,
          "title": "N Step Prioritized Replay Buffer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uazsx5/confused_between_centralized_critic_and/",
          "author": null,
          "description": "I don't understand if having a centralized critic in multi-agent RL is the same as having a centralized training decentralized execution approach. Can you help me clarify this?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uazsx5/confused_between_centralized_critic_and/",
          "publishedOn": "2022-04-24T17:33:04.000Z",
          "wordCount": 208,
          "title": "Confused between \"centralized critic\" and \"centralized training decentralized execution\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uazrqw/theres_a_yo_mama_joke_in_their_somewhere/",
          "author": null,
          "description": "submitted by    /u/boss_007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uazrqw/theres_a_yo_mama_joke_in_their_somewhere/",
          "publishedOn": "2022-04-24T17:31:32.000Z",
          "wordCount": 162,
          "title": "There's a \"Yo Mama\" joke in their somewhere!!",
          "imageUrl": "https://preview.redd.it/liccxu0ciiv81.png?auto=webp&s=24048a2310cf6d051e401576e6d750499cc4139c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uay0nz/algorithms_for_decision_making_kochenderfer_et_al/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uay0nz/algorithms_for_decision_making_kochenderfer_et_al/",
          "publishedOn": "2022-04-24T16:07:19.000Z",
          "wordCount": 173,
          "title": "_Algorithms for Decision Making_, Kochenderfer et al 2022 (textbook draft; more classical ML than S&B)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uawexa/solving_a_large_dynamic_maze_using_dqn_reward/",
          "author": null,
          "description": "Consider a fixed maze with size (100x400) and fixed start and endpoints (1,1) and (99,399), where doors dynamically appear around the agent every time an observation has been made. The doors disapear after some time step n (for simplicity say n=1). For pitty sake lets say the optimum path length is 1000 steps and there is only one way to reach it.\n I have two questions: \n (1) What would be the most appropriate way to frame reward function? I have tested both volatile aproach (i.e. episodeis terminated if agent steps into wall or previosuly made path, otherwise is rewarded in \"cheese\" every 5 steps) and not-so-volatile approach (i.e. free roam for maximum 2000 steps with cheese reward every 5 steps). Evidently these do not work, are there other perhaps more promising approaches or such large mazes?\n (2) Does the colour of objects in a frame matter to the (convolutional) DQN's learning of the maze. Considering a 3 channel RGB input, is there perhaps a smarter way to colour code the walls/emptypath/etc.? Its a bit of a weird question but my curiosity arises from short-term memory examples (namely, space invaders) where the input, multiple greyscale frames, is chosen over one rgb frame - so to this degree channels can be understood as higher-level \"features\" of a frame, hence, can the colours of different objects be optimised? If so is there a logical way of viewing such optimisation?\n Any other advice is always welcome :)\n ​\n N.B. yes, this could probably be solved with other easier methods but lets just say DQN (or other deep-Q alternatives) is needed.\n    submitted by    /u/Background-Cable-491  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uawexa/solving_a_large_dynamic_maze_using_dqn_reward/",
          "publishedOn": "2022-04-24T14:51:51.000Z",
          "wordCount": 628,
          "title": "Solving a large (dynamic) maze using DQN (reward & observation)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uaruyn/rl_for_classification_problems/",
          "author": null,
          "description": "Hello, I aim to use RL in for classification problem, But I can't see where is the difference between using RL and other ML algorithms that are used in classification (such as MLP, KNN, SVM ..) since we have a train phase in which we teach an agent ( or ML algorithm) the classe of each sample of a labeled dataset. Ok the manner of teching is different but the concept is the same. Then, in a second phase, we test the model with a test set.\n My question is, if I choose RL for classification problem, what is the contribution that we can have compared to another algorithm?\n    submitted by    /u/fatenLouati  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uaruyn/rl_for_classification_problems/",
          "publishedOn": "2022-04-24T10:27:06.000Z",
          "wordCount": 613,
          "title": "RL for classification problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uan8q9/design_of_next_observation_when_collision_for_2d/",
          "author": null,
          "description": "Hi, I am trying to create a continuous 2d maze environment. I tried several algorithms but no one can give me a stable 1 success rate. From time to time, it gets stuck around the obstacle corner and fails to move anymore. Like the picture shows below. I guess it relates to my bad design for giving the next observation for an action that can't make the agent move forward. Currently, my design evenly separates the action into 10 substeps, and returns the observation which corresponds to the step right before the agent meets an obstacle.\n It looks like I won't have this issue for mujoco environment like Ant. But it is really hard to see their design.\n https://preview.redd.it/swohj8h8qev81.png?width=282&format=png&auto=webp&s=7353a62e99ff2141b3660c68ae34ce4f5cd9b94f\n    submitted by    /u/AnimatorRemarkable20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uan8q9/design_of_next_observation_when_collision_for_2d/",
          "publishedOn": "2022-04-24T05:01:42.000Z",
          "wordCount": 249,
          "title": "Design of next observation when collision for 2d continuous maze",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uakmma/why_cant_we_make_a_perfect_ai_for_starcraft/",
          "author": null,
          "description": "First of all, let's discuss what the level of AI is now. If the \"level\" refers to the capability of competing, the current AI has been very closed to the top human player in some types of games, like chess, Texas Poker, and Mahjong of CARDS, DOTA2 of MOBA, as well as StarCraft2 of RTS. As for other games, if we have enough human resources and computing performance, we also can get similar results. If the \"level\" has other meanings, like AI agents having human behavior, intelligent NPC can be designed specifically for different people so that they can have different gaming experience. These are all at the stage of issue-defining and exploring new technology solutions. Although traditional game AI is mostly based on hard code, it still has much prior knowledge. In recent years, some hot ML-r…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uakmma/why_cant_we_make_a_perfect_ai_for_starcraft/",
          "publishedOn": "2022-04-24T02:20:33.000Z",
          "wordCount": 1325,
          "title": "Why can't we make a perfect AI for Starcraft through evolution",
          "imageUrl": "https://external-preview.redd.it/9-HMFHEQ4L6sBMqRkJB8id6O45bMpO6XS_4ZcKXO0Yk.jpg?auto=webp&s=cdcf97f6d0db6f8bef41564f1fc1df2fae35bac2"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uadeqk/how_to_stop_stable_baseline_model_during_the/",
          "author": null,
          "description": "I am training PPO2 model on stable-baseline library. I have tabular data with 15000 rows, thus length of the episodes is 15000. I am using nminibatches=4, n_envs=1. For example, I have set total_timesteps=10000. During the training process agent will see 15000 rows several times and updates actions for each rows, but in some particular point, the rest of the time total_timesteps will not be enough to see the full episode, and only part of episodes is available in the last step of learning. To be concrete. For simplicity, lets say we have 10 raws, 23 total_timesteps. The agent will see the full episode 2 times, and only the first 3 rows in the third times and rest of the 7 raws have not seen during last step.\n I want to stop the learning process when Agent reaches the last time full episodes (above example stop learning at when total_timesteps=20) or define total_timesteps in such a way to see full episodes at the end of the training step.\n    submitted by    /u/Mariam_Dundua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uadeqk/how_to_stop_stable_baseline_model_during_the/",
          "publishedOn": "2022-04-23T19:54:42.000Z",
          "wordCount": 338,
          "title": "How to stop stable baseline model during the training exactly at the end of frame?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/uaa4jr/new_to_rl/",
          "author": null,
          "description": "Hello guys, I am pretty new to the rl field and write now i am doing my thesis in it. I've come across a problem in my code. I created a custom environment and when i am trying to solve it with my dqn agent using stable baselines3, I am able to execute the code and print out the required things but the agent is not learning. Any help ? thanks.\n    submitted by    /u/last_2_brain_cells97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/uaa4jr/new_to_rl/",
          "publishedOn": "2022-04-23T17:14:41.000Z",
          "wordCount": 353,
          "title": "New to RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ua0a4x/questions_on_policy_gradients/",
          "author": null,
          "description": "Hi guys, I am new to RL and reading tutorial of spinning up which focus on policy based algorithms. In the derivation of VPG, the tutorial said\"The environment has no dependence on /theta(the parameter of policy), so gradients of R(/tau)(total return of the trajectory) with respect of /theta is 0. \n However, the trajectory depends on our policy, and our policy depends on /theta. As a result, I am confused why total return of trajectory is independent from /theta.\n    submitted by    /u/SkyRimT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ua0a4x/questions_on_policy_gradients/",
          "publishedOn": "2022-04-23T07:50:34.000Z",
          "wordCount": 538,
          "title": "Questions on policy gradients",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9txgh/vicarious_exits_acquihired_by_google_robotics/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9txgh/vicarious_exits_acquihired_by_google_robotics/",
          "publishedOn": "2022-04-23T01:22:06.000Z",
          "wordCount": 134,
          "title": "Vicarious exits: acquihired by Google robotics (Intrinsic) & DeepMind",
          "imageUrl": "https://external-preview.redd.it/dzwPatLSC5SsPson3p4UoC5DbVOwNR-UJvAq75ytssQ.jpg?auto=webp&s=17719699dfcceb5a52afb3a45cf84c9cbf61b3b9"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9ohi1/data_preprocessing_in_tfagents/",
          "author": null,
          "description": "Hi everyone,\n this is my first post please go easy on me.\n I'm currently playing around with a bigger Model in tf-agents. I worked only with structured data (TF, SKlearn, Pandas...). Now I'm struggling a bit with the preprocessing and where in the architecture to place it. I use multiple Inputs and encoding layers for each of them. For the training of the Encoders I used some SKLearn pre-processor (StandardScaler, MinMaxScaler, KBinsDiscretizer). I try to reuse the pre-processing pipeline in the model or extract the information for other pre-processing mechanisms(e.g. pre-processing tf layers)\n My current options I came up with:\n  \nIncorporate it directly into the Environment and return the pre-processed observation \n Pro easy, can probably use my SKlearn pipeline \n Contra I'd like to keep the architecture clean, so the environment should only give out raw values and not prepared values for a certain model\n \n Use an environment wrapper around the \"raw\" environment \n Pro \"raw\" environment needs no tuning\n Contra not sure if I can use my pipeline here and not sure if I'm taking a bad path here \n \n Use pre-processing TF layers \n Pro most of the API is there and can be used in my Encodernetworks, seems to be the TFic way\n Contra the SKlearn pre-processor have values for each column. The layers (e.g. rescale ) seems to only take one configuration for a whole tensor. I could probably create a layer for each value in the Tensor but that doesn't feel that it is supposed to be like that.\n \n  \nIf you have more options or can share your experience one of the options mentioned above I would be very glad.\n    submitted by    /u/Kjiessar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9ohi1/data_preprocessing_in_tfagents/",
          "publishedOn": "2022-04-22T20:54:38.000Z",
          "wordCount": 372,
          "title": "Data Pre-Processing in TF-Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9ies3/masking_in_rnn_in_the_actor_network/",
          "author": null,
          "description": "I am using PPO in the context of multi-agent RL. I was wondering if PyTorch has a way of handling when hidden states should be reinitialized to zeros. \n What I have found is this implementation: \n  def forward(self, x, hxs, masks): if x.size(0) == hxs.size(0): x, hxs = self.rnn(x.unsqueeze(0), (hxs * masks.repeat(1, self._recurrent_N).unsqueeze(-1)).transpose(0, 1).contiguous()) x = x.squeeze(0) hxs = hxs.transpose(0, 1) else: # x is a (T, N, -1) tensor that has been flatten to (T * N, -1) N = hxs.size(0) T = int(x.size(0) / N) # unflatten x = x.view(T, N, x.size(1)) # Same deal with masks masks = masks.view(T, N) # Let's figure out which steps in the sequence have a zero for any agent # We will always assume t=0 has a zero in it as that makes the logic cleaner has_zeros = ((masks[1:] == 0.0) .any(dim=-1) .nonzero() .squeeze() .cpu()) # +1 to correct the masks[1:] if has_zeros.dim() == 0: # Deal with scalar has_zeros = [has_zeros.item() + 1] else: has_zeros = (has_zeros + 1).numpy().tolist() # add t=0 and t=T to the list has_zeros = [0] + has_zeros + [T] hxs = hxs.transpose(0, 1) outputs = [] for i in range(len(has_zeros) - 1): # We can now process steps that don't have any zeros in masks together! # This is much faster start_idx = has_zeros[i] end_idx = has_zeros[i + 1] temp = (hxs * masks[start_idx].view(1, -1, 1).repeat(self._recurrent_N, 1, 1)).contiguous() rnn_scores, hxs = self.rnn(x[start_idx:end_idx], temp) outputs.append(rnn_scores) # assert len(outputs) == T # x is a (T, N, -1) tensor x = torch.cat(outputs, dim=0) # flatten x = x.reshape(T * N, -1) hxs = hxs.transpose(0, 1) \n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9ies3/masking_in_rnn_in_the_actor_network/",
          "publishedOn": "2022-04-22T16:17:47.000Z",
          "wordCount": 553,
          "title": "Masking in RNN in the actor network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9id2s/does_anyone_know_of_a_chess_environment_written/",
          "author": null,
          "description": "I don't think an opensource one exists but figured I'd ask here because you never know what's laying around the internet!\n As an aside, if one doesn't exist, let me know if you're interested in partnering in writing one!\n Edit: For anyone wondering I need the env to be in jax because my muzero implementation is in jax and I need the env to run on TPU cores, not CPU\n    submitted by    /u/evanatyourservice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9id2s/does_anyone_know_of_a_chess_environment_written/",
          "publishedOn": "2022-04-22T16:15:34.000Z",
          "wordCount": 406,
          "title": "Does anyone know of a chess environment written in JAX?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9fnzk/papers_that_use_neural_networks_solely_for/",
          "author": null,
          "description": "I am looking for any papers that do the following: use neural networks in the RL pipeline as the state space is too large for calculating the optimal policy using the traditional tabular value iteration or policy iteration. In this setting, the model is completely known, i.e., no learning.\n Most papers I see with DeepRL assume that the transition probabilities are unknown and that they have access to a simulator that gives them the ability to query data points. I am looking for existing work in DeepRL where the transition probabilities are known but the problem is intractable using tabular methods. Any direction would be appreciated, thanks!\n    submitted by    /u/lolillini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9fnzk/papers_that_use_neural_networks_solely_for/",
          "publishedOn": "2022-04-22T14:13:49.000Z",
          "wordCount": 250,
          "title": "Papers that use neural networks solely for planning in large MDPS (i.e., no learning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9eiu8/ppo_update_without_using_nns_batch_updates/",
          "author": null,
          "description": "Hello, im making a new post as i couldnt find any answers to this before (although this reddit post is similar to my issue)\n I am trying to implement a simple multivariate Gaussian policy without neural networks, basically using a standard policy gradient update with SGD + score function gradient, without batches. The reason for this is to avoid unstable updates, meaning too large updates in mean/variance. The idea is thus to use a trust region update, to keep the updates within some reasonable size.\n I am a little confused regarding the maximization of the surrogate objective. As seen in this stackoverflow post, we wish to maximize [pi/pi_old] , compared to [log(pi)] in vanilla PG.\n Since i do not use automatic differentiation, but one single stochastic descent, how do I find the gradient of pi/pi_old ?\n To my understanding, the flow of the algorithm is this:\n sample experience -> compute new policy parameters -> compare with previous policy -> construct surrogate function -> perform SGD on surrogate to get the actual new policy\n It is the last step i am struggling with.\n    submitted by    /u/Acrobatic-Ad-9189  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9eiu8/ppo_update_without_using_nns_batch_updates/",
          "publishedOn": "2022-04-22T13:20:08.000Z",
          "wordCount": 315,
          "title": "PPO update without using NNs / batch updates",
          "imageUrl": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&s=8cd5e918e2bde6ca72d4445d6fc007f203689799"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u9ehbm/simulating_robotic_arm_for_object_manipulation/",
          "author": null,
          "description": "I'll be starting my work for object manipulation using deep RL, and i would like to get start from the scratch, please recommend the source, tools, and software used for this purpose. but not be working on modeling the robot, instead will be using any robot with gripper which can be interfaced with ROS. Also please link the github repositories which can be helpfull in the learning process Thanks\n    submitted by    /u/Western-Age3148  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u9ehbm/simulating_robotic_arm_for_object_manipulation/",
          "publishedOn": "2022-04-22T13:18:02.000Z",
          "wordCount": 261,
          "title": "Simulating robotic arm for object manipulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u96v3j/policyencoding_mapping_implementation/",
          "author": null,
          "description": "Hi, I want to check policy-encoding mapping \n e : (S → A) → R^k in Universal Successor Features Approximators. \n I don't know how to embedding network to another network. There are too many weights! Do you have any ideas? Thank you for reading!\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u96v3j/policyencoding_mapping_implementation/",
          "publishedOn": "2022-04-22T05:11:54.000Z",
          "wordCount": 168,
          "title": "policy-encoding mapping implementation",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u94ans/useful_tools_and_resources_for_reinforcement/",
          "author": null,
          "description": "Found a useful list of Tools, Frameworks, and Resources for RL/ML. It covers Reinforcement learning, Machine Learning (TensorFlow & PyTorch), Core ML, Deep Learning, Computer Vision (CV). I thought I'd share it for anyone that's interested\n    submitted by    /u/Khaotic_Kernel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u94ans/useful_tools_and_resources_for_reinforcement/",
          "publishedOn": "2022-04-22T02:43:38.000Z",
          "wordCount": 159,
          "title": "Useful Tools and Resources for Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/s-Wj4S_9WJ_xlA5ctanRGEEBVFmgaunBXjCZnxe7ooI.jpg?auto=webp&s=b3a0c384a58fe2df6f5d7251ca3b253c32c6c5e9"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u90m69/question_about_trained_models/",
          "author": null,
          "description": "Hello I have a question.\n For example, in the case of an inverted pendulum or cartpole, I train the model for the pole to be at 0 degrees (vertical) and it works. Then I want this same model to keep the pole at another position, for example, 3 degrees, do I have to train this model again for achieving this to or can I somehow use the model I already trained and what it learnt and input the new position I want it to be?\n idk if I explained myself\n I guess its mostly doubts about how to interact with the model and how to properly use a model that has already been trained. If anyone has some example of code (python, gym), on interacting with a trained model it would be really helpful.\n    submitted by    /u/Sleyck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u90m69/question_about_trained_models/",
          "publishedOn": "2022-04-21T23:31:41.000Z",
          "wordCount": 245,
          "title": "Question about trained models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8vhct/why_is_this_implementation_of_ppo_using_a_replay/",
          "author": null,
          "description": "https://github.com/marlbenchmark/on-policy/blob/main/onpolicy/algorithms/r_mappo/r_mappo.py\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8vhct/why_is_this_implementation_of_ppo_using_a_replay/",
          "publishedOn": "2022-04-21T19:28:37.000Z",
          "wordCount": 282,
          "title": "Why is this implementation of PPO using a replay buffer?",
          "imageUrl": "https://external-preview.redd.it/NILAiM6ka0xRo4eWi6VVljKuwWMAWyxwmZ0MceK7lbk.jpg?auto=webp&s=14995e2d2ebb47523b8c24b4b0b09457e6c2c023"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8unh1/what_is_the_role_of_masks_in_the_computation_of/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8unh1/what_is_the_role_of_masks_in_the_computation_of/",
          "publishedOn": "2022-04-21T18:50:24.000Z",
          "wordCount": 202,
          "title": "What is the role of masks in the computation of GAE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8sq20/question_about_optimal_policy_guarantees_in_pomdps/",
          "author": null,
          "description": "I'm working on a project where I'm trying to prove the existence of a particular set of functions by showing it can be constructed as the solution to a Markov Decision Process. However, it seems that it's much simpler to convert it to a partially observable MDP, rather than a classic one. I know it's been proven that the set of optimal policies for a classic MDP is nonempty, and intuitively I feel like the same should hold for POMDPs, but I'm having a hard time finding a particular source proving such a thing. Does anyone know where I ought to look?\n    submitted by    /u/LessPoliticalAccount  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8sq20/question_about_optimal_policy_guarantees_in_pomdps/",
          "publishedOn": "2022-04-21T17:21:36.000Z",
          "wordCount": 225,
          "title": "Question About Optimal Policy Guarantees in POMDPs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8rprt/can_reinforcement_learning_learn_itself_a_reply/",
          "author": null,
          "description": "submitted by    /u/JBaloney  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8rprt/can_reinforcement_learning_learn_itself_a_reply/",
          "publishedOn": "2022-04-21T16:36:22.000Z",
          "wordCount": 447,
          "title": "Can reinforcement learning learn itself? A reply to 'Reward is enough' (PDF)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8pyvd/what_is_this_line_in_the_suttonbarto_textbook/",
          "author": null,
          "description": "In the first edition of the textbook, the section on actor-critic methods (link) describes the classical approach of using the temporal difference error 𝛿 to modify the probability of selecting action a in state s:\n https://preview.redd.it/fa35vut7ewu81.png?width=238&format=png&auto=webp&s=c1b8952b065a90ecd2b8c0c30b985e36d37dbc30\n Then they briefly mention that one variation on the classical approach is to scale temporal difference error 𝛿 by the inverse of the probability of selecting the action a, where that probability is given by 𝜋(s, a):\n https://preview.redd.it/69gd3zmbdwu81.png?width=375&format=png&auto=webp&s=b66a7d5eef3c2b7bc256473aed728223921a751c\n They say: \" These issues were explored early on, primarily for the immediate reward case (Sutton, 1984; Williams, 1992) and have not been brought fully up to date.\"\n This idea is relevant to a project I'm working on, and I'd like to read more about it. But the references seem to be dead ends: Sutton 1984 is his PhD thesis, which I can't find a digital copy of, and Williams 1992 is this paper, which doesn't seem to contain this idea. Also this section doesn't seem to appear in the second edition of the textbook.\n You folks are much smarter than I am: Does modifying the update in this way mean anything to you? Are there modern approaches that do something like this? Or should I assume it was a little-explored idea in the early days that has been more-or-less forgotten?\n Thanks very much!\n    submitted by    /u/Careless-Argument-37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8pyvd/what_is_this_line_in_the_suttonbarto_textbook/",
          "publishedOn": "2022-04-21T15:18:06.000Z",
          "wordCount": 481,
          "title": "What is this line in the Sutton/Barto textbook referring to?",
          "imageUrl": "https://external-preview.redd.it/nvM-yG-06ytVatoSx5jmOO2dk1m54bekQ4sWGWyP13o.jpg?auto=webp&s=64b68547b2d2fffff368554156c2730c6cdb0c32"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8pbow/reinforcement_learning_with_delays/",
          "author": null,
          "description": "I was wondering what methods there are for RL with time delay other than augmenting the state space with the action buffer or using a model to undelay the environment. I've seen this post How to deal with the time delay in reinforcement learning? - Artificial Intelligence Stack Exchange however it's rather brief and I wondered if there were any more recent advancements.\n I am also struggling to understand partial trajectory resampling ( 2010.02966.pdf (arxiv.org) ) and the code in the accompanying repo. GitHub - rmst/rlrd: PyTorch implementation of our paper Reinforcement Learning with Random Delays (ICLR 2020) \n I was wondering how we can resample actions in environments with constant delays if those actions are used in the state space for all subsequent chosen actions?\n    submitted by    /u/SuperDuperDooken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8pbow/reinforcement_learning_with_delays/",
          "publishedOn": "2022-04-21T14:48:51.000Z",
          "wordCount": 268,
          "title": "Reinforcement Learning with delays",
          "imageUrl": "https://external-preview.redd.it/MyPYjJuEdSjpldenX2HAv7ypDZ5RoSxLh1peLFH0LQY.jpg?auto=webp&s=becf24ba2bf18dec6c08b396b82b8117a41340c4"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8g9do/is_it_stupid_to_use_rl_to_control_solar_panel/",
          "author": null,
          "description": "submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8g9do/is_it_stupid_to_use_rl_to_control_solar_panel/",
          "publishedOn": "2022-04-21T05:31:42.000Z",
          "wordCount": 408,
          "title": "Is it stupid to use rl to control solar panel angle?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u8e9qi/how_can_i_use_the_environment_in_emergence_of/",
          "author": null,
          "description": "Hi, I want to train my agent in the environment used in \"Emergence of Locomotion Behaviours in Rich Environments\". Here is a video about that https://www.youtube.com/watch?v=hx_bgoTF7bs. Is the environment released? Thanks for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u8e9qi/how_can_i_use_the_environment_in_emergence_of/",
          "publishedOn": "2022-04-21T03:33:27.000Z",
          "wordCount": 252,
          "title": "How can I use the environment in Emergence of Locomotion Behaviours in Rich Environments?",
          "imageUrl": "https://external-preview.redd.it/fmJw_BqWhQgP8-1v0fvrbHkuKAsNYOg3NGiEK6vMtb0.jpg?auto=webp&s=259f0644cdbce7ce142e6a4c1a20fa095f7bb14d"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u87xtm/is_there_any_difference_between_how_ddpg_and_ppo/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u87xtm/is_there_any_difference_between_how_ddpg_and_ppo/",
          "publishedOn": "2022-04-20T22:11:06.000Z",
          "wordCount": 433,
          "title": "Is there any difference between how DDPG and PPO use the replay buffer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u87qu6/any_tips_for_a_prospective_graduate_student_in/",
          "author": null,
          "description": "Hello Everyone, I apologize ahead of time if posts like this aren't looked well upon on this sub, but I couldn't find rules against this and I also think this is the best, most niche sub for my question. I also made a new account just to be safe haha.\n ​\n Anyways, I will be graduating this spring with a BS in Computer Science and a BA in Mathematics. I have been researching Machine Learning since my sophomore year (adversarial machine learning) under a professor at my university and recently took upon a second, concurrent research position in RL since last summer.\n ​\n My goal is to get into a PhD program at a higher level than my current university (my current university is good, but doesn't really have much of an AI focus as I've already taken all the AI grad courses as an undergrad). I'm…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u87qu6/any_tips_for_a_prospective_graduate_student_in/",
          "publishedOn": "2022-04-20T22:02:01.000Z",
          "wordCount": 943,
          "title": "Any tips for a prospective graduate student in Reinforcement Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u838na/task_allocation_problem_with_graph_representation/",
          "author": null,
          "description": "Hey everyone,\n I've recently started working on a task allocation problem using RL. I'd just like to make sure my thinking is correct on how to best approach the problem. \n At the moment, we have (effectively) a graph traversal sim for n number of agents, where the goal is to minimize the total distance over an episode, as determined by setting the correct tasks. The task supplied to each agent will determine the route that is taken, and therefore the distance. \n The current idea is to supply an input graph that also contains information on the current location of the agents. A second input would be the set of available tasks. The expected output would be done through a pointer network, where we produce a reordered set of the tasks in descending order of optimality. \n When step is called, the sim runs until a new task is needed (agent completes it's route). \n ​\n In general, does anyone know a good way to represent the inputs and output of this problem? A pointer network seems like it could work to produce actions, but if I need to do a forward pass for every agent, it seems that there would be no consideration of other agents when determining tasks (We shouldn't have 2 agents doing the same task). For the graph representation, a graph nn seems like an obvious choice, but I just wanted to see if anyone had any insight on why they may or may not be used.\n    submitted by    /u/asdfsflhasdfa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u838na/task_allocation_problem_with_graph_representation/",
          "publishedOn": "2022-04-20T18:36:22.000Z",
          "wordCount": 362,
          "title": "Task Allocation problem with graph representation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7usiq/universities_working_on_reinforcement_learning/",
          "author": null,
          "description": "Can you name any good universities (with high acceptance rate) which are working on reinforcement learning for robotics and also accept students from other branches (i.e. Electrical, Mechanical Engineering).\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7usiq/universities_working_on_reinforcement_learning/",
          "publishedOn": "2022-04-20T11:57:05.000Z",
          "wordCount": 398,
          "title": "Universities working on reinforcement learning for robotics.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7sbok/is_the_game_of_chess_a_finite_mdp/",
          "author": null,
          "description": "In the standard intro to RL book, I have read that any MDP that has finite actions and states is a finite MDP. But that limit is subjective. So there are approximately 1045. If I limit myself to 105 states, can I say that chess isn't a finite MDP?\n    submitted by    /u/BraveProfessional656  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7sbok/is_the_game_of_chess_a_finite_mdp/",
          "publishedOn": "2022-04-20T09:12:44.000Z",
          "wordCount": 315,
          "title": "Is the game of chess a finite MDP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7qaw4/reinforcement_learning_over_traditional_machine/",
          "author": null,
          "description": "I am currently studying use cases of RL in finance/banking/insurance and I am keen to understand what are its advantages and disadvantages than traditional methods.\n    submitted by    /u/kachua26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7qaw4/reinforcement_learning_over_traditional_machine/",
          "publishedOn": "2022-04-20T06:44:11.000Z",
          "wordCount": 208,
          "title": "Reinforcement learning over traditional machine learning method in Finance/Banking ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7ggt5/reinforcement_learning_with_actionfree/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7ggt5/reinforcement_learning_with_actionfree/",
          "publishedOn": "2022-04-19T21:49:07.000Z",
          "wordCount": 140,
          "title": "\"Reinforcement Learning with Action-Free Pre-Training from Videos\", Seo et al 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7g00a/inferring_rewards_from_language_in_context_lin_et/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7g00a/inferring_rewards_from_language_in_context_lin_et/",
          "publishedOn": "2022-04-19T21:28:01.000Z",
          "wordCount": 139,
          "title": "\"Inferring Rewards from Language in Context\", Lin et al 202",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u7adqi/bandit_problems_as_sequential_decision_problems/",
          "author": null,
          "description": "Any reinforcement learning problem can be modeled as a sequential decision problem (SDP), which can always be modeled as a Markov decision process (need to model the state carefully). An example of an SDP is a multiarmed bandit problem, where the state is the vector of beliefs about the performance of each arm (or beliefs about a continuous parametric model). Decisions are made by a policy, and there are four classes of policies. For some reason, the RL community tends to focus on just one of the four classes (UCB policies, which fall in the class of cost function approximations), but there are entire communities using each of the other three classes. See chapter 7 of my new book (https://castlelab.princeton.edu/RLSO/) for a complete summary of the four classes of policies for pure learning problems (aka bandit problems). Note that Sutton and Barto (2nd edition) cover bandit problems in chapter 2, and then introduce MDPs in chapter 3. A bandit problem *is* an MDP!\n    submitted by    /u/powell-sda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u7adqi/bandit_problems_as_sequential_decision_problems/",
          "publishedOn": "2022-04-19T17:21:02.000Z",
          "wordCount": 283,
          "title": "Bandit problems as sequential decision problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u78oup/getting_started_with_uavdrone_control/",
          "author": null,
          "description": "Hi, is it currently possible to train a UAV and implement the policy it in real-life? I understand there are different environments for training, e.g. AirSim, GymFC, and others. However, the interesting part for me is the link to the real world: Is there a way to directly implement any learned policy on a real drone, e.g. a commercially available quad-copter? Which UAV would support such a functionality?\n I'd love to get started on training drones for RL purposes (search and rescue, etc), but if there is no way to test it in real-life then this would be disappointing.\n    submitted by    /u/FrankTheThanks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u78oup/getting_started_with_uavdrone_control/",
          "publishedOn": "2022-04-19T16:06:29.000Z",
          "wordCount": 424,
          "title": "Getting started with UAV/drone control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u78gb9/question_about_expected_sarsa_for_prediction_vs/",
          "author": null,
          "description": "I am having a hard time figuring out what makes the difference between Expected Sarsa for prediction vs for control.\n For off-policy Expected Sarsa I believe it's possible to use one epsilon value for a target policy that is epsilon-greedy and another epsilon value for a behaviour policy that is epsilon-greedy. The target policy would be used within the expected value calculation in the update of Q(S,A), the action value function, and the behaviour policy would be used to choose actions from the current state. But I'm not sure how to differentiate between the control version of the algorithm compared to the prediction version though.\n I think prediction usually finds the state-value function but I know that on-line Sarsa for prediction uses Q(S,A) so I'm not sure how to determine the difference between prediction and control algorithms.\n    submitted by    /u/lifelifebalance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u78gb9/question_about_expected_sarsa_for_prediction_vs/",
          "publishedOn": "2022-04-19T15:56:29.000Z",
          "wordCount": 261,
          "title": "Question about Expected Sarsa for prediction vs control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u74qir/exploration_strategies_in_discrete_action_spaces/",
          "author": null,
          "description": "Hello there, I am working on missile command game, and as a baseline I mostly use rllib/ppo. The algorithm never converges, I suspect it is because of the lack of exploration. Since the timesteps are small, the target usually oscillates around center of the screen, it is impossible to explore to go near the border and then explore to fire (to counter incoming missile). What methods should I try?\n Moreover, I have already done reward scaling and frame staking. Any suggestions regarding solving this game is much appreciated. \n Last question, do you now similar (and common) environments that is solved, maybe solutions show the path to follow.Thank you :)\n    submitted by    /u/Street_Excitement_14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u74qir/exploration_strategies_in_discrete_action_spaces/",
          "publishedOn": "2022-04-19T13:06:53.000Z",
          "wordCount": 336,
          "title": "exploration strategies in discrete action spaces",
          "imageUrl": "https://external-preview.redd.it/EVmS5b9nw-cH6h_YyaCIR7CARFegttHf-ELvgY9mmz8.jpg?auto=webp&s=a28b0ae18e162832aaf0358d792bfa77652b5a69"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u71ce8/confusion_of_hyperparameters_in_ppo/",
          "author": null,
          "description": "I'm reading the ppo paper https://arxiv.org/abs/1707.06347 and I'm confusing about the hyperparameters in table 4, Log stdev. of action distribution | LinearAnneal(-0.7, -1.6).\n Best to my knowledge, under the continuous setting, the policy will output mean and std, so why the stdev of action distribution is given as a hyperparameter, and also what is LinearAnneal in detail.\n    submitted by    /u/StrawberryTemporary7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u71ce8/confusion_of_hyperparameters_in_ppo/",
          "publishedOn": "2022-04-19T09:49:32.000Z",
          "wordCount": 297,
          "title": "Confusion of hyperparameters in ppo",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u6yce5/need_help_about_categorical_dqn/",
          "author": null,
          "description": "I dk how the projection of TZ to match Z work and I also dont understand the formula? can someone do step by step calculation to demo?\n    submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u6yce5/need_help_about_categorical_dqn/",
          "publishedOn": "2022-04-19T06:17:59.000Z",
          "wordCount": 175,
          "title": "Need help about categorical dqn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u6ptng/a3c_vs_federated_learning/",
          "author": null,
          "description": "Hi, \n I see this question was asked before but I am still not convinced there is a difference between the two. \n How is asynchronous distributed RL (A3C) and federated learning different? It seems like the basic idea behind them is the same— the agents train in their own environments and only share gradients with the server. \n Is the difference only in terms of the domain they are applied in? Is it just ML vs RL?\n    submitted by    /u/uneasy_daisy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u6ptng/a3c_vs_federated_learning/",
          "publishedOn": "2022-04-18T22:49:11.000Z",
          "wordCount": 186,
          "title": "A3C vs federated learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u61537/can_polyak_averaging_neural_networks_lead_to/",
          "author": null,
          "description": "In Soft Actor Critic several Q networks are used. Target Q networks are gradually updated to match other Q networks.\n See step 15 here: https://spinningup.openai.com/en/latest/algorithms/sac.html#pseudocode\n I've heard this called polyak averaging.\n Let's say we have two weights from two neural networks: W1 from one network, and W2 is the corresponding weight from the other network. Polyak averaging averages these weights as follows:\n W_average = W1 * p + W2 * (1-p)\n When p is 0.5, it's a evenly weighted average. If p is high, then W1 is weighted more heavily than W2, etc.\n My question is: Does this method of averaging weights lead to numerically unstable neural networks? This technique is often used to gradually transform one neural network into another on a weight by weight basis, but there is no guarantee that all intermediate neural networks are well behaved (at least, none that I'm aware of). Whereas, gradient descent with small enough step sizes should, theoretically, keep a neural network well behaved, I think those same theoretical guarantees apply to polyak averaging neural networks.\n What do you think?\n    submitted by    /u/Buttons840  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u61537/can_polyak_averaging_neural_networks_lead_to/",
          "publishedOn": "2022-04-18T01:13:50.000Z",
          "wordCount": 611,
          "title": "Can polyak averaging neural networks lead to numerical instability?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u5jzpy/learning_style_of_play_different_agents_actions/",
          "author": null,
          "description": "Hi, everyone. I'm a relative novice in RL, so bear with me as I try to formulate my question.\n I'm working on a chess bot that can play moves like a player (imitate their style of play) that is chosen from a set of players (that the bot is trained on) , if I give the bot the previous x moves. Using more technical terms, I'm trying to create an agent that is given a sequence of states-actions of another agent (player) and some representation of who that agent (player) is, and predict the next action (continue playing in the style of that player).\n I'm fairly certain this is an RL problem, as I don't know how to frame it as a supervised learning problem (I might be wrong).\n I've seen some papers that abstract offline RL as a sequence modeling problem (Decision Transformer, Trajectory Transformer), so I'm fairly certain I should continue in a similar manner.\n But I'm having a hard time trying to understand how to treat the difference in players. My instinct was to use some representation of the player as the reward, but then how would I even optimize for it or even give it as an input? Do I just add the player as a feature in the game state, but then what should be the reward?\n Has this been done before, or something similar? I couldn't really find any paper or code that worked on differentiating the training data by who made it (I might not be wording it correctly).\n    submitted by    /u/OverhypeUnderdeliver  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u5jzpy/learning_style_of_play_different_agents_actions/",
          "publishedOn": "2022-04-17T10:01:57.000Z",
          "wordCount": 859,
          "title": "Learning style of play (different agents' actions) in the same offline RL environment?",
          "imageUrl": "https://external-preview.redd.it/MeJ3D66GfO9rJcYwzbVXuOn9Z3ZRkFGm-_tW9oPYGkI.jpg?auto=webp&s=08a5addc53a466a49589e35e34c912174b61df9e"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u5899l/rigorous_treatment_of_mdps_bellman_etc_in/",
          "author": null,
          "description": "I am looking for a book/monograph that goes through all the basics of reinforcement learning for continuous spaces with mathematical rigor. The classic RL book from Sutton/Barto and the new RL theory book from Agarwal/Jiang/Kakade/Sun both stick to finite MDPs except for special cases like linear MDPs and the LQR.\n I assume that a general statement of the fundamentals for continuous spaces will require grinding through a lot of details on existence, measurability, suprema vs. maxima, etc., that are not issues in the finite case. Is this why these authors avoid it?\n clarifying edit: I don't need to go all the way to continuous time - just state and action spaces.\n Maybe one of Bertsekas's books?\n    submitted by    /u/quadprog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u5899l/rigorous_treatment_of_mdps_bellman_etc_in/",
          "publishedOn": "2022-04-16T21:57:56.000Z",
          "wordCount": 367,
          "title": "Rigorous treatment of MDPs, Bellman, etc. in continuous spaces?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u51nkf/need_help_making_a_basic_python_model/",
          "author": null,
          "description": "I have a 2 column dataset “Date” “Result”. The Result column produces a 0 or 1 for each date. I need to make a reinforcement model that will predict whether or not the next result will be a 0 or 1. It needs to be done in jupyter notebook .\n    submitted by    /u/EffectiveBug4629  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u51nkf/need_help_making_a_basic_python_model/",
          "publishedOn": "2022-04-16T16:39:32.000Z",
          "wordCount": 188,
          "title": "NEED HELP MAKING A BASIC PYTHON MODEL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u51hk5/from_machine_learning_to_sequential_decision/",
          "author": null,
          "description": "Any reinforcement learning problem can be modeled as a sequential decision problem (SDP), which can always be modeled as a Markov decision process. An example of an SDP is a multiarmed bandit problem, where the state is the vector of beliefs about the performance of each arm (or beliefs about a continuous parametric model). Decisions are made by a policy, and there are four classes of policies. For some reason, the RL community tends to focus on just one of the four classes (UCB policies, which fall in the class of cost function approximations), but there are entire communities using each of the other three classes. See chapter 7 of my new book for a complete summary of the four classes for pure learning problems (aka bandit problems). See https://tinyurl.com/RLandSO/ Curious why Sutton and Barto (2nd edition) cover bandit problems in chapter 2, and then introduce MDPs in chapter 3. A bandit problem *is* an MDP!\n    submitted by    /u/powell-sda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u51hk5/from_machine_learning_to_sequential_decision/",
          "publishedOn": "2022-04-16T16:31:27.000Z",
          "wordCount": 285,
          "title": "From machine learning to sequential decision problems (reinforcement learning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4ygra/policy_gradient_vs_policy_iteration/",
          "author": null,
          "description": "Hello, I'm currently learning about MDPs and machine learning. I have a few questions that might be trivial or obvious but I can't find many concrete answers online:\n -Are policy gradient and policy iteration similar/the same? From what I can gather, policy iteration is a type or subset of policy gradient algorithm, is this correct?\n -Are all policy learning methods less effective for large state spaces? From my understanding you need to use some kind of value function iteration and heursitic function for larger state spaces because you can't encounter all states enough times to converge on an optimal policy\n -Does convergence on a policy/value function find a local or global optimum? With neural nets, simple backpropagation may only find a local minimum for the cost function, is this true of MDP/RL iteration algorithms? \n Thanks!!\n    submitted by    /u/egad_a_mouse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4ygra/policy_gradient_vs_policy_iteration/",
          "publishedOn": "2022-04-16T14:02:27.000Z",
          "wordCount": 561,
          "title": "Policy gradient vs. Policy iteration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4x8pg/how_to_create_a_layer_without_inputs_in_tensorflow/",
          "author": null,
          "description": "In deep rl algorithm like PPO, a continuous stochastic policy is represented by Normal Distribution. For this the recommended way of creating a Normal Distribution is to get the mean by passing the state through NN and then using a state independent layer to predict log_std. This layer which predicts log_std should be trainable using backprop just like biases. So how to create this layer in tensorflow 2.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4x8pg/how_to_create_a_layer_without_inputs_in_tensorflow/",
          "publishedOn": "2022-04-16T12:56:39.000Z",
          "wordCount": 234,
          "title": "How to create a layer without inputs in tensorflow.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4jzbn/new_to_machine_learning_want_to_simulate_robotics/",
          "author": null,
          "description": "My employer makes significant use of robotic weld cells, and while working with the equipment I've noticed what seems to be room for improvement in the programming. This is purely a personal academic project, as I am quite curious on if machine learning could produce comparable or superior results to the human-made programming used at work. However, as such there will unfortunately be areas of vagueness because I need to stick to knowledge that is publicly available regarding their operations. I'm going to have to stick to more generic, publicly available reference material, and will not be able to share most, if any, of the end result.\n I would like to run simulations in a 3D environment, using machine learning to train a computer program to find the most efficient sequence of movements &…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4jzbn/new_to_machine_learning_want_to_simulate_robotics/",
          "publishedOn": "2022-04-15T22:52:33.000Z",
          "wordCount": 943,
          "title": "New to machine learning, want to simulate robotics in a 3d environment",
          "imageUrl": "https://external-preview.redd.it/L21x-Qy50-NkImNnJV3XZ9rjr5qsTyhFX6Rnr9rsIjc.jpg?auto=webp&s=8decf3b0602a577f844c587a17534ef1caf6afc6"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4hsqr/does_using_a_centralized_critic_always_mean_that/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4hsqr/does_using_a_centralized_critic_always_mean_that/",
          "publishedOn": "2022-04-15T21:05:05.000Z",
          "wordCount": 142,
          "title": "Does using a centralized critic always mean that the agents receive global observation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4hcbb/what_algorithm_would_be_suited_for_a_just_do_it/",
          "author": null,
          "description": "I’m really new to RL so please bear with me if I’m making mistakes here, but I’m trying to make an environment that emulates a network of roads. The algorithm will need to generate a quick route between n destinations when n equals some number with an insane amount of permutations, like 30 for example. This is like emulating the destinations required by a mailman’s route on a map, and trying to find the fastest way to get to each one.\n The algorithms sequence of decisions will be choosing a node to travel to, while each node represents an street intersection or point where the street ends. By the time it’s traveled to every destination using the nodes, it’ll review the network of nodes it used and sum the distance between each one to get total distance of route. \n The goal is to get the total distance as small as possible. Is this realistic for a RL problem, or do I need to try to engineer some way to determine if every decision was either good or bad? Could I build a mathematical way to approximate the quickest route and then reward the RL algorithm by generating a better route than the mathematically approximated one?\n I could try rewarding the algorithm at each decision by whether it reduced the total distance required to any target it has yet to visit. I could try to mathematically make this more viable… what do y’all think,should I do something like that? Am I headed in the right direction? \n Thanks for any and all help!\n    submitted by    /u/professorDissociate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4hcbb/what_algorithm_would_be_suited_for_a_just_do_it/",
          "publishedOn": "2022-04-15T20:43:05.000Z",
          "wordCount": 753,
          "title": "What algorithm would be suited for a “Just do it as good as you can” situation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4ev1g/where_is_envns_for_frozen_lake_in_openai_gym/",
          "author": null,
          "description": "I am trying to run this:\n env4 = FrozenLakeEnv(map_name='4x4', is_slippery=False)\n env4.nS\n ​\n I then get this error:\n 'FrozenLakeEnv' object has no attribute 'nS'\n ​\n But I see it in the source code on line 151 and 152:\n https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py\n ​\n Edit: I'm trying to follow along with some tutorials online.\n Thank you for the help!\n    submitted by    /u/postdoc403b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4ev1g/where_is_envns_for_frozen_lake_in_openai_gym/",
          "publishedOn": "2022-04-15T18:46:08.000Z",
          "wordCount": 229,
          "title": "Where is env.nS for Frozen Lake in OpenAI Gym",
          "imageUrl": "https://external-preview.redd.it/nVtKqdjb-CU3wRoPE0dNudgt4TtugQhhLFMCahT2XTY.jpg?auto=webp&s=115d3f128a80fab6cd7e9297ee85d71500121ab3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4ci7r/getting_maxmin_action_in_ddpg_and_td3/",
          "author": null,
          "description": "I am using DDPG for a custom environment. My reward is positive (the sum-rate in a communication system). My problem is that I get the max or min action after a few training steps and it saturates with a non-optimized solution. How can I address this problem? I tried redesigning my reward to include positive and negative values but it didn’t work. I read that some people are using reward scaling. What is it and how would I scale it? I mean is there a specific method? I couldn’t find enough resources on that. Any help is much appreciated!\n    submitted by    /u/alicefaisal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4ci7r/getting_maxmin_action_in_ddpg_and_td3/",
          "publishedOn": "2022-04-15T16:58:26.000Z",
          "wordCount": 222,
          "title": "Getting max/min action in DDPG and TD3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u4b1gq/question_about_pseudocodes/",
          "author": null,
          "description": "Hi I'm redoing all the RL algorithms in python, to better understanding them. I'm mostly following Sutton and Barto but the pseudo code there is often hard to follow.\n Do you know any other place where I can look at?\n    submitted by    /u/New_neanderthal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u4b1gq/question_about_pseudocodes/",
          "publishedOn": "2022-04-15T15:50:21.000Z",
          "wordCount": 150,
          "title": "Question about pseudocodes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u49zmq/industry_use_of_reinforcement_learning/",
          "author": null,
          "description": "I have been studying RL now for 18 months as a goal to get a job in it.\n Yet when I look at jobs, I see very seldom postings about it.\n I am wondering why is it the case ? From my current understanding I could think of dozens of applications with huge potential gains. It feel like an untapped potential.\n Or am I missing something ? What do you think is the big obstacle to wider adoption to RL ? Do you think it overlaps with classical control at the moment and is not justified ?\n    submitted by    /u/Ouassimf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u49zmq/industry_use_of_reinforcement_learning/",
          "publishedOn": "2022-04-15T15:00:56.000Z",
          "wordCount": 1056,
          "title": "Industry use of reinforcement learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u48tsz/comparing_default_vs_custom_reward_function_for/",
          "author": null,
          "description": "submitted by    /u/DIAMBRA_AIArena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u48tsz/comparing_default_vs_custom_reward_function_for/",
          "publishedOn": "2022-04-15T14:06:10.000Z",
          "wordCount": 452,
          "title": "Comparing Default VS Custom Reward Function for Optimal Health Management of a DeepRL Agent Playing Tekken",
          "imageUrl": "https://external-preview.redd.it/eLywtXzeC4PVSu-mzBX2IDefQWfWkxDGmJjWZjWahXA.png?format=pjpg&auto=webp&s=bfc61efa3503e22eae56ad57668c5afc38f1e86c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3pcrp/ppo_with_one_worker_always_picking_the_best_action/",
          "author": null,
          "description": "If I use PPO with distributed workers, and one of the workers always picks the best action, would that skew the PPO algorithm? It might perform a tad slower, but would it factually introduce wrong math? Perhaps because the PPO optimization requires that all actions are taking proportional to their probabilities? Or would it (mathematically) not matter?\n    submitted by    /u/tmuxed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3pcrp/ppo_with_one_worker_always_picking_the_best_action/",
          "publishedOn": "2022-04-14T19:31:16.000Z",
          "wordCount": 224,
          "title": "PPO with one worker always picking the best action?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3nhkz/feedback_collection_for_finrl_financial/",
          "author": null,
          "description": "Dear all,\n As a creator of the open-source FinRL project, I would like to welcome all kinds of feedback regarding financial reinforcement learning, especially about how to improve the open-source project FinRL.\n After several years of development and maintenance, we have passed the phase of caring about #stars, now we care more about #downloads, also Wall Street's adoption.\n Appreciate your feedback and sharing!\n Previously when we exposed our message on Reddit, the community was not very supportive about open-source projects' \"advertisements\". Maybe it consumed public attention and raised bad feelings. Therefore, this time we created a reddit sub-channel for FinRL-related discussions, available at: https://www.reddit.com/r/AI4Finance_FinRL/\n Best,\n Yang\n    submitted by    /u/Character-Meat-9176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3nhkz/feedback_collection_for_finrl_financial/",
          "publishedOn": "2022-04-14T18:04:11.000Z",
          "wordCount": 223,
          "title": "Feedback Collection for FinRL: Financial Reinforcement Learning",
          "imageUrl": "https://external-preview.redd.it/8-Jkr120jBwSEOjE3QprtB37msW5qLklONwZxIIXnb8.jpg?auto=webp&s=cd57c9967110f6a7206244afffb6b6e6f96e9fca"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3hk7l/is_a_steady_linear_increase_in_average_reward/",
          "author": null,
          "description": "submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3hk7l/is_a_steady_linear_increase_in_average_reward/",
          "publishedOn": "2022-04-14T13:28:24.000Z",
          "wordCount": 231,
          "title": "Is a steady linear increase in average reward during training too good to be true? Are there any common pitfalls?",
          "imageUrl": "https://preview.redd.it/9tk351ggxht81.png?auto=webp&s=03d2ce0fc7d8b624e3729f0eb52d21e9d4919640"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u3c5tr/determine_gridworld_values_with_no_probability/",
          "author": null,
          "description": "I am learning Reinforcement learning for games following Gridworld examples. Apologies in advance if this is a basic question, very new to reinforcement learning.\n I am slightly confused in scenarios where probability of moving up, down, left and right are not provided or stated. In this scenario, I assume we assume the optimal policy and therefore, you would apply the Bellman equation as:\n V(s)=maxa(R(s,a)+γV(s′))\n Cost for any movement is 0 and an agent can choose to terminate at a numbered grid to collect a reward amount of the grid number. This is why my square closest to the reward takes in the value 8 since it will terminate with the action to the next state to collect the reward.\n Would this be the correct way to determine the value for the surrounding grid squares?\n https://preview.redd.it/s9l0ok4kbgt81.png?width=806&format=png&auto=webp&s=dfb50450001541b0569d0361fd04a73daa29f222\n    submitted by    /u/Artezian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u3c5tr/determine_gridworld_values_with_no_probability/",
          "publishedOn": "2022-04-14T08:01:55.000Z",
          "wordCount": 487,
          "title": "Determine Gridworld values with no probability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2rkve/does_the_reward_in_reinforcement_learning_have_to/",
          "author": null,
          "description": "I'm trying to train a seq2seq model that generates a sentence with T words using reinforcement learning. The input and all the previously generated words form the state of the environment, and generating a word in the sentence is considered an action. In the previous methods [1, 2], the immediate reward r(s_t, a_t, s_{t+1}) for the t-th action a_t is 0 when t < T, and the reward is the CIDEr score (a scalar that measures the quality of the sentence) of the entire sentence when t = T. The policy is updated after the entire sentence is generated.\n I designed a new reward for each action, and the new reward for the t-th action is not zero when t < T. However, the reward of each action can only be calculated when the entire sentence is generated since it relies on the CIDEr score of the entire sentence, i.e. the reward for all the actions relies on the final state s_T. Can I still define the reward in the form of r(s_t, a_t, s_{t+1}) ?\n [1] Rennie et al. Self-critical sequence training for image captioning, CVPR 2017: 7008-7024.\n [2] Ranzato et al. Sequence level training with recurrent neural networks, ICLR 2016.\n    submitted by    /u/entalent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2rkve/does_the_reward_in_reinforcement_learning_have_to/",
          "publishedOn": "2022-04-13T14:28:00.000Z",
          "wordCount": 390,
          "title": "Does the reward in reinforcement learning have to be immediate reward?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2q8ih/question_about_math/",
          "author": null,
          "description": "I am reading that paper A Distributional Perspective on Reinforcement Learning, and it is related to measure theory. Is it worth to spend time to study whole real analysis and measure theory?\n    submitted by    /u/Professional_Card176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2q8ih/question_about_math/",
          "publishedOn": "2022-04-13T13:23:24.000Z",
          "wordCount": 204,
          "title": "Question about math",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2o03v/what_does_an_oscillating_explained_variance/",
          "author": null,
          "description": "submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2o03v/what_does_an_oscillating_explained_variance/",
          "publishedOn": "2022-04-13T11:19:11.000Z",
          "wordCount": 207,
          "title": "What does an oscillating explained_variance signify during training? (PPO)",
          "imageUrl": "https://preview.redd.it/dj0psf0t5at81.png?auto=webp&s=aefa56dc877f60c03e5431692faa4d0d6a41cdf4"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2jq4n/sb3_herdqn_for_my_simple_discrete_map_env_but_the/",
          "author": null,
          "description": "Hi all, I am creating a multiple-goal environment. Which is an 8*8 discrete map with a start and terminal state (only one) change after each episode. The reward is 100 for reaching the terminal state and -1 for the rest. In fact, I am not sure if the reward is reasonable. \n I used PPO from SB3 and I can easily finish it. But when I go offline, using HER+DQN, the training is very bad. \n Feel free to run it here or take a look at the env and training result. Thank you so much!\n https://colab.research.google.com/drive/1Mt5Yje7GTyjOBHL09zC9C1L05xpTAK9v?usp=sharing\n    submitted by    /u/AnimatorRemarkable20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2jq4n/sb3_herdqn_for_my_simple_discrete_map_env_but_the/",
          "publishedOn": "2022-04-13T06:12:00.000Z",
          "wordCount": 239,
          "title": "SB3- HER+DQN for my simple discrete map env but the training result is pretty bad",
          "imageUrl": "https://external-preview.redd.it/MrcDZx2izDY9ERwgWmMS-Hm2M3GEKZgeYLDszSh-KrQ.jpg?auto=webp&s=73eb91ea5a5347f216c0f0c4d6796396826aae49"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2iy5i/what_would_happen_if_you_connect_inputs_and/",
          "author": null,
          "description": "submitted by    /u/The_impact_theory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2iy5i/what_would_happen_if_you_connect_inputs_and/",
          "publishedOn": "2022-04-13T05:21:16.000Z",
          "wordCount": 666,
          "title": "What would happen if you connect inputs and outputs randomly to a large hebbian Spiking NN and let it learn shape itself in an environment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2h8it/number_of_feature_vs_action_space_in_multiagent/",
          "author": null,
          "description": "Hi All,\n I am working on a MARL fintech project where I use DDQN and for Q-value, I use LSTM bacause it is time series data. This is a project overview. It has 7 features which is derivatives of ask and bid price and has 12 action spaces for action taking.\n Is it possible to generate a good reliable model using only 7 features for 12 action spaces?\n Number of feature or quality of feature is important for taking good decision in RL. \n Open for Suggestion\n #Reinforcement_Learning #MARL\n    submitted by    /u/laxuu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2h8it/number_of_feature_vs_action_space_in_multiagent/",
          "publishedOn": "2022-04-13T03:41:14.000Z",
          "wordCount": 215,
          "title": "Number of Feature VS Action Space in Multi-agent Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u2gcn4/is_there_anyone_interested_in_reimplementing_apt/",
          "author": null,
          "description": "Hi, these day I really interested in self-supervised RL. Especially only based on state novelty. So I wanted to re-implement APT(Behavior From the Void: Unsupervised Active Pre-Training). but my re-implementation showed not meaningful behaviors compared to official implementation. official implementation uses drq-v2 and intrinsic curiosity module. So, I want to re-implement APT as described in paper(using drq-v1 and contrastive learning).\n Is there someone to check my reimplementation?\n https://github.com/seolhokim/apt\n In that repository, DrQ-v1 works well, but only apt doesn't work! I can't understand why agent stop moving when pre-training.\n ​\n Really thank you for reading.\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u2gcn4/is_there_anyone_interested_in_reimplementing_apt/",
          "publishedOn": "2022-04-13T02:52:42.000Z",
          "wordCount": 212,
          "title": "Is there anyone interested in re-implementing APT?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1xeea/best_gridworld_environment/",
          "author": null,
          "description": "In your opinion, what is the best gridworld environment? I want to compare different RL algorithms on it. \n I’m looking for something super basic: - start and goal state - some obstacles - customisable: move the start and goal state, place obstacles in different points, modify reward map etc. - computationally efficient\n Thank you\n    submitted by    /u/wiston_smith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1xeea/best_gridworld_environment/",
          "publishedOn": "2022-04-12T12:00:47.000Z",
          "wordCount": 299,
          "title": "Best GridWorld environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1wvf6/custom_callback_for_max_episode_reward_using/",
          "author": null,
          "description": "Hi all,\n I've built a custom gym env and am using Stable Baselines3 to train an agent. I would like to visualise in TensorBoard the maximum reward achieved for each episode. I have these values in a list in my env, and I am trying to create a custom Callback to plot this in TensorBoard but it's not working. I've looked over the documentation and other forums but can't figure out how to do this. Can anyone help me out? 🙏🏽 Thank you!\n    submitted by    /u/leozinho2r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1wvf6/custom_callback_for_max_episode_reward_using/",
          "publishedOn": "2022-04-12T11:30:48.000Z",
          "wordCount": 220,
          "title": "Custom Callback for Max Episode Reward using Stable Baselines3 with Custom Env",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1tog0/opensourced_nethack_2021_neurips_challenge/",
          "author": null,
          "description": "Recently, we have released the source code of our winning solution for the NetHack 2021 NeurIPS Challenge:\n https://github.com/maciej-sypetkowski/autoascend\n We hope that it will help in leveraging this complex environment, that still seems to be beyond capabilities of reinforcement learning. Check out links in the README \"Description\" section for more context.\n    submitted by    /u/procedural_only  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1tog0/opensourced_nethack_2021_neurips_challenge/",
          "publishedOn": "2022-04-12T07:54:45.000Z",
          "wordCount": 173,
          "title": "Open-sourced NetHack 2021 NeurIPS Challenge winning agent",
          "imageUrl": "https://external-preview.redd.it/Nqt-aA20mIGhIBUB0OpRBitbgSezPyJfZk3b-7nT6Ao.jpg?auto=webp&s=f5ef4c8831e121cfeb748e8328c82e52fe20d5ae"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1sqa2/project/",
          "author": null,
          "description": "Do any of u have any good rl project suggestion or a complete project for college major , I have only done work on some self playing Atari , mario games , if u have any good idea please suggest 🙌\n    submitted by    /u/stoned_egineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1sqa2/project/",
          "publishedOn": "2022-04-12T06:46:59.000Z",
          "wordCount": 163,
          "title": "Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1q15v/training_a_dqn_agent_for_platformer_game/",
          "author": null,
          "description": "Does anyone have experience training agents to play platformer games like mario? I am trying to train an agent for the platformer game Jump King to get past atleast a few levels, using DQN but the agent is performing poorly after 8000 episodes of training, (one episode being the agent spawns at the start and has 15 seconds or so to jump around gaining reward) he is barely able to get past the first level most of the time :c\n I am using a very basic sequential network of 2 Linear layers with inputDim 4, outputDim 4, and hiddenDim 32. and because my state is not using any image data, its just (current_level, x_pos, y_pos, jumpCount) as input to the network . As for the reward, I am using the y position to give reward if the agent is getting to a new level (large reward) or making progress in the current level (curr_y > old_y), otherwise the agent gets a negative reward.\n Should I consider using a CNN and image data to train this agent like in the atari games paper, or is using image data and a conv net going to perform worse rather than using my current state? Should I consider combining image data with the current state, or just keeping the current non-image data state but ?\n Also, roughly how long should I be training the agent for? is 8000 episodes not enough? 1 episode takes roughly 7 seconds in time (it is using pygame engine and I turned off the rendering and I think that made it a little bit faster)\n This is my first time training an agent for a hard game like this using DQN so I would appreciate any tips/advice to improve the agent! repo: https://github.com/senweim/JumpKingAtHome\n    submitted by    /u/TernaryJimbo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1q15v/training_a_dqn_agent_for_platformer_game/",
          "publishedOn": "2022-04-12T03:53:17.000Z",
          "wordCount": 583,
          "title": "Training a DQN agent for platformer game",
          "imageUrl": "https://external-preview.redd.it/_q5O0vyejO1QNlhnm3FzQByLjqArX9Azj4C2W37UJJo.jpg?auto=webp&s=95a72d122f292458457a5ac3f48fa1d7279626af"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1lqa1/which_environment_impress_you_related_with/",
          "author": null,
          "description": "I want to hear about your impressive environment! Specifically, I want to make my custom environment well using various library like openAI gym.\n In this contxet, I find out the highway-env https://github.com/eleurent/highway-env/ !\n I think this environment has convinient API for users.\n Thus, I make my custom env with referencing the highway-env\n https://preview.redd.it/ndl1h1dvpzs81.png?width=711&format=png&auto=webp&s=267320a9713d98e7e49c4bb89423e5a9612bad8e\n In this line, could you speak your best environment? It doesn't matter about your best env has any advantage!\n    submitted by    /u/Seungeon94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1lqa1/which_environment_impress_you_related_with/",
          "publishedOn": "2022-04-12T00:14:26.000Z",
          "wordCount": 199,
          "title": "Which environment impress you? (related with software architecture, API, ...)",
          "imageUrl": "https://external-preview.redd.it/3-M03DqnQMFxCl6FegDvqeHni6hub500G5v6XhJffBg.jpg?auto=webp&s=9247a1725e4ebbbcdd2ee361f15ef2776cdf7af3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1kiox/strategies_to_deal_with_large_action_spaces/",
          "author": null,
          "description": "Hey guys,\n I tried building a PPO model for Wordle.\n My initial test was checking the performance of the model with just 100 words. The agent was able to learn within a few thousand epochs and had an average guess length of about 2.8 before it could correctly identify the words.\n However, when i extend the action space to the entire 2.3k words, the model barely learns. Even after a few 100k iterations, the mean length revolves around 5.9 (given wordle has a max of 6 attempts per game)\n Any suggestions on how to help the agent learn faster in large action spaces?\n ​\n I also tried an embedding based approach, but the performance was very similar.\n ​\n Thanks\n    submitted by    /u/altair9335  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1kiox/strategies_to_deal_with_large_action_spaces/",
          "publishedOn": "2022-04-11T23:15:04.000Z",
          "wordCount": 303,
          "title": "Strategies to deal with Large Action Spaces",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1eu6n/what_are_your_best_results_for_procgen_coinrun/",
          "author": null,
          "description": "Has anyone managed to get a consistent score of > 9 on CoinRun? I understand that some generated levels require LSTMs in order to be solvable 100% of the time, but even excluding these hard-core levels I can see some occasions where my agents are not operating with 100% effectiveness. For some reason \"fully solving\" CoinRun seems harder than expected.\n The papers on CoinRun usually just show the results after 100mm steps or so, but I am more interested in what the community has achieved with \"normal setups\".\n    submitted by    /u/tmuxed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1eu6n/what_are_your_best_results_for_procgen_coinrun/",
          "publishedOn": "2022-04-11T19:06:45.000Z",
          "wordCount": 213,
          "title": "What are your best results for ProcGen: CoinRun?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1dnth/how_to_use_the_same_action_in_trained_rl_network/",
          "author": null,
          "description": "I trained RL agent using stable baseline library and gym env. When I am trying to test agent, this makes different action when I am re running again. I used the same seed in test env.\n for i in range(length-lags-1): action, _states = model.predict(obs_test) obs_test, rewards, dones, info = env_test\n When I am runnig again the above code, I am getting the different results.\n    submitted by    /u/Mariam_Dundua  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1dnth/how_to_use_the_same_action_in_trained_rl_network/",
          "publishedOn": "2022-04-11T17:57:53.000Z",
          "wordCount": 277,
          "title": "How to use the same action in trained RL network, when model is retested?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u1bb4t/unity_rl_ml_agents_module_walker_example/",
          "author": null,
          "description": "Hi all, \n I'm trying to teach my custom fbx model to walk with the help of ppo, as in the example from ml agents. I have difficulties with the exact import and the assignment of rigidbody here, that is, the neural network is being trained, but for some reason physics does not work. Has anyone seen it, or does anyone have an example of how to train a unity custom fbx model using ml agents?\n Thx all!\n    submitted by    /u/IndependenceCivil576  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u1bb4t/unity_rl_ml_agents_module_walker_example/",
          "publishedOn": "2022-04-11T16:13:23.000Z",
          "wordCount": 198,
          "title": "Unity RL ml agents module, walker example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u14990/implementing_rl_algorithm_on_apache_spark/",
          "author": null,
          "description": "I want to run RL algorithm on Apache Spark. However, RL does not exists in Spark's MLib. Is it possible to implement it? any links may help. Thank you in advance\n    submitted by    /u/fatenLouati  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u14990/implementing_rl_algorithm_on_apache_spark/",
          "publishedOn": "2022-04-11T10:06:25.000Z",
          "wordCount": 198,
          "title": "Implementing RL algorithm on apache spark",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0y1iv/is_reinforcement_learning_being_used_for_the/",
          "author": null,
          "description": "We will introduce the general process of self-driving tasks first and then the development of Reinforcement Learning in self-driving cars. \n The general process of self-driving tasks includes perceiving, decision-making, planning and controlling. The tasks of perceiving have adopted deep learning and that did a good job. Being different from monitoring learning, decision intelligence AI methods, which are represented by reinforcement learning, model the environment as Markov Decision Process(MDP)to get optimization. In sequential decision problems the utility of agent's actions do not depend on single decisions, expressed with the state, which the agent would have gotten into, as the result of this decision, but rather on the whole sequence of agent's action. \n Here, one thing that needs t…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0y1iv/is_reinforcement_learning_being_used_for_the/",
          "publishedOn": "2022-04-11T03:10:19.000Z",
          "wordCount": 1182,
          "title": "Is reinforcement learning being used for the development of self-driving cars",
          "imageUrl": "https://external-preview.redd.it/mSgqsMn_oZHx1PllOQIWdMTwhDv7hynBEIa68WGyvQM.jpg?auto=webp&s=920cb071bff3b857cb2c176493fbd98c116be106"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0o1kx/anybody_ever_programmed_a_1st_order_differential/",
          "author": null,
          "description": "submitted by    /u/SmarterCloud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0o1kx/anybody_ever_programmed_a_1st_order_differential/",
          "publishedOn": "2022-04-10T18:44:01.000Z",
          "wordCount": 188,
          "title": "Anybody ever programmed a 1st order differential equation model in MuJoCo?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0n5hv/google_ai_researchers_propose_a_metaalgorithm/",
          "author": null,
          "description": "In the field of artificial intelligence, reinforcement learning is a type of machine-learning strategy that rewards desirable behaviors while penalizing those which aren’t. An agent can perceive its surroundings and act accordingly through trial and error in general with this form or presence – it’s kind of like getting feedback on what works for you. However, learning rules from scratch in contexts with complex exploration problems is a big challenge in RL. Because the agent does not receive any intermediate incentives, it cannot determine how close it is to complete the goal. As a result, exploring the space at random becomes necessary until the door opens. Given the length of the task and the level of precision required, this is highly unlikely.\n Exploring the state space randomly with preliminary information should be avoided while performing this activity. This prior knowledge aids the agent in determining which states of the environment are desirable and should be investigated further. Offline data collected by human demonstrations, programmed policies, or other RL agents could be used to train a policy and then initiate a new RL policy. This would include copying the pre-trained policy’s neural network to the new RL policy in the scenario where we utilize neural networks to describe the procedures. This process transforms the new RL policy into a pre-trained one. However, as seen below, naively initializing a new RL policy like this frequently fails, especially for value-based RL approaches.\n Continue reading the summary\n Paper: https://arxiv.org/pdf/2204.02372.pdf\n Project: https://jumpstart-rl.github.io/\n https://reddit.com/link/u0n5hv/video/fnktgf0wqqs81/player\n    submitted by    /u/No_Coffee_4638  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0n5hv/google_ai_researchers_propose_a_metaalgorithm/",
          "publishedOn": "2022-04-10T18:02:33.000Z",
          "wordCount": 484,
          "title": "Google AI Researchers Propose a Meta-Algorithm, Jump Start Reinforcement Learning, That Uses Prior Policies to Create a Learning Curriculum That Improves Performance",
          "imageUrl": "https://external-preview.redd.it/IUWWG2pHwr6M_wwbFIU4qpxTYNG55LMW8iuMjT-N6W8.jpg?auto=webp&s=0333c60118f14326da9c1ad378b561f37a2a453c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0jtbs/socratic_models_composing_zeroshot_multimodal/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0jtbs/socratic_models_composing_zeroshot_multimodal/",
          "publishedOn": "2022-04-10T15:22:26.000Z",
          "wordCount": 174,
          "title": "\"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language\", Zeng et al 2022",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u0b8nw/classical_dynamic_programming_ve_policy_iteration/",
          "author": null,
          "description": "Cracking my head trying to figure out the differences between classical dynamic programming and policy iteration. I understand that policy iteration in itself is a form of dynamic programming. But if we were to compare the traditional operations of dynamic programming with policy iteration, what would be the differences.\n Thank you Heaps\n    submitted by    /u/BalramVeeragoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u0b8nw/classical_dynamic_programming_ve_policy_iteration/",
          "publishedOn": "2022-04-10T05:50:26.000Z",
          "wordCount": 240,
          "title": "Classical Dynamic Programming ve Policy Iteration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u09lgv/is_my_understanding_to_why_future_rewards_being/",
          "author": null,
          "description": "To my understanding, the Q value is updated like this:\n Q[s,a] = Q[s,a] + lr * (reward + gamma * max(Q[s,a]t+1) — Q[s,a]) \n Where future state reward is considered since the best current reward doesn't grantee the optimal path. E.g.: \n  \nPath A: Q[s,a]t = 1, Q[s,a]t+1 = 10 Total: 11\n Path B: Q[s,a]t = 5, Q[s,a]t+1 = 1 Total: 6\n  \nNot sure if this is a good analogy but here it gives the result that A is the optimal path even though its immediate reward at (t) is less than B.\n Further Question:\n Is there additional benefits to considering future rewards further than Q[s,a]t+1 ?\n Example: \n Q[s,a] = Q[s,a] + lr * (reward + gamma* max(Q[s,a]t+2) - gamma * max(Q[s,a]t+1) — Q[s,a]) \n    submitted by    /u/DangerNoodle314  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u09lgv/is_my_understanding_to_why_future_rewards_being/",
          "publishedOn": "2022-04-10T03:59:28.000Z",
          "wordCount": 337,
          "title": "Is my understanding to why future rewards being considered correct?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u07y3v/any_reason_why_to_use_several_optimizers_in/",
          "author": null,
          "description": "Hi guys. I am currently implementing REDQ by modifying a working implementation of SAC (basically adapted from Spinup) and so far my implementation doesn't work, I am trying to understand why. By looking at the authors' implementation I notice they use 1 pytorch optimizer per Q network, whereas I only use 1 for all parameters. So I wonder, is there any good reason for using several optimizers here?\n Thanks!\n    submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u07y3v/any_reason_why_to_use_several_optimizers_in/",
          "publishedOn": "2022-04-10T02:17:13.000Z",
          "wordCount": 344,
          "title": "Any reason why to use several optimizers in Pytorch implementation of REDQ?",
          "imageUrl": "https://external-preview.redd.it/WNSAA7ek709uuK0adnoPJTjafbMb5oTbtvgxMWHAGjM.jpg?auto=webp&s=ca5e2533e4c6cb29f06a857f944fcbc7f5f8c796"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u07740/learning_in_noisy_observation_space/",
          "author": null,
          "description": "I am fairly new to RL. I'm trying to train an agent (like in gym's Cartpole env) in an environment with noisy (Gaussian noise) observation. I have added Gaussian noise to angle only (not to cart position, cart velocity or ang_velocity). I was fooling around with PPO in stable_baselines but haven't had much luck. Any suggestions on what needs to be tweaked or any good algorithm for this task? \n Also, I tried changing the default forcing magnitude of 10 to other values like 30 but it didn't help much.\n Thanks\n    submitted by    /u/Black_Beard53  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u07740/learning_in_noisy_observation_space/",
          "publishedOn": "2022-04-10T01:33:08.000Z",
          "wordCount": 561,
          "title": "Learning in Noisy Observation space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u049oz/gizmo_is_eating_a_clothes_basket/",
          "author": null,
          "description": "submitted by    /u/mspurplekris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u049oz/gizmo_is_eating_a_clothes_basket/",
          "publishedOn": "2022-04-09T22:46:30.000Z",
          "wordCount": 95,
          "title": "Gizmo is eating a clothes basket",
          "imageUrl": "https://external-preview.redd.it/C8ARUSGC5ZEyVpjpSpYsycIEJfjoC579hwDthyzwJak.png?blur=40&format=pjpg&auto=webp&s=f3be29fb88d38efbe7d113cc1f952a0589c1e209"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u03y3i/habitatweb_learning_embodied_objectsearch/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u03y3i/habitatweb_learning_embodied_objectsearch/",
          "publishedOn": "2022-04-09T22:29:30.000Z",
          "wordCount": 217,
          "title": "\"Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale\", Ramrakhya et al 2022 {FB} (log-scaling of crowdsourced imitation learning in VR robotics)",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u02tyk/is_it_possible_to_implement_acer_with_a2c/",
          "author": null,
          "description": "I'm looking into implementing a replay buffer in A2C. I came upon the ACER [paper](https://arxiv.org/pdf/1611.01224.pdf). From my understanding, it looks like ACER is an extension of A3C, and it seems like the difference between A2C and A3C is that in A2C parameters are updated synchronously and that helps with big batch sizes. \n Is it still possible to implement some kind of replay buffer on A2C?\n Are there any papers that involve implementing a paper with A2C that you recommend I read?\n I'm new to the area of reinforcement learning, so I would be very grateful for any kind of help you can offer. Thanks in advance\n    submitted by    /u/lebr0n99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u02tyk/is_it_possible_to_implement_acer_with_a2c/",
          "publishedOn": "2022-04-09T21:32:29.000Z",
          "wordCount": 245,
          "title": "Is it possible to implement ACER with A2C?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/u00ann/does_anyone_have_a_link_to_the_rl_discord_server/",
          "author": null,
          "description": "Supposedly there is a popular discord server for the RL community, however I am having difficulty finding it.\n    submitted by    /u/jclaessens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/u00ann/does_anyone_have_a_link_to_the_rl_discord_server/",
          "publishedOn": "2022-04-09T19:23:29.000Z",
          "wordCount": 147,
          "title": "Does anyone have a link to 'The RL Discord Server'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzvnhc/imitating_fast_and_slow_robust_learning_from/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzvnhc/imitating_fast_and_slow_robust_learning_from/",
          "publishedOn": "2022-04-09T15:34:42.000Z",
          "wordCount": 156,
          "title": "\"Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning\", Qi et al 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tztri9/reinforcement_learning_looking_for_some_resources/",
          "author": null,
          "description": "Hello friends,\n I'm looking for some resources that would let me quickly start with Reinforcement Learning (preferably in Python). I have some experience with supervised learning (e.g. deep nets) and would like to complement with some RL. Preferably a walkthrough with some examples of implementation. Can you recommend something?\n Thanks in advance!\n    submitted by    /u/andy-codes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tztri9/reinforcement_learning_looking_for_some_resources/",
          "publishedOn": "2022-04-09T13:59:47.000Z",
          "wordCount": 273,
          "title": "Reinforcement Learning - looking for some resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzt78z/im_dumb_at_maths_what_does_this_mean/",
          "author": null,
          "description": "So learning about e-mail learning same have it all understood except for the max thingy. If you care enough to click this blog it's not my blog):\n https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56\n I don't know how to turn this into to a real example:\n Update q values\n Q[state, action] = Q[state, action] + lr * (reward + gamma * np.max(Q[new_state, :]) — Q[state, action])\n Specifically the last bit: \n np.max(Q[new_state, :]) — Q[state, action])\n What does the numpy max actually operate on here?\n Any hard examples? Thanks.\n    submitted by    /u/Togfox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzt78z/im_dumb_at_maths_what_does_this_mean/",
          "publishedOn": "2022-04-09T13:28:32.000Z",
          "wordCount": 566,
          "title": "I'm dumb at maths: what does this mean?",
          "imageUrl": "https://external-preview.redd.it/soqDPbsOXDAx8rb1fY_2BPuguBAOAi7BxwtrOHfJeW0.jpg?auto=webp&s=f7d397129c0a0c3d32549fc5ec56ec6470340e9f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzekkb/rl_for_dynamic_environments/",
          "author": null,
          "description": "In their 2019 review article in Nature Machine Intelligence, Neftci and Averbeck point out, “Most work in biological systems has focused on simple learning problems… where flexibility and ongoing learning are important, similar to real-world learning problems. In contrast, most work in artificial agents has focused on learning a single complex problem in a static environment.”\n Are there RL approaches designed to handle dynamic environments with changing reward functions?\n I did find this earlier post, but thought I'd ask if anyone had other suggested lines of reading.\n Thanks!\n    submitted by    /u/Careless-Argument-37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzekkb/rl_for_dynamic_environments/",
          "publishedOn": "2022-04-08T22:04:50.000Z",
          "wordCount": 244,
          "title": "RL for dynamic environments",
          "imageUrl": "https://external-preview.redd.it/JQx2wIoJt26buLNeTwF2B2kRUu7jfG6Pti_qzRMR2bA.jpg?auto=webp&s=3ace57f9a34e9fe66349fc640a95decc42fcf934"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tzee5s/observationspace_max_size/",
          "author": null,
          "description": "I want to give my AI as many information as possible. Can there be an Issue with a too large observation space?\n    submitted by    /u/Willing-Classroom735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tzee5s/observationspace_max_size/",
          "publishedOn": "2022-04-08T21:56:32.000Z",
          "wordCount": 237,
          "title": "Observationspace max Size?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tz4u57/uc_berkeleys_pieter_abbeel_receives_2021_acm/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tz4u57/uc_berkeleys_pieter_abbeel_receives_2021_acm/",
          "publishedOn": "2022-04-08T14:30:24.000Z",
          "wordCount": 149,
          "title": "\"UC Berkeley’s Pieter Abbeel receives 2021 ACM Prize in Computing\" (for DRL robotics)",
          "imageUrl": "https://external-preview.redd.it/FzJ8NRe2mu_Hd_oJNkTrpZw1A6d1wJnhzgz-JqSkmjk.jpg?auto=webp&s=8c1b8d2a0856815293f22351ef8d0b6d3dca408b"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyxrzi/action_space_dimensional_reduction_for_better/",
          "author": null,
          "description": "I am working on a project in which a robots learns its motion. for example Bipedal robot learns to walk on a straight line by learning to adjust the torque and angular velocity of each joint. However, the robot I am working on has complex architecture. It has 10 joints instead of 2, most importantly all of these joints work simultaneously and coherently to produce a desired motion.\n The Problem I am facing is that, the robot has ten joints and each joint can move between -450 to +450\n for simplicity let me define State and Actions of the system\n State = -450 to +450 -------------> normalization ------------------> -10 to 10\n Actions = choose an angle between -10 to 10 for each joint \n Total Action space for each State at each time step = 10 (no of joints each can move between -10 to 10 at each time step) * 360 (total time steps for a single motion) = 3600 (Output: No of angles required to generate a motion)\n I am using TD3 to solve this conundrum. The Action space is too large how can I reduce the action space?\n    submitted by    /u/SAM_Baloch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyxrzi/action_space_dimensional_reduction_for_better/",
          "publishedOn": "2022-04-08T07:08:41.000Z",
          "wordCount": 491,
          "title": "Action Space Dimensional reduction for better convergence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tytrpx/dynamic_action_space_in_rl/",
          "author": null,
          "description": "I am doing a project and there is a problem with dynamic action space\n A complete action space can be divided into four parts. In each state, the action to be selected is one of them\n For example, the total discrete action space length is 1000, which can be divided into four parts, [0:300], [301:500],[501:900],[901:1000]\n For state 1, action_ space is [0:300], State2, action_ space is [301:500], etc\n For this idea, I have several ideas at present:\n  \nThere is no restriction at all. The legal actions of all States are [1:1000], but it may take longer train time and there is not much innovation\n Soft constraint, for example, if state1 selects an illegal action, such as one action in [251: 500], reward gives a negative value, but it is also not innovative\n Hard constraint, use action space mask in each state, but I don't know how to do it.. Is there any relevant article？\n It is directly divided into four action spaces and uses multi-agent cooperative relationship learning\n  \n​\n Any suggestions？\n thanks！\n    submitted by    /u/RangerWYR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tytrpx/dynamic_action_space_in_rl/",
          "publishedOn": "2022-04-08T02:58:27.000Z",
          "wordCount": 725,
          "title": "Dynamic action space in RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyqv88/any_paper_suggestions/",
          "author": null,
          "description": "Hi everyone, i have to define a project for my master degree, so i'm looking for the best papers published since 2018-2019 until now in Reinforcement Learning . Do you have any suggestions, titles or projects that i can check?\n    submitted by    /u/acaviedes15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyqv88/any_paper_suggestions/",
          "publishedOn": "2022-04-08T00:22:24.000Z",
          "wordCount": 151,
          "title": "Any paper suggestions??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tyog3i/implementation_of_rl/",
          "author": null,
          "description": "Hi all! I am a beginner in RL field and am trying to implement the RL algorithm in the following paper :\n [1912.04321] Learning to Code: Coded Caching via Deep Reinforcement Learning (arxiv.org)\n In short, we are trying to achieve the minimum number of transmission of bits from the server to all users\n Now, after 500 episodes of training the number of transmissions does decrease. But when I implement the same actor critic algorithm this does not happen. In fact, the results seem to be completely random. \n Here is the plot of the same :\n https://preview.redd.it/yve3cay7l6s81.png?width=745&format=png&auto=webp&s=36bf4f0aa813a30024128d797acde3b8adc2df30\n Although my training parameters are slightly different, I can't understand why this would happen.\n I used the parameters and pseudo code from this paper: A Deep Reinforcement Learning Approach for Shared Caching | IEEE Conference Publication | IEEE Xplore - which is an extension of the link at the top.\n ​\n Attaching link to my code: https://www.kaggle.com/samarthtiwari123/rl-for-coded-caching\n Any help would be helpful!!\n Thanks in advance\n    submitted by    /u/samt_123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tyog3i/implementation_of_rl/",
          "publishedOn": "2022-04-07T22:21:20.000Z",
          "wordCount": 261,
          "title": "Implementation of RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tynq4i/how_can_i_extract_the_direction_a_specific_agent/",
          "author": null,
          "description": "submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tynq4i/how_can_i_extract_the_direction_a_specific_agent/",
          "publishedOn": "2022-04-07T21:47:08.000Z",
          "wordCount": 188,
          "title": "How can I extract the direction a specific agent is facing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tylf8u/flow_of_gradients_through_multiple_classes/",
          "author": null,
          "description": "Naive question: if I define my RL model as a combination of different classes (one class that preprocesses the observation, one class that processes the observation, one class that outputs the actions, etc.), is this going to affect the flow of gradients in PyTorch? The alternative would be to create only one class in which I combine everything\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tylf8u/flow_of_gradients_through_multiple_classes/",
          "publishedOn": "2022-04-07T20:01:03.000Z",
          "wordCount": 254,
          "title": "Flow of gradients through multiple classes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tycj9d/can_kl_divergence_be_used_as_a_metric_to_see_the/",
          "author": null,
          "description": "In the hyper parameter section of the paper, it is written that step size of Adam is varied according to KL divergence. So I wanted to know is KL divergence the correct metric to be used for observing the learning progress because we have many states for which probabilites of a particular action is either increased or decreased thus taking average KL mixes up a lot of things.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tycj9d/can_kl_divergence_be_used_as_a_metric_to_see_the/",
          "publishedOn": "2022-04-07T12:59:23.000Z",
          "wordCount": 366,
          "title": "Can KL divergence be used as a metric to see the learning progress in PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ty2dt2/weight_decay_in_policy_network_for_discrete_sac/",
          "author": null,
          "description": "We’re finding that our network is returning a tensor of NaNs towards the end of training. Adding weight decay solves this issue but reduces learning, was wondering if anyone else had experience with vanishing gradients in off-policy methods or any insight?\n    submitted by    /u/TerrificJam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ty2dt2/weight_decay_in_policy_network_for_discrete_sac/",
          "publishedOn": "2022-04-07T02:09:30.000Z",
          "wordCount": 167,
          "title": "Weight decay in policy network for Discrete SAC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txyv62/question_about_model_predictive_control_mpc_cost/",
          "author": null,
          "description": "To my understanding, the cost function is the error between predicted state value and real state value.\n So if I use a neural network as my dynamics model(unknown true dynamics), the MPC cost function is equivalent to NN’s loss function?\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txyv62/question_about_model_predictive_control_mpc_cost/",
          "publishedOn": "2022-04-06T23:07:19.000Z",
          "wordCount": 299,
          "title": "Question about Model Predictive Control (MPC) cost function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txxore/learning_to_play_settlers_of_catan_with_deep_rl/",
          "author": null,
          "description": "submitted by    /u/henrythepaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txxore/learning_to_play_settlers_of_catan_with_deep_rl/",
          "publishedOn": "2022-04-06T22:10:27.000Z",
          "wordCount": 318,
          "title": "Learning To Play \"Settlers of Catan\" With Deep RL - code and write-up",
          "imageUrl": "https://external-preview.redd.it/MCy14opBjTIKzwl5JN-l_h8ogp8jGD7JGmk-A4mmZJI.jpg?auto=webp&s=b34f246a1d389b97fb2013f3661ccf8afbf4403e"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txvc52/which_environments_do_you_use_for_benchmarking/",
          "author": null,
          "description": "Hey guys I'm curious which environments you use to benchmark your standard RL algorithms.\n I typically use some environments from the OpenAI Gym or the DM control suite but benchmarking all my implementations against all environments for multiple seeds would take forever. Are there some of their environments you particularly like for benchmarking?\n    submitted by    /u/NiconiusX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txvc52/which_environments_do_you_use_for_benchmarking/",
          "publishedOn": "2022-04-06T20:24:16.000Z",
          "wordCount": 175,
          "title": "Which environments do you use for benchmarking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txtzv6/how_does_advantage_estimation_is_done_when/",
          "author": null,
          "description": "In the PPO paper it is stated that we have to collect trajectories of length T from N different workers. Suppose I am not using multiple workers then I have to collect episodes N times of fixed length T. But these episode lengths are variable i.e. some episodes end much before T and some much after T. So my question is how do we calculated advantage because according to the PPO paper, for generalized advantage estimate, we have to observe the reward of terminal state. \n ​\n So how should I calculate GAE in this ?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txtzv6/how_does_advantage_estimation_is_done_when/",
          "publishedOn": "2022-04-06T19:24:05.000Z",
          "wordCount": 254,
          "title": "How does advantage estimation is done when episodes are of variable length in PPO?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txs2jh/a_silly_question_from_a_new_beginner/",
          "author": null,
          "description": "I could not find an answer to a question hanging around in my head for a while. Suppose we have some data, if we build up an MDP to capture actions + state dynamics. Would the optimal policy win state-of-art RL algorithms?\n Edit: If that is the case, why would the community bothers with learning algorithm since finding the model of dynamics is the key?\n ​\n    submitted by    /u/musicinthedark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txs2jh/a_silly_question_from_a_new_beginner/",
          "publishedOn": "2022-04-06T17:56:48.000Z",
          "wordCount": 559,
          "title": "A silly question from a new beginner",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txhq5z/what_does_it_look_like_the_output_of_a/",
          "author": null,
          "description": "Hello,\n I am relatively new in the area of machine learning/reinforcement learning. I have this basic question regarding practical implementations. I just want to know, what does it look like the output of a reinforcement learning agent/algorithm in practice? Is it like a 'look-up table' that will set the weights/parameters of the ML model based on the input data? \n Note that I am asking after the offline training of the agent. How to implement the trained agent in practice, like in an embedded system? Do you guys have references or clues to help me to clarify?\n BR\n    submitted by    /u/b0bzera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txhq5z/what_does_it_look_like_the_output_of_a/",
          "publishedOn": "2022-04-06T08:55:08.000Z",
          "wordCount": 352,
          "title": "What does it look like the output of a reinforcement learning agent/algorithm in practice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txhgbe/multidiscrete_action_space_in_sacsoft_actorcritic/",
          "author": null,
          "description": "Hello!\n I am using SAC(Soft Actor-Critic) to complete a reinforcement learning task with only four steps, each action is from one of four different action spaces. These four action spaces are essentially the same, and they are all chemical compound. I just want the agent to take different types of compounds at each step.\n I have the following questions：\n  \nWhether the different four steps can be trained? In fact, there is a paper that only has four steps in a reinforcement learning process, but his action space only has one discrete action space.\n Is there any article I can learn from? because I know that for the handle control of the game, there are usually multiple discrete action spaces, but each discrete space dimension of my task is larger, such as [800, 700, 500, 600]\n  \nThanks！\n    submitted by    /u/RangerWYR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txhgbe/multidiscrete_action_space_in_sacsoft_actorcritic/",
          "publishedOn": "2022-04-06T08:33:16.000Z",
          "wordCount": 314,
          "title": "multi-discrete action space in SAC(Soft Actor-Critic)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txfewf/is_multi_bandit_on_policy_or_off_policy/",
          "author": null,
          "description": "quick question\n    submitted by    /u/Asleep_Donut1382  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txfewf/is_multi_bandit_on_policy_or_off_policy/",
          "publishedOn": "2022-04-06T06:04:14.000Z",
          "wordCount": 128,
          "title": "Is multi bandit on policy or off policy？",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txe8rj/how_wrong_is_it_to_use_sampling_at_inference_time/",
          "author": null,
          "description": "At my company we use RL to solve our problem. The thing is : our problem is rather complex, and this is the core of our product (so clients rely on the results produced). \n In order to reach satisfying results despite an agent that doesn't learn very well, we use sampling at inference time : instead of taking the best trajectory according to the agent, we take X trajectories and keep only the one with the best reward.\n This seems completely fine at first (similar things are done in NLP for example, with beam search), but in our case the sampling size is huge : 1024. Usually when using beam search, we use maybe a beam size of 6. Maybe 10 if you have good hardware ?\n ​\n Now, the agent seems to be learning : the mean return is slightly increasing over time, the entropies for the actions are steadily decreasing, etc...\n Now the goal of the ML team is to improve agent's learning to decrease the sampling size at inference time (because it's costly to run 1024 trajectories through the environment...).\n But whatever we try, the improvements are not reflected (we compare all our experiments with 1024 sampling in order to see what the customers will see).\n ​\n IMO this is because our sampling size is way too huge, even a random agent can produce okay-ish results...\n Is my intuition the right one ?\n    submitted by    /u/dummy-gummy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txe8rj/how_wrong_is_it_to_use_sampling_at_inference_time/",
          "publishedOn": "2022-04-06T04:51:21.000Z",
          "wordCount": 485,
          "title": "How wrong is it to use sampling at inference time ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txduuq/does_a_masters_thesisdoctoral_dissertation_need/",
          "author": null,
          "description": "I'm in the last semester of my undergraduate degree; over the past couple of weeks, I've been trying to brainstorm ideas that I would like to pursue in my graduate research career. I'm interested in the emergence of language in multi-agent reinforcement environments but I can't see how this would be important down the line when there are large language models that are completely dominating language and communication. \n Should this stop me from pursuing this idea or should I let my interest in the idea take precedence?\n    submitted by    /u/clarky103  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txduuq/does_a_masters_thesisdoctoral_dissertation_need/",
          "publishedOn": "2022-04-06T04:27:30.000Z",
          "wordCount": 283,
          "title": "Does a master's thesis/doctoral dissertation need to have implications down the line for it to be good?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/txbvya/how_long_would_it_take_you_to_implement_a_marl/",
          "author": null,
          "description": "Out of curiosity, how long would it take to implement a paper like this one? https://arxiv.org/abs/2104.07750 \n It has PPO agents in MARL, all of them with multihead attention performed on the observation, in such a way that an attention map is created for each agent. This attention map has information about how strongly each agent is attending to various elements of the environment. With KL divergence, the agents are rewarded for minimizing the difference between their attention maps.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/txbvya/how_long_would_it_take_you_to_implement_a_marl/",
          "publishedOn": "2022-04-06T02:37:14.000Z",
          "wordCount": 256,
          "title": "How long would it take you to implement a MARL PPO agent with joint attention architecture?",
          "imageUrl": "https://external-preview.redd.it/Cb_PcUygTcaeTkYhbknuR-wtPZFTuzLC2xj03KfWrwk.jpg?auto=webp&s=fd99bf3e3699fdaded3c895b6c765f548cc9b341"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tx2zbs/need_project_suggestions/",
          "author": null,
          "description": "I’ve been running circles in tutorial purgatory and I want to get out of it with sone projects. Anyone has any suggestions? Guided ones would be nice. For unguided ones, could you please provide source links/hints?\n    submitted by    /u/HellVollhart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tx2zbs/need_project_suggestions/",
          "publishedOn": "2022-04-05T19:31:36.000Z",
          "wordCount": 220,
          "title": "Need project suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tx0cmf/agents_learns_policy_when_sampling_last_episode/",
          "author": null,
          "description": "Hi all. I've been stuck on this problem for a while and I thought I might be able to find some help here. Any kind of assistance would be greatly appreciated. \n My setup is as follows. I have an environment with 3 agents. All 3 agents have a single policy network, and it is based on CommNet. My goal is to implement a replay buffer for this environment. I verified that my replay buffer logic is good. I tried running 3 different types of runs:\n  \nNormal on-policy run: The agents perform an episode, and at the end of each episode the data (such as the states, actions, etc) from this episode are used to calculate the loss\n Using just the last episode from the replay buffer: The agents perform an episode, and the data is stored in the replay buffer. At the end of each episode, the last episode is sampled from the replay buffer (which is the episode that was just performed). This is just to confirm that my replay buffer is working properly, and the reward curve for this case matches that from (1).\n Using 1 random episode from the replay buffer: The agents perform an episode, and the data is stored in the replay buffer. At the end of each episode, a random episode is sampled from the replay buffer and used to calculate the loss. The performance is terrible in this case, and the environment times out each time\n  \nFor some reason, as soon as I turn on random sampling, progress is really bad. I'm sorry to pose such an open-ended question, but what are some things I could check to pinpoint the source of this problem? What could be a reason as to why performance is as expected when just sampling the last episode, whereas it is terrible when randomly sampling episodes? I've tried some things thus far but nothing has worked, and I turned to this community in hopes of getting some help. I'm new to the area of reinforcement learning, so I would be very grateful for any kind of help you can offer. Thanks in advance\n    submitted by    /u/lebr0n99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tx0cmf/agents_learns_policy_when_sampling_last_episode/",
          "publishedOn": "2022-04-05T17:33:13.000Z",
          "wordCount": 822,
          "title": "Agents learns policy when sampling last episode from replay buffer, but don't when randomly sampling from the replay buffer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twvl67/ppo_sample_correlation/",
          "author": null,
          "description": "Hi, I'm wondering if the PPO algorithm can solve the sample correlation problem of on-policy algorithm in training. PPO uses successive samples to compute GAE, doesn't the sample correlation occurring here interfere with learning?\n    submitted by    /u/noisemastar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twvl67/ppo_sample_correlation/",
          "publishedOn": "2022-04-05T13:59:05.000Z",
          "wordCount": 145,
          "title": "PPO sample correlation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twu26i/p_automlconf_competition_dac4automl/",
          "author": null,
          "description": "submitted by    /u/catsortion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twu26i/p_automlconf_competition_dac4automl/",
          "publishedOn": "2022-04-05T12:42:37.000Z",
          "wordCount": 251,
          "title": "[P] AutoML-Conf Competition: DAC4AutoML",
          "imageUrl": "https://external-preview.redd.it/hwN3EBf7WXi3MEvXiPgqOQzZmfA3yEU8ZOPYIry-WJw.jpg?auto=webp&s=e08b4e79f3d8a80bcf43263d687e29f7665b1ad1"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twu0ai/temporal_difference_learning_for_model_predictive/",
          "author": null,
          "description": "submitted by    /u/bendee983  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twu0ai/temporal_difference_learning_for_model_predictive/",
          "publishedOn": "2022-04-05T12:39:47.000Z",
          "wordCount": 135,
          "title": "Temporal Difference Learning for Model Predictive Control",
          "imageUrl": "https://external-preview.redd.it/Gljiri4TRWX3LOG95WYZE6MZGLdmGsASRjvASplDC7E.jpg?auto=webp&s=090bac27aa9321e9cdce487f0e8952373244ca01"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twtuwp/why_is_there_no_rollout_monitoring_for_this/",
          "author": null,
          "description": "​\n Output from using model.learn(env) on both Envs\n On the left I have a simple dummy CustomEnv (Using Stable-Baselines3 with Gym) for testing, and on the right I have my actual CustomEnv that I am working on in a project.\n As you can see, the dummy environment gives me the rollout monitoring, whereas there is no rollout monitoring for the actual environment (just time + train statistics/monitoring). \n I am using very similar code when setting up the training of the model, however the complexity of the actual model is significantly higher than the dummy. In theory, the complexity of the environment shouldnt make a big difference to the monitoring right? All of the key parts are still there (reward function, step function, reset function etc.).\n In both cases it says that the environments are being wrapped by the 'Moniter' wrapper so that cant be it.\n Does anyone know why this might be happening?\n    submitted by    /u/C_BearHill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twtuwp/why_is_there_no_rollout_monitoring_for_this/",
          "publishedOn": "2022-04-05T12:31:27.000Z",
          "wordCount": 288,
          "title": "Why is there no rollout monitoring for this CustomEnv (on the right) ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twrz5x/value_iteration_in_car_racing_v1/",
          "author": null,
          "description": "I’m working on Q table learning model for OpenAI’s. I have everything done in regards to a basic agent, but I’m unsure how I’m supposed to use the box data for action space and observance space, to populate a q table?\n Or is this approach incorrect? Car Racing doesn’t have a P (probability) call so I’m not sure how else I would do value iteration.\n    submitted by    /u/Dzartovian94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twrz5x/value_iteration_in_car_racing_v1/",
          "publishedOn": "2022-04-05T10:38:55.000Z",
          "wordCount": 405,
          "title": "Value Iteration in Car Racing V1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twp4x8/action_spaces_all_landing_to_zero_probability_in/",
          "author": null,
          "description": "Hey guys, I am new to RL and walking through the Keras implementation of Actor Critic.\n ​\n As a variant of it, I am trying to learn the strategy for WORDLE. However, after a few runs, my action spaces all go down to zero. Not sure what's happening. Could someone have any insights or pointers?\n ​\n Attaching my code for reference.\n ​\n Thanks\n import pandas as pd import numpy as np import random import string import random import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # Configuration parameters for the whole setup gamma = 0.9 # Discount factor for past rewards max_runs = 10000 eps = np.finfo(np.float32).eps.item() # Smallest number such that 1.0 + eps != 1.0 my_file = open(\"<wordle set of words data path>\", \"r\") content = my_file.read() content = lis…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twp4x8/action_spaces_all_landing_to_zero_probability_in/",
          "publishedOn": "2022-04-05T07:13:26.000Z",
          "wordCount": 964,
          "title": "Action Spaces all landing to zero probability in few steps",
          "imageUrl": "https://external-preview.redd.it/4-DxLM-C2Ve3tHmVL5ITI6GRtMVG8PzzdBuCKiaabfE.jpg?auto=webp&s=079a7260ec149880c73263d64811698adb22760a"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twlxdl/any_rlrelated_conferences_right_after_neurips_22/",
          "author": null,
          "description": "In case my NeurIPS submission rejected, lol.\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twlxdl/any_rlrelated_conferences_right_after_neurips_22/",
          "publishedOn": "2022-04-05T03:51:12.000Z",
          "wordCount": 226,
          "title": "Any RL-related conferences right after NeurIPS 22’?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twg36r/ppo_alg_confusion/",
          "author": null,
          "description": "As I read the paper and several tutorials, I am quite confused about the details.\n  \nI see many implementations scale the running cumulative discounted reward in a certain way. However, each of them does it in a different way. let R be the running cumulative discounted reward, which is considered the best? Or is there a source of the method to use? implementations I saw from different places include: \n  \n directly use R to calculate the advantage and training value network (most PPO tutorials use this)\n use (R / std(R)), where std is the mini-batch standard deviation\n use (R / std(R)), where std is the running standard deviation\n use ((R - mean(R)) / std(R)), where both mean and std are mini-batch wise\n use ((R - mean(R)) / std(R)), where both mean and std are running stats.\n do the above and clip to a certain range ([-10, 10] or [-1, 1])\n  \n I also see several different ways for the value network, let V be the output of the value network:\n  \n output raw logit, without any scaling/output activation (most PPO tutorials use this)\n output raw logit, but use the same scaling as discussed above for running cumulative discounted reward, for example, if return value is (R / std(R)), value output will be (V / std(R))\n do the same as 2, but use the stat of V instead of R for scaling, for example, if the return value is (R / std(R)), the value output will be (V / std(V))\n output with tanh activation at the last layer\n output with tanh activation at the last layer, and multiply by a constant to match the range of the return\n  \nany help would be appreciated, thanks!\n    submitted by    /u/seermer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twg36r/ppo_alg_confusion/",
          "publishedOn": "2022-04-04T23:10:05.000Z",
          "wordCount": 552,
          "title": "PPO Alg confusion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twbnb2/im_completely_new_to_rl_and_will_be_building_my/",
          "author": null,
          "description": "Hello all,\n As the title describes, I’ll be making my first model as part of my final project. I still have a pretty high-level understanding of everything, so forgive any inaccuracies as I describe what I’m going for.\n The problem I’m attempting to solve is known as the traveling salesman problem. Essentially, a route needs to be formulated that stops at n given locations. Finding the most efficient route with many stops algorithmically is impractical because the number of possible routes increases exponentially with each added location. \n The environment will simulate travel on city roads. Speed will be a constant, set to whatever the roads speed limit is. I am using .pbf format vector GIS data from OSM so that the environment consists of real-world pathways. I’m using GeoPandas and Pyrosm to work with the data, and I’m collecting nodes for the location of gas stations so that the environment can simulate needing to fuel the vehicle. Gas price will be a constant, as well as vehicle fuel-efficiency.\n Scoring will be based on the calculated time it would take to complete a route and the calculated cost (in gas). The goal will be to find the most efficient route to take when n = some large number. \n I’ve never worked with spatial data either, so I’m not sure what kind of challenges that poses. I worry that adding nodes for the locations of gas stations might be difficult. I’m also wondering if I’m better off using Tensorflow and Keras for this, but I’m not really aware of all the technical considerations I should be making before deciding on that.\n Do you have any tips that might help me out? Solutions to problems I haven’t hit just yet, but likely will? \n Thanks for your help!\n    submitted by    /u/professorDissociate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twbnb2/im_completely_new_to_rl_and_will_be_building_my/",
          "publishedOn": "2022-04-04T20:07:52.000Z",
          "wordCount": 475,
          "title": "I’m completely new to RL and will be building my first model as part of my degree-ending project. Do you have any tips you can provide?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twbn40/best_implementations_for_extensibility/",
          "author": null,
          "description": "As far as I am aware, StableBaselines3 is the gold standard for reliable implementations of most popular / SOTA deep RL methods. However working with them in the past, I don't find them to be the most usable when looking for extensibility (making changes to the provided implementations) due to how the code base is structured in the behind the scenes (inheritance, lots of helper methods & utilities, etc.).\n For example, if I wish to change some portion of a method's training update with SB3 it would probably involve overloading a class method before initialization, making sure al the untouched portions of the original method are carried over, etc.\n Could anyone point me in the direction of any implementations that are more workable from the perspective of extensibility? Ideally implementations that are largely self contained to a single class / file, aren't heavily abstracted aware across multiple interfaces, don't rely heavily on utility functions, etc.\n    submitted by    /u/Farconion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twbn40/best_implementations_for_extensibility/",
          "publishedOn": "2022-04-04T20:07:40.000Z",
          "wordCount": 367,
          "title": "Best implementations for extensibility?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/twaicu/is_it_possible_to_use_inspectgetcallargs_to/",
          "author": null,
          "description": "Given a NN class, is there something specific we need to care of when converting *args and **kwargs to a canonical kwarg representation? I ask this because in this code from Google (https://github.com/google-research/google-research/blob/c56b47713b08c95ad427d5f93ee0dbb9ad008964/social_rl/multiagent_tfagents/joint_attention/attention_networks.py#L557) they use a TFDecorator-aware replacement for inspect.getcallargs, instead of using getcallargs directly. So my questions are: \n - Is it possible to use inspect.getcallargs to convert *args and **kwargs to a canonical kwarg representation?\n - If no, is there an equivalent in PyTorch? I couldn't find any, so I was wondering how people go about that.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/twaicu/is_it_possible_to_use_inspectgetcallargs_to/",
          "publishedOn": "2022-04-04T19:21:36.000Z",
          "wordCount": 242,
          "title": "Is it possible to use inspect.getcallargs to convert *args and **kwargs to a canonical kwarg representation in RL?",
          "imageUrl": "https://external-preview.redd.it/CMhpMLhb6T0d4kqxMnDmxlqLqBIUASjloDaZLDY4pDk.jpg?auto=webp&s=411a8f7f0fc00a11f3af1004038b99d54177481c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw75kp/openai_gym_return_donetrue_but_not_seeing_goal_is/",
          "author": null,
          "description": "Hi all, I am running some starter code from openAI(FetchReach-v1, FetchPush-v1) gym with env.action_space.sample(). But I don't see the goal is actually achieved when done returned is True. I copied the code from here (https://openai.com/blog/ingredients-for-robotics-research/). I even let it sleep every step to watch more closely. Another related thing that I can't explain is that it always returns done==True rather quickly with very few sampled actions. These all make me worried about using it as my task environment.\n    submitted by    /u/AnimatorRemarkable20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw75kp/openai_gym_return_donetrue_but_not_seeing_goal_is/",
          "publishedOn": "2022-04-04T17:04:39.000Z",
          "wordCount": 304,
          "title": "openAI gym return done==True but not seeing goal is reached",
          "imageUrl": "https://external-preview.redd.it/lrIvaCZG-_bxok-lBkmGtKy2ufLuAQcEhYGt1O-R0rY.jpg?auto=webp&s=24d01b26bc9d2333ef8868067f3263d0ed1601c3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw3fii/which_elective_monte_carlo_simulation_or/",
          "author": null,
          "description": "Hello /r/reinforcementlearning. I have to choose electives pretty soon, and as i am interested in reinforcement learning, I wanted to know which of these would be the most beneficial. \n  \nMonte Carlo Simulation\n Computational Learning Theory\n  \nThe year after I will also take a course on Reinforcement Learning, but it has not been created yet. \n Note: I can also take both if recommended, if I do so, I will take one of the courses before taking the RL course, and the other would be at the same time. \n Some further thought I've had:\n  \nCLT includes Bandits, which is surely were useful to know, but it seems to be only a rather small part, and I'm unsure whether all the other topics like PAC Learning and Rademacher Bounds are useful?\n \nMC is more practical while CLT is more theoretic (Apparently VERY theoretic according to the course description above). I am not afraid of theoretic courses, but I struggle more with them than more practical courses.\n \nThe sentiment around the MC course, is that it is pretty good. I don't know anyone who have taken the CLT course.\n \nIf I choose both, which order would you take them in?\n \n    submitted by    /u/John_Hitler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw3fii/which_elective_monte_carlo_simulation_or/",
          "publishedOn": "2022-04-04T14:30:21.000Z",
          "wordCount": 462,
          "title": "Which elective: Monte Carlo Simulation or Computational Learning Theory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw2v97/ray_rl_lib_observations_normalized/",
          "author": null,
          "description": "Hey i am using the RL lib from ray and i don't know if the observations automatically normalized by the lib or not?\n By creating a costum environment ray wants you to create an observationspace. That would be a gym box in my case. Anyway idk the exact high and low values. My values lay between -1 and 1 more or less. \n My fear is now that ray would normalize the Observation values to a new range although they are already processed. Does ray normalized observationspace? If yes how can i turn it off?\n Thanks!\n    submitted by    /u/Willing-Classroom735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw2v97/ray_rl_lib_observations_normalized/",
          "publishedOn": "2022-04-04T14:06:31.000Z",
          "wordCount": 266,
          "title": "Ray RL lib observations normalized?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw2dla/cfp_evorl_gecco_2022_one_week_before_the_deadline/",
          "author": null,
          "description": "CALL FOR PAPERS\n EvoRL 2022\n Evolutionary Reinforcement Learning workshop at GECCO 2022, July 9-13, Boston, USA\n \n In recent years reinforcement learning (RL) has received a lot of attention thanks to its performance and ability to address complex tasks. At the same time, multiple recent papers, notably work from OpenAI, have shown that evolution strategies (ES) can be competitive with standard RL algorithms on some problems while being simpler and more scalable. Similar results were obtained by researchers from Uber, this time using a gradient-free genetic algorithm (GA) to train deep neural networks on complex control tasks. Moreover, recent research in the field of evolutionary algorithms (EA) has led to the development of algorithms like Novelty Search and Quality Diversity, capable of…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw2dla/cfp_evorl_gecco_2022_one_week_before_the_deadline/",
          "publishedOn": "2022-04-04T13:44:45.000Z",
          "wordCount": 625,
          "title": "[CfP] EvoRL @ GECCO 2022. One week before the deadline!",
          "imageUrl": "https://external-preview.redd.it/lK42WwByGG32nygWSBuOYR3KR5RyUTDVfuLYvfjqmTI.jpg?auto=webp&s=02c389b64acc7a9d40c4c4ad6555c2381750877f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tw10gn/how_ppo_deals_with_episodes_of_variable_lengths/",
          "author": null,
          "description": "In the paper it is written to collect trajectories of length T. Then calculate advantage and then train the Actor and Critic Network. My question is suppose one episode ends much before T. If I run that episode upto lenth T then it will only collect negative rewards in each timestep which in turn makes the training impossible as the return if very big negative number. So what can be done instead of this?\n I might be getting it wrong, so please correct me by commenting.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tw10gn/how_ppo_deals_with_episodes_of_variable_lengths/",
          "publishedOn": "2022-04-04T12:39:24.000Z",
          "wordCount": 284,
          "title": "How PPO deals with episodes of Variable lengths?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvyv0w/need_help_with_openai_gym_custom_environment/",
          "author": null,
          "description": "Hello,\n I'm making a custom openAI gym environment to train various algorithms on it. I have encountered some issues. \n My .flatten() method on the state class returns a large integer which can be converted back into the same state as the object. However when I try to do this as the returned observation for environment.reset() and environment.step(), when testing it I get: \"AssertionError: The observation returned by the `reset()` method does not match the given observation space\" which I can fix by having it just return a 0. How do I go about resolving this? and are there any better approaches for wanting to train RL agents on an environment? ty!\n    submitted by    /u/snaredrum_merchant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvyv0w/need_help_with_openai_gym_custom_environment/",
          "publishedOn": "2022-04-04T10:38:08.000Z",
          "wordCount": 264,
          "title": "Need help with OpenAI gym custom environment, state representation as \"observation\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvipcq/how_does_the_acer_algorithm_work/",
          "author": null,
          "description": "I am currently writing a report on reinforcement learning, where I am trying to describe how the ACER algorithm works. I have read the arxiv paper on the sample actor-critic with experienced replay, but I don't understand where the experience replay comes in. Is this part of the policy gradient? where the policy is updated every episode it's trained on from the previous knowledge it gathers in previous episodes.\n https://arxiv.org/pdf/1611.01224.pdf\n ​\n    submitted by    /u/beepingwater_neko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvipcq/how_does_the_acer_algorithm_work/",
          "publishedOn": "2022-04-03T20:14:25.000Z",
          "wordCount": 229,
          "title": "How does the ACER algorithm work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tvif3g/whats_the_best_way_to_implement_tree_bases/",
          "author": null,
          "description": "Sorry if this post is not appropriate here, but I have been wondering how can I implement and learn a decision tree or any other non differentiable function approximators for the Value Function.\n It’s relatively easy to formulate and use DQN type algorithms by using neural network and say pytorch + stochastic optimization but I want to try out some tree based methods. (at least to reproduce papers which claim to use them)\n But I don’t know 1) If we have to design the structures and learning algorithms by hand or is there any package I can use? \n 2) How should the learning be done? We obviously can’t go regression type learning because of the bootstrapping nature of the Bellman equation?\n Thanks\n    submitted by    /u/Htaseht  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tvif3g/whats_the_best_way_to_implement_tree_bases/",
          "publishedOn": "2022-04-03T20:03:04.000Z",
          "wordCount": 253,
          "title": "What’s the best way to implement tree bases function approximators for RL/Control?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tv9iif/im_working_on_a_dqn_agent_using_the_keras_rl/",
          "author": null,
          "description": "The episode step count is the same for training and testing.\n    submitted by    /u/Gleann_na_nGealt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tv9iif/im_working_on_a_dqn_agent_using_the_keras_rl/",
          "publishedOn": "2022-04-03T13:40:29.000Z",
          "wordCount": 312,
          "title": "I'm working on a DQN agent using the Keras RL library to play Atari games, however a weird thing keeps happening where every episode is the same length but it's a random number each time.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tuzq36/are_there_any_real_life_projects_i_could_do_with/",
          "author": null,
          "description": "I tried using RL for some work at my university, it did not really work all that well. \n I'm wondering if there are some real life scenarios that I could use to create my own personal projects. Otherwise, I'd be fine with games. \n I want to try all of it out from Dynamic Programming to crazy ass stuff like A3C, PPO and so on. I like RL, more so than any other form of ML, and I want to play around with it as a hobby. \n This is really the area of ML for me. For starters, there are fundamentals behind it, so you can mostly explain why agents do one thing or another. Additionally, there isn't a need to have massive amounts of data. It's also the only type of ML that I've been able to successfully use with software engineering. \n Designing the agent and the API it uses to take actions in an environment is as much a software engineering project as is creating a REST API. \n I feel there is a lot of potential for me to go crazy with this, and I was wondering if people have any cool suggestions. Anything that is real time is anything that I want to do. Real time systems and RL are exactly the sort of thing I love to do.\n    submitted by    /u/HesperusIII  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tuzq36/are_there_any_real_life_projects_i_could_do_with/",
          "publishedOn": "2022-04-03T03:22:28.000Z",
          "wordCount": 477,
          "title": "Are there any real life projects I could do with this? How do I get ideas to use this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tuwhbp/agentzero_ray_pytorch_based_lightweight/",
          "author": null,
          "description": "AgentZero\n https://github.com/zhoubin-me/agent0\n This is my personal project developed two years ago. It covers major DRL algorithms like:\n - [DQN](https://arxiv.org/abs/1312.5602)- [Double DQN](https://arxiv.org/abs/1509.06461)- [Dueling DQN](https://arxiv.org/abs/1511.06581)- [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)- [Noisy Network](https://arxiv.org/abs/1706.10295)- [C51](https://arxiv.org/abs/1707.06887)- [Rainbow](https://arxiv.org/abs/1710.02298)- [QR-DQN](https://arxiv.org/abs/1710.10044)- [IQR](https://arxiv.org/abs/1806.06923)- [FQF](https://arxiv.org/abs/1911.02140)- [DDPG](https://arxiv.org/abs/1509.02971)- [SAC](https://arxiv.org/abs/1801.01290)- [TD3](https://arxiv.org/abs/1802.09477)- [MDQN](https://arxiv.org/abs/2007.14430)\n What is amazing is its speed and memory efficiency after some optimization:\n With a single 2080Ti GPU and a 8 core AMD CPU, the training speed of rainbow for Atari could achieve 3000FPS, which means it can finish training of 10M frames within 1 hour. With compression of image frames, replay memory's RAM usage is down by 20%.\n I have tested several algorithms and games on Atari and get some initial result. Welcome to use and contribute!\n    submitted by    /u/zhoubin-me  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tuwhbp/agentzero_ray_pytorch_based_lightweight/",
          "publishedOn": "2022-04-02T23:35:17.000Z",
          "wordCount": 402,
          "title": "AgentZero: Ray & PyTorch based light-weight Distributed Fast Reinforcement Learning Framework",
          "imageUrl": "https://external-preview.redd.it/rphMmrOxdz-k8Ls0gskVFmjxfTT1RF2a1aqcyU-tVsI.jpg?auto=webp&s=6e71280b62d4d5793c50b37afe494c634c3dd927"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tuv1t5/regularization_for_drl_reward_or_objective/",
          "author": null,
          "description": "I am searching for regularization methods applied to DRL algorithms (either value or policy-based) to understand what has been done so far in the field. I cannot find any valid reference that studies the effect of applying a soft constraint to the reward function instead of to the policy objective. This may seem useless for some applications, but it is highly relevant for finance, which is my domain of application,\n The idea I have so far is that if you constrain the reward, it is like you are imposing limits on the agent's behavior. On the other hand, if you constrain the objective, you are not limiting the behavior, but you are correcting the ex-post the undesired behavior. The latter way does not allow the agent to learn not to behave in a certain way.\n ​\n Did anyone ever think about it? Are they good references that analyze the different effects of a constraint to whatever DRL algorithm?\n    submitted by    /u/alebrini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tuv1t5/regularization_for_drl_reward_or_objective/",
          "publishedOn": "2022-04-02T22:27:26.000Z",
          "wordCount": 297,
          "title": "Regularization for DRL: reward or objective function?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/turvmf/what_does_it_mean_to_feed_the_network_state_in_an/",
          "author": null,
          "description": "I am looking at this code from Google (https://github.com/google-research/google-research/blob/master/social_rl/multiagent_tfagents/joint_attention/attention_networks.py). \n At line 639, the LSTM is called. The first two inputs are the state and the network state, but I don't understand what the latter is.\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/turvmf/what_does_it_mean_to_feed_the_network_state_in_an/",
          "publishedOn": "2022-04-02T20:05:26.000Z",
          "wordCount": 314,
          "title": "What does it mean to feed the \"network state\" in an LSTM in the actor network?",
          "imageUrl": "https://external-preview.redd.it/CMhpMLhb6T0d4kqxMnDmxlqLqBIUASjloDaZLDY4pDk.jpg?auto=webp&s=411a8f7f0fc00a11f3af1004038b99d54177481c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tukbpx/deeprl_and_rubiks_cube/",
          "author": null,
          "description": "I'm part of a group of researchers from top ML institutions and industry, our goal is to figure out how improve efficiency in DeepRL.\n We are looking at Rubik’s Cube as target problem, and kicking off a project which will start from https://github.com/forestagostinelli/DeepCubeA and go from there.\n Prior works require hand crafted curriculum and billion of interactions to solve a cube, we believe that order of magnitude more compute that it should take.\n Is anyone interested to collaborate? I'm happy to dedicate a few hours a week to help a newcomer like I was a few years ago with the RL stuff given some basics of machine learning and programming skills, and this could be the golden opportunity for someone to see RL at scale.\n    submitted by    /u/mind_library  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tukbpx/deeprl_and_rubiks_cube/",
          "publishedOn": "2022-04-02T14:38:04.000Z",
          "wordCount": 528,
          "title": "DeepRL and Rubik’s Cube",
          "imageUrl": "https://external-preview.redd.it/vY5AZeHYgdqG0QCmZ_yxSBdi2a5KSVfQqQEVHBoyAc8.jpg?auto=webp&s=53fd91a99190c8c98634245be5a6b46ddd731ffb"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tujiup/multi_agent_reinforcement_learning/",
          "author": null,
          "description": "I'm absolutely new to machine learning, let alone reinforcement learning. I've been tasked to replicate and if possible improve upon the paper linked in the post. I don't know what platform to use and how to create the custom environment. if anybody could share any resources it would be tremendously helpful.\n https://drive.google.com/file/d/1fIT43hKi61WUIvoTh2a3AWlRsphi-L98/view?usp=sharing\n    submitted by    /u/Lazarus_07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tujiup/multi_agent_reinforcement_learning/",
          "publishedOn": "2022-04-02T14:00:39.000Z",
          "wordCount": 443,
          "title": "Multi agent reinforcement learning",
          "imageUrl": "https://external-preview.redd.it/nA1vBVIvczC8HAsR2ahVxtV-Pril_KFs64Y7NW9J4j0.jpg?auto=webp&s=2fadec1181f76b169acf9693211bc4464bd9156d"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu85b5/qlearning_vs_policy_gradient/",
          "author": null,
          "description": "Trying to wrap my head around the RL essentials. Would it be correct to say that Q-learning attempts to select the best available policy by optimizing the Q-function, while policy gradient methods work directly to optimize a pre-determined policy's parameters?\n    submitted by    /u/JimBeanery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu85b5/qlearning_vs_policy_gradient/",
          "publishedOn": "2022-04-02T02:24:42.000Z",
          "wordCount": 181,
          "title": "q-learning vs. policy gradient",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu7499/how_to_use_a_deep_model_for_drl/",
          "author": null,
          "description": "I noticed most DRL papers use very shallow models like three or four layers. However, when I try to do DRL tasks that have relatively complicated scenes (for example, some modern video game), shallow models become way too weak.\n Are there papers, blogs, articles etc. that use more complex/deep models? Or maybe some methods that can deal with complicated scenes without deep models?\n Thanks\n    submitted by    /u/seermer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu7499/how_to_use_a_deep_model_for_drl/",
          "publishedOn": "2022-04-02T01:31:43.000Z",
          "wordCount": 409,
          "title": "How to use a deep model for DRL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu68ex/any_thought_on_a_universal_parameter_optimizer/",
          "author": null,
          "description": "Hi all, I have an thought on A universal parameter optimizer I wanted to share with you and to see if you know some related work. \n Assume you have a simulation or access to an environment. There are certain parameters you can set to control the performance of a system which lives in this simulation/environment. Naturally, one wants to find the optimal parameters or optimal policy to set the parameter that can result the most reward, however that is defined. \n For example, in the stock market, I may want to find the optimal market price to buy and sell, or the optimal policy. In a car driving game, I may want to determine the optimal policy to set speed and direction. \n Do we know if there is formal way to study this type of problem? Thank you!\n    submitted by    /u/DB8868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu68ex/any_thought_on_a_universal_parameter_optimizer/",
          "publishedOn": "2022-04-02T00:45:21.000Z",
          "wordCount": 257,
          "title": "Any thought on: A universal parameter optimizer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tu3qbd/d_current_algorithms_consistently_outperforming/",
          "author": null,
          "description": "Hi community. It has been 5 years now since these algorithms were released, and I don't feel like they have been quite replaced yet. In your opinion, do we currently have algorithms that make either of them obsolete in 2022?\n    submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tu3qbd/d_current_algorithms_consistently_outperforming/",
          "publishedOn": "2022-04-01T22:42:46.000Z",
          "wordCount": 200,
          "title": "[D] Current algorithms consistently outperforming SAC and PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttujzz/need_help_with_project_idea/",
          "author": null,
          "description": "Hey guys! So I am enrolled in a reinforcement learning course at my university, and I am really confused about a decent project idea. Primarily, I want to work on any game based environment apart from atari ones. Using unity seems promising but not sure if that is easy to pull off. Any suggestions to get me started? Thanks\n    submitted by    /u/ishon_p  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttujzz/need_help_with_project_idea/",
          "publishedOn": "2022-04-01T16:13:30.000Z",
          "wordCount": 212,
          "title": "Need Help with Project Idea",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttu50r/d_completely_removing_the_option_taking_illegal/",
          "author": null,
          "description": "Hi, \n I have a two step custom gym env which is a graph network optimisation task (two steps due to high dimension action space). In the first step the agent chooses the first node and state reward passed to training. in the second step, the agent chooses the second node, and with a class attribute holding the history of the first selected node, now has a node pair which it is then able to remove or add and edge. The training loop now has a new graph state (edges changed between nodes) plus a vector of the first action selected. \n The agent is able to learn well however, even with a negative reward provided to the agent if it takes illegal actions (choosing the same node in each step and thus creating a self connection), even when it learns to maximise reward, it still take illegal actions…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttu50r/d_completely_removing_the_option_taking_illegal/",
          "publishedOn": "2022-04-01T15:56:42.000Z",
          "wordCount": 509,
          "title": "[D] Completely removing the option taking illegal actions in custom gym environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tttw8h/training_drone_via_drl_to_hover_with_just_camera/",
          "author": null,
          "description": "Hi Everyone \n This is my first time trying reinforcement learning and Unity and wanted some help. \n I am trying to train a quadcopter to hover and keep a stationary ball in its camera frame using just visual inputs by a camera sensor. So the input to the network would be an 84*84 grayscale image and the output would be the four forces to the rotor.\n My reward function is \n ​\n Reward Function\n where x and y is the position of the drone and a is the rotation of the drone with respect to the target. I have set A, d and c to 3 and lambda as 1/180. I have also added a condition where if the quadcopter drops below a certain height from the platform, it punishes it by a reward of -1 and resets the episode.\n The network I am using is the ppop network used by the coin-collector example in mlagents. \n My training log is below: \n Training log\n The cumulative reward and episode length just drops after a while and the value loss explodes. I think something maybe wrong with my rewards or network. \n If anyone has any ideas what might be going wrong and tell me, that would be great. \n Thanks\n    submitted by    /u/voyager10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tttw8h/training_drone_via_drl_to_hover_with_just_camera/",
          "publishedOn": "2022-04-01T15:46:38.000Z",
          "wordCount": 325,
          "title": "Training drone via DRL to hover with just camera sensor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tttecp/do_you_know_any_port_of_stablebaselines_3_to_c/",
          "author": null,
          "description": "Has anybody done it already?\n    submitted by    /u/Live_Medium_3949  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tttecp/do_you_know_any_port_of_stablebaselines_3_to_c/",
          "publishedOn": "2022-04-01T15:25:35.000Z",
          "wordCount": 137,
          "title": "Do you know any port of StableBaselines 3 to C++?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttorpr/is_there_a_way_to_get_ppo_controlled_agents_to/",
          "author": null,
          "description": "submitted by    /u/user_00000000000001  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttorpr/is_there_a_way_to_get_ppo_controlled_agents_to/",
          "publishedOn": "2022-04-01T11:49:18.000Z",
          "wordCount": 671,
          "title": "Is there a way to get PPO controlled agents to move a little more gracefully?",
          "imageUrl": "https://external-preview.redd.it/h_sOeh2-6QCTGSEiVV4OoS06tHh7owhf4x2rq8VrHPg.png?format=pjpg&auto=webp&s=38b9d61cd74dfb14f0c9de38121675d6022aeca5"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttntyx/how_to_make_two_policies_in_trpo_ppo_algorithms/",
          "author": null,
          "description": "In both TRPO and PPO, we have r which is ration of new_policy/old_policy. Here we collect data from old_policy and improve new policy. I am confused on how to implement this. Correct me If I am wrong but I have two ways in mind.\n 1) I collect prob while running simulation. When optimizing, I use same neural network to sample another action and its prob, this new and its probability becomes my new_policy and then I optimize for L_clip function. \n 2) I collect prob while running simulation. Before optimizing the ppo objective, I first run a simple policy gradient by using the original prob I collected. After updating the NN, I once more get new_prob which I use in L_clip function.\n Can someone please tell me which should I do and why?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttntyx/how_to_make_two_policies_in_trpo_ppo_algorithms/",
          "publishedOn": "2022-04-01T10:53:47.000Z",
          "wordCount": 352,
          "title": "How to make two policies in TRPO, PPO algorithms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttn09z/intrinsic_curiosity_module_pytorch_multithreading/",
          "author": null,
          "description": "Hello\n I am working on an extension of this implementation https://github.com/philtabor/Youtube-Code-Repository/tree/master/ReinforcementLearning/ICM of the intrinsic curiosity module. It uses A3C(Actor -critic) as a policy and the ICM is a bolt on module.\n I need to fix the seeds for reproducibility but no matter what i have tried I cannot achieve it.\n The implementation uses multithreading on cpu and plays on the oepnai gym cartpole or atari environments.\n I believe that it has something to do with multithreading but im not sure.\n Could someone know what is the solution?\n    submitted by    /u/Formal-Drawing-8421  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttn09z/intrinsic_curiosity_module_pytorch_multithreading/",
          "publishedOn": "2022-04-01T09:56:55.000Z",
          "wordCount": 379,
          "title": "Intrinsic Curiosity Module Pytorch multithreading cpu unable to fix seeds",
          "imageUrl": "https://external-preview.redd.it/SYc06SjJnWJ0Fhmce3m7Rf2njUdkn8xbCXLrqHEAm5g.jpg?auto=webp&s=fc1e9beeb9b3012f760f91047b804d0c58f555ad"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttkpf9/is_replay_buffer_can_remove_done/",
          "author": null,
          "description": "Hi, These days, there are lots of implementation without next state and done for memory like drq-v2 official implementation. But, I have a question about is it okay to throw out \"done\" in replay buffer. In my point of view, there are some problems about done related signal. or did I read implementation code wrong?\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttkpf9/is_replay_buffer_can_remove_done/",
          "publishedOn": "2022-04-01T07:07:21.000Z",
          "wordCount": 260,
          "title": "Is replay buffer can remove \"done\"?",
          "imageUrl": "https://external-preview.redd.it/4IdpVlpDTlQHNocMfJdmvdX02LnEB5rQtaNwb5y62V4.jpg?auto=webp&s=926d3c300953ddaa24dd9dce77a38eb24f4e1323"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ttjeqq/do_policy_gradient_methods_also_require_some/",
          "author": null,
          "description": "Algorithms like A2C, A3C, TRPO and PPO use a stochastic policy, i.e. the actions are sampled from a probability distribution so the exploration should be done inherently by these algorithms. Yet, when I am using PPO to train a bipedalwalker, it seems like some exploration mechanism is required because during the training process reward first go up and then after 1K episodes there is no progress. Please suggest me what can I do stop this from happening.\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ttjeqq/do_policy_gradient_methods_also_require_some/",
          "publishedOn": "2022-04-01T05:41:10.000Z",
          "wordCount": 543,
          "title": "Do policy gradient methods also require some mechanism for exploration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt9anv/policy_gradients_with_pytorch/",
          "author": null,
          "description": "what will the shape of the tensor \"probs\" (marked) look like ? \n will it look like this - \n [ 0.32,0.40,0.28] ?\n ​\n or like this ?\n [ [ 0.32,0.40,0.28],\n [ 0.32,0.40,0.28],\n [ 0.32,0.40,0.28],\n [ 0.32,0.40,0.28] ] \n https://preview.redd.it/3qiq3lzz6sq81.png?width=829&format=png&auto=webp&s=c15ece0e38b9dabf3f443466b2553e146845e92a\n    submitted by    /u/Whole_Run_4485  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt9anv/policy_gradients_with_pytorch/",
          "publishedOn": "2022-03-31T20:45:17.000Z",
          "wordCount": 192,
          "title": "Policy Gradients with pytorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt7ns1/what_are_the_main_roads_to_agi/",
          "author": null,
          "description": "I was wondering if you can help me come up with a list fo all the specific proposals on how to achieve AGI. For example, one of them is: scaling is all you need. In more detail, scaling self-supervised pretrained deep network models (a.k.a. foundation models), data and compute can lead to AGI (scaling assumes \"smart\" one, i.e. as steep as possible/cost-efficient exponents in neural scaling laws). Do you know what other main roads there are to AGI?\n    submitted by    /u/No_Possibility_7588  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt7ns1/what_are_the_main_roads_to_agi/",
          "publishedOn": "2022-03-31T19:31:29.000Z",
          "wordCount": 201,
          "title": "What are the main roads to AGI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt291u/sparse_reward_environments_and_off_policy/",
          "author": null,
          "description": "In my experience, (continuous action space) off Policy algorithms are generally more sample efficient than on policy algorithms but don't perform as well on sparse rewards environments. Are there any papers that address this issue? Do you know of any algorithms that are both sample efficient and learn sparse reward Environments well?\n    submitted by    /u/SirRantcelot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt291u/sparse_reward_environments_and_off_policy/",
          "publishedOn": "2022-03-31T15:26:40.000Z",
          "wordCount": 179,
          "title": "Sparse Reward Environments and Off Policy Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt19mu/how_to_deal_with_delayed_dense_rewards/",
          "author": null,
          "description": "I'm having a doubt that may be a little stupid, but I ask to be sure.\n Assume that in my environment rewards are delayed by a random number n of steps, i.e. the agent takes an action but receives the reward n steps after taking that action. At every step a reward is produced, therefore the reward r_t in transitions s_t, a_t, r_t, s_{t+1} collected by the agent is actually the reward corresponding to the transition at time t-n. \n An example scenario: the RL agent control a transportation network, and a reward is generated only when a package reach its destination. Thus, the reward arrives with possibly several steps of delay with respect to when the relevant actions were taken. \n Now, I know that delayed rewards are not generally an issue, e.g. all those settings in which there is only one reward +1 at the end, but I am wondering if this case is equivalent. What makes me wonder is that here, for a state s_t onwards to state s_{t+n}, there are n rewards in the middle that depend on states previous to s_t. \n Does this make the problem non-markovian? How can one learn the value function V(s_t) if its estimation is always affected by unrelated rewards r_{t-n} ... r_{t-1}?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt19mu/how_to_deal_with_delayed_dense_rewards/",
          "publishedOn": "2022-03-31T14:41:43.000Z",
          "wordCount": 738,
          "title": "How to deal with delayed, dense rewards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tt0jua/sim2real/",
          "author": null,
          "description": "Hi! Does anyone know the “right” way to apply a policy to a robotic manipulator? Now I’m trying creating a real environment and simulate the policy on it but I can’t find anything on the web about this. Thanks!\n    submitted by    /u/Big-Picture8323  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tt0jua/sim2real/",
          "publishedOn": "2022-03-31T14:07:10.000Z",
          "wordCount": 326,
          "title": "Sim2Real",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tsw7rb/pass_a_seed_arg_in_gyms_reset_method_to_play_the/",
          "author": null,
          "description": "I asked a while back how to save state of an episode when this was my original intention. \n even a quick perusal of an environment's code reveals interesting information that's helpful to using gym as a whole\n https://www.github.com/openai/gym/tree/master/gym/envs\n I think it'd be interesting if papers supplied seed numbers for their test andntraining runs, where they're pulled from an array of ints contained in the agent.\n    submitted by    /u/clockface99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tsw7rb/pass_a_seed_arg_in_gyms_reset_method_to_play_the/",
          "publishedOn": "2022-03-31T09:47:38.000Z",
          "wordCount": 265,
          "title": "Pass a seed arg in gyms reset method to play the same game - undocumented feature!",
          "imageUrl": "https://external-preview.redd.it/Nh26Zt33g9Wi2IFRjkAqR7_jDvUNtDK7011BDEcnu8g.jpg?auto=webp&s=14b77bf03ed29b7631ee6bb0526d0ba8c32ab79f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tsv55f/r_reinforcement_learning_in_finance_project/",
          "author": null,
          "description": "Hello, I hope that this message finds you in good health\n FinRL: Deep Reinforcement Learning for Quantitative Finance https://github.com/AI4Finance-Foundation/FinRL is a project from Columbia University. It offers environments for cryptocurrency, paper trading, stock trading, and forex trading. Also, it has support for three reinforcement learning libraries: Stable Baselines3, RLlib, and ElegantRL. This is from AI4Finance-foundation and it aims to provide a plug-play platform for RL in finance. Do check it out and help us to improve this project\n Some resources:\n  \nMy contributions: https://medium.com/@athekunal/list/finrl-contributions-59de6997c5b1\n Resources to learn FinRL: https://github.com/AI4Finance-Foundation/FinRL#tutorials\n All tutorial notebooks: https://github.com/AI4Finance-Foundation/FinRL/tree/master/tutorials\n YouTube Channel: https://www.youtube.com/channel/UCrVri6k3KPBa3NhapVV4K5g\n  \n   submitted by    /u/A_the_kunal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tsv55f/r_reinforcement_learning_in_finance_project/",
          "publishedOn": "2022-03-31T08:25:13.000Z",
          "wordCount": 295,
          "title": "[R] Reinforcement learning in Finance project",
          "imageUrl": "https://external-preview.redd.it/26WP_8wiR4eM6G0YebGmMkj2k6iO24IWXjkX2zAG8Eg.jpg?auto=webp&s=febf91202e8cc5f45f9bc0a588436e70101652d3"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tsf5gf/why_isnt_epsilon_reset_regularly_in_epsilon/",
          "author": null,
          "description": "surely this improves exploration? e.g. I took a default dqn and after 200k frames mountain car env didn't get to the top but after modifying training to reset epsilon to eps max every 3k steps (with a 1000 frame decay rate from 1 to 0.1) helped increase the score during training and got -133.\n after testing a bit I found it helps training if you modify how many N steps you reset epsilon as you train, e.g. I start on 3k for 100k frames and then 10k for 100k frames and then no resetting.\n I can't be the first and I understand there are much more mathematically stronger exploration techniques but is this a poorman's exploration technique?\n    submitted by    /u/clockface99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tsf5gf/why_isnt_epsilon_reset_regularly_in_epsilon/",
          "publishedOn": "2022-03-30T19:31:09.000Z",
          "wordCount": 493,
          "title": "Why isn't epsilon reset regularly in epsilon greedy policies to aid exploration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ts4ct0/cooperative_multiagent_with_a_global_reward/",
          "author": null,
          "description": "In my environment, I have multiple agents that need to cooperate. The reward function is global, such that it depends on the overall state of the system, and not just the sum of each agent reward. Could you point me to some relevant literature in this field?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ts4ct0/cooperative_multiagent_with_a_global_reward/",
          "publishedOn": "2022-03-30T11:32:33.000Z",
          "wordCount": 201,
          "title": "Cooperative multi-agent with a global reward function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/ts3pud/11_best_python_books_for_beginners_to_advanced_to/",
          "author": null,
          "description": "submitted by    /u/sivasiriyapureddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/ts3pud/11_best_python_books_for_beginners_to_advanced_to/",
          "publishedOn": "2022-03-30T10:52:58.000Z",
          "wordCount": 147,
          "title": "11 Best Python Books for beginners to advanced to read in 2022 -",
          "imageUrl": "https://external-preview.redd.it/3pdSs8qDH1dxGz1jom5eFGa2iAZiKGkP654eztme7y0.jpg?auto=webp&s=ac621ceb3cbbdfba20cd59821ecd81a25a9d798f"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/trv703/what_is_tau_in_the_dynaq_algorithm/",
          "author": null,
          "description": "https://imgur.com/UOdDUFH\n From the linked image I am wondering what tau is (the tau looks like a small r in the image unless you zoom in)? Is it a hard coded value like kappa (k)? If not how is the value for tau determined when Dyna Q+ runs?\n    submitted by    /u/lifelifebalance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/trv703/what_is_tau_in_the_dynaq_algorithm/",
          "publishedOn": "2022-03-30T01:36:51.000Z",
          "wordCount": 392,
          "title": "What is tau in the Dyna-Q+ algorithm?",
          "imageUrl": "https://external-preview.redd.it/HdajETvCDYrX_423ty9BsHE7vR6Cm34Zl1JmZduRSc8.jpg?auto=webp&s=5c73ec396915ec4009bf051b5c642d3cc9d40b55"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/truggg/worthwhile_to_convert_custom_env_to_be_dm_env/",
          "author": null,
          "description": "Can anyone speak to their experience using acme (https://github.com/deepmind/acme) and by extension dm_env (https://github.com/deepmind/dm_env)? I'm wondering if it would be worthwhile for me to invest the time into converting my custom environment (which loosely follows the standard RL setup) over to this format.\n I quite like how acme does a lot of heavy lifting in the background and lays out their thoughts on best practices, but perhaps I'm being shortsighted by all the bells and whistles\n    submitted by    /u/whynotmehmm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/truggg/worthwhile_to_convert_custom_env_to_be_dm_env/",
          "publishedOn": "2022-03-30T00:55:48.000Z",
          "wordCount": 204,
          "title": "Worthwhile to convert custom env to be dm_env compatible?",
          "imageUrl": "https://external-preview.redd.it/T4e8rfdsL0OjHAkzcdS0-W7Kn4D6VfNiJ3b4AnQZPoc.jpg?auto=webp&s=f67f879d54089322b68fbde4fcf776a380d707ec"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqyyk3/artificial_intelligence_beats_8_world_champions/",
          "author": null,
          "description": "submitted by    /u/kevinwangg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqyyk3/artificial_intelligence_beats_8_world_champions/",
          "publishedOn": "2022-03-29T12:46:18.000Z",
          "wordCount": 333,
          "title": "Artificial Intelligence beats 8 world champions at a version of Bridge",
          "imageUrl": "https://external-preview.redd.it/WpwXEa7gVOYU6ZgHWiq4aq0r36J-t9FFX1f3bjs0BPs.jpg?auto=webp&s=19a295e3dfbc0682998ddf39a683bb5775f5a64c"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqvy8c/sac_and_position_control_in_mujoco/",
          "author": null,
          "description": "Hi! I'm currently using garage to simulate a robot EE controlled in position. Does anyone know how to make a relative action? I mean, I would like to have a small action space reinitialized at each step in order to have only small increases in position. Thanks!\n    submitted by    /u/Big-Picture8323  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqvy8c/sac_and_position_control_in_mujoco/",
          "publishedOn": "2022-03-29T09:31:33.000Z",
          "wordCount": 178,
          "title": "SAC and Position Control in Mujoco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tquve2/backpropogation_in_ppo_and_gymai/",
          "author": null,
          "description": "I am currently build a PPO agent for OpenAI gym's Pong environment using Pytorch and I had a question:\n So typically the workflow is:\n  \nUse the state as the input for a CNN and output the action probabilities\n Sample the action distribution for an action and perform env.step(action) with it\n Obtain there rewards and calculate some reward / loss function such as log probs*rewards\n Backpropogate this loss/reward using reward/loss.backward() and optimizer.step()\n  \nNow, Pytorch's loss.backward() and optimizer.step() only calculates and updates gradients for pyTorch Variable objects where requires_grad=True.\n So how does Pytorch backpropogate through env.step() ? env.step() outputs numpy arrays (if you're using a parallel environment) or integers (not tensors)...\n Secondly, if I try to convert a Tensor output to a numpy array to input to env.step() - say an array of actions for parallel environments, it breaks my backpropogation right?\n Thirdly, does that mean that env.step() is a differentiable function?\n Thanks in advance!\n    submitted by    /u/Ska82  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tquve2/backpropogation_in_ppo_and_gymai/",
          "publishedOn": "2022-03-29T08:09:08.000Z",
          "wordCount": 260,
          "title": "Backpropogation in PPO and gym.ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqthpf/policy_gradients_with_pytorch/",
          "author": null,
          "description": "Can someone please explain what \"pw\" is on the third image(marked with arrow) ? \n P.S: First two images are for context\n Thank you!\n ​\n https://preview.redd.it/v9ogmrxvn9q81.png?width=753&format=png&auto=webp&s=4ecfc49aabbf328ecccf468ee01aa3767a7a4c8a\n https://preview.redd.it/4mrnjsxvn9q81.png?width=753&format=png&auto=webp&s=42be60ebaed04468d1b10928ba729327a0057b0f\n https://preview.redd.it/o01n5sxvn9q81.png?width=753&format=png&auto=webp&s=112e876c252e075829c1693cf0f6a5d4751cf79a\n    submitted by    /u/Whole_Run_4485  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqthpf/policy_gradients_with_pytorch/",
          "publishedOn": "2022-03-29T06:27:54.000Z",
          "wordCount": 141,
          "title": "Policy Gradients with Pytorch.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqiwz0/basic_neural_network_robots_learning_by_genetic/",
          "author": null,
          "description": "submitted by    /u/djrobsmith  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqiwz0/basic_neural_network_robots_learning_by_genetic/",
          "publishedOn": "2022-03-28T20:45:14.000Z",
          "wordCount": 165,
          "title": "Basic neural network robots learning by genetic algorithms - survival of the fittest! Crazy simulations - source code included",
          "imageUrl": "https://external-preview.redd.it/rpsGCwLy6-FXq43A4DqVxDmXuj_dd0ApnJcZ5u3pijc.jpg?auto=webp&s=ae5232cd6bfac84b12e83356dd0f2c17db2c1e03"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tqb5xs/decision_transformers_in_transformers_library_and/",
          "author": null,
          "description": "Hey there 👋🏻,\n We’re happy to announce that Edward Beeching from Hugging Face has integrated Decision Transformers an Offline Reinforcement Learning method, into the 🤗 transformers library and the Hugging Face Hub.\n In addition, we share nine pre-trained model checkpoints for continuous control tasks in the Gym environment.\n If you want to know more about Decision Transformers and how to start using it, we wrote a tutorial 👉 https://huggingface.co/blog/decision-transformers\n We would love to hear your feedback about it,\n In the coming weeks and months, we will be extending the reinforcement learning ecosystem by:\n  \nBeing able to train your own Decision Transformers from scratch.\n Integrating RL-baselines3-zoo\n Uploading RL-trained-agents models into the Hub: a big collection of pre-trained Reinforcement Learning agents using stable-baselines3\n Integrating other Deep Reinforcement Learning libraries\n Implementing Convolutional Decision Transformers for Atari\n  \nAnd more to come 🥳, so 📢 The best way to keep in touch is to join our discord server to exchange with us and with the community.\n Thanks,\n    submitted by    /u/cranthir_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tqb5xs/decision_transformers_in_transformers_library_and/",
          "publishedOn": "2022-03-28T14:57:14.000Z",
          "wordCount": 306,
          "title": "Decision Transformers in Transformers library and in Hugging Face Hub 🤗",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tq5zyo/discount_factor_agents_is_available_at_different/",
          "author": null,
          "description": "Assume that the time between two agent actions is not fixed, i.e. depending on the state-action, the agent can become unavailable for a time t = t(s, a). During the time the agent is unavailable, several rewards are produced by the environment, and they need to be given to the agent whenever it becomes available again. \n One easy way to deal with this is to just store them and set the reward at the next available state as the sum of the accumulated rewards. But in the discounted reward framework with temporal difference (e.g. DQN) this does not discount rewards properly. How can I set the reward for the next state such that it contains all the accumulated rewards but it is correct in the DQN setting?\n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tq5zyo/discount_factor_agents_is_available_at_different/",
          "publishedOn": "2022-03-28T10:10:00.000Z",
          "wordCount": 508,
          "title": "Discount factor Agents is available at different rates",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tq5p87/current_stateoftheart_rl_algorithms/",
          "author": null,
          "description": "What are the current best algorithms in Reinforcement Learning? It seems everyone still uses TD3, SAC, PPO, Rainbow DQN, etc. However, these are mostly from 2018, which is old for RL standards. What happened afterwards? What is the current algorithm for these kinds of standard tasks? I'm especially interested in algorithms that can handle continuous action spaces. Thank you very much!\n    submitted by    /u/Paraiso93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tq5p87/current_stateoftheart_rl_algorithms/",
          "publishedOn": "2022-03-28T09:48:53.000Z",
          "wordCount": 553,
          "title": "Current State-of-the-art RL algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tq1667/noob_question_about_bellmans_optimality_principle/",
          "author": null,
          "description": "i'm reading the Sutton-Barto and at page 63 it is written then v_star(s)=max_a q_star(a,s), my question is why we have this? where does it come from? i'm trying to start from the definition of v_star and q_star but I can't really find a way\n    submitted by    /u/samas69420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tq1667/noob_question_about_bellmans_optimality_principle/",
          "publishedOn": "2022-03-28T04:27:02.000Z",
          "wordCount": 686,
          "title": "noob question about Bellman's optimality principle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tppn35/the_first_opensource_project_for_financial/",
          "author": null,
          "description": "submitted by    /u/zicxor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tppn35/the_first_opensource_project_for_financial/",
          "publishedOn": "2022-03-27T18:14:30.000Z",
          "wordCount": 318,
          "title": "The first open-source project for financial reinforcement learning",
          "imageUrl": "https://external-preview.redd.it/45ug6EyVRY8Kgg9V2nIc0xZjs53gFpCOk_zMmkLtRaI.jpg?auto=webp&s=b4b061b8dbc2381f12bac25500212ef1c5c724a1"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tppcom/using_rl_to_play_jump_king/",
          "author": null,
          "description": "I am learning RL by having the algorithm play Jump King and am streaming it on twitch, having the chat play against it as well to see who can get the babe first. Check it out at: https://www.twitch.tv/unassignedseat\n    submitted by    /u/UnassginedSeat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tppcom/using_rl_to_play_jump_king/",
          "publishedOn": "2022-03-27T18:00:56.000Z",
          "wordCount": 158,
          "title": "Using RL to play Jump King",
          "imageUrl": "https://external-preview.redd.it/Ker4NHx7mbudKGfPH_8Rz-o5_jtoReGuUY9WG-gHpc4.jpg?auto=webp&s=f911c7fe42085657e28924bf10f017cfaef8df15"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpoy7s/questiondrl_are_intermediate_activations_used/",
          "author": null,
          "description": "Hello all,\n I have a question regarding optimizing a policy represented by a neural network. In Supervised Learning, the intermediate activations created during the forward pass are needed during backpropagation in order to compute weight gradients. This has led to a number of memory management techniques such as offloading and checkpointing being created.\n My question is whether the same is true in DRL. For policy-gradient methods for example, learning starts from an objective computed from the trajectory such as the discounted returns, but are the intermediate activations created during action inference needed when optimizing the policy (i.e. learning)? \n Is there any academic source that covers this topic? \n Thanks!\n    submitted by    /u/PSylvan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpoy7s/questiondrl_are_intermediate_activations_used/",
          "publishedOn": "2022-03-27T17:41:08.000Z",
          "wordCount": 295,
          "title": "[Question][DRL] Are intermediate activations used during training?",
          "imageUrl": "https://external-preview.redd.it/o-Yq16CmbZYLfCx_y5VsD5fcOiaoLcN-zQO1j3qX2es.jpg?auto=webp&s=546795834d06ed5ac69b13898f1acf1fe4d9f163"
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpj7eq/raveforce_in_2022_the_openai_gym_style_toolkit/",
          "author": null,
          "description": "submitted by    /u/chaosprint  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpj7eq/raveforce_in_2022_the_openai_gym_style_toolkit/",
          "publishedOn": "2022-03-27T12:46:28.000Z",
          "wordCount": 148,
          "title": "RaveForce in 2022: The OpenAI Gym style toolkit for music generation experiments just got better",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpgi0k/is_my_problem_suited_for_solving_via/",
          "author": null,
          "description": "My goal is to determine the best course of actions to take given a certain state. \n I'm working in some state space X. For every x in X, I can assign it a value. When I perform an action a given x, I map x to some new state x'. The state x' depends on my action up to some noise produced by the environment. \n I think this is a reinforcement learning problem. What methods are suitable in this context?\n    submitted by    /u/heylanguage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpgi0k/is_my_problem_suited_for_solving_via/",
          "publishedOn": "2022-03-27T09:34:22.000Z",
          "wordCount": 341,
          "title": "Is my problem suited for solving via reinforcement learning methods? What approach should I start with?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tpbg8h/deck_generation_using_reinforcement_learning/",
          "author": null,
          "description": "A brief overview of the game: A deck of 50 objects are chosen from a set of ~1000 objects. The game is then played out deterministically, and rewards are dished out based on win/loss. \n I would like to build a nn that can produce good decks , trained using self-play. However, I'm not too sure how to approach this problem. Relevant research or pointers would be very helpful. Thanks.\n    submitted by    /u/nutpeabutter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tpbg8h/deck_generation_using_reinforcement_learning/",
          "publishedOn": "2022-03-27T03:24:31.000Z",
          "wordCount": 318,
          "title": "Deck generation using reinforcement learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tp0szc/some_confusions_about_actorcritic_a2c/",
          "author": null,
          "description": "In sutton's book, Actor-Critic firstly uses an approximated value function as a baseline, and uses the error to update the policy. In my opinion, the value function is used as a baseline since it assign high value to state with high expected return, and every action in this state have the same baseline. \n Pseudocode in sutton's book\n But I also see a Q-version of AC algorithm, which use Q function as the baseline. In this algorithm, the Q function is used to update the policy, and the TD error is used to update the Q function. How could we get this?\n Q Actor-critic\n Another question is about AC and A2C. Is expected return (G) minus baseline the same as the advantage function in A2C? If so, is that AC with baseline the same as A2C?\n    submitted by    /u/ZavierTi2021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tp0szc/some_confusions_about_actorcritic_a2c/",
          "publishedOn": "2022-03-26T19:24:15.000Z",
          "wordCount": 248,
          "title": "Some confusions about Actor-Critic, A2C",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tozt3g/is_deep_rl_possible_on_microcontrollers/",
          "author": null,
          "description": "I am thinking of applying the deep rl on small scale robots. I have an Arduino Uno and some servos, so is it possible that deep rl can be applied using Arduino?\n    submitted by    /u/Better-Ad8608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tozt3g/is_deep_rl_possible_on_microcontrollers/",
          "publishedOn": "2022-03-26T18:34:49.000Z",
          "wordCount": 297,
          "title": "Is deep rl possible on microcontrollers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/tovpj0/a_possibly_stupid_question_about_deep_qlearning/",
          "author": null,
          "description": "Hi Guys! I am just starting out in RL and I have a possibly stupid question about deep q-learning. Why do all of the code examples train the model on its own discounted prediction plus the reward, if they could just record all of the rewards in an episode and then calculate the total discounted rewards from the actual rewards the agent got in the episode? At least in my Implementations, the latter strategy seems to outperform the former, both in regard to the time it took the model to converge and the quality of the learned policy.\n    submitted by    /u/KayJersch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/tovpj0/a_possibly_stupid_question_about_deep_qlearning/",
          "publishedOn": "2022-03-26T16:16:26.000Z",
          "wordCount": 680,
          "title": "A possibly stupid question about deep q-learning",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=57341",
          "author": "Vincent Granville",
          "description": "If you are employed as a data scientist and have survived (or strived!) in your position for more than a year, chances are you are at least a good data scientist. This is particularly true if you were promoted. The difference between a mediocre and a good data scientist will be the topic of a… Read More »18 Differences Between Good and Great Data Scientists\nThe post 18 Differences Between Good and Great Data Scientists appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/18-differences-between-good-and-great-data-scientists/",
          "publishedOn": "2022-04-21T04:53:40.000Z",
          "wordCount": 1656,
          "title": "18 Differences Between Good and Great Data Scientists",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/How-Microsoft-Power-BI-Revolutionizes-Business-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57313",
          "author": "Ryan Williamson",
          "description": "As cloud-based business intelligence becomes more and more popular in the market, one name has made quite a mark: Power BI. A Microsoft offering, Power BI is an interactive data visualization and analytics tool that promises to revolutionize business. Here are some of its key benefits to help you see how it can do that:… Read More »How Microsoft Power BI Revolutionizes Business\nThe post How Microsoft Power BI Revolutionizes Business appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-microsoft-power-bi-revolutionizes-business/",
          "publishedOn": "2022-04-20T00:25:10.000Z",
          "wordCount": 874,
          "title": "How Microsoft Power BI Revolutionizes Business",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_181885371.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57307",
          "author": "Indhu",
          "description": "Introduction In recent years technology has become prominent, both at work and at home. Machine learning (ML) and Artificial Intelligence (AI) are evolving quickly today. Almost everyone will have some interaction with a form of AI daily. Some common examples include Siri, Google Maps, Netflix, and Social media (Facebook/Snapchat).AI and ML have popularly used buzzwords… Read More »How AI and ML are transforming data quality management?\nThe post How AI and ML are transforming data quality management? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ai-and-ml-are-transforming-data-quality-management/",
          "publishedOn": "2022-04-20T00:19:25.000Z",
          "wordCount": 1244,
          "title": "How AI and ML are transforming data quality management?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/How-AI-and-ML-are-transforming-data-quality-management3-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57318",
          "author": "Howard M. Wiener",
          "description": "In the previous article in this series, we discussed the difference between Agile and business agility and how Agile 2 addresses some of the omissions and failings of traditional Agile.  Both Agile and Agile 2 focus on accelerating digital development; however, the benefits of any Agile approach can be obviated if it is not implemented… Read More »Agile, Agile 2 and Agility, Part II\nThe post Agile, Agile 2 and Agility, Part II appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/agile-agile-2-and-agility-part-ii/",
          "publishedOn": "2022-04-20T00:18:24.000Z",
          "wordCount": 1339,
          "title": "Agile, Agile 2 and Agility, Part II",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_331775861-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57321",
          "author": "Markus Buhmann",
          "description": "Your regulatory data project likely has no use case for design-time data lineage. tl/dr Mapping Data Lineage at design time, for its own end, has no regulatory use case or ROI.  Buying a specialist tool to support that mapping has even less ROI.  Regulations see that kind of documentary data lineage as ancillary at best.… Read More »Do regulatory data projects really need design-time data lineage? Probably not.\nThe post Do regulatory data projects really need design-time data lineage? Probably not. appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/do-regulatory-data-projects-really-need-design-time-data-lineage-probably-not/",
          "publishedOn": "2022-04-19T23:54:02.000Z",
          "wordCount": 2929,
          "title": "Do regulatory data projects really need design-time data lineage? Probably not.",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_17857338-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57301",
          "author": "Alan Morrison",
          "description": "During the 1990s, the physics community began to measure the brightness of certain supernovae in a novel way. This new method supported the conclusion Edwin Hubble had first arrived at in 1929 after discovering that galaxies are becoming more and more distant from us: Dark matter and dark energy play a role in why those… Read More »Dark Energy, Dark Data\nThe post Dark Energy, Dark Data appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dark-energy-dark-data/",
          "publishedOn": "2022-04-19T07:02:18.000Z",
          "wordCount": 1165,
          "title": "Dark Energy, Dark Data",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_98473600.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57295",
          "author": "Rumzz Bajwa",
          "description": "According to the predictions of Garter, by 2024, distributed cloud computing opportunities will be offered by most cloud vendors on a service basis. With the increasing rush in the cloud space and digitalization of documentation, this industry is bound to grow. Understanding Distributed Cloud Distributed cloud is an innovation to traditional cloud computing. It means… Read More »5 Main Benefits of Distributed Cloud Computing\nThe post 5 Main Benefits of Distributed Cloud Computing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/5-main-benefits-of-distributed-cloud-computing/",
          "publishedOn": "2022-04-19T06:52:25.000Z",
          "wordCount": 1409,
          "title": "5 Main Benefits of Distributed Cloud Computing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_267641356.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57270",
          "author": "ajitjaokar",
          "description": "Healthcare offers one of the biggest areas where AI could impact people. AI in healthcare is already widespread but is expected to grow even further. The global artificial intelligence in healthcare market size was valued at USD 10.4 billion in 2021. It is expected to expand at a compound annual growth rate (CAGR) of 38.4%… Read More »AI and Healthcare: AI as a Triaging Tool for Healthcare\nThe post AI and Healthcare: AI as a Triaging Tool for Healthcare appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-and-healthcare-ai-as-a-triaging-tool-for-healthcare/",
          "publishedOn": "2022-04-18T06:48:30.000Z",
          "wordCount": 762,
          "title": "AI and Healthcare: AI as a Triaging Tool for Healthcare",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_332017031.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57272",
          "author": "Bill Schmarzo",
          "description": "In my first blog of the series “Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed”, I preached about the critical importance of reframing the conversion away from data-driven to becoming value-obsessed. Instead of focusing on becoming value-driven, organizations need to focus on how to uncover the customer, product, service, and operational insights buried in… Read More »Fallacy of Becoming Data-driven – Part 2: Cultural Transformation\nThe post Fallacy of Becoming Data-driven – Part 2: Cultural Transformation appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement-datascience-valueengineering-culturaltransformation/",
          "publishedOn": "2022-04-18T06:16:05.000Z",
          "wordCount": 1614,
          "title": "Fallacy of Becoming Data-driven – Part 2: Cultural Transformation",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_121601343.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57125",
          "author": "Kurt Cagle",
          "description": "As with many fields, knowledge graphs boast a wide array of specialized terms. This guide provides a handy reference to these concepts. Resource Description Framework (RDF) The Resource Description Framework (or RDF) is a conceptual framework established in the early 2000s by the World Wide Web Consortium for describing sets of interrelated assertions. RDF breaks… Read More »A Glossary of Knowledge Graph Terms\nThe post A Glossary of Knowledge Graph Terms appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-glossary-of-knowledge-graph-terms/",
          "publishedOn": "2022-04-18T00:44:04.000Z",
          "wordCount": 2851,
          "title": "A Glossary of Knowledge Graph Terms",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_199726799.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57249",
          "author": "Evan Morris",
          "description": "Data has become a huge area of business, helping businesses to drive their intelligence, make better decisions, and formulate strategic plans for future growth. \nThe post Using Data Warehousing as a Service (DWaaS) To Improve Customer Experience appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/using-data-warehousing-as-a-service-dwaas-to-improve-customer-experience/",
          "publishedOn": "2022-04-17T05:19:21.000Z",
          "wordCount": 2109,
          "title": "Using Data Warehousing as a Service (DWaaS) To Improve Customer Experience",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_452879295.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57255",
          "author": "Stephanie Glen",
          "description": "The LIGO observatory can detect astronomical events from billions of light years away. Terabytes of complex daily data makes human analysis impossible. New study applies neural network with up to 97% classification accuracy. Caltech/MIT’s LIGO, the largest gravitational-wave observatory in the world, collects data on minute space-time ripples from cataclysmic astronomical events like colliding black… Read More »ML classifies gravitational-wave glitches with high accuracy\nThe post ML classifies gravitational-wave glitches with high accuracy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ml-classifies-gravitational-wave-glitches-with-high-accuracy/",
          "publishedOn": "2022-04-17T05:14:01.000Z",
          "wordCount": 1119,
          "title": "ML classifies gravitational-wave glitches with high accuracy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_103089241-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57141",
          "author": "Edward Nick",
          "description": "The central principle of the Zero Trust model is based on the authentication and verification of every device connecting to the network before they are trusted. Former Forrester analyst and veteran of the high-technology world, John Kindervag, who has been actively part of a wide array of network technology projects, coined the term “Zero Trust”… Read More »Zero Trust Principles: What is Zero Trust Model?\nThe post Zero Trust Principles: What is Zero Trust Model? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/zero-trust-principles-what-is-zero-trust-model/",
          "publishedOn": "2022-04-17T04:56:05.000Z",
          "wordCount": 1114,
          "title": "Zero Trust Principles: What is Zero Trust Model?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_428848357.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57227",
          "author": "Ryan Williamson",
          "description": "Businesses today face myriad challenges, some of which are successfully addressed with help from cloud computing. This is where AWS cloud migration which promises to be a boon for businesses grappling with a sudden increase in traffic or for those who are looking for accelerated app deployment. It is also handy for cautious businesses that… Read More »AWS Cloud Migration: All You Need to Know\nThe post AWS Cloud Migration: All You Need to Know appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/aws-cloud-migration-all-you-need-to-know/",
          "publishedOn": "2022-04-15T18:12:19.000Z",
          "wordCount": 939,
          "title": "AWS Cloud Migration: All You Need to Know",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_488897244.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57232",
          "author": "Ryan Solecki",
          "description": "What is Artificial Intelligence? Oxford Languages defines AI as the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages. For those of us working in the realm of digital marketing, the impact has become even more clear over… Read More »How AI is Changing Digital Marketing\nThe post How AI is Changing Digital Marketing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ai-is-changing-digital-marketing/",
          "publishedOn": "2022-04-14T05:26:11.000Z",
          "wordCount": 1305,
          "title": "How AI is Changing Digital Marketing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_209957900.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57219",
          "author": "Edouard d'Archimbaud",
          "description": "With the constant rise and use of technology, Artificial Intelligence (AI) has become a great companion to compliance. Compliance is one of the biggest playing fields and plays a pivotal role in banking institutions. It aims to identify, diminish, and manage risks such as insider trading, spoofing attacks, exploitation of the market, front-running, and more by… Read More »AI For Compliance: What, Why, How\nThe post AI For Compliance: What, Why, How appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-for-compliance-what-why-how/",
          "publishedOn": "2022-04-14T05:19:25.000Z",
          "wordCount": 2606,
          "title": "AI For Compliance: What, Why, How",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_407673910.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57214",
          "author": "Indhu",
          "description": "While data compliance is the practice of organizations ensuring that all sensitive data is managed and organized in a way that enables them to meet their business rules alongside legal and governmental regulations, data governance involves the process of managing organizational data’s usability, security, availability, and quality using the internally set rules and policies. Data… Read More »Benefits of Data Governance and Compliance\nThe post Benefits of Data Governance and Compliance appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/benefits-of-data-governance-and-compliance/",
          "publishedOn": "2022-04-14T05:00:39.000Z",
          "wordCount": 781,
          "title": "Benefits of Data Governance and Compliance",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_360525944.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57134",
          "author": "EdwardNick",
          "description": "Technical dissertation writing sometimes seems impossible until it is done. A dissertation is among the lengthiest tasks that can take months to get completed. Thus, it exhausts students, but there is no way around it. It is worth more than about 60 credits in a thesis-based degree. Moreover, gathering proper knowledge and top guidelines about… Read More »How To Write A Technical Dissertation\nThe post How To Write A Technical Dissertation appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-write-a-technical-dissertation/",
          "publishedOn": "2022-04-14T04:32:09.000Z",
          "wordCount": 1359,
          "title": "How To Write A Technical Dissertation",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_310151102-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57178",
          "author": "Aileen Scott",
          "description": "Globally, many think that data scientist is the best job after Harvard declared it to be one of the hottest jobs of the decade.  And since then, many have been choosing it as their career path. But the role of a data engineer is as important as the data scientist is, because if a data… Read More »Why Data Engineers are in Greater Demand than Data Scientists\nThe post Why Data Engineers are in Greater Demand than Data Scientists appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/why-data-engineers-are-in-greater-demand-than-data-scientists/",
          "publishedOn": "2022-04-14T04:19:24.000Z",
          "wordCount": 943,
          "title": "Why Data Engineers are in Greater Demand than Data Scientists",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_216677722.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57182",
          "author": "Bill Schmarzo",
          "description": "I’m sure we all remember the story of “The Little Engine That Could.” A little railroad engine was built for pulling a few cars on and off the switches. When more powerful engines are asked to pull a load over a steep hill, they respond “I can’t; that is too much a pull for me”.… Read More »Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed\nThe post Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datascience-datamanagement-valueengineering/",
          "publishedOn": "2022-04-13T21:27:31.000Z",
          "wordCount": 1780,
          "title": "Fallacy of Becoming Data-driven – Part 1: Becoming Value-obsessed",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Slide1-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57192",
          "author": "Kurt Cagle",
          "description": "The Los Angeles Times recently reported on a growing problem not just for California School Districts, but across much of the Northern Hemisphere: The number of children entering school has been dropping steadily for five years now, and is changing the dynamics of education. What’s worse, those declines are accelerating. Sometimes understanding the future comes… Read More »DSC Weekly Digest 4/12/2022: Demographics Drives Analytics\nThe post DSC Weekly Digest 4/12/2022: Demographics Drives Analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-4-12-2022-demographics-drives-analytics/",
          "publishedOn": "2022-04-13T02:26:00.000Z",
          "wordCount": 1840,
          "title": "DSC Weekly Digest 4/12/2022: Demographics Drives Analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_42581461.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57202",
          "author": "Avani Trivedi",
          "description": "IoT and Machine Learning are the most advanced and evolving technologies that continue to rise in today’s modern world, simplifying human efforts and making lives easier. These technologies have proved to streamline operations and workflows for various industries and provide more robust and scalable applications that allow users to make things done seamlessly.  In recent… Read More »How IoT Uses Machine Learning To Change The World\nThe post How IoT Uses Machine Learning To Change The World appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-iot-uses-machine-learning-to-change-the-world/",
          "publishedOn": "2022-04-12T22:09:51.000Z",
          "wordCount": 1766,
          "title": "How IoT Uses Machine Learning To Change The World",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_263282426.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57115",
          "author": "Jessica Gupta",
          "description": "Recent advances in machine learning (ML) and artificial intelligence (AI) technologies are helping enterprises across industries quickly move from their use cases from the pilot stage to production and operationalization. According to a report by McKinsey & Company, by 2030, businesses that fully absorb AI could double their cash flow, while companies that don’t could… Read More »Drag-and-drop Data Pipelining: The Next Disruptor in ML\nThe post Drag-and-drop Data Pipelining: The Next Disruptor in ML appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/drag-and-drop-data-pipelining-the-next-disruptor-in-ml/",
          "publishedOn": "2022-04-12T19:05:34.000Z",
          "wordCount": 978,
          "title": "Drag-and-drop Data Pipelining: The Next Disruptor in ML",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_473384696-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57133",
          "author": "Nikita Godse",
          "description": "As the Internet of Things (IoT) is gradually moving from being a centralized structure to a more complex network of innumerable decentralized smart devices, the need for security of data will be acknowledged to a greater degree, thereby promoting the expansion of the global IoT security market. The larger the volume of the data transferred… Read More »Advances Highlight the Future of IoT Security\nThe post Advances Highlight the Future of IoT Security appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/advances-highlight-the-future-of-iot-security/",
          "publishedOn": "2022-04-12T18:55:02.000Z",
          "wordCount": 782,
          "title": "Advances Highlight the Future of IoT Security",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/IoT.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57156",
          "author": "Vincent Granville",
          "description": "The success and growth of AI is undeniable. Yet there are still basic tasks performing poorly, despite or because of automation. In some cases, you can blame reliance on outdated AI. In other cases, it is a result of corporate policies or multiple AI systems that compete against each other. The AI systems in question… Read More »6 Business Applications that Badly Need Better AI\nThe post 6 Business Applications that Badly Need Better AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/6-business-applications-that-badly-need-better-ai/",
          "publishedOn": "2022-04-10T19:51:00.000Z",
          "wordCount": 2143,
          "title": "6 Business Applications that Badly Need Better AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/ver.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57148",
          "author": "ajitjaokar",
          "description": "How exactly do you define Artificial Intelligence(AI)? This looks like a back to basics/ back to school question – but the answer is not that simple Recently I was trying to find a good academic definition of AI for a research paper. Surprisingly, its not easy. In this post, I present a good definition for… Read More »How exactly do you define Artificial Intelligence(AI)?\nThe post How exactly do you define Artificial Intelligence(AI)? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-exactly-do-you-define-artificial-intelligenceai/",
          "publishedOn": "2022-04-10T19:44:52.000Z",
          "wordCount": 644,
          "title": "How exactly do you define Artificial Intelligence(AI)?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_213593664.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57153",
          "author": "Stephanie Glen",
          "description": "There are signs that Meta’s plans for the metaverse is faltering, including plummeting stock prices and the company’s announcement that it may withdraw from the EU market. The troubles stem from a myriad of issues, the most significant of which are data collection privacy issues and a lack of investor and public confidence in the… Read More »Public wary of Meta’s Metaverse vision\nThe post Public wary of Meta’s Metaverse vision appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/public-wary-of-metas-metaverse-vision/",
          "publishedOn": "2022-04-10T18:45:35.000Z",
          "wordCount": 1261,
          "title": "Public wary of Meta’s Metaverse vision",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_24686652-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57139",
          "author": "Saurabh Ajmera",
          "description": "NLQ or Natural Language Query or Text-to-SQL or NL2SQL is an arm of computational linguistics, that helps users to fetch required data, visualizations, and insights, from sentences written in human language. As a business user, knowing data schema, table and column names, knowing metadata, having technical know-how of a BI tool or data querying skills… Read More »NLQ: Why You Might Not Need To Call A Data Analyst Anymore\nThe post NLQ: Why You Might Not Need To Call A Data Analyst Anymore appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/nlq-decreasing-reasons-to-call-a-data-analyst/",
          "publishedOn": "2022-04-10T17:56:50.000Z",
          "wordCount": 1198,
          "title": "NLQ: Why You Might Not Need To Call A Data Analyst Anymore",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_398273679.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57110",
          "author": "Aileen Scott",
          "description": "Profession in finance and accounting is one of the top career choices for finance and accounting professionals. Employment of accountants and auditors is projected to grow 7 percent from the year 2020 to the year 2030, about as fast as the average for all occupations. About 135,000 openings for accountants and auditors are projected each year,… Read More »Advance in your finance and accounting careers with top technical skills\nThe post Advance in your finance and accounting careers with top technical skills appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/advance-in-your-finance-and-accounting-careers-with-top-technical-skills/",
          "publishedOn": "2022-04-10T17:31:42.000Z",
          "wordCount": 1013,
          "title": "Advance in your finance and accounting careers with top technical skills",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_229918556.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57118",
          "author": "Ryan Williamson",
          "description": "AI has been making a lot of noise of late, especially in the context of software development. Of course, this topic is quite wide, but in this article, we shall focus our attention on AI-driven automation testing. Let us start with understanding what is AI and automation testing. Automation testing refers to the process of… Read More »Artificial Intelligence: Benefits for Automation Testing\nThe post Artificial Intelligence: Benefits for Automation Testing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/artificial-intelligence-benefits-for-automation-testing/",
          "publishedOn": "2022-04-08T06:38:59.000Z",
          "wordCount": 938,
          "title": "Artificial Intelligence: Benefits for Automation Testing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/max-duzij-qAjJk-un3BI-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57114",
          "author": "Sameer Narkhede",
          "description": "‍What is the shortest distance between two points? A straight line of course. What if there are multiple points? Then, it depends.  A job executed in response to a user action – refreshing a dashboard, aggregating data, building a report, developing an ML algorithm, performing analytics – all require multiple hops through the data ecosystem.… Read More »Data Observability: Cracking the Code\nThe post Data Observability: Cracking the Code appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-observability-cracking-the-code/",
          "publishedOn": "2022-04-07T15:12:45.000Z",
          "wordCount": 1386,
          "title": "Data Observability: Cracking the Code",
          "imageUrl": "https://global-uploads.webflow.com/60ddb7e2e50eaef5bec9595c/624723032cf27f425fe3b49f_BtB8gMQkm1dSTaM6a-zrNRmjPuSL8lIM3WYayENdLoYxbusnO6wJp6Sr-JPhqZ2DgPlA66GvQozKd4nNpOxuXjeZGP2o2FkXe5j-lYz58FaEvCTAeaDWkCub8UeocK6tzk1_IO4p.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57050",
          "author": "Kurt Cagle",
          "description": "For nine years, my family and I have lived in a house in Issaquah, a little community about twenty minutes east of Seattle. The town still retains its charms — a downtown area about three blocks long that includes a vintage (and long since decommissioned) gas station, numerous restaurants, a live theater, the library, and… Read More »DSC Weekly Digest: Moving Time\nThe post DSC Weekly Digest: Moving Time appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-moving-time/",
          "publishedOn": "2022-04-06T15:01:18.000Z",
          "wordCount": 2105,
          "title": "DSC Weekly Digest: Moving Time",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_99749434.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57061",
          "author": "Bill Schmarzo",
          "description": "When I was the Vice President of Advertiser Analytics at Yahoo!, I painfully learned that my targeted user personas (Media Planners & Buyers and Campaign Managers) didn’t want more data in helping them optimize their marketing, campaign, and advertising spend across the Yahoo! Ad Network.  Heck, they didn’t even want analytics!  The aspirations for these… Read More »Building a Data Products-centric Business Model\nThe post Building a Data Products-centric Business Model appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement-ai-iot-ml/",
          "publishedOn": "2022-04-05T20:31:31.000Z",
          "wordCount": 1620,
          "title": "Building a Data Products-centric Business Model",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_203382343.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57077",
          "author": "German Osin",
          "description": "Real-world production ML systems consist of two main components: data and code. Data is clearly the leader, and rapidly taking center stage. Data defines the quality of almost any ML-based product, more so than code or any other aspect. In Feature Store as a Foundation for Machine Learning, we have discussed how feature stores are… Read More »Data Discovery for ML Engineers\nThe post Data Discovery for ML Engineers appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-discovery-for-ml-engineers/",
          "publishedOn": "2022-04-05T19:14:14.000Z",
          "wordCount": 2588,
          "title": "Data Discovery for ML Engineers",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/cyber-g4c6392d4b_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57035",
          "author": "EdwardNick",
          "description": "Many things can help you to write good dissertations. One of the most important is to use content metrics. It is necessary for all of the students to understand content metrics in detail. A clear understanding of its types and measuring strategies help you to evaluate things in a precise way. Whatever is your topic… Read More »Content Metrics That Can Help You To Write  Dissertations\nThe post Content Metrics That Can Help You To Write  Dissertations appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/content-metrics-that-can-help-you-to-write-dissertations/",
          "publishedOn": "2022-04-05T18:24:50.000Z",
          "wordCount": 1365,
          "title": "Content Metrics That Can Help You To Write  Dissertations",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/Content-Metrics-That-Can-Help-You-To-Write-Best-Audiences.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57075",
          "author": "Karen Anthony",
          "description": "The need of a highly functional and fast processing Central Processing Unit (CPU) in today’s world is not just mostly desired, but also mostly required due to the rapid digitalization across the globe. Whether you work on a personal computer (PC) unit or laptop, the necessity of a highly advanced processor is indispensable.  This is… Read More »Comparative analysis of an Intel and AMD Processor\nThe post Comparative analysis of an Intel and AMD Processor appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/comparative-analysis-of-an-intel-and-amd-processor/",
          "publishedOn": "2022-04-05T18:16:54.000Z",
          "wordCount": 879,
          "title": "Comparative analysis of an Intel and AMD Processor",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_408036566.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57089",
          "author": "Aileen Scott",
          "description": "How does artificial intelligence Diversity, Equity, and Inclusion (DEI) fit into the technological stack of daily companies? Fostering a diverse workforce is a very human problem. The cry for a halt to race prejudice has become deafening, and it’s increasingly a decisive factor for talent when weighing job offers and purchases. To stay up with the… Read More »AI And Its Impact On Diversity And Inclusion\nThe post AI And Its Impact On Diversity And Inclusion appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-and-its-impact-on-diversity-and-inclusion/",
          "publishedOn": "2022-04-05T17:04:16.000Z",
          "wordCount": 1132,
          "title": "AI And Its Impact On Diversity And Inclusion",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_469423570.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57056",
          "author": "Kerry Pearce",
          "description": "Understanding consumer behavior is becoming more and more critical as businesses seek to find innovative ways to survive and thrive in a period of constant change. In the last few years, the market has seen significant changes in the way people shop, travel, dine and purchase goods. As a business, when it comes to understanding… Read More »How Data Intelligence Platforms Promote Business Success\nThe post How Data Intelligence Platforms Promote Business Success appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-data-intelligence-platforms-promote-business-success/",
          "publishedOn": "2022-04-05T06:12:10.000Z",
          "wordCount": 1211,
          "title": "How Data Intelligence Platforms Promote Business Success",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_140495395.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57040",
          "author": "ajitjaokar",
          "description": "I read an article from the world economic forum which proposed an AI labeling system for AI products designed for children Today, for the first time, children are growing up in a world shaped by artificial intelligence (AI) and decisions are being made for children implicitly by AI.  Algorithms need data that is collected and… Read More »Exploring AI labeling for children’s products\nThe post Exploring AI labeling for children’s products appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/exploring-ai-labeling-for-childrens-products/",
          "publishedOn": "2022-04-05T06:06:34.000Z",
          "wordCount": 821,
          "title": "Exploring AI labeling for children’s products",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_375140801.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57058",
          "author": "Scott Thompson",
          "description": "In the previous part, we discussed the current state of data imaging tools in healthcare and the future applications of these technologies. While increased access to information is invaluable to physicians, they can still be limited by their own ability to interpret, or the physical limitations of their surgical ability. In addition to augmenting the… Read More »Data Augmented Healthcare Part 2\nThe post Data Augmented Healthcare Part 2 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-augmented-healthcare-part-2/",
          "publishedOn": "2022-04-04T17:41:15.000Z",
          "wordCount": 826,
          "title": "Data Augmented Healthcare Part 2",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_330431239.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57029",
          "author": "Ryan Williamson",
          "description": "Artificial intelligence has been long making waves globally, empowering companies from across the broad spectrum of industries to take their businesses to the next level. So it is no surprise that this technology is making inroads in the grocery retail space, helping grocers deliver personalized and irreproachable experiences across different channels, establishing improved customer loyalty,… Read More »Top Ways in Which AI Impacts Grocery Retail\nThe post Top Ways in Which AI Impacts Grocery Retail appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-ways-in-which-ai-impacts-grocery-retail/",
          "publishedOn": "2022-04-03T21:47:26.000Z",
          "wordCount": 953,
          "title": "Top Ways in Which AI Impacts Grocery Retail",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/04/AdobeStock_311618017.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57026",
          "author": "Alan Morrison",
          "description": "Data is useless if it doesn’t shed light. The more light it sheds on the most acute problems businesses face, the better. Within this context, data synergy–data from multiple sources and disciplines that is more valuable than the sum of its parts–is often underappreciated. With data synergy, the light can be in many more places,… Read More »A different take on business intelligence\nThe post A different take on business intelligence appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-different-take-on-business-intelligence/",
          "publishedOn": "2022-04-03T21:05:49.000Z",
          "wordCount": 1234,
          "title": "A different take on business intelligence",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/waves-gacea61272_1920.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57017",
          "author": "Stephanie Glen",
          "description": "Blockchain is widely touted as a mechanism for securing digital property. Multiple problems exist for driving metaverse transactions. A new review highlights the challenges, some of which may be insurmountable. Blockchain has been touted as a potential solution to securing users’ digital content and data due to its decentralization, immutability, and transparency. However, there are… Read More »Blockchain Won’t Save The Metaverse\nThe post Blockchain Won’t Save The Metaverse appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/blockchain-wont-save-the-metaverse/",
          "publishedOn": "2022-04-03T20:31:44.000Z",
          "wordCount": 1065,
          "title": "Blockchain Won’t Save The Metaverse",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_278111994-1.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57019",
          "author": "Vincent Granville",
          "description": "I tested the job market in the last two weeks, both as an applicant, and as a hiring manager. I share my experience here. It is radically different from what you read in the news, or from what most people say. Data scientists and machine learning engineers looking for a new job are out there.… Read More »The Myth of Analytic Talent Shortage\nThe post The Myth of Analytic Talent Shortage appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/debunking-the-myth-of-analytic-talent/",
          "publishedOn": "2022-03-31T23:01:31.000Z",
          "wordCount": 1849,
          "title": "The Myth of Analytic Talent Shortage",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_252351555.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57007",
          "author": "Rex Ahlstrom",
          "description": "By Rex Ahlstrom, CTO & EVP Growth & Innovation, Syniti   The modern enterprise is composed of a variety of systems, each of which holds data the company needs to conduct business: information about products, services, suppliers, customers, and more. This is the master data, and master data collected by these disparate systems is often stored… Read More »The Increasing Importance of Master Data Management for Your Business: A Primer\nThe post The Increasing Importance of Master Data Management for Your Business: A Primer appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-increasing-importance-of-master-data-management-for-your-business-a-primer/",
          "publishedOn": "2022-03-30T05:49:33.000Z",
          "wordCount": 1505,
          "title": "The Increasing Importance of Master Data Management for Your Business: A Primer",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_392825932-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=57012",
          "author": "Kurt Cagle",
          "description": "The Biden Administration made a recent announcement that it was setting up an exploratory committee for the creation of an e-Currency taskforce. In conjunction with this, a new bill, the Electronic Currency and Secure Hardware (ECASH) Act, was introduced by Rep. Stephen Lynch (MA-08), Chair of the House Committee on Financial Services’ Task Force on… Read More »How ECash Will Change The Economy\nThe post How ECash Will Change The Economy appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ecash-will-change-the-economy/",
          "publishedOn": "2022-03-30T03:19:56.000Z",
          "wordCount": 1299,
          "title": "How ECash Will Change The Economy",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_2860358-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56990",
          "author": "Kurt Cagle",
          "description": "DSC Weekly Digest 29 March 2022 Back in September, I made a prediction: Covid-19 would spike throughout the winter but fade by April as it transitioned from being a pandemic virus to an endemic one. As it turns out, I was mostly correct. Here in Washington State, we finally dropped the mask mandate that had… Read More »Transitions and the Arc of Systems Theory\nThe post Transitions and the Arc of Systems Theory appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-digest-29-march-2022-transitions-and-the-arc-of-systems-theory/",
          "publishedOn": "2022-03-30T00:46:17.000Z",
          "wordCount": 1818,
          "title": "Transitions and the Arc of Systems Theory",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_492175313.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56998",
          "author": "James Wilson",
          "description": "Inventory management is an essential part of any eCommerce business. Especially if you are an eCommerce business owner juggling multiple sales channels, it can save you a lot of effort. However, manually managing your inventories is also a recipe for error. Also, let’s not forget the time you have to spend and the painful process… Read More »Automated Inventory Management System: An Ultimate Guide for 2022 and Beyond\nThe post Automated Inventory Management System: An Ultimate Guide for 2022 and Beyond appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/automated-inventory-management-system-an-ultimate-guide-for-2022-and-beyond/",
          "publishedOn": "2022-03-29T13:58:59.000Z",
          "wordCount": 1385,
          "title": "Automated Inventory Management System: An Ultimate Guide for 2022 and Beyond",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_410872963.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56966",
          "author": "EdwardNick",
          "description": "Statistics gives business owners the freedom to evaluate how their websites are performing. The evaluation involves a couple of things: the bounce rate and the exit rate. But what is the difference between bounce rate and exit rate? This is a point of discussion that requires you to have an open mind to grasp the… Read More »What is the Difference Between Bounce Rate and Exit Rate?\nThe post What is the Difference Between Bounce Rate and Exit Rate? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/what-is-the-difference-between-bounce-rate-and-exit-rate/",
          "publishedOn": "2022-03-29T02:21:21.000Z",
          "wordCount": 1423,
          "title": "What is the Difference Between Bounce Rate and Exit Rate?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_252969949.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56972",
          "author": "ImensoSoftware",
          "description": "There is no denying the importance of the internet and IT in the business scene. Businesses hailing from all sectors are dependent on the web, and they also make use of various types of software applications nowadays. However, with time, such technologies are also evolving. Businesses are coping with huge amounts of data, and to… Read More »Five Major Benefits That Microsoft Power BI Brings To Data Scientists\nThe post Five Major Benefits That Microsoft Power BI Brings To Data Scientists appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/five-major-benefits-that-microsoft-power-bi-brings-to-data-scientists/",
          "publishedOn": "2022-03-29T01:20:33.000Z",
          "wordCount": 1360,
          "title": "Five Major Benefits That Microsoft Power BI Brings To Data Scientists",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_335428295.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56916",
          "author": "Bill Schmarzo",
          "description": "We are in the middle of a business model revolution.  And we are active participants in that revolution.  We have been transitioning from a society where possession and application of physical commodities defined wealth and power, to a society where possession and application of knowledge define wealth and power.  Throughout the 20th century, oil had… Read More »What’s Your Business Model Choice – Hammers or Casino?\nThe post What’s Your Business Model Choice – Hammers or Casino? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datastrategist-datamanagement/",
          "publishedOn": "2022-03-28T16:59:40.000Z",
          "wordCount": 2166,
          "title": "What’s Your Business Model Choice – Hammers or Casino?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_286434477.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56969",
          "author": "Karen Anthony",
          "description": "It is common for growing organizations to reach a point where their existing data solution is no longer adequate for their needs. In most cases, it happens with companies that have used an on-premises infrastructure from the earliest days of business but now need to upgrade their network for continued growth. However, relocating equipment and… Read More »Datacenter relocation is now easier, faster, and more affordable\nThe post Datacenter relocation is now easier, faster, and more affordable appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/datacenter-relocation-is-now-easier-faster-and-more-affordable/",
          "publishedOn": "2022-03-28T13:21:51.000Z",
          "wordCount": 875,
          "title": "Datacenter relocation is now easier, faster, and more affordable",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_252351555.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56948",
          "author": "Stephanie Glen",
          "description": "Astronomy has seen an exponential rise in data collection over the last decade. This requires new methods for data analysis, including AI. With the launch of new surveys, big data methodology has become a necessity. A new class of extremely large telescopes has evolved to collect vast amounts of data; The volume of data collected… Read More »The Evolution of Astronomical AI\nThe post The Evolution of Astronomical AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-evolution-of-astronomical-ai/",
          "publishedOn": "2022-03-28T13:14:39.000Z",
          "wordCount": 1172,
          "title": "The Evolution of Astronomical AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_285562989.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56905",
          "author": "Andrey Koptelov",
          "description": "When such a sophisticated, risky, and complex technology like AI takes our lives by storm, a clearly defined set of rules on its usage is paramount. Previously, public concern was mostly focused on the inappropriate use of personal data. As AI becomes a key technology in many businesses and services, the attention is rightfully shifting… Read More »What to Do About the New AI Regulation?\nThe post What to Do About the New AI Regulation? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/what-to-do-about-the-new-ai-regulation/",
          "publishedOn": "2022-03-28T05:05:44.000Z",
          "wordCount": 1343,
          "title": "What to Do About the New AI Regulation?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/thisisengineering-raeng-8hgmG03spF4-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56710",
          "author": "Rumzz Bajwa",
          "description": "From chatbots and other remote helpers to producing content, improving client encounters, AI companies are now rolling out significant improvements to the advanced promoting scene. While it might be hard to foresee what’s to come, it’s not difficult to see that AI will proceed to advance and assume an undeniably focal point in computerized advertising.… Read More »How Automation and AI Are Changing Internet Marketing\nThe post How Automation and AI Are Changing Internet Marketing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-automation-and-ai-are-changing-internet-marketing/",
          "publishedOn": "2022-03-28T05:03:28.000Z",
          "wordCount": 1204,
          "title": "How Automation and AI Are Changing Internet Marketing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_238361901.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56797",
          "author": "Sonia Mathias",
          "description": "What is Data Science? Data science is a study that helps us to extract information from a set of structured or unstructured data. It makes use of the study of statistics, mathematics, scientific computation to analyze the data.  Demand for Python in Data Science: Before we deep dive into the topic let’s firstly discuss why… Read More »How Python Became THE Language for Data Science\nThe post How Python Became THE Language for Data Science appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-python-became-the-language-for-data-science/",
          "publishedOn": "2022-03-28T04:58:08.000Z",
          "wordCount": 2042,
          "title": "How Python Became THE Language for Data Science",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_283882447.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56924",
          "author": "Kerry Pearce",
          "description": "In today’s landscape, businesses need to look for any competitive advantage they can to ensure their survival, growth and success. A key aspect of gaining a competitive advantage is using data-driven insights to empower decisions for marketing, consumer insights, consumer segmentation, and operations, such as merchandising and real estate.  Especially within large companies, it is… Read More »Three Critical Steps for Data-Driven Success\nThe post Three Critical Steps for Data-Driven Success appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/three-critical-steps-for-data-driven-success/",
          "publishedOn": "2022-03-28T04:52:42.000Z",
          "wordCount": 1259,
          "title": "Three Critical Steps for Data-Driven Success",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_270256472.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56894",
          "author": "Indhu",
          "description": "Data governance is the management of organizations’ data availability, usability, integrity, security, and privacy. According to Gartner, Data governance is the specification of decision rights and a framework for accountability to assure acceptable behavior in the value, generation, consumption, and control of data and analytics. Why Do Organizations Need It? It ensures that data is consistent,… Read More »Data Governance Tool: What To Look For?\nThe post Data Governance Tool: What To Look For? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-governance-tool-what-to-look-for/",
          "publishedOn": "2022-03-28T04:38:53.000Z",
          "wordCount": 770,
          "title": "Data Governance Tool: What To Look For?",
          "imageUrl": null
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56908",
          "author": "EdwardNick",
          "description": "Introduction Security is the buzzword for the digital world today. Businesses have realized that thriving and surviving without a well-functioning security system in place is tough. Security breaches, malware, ransomware and similar incidents are real. The businesses that have suffered from malicious attacks very well know how grave these attacks can be.  The importance of… Read More »Top MDM-Enabled Data Security Hacks You Should Know About\nThe post Top MDM-Enabled Data Security Hacks You Should Know About appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-mdm-enabled-data-security-hacks-you-should-know-about/",
          "publishedOn": "2022-03-28T04:24:35.000Z",
          "wordCount": 1606,
          "title": "Top MDM-Enabled Data Security Hacks You Should Know About",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_124464399-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56911",
          "author": "Howard M. Wiener",
          "description": "If you are running a business today using Agile methods, it’s likely that you are not getting the productivity boost from it that you should, and your time to market for new features is probably not what it could be either. Is that the end of the world?  By and large, yes!  The problem is… Read More »Agile, Agile 2 and Agility, Part I\nThe post Agile, Agile 2 and Agility, Part I appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/agile-agile-2-and-agility-part-i/",
          "publishedOn": "2022-03-27T23:54:24.000Z",
          "wordCount": 1447,
          "title": "Agile, Agile 2 and Agility, Part I",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_233869090.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56926",
          "author": "Nikita Godse",
          "description": "The dynamics of the global commercial artificial intelligence market continues to change over time, thanks to the persistent advancements in technology. This research report offers a detailed and insightful assessment of the global commercial artificial intelligence market, taking primary trends and the future prospects of this market in consideration. Various segments of this market, based on a… Read More »Commercial Artificial Intelligence — The Future of BI\nThe post Commercial Artificial Intelligence — The Future of BI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/commercial-artificial-intelligence-the-future-of-bi/",
          "publishedOn": "2022-03-27T23:29:31.000Z",
          "wordCount": 941,
          "title": "Commercial Artificial Intelligence — The Future of BI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/commercial-AI.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56941",
          "author": "ajitjaokar",
          "description": "One of the best known examples of GPT-3 for developers is the Github co-pilot Trained on billions of lines of public code, GitHub Copilot is more than autocomplete of code. GitHub Copilot is powered by Codex, the new AI system created by OpenAI. GitHub Copilot understands significantly more context than most code assistants. GitHub Copilot… Read More »GitHub Co-Pilot Alternatives: Can They Match the Functionality of Co-Pilot?\nThe post GitHub Co-Pilot Alternatives: Can They Match the Functionality of Co-Pilot? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-do-github-co-pilot-alternatives-work-and-can-they-match-the-functionality-of-co-pilot/",
          "publishedOn": "2022-03-27T23:00:41.000Z",
          "wordCount": 858,
          "title": "GitHub Co-Pilot Alternatives: Can They Match the Functionality of Co-Pilot?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_303166297.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56789",
          "author": "Lewis Wynne-Jones",
          "description": "Increasingly, companies are focused on finding ways to connect to new and valuable sources of data in order to enhance their analytical capabilities, enrich their models, or deliver more insight to their business units.  Due to the increased demand for new data sources, companies are also looking at their internal data differently. Organizations that have… Read More »Five Key Components of a Data Sharing Platform\nThe post Five Key Components of a Data Sharing Platform appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/five-key-components-of-a-data-sharing-platform/",
          "publishedOn": "2022-03-27T20:40:07.000Z",
          "wordCount": 2042,
          "title": "Five Key Components of a Data Sharing Platform",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_267227310.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56785",
          "author": "Eric Whitley",
          "description": "Despite the technological breakthroughs in the advent of Industry 4.0, manufacturers seem to have taken a more gradual approach to adoption. In 2020, less than 30 percent of the industry considered themselves extensive users of advanced integrated tools and processes. The pandemic, however, brought out an unprecedented need to explore opportunities that make manufacturing systems… Read More »Smart Maintenance – How SaaS Frameworks Turn Insights Into Actions Quickly And Efficiently\nThe post Smart Maintenance – How SaaS Frameworks Turn Insights Into Actions Quickly And Efficiently appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/smart-maintenance-how-saas-frameworks-turn-insights-into-actions-quickly-and-efficiently/",
          "publishedOn": "2022-03-27T19:10:19.000Z",
          "wordCount": 1478,
          "title": "Smart Maintenance – How SaaS Frameworks Turn Insights Into Actions Quickly And Efficiently",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_124464399.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56930",
          "author": "Aileen Scott",
          "description": "What is the toll-free number? Businesses provide a cloud-based contact number to allow customers to contact them free of cost. In India, this number- the business toll-free number is available in the 1800 series in an easily recognizable format- 1800-ABC-DEFG. Customers do not have to incur any fee to contact the business, as the company… Read More »Toll-free number: What is it, and how can you get one for your business?\nThe post Toll-free number: What is it, and how can you get one for your business? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/toll-free-number-what-is-it-and-how-can-you-get-one-for-your-business/",
          "publishedOn": "2022-03-27T08:41:11.000Z",
          "wordCount": 1212,
          "title": "Toll-free number: What is it, and how can you get one for your business?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/AdobeStock_481168446.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=56931",
          "author": "Ryan Williamson",
          "description": "With the exponential growth in the number of big data applications in the world, Testing in big data applications is related to database, infrastructure and performance testing, and functional testing. The advancement of technology is enabling the collection of a massive amount of data almost every second. And, big data has emerged as the buzzword… Read More »Top Strategies and Best Practices for Big Data Testing\nThe post Top Strategies and Best Practices for Big Data Testing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-strategies-and-best-practices-for-big-data-testing/",
          "publishedOn": "2022-03-27T07:42:35.000Z",
          "wordCount": 1005,
          "title": "Top Strategies and Best Practices for Big Data Testing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2022/03/stephen-dawson-qwtCeJ5cLYs-unsplash.jpg"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=103782",
          "author": "John",
          "description": "Introduction I was puzzled the first time I saw bilinear transformations, also known as Möbius transformations. I was in a class where everything had been abstract and general, and suddenly thing got very concrete and specific. I wondered why we had changed gears, and I wondered how there could be much to say about something […]\nFixed points of bilinear transformations first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/21/mobius-fixed-points/",
          "publishedOn": "2022-04-21T21:56:00.000Z",
          "wordCount": 524,
          "title": "Fixed points of bilinear transformations",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103774",
          "author": "John",
          "description": "This post looks at how to partition complexity between definitions and theorems, and why it’s useful to be able to partition things more than one way. Quadratic equations Imagine the following dialog in an algebra class. “Quadratic equations always have two roots.” “But what about (x – 5)² = 0. That just has one root, […]\nPartitioning complexity first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/21/partitioning-complexity/",
          "publishedOn": "2022-04-21T14:50:32.000Z",
          "wordCount": 1119,
          "title": "Partitioning complexity",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103710",
          "author": "John",
          "description": "I got an email from a student in France who asked about a French counterpart to my post on Morse code palindromes, and this post is a response to that email. Palindromes A palindrome is a word that remains the same when the letters are reversed, like kayak. A Morse code palindrome is a word […]\nFrench palindromes and Morse code first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/20/french-palindromes-and-morse-code/",
          "publishedOn": "2022-04-20T16:31:53.000Z",
          "wordCount": 731,
          "title": "French palindromes and Morse code",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103703",
          "author": "John",
          "description": "Blaschke factors are complex functions with specified zeros inside the unit disk. Given a complex number a with |a| < 1, the Blaschke factor associated with a is the function Notice the semicolon in b(z; a). This is a convention that a few authors follow, and that I wish more would adopt. From a purely […]\nBlaschke factors first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/20/blaschke-factors/",
          "publishedOn": "2022-04-20T14:45:11.000Z",
          "wordCount": 747,
          "title": "Blaschke factors",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103597",
          "author": "John",
          "description": "Inversion in the unit circle is a way of turning the circle inside-out. Everything that was inside the circle goes outside the circle, and everything that was outside the circle comes in. Not only is the disk turned inside-out, the same thing happens along each ray going out from the origin. Points on that ray […]\nInversion in a circle first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/19/inversion-in-a-circle/",
          "publishedOn": "2022-04-19T16:20:21.000Z",
          "wordCount": 510,
          "title": "Inversion in a circle",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=103049",
          "author": "John",
          "description": "Male and female heights both have a standard deviation of about 3 inches, with means of 70 inches and 64 inches. That’s a good first-pass model using round numbers. If you ask what the height of an average adult is, not specifying male or female, you get a mixture of two normal distributions. If we […]\nHow flat is a normal mixture on top? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/13/how-flat-is-a-normal-mixture-on-top/",
          "publishedOn": "2022-04-14T00:38:00.000Z",
          "wordCount": 653,
          "title": "How flat is a normal mixture on top?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102974",
          "author": "John",
          "description": "A few days ago I wrote about the Hilbert transform and gave as an example that the Hilbert transform of sine is cosine. We’ll bootstrap that example to find the Hilbert transform of any periodic function from its Fourier series. The Hilbert transform of a function f(t) is a function fH(x) defined by where the […]\nHilbert transform and Fourier series first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/13/hilbert-fourier/",
          "publishedOn": "2022-04-13T16:05:15.000Z",
          "wordCount": 719,
          "title": "Hilbert transform and Fourier series",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102966",
          "author": "John",
          "description": "I got an evaluation copy of The Best Writing on Mathematics 2021 yesterday. One article jumped out as I was skimming the table of contents: A Zeroth Power Is Often a Logarithm Yearning to Be Free by Sanjoy Mahajan. Great title. There are quite a few theorems involving powers that have an exceptional case that […]\nLogarithms yearning to be free first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/13/logarithms-yearning-to-be-free/",
          "publishedOn": "2022-04-13T12:00:22.000Z",
          "wordCount": 476,
          "title": "Logarithms yearning to be free",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102336",
          "author": "John",
          "description": "I explained the basics of how a slide rule works in the previous post. But how does a circular slide rule work? Apparently the prop Mr. Spock is holding is an E6B aircraft slide rule. It includes a circular slide rule and more functionality. Start with an ordinary straight slide rule, with each bar labeled […]\nCircular slide rule first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/10/circular-slide-rule/",
          "publishedOn": "2022-04-10T22:05:38.000Z",
          "wordCount": 476,
          "title": "Circular slide rule",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=102298",
          "author": "John",
          "description": "Suppose you have two sticks. The length of one is log x, and the length of the other is log y. If you put the two sticks end to end, the combined length is log x + log y = log xy. That’s the basic idea behind a slide rule. The simplest slide rule consists […]\nWhy a slide rule works first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/10/why-a-slide-rule-works/",
          "publishedOn": "2022-04-10T20:49:00.000Z",
          "wordCount": 689,
          "title": "Why a slide rule works",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101985",
          "author": "John",
          "description": "The Hilbert transform of a function f(t) is a function fH(x) defined [1] by The integral must be interpreted in the sense of the Cauchy principal value: The integrand is not absolutely integrable because of the singularity at x and so the value of the integral depends on how you handle the singularity. The Cauchy […]\nHilbert transform and Mathematica first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/08/hilbert-transform-and-mathematica/",
          "publishedOn": "2022-04-08T15:12:50.000Z",
          "wordCount": 675,
          "title": "Hilbert transform and Mathematica",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101943",
          "author": "John",
          "description": "The plot below is of a meromorphic function f(z). That is, the function f(z) is analytic except possibly at poles, and the colors represent the phase angles, the values of θ if you write the function values in polar form. What is the value of the integral where C is the perimeter of the square? […]\nVisual integration first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/08/visual-integration/",
          "publishedOn": "2022-04-08T11:10:02.000Z",
          "wordCount": 514,
          "title": "Visual integration",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101905",
          "author": "John",
          "description": "Regular expressions can do a lot of tasks in practice that they cannot do in theory. That’s because a particular application of regular expressions comes with context and with error tolerance. For example, much has been said about how regular expressions cannot parse HTML. This is strictly true, but it says nothing about how well […]\nRegular expressions and successive approximation first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/07/regex-approximation/",
          "publishedOn": "2022-04-07T14:00:43.000Z",
          "wordCount": 864,
          "title": "Regular expressions and successive approximation",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101812",
          "author": "John",
          "description": "A couple days ago I wrote about how Vieta’s formulas let you sum the zeros of a polynomial without having to first compute the zeros. This is especially handy for high-order polynomials since there is no explicit formula for the zeros. Most functions that arise in applications are not polynomials. How could you find the […]\nSum the zeros of an analytic function without finding them first first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/06/sum-analytic-function-zeros/",
          "publishedOn": "2022-04-06T13:22:57.000Z",
          "wordCount": 790,
          "title": "Sum the zeros of an analytic function without finding them first",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101725",
          "author": "John",
          "description": "The previous post looked at the problem of finding the zeros of a cubic polynomial. Assuming we’re going to use a numerical method to calculate the zero, the hard part is knowing where to tell the numerical method to look. That post showed how to use a change of variables to guarantee that the polynomial […]\nBounding zeros of an analytic function first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/05/analytic-zeros/",
          "publishedOn": "2022-04-05T14:33:39.000Z",
          "wordCount": 748,
          "title": "Bounding zeros of an analytic function",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101681",
          "author": "John",
          "description": "The analog of the quadratic formula for cubic equations is cumbersome. A lot of people naturally say “Forget all that. If I need to find the roots of a cubic, I’ll just use a numerical method like Newton’s method.” Sounds good. Where to start? But how do you know where to look for the roots? […]\nNumerically finding roots of a cubic first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/05/cubic/",
          "publishedOn": "2022-04-05T12:00:16.000Z",
          "wordCount": 903,
          "title": "Numerically finding roots of a cubic",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101654",
          "author": "John",
          "description": "The following is a slightly edited version of a Twitter thread on @AlgebraFact. The lowest C on a piano is called C1 in scientific pitch notation. The C one octave up is C2 and so forth. Middle C is C4. The frequency of Cn is approximately 2n+4 Hz. This would be exact if C0 were […]\nMathematics and piano tuning first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/mathemacs-and-piano-tuning/",
          "publishedOn": "2022-04-04T23:19:24.000Z",
          "wordCount": 478,
          "title": "Mathematics and piano tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101658",
          "author": "John",
          "description": "Once in a while it’s necessary to calculate some function of the roots of a polynomial, and it may be possible to do this without first calculating the roots. Quadratics The quadratic formula gives explicit solutions to the equation The two solutions for x are where The awkward part is taking the square root of […]\nComputing functions of roots without computing roots first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/vieta/",
          "publishedOn": "2022-04-04T14:42:33.000Z",
          "wordCount": 925,
          "title": "Computing functions of roots without computing roots",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101533",
          "author": "John",
          "description": "This post contains a derives a result I needed recently. The derivation is simple but a little tedious, so I wanted to save it in case I need it again. Full width half maximum A common way to measure the width of a function peak in a function f(x) is to find the place x0 […]\nFWHM for a quadratic first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/fwhm-quadratic/",
          "publishedOn": "2022-04-04T12:59:26.000Z",
          "wordCount": 693,
          "title": "FWHM for a quadratic",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101648",
          "author": "John",
          "description": "Here’s a list of five numbers used as slang in various contexts. Location (CB and police radio) End of column (journalism) Best wishes (ham radio) All aircraft in area (US Navy) I love you (text messages) The motivation for this post was an article Those HTML attributes you never use. I wanted to make a […]\nNumber slang and numbered lists first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/04/number-slang-and-numbered-lists/",
          "publishedOn": "2022-04-04T12:39:43.000Z",
          "wordCount": 242,
          "title": "Number slang and numbered lists",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101499",
          "author": "John",
          "description": "Electrical and mechanical oscillations satisfy analogous equations. This is the basis of using the word “analog” in electronics. You could study a mechanical system by building an analogous circuit and measuring that circuit in a lab. Mass, dashpot, spring Years ago I wrote a series of four posts about mechanical vibrations: Free, undamped vibrations Free, […]\nOscillations in RLC circuits first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/04/02/rlc-circuits/",
          "publishedOn": "2022-04-02T17:16:43.000Z",
          "wordCount": 548,
          "title": "Oscillations in RLC circuits",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101269",
          "author": "John",
          "description": "The length of antenna you need to receive a radio signal is proportional to the signal’s wavelength, typically 1/2 or 1/4 of the wavelength. Cell phones operate at gigahertz frequencies, and so the antennas are small enough to hide inside the phone. But AM radio stations operate at much lower frequencies. For example, there’s a […]\nHow is portable AM radio possible? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/30/portable-am-radio/",
          "publishedOn": "2022-03-30T16:20:14.000Z",
          "wordCount": 1127,
          "title": "How is portable AM radio possible?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101260",
          "author": "John",
          "description": "At first glance, continued fractions look more like a curiosity than like useful mathematics. And yet they come up surprisingly often in applications. For an irrational number x, the numbers you get by truncating the infinite continued fraction for x are the optimal rational approximations to x given the size of their denominators. For example, […]\nApplications of continued fractions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/30/continued-fraction-applications/",
          "publishedOn": "2022-03-30T13:32:24.000Z",
          "wordCount": 459,
          "title": "Applications of continued fractions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101207",
          "author": "John",
          "description": "I mentioned smoothed step functions in the previous post. What would you do if you needed to concretely use a smoothed step function and not just know that one exists? We’ll look at smoothed versions of the signum function sgn(x) = x / |x| which equals -1 for negative x and +1 for positive x. […]\nSmoothed step function first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/29/smoothed-step-function/",
          "publishedOn": "2022-03-29T16:07:30.000Z",
          "wordCount": 684,
          "title": "Smoothed step function",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101189",
          "author": "John",
          "description": "Partitions of unity are a handy technical device. They’re seldom the focus of attention but rather are buried in the middle of proofs. The name sounds odd, but it’s descriptive. A partition of unity is a set of smooth functions into the interval [0, 1] that add up to 1 at every point. The functions […]\nPartitions of unity, smooth ramps, and CW clicks first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/29/partition-of-unity/",
          "publishedOn": "2022-03-29T11:40:41.000Z",
          "wordCount": 587,
          "title": "Partitions of unity, smooth ramps, and CW clicks",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101066",
          "author": "John",
          "description": "Suppose you start with some large number x and want to find a prime number at least as big as x. First you test whether x is prime. Then you test whether x + 1 is prime. Then you test whether x + 2 is prime, and so on until you find a prime. Of […]\nLooking for the next prime first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/28/next-prime/",
          "publishedOn": "2022-03-28T13:52:14.000Z",
          "wordCount": 926,
          "title": "Looking for the next prime",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=101009",
          "author": "John",
          "description": "I had heard of the Svalbard Global Seed Vault, but I hadn’t heard of the nearby Arctic World Archive until today. The latter contains source code preserved on film, a format that should last at least 500 years.\nSeed vault, but for code first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2022/03/27/seed-vault-but-for-code/",
          "publishedOn": "2022-03-27T23:19:41.000Z",
          "wordCount": 186,
          "title": "Seed vault, but for code",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.14.4"
}