{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com/blog/",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=14330",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "The gradient descent algorithm is one of the most popular techniques for training deep neural networks. It has many applications in fields such as computer vision, speech recognition, and natural language processing. While the idea of gradient descent has been around for decades, it’s only recently that it’s been applied to applications related to deep […]\nThe post Implementing Gradient Descent in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/implementing-gradient-descent-in-pytorch/",
          "publishedOn": "2022-11-26T20:28:14.000Z",
          "wordCount": 7592,
          "title": "Implementing Gradient Descent in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/michael-behrens-DA-iYgv8kjE-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14318",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a simple yet powerful technique for predicting the values of variables based on other variables. It is often used for modeling relationships between two or more continuous variables, such as the relationship between income and age, or the relationship between weight and height. Likewise, linear regression can be used to predict continuous […]\nThe post Training a Linear Regression Model in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/training-a-linear-regression-model-in-pytorch/",
          "publishedOn": "2022-11-24T17:24:24.000Z",
          "wordCount": 7119,
          "title": "Training a Linear Regression Model in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/ryan-tasto-chbXE4o0ryU-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14311",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a statistical technique for estimating the relationship between two variables. A simple example of linear regression is to predict the height of someone based on the square root of the person’s weight (that’s what BMI is based on). To do this, we need to find the slope and intercept of the line. […]\nThe post Making Linear Predictions in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/making-linear-predictions-in-pytorch/",
          "publishedOn": "2022-11-24T04:11:30.000Z",
          "wordCount": 6417,
          "title": "Making Linear Predictions in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/daryan-shamkhali-pMCbPPPBSkA-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14301",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Structuring the data pipeline in a way that it can be effortlessly linked to your deep learning model is an important aspect of any deep learning-based system. PyTorch packs everything to do just that. While in the previous tutorial, we used simple datasets, we’ll need to work with larger datasets in real world scenarios in […]\nThe post Loading and Providing Datasets in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/loading-and-providing-datasets-in-pytorch/",
          "publishedOn": "2022-11-19T01:57:22.000Z",
          "wordCount": 5933,
          "title": "Loading and Providing Datasets in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/uriel-sc-11KDtiUWRq4-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14298",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "In machine learning and deep learning problems, a lot of effort goes into preparing the data. Data is usually messy and needs to be preprocessed before it can be used for training a model. If the data is not prepared correctly, the model won’t be able to generalize well. Some of the common steps required […]\nThe post Using Dataset Classes in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/using-dataset-classes-in-pytorch/",
          "publishedOn": "2022-11-17T01:55:54.000Z",
          "wordCount": 6445,
          "title": "Using Dataset Classes in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/nasa-1lfI7wkGWZ4-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13195",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Derivatives are one of the most fundamental concepts in calculus. They describe how changes in the variable inputs affect the function outputs. The objective of this article is to provide a high-level introduction to calculating derivatives in PyTorch for those who are new to the framework. PyTorch offers a convenient way to calculate derivatives for […]\nThe post Calculating Derivatives in PyTorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/calculating-derivatives-in-pytorch/",
          "publishedOn": "2022-11-11T21:30:18.000Z",
          "wordCount": 6011,
          "title": "Calculating Derivatives in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/jossuha-theophile-H-CZjCQfsFw-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13183",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Two-dimensional tensors are analogous to two-dimensional metrics. Like a two-dimensional metric, a two-dimensional tensor also has $n$ number of rows and columns. Let’s take a gray-scale image as an example, which is a two-dimensional matrix of numeric values, commonly known as pixels. Ranging from ‘0’ to ‘255’, each number represents a pixel intensity value. Here, […]\nThe post Two-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/two-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-09T21:30:51.000Z",
          "wordCount": 6286,
          "title": "Two-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/dylan-nolte-NIrgENd0sAY-unsplash-scaled.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13157",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "PyTorch is an open-source deep learning framework based on Python language. It allows you to build, train, and deploy deep learning models, offering a lot of versatility and efficiency. PyTorch is primarily focused on tensor operations while a tensor can be a number, matrix, or a multi-dimensional array. In this tutorial, we will perform some […]\nThe post One-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/one-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-07T21:30:13.000Z",
          "wordCount": 6633,
          "title": "One-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2021/12/jo-szczepanska-9OKGEVJiTKk-unsplash.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14064",
          "author": "MLM Team",
          "description": "Sponsored Post   The unlimited access initiative presents a risk-free way to break into data science.     The online educational platform 365 Data Science launches the #21DaysFREE campaign and provides 100% free unlimited access to all content for three weeks. From November 1 to 21, you can take courses from renowned instructors and earn […]\nThe post 365 Data Science courses free until November 21 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/365-data-science-courses-free-until-november-21/",
          "publishedOn": "2022-11-02T15:50:51.000Z",
          "wordCount": 4628,
          "title": "365 Data Science courses free until November 21",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/mlm-365ds-20221102-1.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14006",
          "author": "MLM Team",
          "description": "Sponsored Post      Attend the Data Science Symposium 2022 on November 8 The Center for Business Analytics at the University of Cincinnati will present its annual Data Science Symposium 2022 on November 8. This all day in-person event will have three featured speakers and two tech talk tracks with four concurrent presentations in each track. The […]\nThe post Attend the Data Science Symposium 2022, November 8 in Cincinnati appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/uccsb-data-science-symposium-2022-cincinnati/",
          "publishedOn": "2022-11-01T15:16:00.000Z",
          "wordCount": 3115,
          "title": "Attend the Data Science Symposium 2022, November 8 in Cincinnati",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/10/mlm-uccsb-221018.png"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": null,
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "26f6bce232483d6777c2e86268fa4b4222390aab",
          "author": "Abhi Shivaditya",
          "description": "What is the optimal framework and configuration for hosting large language models (LLMs) for text-generating generative AI applications? Despite the abundance of options for serving LLMs, this is a hard question to answer due to the size of the models, varying model architectures, performance requirements of applications, and more. The Amazon SageMaker Large Model Inference […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/improve-performance-of-falcon-models-with-amazon-sagemaker/",
          "publishedOn": "2023-10-11T16:28:05.000Z",
          "wordCount": 3961,
          "title": "Improve performance of Falcon models with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/improve-falcon-performance-1257x630.jpg"
        },
        {
          "id": "3fc93bffa4117e4687f3a09d0dc8af011798dc3e",
          "author": "Jiten Dedhia",
          "description": "In this post, we show how to index information stored in websites and use the intelligent search in Amazon Kendra to search for answers from content stored in internal and external websites. In addition, the ML-powered intelligent search can accurately get answers for your questions from unstructured documents with natural language narrative content, for which keyword search is not very effective.",
          "link": "https://aws.amazon.com/blogs/machine-learning/index-your-web-crawled-content-using-the-new-web-crawler-for-amazon-kendra/",
          "publishedOn": "2023-10-11T16:15:29.000Z",
          "wordCount": 2053,
          "title": "Index your web crawled content using the new Web Crawler for Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/11/web-crawled-content-kendra.jpg"
        },
        {
          "id": "145ebaed28dda5de4846c2e0dd8e4a54f97b1216",
          "author": "Anand Iyer",
          "description": "Launched in 2021, Amazon SageMaker Canvas is a visual, point-and-click service that allows business analysts and citizen data scientists to use ready-to-use machine learning (ML) models and build custom ML models to generate accurate predictions without the need to write any code. Ready-to-use models enable you to derive immediate insights from text, image, and document […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/new-no-code-generative-ai-capabilities-now-available-in-amazon-sagemaker-canvas/",
          "publishedOn": "2023-10-10T17:20:10.000Z",
          "wordCount": 2138,
          "title": "New – No-code generative AI capabilities now available in Amazon SageMaker Canvas",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/l-ml-15314-image001-881x630.png"
        },
        {
          "id": "6fbdc7b2c25e72984d866afa8c3024fda8a29b5f",
          "author": "Hemant Singh",
          "description": "Today, we’re excited to announce that the OpenAI Whisper foundation model is available for customers using Amazon SageMaker JumpStart. Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680 thousand hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/whisper-models-for-automatic-speech-recognition-now-available-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-10T17:09:35.000Z",
          "wordCount": 3269,
          "title": "Whisper models for automatic speech recognition now available in Amazon SageMaker JumpStart",
          "enclosure": {
            "length": "1280078",
            "type": "audio/wav",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-15311/sample1.wav"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/02/ML-15311-image001-1225x630.jpg"
        },
        {
          "id": "38ddfd3589f3778d8f34f15c640e9e2097fcaabe",
          "author": "Qiong Zhang",
          "description": "In this blog, you will learn to build a cloud-native FL architecture on AWS. By using infrastructure as code (IaC) tools on AWS, you can deploy FL architectures with ease. Also, a cloud-native architecture takes full advantage of a variety of AWS services with proven security and operational excellence, thereby simplifying the development of FL.",
          "link": "https://aws.amazon.com/blogs/machine-learning/reinventing-a-cloud-native-federated-learning-architecture-on-aws/",
          "publishedOn": "2023-10-10T17:01:51.000Z",
          "wordCount": 3708,
          "title": "Reinventing a cloud-native federated learning architecture on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/26/fl-arch.png"
        },
        {
          "id": "f6379ad2217c7af13a0224391c6b4156d9af2a3d",
          "author": "Kyle Ulrich",
          "description": "Today, we are excited to announce that the Mistral 7B foundation models, developed by Mistral AI, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. With 7 billion parameters, Mistral 7B can be easily customized and quickly deployed. You can try out this model with SageMaker JumpStart, a […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-09T21:37:48.000Z",
          "wordCount": 4168,
          "title": "Mistral 7B foundation models from Mistral AI are now available in Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/mistral-7b-sagemaker-jumpstart.jpg"
        },
        {
          "id": "c5e6ca49ccc13a7f87d34949c97eec679ed55d46",
          "author": "Gavin Satur",
          "description": "According to Gartner, 85% of software buyers trust online reviews as much as personal recommendations. Customers provide feedback and reviews about products they have purchased through many channels, including review websites, vendor websites, sales calls, social media, and many others. The problem with the increasing volume of customer reviews across multiple channels is that it […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-no-code-machine-learning-to-derive-insights-from-product-reviews-using-amazon-sagemaker-canvas-sentiment-analysis-and-text-analysis-models/",
          "publishedOn": "2023-10-09T17:49:32.000Z",
          "wordCount": 2206,
          "title": "Use no-code machine learning to derive insights from product reviews using Amazon SageMaker Canvas sentiment analysis and text analysis models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/no-code-sentiment-reviews.jpg"
        },
        {
          "id": "433fa61bee27e013db333bccd4fcf2d6c6952342",
          "author": "Maysara Hamdan",
          "description": "A recommendation engine is only as good as the data used to prepare it. Transforming raw data into a format that is suitable for a model is key to getting better personalized recommendations for end-users. In this post, we walk through how to prepare and import the MovieLens dataset, a dataset prepared by GroupLens research […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/prepare-your-data-for-amazon-personalize-with-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2023-10-09T17:45:27.000Z",
          "wordCount": 3264,
          "title": "Prepare your data for Amazon Personalize with Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/09/prepare-amazon-personalize-data-wrangler.jpg"
        },
        {
          "id": "17c1ee4bd12ee4affb4e4d86cd777cd7aad766c0",
          "author": "Yanwei Cui",
          "description": "In this post, we elucidate the simple yet powerful idea of combining user profiles and item attributes to generate personalized content recommendations using LLMs. As demonstrated throughout the post, these models hold immense potential in generating high-quality, context-aware input text, which leads to enhanced recommendations. To illustrate this, we guide you through the process of integrating a feature store (representing user profiles) with an LLM to generate these personalized recommendations.",
          "link": "https://aws.amazon.com/blogs/machine-learning/personalize-your-generative-ai-applications-with-amazon-sagemaker-feature-store/",
          "publishedOn": "2023-10-06T16:26:35.000Z",
          "wordCount": 3820,
          "title": "Personalize your generative AI applications with Amazon SageMaker Feature Store",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/LLMRecIllustration-1183x630.png"
        },
        {
          "id": "781b6ebbbb8d93ed3fd71d5f18773e75d56a494b",
          "author": "Yanwei Cui",
          "description": "In this post, we provide an overview of popular multimodality models. We also demonstrate how to deploy these pre-trained models on Amazon SageMaker. Furthermore, we discuss the diverse applications of these models, focusing particularly on several real-world scenarios, such as zero-shot tag and attribution generation for ecommerce and automatic prompt generation from images.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-image-to-text-generative-ai-application-using-multimodality-models-on-amazon-sagemaker/",
          "publishedOn": "2023-10-06T16:12:48.000Z",
          "wordCount": 3860,
          "title": "Build an image-to-text generative AI application using multimodality models on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/15/ML-15190-clip-1012x630.png"
        },
        {
          "id": "b29c68eb95cf8e07624bc83a702735c83f8886bc",
          "author": "Sathya Balakrishnan",
          "description": "In this post, we explain how to build and optimize a custom classification model using Amazon Comprehend. We demonstrate this using an Amazon Comprehend custom classification to build a multi-label custom classification model, and provide guidelines on how to prepare the training dataset and tune the model to meet performance metrics such as accuracy, precision, recall, and F1 score.",
          "link": "https://aws.amazon.com/blogs/machine-learning/improve-prediction-quality-in-custom-classification-models-with-amazon-comprehend/",
          "publishedOn": "2023-10-05T17:21:48.000Z",
          "wordCount": 2363,
          "title": "Improve prediction quality in custom classification models with Amazon Comprehend",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/14/ml-13080-image5.png"
        },
        {
          "id": "ec895ac7cb8adf123a7c801707ca652deb3ea4d3",
          "author": "Hao Zhou",
          "description": "Large language models (LLMs) have captured the imagination and attention of developers, scientists, technologists, entrepreneurs, and executives across several industries. These models can be used for question answering, summarization, translation, and more in applications such as conversational agents for customer support, content creation for marketing, and coding assistants. Recently, Meta released Llama 2 for both […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/fast-and-cost-effective-llama-2-fine-tuning-with-aws-trainium/",
          "publishedOn": "2023-10-05T17:14:03.000Z",
          "wordCount": 2036,
          "title": "Fast and cost-effective LLaMA 2 fine-tuning with AWS Trainium",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/05/fast-cost-effective-llama.jpg"
        },
        {
          "id": "be5af0f28c609a01c405a677e484ed6b08cc7d12",
          "author": "Ramakant Joshi",
          "description": "Analyzing medical images plays a crucial role in diagnosing and treating diseases. The ability to automate this process using machine learning (ML) techniques allows healthcare professionals to more quickly diagnose certain cancers, coronary diseases, and ophthalmologic conditions. However, one of the key challenges faced by clinicians and researchers in this field is the time-consuming and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/simplify-medical-image-classification-using-amazon-sagemaker-canvas/",
          "publishedOn": "2023-10-04T18:58:00.000Z",
          "wordCount": 3421,
          "title": "Simplify medical image classification using Amazon SageMaker Canvas",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/04/simplify-medical-image-classification.jpg"
        },
        {
          "id": "339cdca51b4db2b0c1dffa4ec7bdf02a334b97ef",
          "author": "John Kitaoka",
          "description": "Healthcare and life sciences (HCLS) customers are adopting generative AI as a tool to get more from their data. Use cases include document summarization to help readers focus on key points of a document and transforming unstructured text into standardized formats to highlight important attributes. With unique data formats and strict regulatory requirements, customers are […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/create-an-hcls-document-summarization-application-with-falcon-using-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-04T18:50:15.000Z",
          "wordCount": 2767,
          "title": "Create an HCLS document summarization application with Falcon using Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/04/hcls-document-repository-falcon.jpg"
        },
        {
          "id": "134f648e31243787082518b77533e5e96df76c88",
          "author": "Manish Patel",
          "description": "Prior authorization is a crucial process in healthcare that involves the approval of medical treatments or procedures before they are carried out. This process is necessary to ensure that patients receive the right care and that healthcare providers are following the correct procedures. However, prior authorization can be a time-consuming and complex process that requires […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automate-prior-authorization-using-crd-with-cds-hooks-and-aws-healthlake/",
          "publishedOn": "2023-10-04T18:40:53.000Z",
          "wordCount": 2199,
          "title": "Automate prior authorization using CRD with CDS Hooks and AWS HealthLake",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/26/CRDArchitecture.png"
        },
        {
          "id": "cd418e3c11f7ef613ec7b0e321c2181724319993",
          "author": "Gabriel Synnaeve",
          "description": "Today, we are excited to announce Code Llama foundation models, developed by Meta, are available for customers through Amazon SageMaker JumpStart to deploy with one click for running inference. Code Llama is a state-of-the-art large language model (LLM) capable of generating code and natural language about code from both code and natural language prompts. Code […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/code-llama-code-generation-models-from-meta-are-now-available-via-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-10-02T21:30:04.000Z",
          "wordCount": 3445,
          "title": "Code Llama code generation models from Meta are now available via Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/10/02/code-llama-jumpstart.jpg"
        },
        {
          "id": "fed81d50529eb0b948d390863fd3936ac8a38a50",
          "author": "Michael Roth",
          "description": "A successful deployment of a machine learning (ML) model in a production environment heavily relies on an end-to-end ML pipeline. Although developing such a pipeline can be challenging, it becomes even more complex when dealing with an edge ML use case. Machine learning at the edge is a concept that brings the capability of running […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-mlops-pipeline-for-visual-quality-inspection-at-the-edge-part-1/",
          "publishedOn": "2023-10-02T16:31:29.000Z",
          "wordCount": 3074,
          "title": "Build an end-to-end MLOps pipeline for visual quality inspection at the edge – Part 1",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-6965-pipeline-scribble-820x630.jpg"
        },
        {
          "id": "0840f232e2b2b2594035da8f8fea5ce874257200",
          "author": "Michael Roth",
          "description": "In Part 1 of this series, we drafted an architecture for an end-to-end MLOps pipeline for a visual quality inspection use case at the edge. It is architected to automate the entire machine learning (ML) process, from data labeling to model training and deployment at the edge. The focus on managed and serverless services reduces […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-mlops-pipeline-for-visual-quality-inspection-at-the-edge-part-2/",
          "publishedOn": "2023-10-02T16:31:23.000Z",
          "wordCount": 2687,
          "title": "Build an end-to-end MLOps pipeline for visual quality inspection at the edge – Part 2",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-6965-scratch-sample.jpg"
        },
        {
          "id": "02a4b68b189babfa161fbe557826981b865d651c",
          "author": "Michael Roth",
          "description": "This is Part 3 of our series where we design and implement an MLOps pipeline for visual quality inspection at the edge. In this post, we focus on how to automate the edge deployment part of the end-to-end MLOps pipeline. We show you how to use AWS IoT Greengrass to manage model inference at the […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-end-to-end-mlops-pipeline-for-visual-quality-inspection-at-the-edge-part-3/",
          "publishedOn": "2023-10-02T16:31:18.000Z",
          "wordCount": 2770,
          "title": "Build an end-to-end MLOps pipeline for visual quality inspection at the edge – Part 3",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-6965-arch-diag-1149x630.jpg"
        },
        {
          "id": "e6926913d81f18288eff67d35b63dc80ea3dbb05",
          "author": "Lydia Lihui Zhang",
          "description": "In this analysis, we use a K-nearest neighbors (KNN) model to conduct crop segmentation, and we compare these results with ground truth imagery on an agricultural region. Our results reveal that the classification from the KNN model is more accurately representative of the state of the current crop field in 2017 than the ground truth classification data from 2015. These results are a testament to the power of Planet’s high-cadence geospatial imagery. Agricultural fields change often, sometimes multiple times a season, and having high-frequency satellite imagery available to observe and analyze this land can provide immense value to our understanding of agricultural land and quickly-changing environments.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-crop-segmentation-machine-learning-model-with-planet-data-and-amazon-sagemaker-geospatial-capabilities/",
          "publishedOn": "2023-09-29T21:08:49.000Z",
          "wordCount": 4487,
          "title": "Build a crop segmentation machine learning model with Planet data and Amazon SageMaker geospatial capabilities",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/28/ML-14309-image003.png"
        },
        {
          "id": "24f5f889b8c34a0086855adf5610ddc45d4b8e21",
          "author": "Ilan Geller",
          "description": "This post is co-written with Ilan Geller and Shuyu Yang from Accenture. Enterprises today face major challenges when it comes to using their information and knowledge bases for both internal and external business operations. With constantly evolving operations, processes, policies, and compliance requirements, it can be extremely difficult for employees and customers to stay up […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/accenture-creates-a-knowledge-assist-solution-using-generative-ai-services-on-aws/",
          "publishedOn": "2023-09-28T19:28:41.000Z",
          "wordCount": 2536,
          "title": "Accenture creates a Knowledge Assist solution using generative AI services on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/27/ml-15315-image001-1260x551.png"
        },
        {
          "id": "be5c3861265a49ba4c4d5f34f7428d0baa8bac20",
          "author": "Nirmal Kumar",
          "description": "We’re excited to announce that Amazon SageMaker Canvas now offers a quicker and more user-friendly way to create machine learning models for time-series forecasting. SageMaker Canvas is a visual point-and-click service that enables business analysts to generate accurate machine learning (ML) models without requiring any machine learning experience or having to write a single line of code. SageMaker […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/speed-up-your-time-series-forecasting-by-up-to-50-percent-with-amazon-sagemaker-canvas-ui-and-automl-apis/",
          "publishedOn": "2023-09-28T17:23:10.000Z",
          "wordCount": 2178,
          "title": "Speed up your time series forecasting by up to 50 percent with Amazon SageMaker Canvas UI and AutoML APIs",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/27/ML-15508-image002-1252x630.jpg"
        },
        {
          "id": "9f3745bfee5c63ba48a09c4c8cf8d81544701a20",
          "author": "Nick Biso",
          "description": "In the world of data-driven decision-making, time series forecasting is key in enabling businesses to use historical data patterns to anticipate future outcomes. Whether you are working in asset risk management, trading, weather prediction, energy demand forecasting, vital sign monitoring, or traffic analysis, the ability to forecast accurately is crucial for success. In these applications, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/robust-time-series-forecasting-with-mlops-on-amazon-sagemaker/",
          "publishedOn": "2023-09-28T17:05:11.000Z",
          "wordCount": 3034,
          "title": "Robust time series forecasting with MLOps on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/21/ML-13454-image015.png"
        },
        {
          "id": "f48418b4cb0675d9c19c3900e5b213373fb9b183",
          "author": "Talha Chattha",
          "description": "In the rapidly evolving world of AI and machine learning (ML), foundation models (FMs) have shown tremendous potential for driving innovation and unlocking new use cases. However, as organizations increasingly harness the power of FMs, concerns surrounding data privacy, security, added cost, and compliance have become paramount. Regulated and compliance-oriented industries, such as financial services, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/create-a-generative-ai-gateway-to-allow-secure-and-compliant-consumption-of-foundation-models/",
          "publishedOn": "2023-09-28T17:00:33.000Z",
          "wordCount": 3946,
          "title": "Create a Generative AI Gateway to allow secure and compliant consumption of foundation models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/18/ML-14882-Gen-AI-Gateway-Model-Abstraction.png"
        },
        {
          "id": "b328f2a8d5dcd7e4df0e267b25500c9c34765060",
          "author": "Charles Laughlin",
          "description": "Companies use time series forecasting to make core planning decisions that help them navigate through uncertain futures. This post is meant to address supply chain stakeholders, who share a common need of determining how many finished goods are needed over a mixed variety of planning time horizons. In addition to planning how many units of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/beyond-forecasting-the-delicate-balance-of-serving-customers-and-growing-your-business/",
          "publishedOn": "2023-09-28T16:56:56.000Z",
          "wordCount": 3291,
          "title": "Beyond forecasting: The delicate balance of serving customers and growing your business",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/01/quantile-graphic-blog-1164x630.png"
        },
        {
          "id": "d2dd860a3d9d2f3453bc4683eb72be7f89f33465",
          "author": "Swami Sivasubramanian",
          "description": "From startups to enterprises, organizations of all sizes are getting started with generative AI. They want to capitalize on generative AI and translate the momentum from betas, prototypes, and demos into real-world productivity gains and innovations. But what do organizations need to bring generative AI into the enterprise and make it real? When we talk […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/announcing-new-tools-to-help-every-business-embrace-generative-ai/",
          "publishedOn": "2023-09-28T13:40:01.000Z",
          "wordCount": 3829,
          "title": "Announcing New Tools to Help Every Business Embrace Generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/28/Updated_slide-1127x630.jpg"
        },
        {
          "id": "5fa30641ce2cc6076bed63a524900037901a3a7c",
          "author": "Yunfei Bai",
          "description": "The Amazon EU Design and Construction (Amazon D&C) team is the engineering team designing and constructing Amazon Warehouses across Europe and the MENA region. The design and deployment processes of projects involve many types of Requests for Information (RFIs) about engineering requirements regarding Amazon and project-specific guidelines. These requests range from simple retrieval of baseline […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/a-generative-ai-powered-solution-on-amazon-sagemaker-to-help-amazon-eu-design-and-construction/",
          "publishedOn": "2023-09-27T18:50:49.000Z",
          "wordCount": 3750,
          "title": "A generative AI-powered solution on Amazon SageMaker to help Amazon EU Design and Construction",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/GESS_LLM_architecture_V4.1.png"
        },
        {
          "id": "023cef7ec7be1de4c1d3adc8dda1692a97737a71",
          "author": "Jake Bernstein",
          "description": "MDaudit provides a cloud-based billing compliance and revenue integrity software as a service (SaaS) platform to more than 70,000 healthcare providers and 1,500 healthcare facilities, ensuring healthcare customers maintain regulatory compliance and retain revenue. Working with the top 60+ US healthcare networks, MDaudit needs to be able to scale its artificial intelligence (AI) capabilities to […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/mdaudit-uses-ai-to-improve-revenue-outcomes-for-healthcare-customers/",
          "publishedOn": "2023-09-27T17:12:59.000Z",
          "wordCount": 1619,
          "title": "MDaudit uses AI to improve revenue outcomes for healthcare customers",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/19/ML-13668-arch-diag-1129x630.png"
        },
        {
          "id": "2bb720da771be06913edaebf36d26973e9b30f5f",
          "author": "Praveen Chamarthi",
          "description": "As machine learning (ML) goes mainstream and gains wider adoption, ML-powered inference applications are becoming increasingly common to solve a range of complex business problems. The solution to these complex business problems often requires using multiple ML models and steps. This post shows you how to build and host an ML application with custom containers […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-and-deploy-ml-inference-applications-from-scratch-using-amazon-sagemaker/",
          "publishedOn": "2023-09-26T16:08:20.000Z",
          "wordCount": 3911,
          "title": "Build and deploy ML inference applications from scratch using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/14/ml-13802-image005-1260x448.png"
        },
        {
          "id": "aa5ed4b4974d094d2d6a878faf6ecc32569ffd3f",
          "author": "Jun Zhang",
          "description": "This post was co-authored with Daniele Chiappalupi, participant of the AWS student Hackathon team at ETH Zürich. Everyone can easily get started with machine learning (ML) using Amazon SageMaker JumpStart. In this post, we show you how a university Hackathon team used SageMaker JumpStart to quickly build an application that helps users identify and remove […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/innovation-for-inclusion-hack-the-bias-with-amazon-sagemaker/",
          "publishedOn": "2023-09-25T18:20:11.000Z",
          "wordCount": 2606,
          "title": "Innovation for Inclusion: Hack.The.Bias with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/25/1-3-1126x630.png"
        },
        {
          "id": "15f7ff093827a9976e8e4feffb8a0ccf7b89c7d2",
          "author": "Gagan Singh",
          "description": "We’re at an exciting inflection point in the widespread adoption of machine learning (ML), and we believe most customer experiences and applications will be reinvented with generative AI. Generative AI can create new content and ideas, including conversations, stories, images, videos, and music. Like most AI, generative AI is powered by ML models—very large models […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/improve-throughput-performance-of-llama-2-models-using-amazon-sagemaker/",
          "publishedOn": "2023-09-25T18:10:40.000Z",
          "wordCount": 3526,
          "title": "Improve throughput performance of Llama 2 models using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/25/improve-throughput.jpg"
        },
        {
          "id": "817ee897c4bac0dc53a1189d5bf7fd7b9e14b6ae",
          "author": "Weifeng Chen",
          "description": "In this blog post, we illustrate how RLHF can be performed on Amazon SageMaker by conducting an experiment with the popular, open-sourced RLHF repo Trlx. Through our experiment, we demonstrate how RLHF can be used to increase the helpfulness or harmlessness of a large language model using the publicly available Helpfulness and Harmlessness (HH) dataset provided by Anthropic. Using this dataset, we conduct our experiment with Amazon SageMaker Studio notebook that is running on an ml.p4d.24xlarge instance. Finally, we provide a Jupyter notebook to replicate our experiments.",
          "link": "https://aws.amazon.com/blogs/machine-learning/improving-your-llms-with-rlhf-on-amazon-sagemaker/",
          "publishedOn": "2023-09-22T20:57:24.000Z",
          "wordCount": 3221,
          "title": "Improving your LLMs with RLHF on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/22/ML-14874_image001-1260x559.jpg"
        },
        {
          "id": "6332bae157cdf6c59677bc015e1727ae2f0d8147",
          "author": "Xin Gu",
          "description": "In this post, we discuss how United Airlines, in collaboration with the Amazon Machine Learning Solutions Lab, build an active learning framework on AWS to automate the processing of passenger documents. “In order to deliver the best flying experience for our passengers and make our internal business process as efficient as possible, we have developed […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-united-airlines-built-a-cost-efficient-optical-character-recognition-active-learning-pipeline/",
          "publishedOn": "2023-09-21T16:53:55.000Z",
          "wordCount": 2895,
          "title": "How United Airlines built a cost-efficient Optical Character Recognition active learning pipeline",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/08/ML-13977-02-903x630.png"
        },
        {
          "id": "44eac549e2383cff99c2864c5888005f737bd59d",
          "author": "Wafae Bakkali",
          "description": "To add to our guidance for optimizing deep learning workloads for sustainability on AWS, this post provides recommendations that are specific to generative AI workloads. In particular, we provide practical best practices for different customization scenarios, including training models from scratch, fine-tuning with additional data using full or parameter-efficient techniques, Retrieval Augmented Generation (RAG), and prompt engineering.",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-generative-ai-workloads-for-environmental-sustainability/",
          "publishedOn": "2023-09-21T16:48:28.000Z",
          "wordCount": 2911,
          "title": "Optimize generative AI workloads for environmental sustainability",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/11/Optimize_generative_AI_workloads_for_Sustainabilit_11092023_1-1.png"
        },
        {
          "id": "d582043900a682b8a84ab5a54abafb83f63e7804",
          "author": "Raja Vaidyanathan",
          "description": "In this post, we demonstrate one of the many options that you have to take advantage of AWS’s broadest and deepest set of AI/ML capabilities in a multicloud environment. We show how you can build and train an ML model in AWS and deploy the model in another platform. We train the model using Amazon SageMaker, store the model artifacts in Amazon Simple Storage Service (Amazon S3), and deploy and run the model in Azure.",
          "link": "https://aws.amazon.com/blogs/machine-learning/train-and-deploy-ml-models-in-a-multicloud-environment-using-amazon-sagemaker/",
          "publishedOn": "2023-09-20T16:56:39.000Z",
          "wordCount": 3923,
          "title": "Train and deploy ML models in a multicloud environment using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/20/train-and-deploy-ml-models-multicloud.jpg"
        },
        {
          "id": "1ec3e0ea3ef6c904f91e4c2db436ba1cfed7514b",
          "author": "Sovik Nath",
          "description": "Multi-modal data is a valuable component of the financial industry, encompassing market, economic, customer, news and social media, and risk data. Financial organizations generate, collect, and use this data to gain insights into financial operations, make better decisions, and improve performance. However, there are challenges associated with multi-modal data due to the complexity and lack […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/generative-ai-and-multi-modal-agents-in-aws-the-key-to-unlocking-new-value-in-financial-markets/",
          "publishedOn": "2023-09-19T16:23:49.000Z",
          "wordCount": 5051,
          "title": "Generative AI and multi-modal agents in AWS: The key to unlocking new value in financial markets",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/08/Picture1-6-1203x630.png"
        },
        {
          "id": "d50057e8a0398ec935e831448aff8cb436a18a1a",
          "author": "Adir Sharabi",
          "description": "This post is written in collaboration with Dima Zadorozhny and Fuad Babaev from VirtuSwap. VirtuSwap is a startup company developing innovative technology for decentralized exchange of assets on blockchains. VirtuSwap’s technology provides more efficient trading for assets that don’t have a direct pair between them. The absence of a direct pair leads to costly indirect trading, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-virtuswap-accelerates-their-pandas-based-trading-simulations-with-an-amazon-sagemaker-studio-custom-container-and-aws-gpu-instances/",
          "publishedOn": "2023-09-19T16:16:53.000Z",
          "wordCount": 2692,
          "title": "How VirtuSwap accelerates their pandas-based trading simulations with an Amazon SageMaker Studio custom container and AWS GPU instances",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/19/virtuswap-sagemaker-studio.jpg"
        },
        {
          "id": "a61e18b8cd9edd926ef8c8226f14bf98683b7024",
          "author": "Dhaval Shah",
          "description": "Amazon SageMaker Feature Store provides an end-to-end solution to automate feature engineering for machine learning (ML). For many ML use cases, raw data like log files, sensor readings, or transaction records need to be transformed into meaningful features that are optimized for model training. Feature quality is critical to ensure a highly accurate ML model. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/unlock-ml-insights-using-the-amazon-sagemaker-feature-store-feature-processor/",
          "publishedOn": "2023-09-19T16:08:57.000Z",
          "wordCount": 3667,
          "title": "Unlock ML insights using the Amazon SageMaker Feature Store Feature Processor",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/19/unlock-ml-insights-feature-store.jpg"
        },
        {
          "id": "fc0e0e9bf65f563699ab2e3085fa359225a66db7",
          "author": "Raju Rangan",
          "description": "Machine learning (ML) is becoming increasingly complex as customers try to solve more and more challenging problems. This complexity often leads to the need for distributed ML, where multiple machines are used to train a single model. Although this enables parallelization of tasks across multiple nodes, leading to accelerated training times, enhanced scalability, and improved […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/orchestrate-ray-based-machine-learning-workflows-using-amazon-sagemaker/",
          "publishedOn": "2023-09-18T17:54:56.000Z",
          "wordCount": 3867,
          "title": "Orchestrate Ray-based machine learning workflows using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/11/DBBLOG_15189_image1.jpng_-716x630.png"
        },
        {
          "id": "2037251e722b8f1a9d5985fbd064c9c71a7f93e7",
          "author": "Richard Alexander",
          "description": "This post is co-authored with Richard Alexander and Mark Hallows from Arup. Arup is a global collective of designers, consultants, and experts dedicated to sustainable development. Data underpins Arup consultancy for clients with world-class collection and analysis providing insight to make an impact. The solution presented here is to direct decision-making processes for resilient city […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/designing-resilient-cities-at-arup-using-amazon-sagemaker-geospatial-capabilities/",
          "publishedOn": "2023-09-18T17:52:40.000Z",
          "wordCount": 2804,
          "title": "Designing resilient cities at Arup using Amazon SageMaker geospatial capabilities",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/07/ml-11881_visualisation-1100x630.png"
        },
        {
          "id": "3078dbf5dded8b902326930cc4c8eaed55ce699b",
          "author": "John Hwang",
          "description": "Large language model (LLM) agents are programs that extend the capabilities of standalone LLMs with 1) access to external tools (APIs, functions, webhooks, plugins, and so on), and 2) the ability to plan and execute tasks in a self-directed fashion. Often, LLMs need to interact with other software, databases, or APIs to accomplish complex tasks. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/learn-how-to-build-and-deploy-tool-using-llm-agents-using-aws-sagemaker-jumpstart-foundation-models/",
          "publishedOn": "2023-09-15T15:24:36.000Z",
          "wordCount": 3809,
          "title": "Learn how to build and deploy tool-using LLM agents using AWS SageMaker JumpStart Foundation Models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/31/ML-15042-solution-overview.jpg"
        },
        {
          "id": "60ba0e07738ad3e7fc6a1a59aa323e2926cb5ba2",
          "author": "Yanyan Zhang",
          "description": "In first part of this multi-series blog post, you will learn how to create a scalable training pipeline and prepare training data for Comprehend Custom Classification models. We will introduce a custom classifier training pipeline that can be deployed in your AWS account with few clicks.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-classification-pipeline-with-amazon-comprehend-custom-classification-part-i/",
          "publishedOn": "2023-09-14T16:58:16.000Z",
          "wordCount": 3113,
          "title": "Build a classification pipeline with Amazon Comprehend custom classification (Part I)",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/01/ML14789_1_image_1.jpg"
        },
        {
          "id": "79e9de80c1ca72d14b38bb721ea7c350683f1306",
          "author": "Bruno Pistone",
          "description": "Today, generative AI models cover a variety of tasks from text summarization, Q&A, and image and video generation. To improve the quality of output, approaches like n-short learning, Prompt engineering, Retrieval Augmented Generation (RAG) and fine tuning are used. Fine-tuning allows you to adjust these generative AI models to achieve improved performance on your domain-specific […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/fine-tune-falcon-7b-and-other-llms-on-amazon-sagemaker-with-remote-decorator/",
          "publishedOn": "2023-09-14T16:53:48.000Z",
          "wordCount": 2542,
          "title": "Fine-tune Falcon 7B and other LLMs on Amazon SageMaker with @remote decorator",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/14/fine-tune-falcon-7b-1260x630.jpg"
        },
        {
          "id": "f373585d90ca2452a8f575b61523a3b5d9993d14",
          "author": "Abhishek Maligehalli Shivalingaiah",
          "description": "This post takes you through the most common challenges that customers face when searching internal documents, and gives you concrete guidance on how AWS services can be used to create a generative AI conversational bot that makes internal information more useful. Unstructured data accounts for 80% of all the data found within organizations, consisting of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/simplify-access-to-internal-information-using-retrieval-augmented-generation-and-langchain-agents/",
          "publishedOn": "2023-09-14T16:47:56.000Z",
          "wordCount": 4175,
          "title": "Simplify access to internal information using Retrieval Augmented Generation and LangChain Agents",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/14/DBSBLOG-14696_Image_10-1057x630.jpg"
        },
        {
          "id": "40be6ff2f4544c5a10bacc0b64db35ad113ba178",
          "author": "Clark Lefavour",
          "description": "Searching for insights in a repository of free-form text documents can be like finding a needle in a haystack. A traditional approach might be to use word counting or other basic analysis to parse documents, but with the power of Amazon AI and machine learning (ML) tools, we can gather deeper understanding of the content. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/visualize-an-amazon-comprehend-analysis-with-a-word-cloud-in-amazon-quicksight/",
          "publishedOn": "2023-09-13T16:23:42.000Z",
          "wordCount": 2297,
          "title": "Visualize an Amazon Comprehend analysis with a word cloud in Amazon QuickSight",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/13/visualize-comprehend-wordcloud.jpg"
        },
        {
          "id": "c5176386a69be025f1a39037ff987ad3db274ed8",
          "author": "Vikesh Pandey",
          "description": "Today, we are excited to announce the simplified Quick setup experience in Amazon SageMaker. With this new capability, individual users can launch Amazon SageMaker Studio with default presets in minutes. SageMaker Studio is an integrated development environment (IDE) for machine learning (ML). ML practitioners can perform all ML development steps—from preparing their data to building, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-simplifies-the-amazon-sagemaker-studio-setup-for-individual-users/",
          "publishedOn": "2023-09-12T16:43:16.000Z",
          "wordCount": 1700,
          "title": "Amazon SageMaker simplifies the Amazon SageMaker Studio setup for individual users",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/sagemaker-simplifies-studio-setup.jpg"
        },
        {
          "id": "d0725fec0786bb2853300d9d418b133d27b9b555",
          "author": "Xan Huang",
          "description": "This post addresses the challenge faced by developers and support teams when application logs are presented in languages other than English, making it difficult for them to debug and provide support. The proposed solution uses Amazon Translate to automatically translate non-English logs in CloudWatch, and provides step-by-step guidance on deploying the solution in your environment.",
          "link": "https://aws.amazon.com/blogs/machine-learning/unlocking-language-barriers-translate-application-logs-with-amazon-translate-for-seamless-support/",
          "publishedOn": "2023-09-12T16:09:35.000Z",
          "wordCount": 1705,
          "title": "Unlocking language barriers: Translate application logs with Amazon Translate for seamless support",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/unlocking-language-barriers.jpg"
        },
        {
          "id": "c5489b6f165eb2ac2631eadd90827f7f2ed24a2d",
          "author": "Dr. Sandra Schmid",
          "description": "In this post, we share how SageMaker facilitates the data science team at Scalable to manage the lifecycle of a data science project efficiently, namely the email classifier project. The lifecycle starts with the initial phase of data analysis and exploration with SageMaker Studio; moves on to model experimentation and deployment with SageMaker training, inference, and Hugging Face DLCs; and completes with a training pipeline with SageMaker Pipelines integrated with other AWS services",
          "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-client-success-management-through-email-classification-with-hugging-face-on-amazon-sagemaker/",
          "publishedOn": "2023-09-12T16:05:21.000Z",
          "wordCount": 2904,
          "title": "Accelerate client success management through email classification with Hugging Face on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/accelerate-client-success.jpg"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2306.03364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michel_N/0/1/0/all/0/1\">Nicolas Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chierchia_G/0/1/0/all/0/1\">Giovanni Chierchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negrel_R/0/1/0/all/0/1\">Romain Negrel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bercher_J/0/1/0/all/0/1\">Jean-Fran&#xe7;ois Bercher</a>",
          "description": "We use the maximum a posteriori estimation principle for learning\nrepresentations distributed on the unit sphere. We propose to use the angular\nGaussian distribution, which corresponds to a Gaussian projected on the\nunit-sphere and derive the associated loss function. We also consider the von\nMises-Fisher distribution, which is the conditional of a Gaussian in the\nunit-sphere. The learned representations are pushed toward fixed directions,\nwhich are the prior means of the Gaussians; allowing for a learning strategy\nthat is resilient to data drift. This makes it suitable for online continual\nlearning, which is the problem of training neural networks on a continuous data\nstream, where multiple classification tasks are presented sequentially so that\ndata from past tasks are no longer accessible, and data from the current task\ncan be seen only once. To address this challenging scenario, we propose a\nmemory-based representation learning technique equipped with our new loss\nfunctions. Our approach does not require negative data or knowledge of task\nboundaries and performs well with smaller batch sizes while being\ncomputationally efficient. We demonstrate with extensive experiments that the\nproposed method outperforms the current state-of-the-art methods on both\nstandard evaluation scenarios and realistic scenarios with blurry task\nboundaries. For reproducibility, we use the same training pipeline for every\ncompared method and share the code at https://t.ly/SQTj.",
          "link": "http://arxiv.org/abs/2306.03364",
          "publishedOn": "2023-10-07T00:42:21.704Z",
          "wordCount": 799,
          "title": "Learning Representations on the Unit Sphere: Investigating Angular Gaussian and von Mises-Fisher Distributions for Online Continual Learning. (arXiv:2306.03364v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.02936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bie_A/0/1/0/all/0/1\">Alex Bie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1\">Gautam Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guojun Zhang</a>",
          "description": "We show that the canonical approach for training differentially private GANs\n-- updating the discriminator with differentially private stochastic gradient\ndescent (DPSGD) -- can yield significantly improved results after modifications\nto training. Specifically, we propose that existing instantiations of this\napproach neglect to consider how adding noise only to discriminator updates\ninhibits discriminator training, disrupting the balance between the generator\nand discriminator necessary for successful GAN training. We show that a simple\nfix -- taking more discriminator steps between generator steps -- restores\nparity between the generator and discriminator and improves results.\n\nAdditionally, with the goal of restoring parity, we experiment with other\nmodifications -- namely, large batch sizes and adaptive discriminator update\nfrequency -- to improve discriminator training and see further improvements in\ngeneration quality. Our results demonstrate that on standard image synthesis\nbenchmarks, DPSGD outperforms all alternative GAN privatization schemes. Code:\nhttps://github.com/alexbie98/dpgan-revisit.",
          "link": "http://arxiv.org/abs/2302.02936",
          "publishedOn": "2023-10-07T00:42:21.680Z",
          "wordCount": 673,
          "title": "Private GANs, Revisited. (arXiv:2302.02936v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.14331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hongwu Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ran_R/0/1/0/all/0/1\">Ran Ran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yukui Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiahui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaoyi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorat_K/0/1/0/all/0/1\">Kiran Thorat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_T/0/1/0/all/0/1\">Tong Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenghong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaolin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1\">Wujie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Caiwen Ding</a>",
          "description": "The growth of Graph Convolution Network (GCN) model sizes has revolutionized\nnumerous applications, surpassing human performance in areas such as personal\nhealthcare and financial systems. The deployment of GCNs in the cloud raises\nprivacy concerns due to potential adversarial attacks on client data. To\naddress security concerns, Privacy-Preserving Machine Learning (PPML) using\nHomomorphic Encryption (HE) secures sensitive client data. However, it\nintroduces substantial computational overhead in practical applications. To\ntackle those challenges, we present LinGCN, a framework designed to reduce\nmultiplication depth and optimize the performance of HE based GCN inference.\nLinGCN is structured around three key elements: (1) A differentiable structural\nlinearization algorithm, complemented by a parameterized discrete indicator\nfunction, co-trained with model weights to meet the optimization goal. This\nstrategy promotes fine-grained node-level non-linear location selection,\nresulting in a model with minimized multiplication depth. (2) A compact\nnode-wise polynomial replacement policy with a second-order trainable\nactivation function, steered towards superior convergence by a two-level\ndistillation approach from an all-ReLU based teacher model. (3) an enhanced HE\nsolution that enables finer-grained operator fusion for node-wise activation\nfunctions, further reducing multiplication level consumption in HE-based\ninference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that\nLinGCN excels in latency, accuracy, and scalability for homomorphically\nencrypted inference, outperforming solutions such as CryptoGCN. Remarkably,\nLinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving\nan inference accuracy of 75% and notably reducing multiplication depth.",
          "link": "http://arxiv.org/abs/2309.14331",
          "publishedOn": "2023-10-07T00:42:21.631Z",
          "wordCount": 856,
          "title": "LinGCN: Structural Linearized Graph Convolutional Network for Homomorphically Encrypted Inference. (arXiv:2309.14331v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.17357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karkar_S/0/1/0/all/0/1\">Skander Karkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ibrahim Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a>",
          "description": "Greedy layer-wise or module-wise training of neural networks is compelling in\nconstrained and on-device settings where memory is limited, as it circumvents a\nnumber of problems of end-to-end back-propagation. However, it suffers from a\nstagnation problem, whereby early layers overfit and deeper layers stop\nincreasing the test accuracy after a certain depth. We propose to solve this\nissue by introducing a module-wise regularization inspired by the minimizing\nmovement scheme for gradient flows in distribution space. We call the method\nTRGL for Transport Regularized Greedy Learning and study it theoretically,\nproving that it leads to greedy modules that are regular and that progressively\nsolve the task. Experimentally, we show improved accuracy of module-wise\ntraining of various architectures such as ResNets, Transformers and VGG, when\nour regularization is added, superior to that of other module-wise training\nmethods and often to end-to-end training, with as much as 60% less memory\nusage.",
          "link": "http://arxiv.org/abs/2309.17357",
          "publishedOn": "2023-10-07T00:42:21.551Z",
          "wordCount": 708,
          "title": "Module-wise Training of Neural Networks via the Minimizing Movement Scheme. (arXiv:2309.17357v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2010.11559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yangjing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toh_K/0/1/0/all/0/1\">Kim-Chuan Toh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1\">Defeng Sun</a>",
          "description": "We consider the problem of learning a graph under the Laplacian constraint\nwith a non-convex penalty: minimax concave penalty (MCP). For solving the MCP\npenalized graphical model, we design an inexact proximal difference-of-convex\nalgorithm (DCA) and prove its convergence to critical points. We note that each\nsubproblem of the proximal DCA enjoys the nice property that the objective\nfunction in its dual problem is continuously differentiable with a semismooth\ngradient. Therefore, we apply an efficient semismooth Newton method to\nsubproblems of the proximal DCA. Numerical experiments on various synthetic and\nreal data sets demonstrate the effectiveness of the non-convex penalty MCP in\npromoting sparsity. Compared with the existing state-of-the-art method, our\nmethod is demonstrated to be more efficient and reliable for learning graph\nLaplacian with MCP.",
          "link": "http://arxiv.org/abs/2010.11559",
          "publishedOn": "2023-10-07T00:42:21.522Z",
          "wordCount": 651,
          "title": "Learning Graph Laplacian with MCP. (arXiv:2010.11559v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.05895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1\">Baoxiong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yixin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in generative modeling. Fueled by its flexibility\nin the formulation and strong modeling power of the latent space, recent works\nbuilt upon it have made interesting attempts aiming at the interpretability of\ntext modeling. However, latent space EBMs also inherit some flaws from EBMs in\ndata space; the degenerate MCMC sampling quality in practice can lead to poor\ngeneration quality and instability in training, especially on data with complex\nlatent structures. Inspired by the recent efforts that leverage diffusion\nrecovery likelihood learning as a cure for the sampling issue, we introduce a\nnovel symbiosis between the diffusion models and latent space EBMs in a\nvariational learning framework, coined as the latent diffusion energy-based\nmodel. We develop a geometric clustering-based regularization jointly with the\ninformation bottleneck to further improve the quality of the learned latent\nspace. Experiments on several challenging tasks demonstrate the superior\nperformance of our model on interpretable text modeling over strong\ncounterparts.",
          "link": "http://arxiv.org/abs/2206.05895",
          "publishedOn": "2023-10-07T00:42:21.515Z",
          "wordCount": 723,
          "title": "Latent Diffusion Energy-Based Model for Interpretable Text Modeling. (arXiv:2206.05895v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schiemer_M/0/1/0/all/0/1\">Martin Schiemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaefer_C/0/1/0/all/0/1\">Clemens JS Schaefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vap_J/0/1/0/all/0/1\">Jayden Parker Vap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horeni_M/0/1/0/all/0/1\">Mark James Horeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Emma Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Juan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Siddharth Joshi</a>",
          "description": "Continual learning is a desirable feature in many modern machine learning\napplications, which allows in-field adaptation and updating, ranging from\naccommodating distribution shift, to fine-tuning, and to learning new tasks.\nFor applications with privacy and low latency requirements, the compute and\nmemory demands imposed by continual learning can be cost-prohibitive for\nresource-constraint edge platforms. Reducing computational precision through\nfully quantized training (FQT) simultaneously reduces memory footprint and\nincreases compute efficiency for both training and inference. However,\naggressive quantization especially integer FQT typically degrades model\naccuracy to unacceptable levels. In this paper, we propose a technique that\nleverages inexpensive Hadamard transforms to enable low-precision training with\nonly integer matrix multiplications. We further determine which tensors need\nstochastic rounding and propose tiled matrix multiplication to enable low-bit\nwidth accumulators. We demonstrate the effectiveness of our technique on\nseveral human activity recognition datasets and CIFAR100 in a class incremental\nlearning setting. We achieve less than 0.5% and 3% accuracy degradation while\nwe quantize all matrix multiplications inputs down to 4-bits with 8-bit\naccumulators.",
          "link": "http://arxiv.org/abs/2310.03675",
          "publishedOn": "2023-10-07T00:42:21.495Z",
          "wordCount": 692,
          "title": "Hadamard Domain Training with Integers for Class Incremental Quantized Learning. (arXiv:2310.03675v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.01751",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_G/0/1/0/all/0/1\">Guan-Horng Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>",
          "description": "It is a crucial challenge to reconstruct population dynamics using unlabeled\nsamples from distributions at coarse time intervals. Recent approaches such as\nflow-based models or Schr\\\"odinger Bridge (SB) models have demonstrated\nappealing performance, yet the inferred sample trajectories either fail to\naccount for the underlying stochasticity or are $\\underline{D}$eep\n$\\underline{M}$omentum Multi-Marginal $\\underline{S}$chr\\\"odinger\n$\\underline{B}$ridge(DMSB), a novel computational framework that learns the\nsmooth measure-valued spline for stochastic systems that satisfy position\nmarginal constraints across time. By tailoring the celebrated Bregman Iteration\nand extending the Iteration Proportional Fitting to phase space, we manage to\nhandle high-dimensional multi-marginal trajectory inference tasks efficiently.\nOur algorithm outperforms baselines significantly, as evidenced by experiments\nfor synthetic datasets and a real-world single-cell RNA sequence dataset.\nAdditionally, the proposed approach can reasonably reconstruct the evolution of\nvelocity distribution, from position snapshots only, when there is a ground\ntruth velocity that is nevertheless inaccessible.",
          "link": "http://arxiv.org/abs/2303.01751",
          "publishedOn": "2023-10-07T00:42:21.455Z",
          "wordCount": 658,
          "title": "Deep Momentum Multi-Marginal Schr\\\"odinger Bridge. (arXiv:2303.01751v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.02648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moayeri_M/0/1/0/all/0/1\">Mazda Moayeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "We present a simple but effective method to measure and mitigate model biases\ncaused by reliance on spurious cues. Instead of requiring costly changes to\none's data or model training, our method better utilizes the data one already\nhas by sorting them. Specifically, we rank images within their classes based on\nspuriosity (the degree to which common spurious cues are present), proxied via\ndeep neural features of an interpretable network. With spuriosity rankings, it\nis easy to identify minority subpopulations (i.e. low spuriosity images) and\nassess model bias as the gap in accuracy between high and low spuriosity\nimages. One can even efficiently remove a model's bias at little cost to\naccuracy by finetuning its classification head on low spuriosity images,\nresulting in fairer treatment of samples regardless of spuriosity. We\ndemonstrate our method on ImageNet, annotating $5000$ class-feature\ndependencies ($630$ of which we find to be spurious) and generating a dataset\nof $325k$ soft segmentations for these features along the way. Having computed\nspuriosity rankings via the identified spurious neural features, we assess\nbiases for $89$ diverse models and find that class-wise biases are highly\ncorrelated across models. Our results suggest that model bias due to spurious\nfeature reliance is influenced far more by what the model is trained on than\nhow it is trained.",
          "link": "http://arxiv.org/abs/2212.02648",
          "publishedOn": "2023-10-07T00:42:21.448Z",
          "wordCount": 754,
          "title": "Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases. (arXiv:2212.02648v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.12148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madan_N/0/1/0/all/0/1\">Neelu Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1\">Nicolae-Catalin Ristea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasrollahi_K/0/1/0/all/0/1\">Kamal Nasrollahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moeslund_T/0/1/0/all/0/1\">Thomas B. Moeslund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Anomaly detection has recently gained increasing attention in the field of\ncomputer vision, likely due to its broad set of applications ranging from\nproduct fault detection on industrial production lines and impending event\ndetection in video surveillance to finding lesions in medical scans. Regardless\nof the domain, anomaly detection is typically framed as a one-class\nclassification task, where the learning is conducted on normal examples only.\nAn entire family of successful anomaly detection methods is based on learning\nto reconstruct masked normal inputs (e.g. patches, future frames, etc.) and\nexerting the magnitude of the reconstruction error as an indicator for the\nabnormality level. Unlike other reconstruction-based methods, we present a\nnovel self-supervised masked convolutional transformer block (SSMCTB) that\ncomprises the reconstruction-based functionality at a core architectural level.\nThe proposed self-supervised block is extremely flexible, enabling information\nmasking at any layer of a neural network and being compatible with a wide range\nof neural architectures. In this work, we extend our previous self-supervised\npredictive convolutional attentive block (SSPCAB) with a 3D masked\nconvolutional layer, a transformer for channel-wise attention, as well as a\nnovel self-supervised objective based on Huber loss. Furthermore, we show that\nour block is applicable to a wider variety of tasks, adding anomaly detection\nin medical images and thermal videos to the previously considered tasks based\non RGB images and surveillance videos. We exhibit the generality and\nflexibility of SSMCTB by integrating it into multiple state-of-the-art neural\nmodels for anomaly detection, bringing forth empirical results that confirm\nconsiderable performance improvements on five benchmarks. We release our code\nand data as open source at: https://github.com/ristea/ssmctb.",
          "link": "http://arxiv.org/abs/2209.12148",
          "publishedOn": "2023-10-07T00:42:21.419Z",
          "wordCount": 827,
          "title": "Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection. (arXiv:2209.12148v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schulze_L/0/1/0/all/0/1\">Lennart Schulze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1\">Hod Lipson</a>",
          "description": "A robot self-model is a task-agnostic representation of the robot's physical\nmorphology that can be used for motion planning tasks in absence of classical\ngeometric kinematic models. In particular, when the latter are hard to engineer\nor the robot's kinematics change unexpectedly, human-free self-modeling is a\nnecessary feature of truly autonomous agents. In this work, we leverage neural\nfields to allow a robot to self-model its kinematics as a neural-implicit query\nmodel learned only from 2D images annotated with camera poses and\nconfigurations. This enables significantly greater applicability than existing\napproaches which have been dependent on depth images or geometry knowledge. To\nthis end, alongside a curricular data sampling strategy, we propose a new\nencoder-based neural density field architecture for dynamic object-centric\nscenes conditioned on high numbers of degrees of freedom (DOFs). In a 7-DOF\nrobot test setup, the learned self-model achieves a Chamfer-L2 distance of 2%\nof the robot's workspace dimension. We demonstrate the capabilities of this\nmodel on a motion planning task as an exemplary downstream application.",
          "link": "http://arxiv.org/abs/2310.03624",
          "publishedOn": "2023-10-07T00:42:21.349Z",
          "wordCount": 693,
          "title": "High-Degrees-of-Freedom Dynamic Neural Fields for Robot Self-Modeling and Motion Planning. (arXiv:2310.03624v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.02671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Klein_S/0/1/0/all/0/1\">Sara Klein</a>, <a href=\"http://arxiv.org/find/math/1/au:+Weissmann_S/0/1/0/all/0/1\">Simon Weissmann</a>, <a href=\"http://arxiv.org/find/math/1/au:+Doring_L/0/1/0/all/0/1\">Leif D&#xf6;ring</a>",
          "description": "Markov Decision Processes (MDPs) are a formal framework for modeling and\nsolving sequential decision-making problems. In finite-time horizons such\nproblems are relevant for instance for optimal stopping or specific supply\nchain problems, but also in the training of large language models. In contrast\nto infinite horizon MDPs optimal policies are not stationary, policies must be\nlearned for every single epoch. In practice all parameters are often trained\nsimultaneously, ignoring the inherent structure suggested by dynamic\nprogramming. This paper introduces a combination of dynamic programming and\npolicy gradient called dynamic policy gradient, where the parameters are\ntrained backwards in time. For the tabular softmax parametrisation we carry out\nthe convergence analysis for simultaneous and dynamic policy gradient towards\nglobal optima, both in the exact and sampled gradient settings without\nregularisation. It turns out that the use of dynamic policy gradient training\nmuch better exploits the structure of finite-time problems which is reflected\nin improved convergence bounds.",
          "link": "http://arxiv.org/abs/2310.02671",
          "publishedOn": "2023-10-07T00:42:21.342Z",
          "wordCount": 664,
          "title": "Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods. (arXiv:2310.02671v1 [math.OC] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>",
          "description": "High-quality text embedding is pivotal in improving semantic textual\nsimilarity (STS) tasks, which are crucial components in Large Language Model\n(LLM) applications. However, a common challenge existing text embedding models\nface is the problem of vanishing gradients, primarily due to their reliance on\nthe cosine function in the optimization objective, which has saturation zones.\nTo address this issue, this paper proposes a novel angle-optimized text\nembedding model called AnglE. The core idea of AnglE is to introduce angle\noptimization in a complex space. This novel approach effectively mitigates the\nadverse effects of the saturation zone in the cosine function, which can impede\ngradient and hinder optimization processes. To set up a comprehensive STS\nevaluation, we experimented on existing short-text STS datasets and a newly\ncollected long-text STS dataset from GitHub Issues. Furthermore, we examine\ndomain-specific STS scenarios with limited labeled data and explore how AnglE\nworks with LLM-annotated data. Extensive experiments were conducted on various\ntasks including short-text STS, long-text STS, and domain-specific STS tasks.\nThe results show that AnglE outperforms the state-of-the-art (SOTA) STS models\nthat ignore the cosine saturation zone. These findings demonstrate the ability\nof AnglE to generate high-quality text embeddings and the usefulness of angle\noptimization in STS.",
          "link": "http://arxiv.org/abs/2309.12871",
          "publishedOn": "2023-10-07T00:42:21.336Z",
          "wordCount": 705,
          "title": "AnglE-optimized Text Embeddings. (arXiv:2309.12871v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Houxing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aojun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zimu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Sichun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weikang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Renrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_M/0/1/0/all/0/1\">Mingjie Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "The recently released GPT-4 Code Interpreter has demonstrated remarkable\nproficiency in solving challenging math problems, primarily attributed to its\nability to seamlessly reason with natural language, generate code, execute\ncode, and continue reasoning based on the execution output. In this paper, we\npresent a method to fine-tune open-source language models, enabling them to use\ncode for modeling and deriving math equations and, consequently, enhancing\ntheir mathematical reasoning abilities. We propose a method of generating novel\nand high-quality datasets with math problems and their code-based solutions,\nreferred to as MathCodeInstruct. Each solution interleaves natural language,\ncode, and execution results. We also introduce a customized supervised\nfine-tuning and inference approach. This approach yields the MathCoder models,\na family of models capable of generating code-based solutions for solving\nchallenging math problems. Impressively, the MathCoder models achieve\nstate-of-the-art scores among open-source LLMs on the MATH (45.2%) and GSM8K\n(83.9%) datasets, substantially outperforming other open-source alternatives.\nNotably, the MathCoder model not only surpasses ChatGPT-3.5 and PaLM-2 on GSM8K\nand MATH but also outperforms GPT-4 on the competition-level MATH dataset. The\ndataset and models will be released at https://github.com/mathllm/MathCoder.",
          "link": "http://arxiv.org/abs/2310.03731",
          "publishedOn": "2023-10-07T00:42:21.276Z",
          "wordCount": 725,
          "title": "MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning. (arXiv:2310.03731v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.10650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slusarz_N/0/1/0/all/0/1\">Natalia &#x15a;lusarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komendantskaya_E/0/1/0/all/0/1\">Ekaterina Komendantskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daggitt_M/0/1/0/all/0/1\">Matthew L. Daggitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stewart_R/0/1/0/all/0/1\">Robert Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stark_K/0/1/0/all/0/1\">Kathrin Stark</a>",
          "description": "Differentiable logics (DL) have recently been proposed as a method of\ntraining neural networks to satisfy logical specifications. A DL consists of a\nsyntax in which specifications are stated and an interpretation function that\ntranslates expressions in the syntax into loss functions. These loss functions\ncan then be used during training with standard gradient descent algorithms. The\nvariety of existing DLs and the differing levels of formality with which they\nare treated makes a systematic comparative study of their properties and\nimplementations difficult. This paper remedies this problem by suggesting a\nmeta-language for defining DLs that we call the Logic of Differentiable Logics,\nor LDL. Syntactically, it generalises the syntax of existing DLs to FOL, and\nfor the first time introduces the formalism for reasoning about vectors and\nlearners. Semantically, it introduces a general interpretation function that\ncan be instantiated to define loss functions arising from different existing\nDLs. We use LDL to establish several theoretical properties of existing DLs,\nand to conduct their empirical study in neural network verification.",
          "link": "http://arxiv.org/abs/2303.10650",
          "publishedOn": "2023-10-07T00:42:21.104Z",
          "wordCount": 725,
          "title": "Logic of Differentiable Logics: Towards a Uniform Semantics of DL. (arXiv:2303.10650v4 [cs.LO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.04054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hagmann_M/0/1/0/all/0/1\">Michael Hagmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meier_P/0/1/0/all/0/1\">Philipp Meier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>",
          "description": "Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.",
          "link": "http://arxiv.org/abs/2302.04054",
          "publishedOn": "2023-10-07T00:42:21.087Z",
          "wordCount": 773,
          "title": "Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.12081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chufan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Cao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "Tabular data prediction has been employed in medical applications such as\npatient health risk prediction. However, existing methods usually revolve\naround the algorithm design while overlooking the significance of data\nengineering. Medical tabular datasets frequently exhibit significant\nheterogeneity across different sources, with limited sample sizes per source.\nAs such, previous predictors are often trained on manually curated small\ndatasets that struggle to generalize across different tabular datasets during\ninference. This paper proposes to scale medical tabular data predictors\n(MediTab) to various tabular inputs with varying features. The method uses a\ndata engine that leverages large language models (LLMs) to consolidate tabular\nsamples to overcome the barrier across tables with distinct schema. It also\naligns out-domain data with the target task using a \"learn, annotate, and\nrefinement\" pipeline. The expanded training data then enables the pre-trained\nMediTab to infer for arbitrary tabular input in the domain without fine-tuning,\nresulting in significant improvements over supervised baselines: it reaches an\naverage ranking of 1.57 and 1.00 on 7 patient outcome prediction datasets and 3\ntrial outcome prediction datasets, respectively. In addition, MediTab exhibits\nimpressive zero-shot performances: it outperforms supervised XGBoost models by\n8.9% and 17.2% on average in two prediction tasks, respectively. The code is\navailable at https://github.com/RyanWangZf/MediTab.",
          "link": "http://arxiv.org/abs/2305.12081",
          "publishedOn": "2023-10-07T00:42:21.059Z",
          "wordCount": 755,
          "title": "MediTab: Scaling Medical Tabular Data Predictors via Data Consolidation, Enrichment, and Refinement. (arXiv:2305.12081v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1\">Omar Khattab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singhvi_A/0/1/0/all/0/1\">Arnav Singhvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_P/0/1/0/all/0/1\">Paridhi Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santhanam_K/0/1/0/all/0/1\">Keshav Santhanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardhamanan_S/0/1/0/all/0/1\">Sri Vardhamanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haq_S/0/1/0/all/0/1\">Saiful Haq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Ashutosh Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_T/0/1/0/all/0/1\">Thomas T. Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moazam_H/0/1/0/all/0/1\">Hanna Moazam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_H/0/1/0/all/0/1\">Heather Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>",
          "description": "The ML community is rapidly exploring techniques for prompting language\nmodels (LMs) and for stacking them into pipelines that solve complex tasks.\nUnfortunately, existing LM pipelines are typically implemented using hard-coded\n\"prompt templates\", i.e. lengthy strings discovered via trial and error. Toward\na more systematic approach for developing and optimizing LM pipelines, we\nintroduce DSPy, a programming model that abstracts LM pipelines as text\ntransformation graphs, i.e. imperative computational graphs where LMs are\ninvoked through declarative modules. DSPy modules are parameterized, meaning\nthey can learn (by creating and collecting demonstrations) how to apply\ncompositions of prompting, finetuning, augmentation, and reasoning techniques.\nWe design a compiler that will optimize any DSPy pipeline to maximize a given\nmetric. We conduct two case studies, showing that succinct DSPy programs can\nexpress and optimize sophisticated LM pipelines that reason about math word\nproblems, tackle multi-hop retrieval, answer complex questions, and control\nagent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and\nllama2-13b-chat to self-bootstrap pipelines that outperform standard few-shot\nprompting (generally by over 25% and 65%, respectively) and pipelines with\nexpert-created demonstrations (by up to 5-46% and 16-40%, respectively). On top\nof that, DSPy programs compiled to open and relatively small LMs like\n770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely\non expert-written prompt chains for proprietary GPT-3.5. DSPy is available at\nhttps://github.com/stanfordnlp/dspy",
          "link": "http://arxiv.org/abs/2310.03714",
          "publishedOn": "2023-10-07T00:42:21.052Z",
          "wordCount": 758,
          "title": "DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines. (arXiv:2310.03714v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elnaggar_A/0/1/0/all/0/1\">Ahmed Fakhry Elnaggar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khafagy_R/0/1/0/all/0/1\">Raneem Ali Khafagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludl_A/0/1/0/all/0/1\">Adriaan-Alexander Ludl</a>",
          "description": "Detecting and discovering new gene interactions based on known gene\nexpressions and gene interaction data presents a significant challenge. Various\nstatistical and deep learning methods have attempted to tackle this challenge\nby leveraging the topological structure of gene interactions and gene\nexpression patterns to predict novel gene interactions. In contrast, some\napproaches have focused exclusively on utilizing gene expression profiles. In\nthis context, we introduce GENER, a parallel-layer deep learning network\ndesigned exclusively for the identification of gene-gene relationships using\ngene expression data. We conducted two training experiments and compared the\nperformance of our network with that of existing statistical and deep learning\napproaches. Notably, our model achieved an average AUROC score of 0.834 on the\ncombined BioGRID&DREAM5 dataset, outperforming competing methods in predicting\ngene-gene interactions.",
          "link": "http://arxiv.org/abs/2310.03611",
          "publishedOn": "2023-10-07T00:42:21.044Z",
          "wordCount": 657,
          "title": "GENER: A Parallel Layer Deep Learning Network To Detect Gene-Gene Interactions From Gene Expression Data. (arXiv:2310.03611v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.00942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehanobish_A/0/1/0/all/0/1\">Arijit Sehanobish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Han Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yunfan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_E/0/1/0/all/0/1\">Eli Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parshakova_T/0/1/0/all/0/1\">Tetiana Parshakova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_A/0/1/0/all/0/1\">Alvin Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_D/0/1/0/all/0/1\">David Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1\">Valerii Likhosherstov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Somnath Basu Roy Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1\">Avinava Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1\">Deepali Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1\">Tamas Sarlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaturvedi_S/0/1/0/all/0/1\">Snigdha Chaturvedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>",
          "description": "We present two new classes of algorithms for efficient field integration on\ngraphs encoding point clouds. The first class, SeparatorFactorization(SF),\nleverages the bounded genus of point cloud mesh graphs, while the second class,\nRFDiffusion(RFD), uses popular epsilon-nearest-neighbor graph representations\nfor point clouds. Both can be viewed as providing the functionality of Fast\nMultipole Methods (FMMs), which have had a tremendous impact on efficient\nintegration, but for non-Euclidean spaces. We focus on geometries induced by\ndistributions of walk lengths between points (e.g., shortest-path distance). We\nprovide an extensive theoretical analysis of our algorithms, obtaining new\nresults in structural graph theory as a byproduct. We also perform exhaustive\nempirical evaluation, including on-surface interpolation for rigid and\ndeformable objects (particularly for mesh-dynamics modeling), Wasserstein\ndistance computations for point clouds, and the Gromov-Wasserstein variant.",
          "link": "http://arxiv.org/abs/2302.00942",
          "publishedOn": "2023-10-07T00:42:21.036Z",
          "wordCount": 710,
          "title": "Efficient Graph Field Integrators Meet Point Clouds. (arXiv:2302.00942v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Golovanevsky_M/0/1/0/all/0/1\">Michal Golovanevsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiller_E/0/1/0/all/0/1\">Eva Schiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Akira Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Ritambhara Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1\">Carsten Eickhoff</a>",
          "description": "Multimodal learning models have become increasingly important as they surpass\nsingle-modality approaches on diverse tasks ranging from question-answering to\nautonomous driving. Despite the importance of multimodal learning, existing\nefforts focus on NLP applications, where the number of modalities is typically\nless than four (audio, video, text, images). However, data inputs in other\ndomains, such as the medical field, may include X-rays, PET scans, MRIs,\ngenetic screening, clinical notes, and more, creating a need for both efficient\nand accurate information fusion. Many state-of-the-art models rely on pairwise\ncross-modal attention, which does not scale well for applications with more\nthan three modalities. For $n$ modalities, computing attention will result in\n$n \\choose 2$ operations, potentially requiring considerable amounts of\ncomputational resources. To address this, we propose a new domain-neutral\nattention mechanism, One-Versus-Others (OvO) attention, that scales linearly\nwith the number of modalities and requires only $n$ attention operations, thus\noffering a significant reduction in computational complexity compared to\nexisting cross-modal attention algorithms. Using three diverse real-world\ndatasets as well as an additional simulation experiment, we show that our\nmethod improves performance compared to popular fusion techniques while\ndecreasing computation costs.",
          "link": "http://arxiv.org/abs/2307.05435",
          "publishedOn": "2023-10-07T00:42:21.006Z",
          "wordCount": 698,
          "title": "One-Versus-Others Attention: Scalable Multimodal Integration. (arXiv:2307.05435v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.11447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1\">Xinyu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yichun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jingwen Shi</a>",
          "description": "Federated learning (FL) supports distributed training of a global machine\nlearning model across multiple devices with the help of a central server.\nHowever, data heterogeneity across different devices leads to the client model\ndrift issue and results in model performance degradation and poor model\nfairness. To address the issue, we design Federated learning with global-local\nKnowledge Fusion (FedKF) scheme in this paper. The key idea in FedKF is to let\nthe server return the global knowledge to be fused with the local knowledge in\neach training round so that the local model can be regularized towards the\nglobal optima. Therefore, the client model drift issue can be mitigated. In\nFedKF, we first propose the active-inactive model aggregation technique that\nsupports a precise global knowledge representation. Then, we propose a\ndata-free knowledge distillation (KD) approach to enable each client model to\nlearn the global knowledge (embedded in the global model) while each client\nmodel can still learn the local knowledge (embedded in the local dataset)\nsimultaneously, thereby realizing the global-local knowledge fusion process.\nThe theoretical analysis and intensive experiments demonstrate the superiority\nof FedKF over previous solutions.",
          "link": "http://arxiv.org/abs/2207.11447",
          "publishedOn": "2023-10-07T00:42:20.997Z",
          "wordCount": 727,
          "title": "Handling Data Heterogeneity in Federated Learning via Knowledge Distillation and Fusion. (arXiv:2207.11447v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tinghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1\">Peter Henderson</a>",
          "description": "Optimizing large language models (LLMs) for downstream use cases often\ninvolves the customization of pre-trained LLMs through further fine-tuning.\nMeta's open release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5\nTurbo on custom datasets also encourage this practice. But, what are the safety\ncosts associated with such custom fine-tuning? We note that while existing\nsafety alignment infrastructures can restrict harmful behaviors of LLMs at\ninference time, they do not cover safety risks when fine-tuning privileges are\nextended to end-users. Our red teaming studies find that the safety alignment\nof LLMs can be compromised by fine-tuning with only a few adversarially\ndesigned training examples. For instance, we jailbreak GPT-3.5 Turbo's safety\nguardrails by fine-tuning it on only 10 such examples at a cost of less than\n$0.20 via OpenAI's APIs, making the model responsive to nearly any harmful\ninstructions. Disconcertingly, our research also reveals that, even without\nmalicious intent, simply fine-tuning with benign and commonly used datasets can\nalso inadvertently degrade the safety alignment of LLMs, though to a lesser\nextent. These findings suggest that fine-tuning aligned LLMs introduces new\nsafety risks that current safety infrastructures fall short of addressing --\neven if a model's initial safety alignment is impeccable, it is not necessarily\nto be maintained after custom fine-tuning. We outline and critically analyze\npotential mitigations and advocate for further research efforts toward\nreinforcing safety protocols for the custom fine-tuning of aligned LLMs.",
          "link": "http://arxiv.org/abs/2310.03693",
          "publishedOn": "2023-10-07T00:42:20.982Z",
          "wordCount": 769,
          "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!. (arXiv:2310.03693v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.16102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajorlou_A/0/1/0/all/0/1\">Amir Ajorlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jadbabaie_A/0/1/0/all/0/1\">Ali Jadbabaie</a>",
          "description": "Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where\nincreasing network depth leads to homogeneous node representations. While\nprevious work has established that Graph Convolutional Networks (GCNs)\nexponentially lose expressive power, it remains controversial whether the graph\nattention mechanism can mitigate oversmoothing. In this work, we provide a\ndefinitive answer to this question through a rigorous mathematical analysis, by\nviewing attention-based GNNs as nonlinear time-varying dynamical systems and\nincorporating tools and techniques from the theory of products of inhomogeneous\nmatrices and the joint spectral radius. We establish that, contrary to popular\nbelief, the graph attention mechanism cannot prevent oversmoothing and loses\nexpressive power exponentially. The proposed framework extends the existing\nresults on oversmoothing for symmetric GCNs to a significantly broader class of\nGNN models, including random walk GCNs, Graph Attention Networks (GATs) and\n(graph) transformers. In particular, our analysis accounts for asymmetric,\nstate-dependent and time-varying aggregation operators and a wide range of\ncommon nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU.",
          "link": "http://arxiv.org/abs/2305.16102",
          "publishedOn": "2023-10-07T00:42:20.974Z",
          "wordCount": 699,
          "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16150",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_Z/0/1/0/all/0/1\">Ziyun Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anthony_H/0/1/0/all/0/1\">Harry Anthony</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wagner_F/0/1/0/all/0/1\">Felix Wagner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamnitsas_K/0/1/0/all/0/1\">Konstantinos Kamnitsas</a>",
          "description": "Unsupervised anomaly segmentation aims to detect patterns that are distinct\nfrom any patterns processed during training, commonly called abnormal or\nout-of-distribution patterns, without providing any associated manual\nsegmentations. Since anomalies during deployment can lead to model failure,\ndetecting the anomaly can enhance the reliability of models, which is valuable\nin high-risk domains like medical imaging. This paper introduces Masked\nModality Cycles with Conditional Diffusion (MMCCD), a method that enables\nsegmentation of anomalies across diverse patterns in multimodal MRI. The method\nis based on two fundamental ideas. First, we propose the use of cyclic modality\ntranslation as a mechanism for enabling abnormality detection.\nImage-translation models learn tissue-specific modality mappings, which are\ncharacteristic of tissue physiology. Thus, these learned mappings fail to\ntranslate tissues or image patterns that have never been encountered during\ntraining, and the error enables their segmentation. Furthermore, we combine\nimage translation with a masked conditional diffusion model, which attempts to\n`imagine' what tissue exists under a masked area, further exposing unknown\npatterns as the generative model fails to recreate them. We evaluate our method\non a proxy task by training on healthy-looking slices of BraTS2021\nmulti-modality MRIs and testing on slices with tumors. We show that our method\ncompares favorably to previous unsupervised approaches based on image\nreconstruction and denoising with autoencoders and diffusion models.",
          "link": "http://arxiv.org/abs/2308.16150",
          "publishedOn": "2023-10-07T00:42:20.868Z",
          "wordCount": 775,
          "title": "Modality Cycles with Masked Conditional Diffusion for Unsupervised Anomaly Segmentation in MRI. (arXiv:2308.16150v2 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2204.05923",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Engquist_B/0/1/0/all/0/1\">Bj&#xf6;rn Engquist</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ren_K/0/1/0/all/0/1\">Kui Ren</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_Y/0/1/0/all/0/1\">Yunan Yang</a>",
          "description": "We propose a new gradient descent algorithm with added stochastic terms for\nfinding the global optimizers of nonconvex optimization problems. A key\ncomponent in the algorithm is the adaptive tuning of the randomness based on\nthe value of the objective function. In the language of simulated annealing,\nthe temperature is state-dependent. With this, we prove the global convergence\nof the algorithm with an algebraic rate both in probability and in the\nparameter space. This is a significant improvement over the classical rate from\nusing a more straightforward control of the noise term. The convergence proof\nis based on the actual discrete setup of the algorithm, not just its continuous\nlimit as often done in the literature. We also present several numerical\nexamples to demonstrate the efficiency and robustness of the algorithm for\nreasonably complex objective functions.",
          "link": "http://arxiv.org/abs/2204.05923",
          "publishedOn": "2023-10-07T00:42:20.858Z",
          "wordCount": 679,
          "title": "An Algebraically Converging Stochastic Gradient Descent Algorithm for Global Optimization. (arXiv:2204.05923v3 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1\">Mark Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1\">Nicholas M. Boffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>",
          "description": "Generative models inspired by dynamical transport of measure -- such as flows\nand diffusions -- construct a continuous-time map between two probability\ndensities. Conventionally, one of these is the target density, only accessible\nthrough samples, while the other is taken as a simple base density that is\ndata-agnostic. In this work, using the framework of stochastic interpolants, we\nformalize how to \\textit{couple} the base and the target densities. This\nenables us to incorporate information about class labels or continuous\nembeddings to construct dynamical transport maps that serve as conditional\ngenerative models. We show that these transport maps can be learned by solving\na simple square loss regression problem analogous to the standard independent\nsetting. We demonstrate the usefulness of constructing dependent couplings in\npractice through experiments in super-resolution and in-painting.",
          "link": "http://arxiv.org/abs/2310.03725",
          "publishedOn": "2023-10-07T00:42:20.847Z",
          "wordCount": 631,
          "title": "Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schmalstieg_F/0/1/0/all/0/1\">Fabian Schmalstieg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honerkamp_D/0/1/0/all/0/1\">Daniel Honerkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1\">Tim Welschehold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1\">Abhinav Valada</a>",
          "description": "Existing object-search approaches enable robots to search through free\npathways, however, robots operating in unstructured human-centered environments\nfrequently also have to manipulate the environment to their needs. In this\nwork, we introduce a novel interactive multi-object search task in which a\nrobot has to open doors to navigate rooms and search inside cabinets and\ndrawers to find target objects. These new challenges require combining\nmanipulation and navigation skills in unexplored environments. We present\nHIMOS, a hierarchical reinforcement learning approach that learns to compose\nexploration, navigation, and manipulation skills. To achieve this, we design an\nabstract high-level action space around a semantic map memory and leverage the\nexplored environment as instance navigation points. We perform extensive\nexperiments in simulation and the real world that demonstrate that, with\naccurate perception, the decision making of HIMOS effectively transfers to new\nenvironments in a zero-shot manner. It shows robustness to unseen subpolicies,\nfailures in their execution, and different robot kinematics. These capabilities\nopen the door to a wide range of downstream tasks across embodied AI and\nreal-world use cases.",
          "link": "http://arxiv.org/abs/2307.06125",
          "publishedOn": "2023-10-07T00:42:20.820Z",
          "wordCount": 696,
          "title": "Learning Hierarchical Interactive Multi-Object Search for Mobile Manipulation. (arXiv:2307.06125v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kreikemeyer_J/0/1/0/all/0/1\">Justin N. Kreikemeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andelfinger_P/0/1/0/all/0/1\">Philipp Andelfinger</a>",
          "description": "Programs involving discontinuities introduced by control flow constructs such\nas conditional branches pose challenges to mathematical optimization methods\nthat assume a degree of smoothness in the objective function's response\nsurface. Smooth interpretation (SI) is a form of abstract interpretation that\napproximates the convolution of a program's output with a Gaussian kernel, thus\nsmoothing its output in a principled manner. Here, we combine SI with automatic\ndifferentiation (AD) to efficiently compute gradients of smoothed programs. In\ncontrast to AD across a regular program execution, these gradients also capture\nthe effects of alternative control flow paths. The combination of SI with AD\nenables the direct gradient-based parameter synthesis for branching programs,\nallowing for instance the calibration of simulation models or their combination\nwith neural network models in machine learning pipelines. We detail the effects\nof the approximations made for tractability in SI and propose a novel Monte\nCarlo estimator that avoids the underlying assumptions by estimating the\nsmoothed programs' gradients through a combination of AD and sampling. Using\nDiscoGrad, our tool for automatically translating simple C++ programs to a\nsmooth differentiable form, we perform an extensive evaluation. We compare the\ncombination of SI with AD and our Monte Carlo estimator to existing\ngradient-free and stochastic methods on four non-trivial and originally\ndiscontinuous problems ranging from classical simulation-based optimization to\nneural network-driven control. While the optimization progress with the\nSI-based estimator depends on the complexity of the programs' control flow, our\nMonte Carlo estimator is competitive in all problems, exhibiting the fastest\nconvergence by a substantial margin in our highest-dimensional problem.",
          "link": "http://arxiv.org/abs/2310.03585",
          "publishedOn": "2023-10-07T00:42:20.811Z",
          "wordCount": 770,
          "title": "Smoothing Methods for Automatic Differentiation Across Conditional Branches. (arXiv:2310.03585v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.01690",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Nath_P/0/1/0/all/0/1\">Pritthijit Nath</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shukla_P/0/1/0/all/0/1\">Pancham Shukla</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Quilodran_Casas_C/0/1/0/all/0/1\">C&#xe9;sar Quilodr&#xe1;n-Casas</a>",
          "description": "As cyclones become more intense due to climate change, the rise of AI-based\nmodelling provides a more affordable and accessible approach compared to\ntraditional methods based on mathematical models. This work leverages diffusion\nmodels to forecast cyclone trajectories and precipitation patterns by\nintegrating satellite imaging, remote sensing, and atmospheric data, employing\na cascaded approach that incorporates forecasting, super-resolution, and\nprecipitation modelling, with training on a dataset of 51 cyclones from six\nmajor basins. Experiments demonstrate that the final forecasts from the\ncascaded models show accurate predictions up to a 36-hour rollout, with SSIM\nand PSNR values exceeding 0.5 and 20 dB, respectively, for all three tasks.\nThis work also highlights the promising efficiency of AI methods such as\ndiffusion models for high-performance needs, such as cyclone forecasting, while\nremaining computationally affordable, making them ideal for highly vulnerable\nregions with critical forecasting needs and financial limitations. Code\naccessible at \\url{https://github.com/nathzi1505/forecast-diffmodels}.",
          "link": "http://arxiv.org/abs/2310.01690",
          "publishedOn": "2023-10-07T00:42:20.781Z",
          "wordCount": 680,
          "title": "Forecasting Tropical Cyclones with Cascaded Diffusion Models. (arXiv:2310.01690v2 [physics.ao-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.00195",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Altabaa_A/0/1/0/all/0/1\">Awni Altabaa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_T/0/1/0/all/0/1\">Taylor Webb</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1\">Jonathan Cohen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "An extension of Transformers is proposed that enables explicit relational\nreasoning through a novel module called the Abstractor. At the core of the\nAbstractor is a variant of attention called relational cross-attention. The\napproach is motivated by an architectural inductive bias for relational\nlearning that disentangles relational information from extraneous features\nabout individual objects. This enables explicit relational reasoning,\nsupporting abstraction and generalization from limited data. The Abstractor is\nfirst evaluated on simple discriminative relational tasks and compared to\nexisting relational architectures. Next, the Abstractor is evaluated on purely\nrelational sequence-to-sequence tasks, where dramatic improvements are seen in\nsample efficiency compared to standard Transformers. Finally, Abstractors are\nevaluated on a collection of tasks based on mathematical problem solving, where\nmodest but consistent improvements in performance and sample efficiency are\nobserved.",
          "link": "http://arxiv.org/abs/2304.00195",
          "publishedOn": "2023-10-07T00:42:20.761Z",
          "wordCount": 678,
          "title": "Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers. (arXiv:2304.00195v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davis_O/0/1/0/all/0/1\">Owen Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motamed_M/0/1/0/all/0/1\">Mohammad Motamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tempone_R/0/1/0/all/0/1\">Raul Tempone</a>",
          "description": "In this work, we consider the general problem of constructing a neural\nnetwork surrogate model using multi-fidelity information. Given an inexpensive\nlow-fidelity and an expensive high-fidelity computational model, we present a\nresidual multi-fidelity computational framework that formulates the correlation\nbetween models as a residual function, a possibly non-linear mapping between 1)\nthe shared input space of the models together with the low-fidelity model\noutput and 2) the discrepancy between the two model outputs. To accomplish\nthis, we train two neural networks to work in concert. The first network learns\nthe residual function on a small set of high-fidelity and low-fidelity data.\nOnce trained, this network is used to generate additional synthetic\nhigh-fidelity data, which is used in the training of a second network. This\nsecond network, once trained, acts as our surrogate for the high-fidelity\nquantity of interest. We present three numerical examples to demonstrate the\npower of the proposed framework. In particular, we show that dramatic savings\nin computational cost may be achieved when the output predictions are desired\nto be accurate within small tolerances.",
          "link": "http://arxiv.org/abs/2310.03572",
          "publishedOn": "2023-10-07T00:42:20.736Z",
          "wordCount": 673,
          "title": "Residual Multi-Fidelity Neural Network Computing. (arXiv:2310.03572v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raina_D/0/1/0/all/0/1\">Deepak Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1\">Abhishek Mathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voyles_R/0/1/0/all/0/1\">Richard M. Voyles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachs_J/0/1/0/all/0/1\">Juan Wachs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrashekhara_S/0/1/0/all/0/1\">SH Chandrashekhara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Subir Kumar Saha</a>",
          "description": "The one of the significant challenges faced by autonomous robotic ultrasound\nsystems is acquiring high-quality images across different patients. The proper\norientation of the robotized probe plays a crucial role in governing the\nquality of ultrasound images. To address this challenge, we propose a\nsample-efficient method to automatically adjust the orientation of the\nultrasound probe normal to the point of contact on the scanning surface,\nthereby improving the acoustic coupling of the probe and resulting image\nquality. Our method utilizes Bayesian Optimization (BO) based search on the\nscanning surface to efficiently search for the normalized probe orientation. We\nformulate a novel objective function for BO that leverages the contact force\nmeasurements and underlying mechanics to identify the normal. We further\nincorporate a regularization scheme in BO to handle the noisy objective\nfunction. The performance of the proposed strategy has been assessed through\nexperiments on urinary bladder phantoms. These phantoms included planar,\ntilted, and rough surfaces, and were examined using both linear and convex\nprobes with varying search space limits. Further, simulation-based studies have\nbeen carried out using 3D human mesh models. The results demonstrate that the\nmean ($\\pm$SD) absolute angular error averaged over all phantoms and 3D models\nis $\\boldsymbol{2.4\\pm0.7^\\circ}$ and $\\boldsymbol{2.1\\pm1.3^\\circ}$,\nrespectively.",
          "link": "http://arxiv.org/abs/2310.03406",
          "publishedOn": "2023-10-07T00:42:20.721Z",
          "wordCount": 748,
          "title": "RUSOpt: Robotic UltraSound Probe Normalization with Bayesian Optimization for In-plane and Out-plane Scanning. (arXiv:2310.03406v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masclef_N/0/1/0/all/0/1\">Ninon Liz&#xe9; Masclef</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1\">T. Anderson Keller</a>",
          "description": "A prominent theory of affective response to music revolves around the\nconcepts of surprisal and expectation. In prior work, this idea has been\noperationalized in the form of probabilistic models of music which allow for\nprecise computation of song (or note-by-note) probabilities, conditioned on a\n'training set' of prior musical or cultural experiences. To date, however,\nthese models have been limited to compute exact probabilities through\nhand-crafted features or restricted to linear models which are likely not\nsufficient to represent the complex conditional distributions present in music.\nIn this work, we propose to use modern deep probabilistic generative models in\nthe form of a Diffusion Model to compute an approximate likelihood of a musical\ninput sequence. Unlike prior work, such a generative model parameterized by\ndeep neural networks is able to learn complex non-linear features directly from\na training set itself. In doing so, we expect to find that such models are able\nto more accurately represent the 'surprisal' of music for human listeners. From\nthe literature, it is known that there is an inverted U-shaped relationship\nbetween surprisal and the amount human subjects 'like' a given song. In this\nwork we show that pre-trained diffusion models indeed yield musical surprisal\nvalues which exhibit a negative quadratic relationship with measured subject\n'liking' ratings, and that the quality of this relationship is competitive with\nstate of the art methods such as IDyOM. We therefore present this model a\npreliminary step in developing modern deep generative models of music\nexpectation and subjective likability.",
          "link": "http://arxiv.org/abs/2310.03500",
          "publishedOn": "2023-10-07T00:42:20.713Z",
          "wordCount": 745,
          "title": "Deep Generative Models of Music Expectation. (arXiv:2310.03500v1 [cs.SD])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yihang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zuxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_Z/0/1/0/all/0/1\">Zhepeng Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiacheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tingnan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "Safe reinforcement learning (RL) focuses on training reward-maximizing agents\nsubject to pre-defined safety constraints. Yet, learning versatile safe\npolicies that can adapt to varying safety constraint requirements during\ndeployment without retraining remains a largely unexplored and challenging\narea. In this work, we formulate the versatile safe RL problem and consider two\nprimary requirements: training efficiency and zero-shot adaptation capability.\nTo address them, we introduce the Conditioned Constrained Policy Optimization\n(CCPO) framework, consisting of two key modules: (1) Versatile Value Estimation\n(VVE) for approximating value functions under unseen threshold conditions, and\n(2) Conditioned Variational Inference (CVI) for encoding arbitrary constraint\nthresholds during policy optimization. Our extensive experiments demonstrate\nthat CCPO outperforms the baselines in terms of safety and task performance\nwhile preserving zero-shot adaptation capabilities to different constraint\nthresholds data-efficiently. This makes our approach suitable for real-world\ndynamic applications.",
          "link": "http://arxiv.org/abs/2310.03718",
          "publishedOn": "2023-10-07T00:42:20.706Z",
          "wordCount": 650,
          "title": "Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning. (arXiv:2310.03718v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2201.02824",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stephanovitch_A/0/1/0/all/0/1\">Arthur St&#xe9;phanovitch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tanielian_U/0/1/0/all/0/1\">Ugo Tanielian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cadre_B/0/1/0/all/0/1\">Beno&#xee;t Cadre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Klutchnikoff_N/0/1/0/all/0/1\">Nicolas Klutchnikoff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Biau_G/0/1/0/all/0/1\">G&#xe9;rard Biau</a>",
          "description": "The mathematical forces at work behind Generative Adversarial Networks raise\nchallenging theoretical issues. Motivated by the important question of\ncharacterizing the geometrical properties of the generated distributions, we\nprovide a thorough analysis of Wasserstein GANs (WGANs) in both the finite\nsample and asymptotic regimes. We study the specific case where the latent\nspace is univariate and derive results valid regardless of the dimension of the\noutput space. We show in particular that for a fixed sample size, the optimal\nWGANs are closely linked with connected paths minimizing the sum of the squared\nEuclidean distances between the sample points. We also highlight the fact that\nWGANs are able to approach (for the 1-Wasserstein distance) the target\ndistribution as the sample size tends to infinity, at a given convergence rate\nand provided the family of generative Lipschitz functions grows appropriately.\nWe derive in passing new results on optimal transport theory in the\nsemi-discrete setting.",
          "link": "http://arxiv.org/abs/2201.02824",
          "publishedOn": "2023-10-07T00:42:20.698Z",
          "wordCount": 664,
          "title": "Optimal 1-Wasserstein Distance for WGANs. (arXiv:2201.02824v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcin_S/0/1/0/all/0/1\">Samuel Garcin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doran_J/0/1/0/all/0/1\">James Doran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shangmin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_C/0/1/0/all/0/1\">Christopher G. Lucas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "A key limitation preventing the wider adoption of autonomous agents trained\nvia deep reinforcement learning (RL) is their limited ability to generalise to\nnew environments, even when these share similar characteristics with\nenvironments encountered during training. In this work, we investigate how a\nnon-uniform sampling strategy of individual environment instances, or levels,\naffects the zero-shot generalisation (ZSG) ability of RL agents, considering\ntwo failure modes: overfitting and over-generalisation. As a first step, we\nmeasure the mutual information (MI) between the agent's internal representation\nand the set of training levels, which we find to be well-correlated to instance\noverfitting. In contrast to uniform sampling, adaptive sampling strategies\nprioritising levels based on their value loss are more effective at maintaining\nlower MI, which provides a novel theoretical justification for this class of\ntechniques. We then turn our attention to unsupervised environment design (UED)\nmethods, which adaptively generate new training levels and minimise MI more\neffectively than methods sampling from a fixed set. However, we find UED\nmethods significantly shift the training distribution, resulting in\nover-generalisation and worse ZSG performance over the distribution of\ninterest. To prevent both instance overfitting and over-generalisation, we\nintroduce self-supervised environment design (SSED). SSED generates levels\nusing a variational autoencoder, effectively reducing MI while minimising the\nshift with the distribution of interest, and leads to statistically significant\nimprovements in ZSG over fixed-set level sampling strategies and UED methods.",
          "link": "http://arxiv.org/abs/2310.03494",
          "publishedOn": "2023-10-07T00:42:20.674Z",
          "wordCount": 762,
          "title": "How the level sampling process impacts zero-shot generalisation in deep reinforcement learning. (arXiv:2310.03494v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maddock_S/0/1/0/all/0/1\">Samuel Maddock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cormode_G/0/1/0/all/0/1\">Graham Cormode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maple_C/0/1/0/all/0/1\">Carsten Maple</a>",
          "description": "Preserving individual privacy while enabling collaborative data sharing is\ncrucial for organizations. Synthetic data generation is one solution, producing\nartificial data that mirrors the statistical properties of private data. While\nnumerous techniques have been devised under differential privacy, they\npredominantly assume data is centralized. However, data is often distributed\nacross multiple clients in a federated manner. In this work, we initiate the\nstudy of federated synthetic tabular data generation. Building upon a SOTA\ncentral method known as AIM, we present DistAIM and FLAIM. We show it is\nstraightforward to distribute AIM, extending a recent approach based on secure\nmulti-party computation which necessitates additional overhead, making it less\nsuited to federated scenarios. We then demonstrate that naively federating AIM\ncan lead to substantial degradation in utility under the presence of\nheterogeneity. To mitigate both issues, we propose an augmented FLAIM approach\nthat maintains a private proxy of heterogeneity. We simulate our methods across\na range of benchmark datasets under different degrees of heterogeneity and show\nthis can improve utility while reducing overhead.",
          "link": "http://arxiv.org/abs/2310.03447",
          "publishedOn": "2023-10-07T00:42:20.667Z",
          "wordCount": 674,
          "title": "FLAIM: AIM-based Synthetic Data Generation in the Federated Setting. (arXiv:2310.03447v1 [cs.CR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1802.00810",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Yue_T/0/1/0/all/0/1\">Tianwei Yue</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanxin Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_L/0/1/0/all/0/1\">Longxiang Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gu_C/0/1/0/all/0/1\">Chunming Gu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xue_H/0/1/0/all/0/1\">Haoru Xue</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1\">Wenping Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lyu_Q/0/1/0/all/0/1\">Qi Lyu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dun_Y/0/1/0/all/0/1\">Yujie Dun</a>",
          "description": "Advancements in genomic research such as high-throughput sequencing\ntechniques have driven modern genomic studies into \"big data\" disciplines. This\ndata explosion is constantly challenging conventional methods used in genomics.\nIn parallel with the urgent demand for robust algorithms, deep learning has\nsucceeded in a variety of fields such as vision, speech, and text processing.\nYet genomics entails unique challenges to deep learning since we are expecting\nfrom deep learning a superhuman intelligence that explores beyond our knowledge\nto interpret the genome. A powerful deep learning model should rely on\ninsightful utilization of task-specific knowledge. In this paper, we briefly\ndiscuss the strengths of different deep learning models from a genomic\nperspective so as to fit each particular task with a proper deep architecture,\nand remark on practical considerations of developing modern deep learning\narchitectures for genomics. We also provide a concise review of deep learning\napplications in various aspects of genomic research, as well as pointing out\npotential opportunities and obstacles for future genomics applications.",
          "link": "http://arxiv.org/abs/1802.00810",
          "publishedOn": "2023-10-07T00:42:20.651Z",
          "wordCount": 702,
          "title": "Deep Learning for Genomics: A Concise Overview. (arXiv:1802.00810v4 [q-bio.GN] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1\">Zeyuan Allen-Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "We design controlled experiments to study HOW generative language models,\nlike GPT, learn context-free grammars (CFGs) -- diverse language systems with a\ntree-like structure capturing many aspects of natural languages, programs, and\nlogics. CFGs are as hard as pushdown automata, and can be ambiguous so that\nverifying if a string satisfies the rules requires dynamic programming. We\nconstruct synthetic data and demonstrate that even for difficult (long and\nambiguous) CFGs, pre-trained transformers can learn to generate sentences with\nnear-perfect accuracy and impressive diversity.\n\nMore importantly, we delve into the physical principles behind how\ntransformers learns CFGs. We discover that the hidden states within the\ntransformer implicitly and precisely encode the CFG structure (such as putting\ntree node information exactly on the subtree boundary), and learn to form\n\"boundary to boundary\" attentions resembling dynamic programming. We also cover\nsome extension of CFGs as well as the robustness aspect of transformers against\ngrammar mistakes. Overall, our research provides a comprehensive and empirical\nunderstanding of how transformers learn CFGs, and reveals the physical\nmechanisms utilized by transformers to capture the structure and rules of\nlanguages.",
          "link": "http://arxiv.org/abs/2305.13673",
          "publishedOn": "2023-10-07T00:42:20.562Z",
          "wordCount": 708,
          "title": "Physics of Language Models: Part 1, Context-Free Grammar. (arXiv:2305.13673v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.17260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suomela_L/0/1/0/all/0/1\">Lauri Suomela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalliola_J/0/1/0/all/0/1\">Jussi Kalliola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edelman_H/0/1/0/all/0/1\">Harry Edelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamarainen_J/0/1/0/all/0/1\">Joni-Kristian K&#xe4;m&#xe4;r&#xe4;inen</a>",
          "description": "Recent results suggest that splitting topological navigation into\nrobot-independent and robot-specific components improves navigation performance\nby enabling the robot-independent part to be trained with data collected by\ndifferent robot types. However, the navigation methods are still limited by the\nscarcity of suitable training data and suffer from poor computational scaling.\nIn this work, we present PlaceNav, subdividing the robot-independent part into\nnavigation-specific and generic computer vision components. We utilize visual\nplace recognition for the subgoal selection of the topological navigation\npipeline. This makes subgoal selection more efficient and enables leveraging\nlarge-scale datasets from non-robotics sources, increasing training data\navailability. Bayesian filtering, enabled by place recognition, further\nimproves navigation performance by increasing the temporal consistency of\nsubgoals. Our experimental results verify the design and the new model obtains\na 76% higher success rate in indoor and 23% higher in outdoor navigation tasks\nwith higher computational efficiency.",
          "link": "http://arxiv.org/abs/2309.17260",
          "publishedOn": "2023-10-07T00:42:20.550Z",
          "wordCount": 663,
          "title": "PlaceNav: Topological Navigation through Place Recognition. (arXiv:2309.17260v3 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03722",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1\">Hongjian Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "In 1976, Lai constructed a nontrivial confidence sequence for the mean $\\mu$\nof a Gaussian distribution with unknown variance $\\sigma$. Curiously, he\nemployed both an improper (right Haar) mixture over $\\sigma$ and an improper\n(flat) mixture over $\\mu$. Here, we elaborate carefully on the details of his\nconstruction, which use generalized nonintegrable martingales and an extended\nVille's inequality. While this does yield a sequential t-test, it does not\nyield an ``e-process'' (due to the nonintegrability of his martingale). In this\npaper, we develop two new e-processes and confidence sequences for the same\nsetting: one is a test martingale in a reduced filtration, while the other is\nan e-process in the canonical data filtration. These are respectively obtained\nby swapping Lai's flat mixture for a Gaussian mixture, and swapping the right\nHaar mixture over $\\sigma$ with the maximum likelihood estimate under the null,\nas done in universal inference. We also analyze the width of resulting\nconfidence sequences, which have a curious dependence on the error probability\n$\\alpha$. Numerical experiments are provided along the way to compare and\ncontrast the various approaches.",
          "link": "http://arxiv.org/abs/2310.03722",
          "publishedOn": "2023-10-07T00:42:20.528Z",
          "wordCount": 698,
          "title": "Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1\">Albert Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anitescu_M/0/1/0/all/0/1\">Mihai Anitescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanyam_A/0/1/0/all/0/1\">Anirudh Subramanyam</a>",
          "description": "Measures of power grid vulnerability are often assessed by the amount of\ndamage an adversary can exact on the network. However, the cascading impact of\nsuch attacks is often overlooked, even though cascades are one of the primary\ncauses of large-scale blackouts. This paper explores modifications of\ntransmission line protection settings as candidates for adversarial attacks,\nwhich can remain undetectable as long as the network equilibrium state remains\nunaltered. This forms the basis of a black-box function in a Bayesian\noptimization procedure, where the objective is to find protection settings that\nmaximize network degradation due to cascading. Notably, our proposed method is\nagnostic to the choice of the cascade simulator and its underlying assumptions.\nNumerical experiments reveal that, against conventional wisdom, maximally\nmisconfiguring the protection settings of all network lines does not cause the\nmost cascading. More surprisingly, even when the degree of misconfiguration is\nlimited due to resource constraints, it is still possible to find settings that\nproduce cascades comparable in severity to instances where there are no\nresource constraints.",
          "link": "http://arxiv.org/abs/2304.14420",
          "publishedOn": "2023-10-07T00:42:20.474Z",
          "wordCount": 701,
          "title": "Network Cascade Vulnerability using Constrained Bayesian Optimization. (arXiv:2304.14420v2 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sodhi_P/0/1/0/all/0/1\">Paloma Sodhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Branavan_S/0/1/0/all/0/1\">S.R.K. Branavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_R/0/1/0/all/0/1\">Ryan McDonald</a>",
          "description": "Large language models (LLMs) have demonstrated remarkable capabilities in\nperforming a range of instruction following tasks in few and zero-shot\nsettings. However, teaching LLMs to perform tasks on the web presents\nfundamental challenges -- combinatorially large open-world tasks and variations\nacross web interfaces. We tackle these challenges by leveraging LLMs to\ndecompose web tasks into a collection of sub-tasks, each of which can be solved\nby a low-level, closed-loop policy. These policies constitute a shared grammar\nacross tasks, i.e., new web tasks can be expressed as a composition of these\npolicies. We propose a novel framework, Hierarchical Policies for Web Actions\nusing LLMs (HeaP), that learns a set of hierarchical LLM prompts from\ndemonstrations for planning high-level tasks and executing them via a sequence\nof low-level policies. We evaluate HeaP against a range of baselines on a suite\nof web tasks, including MiniWoB++, WebArena, a mock airline CRM, as well as\nlive website interactions, and show that it is able to outperform prior works\nusing orders of magnitude less data.",
          "link": "http://arxiv.org/abs/2310.03720",
          "publishedOn": "2023-10-07T00:42:20.429Z",
          "wordCount": 673,
          "title": "HeaP: Hierarchical Policies for Web Actions using LLMs. (arXiv:2310.03720v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.08417",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gerhardus_A/0/1/0/all/0/1\">Andreas Gerhardus</a>",
          "description": "In this paper, we introduce a novel class of graphical models for\nrepresenting time lag specific causal relationships and independencies of\nmultivariate time series with unobserved confounders. We completely\ncharacterize these graphs and show that they constitute proper subsets of the\ncurrently employed model classes. As we show, from the novel graphs one can\nthus draw stronger causal inferences -- without additional assumptions. We\nfurther introduce a graphical representation of Markov equivalence classes of\nthe novel graphs. This graphical representation contains more causal knowledge\nthan what current state-of-the-art causal discovery algorithms learn.",
          "link": "http://arxiv.org/abs/2112.08417",
          "publishedOn": "2023-10-07T00:42:20.394Z",
          "wordCount": 625,
          "title": "Characterization of causal ancestral graphs for time series with latent confounders. (arXiv:2112.08417v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mullen_A/0/1/0/all/0/1\">Aaron D. Mullen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armstrong_S/0/1/0/all/0/1\">Samuel E. Armstrong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talbert_J/0/1/0/all/0/1\">Jeff Talbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bumgardner_V/0/1/0/all/0/1\">V.K. Cody Bumgardner</a>",
          "description": "Machine learning classification problems are widespread in bioinformatics,\nbut the technical knowledge required to perform model training, optimization,\nand inference can prevent researchers from utilizing this technology. This\narticle presents an automated tool for machine learning classification problems\nto simplify the process of training models and producing results while\nproviding informative visualizations and insights into the data. This tool\nsupports both binary and multiclass classification problems, and it provides\naccess to a variety of models and methods. Synthetic data can be generated\nwithin the interface to fill missing values, balance class labels, or generate\nentirely new datasets. It also provides support for feature evaluation and\ngenerates explainability scores to indicate which features influence the output\nthe most. We present CLASSify, an open-source tool for simplifying the user\nexperience of solving classification problems without the need for knowledge of\nmachine learning.",
          "link": "http://arxiv.org/abs/2310.03618",
          "publishedOn": "2023-10-07T00:42:20.382Z",
          "wordCount": 668,
          "title": "CLASSify: A Web-Based Tool for Machine Learning. (arXiv:2310.03618v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.00818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Huiyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sano_A/0/1/0/all/0/1\">Akane Sano</a>",
          "description": "Electrocardiogram (ECG) is an essential signal in monitoring human heart\nactivities. Researchers have achieved promising results in leveraging ECGs in\nclinical applications with deep learning models. However, the mainstream deep\nlearning approaches usually neglect the periodic and formative attribute of the\nECG heartbeat waveform. In this work, we propose a novel ECG-Segment based\nLearning (ECG-SL) framework to explicitly model the periodic nature of ECG\nsignals. More specifically, ECG signals are first split into heartbeat\nsegments, and then structural features are extracted from each of the segments.\nBased on the structural features, a temporal model is designed to learn the\ntemporal information for various clinical tasks. Further, due to the fact that\nmassive ECG signals are available but the labeled data are very limited, we\nalso explore self-supervised learning strategy to pre-train the models,\nresulting significant improvement for downstream tasks. The proposed method\noutperforms the baseline model and shows competitive performances compared with\ntask-specific methods in three clinical applications: cardiac condition\ndiagnosis, sleep apnea detection, and arrhythmia classification. Further, we\nfind that the ECG-SL tends to focus more on each heartbeat's peak and ST range\nthan ResNet by visualizing the saliency maps.",
          "link": "http://arxiv.org/abs/2310.00818",
          "publishedOn": "2023-10-07T00:42:20.306Z",
          "wordCount": 721,
          "title": "ECG-SL: Electrocardiogram(ECG) Segment Learning, a deep learning method for ECG signal. (arXiv:2310.00818v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.02964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Ge Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jiangbin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>",
          "description": "Peptides are formed by the dehydration condensation of multiple amino acids.\nThe primary structure of a peptide can be represented either as an amino acid\nsequence or as a molecular graph consisting of atoms and chemical bonds.\nPrevious studies have indicated that deep learning routes specific to\nsequential and graphical peptide forms exhibit comparable performance on\ndownstream tasks. Despite the fact that these models learn representations of\nthe same modality of peptides, we find that they explain their predictions\ndifferently. Considering sequential and graphical models as two experts making\ninferences from different perspectives, we work on fusing expert knowledge to\nenrich the learned representations for improving the discriminative\nperformance. To achieve this, we propose a peptide co-modeling method, RepCon,\nwhich employs a contrastive learning-based framework to enhance the mutual\ninformation of representations from decoupled sequential and graphical\nend-to-end models. It considers representations from the sequential encoder and\nthe graphical encoder for the same peptide sample as a positive pair and learns\nto enhance the consistency of representations between positive sample pairs and\nto repel representations between negative pairs. Empirical studies of RepCon\nand other co-modeling methods are conducted on open-source discriminative\ndatasets, including aggregation propensity, retention time, antimicrobial\npeptide prediction, and family classification from Peptide Database. Our\nresults demonstrate the superiority of the co-modeling approach over\nindependent modeling, as well as the superiority of RepCon over other methods\nunder the co-modeling framework. In addition, the attribution on RepCon further\ncorroborates the validity of the approach at the level of model explanation.",
          "link": "http://arxiv.org/abs/2310.02964",
          "publishedOn": "2023-10-07T00:42:20.283Z",
          "wordCount": 782,
          "title": "Co-modeling the Sequential and Graphical Routes for Peptide Representation Learning. (arXiv:2310.02964v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.00944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Piroli_A/0/1/0/all/0/1\">Aldi Piroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dallabetta_V/0/1/0/all/0/1\">Vinzenz Dallabetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopp_J/0/1/0/all/0/1\">Johannes Kopp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walessa_M/0/1/0/all/0/1\">Marc Walessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meissner_D/0/1/0/all/0/1\">Daniel Meissner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietmayer_K/0/1/0/all/0/1\">Klaus Dietmayer</a>",
          "description": "LiDAR sensors are used in autonomous driving applications to accurately\nperceive the environment. However, they are affected by adverse weather\nconditions such as snow, fog, and rain. These everyday phenomena introduce\nunwanted noise into the measurements, severely degrading the performance of\nLiDAR-based perception systems. In this work, we propose a framework for\nimproving the robustness of LiDAR-based 3D object detectors against road spray.\nOur approach uses a state-of-the-art adverse weather detection network to\nfilter out spray from the LiDAR point cloud, which is then used as input for\nthe object detector. In this way, the detected objects are less affected by the\nadverse weather in the scene, resulting in a more accurate perception of the\nenvironment. In addition to adverse weather filtering, we explore the use of\nradar targets to further filter false positive detections. Tests on real-world\ndata show that our approach improves the robustness to road spray of several\npopular 3D object detectors.",
          "link": "http://arxiv.org/abs/2310.00944",
          "publishedOn": "2023-10-07T00:42:20.276Z",
          "wordCount": 693,
          "title": "Towards Robust 3D Object Detection In Rainy Conditions. (arXiv:2310.00944v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.06921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sam_D/0/1/0/all/0/1\">Dylan Sam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>",
          "description": "Owing to the prohibitive costs of generating large amounts of labeled data,\nprogrammatic weak supervision is a growing paradigm within machine learning. In\nthis setting, users design heuristics that provide noisy labels for subsets of\nthe data. These weak labels are combined (typically via a graphical model) to\nform pseudolabels, which are then used to train a downstream model. In this\nwork, we question a foundational premise of the typical weakly supervised\nlearning pipeline: given that the heuristic provides all ``label\" information,\nwhy do we need to generate pseudolabels at all? Instead, we propose to directly\ntransform the heuristics themselves into corresponding loss functions that\npenalize differences between our model and the heuristic. By constructing\nlosses directly from the heuristics, we can incorporate more information than\nis used in the standard weakly supervised pipeline, such as how the heuristics\nmake their decisions, which explicitly informs feature selection during\ntraining. We call our method Losses over Labels (LoL) as it creates losses\ndirectly from heuristics without going through the intermediate step of a\nlabel. We show that LoL improves upon existing weak supervision methods on\nseveral benchmark text and image classification tasks and further demonstrate\nthat incorporating gradient information leads to better performance on almost\nevery task.",
          "link": "http://arxiv.org/abs/2212.06921",
          "publishedOn": "2023-10-07T00:42:20.270Z",
          "wordCount": 738,
          "title": "Losses over Labels: Weakly Supervised Learning via Direct Loss Construction. (arXiv:2212.06921v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhanhui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1\">Jing Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiangyu Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>",
          "description": "Language models (LMs), despite aligning well with an average labeler through\nreinforcement learning from human feedback (RLHF), may not universally suit\ndiverse human preferences. Recent approaches therefore opt for customization by\ncollecting multi-dimensional feedback and creating distinct rewards for each\ndimension (e.g., helpfulness, harmlessness, honesty). LMs can then be tailored\nto different preferences using multi-objective RL (MORL) with different reward\nweightings. Yet, RL fine-tuning is unstable and resource-heavy, especially for\nMORLHF with diverse and usually conflicting objectives. In this paper, we\npresent Multi-Objective Direct Preference Optimization (MODPO), an RL-free\nalgorithm that extends Direct Preference Optimization (DPO) for multiple\nalignment objectives. Essentially, MODPO trains different LMs to represent\ndifferent collective reward models that combine all objectives with specific\nweightings. With a simple cross-entropy loss, the LMs optimized against the\nMODPO objective are analytically the exact solutions of the original MORLHF\nobjective. Empirical results in safety alignment and long-form question\nanswering confirm that MODPO matches or outperforms existing methods,\nefficiently producing a Pareto-optimal set of LMs that cater to diverse\npreferences with 3 times less computational resources compared with MORLHF.",
          "link": "http://arxiv.org/abs/2310.03708",
          "publishedOn": "2023-10-07T00:42:20.262Z",
          "wordCount": 684,
          "title": "Beyond One-Preference-for-All: Multi-Objective Direct Preference Optimization. (arXiv:2310.03708v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_P/0/1/0/all/0/1\">Prasann Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_T/0/1/0/all/0/1\">Tanya Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiacheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>",
          "description": "Great successes have been reported using Reinforcement Learning from Human\nFeedback (RLHF) to align large language models. Open-source preference datasets\nand reward models have enabled wider experimentation beyond generic chat\nsettings, particularly to make systems more \"helpful\" for tasks like web\nquestion answering, summarization, and multi-turn dialogue. When optimizing for\nhelpfulness, RLHF has been consistently observed to drive models to produce\nlonger outputs. This paper demonstrates that optimizing for response length is\na significant factor behind RLHF's reported improvements in these settings.\nFirst, we study the relationship between reward and length for reward models\ntrained on three open-source preference datasets for helpfulness. Here, length\ncorrelates strongly with reward, and improvements in reward score are driven in\nlarge part by shifting the distribution over output lengths. We then explore\ninterventions during both RL and reward model learning to see if we can achieve\nthe same downstream improvements as RLHF without increasing length. While our\ninterventions mitigate length increases, they aren't uniformly effective across\nsettings. Furthermore, we find that even running RLHF with a reward based\nsolely on length can reproduce most of the downstream improvements over the\ninitial policy model, showing that reward models in these settings have a long\nway to go.",
          "link": "http://arxiv.org/abs/2310.03716",
          "publishedOn": "2023-10-07T00:42:20.246Z",
          "wordCount": 713,
          "title": "A Long Way to Go: Investigating Length Correlations in RLHF. (arXiv:2310.03716v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Both centralized and decentralized approaches have shown excellent\nperformance and great application value in federated learning (FL). However,\ncurrent studies do not provide sufficient evidence to show which one performs\nbetter. Although from the optimization perspective, decentralized methods can\napproach the comparable convergence of centralized methods with less\ncommunication, its test performance has always been inefficient in empirical\nstudies. To comprehensively explore their behaviors in FL, we study their\nexcess risks, including the joint analysis of both optimization and\ngeneralization. We prove that on smooth non-convex objectives, 1) centralized\nFL (CFL) always generalizes better than decentralized FL (DFL); 2) from\nperspectives of the excess risk and test error in CFL, adopting partial\nparticipation is superior to full participation; and, 3) there is a necessary\nrequirement for the topology in DFL to avoid performance collapse as the\ntraining scale increases. Based on some simple hardware metrics, we could\nevaluate which framework is better in practice. Extensive experiments are\nconducted on common setups in FL to validate that our theoretical analysis is\ncontextually valid in practical scenarios.",
          "link": "http://arxiv.org/abs/2310.03461",
          "publishedOn": "2023-10-07T00:42:20.237Z",
          "wordCount": 687,
          "title": "Which mode is better for federated learning? Centralized or Decentralized. (arXiv:2310.03461v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.08979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xinyue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>",
          "description": "The way users acquire information is undergoing a paradigm shift with the\nadvent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves\nknowledge from the model itself and generates answers for users. ChatGPT's\nimpressive question-answering (QA) capability has attracted more than 100\nmillion users within a short period of time but has also raised concerns\nregarding its reliability. In this paper, we perform the first large-scale\nmeasurement of ChatGPT's reliability in the generic QA scenario with a\ncarefully curated set of 5,695 questions across ten datasets and eight domains.\nWe find that ChatGPT's reliability varies across different domains, especially\nunderperforming in law and science questions. We also demonstrate that system\nroles, originally designed by OpenAI to allow users to steer ChatGPT's\nbehavior, can impact ChatGPT's reliability in an imperceptible way. We further\nshow that ChatGPT is vulnerable to adversarial examples, and even a single\ncharacter change can negatively affect its reliability in certain cases. We\nbelieve that our study provides valuable insights into ChatGPT's reliability\nand underscores the need for strengthening the reliability and security of\nlarge language models (LLMs).",
          "link": "http://arxiv.org/abs/2304.08979",
          "publishedOn": "2023-10-07T00:42:20.227Z",
          "wordCount": 717,
          "title": "In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. (arXiv:2304.08979v2 [cs.CR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laufer_B/0/1/0/all/0/1\">Benjamin Laufer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1\">Jon Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1\">Karen Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nissenbaum_H/0/1/0/all/0/1\">Helen Nissenbaum</a>",
          "description": "A broad current application of algorithms is in formal and quantitative\nmeasures of murky concepts -- like merit -- to make decisions. When people\nstrategically respond to these sorts of evaluations in order to gain favorable\ndecision outcomes, their behavior can be subjected to moral judgments. They may\nbe described as 'gaming the system' or 'cheating,' or (in other cases)\ninvesting 'honest effort' or 'improving.' Machine learning literature on\nstrategic behavior has tried to describe these dynamics by emphasizing the\nefforts expended by decision subjects hoping to obtain a more favorable\nassessment -- some works offer ways to preempt or prevent such manipulations,\nsome differentiate 'gaming' from 'improvement' behavior, while others aim to\nmeasure the effort burden or disparate effects of classification systems. We\nbegin from a different starting point: that the design of an evaluation itself\ncan be understood as furthering goals held by the evaluator which may be\nmisaligned with broader societal goals. To develop the idea that evaluation\nrepresents a strategic interaction in which both the evaluator and the subject\nof their evaluation are operating out of self-interest, we put forward a model\nthat represents the process of evaluation using three interacting agents: a\ndecision subject, an evaluator, and society, representing a bundle of values\nand oversight mechanisms. We highlight our model's applicability to a number of\nsocial systems where one or two players strategically undermine the others'\ninterests to advance their own. Treating evaluators as themselves strategic\nallows us to re-cast the scrutiny directed at decision subjects, towards the\nincentives that underpin institutional designs of evaluations. The moral\nstanding of strategic behaviors often depend on the moral standing of the\nevaluations and incentives that provoke such behaviors.",
          "link": "http://arxiv.org/abs/2310.03655",
          "publishedOn": "2023-10-07T00:42:20.202Z",
          "wordCount": null,
          "title": "Strategic Evaluation: Subjects, Evaluators, and Society. (arXiv:2310.03655v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fuhg_J/0/1/0/all/0/1\">Jan N. Fuhg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1\">Reese E. Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouklas_N/0/1/0/all/0/1\">Nikolaos Bouklas</a>",
          "description": "Data-driven constitutive modeling with neural networks has received increased\ninterest in recent years due to its ability to easily incorporate physical and\nmechanistic constraints and to overcome the challenging and time-consuming task\nof formulating phenomenological constitutive laws that can accurately capture\nthe observed material response. However, even though neural network-based\nconstitutive laws have been shown to generalize proficiently, the generated\nrepresentations are not easily interpretable due to their high number of\ntrainable parameters. Sparse regression approaches exist that allow to\nobtaining interpretable expressions, but the user is tasked with creating a\nlibrary of model forms which by construction limits their expressiveness to the\nfunctional forms provided in the libraries. In this work, we propose to train\nregularized physics-augmented neural network-based constitutive models\nutilizing a smoothed version of $L^{0}$-regularization. This aims to maintain\nthe trustworthiness inherited by the physical constraints, but also enables\ninterpretability which has not been possible thus far on any type of machine\nlearning-based constitutive model where model forms were not assumed a-priory\nbut were actually discovered. During the training process, the network\nsimultaneously fits the training data and penalizes the number of active\nparameters, while also ensuring constitutive constraints such as thermodynamic\nconsistency. We show that the method can reliably obtain interpretable and\ntrustworthy constitutive models for compressible and incompressible\nhyperelasticity, yield functions, and hardening models for elastoplasticity,\nfor synthetic and experimental data.",
          "link": "http://arxiv.org/abs/2310.03652",
          "publishedOn": "2023-10-07T00:42:20.201Z",
          "wordCount": null,
          "title": "Extreme sparsification of physics-augmented neural networks for interpretable model discovery in mechanics. (arXiv:2310.03652v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jiashu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanatsoulis_C/0/1/0/all/0/1\">Charilaos I. Kanatsoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>",
          "description": "Network alignment is the task of establishing one-to-one correspondences\nbetween the nodes of different graphs and finds a plethora of applications in\nhigh-impact domains. However, this task is known to be NP-hard in its general\nform, and existing algorithms do not scale up as the size of the graphs\nincreases. To tackle both challenges we propose a novel generalized graph\nautoencoder architecture, designed to extract powerful and robust node\nembeddings, that are tailored to the alignment task. We prove that the\ngenerated embeddings are associated with the eigenvalues and eigenvectors of\nthe graphs and can achieve more accurate alignment compared to classical\nspectral methods. Our proposed framework also leverages transfer learning and\ndata augmentation to achieve efficient network alignment at a very large scale\nwithout retraining. Extensive experiments on both network and sub-network\nalignment with real-world graphs provide corroborating evidence supporting the\neffectiveness and scalability of the proposed approach.",
          "link": "http://arxiv.org/abs/2310.03272",
          "publishedOn": "2023-10-07T00:42:20.200Z",
          "wordCount": null,
          "title": "Network Alignment with Transferable Graph Autoencoders. (arXiv:2310.03272v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15357",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_Y/0/1/0/all/0/1\">Yiyang Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1\">Huan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_W/0/1/0/all/0/1\">Wenhan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_J/0/1/0/all/0/1\">Jianlong Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jiaying Liu</a>",
          "description": "Diffusion models, as a kind of powerful generative model, have given\nimpressive results on image super-resolution (SR) tasks. However, due to the\nrandomness introduced in the reverse process of diffusion models, the\nperformances of diffusion-based SR models are fluctuating at every time of\nsampling, especially for samplers with few resampled steps. This inherent\nrandomness of diffusion models results in ineffectiveness and instability,\nmaking it challenging for users to guarantee the quality of SR results.\nHowever, our work takes this randomness as an opportunity: fully analyzing and\nleveraging it leads to the construction of an effective plug-and-play sampling\nmethod that owns the potential to benefit a series of diffusion-based SR\nmethods. More in detail, we propose to steadily sample high-quality SR images\nfrom pre-trained diffusion-based SR models by solving diffusion ordinary\ndifferential equations (diffusion ODEs) with optimal boundary conditions (BCs)\nand analyze the characteristics between the choices of BCs and their\ncorresponding SR results. Our analysis shows the route to obtain an\napproximately optimal BC via an efficient exploration in the whole space. The\nquality of SR results sampled by the proposed method with fewer steps\noutperforms the quality of results sampled by current methods with randomness\nfrom the same pre-trained diffusion-based SR model, which means that our\nsampling method \"boosts\" current diffusion-based SR models without any\nadditional training.",
          "link": "http://arxiv.org/abs/2305.15357",
          "publishedOn": "2023-10-07T00:42:20.199Z",
          "wordCount": null,
          "title": "Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution. (arXiv:2305.15357v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03696",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Parhi_R/0/1/0/all/0/1\">Rahul Parhi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Unser_M/0/1/0/all/0/1\">Michael Unser</a>",
          "description": "We investigate the variational optimality (specifically, the Banach space\noptimality) of a large class of neural architectures with multivariate\nnonlinearities/activation functions. To that end, we construct a new family of\nBanach spaces defined via a regularization operator and the $k$-plane\ntransform. We prove a representer theorem that states that the solution sets to\nlearning problems posed over these Banach spaces are completely characterized\nby neural architectures with multivariate nonlinearities. These optimal\narchitectures have skip connections and are tightly connected to orthogonal\nweight normalization and multi-index models, both of which have received\nconsiderable interest in the neural network community. Our framework is\ncompatible with a number of classical nonlinearities including the rectified\nlinear unit (ReLU) activation function, the norm activation function, and the\nradial basis functions found in the theory of thin-plate/polyharmonic splines.\nWe also show that the underlying spaces are special instances of reproducing\nkernel Banach spaces and variation spaces. Our results shed light on the\nregularity of functions learned by neural networks trained on data,\nparticularly with multivariate nonlinearities, and provide new theoretical\nmotivation for several architectural choices found in practice.",
          "link": "http://arxiv.org/abs/2310.03696",
          "publishedOn": "2023-10-07T00:42:20.197Z",
          "wordCount": null,
          "title": "Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choffrut_A/0/1/0/all/0/1\">Antoine Choffrut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinot_R/0/1/0/all/0/1\">Rafael Pinot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sirdey_R/0/1/0/all/0/1\">Renaud Sirdey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1\">John Stephan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuber_M/0/1/0/all/0/1\">Martin Zuber</a>",
          "description": "Due to the large-scale availability of data, machine learning (ML) algorithms\nare being deployed in distributed topologies, where different nodes collaborate\nto train ML models over their individual data by exchanging model-related\ninformation (e.g., gradients) with a central server. However, distributed\nlearning schemes are notably vulnerable to two threats. First, Byzantine nodes\ncan single-handedly corrupt the learning by sending incorrect information to\nthe server, e.g., erroneous gradients. The standard approach to mitigate such\nbehavior is to use a non-linear robust aggregation method at the server.\nSecond, the server can violate the privacy of the nodes. Recent attacks have\nshown that exchanging (unencrypted) gradients enables a curious server to\nrecover the totality of the nodes' data. The use of homomorphic encryption\n(HE), a gold standard security primitive, has extensively been studied as a\nprivacy-preserving solution to distributed learning in non-Byzantine scenarios.\nHowever, due to HE's large computational demand especially for high-dimensional\nML models, there has not yet been any attempt to design purely homomorphic\noperators for non-linear robust aggregators. In this work, we present SABLE,\nthe first completely homomorphic and Byzantine robust distributed learning\nalgorithm. SABLE essentially relies on a novel plaintext encoding method that\nenables us to implement the robust aggregator over batching-friendly BGV.\nMoreover, this encoding scheme also accelerates state-of-the-art homomorphic\nsorting with larger security margins and smaller ciphertext size. We perform\nextensive experiments on image classification tasks and show that our algorithm\nachieves practical execution times while matching the ML performance of its\nnon-private counterpart.",
          "link": "http://arxiv.org/abs/2309.05395",
          "publishedOn": "2023-10-07T00:42:20.193Z",
          "wordCount": null,
          "title": "Practical Homomorphic Aggregation for Byzantine ML. (arXiv:2309.05395v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yujin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiaming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">Zeying Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Junwei Liang</a>",
          "description": "Accurate precipitation forecasting is a vital challenge of both scientific\nand societal importance. Data-driven approaches have emerged as a widely used\nsolution for addressing this challenge. However, solely relying on data-driven\napproaches has limitations in modeling the underlying physics, making accurate\npredictions difficult. Coupling AI-based post-processing techniques with\ntraditional Numerical Weather Prediction (NWP) methods offers a more effective\nsolution for improving forecasting accuracy. Despite previous post-processing\nefforts, accurately predicting heavy rainfall remains challenging due to the\nimbalanced precipitation data across locations and complex relationships\nbetween multiple meteorological variables. To address these limitations, we\nintroduce the PostRainBench, a comprehensive multi-variable NWP post-processing\nbenchmark consisting of three datasets for NWP post-processing-based\nprecipitation forecasting. We propose CAMT, a simple yet effective Channel\nAttention Enhanced Multi-task Learning framework with a specially designed\nweighted loss function. Its flexible design allows for easy plug-and-play\nintegration with various backbones. Extensive experimental results on the\nproposed benchmark show that our method outperforms state-of-the-art methods by\n6.3%, 4.7%, and 26.8% in rain CSI on the three datasets respectively. Most\nnotably, our model is the first deep learning-based method to outperform\ntraditional Numerical Weather Prediction (NWP) approaches in extreme\nprecipitation conditions. It shows improvements of 15.6%, 17.4%, and 31.8% over\nNWP predictions in heavy rain CSI on respective datasets. These results\nhighlight the potential impact of our model in reducing the severe consequences\nof extreme weather events.",
          "link": "http://arxiv.org/abs/2310.02676",
          "publishedOn": "2023-10-07T00:42:20.192Z",
          "wordCount": null,
          "title": "PostRainBench: A comprehensive benchmark and a new model for precipitation forecasting. (arXiv:2310.02676v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akram_A/0/1/0/all/0/1\">Arslan Akram</a>",
          "description": "Since ChatGPT has emerged as a major AIGC model, providing high-quality\nresponses across a wide range of applications (including software development\nand maintenance), it has attracted much interest from many individuals. ChatGPT\nhas great promise, but there are serious problems that might arise from its\nmisuse, especially in the realms of education and public safety. Several AIGC\ndetectors are available, and they have all been tested on genuine text.\nHowever, more study is needed to see how effective they are for multi-domain\nChatGPT material. This study aims to fill this need by creating a multi-domain\ndataset for testing the state-of-the-art APIs and tools for detecting\nartificially generated information used by universities and other research\ninstitutions. A large dataset consisting of articles, abstracts, stories, news,\nand product reviews was created for this study. The second step is to use the\nnewly created dataset to put six tools through their paces. Six different\nartificial intelligence (AI) text identification systems, including \"GPTkit,\"\n\"GPTZero,\" \"Originality,\" \"Sapling,\" \"Writer,\" and \"Zylalab,\" have accuracy\nrates between 55.29 and 97.0%. Although all the tools fared well in the\nevaluations, originality was particularly effective across the board.",
          "link": "http://arxiv.org/abs/2310.01423",
          "publishedOn": "2023-10-07T00:42:20.188Z",
          "wordCount": null,
          "title": "An Empirical Study of AI Generated Text Detection Tools. (arXiv:2310.01423v1 [cs.CL] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1\">Aadi Kothari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tohme_T/0/1/0/all/0/1\">Tony Tohme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Youcef_Toumi_K/0/1/0/all/0/1\">Kamal Youcef-Toumi</a>",
          "description": "Human motion prediction is an essential step for efficient and safe\nhuman-robot collaboration. Current methods either purely rely on representing\nthe human joints in some form of neural network-based architecture or use\nregression models offline to fit hyper-parameters in the hope of capturing a\nmodel encompassing human motion. While these methods provide good initial\nresults, they are missing out on leveraging well-studied human body kinematic\nmodels as well as body and scene constraints which can help boost the efficacy\nof these prediction frameworks while also explicitly avoiding implausible human\njoint configurations. We propose a novel human motion prediction framework that\nincorporates human joint constraints and scene constraints in a Gaussian\nProcess Regression (GPR) model to predict human motion over a set time horizon.\nThis formulation is combined with an online context-aware constraints model to\nleverage task-dependent motions. It is tested on a human arm kinematic model\nand implemented on a human-robot collaborative setup with a UR5 robot arm to\ndemonstrate the real-time capability of our approach. Simulations were also\nperformed on datasets like HA4M and ANDY. The simulation and experimental\nresults demonstrate considerable improvements in a Gaussian Process framework\nwhen these constraints are explicitly considered.",
          "link": "http://arxiv.org/abs/2310.03314",
          "publishedOn": "2023-10-07T00:42:20.186Z",
          "wordCount": null,
          "title": "Enhanced Human-Robot Collaboration using Constrained Probabilistic Human-Motion Prediction. (arXiv:2310.03314v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.17329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1\">Kangxian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiancheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Donglai Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1\">Ziqiao Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Pulmonary diseases rank prominently among the principal causes of death\nworldwide. Curing them will require, among other things, a better understanding\nof the many complex 3D tree-shaped structures within the pulmonary system, such\nas airways, arteries, and veins. In theory, they can be modeled using\nhigh-resolution image stacks. Unfortunately, standard CNN approaches operating\non dense voxel grids are prohibitively expensive. To remedy this, we introduce\na point-based approach that preserves graph connectivity of tree skeleton and\nincorporates an implicit surface representation. It delivers SOTA accuracy at a\nlow computational cost and the resulting models have usable surfaces. Due to\nthe scarcity of publicly accessible data, we have also curated an extensive\ndataset to evaluate our approach and will make it public.",
          "link": "http://arxiv.org/abs/2309.17329",
          "publishedOn": "2023-10-07T00:42:20.182Z",
          "wordCount": null,
          "title": "Efficient Anatomical Labeling of Pulmonary Tree Structures via Implicit Point-Graph Networks. (arXiv:2309.17329v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zelai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yancheng Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi Wu</a>",
          "description": "Self-play (SP) is a popular multi-agent reinforcement learning (MARL)\nframework for solving competitive games, where each agent optimizes policy by\ntreating others as part of the environment. Despite the empirical successes,\nthe theoretical properties of SP-based methods are limited to two-player\nzero-sum games. However, for mixed cooperative-competitive games where agents\non the same team need to cooperate with each other, we can show a simple\ncounter-example where SP-based methods cannot converge to a global Nash\nequilibrium (NE) with high probability. Alternatively, Policy-Space Response\nOracles (PSRO) is an iterative framework for learning NE, where the best\nresponses w.r.t. previous policies are learned in each iteration. PSRO can be\ndirectly extended to mixed cooperative-competitive settings by jointly learning\nteam best responses with all convergence properties unchanged. However, PSRO\nrequires repeatedly training joint policies from scratch till convergence,\nwhich makes it hard to scale to complex games. In this work, we develop a novel\nalgorithm, Fictitious Cross-Play (FXP), which inherits the benefits from both\nframeworks. FXP simultaneously trains an SP-based main policy and a counter\npopulation of best response policies. The main policy is trained by fictitious\nself-play and cross-play against the counter population, while the counter\npolicies are trained as the best responses to the main policy's past versions.\nWe validate our method in matrix games and show that FXP converges to global\nNEs while SP methods fail. We also conduct experiments in a gridworld domain,\nwhere FXP achieves higher Elo ratings and lower exploitabilities than\nbaselines, and a more challenging football game, where FXP defeats SOTA models\nwith over 94% win rate.",
          "link": "http://arxiv.org/abs/2310.03354",
          "publishedOn": "2023-10-07T00:42:20.181Z",
          "wordCount": null,
          "title": "Fictitious Cross-Play: Learning Global Nash Equilibrium in Mixed Cooperative-Competitive Games. (arXiv:2310.03354v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03378",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bhure_P/0/1/0/all/0/1\">Pawan R. Bhure</a>, <a href=\"http://arxiv.org/find/math/1/au:+Santhanam_M/0/1/0/all/0/1\">M. S. Santhanam</a>",
          "description": "The study of interacting dynamical systems continues to attract research\ninterest in various fields of science and engineering. In a collection of\ninteracting particles, the interaction network contains information about how\nvarious components interact with one another. Inferring the information about\nthe interaction network from the dynamics of agents is a problem of\nlong-standing interest. In this work, we employ a self-supervised neural\nnetwork model to achieve two outcomes: to recover the interaction network and\nto predict the dynamics of individual agents. Both these information are\ninferred solely from the observed trajectory data. This work presents an\napplication of the Neural Relational Inference model to two dynamical systems:\ncoupled particles mediated by Hooke's law interaction and coupled phase\n(Kuramoto) oscillators.",
          "link": "http://arxiv.org/abs/2310.03378",
          "publishedOn": "2023-10-07T00:42:20.180Z",
          "wordCount": null,
          "title": "Machine learning the interaction network in coupled dynamical systems. (arXiv:2310.03378v1 [math.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.20057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lisha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernando_H/0/1/0/all/0/1\">Heshan Fernando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>",
          "description": "Multi-objective learning (MOL) problems often arise in emerging machine\nlearning problems when there are multiple learning criteria, data modalities,\nor learning tasks. Different from single-objective learning, one of the\ncritical challenges in MOL is the potential conflict among different objectives\nduring the iterative optimization process. Recent works have developed various\ndynamic weighting algorithms for MOL such as MGDA and its variants, where the\ncentral idea is to find an update direction that avoids conflicts among\nobjectives. Albeit its appealing intuition, empirical studies show that dynamic\nweighting methods may not always outperform static ones. To understand this\ntheory-practical gap, we focus on a new stochastic variant of MGDA - the\nMulti-objective gradient with Double sampling (MoDo) algorithm, and study the\ngeneralization performance of the dynamic weighting-based MoDo and its\ninterplay with optimization through the lens of algorithm stability. Perhaps\nsurprisingly, we find that the key rationale behind MGDA -- updating along\nconflict-avoidant direction - may hinder dynamic weighting algorithms from\nachieving the optimal ${\\cal O}(1/\\sqrt{n})$ population risk, where $n$ is the\nnumber of training samples. We further demonstrate the impact of the\nvariability of dynamic weights on the three-way trade-off among optimization,\ngeneralization, and conflict avoidance that is unique in MOL. We showcase the\ngenerality of our theoretical framework by analyzing other existing stochastic\nMOL algorithms under the framework. Experiments on various multi-task learning\nbenchmarks are performed to demonstrate the practical applicability. Code is\navailable at https://github.com/heshandevaka/Trade-Off-MOL.",
          "link": "http://arxiv.org/abs/2305.20057",
          "publishedOn": "2023-10-07T00:42:20.179Z",
          "wordCount": null,
          "title": "Three-Way Trade-Off in Multi-Objective Learning: Optimization, Generalization and Conflict-Avoidance. (arXiv:2305.20057v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuelin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "Building machines that can reason about physical events and their causal\nrelationships is crucial for flexible interaction with the physical world.\nHowever, most existing physical and causal reasoning benchmarks are exclusively\nbased on synthetically generated events and synthetic natural language\ndescriptions of causal relationships. This design brings up two issues. First,\nthere is a lack of diversity in both event types and natural language\ndescriptions; second, causal relationships based on manually-defined heuristics\nare different from human judgments. To address both shortcomings, we present\nthe CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of\nphysical events with human labels. We employ two techniques to improve data\ncollection efficiency: first, a novel iterative event cloze task to elicit a\nnew representation of events in videos, which we term Causal Event Graphs\n(CEGs); second, a data augmentation technique based on neural language\ngenerative models. We convert the collected CEGs into questions and answers to\nbe consistent with prior work. Finally, we study a collection of baseline\napproaches for CLEVRER-Humans question-answering, highlighting the great\nchallenges set forth by our benchmark.",
          "link": "http://arxiv.org/abs/2310.03635",
          "publishedOn": "2023-10-07T00:42:20.177Z",
          "wordCount": null,
          "title": "CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooper_C/0/1/0/all/0/1\">Coleman Hooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1\">Amir Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Sheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1\">Michael W. Mahoney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>",
          "description": "Generative Large Language Models (LLMs) have demonstrated remarkable results\nfor a wide range of tasks. However, deploying these models for inference has\nbeen a significant challenge due to their unprecedented resource requirements.\nThis has forced existing deployment frameworks to use multi-GPU inference\npipelines, which are often complex and costly, or to use smaller and less\nperformant models. In this work, we demonstrate that the main bottleneck for\ngenerative inference with LLMs is memory bandwidth, rather than compute,\nspecifically for single batch inference. While quantization has emerged as a\npromising solution by representing model weights with reduced precision,\nprevious efforts have often resulted in notable performance degradation. To\naddress this, we introduce SqueezeLLM, a post-training quantization framework\nthat not only enables lossless compression to ultra-low precisions of up to\n3-bit, but also achieves higher quantization performance under the same memory\nconstraint. Our framework incorporates two novel ideas: (i) sensitivity-based\nnon-uniform quantization, which searches for the optimal bit precision\nassignment based on second-order information; and (ii) the Dense-and-Sparse\ndecomposition that stores outliers and sensitive weight values in an efficient\nsparse format. When applied to the LLaMA models, our 3-bit quantization\nsignificantly reduces the perplexity gap from the FP16 baseline by up to 2.1x\nas compared to the state-of-the-art methods with the same memory requirement.\nFurthermore, when deployed on an A6000 GPU, our quantized models achieve up to\n2.3x speedup compared to the baseline. Our code is open-sourced and available\nonline.",
          "link": "http://arxiv.org/abs/2306.07629",
          "publishedOn": "2023-10-07T00:42:20.176Z",
          "wordCount": null,
          "title": "SqueezeLLM: Dense-and-Sparse Quantization. (arXiv:2306.07629v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ettenhofer_A/0/1/0/all/0/1\">Armin Ettenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulze_J/0/1/0/all/0/1\">Jan-Philipp Schulze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pizzi_K/0/1/0/all/0/1\">Karla Pizzi</a>",
          "description": "Audio adversarial examples are audio files that have been manipulated to fool\nan automatic speech recognition (ASR) system, while still sounding benign to a\nhuman listener. Most methods to generate such samples are based on a two-step\nalgorithm: first, a viable adversarial audio file is produced, then, this is\nfine-tuned with respect to perceptibility and robustness. In this work, we\npresent an integrated algorithm that uses psychoacoustic models and room\nimpulse responses (RIR) in the generation step. The RIRs are dynamically\ncreated by a neural network during the generation process to simulate a\nphysical environment to harden our examples against transformations experienced\nin over-the-air attacks. We compare the different approaches in three\nexperiments: in a simulated environment and in a realistic over-the-air\nscenario to evaluate the robustness, and in a human study to evaluate the\nperceptibility. Our algorithms considering psychoacoustics only or in addition\nto the robustness show an improvement in the signal-to-noise ratio (SNR) as\nwell as in the human perception study, at the cost of an increased word error\nrate (WER).",
          "link": "http://arxiv.org/abs/2310.03349",
          "publishedOn": "2023-10-07T00:42:20.174Z",
          "wordCount": null,
          "title": "An Integrated Algorithm for Robust and Imperceptible Audio Adversarial Examples. (arXiv:2310.03349v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.11546",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Tracey_B/0/1/0/all/0/1\">Brendan D. Tracey</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Michi_A/0/1/0/all/0/1\">Andrea Michi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chervonyi_Y/0/1/0/all/0/1\">Yuri Chervonyi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Davies_I/0/1/0/all/0/1\">Ian Davies</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Paduraru_C/0/1/0/all/0/1\">Cosmin Paduraru</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lazic_N/0/1/0/all/0/1\">Nevena Lazic</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Felici_F/0/1/0/all/0/1\">Federico Felici</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ewalds_T/0/1/0/all/0/1\">Timo Ewalds</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Donner_C/0/1/0/all/0/1\">Craig Donner</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Galperti_C/0/1/0/all/0/1\">Cristian Galperti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Buchli_J/0/1/0/all/0/1\">Jonas Buchli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Neunert_M/0/1/0/all/0/1\">Michael Neunert</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huber_A/0/1/0/all/0/1\">Andrea Huber</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Evens_J/0/1/0/all/0/1\">Jonathan Evens</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kurylowicz_P/0/1/0/all/0/1\">Paula Kurylowicz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mankowitz_D/0/1/0/all/0/1\">Daniel J. Mankowitz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>, The <a href=\"http://arxiv.org/find/physics/1/au:+Team_TCV/0/1/0/all/0/1\">TCV Team</a>",
          "description": "Reinforcement learning (RL) has shown promising results for real-time control\nsystems, including the domain of plasma magnetic control. However, there are\nstill significant drawbacks compared to traditional feedback control approaches\nfor magnetic confinement. In this work, we address key drawbacks of the RL\nmethod; achieving higher control accuracy for desired plasma properties,\nreducing the steady-state error, and decreasing the required time to learn new\ntasks. We build on top of \\cite{degrave2022magnetic}, and present algorithmic\nimprovements to the agent architecture and training procedure. We present\nsimulation results that show up to 65\\% improvement in shape accuracy, achieve\nsubstantial reduction in the long-term bias of the plasma current, and\nadditionally reduce the training time required to learn new tasks by a factor\nof 3 or more. We present new experiments using the upgraded RL-based\ncontrollers on the TCV tokamak, which validate the simulation results achieved,\nand point the way towards routinely achieving accurate discharges using the RL\napproach.",
          "link": "http://arxiv.org/abs/2307.11546",
          "publishedOn": "2023-10-07T00:42:20.174Z",
          "wordCount": null,
          "title": "Towards practical reinforcement learning for tokamak magnetic control. (arXiv:2307.11546v2 [physics.plasm-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Seungwoo Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1\">Wonsik Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_J/0/1/0/all/0/1\">Junghyo Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1\">Heung-Il Suk</a>",
          "description": "Alzheimer's disease (AD) is a devastating neurodegenerative condition that\nprecedes progressive and irreversible dementia; thus, predicting its\nprogression over time is vital for clinical diagnosis and treatment. Numerous\nstudies have implemented structural magnetic resonance imaging (MRI) to model\nAD progression, focusing on three integral aspects: (i) temporal variability,\n(ii) incomplete observations, and (iii) temporal geometric characteristics.\nHowever, deep learning-based approaches regarding data variability and sparsity\nhave yet to consider inherent geometrical properties sufficiently. The ordinary\ndifferential equation-based geometric modeling method (ODE-RGRU) has recently\nemerged as a promising strategy for modeling time-series data by intertwining a\nrecurrent neural network and an ODE in Riemannian space. Despite its\nachievements, ODE-RGRU encounters limitations when extrapolating positive\ndefinite symmetric metrics from incomplete samples, leading to feature reverse\noccurrences that are particularly problematic, especially within the clinical\nfacet. Therefore, this study proposes a novel geometric learning approach that\nmodels longitudinal MRI biomarkers and cognitive scores by combining three\nmodules: topological space shift, ODE-RGRU, and trajectory estimation. We have\nalso developed a training algorithm that integrates manifold mapping with\nmonotonicity constraints to reflect measurement transition irreversibility. We\nverify our proposed method's efficacy by predicting clinical labels and\ncognitive scores over time in regular and irregular settings. Furthermore, we\nthoroughly analyze our proposed framework through an ablation study.",
          "link": "http://arxiv.org/abs/2310.03353",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "Deep Geometric Learning with Monotonicity Constraints for Alzheimer's Disease Progression. (arXiv:2310.03353v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03365",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jafari_H/0/1/0/all/0/1\">Hossein Jafari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Faez_K/0/1/0/all/0/1\">Karim Faez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Amindavar_H/0/1/0/all/0/1\">Hamidreza Amindavar</a>",
          "description": "Lung cancer is highly lethal, emphasizing the critical need for early\ndetection. However, identifying lung nodules poses significant challenges for\nradiologists, who rely heavily on their expertise and experience for accurate\ndiagnosis. To address this issue, computer-aided diagnosis systems based on\nmachine learning techniques have emerged to assist doctors in identifying lung\nnodules from computed tomography (CT) scans. Unfortunately, existing networks\nin this domain often suffer from computational complexity, leading to high\nrates of false negatives and false positives, limiting their effectiveness. To\naddress these challenges, we present an innovative model that harnesses the\nstrengths of both convolutional neural networks and vision transformers.\nInspired by object detection in videos, we treat each 3D CT image as a video,\nindividual slices as frames, and lung nodules as objects, enabling a\ntime-series application. The primary objective of our work is to overcome\nhardware limitations during model training, allowing for efficient processing\nof 2D data while utilizing inter-slice information for accurate identification\nbased on 3D image context. We validated the proposed network by applying a\n10-fold cross-validation technique to the publicly available Lung Nodule\nAnalysis 2016 dataset. Our proposed architecture achieves an average\nsensitivity criterion of 97.84% and a competition performance metrics (CPM) of\n96.0% with few parameters. Comparative analysis with state-of-the-art\nadvancements in lung nodule identification demonstrates the significant\naccuracy achieved by our proposed model.",
          "link": "http://arxiv.org/abs/2310.03365",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "Swin-Tempo: Temporal-Aware Lung Nodule Detection in CT Scans as Video Sequences Using Swin Transformer-Enhanced UNet. (arXiv:2310.03365v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.06178",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Allam_T/0/1/0/all/0/1\">Tarek Allam Jr.</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+McEwen_J/0/1/0/all/0/1\">Jason D. McEwen</a>",
          "description": "Future surveys such as the Legacy Survey of Space and Time (LSST) of the Vera\nC. Rubin Observatory will observe an order of magnitude more astrophysical\ntransient events than any previous survey before. With this deluge of\nphotometric data, it will be impossible for all such events to be classified by\nhumans alone. Recent efforts have sought to leverage machine learning methods\nto tackle the challenge of astronomical transient classification, with ever\nimproving success. Transformers are a recently developed deep learning\narchitecture, first proposed for natural language processing, that have shown a\ngreat deal of recent success. In this work we develop a new transformer\narchitecture, which uses multi-head self attention at its core, for general\nmulti-variate time-series data. Furthermore, the proposed time-series\ntransformer architecture supports the inclusion of an arbitrary number of\nadditional features, while also offering interpretability. We apply the\ntime-series transformer to the task of photometric classification, minimising\nthe reliance of expert domain knowledge for feature selection, while achieving\nresults comparable to state-of-the-art photometric classification methods. We\nachieve a logarithmic-loss of 0.507 on imbalanced data in a representative\nsetting using data from the Photometric LSST Astronomical Time-Series\nClassification Challenge (PLAsTiCC). Moreover, we achieve a micro-averaged\nreceiver operating characteristic area under curve of 0.98 and micro-averaged\nprecision-recall area under curve of 0.87.",
          "link": "http://arxiv.org/abs/2105.06178",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "Paying Attention to Astronomical Transients: Introducing the Time-series Transformer for Photometric Classification. (arXiv:2105.06178v3 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaxu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinping Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaowei Huang</a>",
          "description": "Hyperbolic graph convolutional networks (HGCN) have demonstrated significant\npotential in extracting information from hierarchical graphs. However, existing\nHGCNs are limited to shallow architectures, due to the expensive hyperbolic\noperations and the over-smoothing issue as depth increases. Although in GCNs,\ntreatments have been applied to alleviate over-smoothing, developing a\nhyperbolic therapy presents distinct challenges since operations should be\ncarefully designed to fit the hyperbolic nature. Addressing the above\nchallenges, in this work, we propose DeepHGCN, the first deep multi-layer HGCN\narchitecture with dramatically improved computational efficiency and\nsubstantially alleviated over-smoothing effect. DeepHGCN presents two key\nenablers of deep HGCNs: (1) a novel hyperbolic feature transformation layer\nthat enables fast and accurate linear maps; and (2) Techniques such as\nhyperbolic residual connections and regularization for both weights and\nfeatures facilitated by an efficient hyperbolic midpoint method. Extensive\nexperiments demonstrate that DeepHGCN obtains significant improvements in link\nprediction and node classification tasks compared to both Euclidean and shallow\nhyperbolic GCN variants.",
          "link": "http://arxiv.org/abs/2310.02027",
          "publishedOn": "2023-10-07T00:42:20.173Z",
          "wordCount": null,
          "title": "DeepHGCN: Toward Deeper Hyperbolic Graph Convolutional Networks. (arXiv:2310.02027v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Haosen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Existing approaches to algorithmic fairness aim to ensure equitable outcomes\nif human decision-makers comply perfectly with algorithmic decisions. However,\nperfect compliance with the algorithm is rarely a reality or even a desirable\noutcome in human-AI collaboration. Yet, recent studies have shown that\nselective compliance with fair algorithms can amplify discrimination relative\nto the prior human policy. As a consequence, ensuring equitable outcomes\nrequires fundamentally different algorithmic design principles that ensure\nrobustness to the decision-maker's (a priori unknown) compliance pattern. We\ndefine the notion of compliance-robustly fair algorithmic recommendations that\nare guaranteed to (weakly) improve fairness in decisions, regardless of the\nhuman's compliance pattern. We propose a simple optimization strategy to\nidentify the best performance-improving compliance-robustly fair policy.\nHowever, we show that it may be infeasible to design algorithmic\nrecommendations that are simultaneously fair in isolation, compliance-robustly\nfair, and more accurate than the human policy; thus, if our goal is to improve\nthe equity and accuracy of human-AI collaboration, it may not be desirable to\nenforce traditional fairness constraints.",
          "link": "http://arxiv.org/abs/2310.03647",
          "publishedOn": "2023-10-07T00:42:20.171Z",
          "wordCount": 659,
          "title": "Rethinking Fairness for Human-AI Collaboration. (arXiv:2310.03647v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.09376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1\">Binhang Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hailong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ruobing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiang Gao</a>",
          "description": "Deep neural network (DNN) models have become increasingly crucial components\nin intelligent software systems. However, training a DNN model is typically\nexpensive in terms of both time and money. To address this issue, researchers\nhave recently focused on reusing existing DNN models - borrowing the idea of\ncode reuse in software engineering. However, reusing an entire model could\ncause extra overhead or inherits the weakness from the undesired\nfunctionalities. Hence, existing work proposes to decompose an already trained\nmodel into modules, i.e., modularizing-after-training, and enable module reuse.\nSince trained models are not built for modularization,\nmodularizing-after-training incurs huge overhead and model accuracy loss. In\nthis paper, we propose a novel approach that incorporates modularization into\nthe model training process, i.e., modularizing-while-training (MwT). We train a\nmodel to be structurally modular through two loss functions that optimize\nintra-module cohesion and inter-module coupling. We have implemented the\nproposed approach for modularizing Convolutional Neural Network (CNN) models in\nthis work. The evaluation results on representative models demonstrate that MwT\noutperforms the state-of-the-art approach. Specifically, the accuracy loss\ncaused by MwT is only 1.13 percentage points, which is 1.76 percentage points\nless than that of the baseline. The kernel retention rate of the modules\ngenerated by MwT is only 14.58%, with a reduction of 74.31% over the\nstate-of-the-art approach. Furthermore, the total time cost required for\ntraining and modularizing is only 108 minutes, half of the baseline.",
          "link": "http://arxiv.org/abs/2306.09376",
          "publishedOn": "2023-10-07T00:42:20.111Z",
          "wordCount": null,
          "title": "Modularizing while Training: A New Paradigm for Modularizing DNN Models. (arXiv:2306.09376v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.13777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+French_M/0/1/0/all/0/1\">Matthew G. French</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Talou_G/0/1/0/all/0/1\">Gonzalo D. Maso Talou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gamage_T/0/1/0/all/0/1\">Thiranja P. Babarenda Gamage</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nash_M/0/1/0/all/0/1\">Martyn P. Nash</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nielsen_P/0/1/0/all/0/1\">Poul M. Nielsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doyle_A/0/1/0/all/0/1\">Anthony J. Doyle</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Iglesias_J/0/1/0/all/0/1\">Juan Eugenio Iglesias</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Balbastre_Y/0/1/0/all/0/1\">Ya&#xeb;l Balbastre</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Young_S/0/1/0/all/0/1\">Sean I. Young</a>",
          "description": "In breast surgical planning, accurate registration of MR images across\npatient positions has the potential to improve the localisation of tumours\nduring breast cancer treatment. While learning-based registration methods have\nrecently become the state-of-the-art approach for most medical image\nregistration tasks, these methods have yet to make inroads into breast image\nregistration due to certain difficulties-the lack of rich texture information\nin breast MR images and the need for the deformations to be diffeomophic. In\nthis work, we propose learning strategies for breast MR image registration that\nare amenable to diffeomorphic constraints, together with early experimental\nresults from in-silico and in-vivo experiments. One key contribution of this\nwork is a registration network which produces superior registration outcomes\nfor breast images in addition to providing diffeomorphic guarantees.",
          "link": "http://arxiv.org/abs/2309.13777",
          "publishedOn": "2023-10-07T00:42:20.105Z",
          "wordCount": null,
          "title": "Diffeomorphic Multi-Resolution Deep Learning Registration for Applications in Breast MRI. (arXiv:2309.13777v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1\">Adrian Cosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radoi_E/0/1/0/all/0/1\">Emilian Radoi</a>",
          "description": "Gait analysis leverages unique walking patterns for person identification and\nassessment across multiple domains. Among the methods used for gait analysis,\nskeleton-based approaches have shown promise due to their robust and\ninterpretable features. However, these methods often rely on hand-crafted\nspatial-temporal graphs that are based on human anatomy disregarding the\nparticularities of the dataset and task. This paper proposes a novel method to\nsimplify the spatial-temporal graph representation for gait-based gender\nestimation, improving interpretability without losing performance. Our approach\nemploys two models, an upstream and a downstream model, that can adjust the\nadjacency matrix for each walking instance, thereby removing the fixed nature\nof the graph. By employing the Straight-Through Gumbel-Softmax trick, our model\nis trainable end-to-end. We demonstrate the effectiveness of our approach on\nthe CASIA-B dataset for gait-based gender estimation. The resulting graphs are\ninterpretable and differ qualitatively from fixed graphs used in existing\nmodels. Our research contributes to enhancing the explainability and\ntask-specific adaptability of gait recognition, promoting more efficient and\nreliable gait-based biometrics.",
          "link": "http://arxiv.org/abs/2310.03396",
          "publishedOn": "2023-10-07T00:42:20.104Z",
          "wordCount": null,
          "title": "Learning to Simplify Spatial-Temporal Graphs in Gait Analysis. (arXiv:2310.03396v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sixing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munoz_J/0/1/0/all/0/1\">J. Pablo Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "Federated learning (FL) offers privacy-preserving decentralized machine\nlearning, optimizing models at edge clients without sharing private data.\nSimultaneously, foundation models (FMs) have gained traction in the artificial\nintelligence (AI) community due to their exceptional performance across various\ntasks. However, integrating FMs into FL presents challenges, primarily due to\ntheir substantial size and intensive resource requirements. This is especially\ntrue when considering the resource heterogeneity in edge FL systems. We present\nan adaptive framework for Resource-aware Federated Foundation Models (RaFFM) to\naddress these challenges. RaFFM introduces specialized model compression\nalgorithms tailored for FL scenarios, such as salient parameter prioritization\nand high-performance subnetwork extraction. These algorithms enable dynamic\nscaling of given transformer-based FMs to fit heterogeneous resource\nconstraints at the network edge during both FL's optimization and deployment\nstages. Experimental results demonstrate that RaFFM shows significant\nsuperiority in resource utilization efficiency and uses fewer resources to\ndeploy FMs to FL. Despite the lower resource consumption, target models\noptimized by RaFFM achieve performance on par with traditional FL methods\napplied to full-sized FMs. This is evident across tasks in both natural\nlanguage processing and computer vision domains.",
          "link": "http://arxiv.org/abs/2310.00247",
          "publishedOn": "2023-10-07T00:42:20.104Z",
          "wordCount": null,
          "title": "Bridging the Gap Between Foundation Models and Heterogeneous Federated Learning. (arXiv:2310.00247v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gong_S/0/1/0/all/0/1\">Shijin Gong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>",
          "description": "When artificial neural networks have demonstrated exceptional practical\nsuccess in a variety of domains, investigations into their theoretical\ncharacteristics, such as their approximation power, statistical properties, and\ngeneralization performance, have concurrently made significant strides. In this\npaper, we construct a novel theory for understanding the effectiveness of\nneural networks, which offers a perspective distinct from prior research.\nSpecifically, we explore the rationale underlying a common practice during the\nconstruction of neural network models: sample splitting. Our findings indicate\nthat the optimal hyperparameters derived from sample splitting can enable a\nneural network model that asymptotically minimizes the prediction risk. We\nconduct extensive experiments across different application scenarios and\nnetwork architectures, and the results manifest our theory's effectiveness.",
          "link": "http://arxiv.org/abs/2307.07726",
          "publishedOn": "2023-10-07T00:42:20.103Z",
          "wordCount": null,
          "title": "Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Johor Jara Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cooper_S/0/1/0/all/0/1\">Seth Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1\">Matthew Guzdial</a>",
          "description": "Automated game design (AGD), the study of automatically generating game\nrules, has a long history in technical games research. AGD approaches generally\nrely on approximations of human play, either objective functions or AI agents.\nDespite this, the majority of these approximators are static, meaning they do\nnot reflect human player's ability to learn and improve in a game. In this\npaper, we investigate the application of Reinforcement Learning (RL) as an\napproximator for human play for rule generation. We recreate the classic AGD\nenvironment Mechanic Maker in Unity as a new, open-source rule generation\nframework. Our results demonstrate that RL produces distinct sets of rules from\nan A* agent baseline, which may be more usable by humans.",
          "link": "http://arxiv.org/abs/2309.09476",
          "publishedOn": "2023-10-07T00:42:20.102Z",
          "wordCount": null,
          "title": "Mechanic Maker 2.0: Reinforcement Learning for Evaluating Generated Rules. (arXiv:2309.09476v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sherborne_T/0/1/0/all/0/1\">Tom Sherborne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasigi_P/0/1/0/all/0/1\">Pradeep Dasigi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>",
          "description": "By reducing the curvature of the loss surface in the parameter space,\nSharpness-aware minimization (SAM) yields widespread robustness improvement\nunder domain transfer. Instead of focusing on parameters, however, this work\nconsiders the transferability of representations as the optimization target for\nout-of-domain generalization in a fine-tuning setup. To encourage the retention\nof transferable representations, we consider trust region-based fine-tuning\nmethods, which exploit task-specific skills without forgetting task-agnostic\nrepresentations from pre-training. We unify parameter- and representation-space\nsmoothing approaches by using trust region bounds to inform SAM-style\nregularizers on both of these optimization surfaces. We propose Trust Region\nAware Minimization (TRAM), a fine-tuning algorithm that optimizes for flat\nminima and smooth, informative representations without forgetting pre-trained\nstructure. We find that TRAM outperforms both sharpness-aware and trust\nregion-based optimization methods on cross-domain language modeling and\ncross-lingual transfer, where robustness to domain transfer and representation\ngenerality are critical for success. TRAM establishes a new standard in\ntraining generalizable models with minimal additional computation.",
          "link": "http://arxiv.org/abs/2310.03646",
          "publishedOn": "2023-10-07T00:42:20.101Z",
          "wordCount": null,
          "title": "TRAM: Bridging Trust Regions and Sharpness Aware Minimization. (arXiv:2310.03646v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azzizadenesheli_K/0/1/0/all/0/1\">Kamyar Azzizadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovachki_N/0/1/0/all/0/1\">Nikola Kovachki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Schiaffini_M/0/1/0/all/0/1\">Miguel Liu-Schiaffini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1\">Jean Kossaifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Scientific discovery and engineering design are currently limited by the time\nand cost of physical experiments, selected mostly through trial-and-error and\nintuition that require deep domain expertise. Numerical simulations present an\nalternative to physical experiments but are usually infeasible for complex\nreal-world domains due to the computational requirements of existing numerical\nmethods. Artificial intelligence (AI) presents a potential paradigm shift by\ndeveloping fast data-driven surrogate models. In particular, an AI framework,\nknown as neural operators, presents a principled framework for learning\nmappings between functions defined on continuous domains, e.g., spatiotemporal\nprocesses and partial differential equations (PDE). They can extrapolate and\npredict solutions at new locations unseen during training, i.e., perform\nzero-shot super-resolution. Neural operators can augment or even replace\nexisting simulators in many applications, such as computational fluid dynamics,\nweather forecasting, and material modeling, while being 4-5 orders of magnitude\nfaster. Further, neural operators can be integrated with physics and other\ndomain constraints enforced at finer resolutions to obtain high-fidelity\nsolutions and good generalization. Since neural operators are differentiable,\nthey can directly optimize parameters for inverse design and other inverse\nproblems. We believe that neural operators present a transformative approach to\nsimulation and design, enabling rapid research and development.",
          "link": "http://arxiv.org/abs/2309.15325",
          "publishedOn": "2023-10-07T00:42:20.101Z",
          "wordCount": null,
          "title": "Neural Operators for Accelerating Scientific Simulations and Design. (arXiv:2309.15325v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Komatsu_T/0/1/0/all/0/1\">Takayuki Komatsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohmura_Y/0/1/0/all/0/1\">Yoshiyuki Ohmura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1\">Yasuo Kuniyoshi</a>",
          "description": "Multi-object representation learning aims to represent complex real-world\nvisual input using the composition of multiple objects. Representation learning\nmethods have often used unsupervised learning to segment an input image into\nindividual objects and encode these objects into each latent vector. However,\nit is not clear how previous methods have achieved the appropriate segmentation\nof individual objects. Additionally, most of the previous methods regularize\nthe latent vectors using a Variational Autoencoder (VAE). Therefore, it is not\nclear whether VAE regularization contributes to appropriate object\nsegmentation. To elucidate the mechanism of object segmentation in multi-object\nrepresentation learning, we conducted an ablation study on MONet, which is a\ntypical method. MONet represents multiple objects using pairs that consist of\nan attention mask and the latent vector corresponding to the attention mask.\nEach latent vector is encoded from the input image and attention mask. Then,\nthe component image and attention mask are decoded from each latent vector. The\nloss function of MONet consists of 1) the sum of reconstruction losses between\nthe input image and decoded component image, 2) the VAE regularization loss of\nthe latent vector, and 3) the reconstruction loss of the attention mask to\nexplicitly encode shape information. We conducted an ablation study on these\nthree loss functions to investigate the effect on segmentation performance. Our\nresults showed that the VAE regularization loss did not affect segmentation\nperformance and the others losses did affect it. Based on this result, we\nhypothesize that it is important to maximize the attention mask of the image\nregion best represented by a single latent vector corresponding to the\nattention mask. We confirmed this hypothesis by evaluating a new loss function\nwith the same mechanism as the hypothesis.",
          "link": "http://arxiv.org/abs/2310.03273",
          "publishedOn": "2023-10-07T00:42:20.100Z",
          "wordCount": null,
          "title": "Ablation Study to Clarify the Mechanism of Object Segmentation in Multi-Object Representation Learning. (arXiv:2310.03273v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1\">Chen Dun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_M/0/1/0/all/0/1\">Mirian Hipolito Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1\">Dimitrios Dimitriadis</a>",
          "description": "One of the goals in Federated Learning (FL) is to create personalized models\nthat can adapt to the context of each participating client, while utilizing\nknowledge from a shared global model. Yet, often, personalization requires a\nfine-tuning step using clients' labeled data in order to achieve good\nperformance. This may not be feasible in scenarios where incoming clients are\nfresh and/or have privacy concerns. It, then, remains open how one can achieve\njust-in-time personalization in these scenarios. We propose FedJETs, a novel\nsolution by using a Mixture-of-Experts (MoE) framework within a FL setup. Our\nmethod leverages the diversity of the clients to train specialized experts on\ndifferent subsets of classes, and a gating function to route the input to the\nmost relevant expert(s). Our gating function harnesses the knowledge of a\npretrained model common expert to enhance its routing decisions on-the-fly. As\na highlight, our approach can improve accuracy up to 18\\% in state of the art\nFL settings, while maintaining competitive zero-shot performance. In practice,\nour method can handle non-homogeneous data distributions, scale more\nefficiently, and improve the state-of-the-art performance on common FL\nbenchmarks.",
          "link": "http://arxiv.org/abs/2306.08586",
          "publishedOn": "2023-10-07T00:42:20.100Z",
          "wordCount": null,
          "title": "FedJETs: Efficient Just-In-Time Personalization with Federated Mixture of Experts. (arXiv:2306.08586v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balasubramaniam Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ioannidis_V/0/1/0/all/0/1\">Vassilis N. Ioannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1\">Huzefa Rangwala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anubhai_R/0/1/0/all/0/1\">Rishita Anubhai</a>",
          "description": "Foundation models (FMs) are able to leverage large volumes of unlabeled data\nto demonstrate superior performance across a wide range of tasks. However, FMs\ndeveloped for biomedical domains have largely remained unimodal, i.e.,\nindependently trained and used for tasks on protein sequences alone, small\nmolecule structures alone, or clinical data alone. To overcome this limitation\nof biomedical FMs, we present BioBridge, a novel parameter-efficient learning\nframework, to bridge independently trained unimodal FMs to establish multimodal\nbehavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn\ntransformations between one unimodal FM and another without fine-tuning any\nunderlying unimodal FMs. Our empirical results demonstrate that BioBridge can\nbeat the best baseline KG embedding methods (on average by around 76.3%) in\ncross-modal retrieval tasks. We also identify BioBridge demonstrates\nout-of-domain generalization ability by extrapolating to unseen modalities or\nrelations. Additionally, we also show that BioBridge presents itself as a\ngeneral purpose retriever that can aid biomedical multimodal question answering\nas well as enhance the guided generation of novel drugs.",
          "link": "http://arxiv.org/abs/2310.03320",
          "publishedOn": "2023-10-07T00:42:20.099Z",
          "wordCount": null,
          "title": "BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph. (arXiv:2310.03320v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_A/0/1/0/all/0/1\">Andras Horvath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jozsa_C/0/1/0/all/0/1\">Csaba M. Jozsa</a>",
          "description": "Neural Radiance Fields (NeRFs) have recently emerged as a powerful tool for\n3D scene representation and rendering. These data-driven models can learn to\nsynthesize high-quality images from sparse 2D observations, enabling realistic\nand interactive scene reconstructions. However, the growing usage of NeRFs in\ncritical applications such as augmented reality, robotics, and virtual\nenvironments could be threatened by adversarial attacks.\n\nIn this paper we present how generalizable NeRFs can be attacked by both\nlow-intensity adversarial attacks and adversarial patches, where the later\ncould be robust enough to be used in real world applications. We also\ndemonstrate targeted attacks, where a specific, predefined output scene is\ngenerated by these attack with success.",
          "link": "http://arxiv.org/abs/2310.03578",
          "publishedOn": "2023-10-07T00:42:20.097Z",
          "wordCount": null,
          "title": "Targeted Adversarial Attacks on Generalizable Neural Radiance Fields. (arXiv:2310.03578v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.03519",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_P/0/1/0/all/0/1\">Peizhou Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoyi Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoliang Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiaojuan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dong_L/0/1/0/all/0/1\">Liang Dong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ying_L/0/1/0/all/0/1\">Leslie Ying</a>",
          "description": "Deep learning methods have been successfully used in various computer vision\ntasks. Inspired by that success, deep learning has been explored in magnetic\nresonance imaging (MRI) reconstruction. In particular, integrating deep\nlearning and model-based optimization methods has shown considerable\nadvantages. However, a large amount of labeled training data is typically\nneeded for high reconstruction quality, which is challenging for some MRI\napplications. In this paper, we propose a novel reconstruction method, named\nDURED-Net, that enables interpretable self-supervised learning for MR image\nreconstruction by combining a self-supervised denoising network and a\nplug-and-play method. We aim to boost the reconstruction performance of\nNoise2Noise in MR reconstruction by adding an explicit prior that utilizes\nimaging physics. Specifically, the leverage of a denoising network for MRI\nreconstruction is achieved using Regularization by Denoising (RED). Experiment\nresults demonstrate that the proposed method requires a reduced amount of\ntraining data to achieve high reconstruction quality among the state-of-art of\nMR reconstruction utilizing the Noise2Noise method.",
          "link": "http://arxiv.org/abs/2205.03519",
          "publishedOn": "2023-10-07T00:42:20.096Z",
          "wordCount": null,
          "title": "Self-supervised Deep Unrolled Reconstruction Using Regularization by Denoising. (arXiv:2205.03519v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1\">Wonsik Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_E/0/1/0/all/0/1\">Eunjin Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_E/0/1/0/all/0/1\">Eunsong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suk_H/0/1/0/all/0/1\">Heung-Il Suk</a>",
          "description": "Deep learning models based on resting-state functional magnetic resonance\nimaging (rs-fMRI) have been widely used to diagnose brain diseases,\nparticularly autism spectrum disorder (ASD). Existing studies have leveraged\nthe functional connectivity (FC) of rs-fMRI, achieving notable classification\nperformance. However, they have significant limitations, including the lack of\nadequate information while using linear low-order FC as inputs to the model,\nnot considering individual characteristics (i.e., different symptoms or varying\nstages of severity) among patients with ASD, and the non-explainability of the\ndecision process. To cover these limitations, we propose a novel\nexplainability-guided region of interest (ROI) selection (EAG-RS) framework\nthat identifies non-linear high-order functional associations among brain\nregions by leveraging an explainable artificial intelligence technique and\nselects class-discriminative regions for brain disease identification. The\nproposed framework includes three steps: (i) inter-regional relation learning\nto estimate non-linear relations through random seed-based network masking,\n(ii) explainable connection-wise relevance score estimation to explore\nhigh-order relations between functional connections, and (iii) non-linear\nhigh-order FC-based diagnosis-informative ROI selection and classifier learning\nto identify ASD. We validated the effectiveness of our proposed method by\nconducting experiments using the Autism Brain Imaging Database Exchange (ABIDE)\ndataset, demonstrating that the proposed method outperforms other comparative\nmethods in terms of various evaluation metrics. Furthermore, we qualitatively\nanalyzed the selected ROIs and identified ASD subtypes linked to previous\nneuroscientific studies.",
          "link": "http://arxiv.org/abs/2310.03404",
          "publishedOn": "2023-10-07T00:42:20.092Z",
          "wordCount": null,
          "title": "EAG-RS: A Novel Explainability-guided ROI-Selection Framework for ASD Diagnosis via Inter-regional Relation Learning. (arXiv:2310.03404v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattaneo_M/0/1/0/all/0/1\">Matias D. Cattaneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klusowski_J/0/1/0/all/0/1\">Jason M. Klusowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shigida_B/0/1/0/all/0/1\">Boris Shigida</a>",
          "description": "In previous literature, backward error analysis was used to find ordinary\ndifferential equations (ODEs) approximating the gradient descent trajectory. It\nwas found that finite step sizes implicitly regularize solutions because terms\nappearing in the ODEs penalize the two-norm of the loss gradients. We prove\nthat the existence of similar implicit regularization in RMSProp and Adam\ndepends on their hyperparameters and the training stage, but with a different\n\"norm\" involved: the corresponding ODE terms either penalize the (perturbed)\none-norm of the loss gradients or, on the contrary, hinder its decrease (the\nlatter case being typical). We also conduct numerical experiments and discuss\nhow the proven facts can influence generalization.",
          "link": "http://arxiv.org/abs/2309.00079",
          "publishedOn": "2023-10-07T00:42:20.092Z",
          "wordCount": null,
          "title": "On the Implicit Bias of Adam. (arXiv:2309.00079v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16738",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yue_Y/0/1/0/all/0/1\">Yubiao Yue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jun Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1\">Haihua Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_B/0/1/0/all/0/1\">Bingchun Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Zhenzhang Li</a>",
          "description": "Booming deep learning has substantially improved the diagnosis for diverse\nlesions in ultrasound images, but a conspicuous research gap concerning\ncervical lymph node lesions still remains. The objective of this work is to\ndiagnose cervical lymph node lesions in ultrasound images by leveraging a deep\nlearning model. To this end, we first collected 3392 cervical ultrasound images\ncontaining normal lymph nodes, benign lymph node lesions, malignant primary\nlymph node lesions, and malignant metastatic lymph node lesions. Given that\nultrasound images are generated by the reflection and scattering of sound waves\nacross varied bodily tissues, we proposed the Conv-FFT Block. It integrates\nconvolutional operations with the fast Fourier transform to more astutely model\nthe images. Building upon this foundation, we designed a novel architecture,\nnamed SFUSNet. SFUSNet not only discerns variances in ultrasound images from\nthe spatial domain but also adeptly captures micro-structural alterations\nacross various lesions in the frequency domain. To ascertain the potential of\nSFUSNet, we benchmarked it against 12 popular architectures through five-fold\ncross-validation. The results show that SFUSNet is the state-of-the-art model\nand can achieve 92.89% accuracy. Moreover, its average precision, average\nsensitivity and average specificity for four types of lesions achieve 90.46%,\n89.95% and 97.49%, respectively.",
          "link": "http://arxiv.org/abs/2308.16738",
          "publishedOn": "2023-10-07T00:42:20.091Z",
          "wordCount": null,
          "title": "SFUSNet: A Spatial-Frequency domain-based Multi-branch Network for diagnosis of Cervical Lymph Node Lesions in Ultrasound Images. (arXiv:2308.16738v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Crispino_N/0/1/0/all/0/1\">Nicholas Crispino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montgomery_K/0/1/0/all/0/1\">Kyle Montgomery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1\">Fankun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenguang Wang</a>",
          "description": "We introduce a method to improve the zero-shot reasoning abilities of large\nlanguage models on general language understanding tasks. Specifically, we build\nan autonomous agent to instruct the reasoning process of large language models.\nWe show this approach further unleashes the zero-shot reasoning abilities of\nlarge language models to more tasks. We study the performance of our method on\na wide set of datasets spanning generation, classification, and reasoning. We\nshow that our method generalizes to most tasks and obtains state-of-the-art\nzero-shot performance on 20 of the 29 datasets that we evaluate. For instance,\nour method boosts the performance of state-of-the-art large language models by\na large margin, including Vicuna-13b (13.3%), Llama-2-70b-chat (23.2%), and\nGPT-3.5 Turbo (17.0%). Compared to zero-shot chain of thought, our improvement\nin reasoning is striking, with an average increase of 10.5%. With our method,\nLlama-2-70b-chat outperforms zero-shot GPT-3.5 Turbo by 10.2%.",
          "link": "http://arxiv.org/abs/2310.03710",
          "publishedOn": "2023-10-07T00:42:20.085Z",
          "wordCount": null,
          "title": "Agent Instructs Large Language Models to be General Zero-Shot Reasoners. (arXiv:2310.03710v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.17167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>",
          "description": "Large language models (LLMs) have achieved remarkable performance in various\nevaluation benchmarks. However, concerns about their performance are raised on\npotential data contamination in their considerable volume of training corpus.\nMoreover, the static nature and fixed complexity of current benchmarks may\ninadequately gauge the advancing capabilities of LLMs. In this paper, we\nintroduce DyVal, a novel, general, and flexible evaluation protocol for dynamic\nevaluation of LLMs. Based on our proposed dynamic evaluation framework, we\nbuild graph-informed DyVal by leveraging the structural advantage of directed\nacyclic graphs to dynamically generate evaluation samples with controllable\ncomplexities. DyVal generates challenging evaluation sets on reasoning tasks\nincluding mathematics, logical reasoning, and algorithm problems. We evaluate\nvarious LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments\ndemonstrate that LLMs perform worse in DyVal-generated evaluation samples with\ndifferent complexities, emphasizing the significance of dynamic evaluation. We\nalso analyze the failure cases and results of different prompting methods.\nMoreover, DyVal-generated samples are not only evaluation sets, but also\nhelpful data for fine-tuning to improve the performance of LLMs on existing\nbenchmarks. We hope that DyVal can shed light on the future evaluation research\nof LLMs.",
          "link": "http://arxiv.org/abs/2309.17167",
          "publishedOn": "2023-10-07T00:42:20.084Z",
          "wordCount": null,
          "title": "DyVal: Graph-informed Dynamic Evaluation of Large Language Models. (arXiv:2309.17167v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1\">Domenico Marinucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1\">Ivan Nourdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1\">Giovanni Peccati</a>",
          "description": "We study the distribution of a fully connected neural network with random\nGaussian weights and biases in which the hidden layer widths are proportional\nto a large constant $n$. Under mild assumptions on the non-linearity, we obtain\nquantitative bounds on normal approximations valid at large but finite $n$ and\nany fixed network depth. Our theorems show both for the finite-dimensional\ndistributions and the entire process, that the distance between a random fully\nconnected network (and its derivatives) to the corresponding infinite width\nGaussian process scales like $n^{-\\gamma}$ for $\\gamma>0$, with the exponent\ndepending on the metric used to measure discrepancy. Our bounds are strictly\nstronger in terms of their dependence on network width than any previously\navailable in the literature; in the one-dimensional case, we also prove that\nthey are optimal, i.e., we establish matching lower bounds.",
          "link": "http://arxiv.org/abs/2307.06092",
          "publishedOn": "2023-10-07T00:42:20.082Z",
          "wordCount": null,
          "title": "Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lanzendorfer_L/0/1/0/all/0/1\">Luca A. Lanzend&#xf6;rfer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grotschla_F/0/1/0/all/0/1\">Florian Gr&#xf6;tschla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funke_E/0/1/0/all/0/1\">Emil Funke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>",
          "description": "Music datasets play a crucial role in advancing research in machine learning\nfor music. However, existing music datasets suffer from limited size,\naccessibility, and lack of audio resources. To address these shortcomings, we\npresent DISCO-10M, a novel and extensive music dataset that surpasses the\nlargest previously available music dataset by an order of magnitude. To ensure\nhigh-quality data, we implement a multi-stage filtering process. This process\nincorporates similarities based on textual descriptions and audio embeddings.\nMoreover, we provide precomputed CLAP embeddings alongside DISCO-10M,\nfacilitating direct application on various downstream tasks. These embeddings\nenable efficient exploration of machine learning applications on the provided\ndata. With DISCO-10M, we aim to democratize and facilitate new research to help\nadvance the development of novel machine learning models for music.",
          "link": "http://arxiv.org/abs/2306.13512",
          "publishedOn": "2023-10-07T00:42:20.081Z",
          "wordCount": null,
          "title": "DISCO-10M: A Large-Scale Music Dataset. (arXiv:2306.13512v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.00436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miao_N/0/1/0/all/0/1\">Ning Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "The recent progress in large language models (LLMs), especially the invention\nof chain-of-thought prompting, has made it possible to automatically answer\nquestions by stepwise reasoning. However, when faced with more complicated\nproblems that require non-linear thinking, even the strongest LLMs make\nmistakes. To address this, we explore whether LLMs are able to recognize errors\nin their own step-by-step reasoning, without resorting to external resources.\nTo this end, we propose SelfCheck, a general-purpose zero-shot verification\nschema for recognizing such errors. We then use the results of these checks to\nimprove question-answering performance by conducting weighted voting on\nmultiple solutions to the question. We test SelfCheck on three datasets (GSM8K,\nMathQA, and MATH) and find that it successfully recognizes errors and, in turn,\nincreases final answer accuracies.",
          "link": "http://arxiv.org/abs/2308.00436",
          "publishedOn": "2023-10-07T00:42:20.079Z",
          "wordCount": null,
          "title": "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. (arXiv:2308.00436v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xidong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jianhui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhengmian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aidong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>",
          "description": "The minimax problems arise throughout machine learning applications, ranging\nfrom adversarial training and policy evaluation in reinforcement learning to\nAUROC maximization. To address the large-scale data challenges across multiple\nclients with communication-efficient distributed training, federated learning\n(FL) is gaining popularity. Many optimization algorithms for minimax problems\nhave been developed in the centralized setting (\\emph{i.e.} single-machine).\nNonetheless, the algorithm for minimax problems under FL is still\nunderexplored. In this paper, we study a class of federated nonconvex minimax\noptimization problems. We propose FL algorithms (FedSGDA+ and FedSGDA-M) and\nreduce existing complexity results for the most common minimax problems. For\nnonconvex-concave problems, we propose FedSGDA+ and reduce the communication\ncomplexity to $O(\\varepsilon^{-6})$. Under nonconvex-strongly-concave and\nnonconvex-PL minimax settings, we prove that FedSGDA-M has the best-known\nsample complexity of $O(\\kappa^{3} N^{-1}\\varepsilon^{-3})$ and the best-known\ncommunication complexity of $O(\\kappa^{2}\\varepsilon^{-2})$. FedSGDA-M is the\nfirst algorithm to match the best sample complexity $O(\\varepsilon^{-3})$\nachieved by the single-machine method under the nonconvex-strongly-concave\nsetting. Extensive experimental results on fair classification and AUROC\nmaximization show the efficiency of our algorithms.",
          "link": "http://arxiv.org/abs/2310.03613",
          "publishedOn": "2023-10-07T00:42:20.078Z",
          "wordCount": null,
          "title": "Solving a Class of Non-Convex Minimax Optimization in Federated Learning. (arXiv:2310.03613v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1\">Nicholas M. Boffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindsey_M/0/1/0/all/0/1\">Michael Lindsey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>",
          "description": "Given a set of $K$ probability densities, we consider the multimarginal\ngenerative modeling problem of learning a joint distribution that recovers\nthese densities as marginals. The structure of this joint distribution should\nidentify multi-way correspondences among the prescribed marginals. We formalize\nan approach to this task within a generalization of the stochastic interpolant\nframework, leading to efficient learning algorithms built upon dynamical\ntransport of measure. Our generative models are defined by velocity and score\nfields that can be characterized as the minimizers of simple quadratic\nobjectives, and they are defined on a simplex that generalizes the time\nvariable in the usual dynamical transport framework. The resulting transport on\nthe simplex is influenced by all marginals, and we show that multi-way\ncorrespondences can be extracted. The identification of such correspondences\nhas applications to style transfer, algorithmic fairness, and data\ndecorruption. In addition, the multimarginal perspective enables an efficient\nalgorithm for reducing the dynamical transport cost in the ordinary\ntwo-marginal setting. We demonstrate these capacities with several numerical\nexamples.",
          "link": "http://arxiv.org/abs/2310.03695",
          "publishedOn": "2023-10-07T00:42:20.077Z",
          "wordCount": null,
          "title": "Multimarginal generative modeling with stochastic interpolants. (arXiv:2310.03695v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Monteiro_R/0/1/0/all/0/1\">Rafael Monteiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sau_K/0/1/0/all/0/1\">Kartik Sau</a>",
          "description": "In this paper, we introduce a new heuristics for global optimization in\nscenarios where extensive evaluations of the cost function are expensive,\ninaccessible, or even prohibitive. The method, which we call\nLandscape-Sketch-and-Step (LSS), combines Machine Learning, Stochastic\nOptimization, and Reinforcement Learning techniques, relying on historical\ninformation from previously sampled points to make judicious choices of\nparameter values where the cost function should be evaluated at. Unlike\noptimization by Replica Exchange Monte Carlo methods, the number of evaluations\nof the cost function required in this approach is comparable to that used by\nSimulated Annealing, quality that is especially important in contexts like\nhigh-throughput computing or high-performance computing tasks, where\nevaluations are either computationally expensive or take a long time to be\nperformed. The method also differs from standard Surrogate Optimization\ntechniques, for it does not construct a surrogate model that aims at\napproximating or reconstructing the objective function. We illustrate our\nmethod by applying it to low dimensional optimization problems (dimensions 1,\n2, 4, and 8) that mimick known difficulties of minimization on rugged energy\nlandscapes often seen in Condensed Matter Physics, where cost functions are\nrugged and plagued with local minima. When compared to classical Simulated\nAnnealing, the LSS shows an effective acceleration of the optimization process.",
          "link": "http://arxiv.org/abs/2309.07936",
          "publishedOn": "2023-10-07T00:42:20.075Z",
          "wordCount": null,
          "title": "Landscape-Sketch-Step: An AI/ML-Based Metaheuristic for Surrogate Optimization Problems. (arXiv:2309.07936v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.09350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nentidis_A/0/1/0/all/0/1\">Anastasios Nentidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzopoulos_T/0/1/0/all/0/1\">Thomas Chatzopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krithara_A/0/1/0/all/0/1\">Anastasia Krithara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1\">Grigorios Tsoumakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paliouras_G/0/1/0/all/0/1\">Georgios Paliouras</a>",
          "description": "Objective: Semantic indexing of biomedical literature is usually done at the\nlevel of MeSH descriptors with several related but distinct biomedical concepts\noften grouped together and treated as a single topic. This study proposes a new\nmethod for the automated refinement of subject annotations at the level of MeSH\nconcepts. Methods: Lacking labelled data, we rely on weak supervision based on\nconcept occurrence in the abstract of an article, which is also enhanced by\ndictionary-based heuristics. In addition, we investigate deep learning\napproaches, making design choices to tackle the particular challenges of this\ntask. The new method is evaluated on a large-scale retrospective scenario,\nbased on concepts that have been promoted to descriptors. Results: In our\nexperiments concept occurrence was the strongest heuristic achieving a macro-F1\nscore of about 0.63 across several labels. The proposed method improved it\nfurther by more than 4pp. Conclusion: The results suggest that concept\noccurrence is a strong heuristic for refining the coarse-grained labels at the\nlevel of MeSH concepts and the proposed method improves it further.",
          "link": "http://arxiv.org/abs/2301.09350",
          "publishedOn": "2023-10-07T00:42:20.071Z",
          "wordCount": null,
          "title": "Large-scale investigation of weakly-supervised deep learning for the fine-grained semantic indexing of biomedical literature. (arXiv:2301.09350v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07056",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Jaouni_T/0/1/0/all/0/1\">Tareq Jaouni</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Arlt_S/0/1/0/all/0/1\">S&#xf6;ren Arlt</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ruiz_Gonzalez_C/0/1/0/all/0/1\">Carlos Ruiz-Gonzalez</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Karimi_E/0/1/0/all/0/1\">Ebrahim Karimi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gu_X/0/1/0/all/0/1\">Xuemei Gu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Krenn_M/0/1/0/all/0/1\">Mario Krenn</a>",
          "description": "Despite their promise to facilitate new scientific discoveries, the\nopaqueness of neural networks presents a challenge in interpreting the logic\nbehind their findings. Here, we use a eXplainable-AI (XAI) technique called\n$inception$ or $deep$ $dreaming$, which has been invented in machine learning\nfor computer vision. We use this technique to explore what neural networks\nlearn about quantum optics experiments. Our story begins by training deep\nneural networks on the properties of quantum systems. Once trained, we \"invert\"\nthe neural network -- effectively asking how it imagines a quantum system with\na specific property, and how it would continuously modify the quantum system to\nchange a property. We find that the network can shift the initial distribution\nof properties of the quantum system, and we can conceptualize the learned\nstrategies of the neural network. Interestingly, we find that, in the first\nlayers, the neural network identifies simple properties, while in the deeper\nones, it can identify complex quantum structures and even quantum entanglement.\nThis is in reminiscence of long-understood properties known in computer vision,\nwhich we now identify in a complex natural science task. Our approach could be\nuseful in a more interpretable way to develop new advanced AI-based scientific\ndiscovery techniques in quantum physics.",
          "link": "http://arxiv.org/abs/2309.07056",
          "publishedOn": "2023-10-07T00:42:20.070Z",
          "wordCount": null,
          "title": "Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into Quantum Experiments. (arXiv:2309.07056v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katdare_P/0/1/0/all/0/1\">Pulkit Katdare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1\">Katherine Driggs-Campbell</a>",
          "description": "Reinforcement Learning (RL) methods are typically sample-inefficient, making\nit challenging to train and deploy RL-policies in real world robots. Even a\nrobust policy trained in simulation requires a real-world deployment to assess\ntheir performance. This paper proposes a new approach to evaluate the\nreal-world performance of agent policies prior to deploying them in the real\nworld. Our approach incorporates a simulator along with real-world offline data\nto evaluate the performance of any policy using the framework of Marginalized\nImportance Sampling (MIS). Existing MIS methods face two challenges: (1) large\ndensity ratios that deviate from a reasonable range and (2) indirect\nsupervision, where the ratio needs to be inferred indirectly, thus exacerbating\nestimation error. Our approach addresses these challenges by introducing the\ntarget policy's occupancy in the simulator as an intermediate variable and\nlearning the density ratio as the product of two terms that can be learned\nseparately. The first term is learned with direct supervision and the second\nterm has a small magnitude, thus making it computationally efficient. We\nanalyze the sample complexity as well as error propagation of our two\nstep-procedure. Furthermore, we empirically evaluate our approach on Sim2Sim\nenvironments such as Cartpole, Reacher, and Half-Cheetah. Our results show that\nour method generalizes well across a variety of Sim2Sim gap, target policies\nand offline data collection policies. We also demonstrate the performance of\nour algorithm on a Sim2Real task of validating the performance of a 7 DoF\nrobotic arm using offline data along with the Gazebo simulator.",
          "link": "http://arxiv.org/abs/2309.01807",
          "publishedOn": "2023-10-07T00:42:20.069Z",
          "wordCount": null,
          "title": "Marginalized Importance Sampling for Off-Environment Policy Evaluation. (arXiv:2309.01807v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pengyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caprio_M/0/1/0/all/0/1\">Michele Caprio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>",
          "description": "Like generic multi-task learning, continual learning has the nature of\nmulti-objective optimization, and therefore faces a trade-off between the\nperformance of different tasks. That is, to optimize for the current task\ndistribution, it may need to compromise performance on some previous tasks.\nThis means that there exist multiple models that are Pareto-optimal at\ndifferent times, each addressing a distinct task performance trade-off.\nResearchers have discussed how to train particular models to address specific\ntrade-off preferences. However, existing algorithms require training overheads\nproportional to the number of preferences -- a large burden when there are\nmultiple, possibly infinitely many, preferences. As a response, we propose\nImprecise Bayesian Continual Learning (IBCL). Upon a new task, IBCL (1) updates\na knowledge base in the form of a convex hull of model parameter distributions\nand (2) obtains particular models to address task trade-off preferences with\nzero-shot. That is, IBCL does not require any additional training overhead to\ngenerate preference-addressing models from its knowledge base. We show that\nmodels obtained by IBCL have guarantees in identifying the Pareto optimal\nparameters. Moreover, experiments on standard image classification and NLP\ntasks support this guarantee. Statistically, IBCL improves average per-task\naccuracy by at most 23\\% and peak per-task accuracy by at most 15\\% with\nrespect to the baseline methods, with steadily near-zero or positive backward\ntransfer. Most importantly, IBCL significantly reduces the training overhead\nfrom training 1 model per preference to at most 3 models for all preferences.",
          "link": "http://arxiv.org/abs/2310.02995",
          "publishedOn": "2023-10-07T00:42:20.069Z",
          "wordCount": null,
          "title": "IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning. (arXiv:2310.02995v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.01425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bottou_L/0/1/0/all/0/1\">L&#xe9;on Bottou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Many believe that Large Language Models (LLMs) open the era of Artificial\nIntelligence (AI). Some see opportunities while others see dangers. Yet both\nproponents and opponents grasp AI through the imagery popularised by science\nfiction. Will the machine become sentient and rebel against its creators? Will\nwe experience a paperclip apocalypse? Before answering such questions, we\nshould first ask whether this mental imagery provides a good description of the\nphenomenon at hand. Understanding weather patterns through the moods of the\ngods only goes so far. The present paper instead advocates understanding LLMs\nand their connection to AI through the imagery of Jorge Luis Borges, a master\nof 20th century literature, forerunner of magical realism, and precursor to\npostmodern literature. This exercise leads to a new perspective that\nilluminates the relation between language modelling and artificial\nintelligence.",
          "link": "http://arxiv.org/abs/2310.01425",
          "publishedOn": "2023-10-07T00:42:20.067Z",
          "wordCount": null,
          "title": "Borges and AI. (arXiv:2310.01425v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tinghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Ping He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiachen T. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>",
          "description": "We present a novel defense, against backdoor attacks on Deep Neural Networks\n(DNNs), wherein adversaries covertly implant malicious behaviors (backdoors)\ninto DNNs. Our defense falls within the category of post-development defenses\nthat operate independently of how the model was generated. The proposed defense\nis built upon a novel reverse engineering approach that can directly extract\nbackdoor functionality of a given backdoored model to a backdoor expert model.\nThe approach is straightforward -- finetuning the backdoored model over a small\nset of intentionally mislabeled clean samples, such that it unlearns the normal\nfunctionality while still preserving the backdoor functionality, and thus\nresulting in a model (dubbed a backdoor expert model) that can only recognize\nbackdoor inputs. Based on the extracted backdoor expert model, we show the\nfeasibility of devising highly accurate backdoor input detectors that filter\nout the backdoor inputs during model inference. Further augmented by an\nensemble strategy with a finetuned auxiliary model, our defense, BaDExpert\n(Backdoor Input Detection with Backdoor Expert), effectively mitigates 17 SOTA\nbackdoor attacks while minimally impacting clean utility. The effectiveness of\nBaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet)\nacross various model architectures (ResNet, VGG, MobileNetV2 and Vision\nTransformer).",
          "link": "http://arxiv.org/abs/2308.12439",
          "publishedOn": "2023-10-07T00:42:20.063Z",
          "wordCount": null,
          "title": "BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection. (arXiv:2308.12439v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.00143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bassan_S/0/1/0/all/0/1\">Shahaf Bassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amir_G/0/1/0/all/0/1\">Guy Amir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corsi_D/0/1/0/all/0/1\">Davide Corsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Refaeli_I/0/1/0/all/0/1\">Idan Refaeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1\">Guy Katz</a>",
          "description": "Deep neural networks (DNNs) are increasingly being used as controllers in\nreactive systems. However, DNNs are highly opaque, which renders it difficult\nto explain and justify their actions. To mitigate this issue, there has been a\nsurge of interest in explainable AI (XAI) techniques, capable of pinpointing\nthe input features that caused the DNN to act as it did. Existing XAI\ntechniques typically face two limitations: (i) they are heuristic, and do not\nprovide formal guarantees that the explanations are correct; and (ii) they\noften apply to ``one-shot'' systems, where the DNN is invoked independently of\npast invocations, as opposed to reactive systems. Here, we begin bridging this\ngap, and propose a formal DNN-verification-based XAI technique for reasoning\nabout multi-step, reactive systems. We suggest methods for efficiently\ncalculating succinct explanations, by exploiting the system's transition\nconstraints in order to curtail the search space explored by the underlying\nverifier. We evaluate our approach on two popular benchmarks from the domain of\nautomated navigation; and observe that our methods allow the efficient\ncomputation of minimal and minimum explanations, significantly outperforming\nthe state of the art. We also demonstrate that our methods produce formal\nexplanations that are more reliable than competing, non-verification-based XAI\ntechniques.",
          "link": "http://arxiv.org/abs/2308.00143",
          "publishedOn": "2023-10-07T00:42:19.707Z",
          "wordCount": null,
          "title": "Formally Explaining Neural Networks within Reactive Systems. (arXiv:2308.00143v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chendi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manolache_A/0/1/0/all/0/1\">Andrei Manolache</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_K/0/1/0/all/0/1\">Kareem Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhe Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1\">Mathias Niepert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1\">Christopher Morris</a>",
          "description": "Message-passing graph neural networks (MPNNs) emerged as powerful tools for\nprocessing graph-structured input. However, they operate on a fixed input graph\nstructure, ignoring potential noise and missing information. Furthermore, their\nlocal aggregation mechanism can lead to problems such as over-squashing and\nlimited expressive power in capturing relevant graph structures. Existing\nsolutions to these challenges have primarily relied on heuristic methods, often\ndisregarding the underlying data distribution. Hence, devising principled\napproaches for learning to infer graph structures relevant to the given\nprediction task remains an open challenge. In this work, leveraging recent\nprogress in exact and differentiable $k$-subset sampling, we devise\nprobabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges\nwhile omitting less beneficial ones. For the first time, our theoretical\nanalysis explores how PR-MPNNs enhance expressive power, and we identify\nprecise conditions under which they outperform purely randomized approaches.\nEmpirically, we demonstrate that our approach effectively mitigates issues like\nover-squashing and under-reaching. In addition, on established real-world\ndatasets, our method exhibits competitive or superior predictive performance\ncompared to traditional MPNN models and recent graph transformer architectures.",
          "link": "http://arxiv.org/abs/2310.02156",
          "publishedOn": "2023-10-07T00:42:19.707Z",
          "wordCount": null,
          "title": "Probabilistically Rewired Message-Passing Neural Networks. (arXiv:2310.02156v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shikun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1\">Xiaobo Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiankang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shiming Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>",
          "description": "Learning from crowds describes that the annotations of training data are\nobtained with crowd-sourcing services. Multiple annotators each complete their\nown small part of the annotations, where labeling mistakes that depend on\nannotators occur frequently. Modeling the label-noise generation process by the\nnoise transition matrix is a power tool to tackle the label noise. In\nreal-world crowd-sourcing scenarios, noise transition matrices are both\nannotator- and instance-dependent. However, due to the high complexity of\nannotator- and instance-dependent transition matrices (AIDTM), annotation\nsparsity, which means each annotator only labels a little part of instances,\nmakes modeling AIDTM very challenging. Prior works simplify the problem by\nassuming the transition matrix is instance-independent or using simple\nparametric ways, which lose modeling generality. Motivated by this, we target a\nmore realistic problem, estimating general AIDTM in practice. Without losing\nmodeling generality, we parameterize AIDTM with deep neural networks. To\nalleviate the modeling challenge, we suppose every annotator shares its noise\npattern with similar annotators, and estimate AIDTM via knowledge transfer. We\nhence first model the mixture of noise patterns by all annotators, and then\ntransfer this modeling to individual annotators. Furthermore, considering that\nthe transfer from the mixture of noise patterns to individuals may cause two\nannotators with highly different noise generations to perturb each other, we\nemploy the knowledge transfer between identified neighboring annotators to\ncalibrate the modeling. Theoretical analyses are derived to demonstrate that\nboth the knowledge transfer from global to individuals and the knowledge\ntransfer between neighboring individuals can help model general AIDTM.\nExperiments confirm the superiority of the proposed approach on synthetic and\nreal-world crowd-sourcing data.",
          "link": "http://arxiv.org/abs/2306.03116",
          "publishedOn": "2023-10-07T00:42:19.694Z",
          "wordCount": null,
          "title": "Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds. (arXiv:2306.03116v2 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abusnaina_A/0/1/0/all/0/1\">Ahmed Abusnaina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sunpreet Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christodorescu_M/0/1/0/all/0/1\">Mihai Christodorescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohaisen_D/0/1/0/all/0/1\">David Mohaisen</a>",
          "description": "Toward robust malware detection, we explore the attack surface of existing\nmalware detection systems. We conduct root-cause analyses of the practical\nbinary-level black-box adversarial malware examples. Additionally, we uncover\nthe sensitivity of volatile features within the detection engines and exhibit\ntheir exploitability. Highlighting volatile information channels within the\nsoftware, we introduce three software pre-processing steps to eliminate the\nattack surface, namely, padding removal, software stripping, and inter-section\ninformation resetting. Further, to counter the emerging section injection\nattacks, we propose a graph-based section-dependent information extraction\nscheme for software representation. The proposed scheme leverages aggregated\ninformation within various sections in the software to enable robust malware\ndetection and mitigate adversarial settings. Our experimental results show that\ntraditional malware detection models are ineffective against adversarial\nthreats. However, the attack surface can be largely reduced by eliminating the\nvolatile information. Therefore, we propose simple-yet-effective methods to\nmitigate the impacts of binary manipulation attacks. Overall, our graph-based\nmalware detection scheme can accurately detect malware with an area under the\ncurve score of 88.32\\% and a score of 88.19% under a combination of binary\nmanipulation attacks, exhibiting the efficiency of our proposed scheme.",
          "link": "http://arxiv.org/abs/2310.03285",
          "publishedOn": "2023-10-07T00:42:19.689Z",
          "wordCount": null,
          "title": "Burning the Adversarial Bridges: Robust Windows Malware Detection Against Binary-level Mutations. (arXiv:2310.03285v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15294",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wong_H/0/1/0/all/0/1\">Hong Shen Wong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chan_W/0/1/0/all/0/1\">Wei Xuan Chan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_B/0/1/0/all/0/1\">Bing Huan Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yap_C/0/1/0/all/0/1\">Choon Hwai Yap</a>",
          "description": "Fluid dynamics computations for tube-like geometries are important for\nbiomedical evaluation of vascular and airway fluid dynamics. Physics-Informed\nNeural Networks (PINNs) have recently emerged as a good alternative to\ntraditional computational fluid dynamics (CFD) methods. The vanilla PINN,\nhowever, requires much longer training time than the traditional CFD methods\nfor each specific flow scenario and thus does not justify its mainstream use.\nHere, we explore the use of the multi-case PINN approach for calculating\nbiomedical tube flows, where varied geometry cases are parameterized and\npre-trained on the PINN, such that results for unseen geometries can be\nobtained in real time. Our objective is to identify network architecture,\ntube-specific, and regularization strategies that can optimize this, via\nexperiments on a series of idealized 2D stenotic tube flows.",
          "link": "http://arxiv.org/abs/2309.15294",
          "publishedOn": "2023-10-07T00:42:19.689Z",
          "wordCount": null,
          "title": "Multiple Case Physics-Informed Neural Network for Biomedical Tube Flows. (arXiv:2309.15294v2 [physics.flu-dyn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiangyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sibo Wang</a>",
          "description": "Graph-level anomaly detection has gained significant attention as it finds\nmany applications in various domains, such as cancer diagnosis and enzyme\nprediction. However, existing methods fail to capture the underlying properties\nof graph anomalies, resulting in unexplainable framework design and\nunsatisfying performance. In this paper, we take a step back and re-investigate\nthe spectral differences between anomalous and normal graphs. Our main\nobservation shows a significant disparity in the accumulated spectral energy\nbetween these two classes. Moreover, we prove that the accumulated spectral\nenergy of the graph signal can be represented by its Rayleigh Quotient,\nindicating that the Rayleigh Quotient is a driving factor behind the anomalous\nproperties of graphs. Motivated by this, we propose Rayleigh Quotient Graph\nNeural Network (RQGNN), the first spectral GNN for graph-level anomaly\ndetection, providing a new perspective on exploring the inherent spectral\nfeatures of anomalous graphs. Specifically, we introduce a novel framework that\nconsists of two components: the Rayleigh Quotient learning component (RQL) and\nChebyshev Wavelet GNN with RQ-pooling (CWGNN-RQ). RQL explicitly captures the\nRayleigh Quotient of graphs and CWGNN-RQ implicitly explores the spectral space\nof graphs. Extensive experiments on 10 real-world datasets show that RQGNN\noutperforms the best rival by 6.74% in Macro-F1 score and 1.44% in AUC,\ndemonstrating the effectiveness of our framework.",
          "link": "http://arxiv.org/abs/2310.02861",
          "publishedOn": "2023-10-07T00:42:19.689Z",
          "wordCount": null,
          "title": "Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection. (arXiv:2310.02861v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1\">Zhongkai Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiachen Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Chang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_F/0/1/0/all/0/1\">Fanzhi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1\">Zeyu Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Songming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Lu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "While significant progress has been made on Physics-Informed Neural Networks\n(PINNs), a comprehensive comparison of these methods across a wide range of\nPartial Differential Equations (PDEs) is still lacking. This study introduces\nPINNacle, a benchmarking tool designed to fill this gap. PINNacle provides a\ndiverse dataset, comprising over 20 distinct PDEs from various domains,\nincluding heat conduction, fluid dynamics, biology, and electromagnetics. These\nPDEs encapsulate key challenges inherent to real-world problems, such as\ncomplex geometry, multi-scale phenomena, nonlinearity, and high dimensionality.\nPINNacle also offers a user-friendly toolbox, incorporating about 10\nstate-of-the-art PINN methods for systematic evaluation and comparison. We have\nconducted extensive experiments with these methods, offering insights into\ntheir strengths and weaknesses. In addition to providing a standardized means\nof assessing performance, PINNacle also offers an in-depth analysis to guide\nfuture research, particularly in areas such as domain decomposition methods and\nloss reweighting for handling multi-scale problems and complex geometry. To the\nbest of our knowledge, it is the largest benchmark with a diverse and\ncomprehensive evaluation that will undoubtedly foster further research in\nPINNs.",
          "link": "http://arxiv.org/abs/2306.08827",
          "publishedOn": "2023-10-07T00:42:19.688Z",
          "wordCount": null,
          "title": "PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs. (arXiv:2306.08827v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Johor Jara Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1\">Matthew Guzdial</a>",
          "description": "Procedural Content Generation (PCG) and Procedural Content Generation via\nMachine Learning (PCGML) have been used in prior work for generating levels in\nvarious games. This paper introduces Content Augmentation and focuses on the\nsubproblem of level inpainting, which involves reconstructing and extending\nvideo game levels. Drawing inspiration from image inpainting, we adapt two\ntechniques from this domain to address our specific use case. We present two\napproaches for level inpainting: an Autoencoder and a U-net. Through a\ncomprehensive case study, we demonstrate their superior performance compared to\na baseline method and discuss their relative merits. Furthermore, we provide a\npractical demonstration of both approaches for the level inpainting task and\noffer insights into potential directions for future research.",
          "link": "http://arxiv.org/abs/2309.09472",
          "publishedOn": "2023-10-07T00:42:19.676Z",
          "wordCount": null,
          "title": "Reconstructing Existing Levels through Level Inpainting. (arXiv:2309.09472v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03597",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Zhengyu Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1\">Jiaoyang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M Stuart</a>",
          "description": "Sampling a target probability distribution with an unknown normalization\nconstant is a fundamental challenge in computational science and engineering.\nRecent work shows that algorithms derived by considering gradient flows in the\nspace of probability measures open up new avenues for algorithm development.\nThis paper makes three contributions to this sampling approach by scrutinizing\nthe design components of such gradient flows. Any instantiation of a gradient\nflow for sampling needs an energy functional and a metric to determine the\nflow, as well as numerical approximations of the flow to derive algorithms. Our\nfirst contribution is to show that the Kullback-Leibler divergence, as an\nenergy functional, has the unique property (among all f-divergences) that\ngradient flows resulting from it do not depend on the normalization constant of\nthe target distribution. Our second contribution is to study the choice of\nmetric from the perspective of invariance. The Fisher-Rao metric is known as\nthe unique choice (up to scaling) that is diffeomorphism invariant. As a\ncomputationally tractable alternative, we introduce a relaxed, affine\ninvariance property for the metrics and gradient flows. In particular, we\nconstruct various affine invariant Wasserstein and Stein gradient flows. Affine\ninvariant gradient flows are shown to behave more favorably than their\nnon-affine-invariant counterparts when sampling highly anisotropic\ndistributions, in theory and by using particle methods. Our third contribution\nis to study, and develop efficient algorithms based on Gaussian approximations\nof the gradient flows; this leads to an alternative to particle methods. We\nestablish connections between various Gaussian approximate gradient flows,\ndiscuss their relation to gradient methods arising from parametric variational\ninference, and study their convergence properties both theoretically and\nnumerically.",
          "link": "http://arxiv.org/abs/2310.03597",
          "publishedOn": "2023-10-07T00:42:19.675Z",
          "wordCount": null,
          "title": "Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mangold_L/0/1/0/all/0/1\">Lena Mangold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_C/0/1/0/all/0/1\">Camille Roth</a>",
          "description": "A myriad of approaches have been proposed to characterise the mesoscale\nstructure of networks - most often as a partition based on patterns variously\ncalled communities, blocks, or clusters. Clearly, distinct methods designed to\ndetect different types of patterns may provide a variety of answers to the\nnetwork's mesoscale structure. Yet, even multiple runs of a given method can\nsometimes yield diverse and conflicting results, producing entire landscapes of\npartitions which potentially include multiple (locally optimal) mesoscale\nexplanations of the network. Such ambiguity motivates a closer look at the\nability of these methods to find multiple qualitatively different 'ground\ntruth' partitions in a network. Here, we propose the stochastic cross-block\nmodel (SCBM), a generative model which allows for two distinct partitions to be\nbuilt into the mesoscale structure of a single benchmark network. We\ndemonstrate a use case of the benchmark model by appraising the power of\nstochastic block models (SBMs) to detect implicitly planted coexisting\nbi-community and core-periphery structures of different strengths. Given our\nmodel design and experimental set-up, we find that the ability to detect the\ntwo partitions individually varies by SBM variant and that coexistence of both\npartitions is recovered only in a very limited number of cases. Our findings\nsuggest that in most instances only one - in some way dominating - structure\ncan be detected, even in the presence of other partitions. They underline the\nneed for considering entire landscapes of partitions when different competing\nexplanations exist and motivate future research to advance partition\ncoexistence detection methods. Our model also contributes to the field of\nbenchmark networks more generally by enabling further exploration of the\nability of new and existing methods to detect ambiguity in the mesoscale\nstructure of networks.",
          "link": "http://arxiv.org/abs/2302.02787",
          "publishedOn": "2023-10-07T00:42:19.675Z",
          "wordCount": null,
          "title": "Generative models for two-ground-truth partitions in networks. (arXiv:2302.02787v3 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.00696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tekin_S/0/1/0/all/0/1\">Selim Furkan Tekin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazla_A/0/1/0/all/0/1\">Arda Fazla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozat_S/0/1/0/all/0/1\">Suleyman Serdar Kozat</a>",
          "description": "Numerical weather forecasting using high-resolution physical models often\nrequires extensive computational resources on supercomputers, which diminishes\ntheir wide usage in most real-life applications. As a remedy, applying deep\nlearning methods has revealed innovative solutions within this field. To this\nend, we introduce a novel deep learning architecture for forecasting\nhigh-resolution spatio-temporal weather data. Our approach extends the\nconventional encoder-decoder structure by integrating Convolutional Long-short\nTerm Memory and Convolutional Neural Networks. In addition, we incorporate\nattention and context matcher mechanisms into the model architecture. Our\nWeather Model achieves significant performance improvements compared to\nbaseline deep learning models, including ConvLSTM, TrajGRU, and U-Net. Our\nexperimental evaluation involves high-scale, real-world benchmark numerical\nweather datasets, namely the ERA5 hourly dataset on pressure levels and\nWeatherBench. Our results demonstrate substantial improvements in identifying\nspatial and temporal correlations with attention matrices focusing on distinct\nparts of the input series to model atmospheric circulations. We also compare\nour model with high-resolution physical models using the benchmark metrics and\nshow that our Weather Model is accurate and easy to interpret.",
          "link": "http://arxiv.org/abs/2102.00696",
          "publishedOn": "2023-10-07T00:42:19.674Z",
          "wordCount": null,
          "title": "Numerical Weather Forecasting using Convolutional-LSTM with Attention and Context Matcher Mechanisms. (arXiv:2102.00696v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.05250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Hao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaojun Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chunhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_W/0/1/0/all/0/1\">Weihua Gui</a>",
          "description": "Thank you very much for the attention and concern of colleagues and scholars\nin this work. With the comments and guidance of experts, editors, and\nreviewers, this work has been accepted for publishing in the journal \"Process\nSafety and Environmental Protection\". The theme of this paper relies on the\nSpatial-temporal associations of numerous variables in the same industrial\nprocesses, which refers to numerous variables obtained in dynamic industrial\nprocesses with Spatial-temporal correlation characteristics, i.e., these\nvariables are not only highly correlated in time but also interrelated in\nspace. To handle this problem, three key issues need to be well addressed:\nvariable characteristics modeling and representation, graph network\nconstruction (temporal information), and graph characteristics perception. The\nfirst issue is implemented by assuming the data follows one improved Gaussian\ndistribution, while the graph network can be defined by the monitoring\nvariables and their edges which are calculated by their characteristics in\ntime. Finally, these networks corresponding to process states at different\ntimes are fed into a graph convolutional neural network to implement graph\nclassification to achieve process monitoring. A benchmark experiment (Tennessee\nEastman chemical process) and one application study (cobalt purification from\nzinc solution) are employed to demonstrate the feasibility and applicability of\nthis paper.",
          "link": "http://arxiv.org/abs/2205.05250",
          "publishedOn": "2023-10-07T00:42:19.674Z",
          "wordCount": null,
          "title": "Spatial-temporal associations representation and application for process monitoring using graph convolution neural network. (arXiv:2205.05250v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.09874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hepburn_A/0/1/0/all/0/1\">Alexander Hepburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1\">Valero Laparra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Ra&#xfa;l Santos-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malo_J/0/1/0/all/0/1\">Jes&#xfa;s Malo</a>",
          "description": "In the 1950s, Barlow and Attneave hypothesised a link between biological\nvision and information maximisation. Following Shannon, information was defined\nusing the probability of natural images. A number of physiological and\npsychophysical phenomena have been derived ever since from principles like\ninfo-max, efficient coding, or optimal denoising. However, it remains unclear\nhow this link is expressed in mathematical terms from image probability. First,\nclassical derivations were subjected to strong assumptions on the probability\nmodels and on the behaviour of the sensors. Moreover, the direct evaluation of\nthe hypothesis was limited by the inability of the classical image models to\ndeliver accurate estimates of the probability. In this work we directly\nevaluate image probabilities using an advanced generative model for natural\nimages, and we analyse how probability-related factors can be combined to\npredict human perception via sensitivity of state-of-the-art subjective image\nquality metrics. We use information theory and regression analysis to find a\ncombination of just two probability-related factors that achieves 0.8\ncorrelation with subjective metrics. This probability-based sensitivity is\npsychophysically validated by reproducing the basic trends of the Contrast\nSensitivity Function, its suprathreshold variation, and trends of the Weber-law\nand masking.",
          "link": "http://arxiv.org/abs/2303.09874",
          "publishedOn": "2023-10-07T00:42:19.674Z",
          "wordCount": null,
          "title": "Disentangling the Link Between Image Statistics and Human Perception. (arXiv:2303.09874v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tal_O/0/1/0/all/0/1\">Ofir Bar Tal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haviv_A/0/1/0/all/0/1\">Adi Haviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1\">Amit H. Bermano</a>",
          "description": "Evasion Attacks (EA) are used to test the robustness of trained neural\nnetworks by distorting input data to misguide the model into incorrect\nclassifications. Creating these attacks is a challenging task, especially with\nthe ever-increasing complexity of models and datasets. In this work, we\nintroduce a self-supervised, computationally economical method for generating\nadversarial examples, designed for the unseen black-box setting. Adapting\ntechniques from representation learning, our method generates on-manifold EAs\nthat are encouraged to resemble the data distribution. These attacks are\ncomparable in effectiveness compared to the state-of-the-art when attacking the\nmodel trained on, but are significantly more effective when attacking unseen\nmodels, as the attacks are more related to the data rather than the model\nitself. Our experiments consistently demonstrate the method is effective across\nvarious models, unseen data categories, and even defended models, suggesting a\nsignificant role for on-manifold EAs when targeting unseen models.",
          "link": "http://arxiv.org/abs/2310.03707",
          "publishedOn": "2023-10-07T00:42:19.671Z",
          "wordCount": null,
          "title": "OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks. (arXiv:2310.03707v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.17348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farinha_M/0/1/0/all/0/1\">Matilde Tristany Farinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortner_T/0/1/0/all/0/1\">Thomas Ortner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dellaferrera_G/0/1/0/all/0/1\">Giorgia Dellaferrera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1\">Benjamin Grewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pantazi_A/0/1/0/all/0/1\">Angeliki Pantazi</a>",
          "description": "Artificial Neural Networks (ANNs) trained with Backpropagation (BP) show\nastounding performance and are increasingly often used in performing our daily\nlife tasks. However, ANNs are highly vulnerable to adversarial attacks, which\nalter inputs with small targeted perturbations that drastically disrupt the\nmodels' performance. The most effective method to make ANNs robust against\nthese attacks is adversarial training, in which the training dataset is\naugmented with exemplary adversarial samples. Unfortunately, this approach has\nthe drawback of increased training complexity since generating adversarial\nsamples is very computationally demanding. In contrast to ANNs, humans are not\nsusceptible to adversarial attacks. Therefore, in this work, we investigate\nwhether biologically-plausible learning algorithms are more robust against\nadversarial attacks than BP. In particular, we present an extensive comparative\nanalysis of the adversarial robustness of BP and Present the Error to Perturb\nthe Input To modulate Activity (PEPITA), a recently proposed\nbiologically-plausible learning algorithm, on various computer vision tasks. We\nobserve that PEPITA has higher intrinsic adversarial robustness and, with\nadversarial training, has a more favourable natural-vs-adversarial performance\ntrade-off as, for the same natural accuracies, PEPITA's adversarial accuracies\ndecrease in average by 0.26% and BP's by 8.05%.",
          "link": "http://arxiv.org/abs/2309.17348",
          "publishedOn": "2023-10-07T00:42:19.669Z",
          "wordCount": null,
          "title": "Efficient Biologically Plausible Adversarial Training. (arXiv:2309.17348v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.00035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1\">Maja Rudolph</a>",
          "description": "Finetuned LLMs often exhibit poor uncertainty quantification, manifesting as\noverconfidence, poor calibration, and unreliable prediction results on test\ndata or out-of-distribution samples. One approach commonly used in vision for\nalleviating this issue is a deep ensemble, which constructs an ensemble by\ntraining the same model multiple times using different random initializations.\nHowever, there is a huge challenge to ensembling LLMs: the most effective LLMs\nare very, very large. Keeping a single LLM in memory is already challenging\nenough: keeping an ensemble of e.g. 5 LLMs in memory is impossible in many\nsettings. To address these issues, we propose an ensemble approach using\nLow-Rank Adapters (LoRA), a parameter-efficient fine-tuning technique.\nCritically, these low-rank adapters represent a very small number of\nparameters, orders of magnitude less than the underlying pre-trained model.\nThus, it is possible to construct large ensembles of LoRA adapters with almost\nthe same computational overhead as using the original model. We find that LoRA\nensembles, applied on its own or on top of pre-existing regularization\ntechniques, gives consistent improvements in predictive accuracy and\nuncertainty quantification.",
          "link": "http://arxiv.org/abs/2310.00035",
          "publishedOn": "2023-10-07T00:42:19.669Z",
          "wordCount": null,
          "title": "LoRA ensembles for large language model fine-tuning. (arXiv:2310.00035v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15871",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daolang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bharti_A/0/1/0/all/0/1\">Ayush Bharti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Souza_A/0/1/0/all/0/1\">Amauri Souza</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acerbi_L/0/1/0/all/0/1\">Luigi Acerbi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "Simulation-based inference (SBI) methods such as approximate Bayesian\ncomputation (ABC), synthetic likelihood, and neural posterior estimation (NPE)\nrely on simulating statistics to infer parameters of intractable likelihood\nmodels. However, such methods are known to yield untrustworthy and misleading\ninference outcomes under model misspecification, thus hindering their\nwidespread applicability. In this work, we propose the first general approach\nto handle model misspecification that works across different classes of SBI\nmethods. Leveraging the fact that the choice of statistics determines the\ndegree of misspecification in SBI, we introduce a regularized loss function\nthat penalises those statistics that increase the mismatch between the data and\nthe model. Taking NPE and ABC as use cases, we demonstrate the superior\nperformance of our method on high-dimensional time-series models that are\nartificially misspecified. We also apply our method to real data from the field\nof radio propagation where the model is known to be misspecified. We show\nempirically that the method yields robust inference in misspecified scenarios,\nwhilst still being accurate when the model is well-specified.",
          "link": "http://arxiv.org/abs/2305.15871",
          "publishedOn": "2023-10-07T00:42:19.659Z",
          "wordCount": null,
          "title": "Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03575",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cui_H/0/1/0/all/0/1\">Hugo Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krzakala_F/0/1/0/all/0/1\">Florent Krzakala</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "We study the problem of training a flow-based generative model, parametrized\nby a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture.\nWe provide a sharp end-to-end analysis of the problem. First, we provide a\ntight closed-form characterization of the learnt velocity field, when\nparametrized by a shallow denoising auto-encoder trained on a finite number $n$\nof samples from the target distribution. Building on this analysis, we provide\na sharp description of the corresponding generative flow, which pushes the base\nGaussian density forward to an approximation of the target density. In\nparticular, we provide closed-form formulae for the distance between the mean\nof the generated mixture and the mean of the target mixture, which we show\ndecays as $\\Theta_n(\\frac{1}{n})$. Finally, this rate is shown to be in fact\nBayes-optimal.",
          "link": "http://arxiv.org/abs/2310.03575",
          "publishedOn": "2023-10-07T00:42:19.653Z",
          "wordCount": null,
          "title": "Analysis of learning a flow-based generative model from limited sample complexity. (arXiv:2310.03575v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.05603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1\">Shiye Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Deep learning technology has developed unprecedentedly in the last decade and\nhas become the primary choice in many application domains. This progress is\nmainly attributed to a systematic collaboration in which rapidly growing\ncomputing resources encourage advanced algorithms to deal with massive data.\nHowever, it has gradually become challenging to handle the unlimited growth of\ndata with limited computing power. To this end, diverse approaches are proposed\nto improve data processing efficiency. Dataset distillation, a dataset\nreduction method, addresses this problem by synthesizing a small typical\ndataset from substantial data and has attracted much attention from the deep\nlearning community. Existing dataset distillation methods can be taxonomized\ninto meta-learning and data matching frameworks according to whether they\nexplicitly mimic the performance of target data. Although dataset distillation\nhas shown surprising performance in compressing datasets, there are still\nseveral limitations such as distilling high-resolution data or data with\ncomplex label spaces. This paper provides a holistic understanding of dataset\ndistillation from multiple aspects, including distillation frameworks and\nalgorithms, factorized dataset distillation, performance comparison, and\napplications. Finally, we discuss challenges and promising directions to\nfurther promote future studies on dataset distillation.",
          "link": "http://arxiv.org/abs/2301.05603",
          "publishedOn": "2023-10-07T00:42:19.646Z",
          "wordCount": null,
          "title": "A Comprehensive Survey of Dataset Distillation. (arXiv:2301.05603v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Maliki_S/0/1/0/all/0/1\">Shawqi Al-Maliki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qayyum_A/0/1/0/all/0/1\">Adnan Qayyum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1\">Hassan Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdallah_M/0/1/0/all/0/1\">Mohamed Abdallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qadir_J/0/1/0/all/0/1\">Junaid Qadir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Dinh Thai Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1\">Dusit Niyato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Fuqaha_A/0/1/0/all/0/1\">Ala Al-Fuqaha</a>",
          "description": "Deep Neural Networks (DNNs) have been the driving force behind many of the\nrecent advances in machine learning. However, research has shown that DNNs are\nvulnerable to adversarial examples -- input samples that have been perturbed to\nforce DNN-based models to make errors. As a result, Adversarial Machine\nLearning (AdvML) has gained a lot of attention, and researchers have\ninvestigated these vulnerabilities in various settings and modalities. In\naddition, DNNs have also been found to incorporate embedded bias and often\nproduce unexplainable predictions, which can result in anti-social AI\napplications. The emergence of new AI technologies that leverage Large Language\nModels (LLMs), such as ChatGPT and GPT-4, increases the risk of producing\nanti-social applications at scale. AdvML for Social Good (AdvML4G) is an\nemerging field that repurposes the AdvML bug to invent pro-social applications.\nRegulators, practitioners, and researchers should collaborate to encourage the\ndevelopment of pro-social applications and hinder the development of\nanti-social ones. In this work, we provide the first comprehensive review of\nthe emerging field of AdvML4G. This paper encompasses a taxonomy that\nhighlights the emergence of AdvML4G, a discussion of the differences and\nsimilarities between AdvML4G and AdvML, a taxonomy covering social good-related\nconcepts and aspects, an exploration of the motivations behind the emergence of\nAdvML4G at the intersection of ML4G and AdvML, and an extensive summary of the\nworks that utilize AdvML4G as an auxiliary tool for innovating pro-social\napplications. Finally, we elaborate upon various challenges and open research\nissues that require significant attention from the research community.",
          "link": "http://arxiv.org/abs/2310.03614",
          "publishedOn": "2023-10-07T00:42:19.645Z",
          "wordCount": null,
          "title": "Adversarial Machine Learning for Social Good: Reframing the Adversary as an Ally. (arXiv:2310.03614v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.12266",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Defossez_A/0/1/0/all/0/1\">Alexandre D&#xe9;fossez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Caucheteux_C/0/1/0/all/0/1\">Charlotte Caucheteux</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rapin_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my Rapin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kabeli_O/0/1/0/all/0/1\">Ori Kabeli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+King_J/0/1/0/all/0/1\">Jean-R&#xe9;mi King</a>",
          "description": "Decoding speech from brain activity is a long-awaited goal in both healthcare\nand neuroscience. Invasive devices have recently led to major milestones in\nthat regard: deep learning algorithms trained on intracranial recordings now\nstart to decode elementary linguistic features (e.g. letters, words,\nspectrograms). However, extending this approach to natural speech and\nnon-invasive brain recordings remains a major challenge. Here, we introduce a\nmodel trained with contrastive-learning to decode self-supervised\nrepresentations of perceived speech from the non-invasive recordings of a large\ncohort of healthy individuals. To evaluate this approach, we curate and\nintegrate four public datasets, encompassing 175 volunteers recorded with\nmagneto- or electro-encephalography (M/EEG), while they listened to short\nstories and isolated sentences. The results show that our model can identify,\nfrom 3 seconds of MEG signals, the corresponding speech segment with up to 41%\naccuracy out of more than 1,000 distinct possibilities on average across\nparticipants, and more than 80% in the very best participants - a performance\nthat allows the decoding of words and phrases absent from the training set. The\ncomparison of our model to a variety of baselines highlights the importance of\n(i) a contrastive objective, (ii) pretrained representations of speech and\n(iii) a common convolutional architecture simultaneously trained across\nmultiple participants. Finally, the analysis of the decoder's predictions\nsuggests that they primarily depend on lexical and contextual semantic\nrepresentations. Overall, this effective decoding of perceived speech from\nnon-invasive recordings delineates a promising path to decode language from\nbrain activity, without putting patients at risk for brain surgery.",
          "link": "http://arxiv.org/abs/2208.12266",
          "publishedOn": "2023-10-07T00:42:19.516Z",
          "wordCount": null,
          "title": "Decoding speech perception from non-invasive brain recordings. (arXiv:2208.12266v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.06074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghazi_B/0/1/0/all/0/1\">Badih Ghazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1\">Pritish Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Ravi Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leeman_E/0/1/0/all/0/1\">Ethan Leeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1\">Pasin Manurangsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varadarajan_A/0/1/0/all/0/1\">Avinash V Varadarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chiyuan Zhang</a>",
          "description": "We study the task of training regression models with the guarantee of label\ndifferential privacy (DP). Based on a global prior distribution on label\nvalues, which could be obtained privately, we derive a label DP randomization\nmechanism that is optimal under a given regression loss function. We prove that\nthe optimal mechanism takes the form of a \"randomized response on bins\", and\npropose an efficient algorithm for finding the optimal bin values. We carry out\na thorough experimental evaluation on several datasets demonstrating the\nefficacy of our algorithm.",
          "link": "http://arxiv.org/abs/2212.06074",
          "publishedOn": "2023-10-07T00:42:19.472Z",
          "wordCount": null,
          "title": "Regression with Label Differential Privacy. (arXiv:2212.06074v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.15497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yixin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>",
          "description": "We present Deep Region Competition (DRC), an algorithm designed to extract\nforeground objects from images in a fully unsupervised manner. Foreground\nextraction can be viewed as a special case of generic image segmentation that\nfocuses on identifying and disentangling objects from the background. In this\nwork, we rethink the foreground extraction by reconciling energy-based prior\nwith generative image modeling in the form of Mixture of Experts (MoE), where\nwe further introduce the learned pixel re-assignment as the essential inductive\nbias to capture the regularities of background regions. With this modeling, the\nforeground-background partition can be naturally found through\nExpectation-Maximization (EM). We show that the proposed method effectively\nexploits the interaction between the mixture components during the partitioning\nprocess, which closely connects to region competition, a seminal approach for\ngeneric image segmentation. Experiments demonstrate that DRC exhibits more\ncompetitive performances on complex real-world data and challenging\nmulti-object scenes compared with prior methods. Moreover, we show empirically\nthat DRC can potentially generalize to novel foreground objects even from\ncategories unseen during training.",
          "link": "http://arxiv.org/abs/2110.15497",
          "publishedOn": "2023-10-07T00:42:19.395Z",
          "wordCount": null,
          "title": "Unsupervised Foreground Extraction via Deep Region Competition. (arXiv:2110.15497v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.01150",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bernardoni_W/0/1/0/all/0/1\">William Bernardoni</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cardona_R/0/1/0/all/0/1\">Robert Cardona</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cleveland_J/0/1/0/all/0/1\">Jacob Cleveland</a>, <a href=\"http://arxiv.org/find/math/1/au:+Curry_J/0/1/0/all/0/1\">Justin Curry</a>, <a href=\"http://arxiv.org/find/math/1/au:+Green_R/0/1/0/all/0/1\">Robert Green</a>, <a href=\"http://arxiv.org/find/math/1/au:+Heller_B/0/1/0/all/0/1\">Brian Heller</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hylton_A/0/1/0/all/0/1\">Alan Hylton</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lam_T/0/1/0/all/0/1\">Tung Lam</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kassouf_Short_R/0/1/0/all/0/1\">Robert Kassouf-Short</a>",
          "description": "In this paper we introduce some new algebraic and geometric perspectives on\nnetworked space communications. Our main contribution is a novel definition of\na time-varying graph (TVG), defined in terms of a matrix with values in subsets\nof the real line P(R). We leverage semi-ring properties of P(R) to model\nmulti-hop communication in a TVG using matrix multiplication and a truncated\nKleene star. This leads to novel statistics on the communication capacity of\nTVGs called lifetime curves, which we generate for large samples of randomly\nchosen STARLINK satellites, whose connectivity is modeled over day-long\nsimulations. Determining when a large subsample of STARLINK is temporally\nstrongly connected is further analyzed using novel metrics introduced here that\nare inspired by topological data analysis (TDA). To better model networking\nscenarios between the Earth and Mars, we introduce various semi-rings capable\nof modeling propagation delay as well as protocols common to Delay Tolerant\nNetworking (DTN), such as store-and-forward. Finally, we illustrate the\napplicability of zigzag persistence for featurizing different space networks\nand demonstrate the efficacy of K-Nearest Neighbors (KNN) classification for\ndistinguishing Earth-Mars and Earth-Moon satellite systems using time-varying\ntopology alone.",
          "link": "http://arxiv.org/abs/2304.01150",
          "publishedOn": "2023-10-07T00:42:19.394Z",
          "wordCount": null,
          "title": "Algebraic and Geometric Models for Space Networking. (arXiv:2304.01150v2 [math.AT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.02062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Calderon_P/0/1/0/all/0/1\">Pio Calderon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soen_A/0/1/0/all/0/1\">Alexander Soen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>",
          "description": "The multivariate Hawkes process (MHP) is widely used for analyzing data\nstreams that interact with each other, where events generate new events within\ntheir own dimension (via self-excitation) or across different dimensions (via\ncross-excitation). However, in certain applications, the timestamps of\nindividual events in some dimensions are unobservable, and only event counts\nwithin intervals are known, referred to as partially interval-censored data.\nThe MHP is unsuitable for handling such data since its estimation requires\nevent timestamps. In this study, we introduce the Partial Mean Behavior Poisson\n(PMBP) process, a novel point process which shares parameter equivalence with\nthe MHP and can effectively model both timestamped and interval-censored data.\nWe demonstrate the capabilities of the PMBP process using synthetic and\nreal-world datasets. Firstly, we illustrate that the PMBP process can\napproximate MHP parameters and recover the spectral radius using synthetic\nevent histories. Next, we assess the performance of the PMBP process in\npredicting YouTube popularity and find that it surpasses state-of-the-art\nmethods. Lastly, we leverage the PMBP process to gain qualitative insights from\na dataset comprising daily COVID-19 case counts from multiple countries and\nCOVID-19-related news articles. By clustering the PMBP-modeled countries, we\nunveil hidden interaction patterns between occurrences of COVID-19 cases and\nnews reporting.",
          "link": "http://arxiv.org/abs/2111.02062",
          "publishedOn": "2023-10-07T00:42:19.381Z",
          "wordCount": null,
          "title": "Linking Across Data Granularity: Fitting Multivariate Hawkes Processes to Partially Interval-Censored Data. (arXiv:2111.02062v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Beomsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1\">Gihyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kwanyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Diffusion models are a powerful class of generative models which simulate\nstochastic differential equations (SDEs) to generate data from noise. Although\ndiffusion models have achieved remarkable progress in recent years, they have\nlimitations in the unpaired image-to-image translation tasks due to the\nGaussian prior assumption. Schr\\\"odinger Bridge (SB), which learns an SDE to\ntranslate between two arbitrary distributions, have risen as an attractive\nsolution to this problem. However, none of SB models so far have been\nsuccessful at unpaired translation between high-resolution images. In this\nwork, we propose the Unpaired Neural Schr\\\"odinger Bridge (UNSB), which\nexpresses SB problem as a sequence of adversarial learning problems. This\nallows us to incorporate advanced discriminators and regularization to learn a\nSB between unpaired data. We demonstrate that UNSB is scalable and successfully\nsolves various unpaired image-to-image translation tasks. Code:\n\\url{https://github.com/cyclomon/UNSB}",
          "link": "http://arxiv.org/abs/2305.15086",
          "publishedOn": "2023-10-07T00:42:19.379Z",
          "wordCount": null,
          "title": "Unpaired Image-to-Image Translation via Neural Schr\\\"odinger Bridge. (arXiv:2305.15086v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sukrita Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarna_N/0/1/0/all/0/1\">Neeraj Sarna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orfanoudaki_A/0/1/0/all/0/1\">Agni Orfanoudaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1\">Michael Berger</a>",
          "description": "Machine learning algorithms have grown in sophistication over the years and\nare increasingly deployed for real-life applications. However, when using\nmachine learning techniques in practical settings, particularly in high-risk\napplications such as medicine and engineering, obtaining the failure\nprobability of the predictive model is critical. We refer to this problem as\nthe risk-assessment task. We focus on regression algorithms and the\nrisk-assessment task of computing the probability of the true label lying\ninside an interval defined around the model's prediction. We solve the\nrisk-assessment problem using the conformal prediction approach, which provides\nprediction intervals that are guaranteed to contain the true label with a given\nprobability. Using this coverage property, we prove that our approximated\nfailure probability is conservative in the sense that it is not lower than the\ntrue failure probability of the ML algorithm. We conduct extensive experiments\nto empirically study the accuracy of the proposed method for problems with and\nwithout covariate shift. Our analysis focuses on different modeling regimes,\ndataset sizes, and conformal prediction methodologies.",
          "link": "http://arxiv.org/abs/2310.03545",
          "publishedOn": "2023-10-07T00:42:19.378Z",
          "wordCount": null,
          "title": "Distribution-free risk assessment of regression-based machine learning algorithms. (arXiv:2310.03545v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.01422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fakoor_R/0/1/0/all/0/1\">Rasool Fakoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1\">Jonas Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1\">Pratik Chaudhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1\">Alexander J. Smola</a>",
          "description": "Real-world deployment of machine learning models is challenging because data\nevolves over time. While no model can work when data evolves in an arbitrary\nfashion, if there is some pattern to these changes, we might be able to design\nmethods to address it. This paper addresses situations when data evolves\ngradually. We introduce a time-varying propensity score that can detect gradual\nshifts in the distribution of data which allows us to selectively sample past\ndata to update the model -- not just similar data from the past like that of a\nstandard propensity score but also data that evolved in a similar fashion in\nthe past. The time-varying propensity score is quite general: we demonstrate\ndifferent ways of implementing it and evaluate it on a variety of problems\nranging from supervised learning (e.g., image classification problems) where\ndata undergoes a sequence of gradual shifts, to reinforcement learning tasks\n(e.g., robotic manipulation and continuous control) where data shifts as the\npolicy or the task changes.",
          "link": "http://arxiv.org/abs/2210.01422",
          "publishedOn": "2023-10-07T00:42:19.376Z",
          "wordCount": null,
          "title": "Time-Varying Propensity Score to Bridge the Gap between the Past and Present. (arXiv:2210.01422v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05120",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wei Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty\nquantification and mean predictions with distributed clients. In particular, we\ngeneralize beyond normal posterior distributions and consider a general class\nof models. We develop theoretical guarantees for FA-LD for strongly log-concave\ndistributions with non-i.i.d data and study how the injected noise and the\nstochastic-gradient noise, the heterogeneity of data, and the varying learning\nrates affect the convergence. Such an analysis sheds light on the optimal\nchoice of local updates to minimize communication costs. Important to our\napproach is that the communication efficiency does not deteriorate with the\ninjected noise in the Langevin algorithms. In addition, we examine in our FA-LD\nalgorithm both independent and correlated noise used over different clients. We\nobserve there is a trade-off between the pairs among communication, accuracy,\nand data privacy. As local devices may become inactive in federated networks,\nwe also show convergence results based on different averaging schemes where\nonly partial device updates are available. In such a case, we discover an\nadditional bias that does not decay to zero.",
          "link": "http://arxiv.org/abs/2112.05120",
          "publishedOn": "2023-10-07T00:42:19.315Z",
          "wordCount": null,
          "title": "On Convergence of Federated Averaging Langevin Dynamics. (arXiv:2112.05120v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunha_W/0/1/0/all/0/1\">Washington Cunha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franca_C/0/1/0/all/0/1\">Celso Fran&#xe7;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocha_L/0/1/0/all/0/1\">Leonardo Rocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goncalves_M/0/1/0/all/0/1\">Marcos Andr&#xe9; Gon&#xe7;alves</a>",
          "description": "There is a niche of companies responsible for intermediating the purchase of\nlarge batches of varied products for other companies, for which the main\nchallenge is to perform product description standardization, i.e., matching an\nitem described by a client with a product described in a catalog. The problem\nis complex since the client's product description may be: (1) potentially\nnoisy; (2) short and uninformative (e.g., missing information about model and\nsize); and (3) cross-language. In this paper, we formalize this problem as a\nranking task: given an initial client product specification (query), return the\nmost appropriate standardized descriptions (response). In this paper, we\npropose TPDR, a two-step Transformer-based Product and Class Description\nRetrieval method that is able to explore the semantic correspondence between IS\nand SD, by exploiting attention mechanisms and contrastive learning. First,\nTPDR employs the transformers as two encoders sharing the embedding vector\nspace: one for encoding the IS and another for the SD, in which corresponding\npairs (IS, SD) must be close in the vector space. Closeness is further enforced\nby a contrastive learning mechanism leveraging a specialized loss function.\nTPDR also exploits a (second) re-ranking step based on syntactic features that\nare very important for the exact matching (model, dimension) of certain\nproducts that may have been neglected by the transformers. To evaluate our\nproposal, we consider 11 datasets from a real company, covering different\napplication contexts. Our solution was able to retrieve the correct\nstandardized product before the 5th ranking position in 71% of the cases and\nits correct category in the first position in 80% of the situations. Moreover,\nthe effectiveness gains over purely syntactic or semantic baselines reach up to\n3.7 times, solving cases that none of the approaches in isolation can do by\nthemselves.",
          "link": "http://arxiv.org/abs/2310.03491",
          "publishedOn": "2023-10-07T00:42:19.312Z",
          "wordCount": null,
          "title": "TPDR: A Novel Two-Step Transformer-based Product and Class Description Match and Retrieval Method. (arXiv:2310.03491v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03546",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Renaud_M/0/1/0/all/0/1\">Marien Renaud</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jiaming Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin de Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almansa_A/0/1/0/all/0/1\">Andr&#xe9;s Almansa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kamilov_U/0/1/0/all/0/1\">Ulugbek S. Kamilov</a>",
          "description": "Posterior sampling has been shown to be a powerful Bayesian approach for\nsolving imaging inverse problems. The recent plug-and-play unadjusted Langevin\nalgorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling\nand minimum mean squared error (MMSE) estimation by combining physical\nmeasurement models with deep-learning priors specified using image denoisers.\nHowever, the intricate relationship between the sampling distribution of\nPnP-ULA and the mismatched data-fidelity and denoiser has not been\ntheoretically analyzed. We address this gap by proposing a posterior-L2\npseudometric and using it to quantify an explicit error bound for PnP-ULA under\nmismatched posterior distribution. We numerically validate our theory on\nseveral inverse problems such as sampling from Gaussian mixture models and\nimage deblurring. Our results suggest that the sensitivity of the sampling\ndistribution of PnP-ULA to a mismatch in the measurement model and the denoiser\ncan be precisely characterized.",
          "link": "http://arxiv.org/abs/2310.03546",
          "publishedOn": "2023-10-07T00:42:19.311Z",
          "wordCount": null,
          "title": "Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Ling Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Moksh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madan_K/0/1/0/all/0/1\">Kanika Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Generative Flow Networks (GFlowNets) are amortized samplers that learn\nstochastic policies to sequentially generate compositional objects from a given\nunnormalized reward distribution. They can generate diverse sets of high-reward\nobjects, which is an important consideration in scientific discovery tasks.\nHowever, as they are typically trained from a given extrinsic reward function,\nit remains an important open challenge about how to leverage the power of\npre-training and train GFlowNets in an unsupervised fashion for efficient\nadaptation to downstream tasks. Inspired by recent successes of unsupervised\npre-training in various domains, we introduce a novel approach for reward-free\npre-training of GFlowNets. By framing the training as a self-supervised\nproblem, we propose an outcome-conditioned GFlowNet (OC-GFN) that learns to\nexplore the candidate space. Specifically, OC-GFN learns to reach any targeted\noutcomes, akin to goal-conditioned policies in reinforcement learning. We show\nthat the pre-trained OC-GFN model can allow for a direct extraction of a policy\ncapable of sampling from any new reward functions in downstream tasks.\nNonetheless, adapting OC-GFN on a downstream task-specific reward involves an\nintractable marginalization over possible outcomes. We propose a novel way to\napproximate this marginalization by learning an amortized predictor enabling\nefficient fine-tuning. Extensive experimental results validate the efficacy of\nour approach, demonstrating the effectiveness of pre-training the OC-GFN, and\nits ability to swiftly adapt to downstream tasks and discover modes more\nefficiently. This work may serve as a foundation for further exploration of\npre-training strategies in the context of GFlowNets.",
          "link": "http://arxiv.org/abs/2310.03419",
          "publishedOn": "2023-10-07T00:42:19.310Z",
          "wordCount": null,
          "title": "Pre-Training and Fine-Tuning Generative Flow Networks. (arXiv:2310.03419v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.14655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ji Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_T/0/1/0/all/0/1\">Teng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1\">Kunyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yifan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1\">Xinyu Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaozhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Weidong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu Xu</a>",
          "description": "Despite the recent emergence of video captioning models, how to generate\nvivid, fine-grained video descriptions based on the background knowledge (i.e.,\nlong and informative commentary about the domain-specific scenes with\nappropriate reasoning) is still far from being solved, which however has great\napplications such as automatic sports narrative. In this paper, we present\nGOAL, a benchmark of over 8.9k soccer video clips, 22k sentences, and 42k\nknowledge triples for proposing a challenging new task setting as\nKnowledge-grounded Video Captioning (KGVC). Moreover, we conduct experimental\nadaption of existing methods to show the difficulty and potential directions\nfor solving this valuable and applicable task. Our data and code are available\nat https://github.com/THU-KEG/goal.",
          "link": "http://arxiv.org/abs/2303.14655",
          "publishedOn": "2023-10-07T00:42:19.310Z",
          "wordCount": null,
          "title": "GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Generation. (arXiv:2303.14655v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Younesian_T/0/1/0/all/0/1\">Taraneh Younesian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thanapalasingam_T/0/1/0/all/0/1\">Thiviyan Thanapalasingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krieken_E/0/1/0/all/0/1\">Emile van Krieken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_D/0/1/0/all/0/1\">Daniel Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bloem_P/0/1/0/all/0/1\">Peter Bloem</a>",
          "description": "Graph neural networks (GNNs) learn the representation of nodes in a graph by\naggregating the neighborhood information in various ways. As these networks\ngrow in depth, their receptive field grows exponentially due to the increase in\nneighborhood sizes, resulting in high memory costs. Graph sampling solves\nmemory issues in GNNs by sampling a small ratio of the nodes in the graph. This\nway, GNNs can scale to much larger graphs. Most sampling methods focus on fixed\nsampling heuristics, which may not generalize to different structures or tasks.\nWe introduce GRAPES, an adaptive graph sampling method that learns to identify\nsets of influential nodes for training a GNN classifier. GRAPES uses a GFlowNet\nto learn node sampling probabilities given the classification objectives. We\nevaluate GRAPES across several small- and large-scale graph benchmarks and\ndemonstrate its effectiveness in accuracy and scalability. In contrast to\nexisting sampling methods, GRAPES maintains high accuracy even with small\nsample sizes and, therefore, can scale to very large graphs. Our code is\npublicly available at https://github.com/dfdazac/grapes.",
          "link": "http://arxiv.org/abs/2310.03399",
          "publishedOn": "2023-10-07T00:42:19.309Z",
          "wordCount": null,
          "title": "GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks. (arXiv:2310.03399v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Huan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peilin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bingzhe Wu</a>",
          "description": "Nowadays, billions of people engage in communication and express their\nopinions on the internet daily. Unfortunately, not all of these expressions are\nfriendly or compliant, making content moderation an indispensable task. With\nthe successful development of Large Language Models (LLMs) in recent years,\nLLM-based methods have become a feasible solution for handling tasks in various\ndomains. However, in the field of content moderation, there is still a lack of\ndetailed work that systematically introduces implementation details. In this\npaper, we introduce how to fine-tune an LLM model that can be privately\ndeployed for content moderation. Specifically, we discuss whether incorporating\nreasons during the fine-tuning process would be better or if it should be\ntreated as a classification task directly. We also explore the benefits of\nutilizing reasons generated by more powerful LLMs for fine-tuning privately\ndeployed models and the impact of different processing approaches when the\nanswers generated by the more powerful LLMs are incorrect. We report the entire\nresearch process and the key findings in this paper, hoping to provide valuable\nexperience for researchers who are fine-tuning privately deployed models in\ntheir domain-specific research.",
          "link": "http://arxiv.org/abs/2310.03400",
          "publishedOn": "2023-10-07T00:42:19.308Z",
          "wordCount": null,
          "title": "Adapting Large Language Models for Content Moderation: Pitfalls in Data Engineering and Supervised Fine-tuning. (arXiv:2310.03400v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03324",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1\">Jie-Jing Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiang-Xin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiao-Wen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Lan-Zhe Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu-Feng Li</a>",
          "description": "Contrastive Language-Image Pre-training (CLIP) provides a foundation model by\nintegrating natural language into visual concepts, enabling zero-shot\nrecognition on downstream tasks. It is usually expected that satisfactory\noverall accuracy can be achieved across numerous domains through well-designed\ntextual prompts. However, we found that their performance in the worst\ncategories is significantly inferior to the overall performance. For example,\non ImageNet, there are a total of 10 categories with class-wise accuracy as low\nas 0\\%, even though the overall performance has achieved 64.1\\%. This\nphenomenon reveals the potential risks associated with using CLIP models,\nparticularly in risk-sensitive applications where specific categories hold\nsignificant importance. To address this issue, we investigate the alignment\nbetween the two modalities in the CLIP model and propose the Class-wise\nMatching Margin (\\cmm) to measure the inference confusion. \\cmm\\ can\neffectively identify the worst-performing categories and estimate the potential\nperformance of the candidate prompts. We further query large language models to\nenrich descriptions of worst-performing categories and build a weighted\nensemble to highlight the efficient prompts. Experimental results clearly\nverify the effectiveness of our proposal, where the accuracy on the worst-10\ncategories on ImageNet is boosted to 5.2\\%, without manual prompt engineering,\nlaborious optimization, or access to labeled validation data.",
          "link": "http://arxiv.org/abs/2310.03324",
          "publishedOn": "2023-10-07T00:42:19.307Z",
          "wordCount": null,
          "title": "Investigating the Limitation of CLIP Models: The Worst-Performing Categories. (arXiv:2310.03324v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03393",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kapllani_L/0/1/0/all/0/1\">Lorenc Kapllani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Teng_L/0/1/0/all/0/1\">Long Teng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rottmann_M/0/1/0/all/0/1\">Matthias Rottmann</a>",
          "description": "Deep learning-based numerical schemes for solving high-dimensional backward\nstochastic differential equations (BSDEs) have recently raised plenty of\nscientific interest. While they enable numerical methods to approximate very\nhigh-dimensional BSDEs, their reliability has not been studied and is thus not\nunderstood. In this work, we study uncertainty quantification (UQ) for a class\nof deep learning-based BSDE schemes. More precisely, we review the sources of\nuncertainty involved in the schemes and numerically study the impact of\ndifferent sources. Usually, the standard deviation (STD) of the approximate\nsolutions obtained from multiple runs of the algorithm with different datasets\nis calculated to address the uncertainty. This approach is computationally\nquite expensive, especially for high-dimensional problems. Hence, we develop a\nUQ model that efficiently estimates the STD of the approximate solution using\nonly a single run of the algorithm. The model also estimates the mean of the\napproximate solution, which can be leveraged to initialize the algorithm and\nimprove the optimization process. Our numerical experiments show that the UQ\nmodel produces reliable estimates of the mean and STD of the approximate\nsolution for the considered class of deep learning-based BSDE schemes. The\nestimated STD captures multiple sources of uncertainty, demonstrating its\neffectiveness in quantifying the uncertainty. Additionally, the model\nillustrates the improved performance when comparing different schemes based on\nthe estimated STD values. Furthermore, it can identify hyperparameter values\nfor which the scheme achieves good approximations.",
          "link": "http://arxiv.org/abs/2310.03393",
          "publishedOn": "2023-10-07T00:42:19.305Z",
          "wordCount": null,
          "title": "Uncertainty quantification for deep learning-based schemes for solving high-dimensional backward stochastic differential equations. (arXiv:2310.03393v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03556",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bolat_K/0/1/0/all/0/1\">Kutay B&#xf6;lat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tindemans_S/0/1/0/all/0/1\">Simon H. Tindemans</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Palensky_P/0/1/0/all/0/1\">Peter Palensky</a>",
          "description": "Probabilistic modelling of power systems operation and planning processes\ndepends on data-driven methods, which require sufficiently large datasets. When\nhistorical data lacks this, it is desired to model the underlying data\ngeneration mechanism as a probability distribution to assess the data quality\nand generate more data, if needed. Kernel density estimation (KDE) based models\nare popular choices for this task, but they fail to adapt to data regions with\nvarying densities. In this paper, an adaptive KDE model is employed to\ncircumvent this, where each kernel in the model has an individual bandwidth.\nThe leave-one-out maximum log-likelihood (LOO-MLL) criterion is proposed to\nprevent the singular solutions that the regular MLL criterion gives rise to,\nand it is proven that LOO-MLL prevents these. Relying on this guaranteed\nrobustness, the model is extended by assigning learnable weights to the\nkernels. In addition, a modified expectation-maximization algorithm is employed\nto accelerate the optimization speed reliably. The performance of the proposed\nmethod and models are exhibited on two power systems datasets using different\nstatistical tests and by comparison with Gaussian mixture models. Results show\nthat the proposed models have promising performance, in addition to their\nsingularity prevention guarantees.",
          "link": "http://arxiv.org/abs/2310.03556",
          "publishedOn": "2023-10-07T00:42:19.305Z",
          "wordCount": null,
          "title": "Stable Training of Probabilistic Models Using the Leave-One-Out Maximum Log-Likelihood Objective. (arXiv:2310.03556v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03298",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ping Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Comlek_Y/0/1/0/all/0/1\">Yigitcan Comlek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate\nmodeling and design optimization by incorporating data from various\nlow-fidelity (LF) models. While most existing MF methods assume a fixed\ndataset, adaptive sampling methods that dynamically allocate resources among\nfidelity models can achieve higher efficiency in the exploring and exploiting\nthe design space. However, most existing MF methods rely on the hierarchical\nassumption of fidelity levels or fail to capture the intercorrelation between\nmultiple fidelity levels and utilize it to quantify the value of the future\nsamples and navigate the adaptive sampling. To address this hurdle, we propose\na framework hinged on a latent embedding for different fidelity models and the\nassociated pre-posterior analysis to explicitly utilize their correlation for\nadaptive sampling. In this framework, each infill sampling iteration includes\ntwo steps: We first identify the location of interest with the greatest\npotential improvement using the high-fidelity (HF) model, then we search for\nthe next sample across all fidelity levels that maximize the improvement per\nunit cost at the location identified in the first step. This is made possible\nby a single Latent Variable Gaussian Process (LVGP) model that maps different\nfidelity models into an interpretable latent space to capture their\ncorrelations without assuming hierarchical fidelity levels. The LVGP enables us\nto assess how LF sampling candidates will affect HF response with pre-posterior\nanalysis and determine the next sample with the best benefit-to-cost ratio.\nThrough test cases, we demonstrate that the proposed method outperforms the\nbenchmark methods in both MF global fitting (GF) and Bayesian Optimization (BO)\nproblems in convergence rate and robustness. Moreover, the method offers the\nflexibility to switch between GF and BO by simply changing the acquisition\nfunction.",
          "link": "http://arxiv.org/abs/2310.03298",
          "publishedOn": "2023-10-07T00:42:19.303Z",
          "wordCount": null,
          "title": "A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1912.05957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_H/0/1/0/all/0/1\">Hamid Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasteh_S/0/1/0/all/0/1\">Seyed Hossein Khasteh</a>",
          "description": "Evaluating the readability of a text can significantly facilitate the precise\nexpression of information in written form. The formulation of text readability\nassessment involves the identification of meaningful properties of the text\nregardless of its length. Sophisticated features and models are used to\nevaluate the comprehensibility of texts accurately. Despite this, the problem\nof assessing texts' readability efficiently remains relatively untouched. The\nefficiency of state-of-the-art text readability assessment models can be\nfurther improved using deep reinforcement learning models. Using a hard\nattention-based active inference technique, the proposed approach makes\nefficient use of input text and computational resources. Through the use of\nsemi-supervised signals, the reinforcement learning model uses the minimum\namount of text in order to determine text's readability. A comparison of the\nmodel on Weebit and Cambridge Exams with state-of-the-art models, such as the\nBERT text readability model, shows that it is capable of achieving\nstate-of-the-art accuracy with a significantly smaller amount of input text\nthan other models.",
          "link": "http://arxiv.org/abs/1912.05957",
          "publishedOn": "2023-10-07T00:42:19.301Z",
          "wordCount": null,
          "title": "Text as Environment: A Deep Reinforcement Learning Text Readability Assessment Model. (arXiv:1912.05957v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emili_L/0/1/0/all/0/1\">Leonardo Emili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraga_Silva_T/0/1/0/all/0/1\">Thiago Fraga-Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pusateri_E/0/1/0/all/0/1\">Ernest Pusateri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nussbaum_Thom_M/0/1/0/all/0/1\">Markus Nu&#xdf;baum-Thom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oualil_Y/0/1/0/all/0/1\">Youssef Oualil</a>",
          "description": "We study model pruning methods applied to Transformer-based neural network\nlanguage models for automatic speech recognition. We explore three aspects of\nthe pruning frame work, namely criterion, method and scheduler, analyzing their\ncontribution in terms of accuracy and inference speed. To the best of our\nknowledge, such in-depth analyses on large-scale recognition systems has not\nbeen reported in the literature. In addition, we propose a variant of low-rank\napproximation suitable for incrementally compressing models, and delivering\nmultiple models with varied target sizes. Among other results, we show that a)\ndata-driven pruning outperforms magnitude-driven in several scenarios; b)\nincremental pruning achieves higher accuracy compared to one-shot pruning,\nespecially when targeting smaller sizes; and c) low-rank approximation presents\nthe best trade-off between size reduction and inference speed-up for moderate\ncompression.",
          "link": "http://arxiv.org/abs/2310.03424",
          "publishedOn": "2023-10-07T00:42:19.300Z",
          "wordCount": null,
          "title": "Neural Language Model Pruning for Automatic Speech Recognition. (arXiv:2310.03424v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03339",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trebbien_J/0/1/0/all/0/1\">Julius Trebbien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putz_S/0/1/0/all/0/1\">Sebastian P&#xfc;tz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_B/0/1/0/all/0/1\">Benjamin Sch&#xe4;fer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nygaard_H/0/1/0/all/0/1\">Heidi S. Nyg&#xe5;rd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorjao_L/0/1/0/all/0/1\">Leonardo Rydin Gorj&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witthaut_D/0/1/0/all/0/1\">Dirk Witthaut</a>",
          "description": "Accurate forecasts of electricity prices are crucial for the management of\nelectric power systems and the development of smart applications. European\nelectricity prices have risen substantially and became highly volatile after\nthe Russian invasion of Ukraine, challenging established forecasting methods.\nHere, we present a Long Short-Term Memory (LSTM) model for the\nGerman-Luxembourg day-ahead electricity prices addressing these challenges. The\nrecurrent structure of the LSTM allows the model to adapt to trends, while the\njoint prediction of both mean and standard deviation enables a probabilistic\nprediction. Using a physics-inspired approach - superstatistics - to derive an\nexplanation for the statistics of prices, we show that the LSTM model\nfaithfully reproduces both prices and their volatility.",
          "link": "http://arxiv.org/abs/2310.03339",
          "publishedOn": "2023-10-07T00:42:19.298Z",
          "wordCount": null,
          "title": "Probabilistic Forecasting of Day-Ahead Electricity Prices and their Volatility with LSTMs. (arXiv:2310.03339v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.15122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Temizoz_T/0/1/0/all/0/1\">Tarkan Temiz&#xf6;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imdahl_C/0/1/0/all/0/1\">Christina Imdahl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijkman_R/0/1/0/all/0/1\">Remco Dijkman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamghari_Idrissi_D/0/1/0/all/0/1\">Douniel Lamghari-Idrissi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaarsveld_W/0/1/0/all/0/1\">Willem van Jaarsveld</a>",
          "description": "Problem Definition: Are traditional deep reinforcement learning (DRL)\nalgorithms, developed for a broad range of purposes including game-play and\nrobotics, the most suitable machine learning algorithms for applications in\ninventory control? To what extent would DRL algorithms tailored to the unique\ncharacteristics of inventory control problems provide superior performance\ncompared to DRL and traditional benchmarks? Methodology/results: We propose and\nstudy Deep Controlled Learning (DCL), a new DRL framework based on approximate\npolicy iteration specifically designed to tackle inventory problems.\nComparative evaluations reveal that DCL outperforms existing state-of-the-art\nheuristics in lost sales inventory control, perishable inventory systems, and\ninventory systems with random lead times, achieving lower average costs across\nall test instances and maintaining an optimality gap of no more than 0.1\\%.\nNotably, the same hyperparameter set is utilized across all experiments,\nunderscoring the robustness and generalizability of the proposed method.\nManagerial implications: These substantial performance and robustness\nimprovements pave the way for the effective application of tailored DRL\nalgorithms to inventory management problems, empowering decision-makers to\noptimize stock levels, minimize costs, and enhance responsiveness across\nvarious industries.",
          "link": "http://arxiv.org/abs/2011.15122",
          "publishedOn": "2023-10-07T00:42:19.289Z",
          "wordCount": null,
          "title": "Deep Controlled Learning for Inventory Control. (arXiv:2011.15122v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_Q/0/1/0/all/0/1\">Qirong Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyi Wang</a>",
          "description": "Weight decay is a standard technique to improve generalization performance in\nmodern deep neural network optimization, and is also widely adopted in\nfederated learning (FL) to prevent overfitting in local clients. In this paper,\nwe first explore the choices of weight decay and identify that weight decay\nvalue appreciably influences the convergence of existing FL algorithms. While\npreventing overfitting is crucial, weight decay can introduce a different\noptimization goal towards the global objective, which is further amplified in\nFL due to multiple local updates and heterogeneous data distribution. To\naddress this challenge, we develop {\\it Federated optimization with Normalized\nAnnealing Regularization} (FedNAR), a simple yet effective and versatile\nalgorithmic plug-in that can be seamlessly integrated into any existing FL\nalgorithms. Essentially, we regulate the magnitude of each update by performing\nco-clipping of the gradient and weight decay. We provide a comprehensive\ntheoretical analysis of FedNAR's convergence rate and conduct extensive\nexperiments on both vision and language datasets with different backbone\nfederated optimization algorithms. Our experimental results consistently\ndemonstrate that incorporating FedNAR into existing FL algorithms leads to\naccelerated convergence and heightened model accuracy. Moreover, FedNAR\nexhibits resilience in the face of various hyperparameter configurations.\nSpecifically, FedNAR has the ability to self-adjust the weight decay when the\ninitial specification is not optimal, while the accuracy of traditional FL\nalgorithms would markedly decline. Our codes are released at\n\\href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.",
          "link": "http://arxiv.org/abs/2310.03163",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "FedNAR: Federated Optimization with Normalized Annealing Regularization. (arXiv:2310.03163v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frey_J/0/1/0/all/0/1\">Jonas Frey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudin_N/0/1/0/all/0/1\">Nikita Rudin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattamala_M/0/1/0/all/0/1\">Matias Mattamala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cadena_C/0/1/0/all/0/1\">Cesar Cadena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1\">Marco Hutter</a>",
          "description": "Autonomous robots must navigate reliably in unknown environments even under\ncompromised exteroceptive perception, or perception failures. Such failures\noften occur when harsh environments lead to degraded sensing, or when the\nperception algorithm misinterprets the scene due to limited generalization. In\nthis paper, we model perception failures as invisible obstacles and pits, and\ntrain a reinforcement learning (RL) based local navigation policy to guide our\nlegged robot. Unlike previous works relying on heuristics and anomaly detection\nto update navigational information, we train our navigation policy to\nreconstruct the environment information in the latent space from corrupted\nperception and react to perception failures end-to-end. To this end, we\nincorporate both proprioception and exteroception into our policy inputs,\nthereby enabling the policy to sense collisions on different body parts and\npits, prompting corresponding reactions. We validate our approach in simulation\nand on the real quadruped robot ANYmal running in real-time (<10 ms CPU\ninference). In a quantitative comparison with existing heuristic-based locally\nreactive planners, our policy increases the success rate over 30% when facing\nperception failures. Project Page: https://bit.ly/45NBTuh.",
          "link": "http://arxiv.org/abs/2310.03581",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "Resilient Legged Local Navigation: Learning to Traverse with Compromised Perception End-to-End. (arXiv:2310.03581v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garza_A/0/1/0/all/0/1\">Azul Garza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mergenthaler_Canseco_M/0/1/0/all/0/1\">Max Mergenthaler-Canseco</a>",
          "description": "In this paper, we introduce TimeGPT, the first foundation model for time\nseries, capable of generating accurate predictions for diverse datasets not\nseen during training. We evaluate our pre-trained model against established\nstatistical, machine learning, and deep learning methods, demonstrating that\nTimeGPT zero-shot inference excels in performance, efficiency, and simplicity.\nOur study provides compelling evidence that insights from other domains of\nartificial intelligence can be effectively applied to time series analysis. We\nconclude that large-scale time series models offer an exciting opportunity to\ndemocratize access to precise predictions and reduce uncertainty by leveraging\nthe capabilities of contemporary advancements in deep learning.",
          "link": "http://arxiv.org/abs/2310.03589",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "TimeGPT-1. (arXiv:2310.03589v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.01856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shihan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarke_A/0/1/0/all/0/1\">Alexander Kenneth Clarke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maksymenko_K/0/1/0/all/0/1\">Kostiantyn Maksymenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deslauriers_Gauthier_S/0/1/0/all/0/1\">Samuel Deslauriers-Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1\">Xinjun Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiangyang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farina_D/0/1/0/all/0/1\">Dario Farina</a>",
          "description": "Numerical models of electromyographic (EMG) signals have provided a huge\ncontribution to our fundamental understanding of human neurophysiology and\nremain a central pillar of motor neuroscience and the development of\nhuman-machine interfaces. However, whilst modern biophysical simulations based\non finite element methods are highly accurate, they are extremely\ncomputationally expensive and thus are generally limited to modelling static\nsystems such as isometrically contracting limbs. As a solution to this problem,\nwe propose a transfer learning approach, in which a conditional generative\nmodel is trained to mimic the output of an advanced numerical model. To this\nend, we present BioMime, a conditional generative neural network trained\nadversarially to generate motor unit activation potential waveforms under a\nwide variety of volume conductor parameters. We demonstrate the ability of such\na model to predictively interpolate between a much smaller number of numerical\nmodel's outputs with a high accuracy. Consequently, the computational load is\ndramatically reduced, which allows the rapid simulation of EMG signals during\ntruly dynamic and naturalistic movements.",
          "link": "http://arxiv.org/abs/2211.01856",
          "publishedOn": "2023-10-07T00:42:19.281Z",
          "wordCount": null,
          "title": "Conditional Generative Models for Simulation of EMG During Naturalistic Movements. (arXiv:2211.01856v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03281",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1\">Yanyi Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yupeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_L/0/1/0/all/0/1\">Le Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jason Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>",
          "description": "The 5' UTR, a regulatory region at the beginning of an mRNA molecule, plays a\ncrucial role in regulating the translation process and impacts the protein\nexpression level. Language models have showcased their effectiveness in\ndecoding the functions of protein and genome sequences. Here, we introduced a\nlanguage model for 5' UTR, which we refer to as the UTR-LM. The UTR-LM is\npre-trained on endogenous 5' UTRs from multiple species and is further\naugmented with supervised information including secondary structure and minimum\nfree energy. We fine-tuned the UTR-LM in a variety of downstream tasks. The\nmodel outperformed the best-known benchmark by up to 42% for predicting the\nMean Ribosome Loading, and by up to 60% for predicting the Translation\nEfficiency and the mRNA Expression Level. The model also applies to identifying\nunannotated Internal Ribosome Entry Sites within the untranslated region and\nimproves the AUPR from 0.37 to 0.52 compared to the best baseline. Further, we\ndesigned a library of 211 novel 5' UTRs with high predicted values of\ntranslation efficiency and evaluated them via a wet-lab assay. Experiment\nresults confirmed that our top designs achieved a 32.5% increase in protein\nproduction level relative to well-established 5' UTR optimized for\ntherapeutics.",
          "link": "http://arxiv.org/abs/2310.03281",
          "publishedOn": "2023-10-07T00:42:19.280Z",
          "wordCount": null,
          "title": "A 5' UTR Language Model for Decoding Untranslated Regions of mRNA and Function Predictions. (arXiv:2310.03281v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hellsten_E/0/1/0/all/0/1\">Erik Orm Hellsten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hvarfner_C/0/1/0/all/0/1\">Carl Hvarfner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papenmeier_L/0/1/0/all/0/1\">Leonard Papenmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nardi_L/0/1/0/all/0/1\">Luigi Nardi</a>",
          "description": "Bayesian optimization is an effective method for optimizing\nexpensive-to-evaluate black-box functions. High-dimensional problems are\nparticularly challenging as the surrogate model of the objective suffers from\nthe curse of dimensionality, which makes accurate modeling difficult. We\npropose a group testing approach to identify active variables to facilitate\nefficient optimization in these domains. The proposed algorithm, Group Testing\nBayesian Optimization (GTBO), first runs a testing phase where groups of\nvariables are systematically selected and tested on whether they influence the\nobjective. To that end, we extend the well-established theory of group testing\nto functions of continuous ranges. In the second phase, GTBO guides\noptimization by placing more importance on the active dimensions. By exploiting\nthe axis-aligned subspace assumption, GTBO is competitive against\nstate-of-the-art methods on several synthetic and real-world high-dimensional\noptimization tasks. Furthermore, GTBO aids in the discovery of active\nparameters in applications, thereby enhancing practitioners' understanding of\nthe problem at hand.",
          "link": "http://arxiv.org/abs/2310.03515",
          "publishedOn": "2023-10-07T00:42:19.280Z",
          "wordCount": null,
          "title": "High-dimensional Bayesian Optimization with Group Testing. (arXiv:2310.03515v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.03991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1\">Rachid Guerraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Nirupam Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinot_R/0/1/0/all/0/1\">Rafael Pinot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouault_S/0/1/0/all/0/1\">Sebastien Rouault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1\">John Stephan</a>",
          "description": "Privacy and Byzantine resilience (BR) are two crucial requirements of\nmodern-day distributed machine learning. The two concepts have been extensively\nstudied individually but the question of how to combine them effectively\nremains unanswered. This paper contributes to addressing this question by\nstudying the extent to which the distributed SGD algorithm, in the standard\nparameter-server architecture, can learn an accurate model despite (a) a\nfraction of the workers being malicious (Byzantine), and (b) the other\nfraction, whilst being honest, providing noisy information to the server to\nensure differential privacy (DP). We first observe that the integration of\nstandard practices in DP and BR is not straightforward. In fact, we show that\nmany existing results on the convergence of distributed SGD under Byzantine\nfaults, especially those relying on $(\\alpha,f)$-Byzantine resilience, are\nrendered invalid when honest workers enforce DP. To circumvent this\nshortcoming, we revisit the theory of $(\\alpha,f)$-BR to obtain an approximate\nconvergence guarantee. Our analysis provides key insights on how to improve\nthis guarantee through hyperparameter optimization. Essentially, our\ntheoretical and empirical results show that (1) an imprudent combination of\nstandard approaches to DP and BR might be fruitless, but (2) by carefully\nre-tuning the learning algorithm, we can obtain reasonable learning accuracy\nwhile simultaneously guaranteeing DP and BR.",
          "link": "http://arxiv.org/abs/2110.03991",
          "publishedOn": "2023-10-07T00:42:19.280Z",
          "wordCount": null,
          "title": "Combining Differential Privacy and Byzantine Resilience in Distributed SGD. (arXiv:2110.03991v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vora_J/0/1/0/all/0/1\">Jian Vora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>",
          "description": "Scientific experimentation involves an iterative process of creating\nhypotheses, designing experiments, running experiments, and analyzing the\nresults. Can we build AI research agents to perform these long-horizon tasks?\nTo take a step towards building and evaluating research agents on such\nopen-ended decision-making tasks, we focus on the problem of machine learning\nengineering: given a task description and a dataset, build a high-performing\nmodel. In this paper, we propose MLAgentBench, a suite of ML tasks for\nbenchmarking AI research agents. Agents can perform actions like\nreading/writing files, executing code, and inspecting outputs. With these\nactions, agents could run experiments, analyze the results, and modify the code\nof entire machine learning pipelines, such as data processing, architecture,\ntraining processes, etc. The benchmark then automatically evaluates the agent's\nperformance objectively over various metrics related to performance and\nefficiency. We also design an LLM-based research agent to automatically perform\nexperimentation loops in such an environment. Empirically, we find that a\nGPT-4-based research agent can feasibly build compelling ML models over many\ntasks in MLAgentBench, displaying highly interpretable plans and actions.\nHowever, the success rates vary considerably; they span from almost 90\\% on\nwell-established older datasets to as low as 10\\% on recent Kaggle Challenges\n-- unavailable during the LLM model's pretraining -- and even 0\\% on newer\nresearch challenges like BabyLM. Finally, we identify several key challenges\nfor LLM-based research agents such as long-term planning and hallucination. Our\ncode is released at https://github.com/snap-stanford/MLAgentBench.",
          "link": "http://arxiv.org/abs/2310.03302",
          "publishedOn": "2023-10-07T00:42:19.279Z",
          "wordCount": null,
          "title": "Benchmarking Large Language Models As AI Research Agents. (arXiv:2310.03302v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1\">Jonathan Crabb&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "Interpretability methods are valuable only if their explanations faithfully\ndescribe the explained model. In this work, we consider neural networks whose\npredictions are invariant under a specific symmetry group. This includes\npopular architectures, ranging from convolutional to graph neural networks. Any\nexplanation that faithfully explains this type of model needs to be in\nagreement with this invariance property. We formalize this intuition through\nthe notion of explanation invariance and equivariance by leveraging the\nformalism from geometric deep learning. Through this rigorous formalism, we\nderive (1) two metrics to measure the robustness of any interpretability method\nwith respect to the model symmetry group; (2) theoretical robustness guarantees\nfor some popular interpretability methods and (3) a systematic approach to\nincrease the invariance of any interpretability method with respect to a\nsymmetry group. By empirically measuring our metrics for explanations of models\nassociated with various modalities and symmetry groups, we derive a set of 5\nguidelines to allow users and developers of interpretability methods to produce\nrobust explanations.",
          "link": "http://arxiv.org/abs/2304.06715",
          "publishedOn": "2023-10-07T00:42:19.279Z",
          "wordCount": null,
          "title": "Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance. (arXiv:2304.06715v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03388",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rabino_P/0/1/0/all/0/1\">Paolo Rabino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alliegro_A/0/1/0/all/0/1\">Antonio Alliegro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borlino_F/0/1/0/all/0/1\">Francesco Cappio Borlino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tommasi_T/0/1/0/all/0/1\">Tatiana Tommasi</a>",
          "description": "Moving deep learning models from the laboratory setting to the open world\nentails preparing them to handle unforeseen conditions. In several applications\nthe occurrence of novel classes during deployment poses a significant threat,\nthus it is crucial to effectively detect them. Ideally, this skill should be\nused when needed without requiring any further computational training effort at\nevery new task. Out-of-distribution detection has attracted significant\nattention in the last years, however the majority of the studies deal with 2D\nimages ignoring the inherent 3D nature of the real-world and often confusing\nbetween domain and semantic novelty. In this work, we focus on the latter,\nconsidering the objects geometric structure captured by 3D point clouds\nregardless of the specific domain. We advance the field by introducing\nOpenPatch that builds on a large pre-trained model and simply extracts from its\nintermediate features a set of patch representations that describe each known\nclass. For any new sample, we obtain a novelty score by evaluating whether it\ncan be recomposed mainly by patches of a single known class or rather via the\ncontribution of multiple classes. We present an extensive experimental\nevaluation of our approach for the task of semantic novelty detection on\nreal-world point cloud samples when the reference known data are synthetic. We\ndemonstrate that OpenPatch excels in both the full and few-shot known sample\nscenarios, showcasing its robustness across varying pre-training objectives and\nnetwork backbones. The inherent training-free nature of our method allows for\nits immediate application to a wide array of real-world tasks, offering a\ncompelling advantage over approaches that need expensive retraining efforts.",
          "link": "http://arxiv.org/abs/2310.03388",
          "publishedOn": "2023-10-07T00:42:19.278Z",
          "wordCount": null,
          "title": "OpenPatch: a 3D patchwork for Out-Of-Distribution detectionpdf icon. (arXiv:2310.03388v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.01944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Darabi_S/0/1/0/all/0/1\">Sajad Darabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bigaj_P/0/1/0/all/0/1\">Piotr Bigaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majchrowski_D/0/1/0/all/0/1\">Dawid Majchrowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasymov_A/0/1/0/all/0/1\">Artur Kasymov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morkisz_P/0/1/0/all/0/1\">Pawel Morkisz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fit_Florea_A/0/1/0/all/0/1\">Alex Fit-Florea</a>",
          "description": "Recently there has been increasing interest in developing and deploying deep\ngraph learning algorithms for many tasks, such as fraud detection and\nrecommender systems. Albeit, there is a limited number of publicly available\ngraph-structured datasets, most of which are tiny compared to production-sized\napplications or are limited in their application domain. This work tackles this\nshortcoming by proposing a scalable synthetic graph generation tool to scale\nthe datasets to production-size graphs with trillions of edges and billions of\nnodes. The tool learns a series of parametric models from proprietary datasets\nthat can be released to researchers to study various graph methods on the\nsynthetic data increasing prototype development and novel applications. We\ndemonstrate the generalizability of the framework across a series of datasets,\nmimicking structural and feature distributions as well as the ability to scale\nthem across varying sizes demonstrating their usefulness for benchmarking and\nmodel development. Code can be found on\nhttps://github.com/NVIDIA/DeepLearningExamples/tree/master/Tools/DGLPyTorch/SyntheticGraphGeneration.",
          "link": "http://arxiv.org/abs/2210.01944",
          "publishedOn": "2023-10-07T00:42:19.277Z",
          "wordCount": null,
          "title": "A Framework for Large Scale Synthetic Graph Dataset Generation. (arXiv:2210.01944v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Si Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Daliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasik_M/0/1/0/all/0/1\">Michal Lukasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Felix Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit S Dhillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>",
          "description": "Pretrained large language models (LLMs) are general purpose problem solvers\napplicable to a diverse set of tasks with prompts. They can be further improved\ntowards a specific task by fine-tuning on a specialized dataset. However,\nfine-tuning usually makes the model narrowly specialized on this dataset with\nreduced general in-context learning performances, which is undesirable whenever\nthe fine-tuned model needs to handle additional tasks where no fine-tuning data\nis available. In this work, we first demonstrate that fine-tuning on a single\ntask indeed decreases LLMs' general in-context learning performance. We\ndiscover one important cause of such forgetting, format specialization, where\nthe model overfits to the format of the fine-tuned task. We further show that\nformat specialization happens at the very beginning of fine-tuning. To solve\nthis problem, we propose Prompt Tuning with MOdel Tuning (ProMoT), a simple yet\neffective two-stage fine-tuning framework that reduces format specialization\nand improves generalization. ProMoT offloads task-specific format learning into\nadditional and removable parameters by first doing prompt tuning and then\nfine-tuning the model itself with this soft prompt attached. With experiments\non several fine-tuning tasks and 8 in-context evaluation tasks, we show that\nProMoT achieves comparable performance on fine-tuned tasks to standard\nfine-tuning, but with much less loss of in-context learning performances across\na board range of out-of-domain evaluation tasks. More importantly, ProMoT can\neven enhance generalization on in-context learning tasks that are semantically\nrelated to the fine-tuned task, e.g. ProMoT on En-Fr translation significantly\nimproves performance on other language pairs, and ProMoT on NLI improves\nperformance on summarization. Experiments also show that ProMoT can improve the\ngeneralization performance of multi-task training.",
          "link": "http://arxiv.org/abs/2211.00635",
          "publishedOn": "2023-10-07T00:42:19.276Z",
          "wordCount": null,
          "title": "Two-stage LLM Fine-tuning with Less Specialization and More Generalization. (arXiv:2211.00635v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Boya Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weijian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "Adversarial attacks have the potential to mislead deep neural network\nclassifiers by introducing slight perturbations. Developing algorithms that can\nmitigate the effects of these attacks is crucial for ensuring the safe use of\nartificial intelligence. Recent studies have suggested that score-based\ndiffusion models are effective in adversarial defenses. However, existing\ndiffusion-based defenses rely on the sequential simulation of the reversed\nstochastic differential equations of diffusion models, which are\ncomputationally inefficient and yield suboptimal results. In this paper, we\nintroduce a novel adversarial defense scheme named ScoreOpt, which optimizes\nadversarial samples at test-time, towards original clean data in the direction\nguided by score-based priors. We conduct comprehensive experiments on multiple\ndatasets, including CIFAR10, CIFAR100 and ImageNet. Our experimental results\ndemonstrate that our approach outperforms existing adversarial defenses in\nterms of both robustness performance and inference speed.",
          "link": "http://arxiv.org/abs/2307.04333",
          "publishedOn": "2023-10-07T00:42:19.276Z",
          "wordCount": null,
          "title": "Enhancing Adversarial Robustness via Score-Based Optimization. (arXiv:2307.04333v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Postovan_A/0/1/0/all/0/1\">Andreea Postovan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erascu_M/0/1/0/all/0/1\">M&#x103;d&#x103;lina Era&#x15f;cu</a>",
          "description": "Traffic signs play a critical role in road safety and traffic management for\nautonomous driving systems. Accurate traffic sign classification is essential\nbut challenging due to real-world complexities like adversarial examples and\nocclusions. To address these issues, binary neural networks offer promise in\nconstructing classifiers suitable for resource-constrained devices.\n\nIn our previous work, we proposed high-accuracy BNN models for traffic sign\nrecognition, focusing on compact size for limited computation and energy\nresources. To evaluate their local robustness, this paper introduces a set of\nbenchmark problems featuring layers that challenge state-of-the-art\nverification tools. These layers include binarized convolutions, max pooling,\nbatch normalization, fully connected. The difficulty of the verification\nproblem is given by the high number of network parameters (905k - 1.7 M), of\nthe input dimension (2.7k-12k), and of the number of regions (43) as well by\nthe fact that the neural networks are not sparse.\n\nThe proposed BNN models and local robustness properties can be checked at\nhttps://github.com/ChristopherBrix/vnncomp2023_benchmarks/tree/main/benchmarks/traffic_signs_recognition.\n\nThe results of the 4th International Verification of Neural Networks\nCompetition (VNN-COMP'23) revealed the fact that 4, out of 7, solvers can\nhandle many of our benchmarks randomly selected (minimum is 6, maximum is 36,\nout of 45). Surprisingly, tools output also wrong results or missing\ncounterexample (ranging from 1 to 4). Currently, our focus lies in exploring\nthe possibility of achieving a greater count of solved instances by extending\nthe allotted time (previously set at 8 minutes). Furthermore, we are intrigued\nby the reasons behind the erroneous outcomes provided by the tools for certain\nbenchmarks.",
          "link": "http://arxiv.org/abs/2310.03033",
          "publishedOn": "2023-10-07T00:42:19.275Z",
          "wordCount": null,
          "title": "Benchmarking Local Robustness of High-Accuracy Binary Neural Networks for Enhanced Traffic Sign Recognition. (arXiv:2310.03033v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebadi_A/0/1/0/all/0/1\">Ali Ebadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahafizadeh_E/0/1/0/all/0/1\">Ebrahim Sahafizadeh</a>",
          "description": "This literature review aimed to compare various time-series analysis\napproaches utilized in forecasting COVID-19 cases in Africa. The study involved\na methodical search for English-language research papers published between\nJanuary 2020 and July 2023, focusing specifically on papers that utilized\ntime-series analysis approaches on COVID-19 datasets in Africa. A variety of\ndatabases including PubMed, Google Scholar, Scopus, and Web of Science were\nutilized for this process. The research papers underwent an evaluation process\nto extract relevant information regarding the implementation and performance of\nthe time-series analysis models. The study highlighted the different\nmethodologies employed, evaluating their effectiveness and limitations in\nforecasting the spread of the virus. The result of this review could contribute\ndeeper insights into the field, and future research should consider these\ninsights to improve time series analysis models and explore the integration of\ndifferent approaches for enhanced public health decision-making.",
          "link": "http://arxiv.org/abs/2310.03606",
          "publishedOn": "2023-10-07T00:42:19.275Z",
          "wordCount": null,
          "title": "Comparing Time-Series Analysis Approaches Utilized in Research Papers to Forecast COVID-19 Cases in Africa: A Literature Review. (arXiv:2310.03606v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03243",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1\">Mingxuan Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liang_F/0/1/0/all/0/1\">Faming Liang</a>",
          "description": "Sparse deep learning has become a popular technique for improving the\nperformance of deep neural networks in areas such as uncertainty\nquantification, variable selection, and large-scale network compression.\nHowever, most existing research has focused on problems where the observations\nare independent and identically distributed (i.i.d.), and there has been little\nwork on the problems where the observations are dependent, such as time series\ndata and sequential data in natural language processing. This paper aims to\naddress this gap by studying the theory for sparse deep learning with dependent\ndata. We show that sparse recurrent neural networks (RNNs) can be consistently\nestimated, and their predictions are asymptotically normally distributed under\nappropriate assumptions, enabling the prediction uncertainty to be correctly\nquantified. Our numerical results show that sparse deep learning outperforms\nstate-of-the-art methods, such as conformal predictions, in prediction\nuncertainty quantification for time series data. Furthermore, our results\nindicate that the proposed method can consistently identify the autoregressive\norder for time series data and outperform existing methods in large-scale model\ncompression. Our proposed method has important practical implications in fields\nsuch as finance, healthcare, and energy, where both accurate point estimates\nand prediction uncertainty quantification are of concern.",
          "link": "http://arxiv.org/abs/2310.03243",
          "publishedOn": "2023-10-07T00:42:19.271Z",
          "wordCount": null,
          "title": "Sparse Deep Learning for Time Series Data: Theory and Applications. (arXiv:2310.03243v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1\">Nuoyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Decheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Dawei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nannan Wang</a>",
          "description": "Deep neural networks are vulnerable to adversarial noise. Adversarial\ntraining (AT) has been demonstrated to be the most effective defense strategy\nto protect neural networks from being fooled. However, we find AT omits to\nlearning robust features, resulting in poor performance of adversarial\nrobustness. To address this issue, we highlight two characteristics of robust\nrepresentation: (1) $\\bf{exclusion}$: the feature of natural examples keeps\naway from that of other classes; (2) $\\bf{alignment}$: the feature of natural\nand corresponding adversarial examples is close to each other. These motivate\nus to propose a generic framework of AT to gain robust representation, by the\nasymmetric negative contrast and reverse attention. Specifically, we design an\nasymmetric negative contrast based on predicted probabilities, to push away\nexamples of different classes in the feature space. Moreover, we propose to\nweight feature by parameters of the linear classifier as the reverse attention,\nto obtain class-aware feature and pull close the feature of the same class.\nEmpirical evaluations on three benchmark datasets show our methods greatly\nadvance the robustness of AT and achieve state-of-the-art performance. Code is\navailable at <https://github.com/changzhang777/ANCRA>.",
          "link": "http://arxiv.org/abs/2310.03358",
          "publishedOn": "2023-10-07T00:42:19.270Z",
          "wordCount": null,
          "title": "Robust Representation Learning via Asymmetric Negative Contrast and Reverse Attention. (arXiv:2310.03358v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.14883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shenggui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_Z/0/1/0/all/0/1\">Zhengda Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1\">Jiarui Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haichen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "The success of Transformer models has pushed the deep learning model scale to\nbillions of parameters. Due to the limited memory resource of a single GPU,\nHowever, the best practice for choosing the optimal parallel strategy is still\nlacking, since it requires domain expertise in both deep learning and parallel\ncomputing.\n\nThe Colossal-AI system addressed the above challenge by introducing a unified\ninterface to scale your sequential code of model training to distributed\nenvironments. It supports parallel training methods such as data, pipeline,\ntensor, and sequence parallelism, as well as heterogeneous training methods\nintegrated with zero redundancy optimizer. Compared to the baseline system,\nColossal-AI can achieve up to 2.76 times training speedup on large-scale\nmodels.",
          "link": "http://arxiv.org/abs/2110.14883",
          "publishedOn": "2023-10-07T00:42:19.269Z",
          "wordCount": null,
          "title": "Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training. (arXiv:2110.14883v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assel_H/0/1/0/all/0/1\">Hugues Van Assel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_Cuaz_C/0/1/0/all/0/1\">C&#xe9;dric Vincent-Cuaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayer_T/0/1/0/all/0/1\">Titouan Vayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1\">R&#xe9;mi Flamary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1\">Nicolas Courty</a>",
          "description": "We present a versatile adaptation of existing dimensionality reduction (DR)\nobjectives, enabling the simultaneous reduction of both sample and feature\nsizes. Correspondances between input and embedding samples are computed through\na semi-relaxed Gromov-Wasserstein optimal transport (OT) problem. When the\nembedding sample size matches that of the input, our model recovers classical\npopular DR models. When the embedding's dimensionality is unconstrained, we\nshow that the OT plan delivers a competitive hard clustering. We emphasize the\nimportance of intermediate stages that blend DR and clustering for summarizing\nreal data and apply our method to visualize datasets of images.",
          "link": "http://arxiv.org/abs/2310.03398",
          "publishedOn": "2023-10-07T00:42:19.268Z",
          "wordCount": null,
          "title": "Interpolating between Clustering and Dimensionality Reduction with Gromov-Wasserstein. (arXiv:2310.03398v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fish_E/0/1/0/all/0/1\">Edward Fish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinbren_J/0/1/0/all/0/1\">Jon Weinbren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilbert_A/0/1/0/all/0/1\">Andrew Gilbert</a>",
          "description": "Temporal Action Localization (TAL) aims to identify actions' start, end, and\nclass labels in untrimmed videos. While recent advancements using transformer\nnetworks and Feature Pyramid Networks (FPN) have enhanced visual feature\nrecognition in TAL tasks, less progress has been made in the integration of\naudio features into such frameworks. This paper introduces the Multi-Resolution\nAudio-Visual Feature Fusion (MRAV-FF), an innovative method to merge\naudio-visual data across different temporal resolutions. Central to our\napproach is a hierarchical gated cross-attention mechanism, which discerningly\nweighs the importance of audio information at diverse temporal scales. Such a\ntechnique not only refines the precision of regression boundaries but also\nbolsters classification confidence. Importantly, MRAV-FF is versatile, making\nit compatible with existing FPN TAL architectures and offering a significant\nenhancement in performance when audio data is available.",
          "link": "http://arxiv.org/abs/2310.03456",
          "publishedOn": "2023-10-07T00:42:19.267Z",
          "wordCount": null,
          "title": "Multi-Resolution Audio-Visual Feature Fusion for Temporal Action Localization. (arXiv:2310.03456v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>",
          "description": "The theoretical landscape of federated learning (FL) undergoes rapid\nevolution, but its practical application encounters a series of intricate\nchallenges, and hyperparameter optimization is one of these critical\nchallenges. Amongst the diverse adjustments in hyperparameters, the adaptation\nof the learning rate emerges as a crucial component, holding the promise of\nsignificantly enhancing the efficacy of FL systems. In response to this\ncritical need, this paper presents FedHyper, a novel hypergradient-based\nlearning rate adaptation algorithm specifically designed for FL. FedHyper\nserves as a universal learning rate scheduler that can adapt both global and\nlocal rates as the training progresses. In addition, FedHyper not only\nshowcases unparalleled robustness to a spectrum of initial learning rate\nconfigurations but also significantly alleviates the necessity for laborious\nempirical learning rate adjustments. We provide a comprehensive theoretical\nanalysis of FedHyper's convergence rate and conduct extensive experiments on\nvision and language benchmark datasets. The results demonstrate that FEDHYPER\nconsistently converges 1.1-3x faster than FedAvg and the competing baselines\nwhile achieving superior final accuracy. Moreover, FedHyper catalyzes a\nremarkable surge in accuracy, augmenting it by up to 15% compared to FedAvg\nunder suboptimal initial learning rate settings.",
          "link": "http://arxiv.org/abs/2310.03156",
          "publishedOn": "2023-10-07T00:42:19.264Z",
          "wordCount": null,
          "title": "FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent. (arXiv:2310.03156v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.02357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berezin_S/0/1/0/all/0/1\">Sergey Berezin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahbakhsh_R/0/1/0/all/0/1\">Reza Farahbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crespi_N/0/1/0/all/0/1\">Noel Crespi</a>",
          "description": "The fundamental problem in toxicity detection task lies in the fact that the\ntoxicity is ill-defined. This causes us to rely on subjective and vague data in\nmodels' training, which results in non-robust and non-accurate results: garbage\nin - garbage out.\n\nThis work suggests a new, stress-level-based definition of toxicity designed\nto be objective and context-aware. On par with it, we also describe possible\nways of applying this new definition to dataset creation and model training.",
          "link": "http://arxiv.org/abs/2310.02357",
          "publishedOn": "2023-10-07T00:42:19.263Z",
          "wordCount": null,
          "title": "On the definition of toxicity in NLP. (arXiv:2310.02357v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.16887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_G/0/1/0/all/0/1\">Guan Zhe Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yin Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuxman_A/0/1/0/all/0/1\">Ariel Fuxman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_S/0/1/0/all/0/1\">Stanley H. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_E/0/1/0/all/0/1\">Enming Luo</a>",
          "description": "In this paper, we study how the granularity of pretraining labels affects the\ngeneralization of deep neural networks in image classification tasks. We focus\non the \"fine-to-coarse\" transfer learning setting, where the pretraining label\nspace is more fine-grained than that of the target problem. Empirically, we\nshow that pretraining on the leaf labels of ImageNet21k produces better\ntransfer results on ImageNet1k than pretraining on other coarser granularity\nlevels, which supports the common practice used in the community.\nTheoretically, we explain the benefit of fine-grained pretraining by proving\nthat, for a data distribution satisfying certain hierarchy conditions, 1)\ncoarse-grained pretraining only allows a neural network to learn the \"common\"\nor \"easy-to-learn\" features well, while 2) fine-grained pretraining helps the\nnetwork learn the \"rarer\" or \"fine-grained\" features in addition to the common\nones, thus improving its accuracy on hard downstream test samples in which\ncommon features are missing or weak in strength. Furthermore, we perform\ncomprehensive experiments using the label hierarchies of iNaturalist 2021 and\nobserve that the following conditions, in addition to proper choice of label\ngranularity, enable the transfer to work well in practice: 1) the pretraining\ndataset needs to have a meaningful label hierarchy, and 2) the pretraining and\ntarget label functions need to align well.",
          "link": "http://arxiv.org/abs/2303.16887",
          "publishedOn": "2023-10-07T00:42:19.262Z",
          "wordCount": null,
          "title": "Towards Understanding the Effect of Pretraining Label Granularity. (arXiv:2303.16887v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1\">Hyosoon Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungsoo Ahn</a>",
          "description": "This paper studies generative flow networks (GFlowNets) to sample objects\nfrom the Boltzmann energy distribution via a sequence of actions. In\nparticular, we focus on improving GFlowNet with partial inference: training\nflow functions with the evaluation of the intermediate states or transitions.\nTo this end, the recently developed forward-looking GFlowNet reparameterizes\nthe flow functions based on evaluating the energy of intermediate states.\nHowever, such an evaluation of intermediate energies may (i) be too expensive\nor impossible to evaluate and (ii) even provide misleading training signals\nunder large energy fluctuations along the sequence of actions. To resolve this\nissue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our\nmain idea is to (i) decompose the energy of an object into learnable potential\nfunctions defined on state transitions and (ii) reparameterize the flow\nfunctions using the potential functions. In particular, to produce informative\nlocal credits, we propose to regularize the potential to change smoothly over\nthe sequence of actions. It is also noteworthy that training GFlowNet with our\nlearned potential can preserve the optimal policy. We empirically verify the\nsuperiority of LED-GFN in five problems including the generation of\nunstructured and maximum independent sets, molecular graphs, and RNA sequences.",
          "link": "http://arxiv.org/abs/2310.03301",
          "publishedOn": "2023-10-07T00:42:19.261Z",
          "wordCount": null,
          "title": "Learning Energy Decompositions for Partial Inference of GFlowNets. (arXiv:2310.03301v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_Y/0/1/0/all/0/1\">Yuka Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "We identify hidden layers inside a DNN with group actions on the data space,\nand formulate the DNN as a dual voice transform with respect to Koopman\noperator, a linear representation of the group action. Based on the group\ntheoretic arguments, particularly by using Schur's lemma, we show a simple\nproof of the universality of those DNNs.",
          "link": "http://arxiv.org/abs/2310.03529",
          "publishedOn": "2023-10-07T00:42:19.260Z",
          "wordCount": null,
          "title": "Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality of Formal Deep Networks. (arXiv:2310.03529v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Altabaa_A/0/1/0/all/0/1\">Awni Altabaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "A maturing area of research in deep learning is the development of\narchitectures that can learn explicit representations of relational features.\nIn this paper, we focus on the problem of learning representations of\nhierarchical relations, proposing an architectural framework we call\n\"relational convolutional networks\". Given a sequence of objects, a\n\"multi-dimensional inner product relation\" module produces a relation tensor\ndescribing all pairwise relations. A \"relational convolution\" layer then\ntransforms the relation tensor into a sequence of new objects, each describing\nthe relations within some group of objects at the previous layer. Graphlet\nfilters, analogous to filters in convolutional neural networks, represent a\ntemplate of relations against which the relation tensor is compared at each\ngrouping. Repeating this yields representations of higher-order, hierarchical\nrelations. We present the motivation and details of the architecture, together\nwith a set of experiments to demonstrate how relational convolutional networks\ncan provide an effective framework for modeling relational tasks that have\nhierarchical structure.",
          "link": "http://arxiv.org/abs/2310.03240",
          "publishedOn": "2023-10-07T00:42:19.257Z",
          "wordCount": null,
          "title": "Relational Convolutional Networks: A framework for learning representations of hierarchical relations. (arXiv:2310.03240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vallin_J/0/1/0/all/0/1\">Jonatan Vallin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larsson_K/0/1/0/all/0/1\">Karl Larsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larson_M/0/1/0/all/0/1\">Mats G. Larson</a>",
          "description": "We formalize and interpret the geometric structure of $d$-dimensional fully\nconnected ReLU-layers in neural networks. The parameters of a ReLU-layer induce\na natural partition of the input domain, such that in each sector of the\npartition, the ReLU-layer can be greatly simplified. This leads to a geometric\ninterpretation of a ReLU-layer as a projection onto a polyhedral cone followed\nby an affine transformation, in line with the description in\n[doi:10.48550/arXiv.1905.08922] for convolutional networks with ReLU\nactivations. Further, this structure facilitates simplified expressions for\npreimages of the intersection between partition sectors and hyperplanes, which\nis useful when describing decision boundaries in a classification setting. We\ninvestigate this in detail for a feed-forward network with one hidden\nReLU-layer, where we provide results on the geometric complexity of the\ndecision boundary generated by such networks, as well as proving that modulo an\naffine transformation, such a network can only generate $d$ different decision\nboundaries. Finally, the effect of adding more layers to the network is\ndiscussed.",
          "link": "http://arxiv.org/abs/2310.03482",
          "publishedOn": "2023-10-07T00:42:19.228Z",
          "wordCount": null,
          "title": "The Geometric Structure of Fully-Connected ReLU-Layers. (arXiv:2310.03482v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1\">Yang Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weijiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">James Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>",
          "description": "Machine Learning (ML) techniques have found applications in estimating\nchemical kinetics properties. With the accumulated drug molecules identified\nthrough \"AI4drug discovery\", the next imperative lies in AI-driven design for\nhigh-throughput chemical synthesis processes, with the estimation of properties\nof unseen reactions with unexplored molecules. To this end, the existing ML\napproaches for kinetics property prediction are required to be\nOut-Of-Distribution (OOD) generalizable. In this paper, we categorize the OOD\nkinetic property prediction into three levels (structure, condition, and\nmechanism), revealing unique aspects of such problems. Under this framework, we\ncreate comprehensive datasets to benchmark (1) the state-of-the-art ML\napproaches for reaction prediction in the OOD setting and (2) the\nstate-of-the-art graph OOD methods in kinetics property prediction problems.\nOur results demonstrated the challenges and opportunities in OOD kinetics\nproperty prediction. Our datasets and benchmarks can further support research\nin this direction.",
          "link": "http://arxiv.org/abs/2310.03152",
          "publishedOn": "2023-10-07T00:42:19.227Z",
          "wordCount": null,
          "title": "Towards out-of-distribution generalizable predictions of chemical kinetics properties. (arXiv:2310.03152v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03112",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herbinger_J/0/1/0/all/0/1\">Julia Herbinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dandl_S/0/1/0/all/0/1\">Susanne Dandl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ewald_F/0/1/0/all/0/1\">Fiona K. Ewald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loibl_S/0/1/0/all/0/1\">Sofia Loibl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1\">Giuseppe Casalicchio</a>",
          "description": "Surrogate models play a crucial role in retrospectively interpreting complex\nand powerful black box machine learning models via model distillation. This\npaper focuses on using model-based trees as surrogate models which partition\nthe feature space into interpretable regions via decision rules. Within each\nregion, interpretable models based on additive main effects are used to\napproximate the behavior of the black box model, striking for an optimal\nbalance between interpretability and performance. Four model-based tree\nalgorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their\nability to generate such surrogate models. We investigate fidelity,\ninterpretability, stability, and the algorithms' capability to capture\ninteraction effects through appropriate splits. Based on our comprehensive\nanalyses, we finally provide an overview of user-specific recommendations.",
          "link": "http://arxiv.org/abs/2310.03112",
          "publishedOn": "2023-10-07T00:42:19.225Z",
          "wordCount": null,
          "title": "Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saeed_M/0/1/0/all/0/1\">Muhammad Kamran Saeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_A/0/1/0/all/0/1\">Ahmed E. Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khokhar_A/0/1/0/all/0/1\">Ashfaq Khokhar</a>",
          "description": "Massive MIMO is expected to play an important role in the development of 5G\nnetworks. This paper addresses the issue of pilot contamination and scalability\nin massive MIMO systems. The current practice of reusing orthogonal pilot\nsequences in adjacent cells leads to difficulty in differentiating incoming\ninter- and intra-cell pilot sequences. One possible solution is to increase the\nnumber of orthogonal pilot sequences, which results in dedicating more space of\ncoherence block to pilot transmission than data transmission. This, in turn,\nalso hinders the scalability of massive MIMO systems, particularly in\naccommodating a large number of IoT devices within a cell. To overcome these\nchallenges, this paper devises an innovative pilot allocation scheme based on\nthe data transfer patterns of IoT devices. The scheme assigns orthogonal pilot\nsequences to clusters of devices instead of individual devices, allowing\nmultiple devices to utilize the same pilot for periodically transmitting data.\nMoreover, we formulate the pilot assignment problem as a graph coloring problem\nand use the max k-cut graph partitioning approach to overcome the pilot\ncontamination in a multicell massive MIMO system. The proposed scheme\nsignificantly improves the spectral efficiency and enables the scalability of\nmassive MIMO systems; for instance, by using ten orthogonal pilot sequences, we\nare able to accommodate 200 devices with only a 12.5% omission rate.",
          "link": "http://arxiv.org/abs/2310.03278",
          "publishedOn": "2023-10-07T00:42:19.225Z",
          "wordCount": null,
          "title": "Mitigating Pilot Contamination and Enabling IoT Scalability in Massive MIMO Systems. (arXiv:2310.03278v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Deqian Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "This paper proposes a latent prompt Transformer model for solving challenging\noptimization problems such as molecule design, where the goal is to find\nmolecules with optimal values of a target chemical or biological property that\ncan be computed by an existing software. Our proposed model consists of three\ncomponents. (1) A latent vector whose prior distribution is modeled by a Unet\ntransformation of a Gaussian white noise vector. (2) A molecule generation\nmodel that generates the string-based representation of molecule conditional on\nthe latent vector in (1). We adopt the causal Transformer model that takes the\nlatent vector in (1) as prompt. (3) A property prediction model that predicts\nthe value of the target property of a molecule based on a non-linear regression\non the latent vector in (1). We call the proposed model the latent prompt\nTransformer model. After initial training of the model on existing molecules\nand their property values, we then gradually shift the model distribution\ntowards the region that supports desired values of the target property for the\npurpose of molecule design. Our experiments show that our proposed model\nachieves state of the art performances on several benchmark molecule design\ntasks.",
          "link": "http://arxiv.org/abs/2310.03253",
          "publishedOn": "2023-10-07T00:42:19.224Z",
          "wordCount": null,
          "title": "Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Song Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1\">Xiangrui Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huestis_Mitchell_S/0/1/0/all/0/1\">Sarah A Huestis-Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shixiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1\">Alinson Santos Xavier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_F/0/1/0/all/0/1\">Feng Qiu</a>",
          "description": "Energy justice is a growing area of interest in interdisciplinary energy\nresearch. However, identifying systematic biases in the energy sector remains\nchallenging due to confounding variables, intricate heterogeneity in treatment\neffects, and limited data availability. To address these challenges, we\nintroduce a novel approach for counterfactual causal analysis centered on\nenergy justice. We use subgroup analysis to manage diverse factors and leverage\nthe idea of transfer learning to mitigate data scarcity in each subgroup. In\nour numerical analysis, we apply our method to a large-scale customer-level\npower outage data set and investigate the counterfactual effect of demographic\nfactors, such as income and age of the population, on power outage durations.\nOur results indicate that low-income and elderly-populated areas consistently\nexperience longer power outages, regardless of weather conditions. This points\nto existing biases in the power system and highlights the need for focused\nimprovements in areas with economic challenges.",
          "link": "http://arxiv.org/abs/2310.03258",
          "publishedOn": "2023-10-07T00:42:19.224Z",
          "wordCount": null,
          "title": "Detecting Electricity Service Equity Issues with Transfer Counterfactual Learning on Large-Scale Outage Datasets. (arXiv:2310.03258v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montaruli_B/0/1/0/all/0/1\">Biagio Montaruli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demetrio_L/0/1/0/all/0/1\">Luca Demetrio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1\">Maura Pintor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Compagna_L/0/1/0/all/0/1\">Luca Compagna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balzarotti_D/0/1/0/all/0/1\">Davide Balzarotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>",
          "description": "Machine-learning phishing webpage detectors (ML-PWD) have been shown to\nsuffer from adversarial manipulations of the HTML code of the input webpage.\nNevertheless, the attacks recently proposed have demonstrated limited\neffectiveness due to their lack of optimizing the usage of the adopted\nmanipulations, and they focus solely on specific elements of the HTML code. In\nthis work, we overcome these limitations by first designing a novel set of\nfine-grained manipulations which allow to modify the HTML code of the input\nphishing webpage without compromising its maliciousness and visual appearance,\ni.e., the manipulations are functionality- and rendering-preserving by design.\nWe then select which manipulations should be applied to bypass the target\ndetector by a query-efficient black-box optimization algorithm. Our experiments\nshow that our attacks are able to raze to the ground the performance of current\nstate-of-the-art ML-PWD using just 30 queries, thus overcoming the weaker\nattacks developed in previous work, and enabling a much fairer robustness\nevaluation of ML-PWD.",
          "link": "http://arxiv.org/abs/2310.03166",
          "publishedOn": "2023-10-07T00:42:19.222Z",
          "wordCount": null,
          "title": "Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors. (arXiv:2310.03166v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Su Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durlofsky_L/0/1/0/all/0/1\">Louis J. Durlofsky</a>",
          "description": "History matching based on monitoring data will enable uncertainty reduction,\nand thus improved aquifer management, in industrial-scale carbon storage\noperations. In traditional model-based data assimilation, geomodel parameters\nare modified to force agreement between flow simulation results and\nobservations. In data-space inversion (DSI), history-matched quantities of\ninterest, e.g., posterior pressure and saturation fields conditioned to\nobservations, are inferred directly, without constructing posterior geomodels.\nThis is accomplished efficiently using a set of O(1000) prior simulation\nresults, data parameterization, and posterior sampling within a Bayesian\nsetting. In this study, we develop and implement (in DSI) a deep-learning-based\nparameterization to represent spatio-temporal pressure and CO2 saturation\nfields at a set of time steps. The new parameterization uses an adversarial\nautoencoder (AAE) for dimension reduction and a convolutional long short-term\nmemory (convLSTM) network to represent the spatial distribution and temporal\nevolution of the pressure and saturation fields. This parameterization is used\nwith an ensemble smoother with multiple data assimilation (ESMDA) in the DSI\nframework to enable posterior predictions. A realistic 3D system characterized\nby prior geological realizations drawn from a range of geological scenarios is\nconsidered. A local grid refinement procedure is introduced to estimate the\nerror covariance term that appears in the history matching formulation.\nExtensive history matching results are presented for various quantities, for\nmultiple synthetic true models. Substantial uncertainty reduction in posterior\npressure and saturation fields is achieved in all cases. The framework is\napplied to efficiently provide posterior predictions for a range of error\ncovariance specifications. Such an assessment would be expensive using a\nmodel-based approach.",
          "link": "http://arxiv.org/abs/2310.03228",
          "publishedOn": "2023-10-07T00:42:19.221Z",
          "wordCount": null,
          "title": "History Matching for Geological Carbon Storage using Data-Space Inversion with Spatio-Temporal Data Parameterization. (arXiv:2310.03228v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.14073",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saremi_M/0/1/0/all/0/1\">Mehrzad Saremi</a>",
          "description": "We propose a graphical structure for structural equation models that is\nstable under marginalization under linearity and Gaussianity assumptions. We\nshow that computing the maximum likelihood estimation of this model is\nequivalent to training a neural network. We implement a GPU-based algorithm\nthat computes the maximum likelihood estimation of these models.",
          "link": "http://arxiv.org/abs/2309.14073",
          "publishedOn": "2023-10-07T00:42:19.219Z",
          "wordCount": null,
          "title": "Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.11004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huayu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ditzler_G/0/1/0/all/0/1\">Gregory Ditzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roveda_J/0/1/0/all/0/1\">Janet Roveda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ao Li</a>",
          "description": "Knowledge distillation constitutes a potent methodology for condensing\nsubstantial neural networks into more compact and efficient counterparts.\nWithin this context, softmax regression representation learning serves as a\nwidely embraced approach, leveraging a pre-established teacher network to guide\nthe learning process of a diminutive student network. Notably, despite the\nextensive inquiry into the efficacy of softmax regression representation\nlearning, the intricate underpinnings governing the knowledge transfer\nmechanism remain inadequately elucidated. This study introduces the 'Ideal\nJoint Classifier Knowledge Distillation' (IJCKD) framework, an overarching\nparadigm that not only furnishes a lucid and exhaustive comprehension of\nprevailing knowledge distillation techniques but also establishes a theoretical\nunderpinning for prospective investigations. Employing mathematical\nmethodologies derived from domain adaptation theory, this investigation\nconducts a comprehensive examination of the error boundary of the student\nnetwork contingent upon the teacher network. Consequently, our framework\nfacilitates efficient knowledge transference between teacher and student\nnetworks, thereby accommodating a diverse spectrum of applications.",
          "link": "http://arxiv.org/abs/2304.11004",
          "publishedOn": "2023-10-07T00:42:19.217Z",
          "wordCount": null,
          "title": "Knowledge Distillation Under Ideal Joint Classifier Assumption. (arXiv:2304.11004v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zherui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeow_R/0/1/0/all/0/1\">Raye Chen-Hua Yeow</a>",
          "description": "Real-time intelligent detection and prediction of subjects' behavior\nparticularly their movements or actions is critical in the ward. This approach\noffers the advantage of reducing in-hospital care costs and improving the\nefficiency of healthcare workers, which is especially true for scenarios at\nnight or during peak admission periods. Therefore, in this work, we propose\nusing computer vision (CV) and deep learning (DL) methods for detecting\nsubjects and recognizing their actions. We utilize OpenPose as an accurate\nsubject detector for recognizing the positions of human subjects in the video\nstream. Additionally, we employ AlphAction's Asynchronous Interaction\nAggregation (AIA) network to predict the actions of detected subjects. This\nintegrated model, referred to as PoseAction, is proposed. At the same time, the\nproposed model is further trained to predict 12 common actions in ward areas,\nsuch as staggering, chest pain, and falling down, using medical-related video\nclips from the NTU RGB+D and NTU RGB+D 120 datasets. The results demonstrate\nthat PoseAction achieves the highest classification mAP of 98.72% (IoU@0.5).\nAdditionally, this study develops an online real-time mode for action\nrecognition, which strongly supports the clinical translation of PoseAction.\nFurthermore, using OpenPose's function for recognizing face key points, we also\nimplement face blurring, which is a practical solution to address the privacy\nprotection concerns of patients and healthcare workers. Nevertheless, the\ntraining data for PoseAction is currently limited, particularly in terms of\nlabel diversity. Consequently, the subsequent step involves utilizing a more\ndiverse dataset (including general actions) to train the model's parameters for\nimproved generalization.",
          "link": "http://arxiv.org/abs/2310.03288",
          "publishedOn": "2023-10-07T00:42:19.212Z",
          "wordCount": null,
          "title": "PoseAction: Action Recognition for Patients in the Ward using Deep Learning Approaches. (arXiv:2310.03288v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangjun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bak_J/0/1/0/all/0/1\">JinYeong Bak</a>",
          "description": "Transformers have demonstrated their success in various domains and tasks.\nHowever, Transformers struggle with long input sequences due to their limited\ncapacity. While one solution is to increase input length, endlessly stretching\nthe length is unrealistic. Furthermore, humans selectively remember and use\nonly relevant information from inputs, unlike Transformers which process all\nraw data from start to end. We introduce Memoria, a general memory network that\napplies Hebbian theory which is a major theory explaining human memory\nformulation to enhance long-term dependencies in neural networks. Memoria\nstores and retrieves information called engram at multiple memory levels of\nworking memory, short-term memory, and long-term memory, using connection\nweights that change according to Hebb's rule. Through experiments with popular\nTransformer-based models like BERT and GPT, we present that Memoria\nsignificantly improves the ability to consider long-term dependencies in\nvarious tasks. Results show that Memoria outperformed existing methodologies in\nsorting and language modeling, and long text classification.",
          "link": "http://arxiv.org/abs/2310.03052",
          "publishedOn": "2023-10-07T00:42:19.211Z",
          "wordCount": null,
          "title": "Memoria: Hebbian Memory Architecture for Human-Like Sequential Processing. (arXiv:2310.03052v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_W/0/1/0/all/0/1\">William Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medina_A/0/1/0/all/0/1\">Andr&#xe9;s Mu&#xf1;oz Medina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribero_M/0/1/0/all/0/1\">M&#xf3;nica Ribero</a>",
          "description": "Unsupervised pre-training is a common step in developing computer vision\nmodels and large language models. In this setting, the absence of labels\nrequires the use of similarity-based loss functions, such as contrastive loss,\nthat favor minimizing the distance between similar inputs and maximizing the\ndistance between distinct inputs. As privacy concerns mount, training these\nmodels using differential privacy has become more important. However, due to\nhow inputs are generated for these losses, one of their undesirable properties\nis that their $L_2$ sensitivity can grow with increasing batch size. This\nproperty is particularly disadvantageous for differentially private training\nmethods, such as DP-SGD. To overcome this issue, we develop a new DP-SGD\nvariant for similarity based loss functions -- in particular the commonly used\ncontrastive loss -- that manipulates gradients of the objective function in a\nnovel way to obtain a senstivity of the summed gradient that is $O(1)$ for\nbatch size $n$. We test our DP-SGD variant on some preliminary CIFAR-10\npre-training and CIFAR-100 finetuning tasks and show that, in both tasks, our\nmethod's performance comes close to that of a non-private model and generally\noutperforms DP-SGD applied directly to the contrastive loss.",
          "link": "http://arxiv.org/abs/2310.03104",
          "publishedOn": "2023-10-07T00:42:19.211Z",
          "wordCount": null,
          "title": "DP-SGD for non-decomposable objective functions. (arXiv:2310.03104v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Urchs_S/0/1/0/all/0/1\">Stefanie Urchs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thurner_V/0/1/0/all/0/1\">Veronika Thurner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1\">Matthias A&#xdf;enmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heumann_C/0/1/0/all/0/1\">Christian Heumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiemichen_S/0/1/0/all/0/1\">Stephanie Thiemichen</a>",
          "description": "With the introduction of ChatGPT, OpenAI made large language models (LLM)\naccessible to users with limited IT expertise. However, users with no\nbackground in natural language processing (NLP) might lack a proper\nunderstanding of LLMs. Thus the awareness of their inherent limitations, and\ntherefore will take the systems' output at face value. In this paper, we\nsystematically analyse prompts and the generated responses to identify possible\nproblematic issues with a special focus on gender biases, which users need to\nbe aware of when processing the system's output. We explore how ChatGPT reacts\nin English and German if prompted to answer from a female, male, or neutral\nperspective. In an in-depth investigation, we examine selected prompts and\nanalyse to what extent responses differ if the system is prompted several times\nin an identical way. On this basis, we show that ChatGPT is indeed useful for\nhelping non-IT users draft texts for their daily work. However, it is\nabsolutely crucial to thoroughly check the system's responses for biases as\nwell as for syntactic and grammatical mistakes.",
          "link": "http://arxiv.org/abs/2310.03031",
          "publishedOn": "2023-10-07T00:42:19.208Z",
          "wordCount": null,
          "title": "How Prevalent is Gender Bias in ChatGPT? -- Exploring German and English ChatGPT Responses. (arXiv:2310.03031v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gondur_R/0/1/0/all/0/1\">Rabia Gondur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikandar_U/0/1/0/all/0/1\">Usama Bin Sikandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaffer_E/0/1/0/all/0/1\">Evan Schaffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aoi_M/0/1/0/all/0/1\">Mikio Christian Aoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keeley_S/0/1/0/all/0/1\">Stephen L Keeley</a>",
          "description": "Characterizing the relationship between neural population activity and\nbehavioral data is a central goal of neuroscience. While latent variable models\n(LVMs) are successful in describing high-dimensional time-series data, they are\ntypically only designed for a single type of data, making it difficult to\nidentify structure shared across different experimental data modalities. Here,\nwe address this shortcoming by proposing an unsupervised LVM which extracts\ntemporally evolving shared and independent latents for distinct, simultaneously\nrecorded experimental modalities. We do this by combining Gaussian Process\nFactor Analysis (GPFA), an interpretable LVM for neural spiking data with\ntemporally smooth latent space, with Gaussian Process Variational Autoencoders\n(GP-VAEs), which similarly use a GP prior to characterize correlations in a\nlatent space, but admit rich expressivity due to a deep neural network mapping\nto observations. We achieve interpretability in our model by partitioning\nlatent variability into components that are either shared between or\nindependent to each modality. We parameterize the latents of our model in the\nFourier domain, and show improved latent identification using this approach\nover standard GP-VAE methods. We validate our model on simulated multi-modal\ndata consisting of Poisson spike counts and MNIST images that scale and rotate\nsmoothly over time. We show that the multi-modal GP-VAE (MM-GPVAE) is able to\nnot only identify the shared and independent latent structure across modalities\naccurately, but provides good reconstructions of both images and neural rates\non held-out trials. Finally, we demonstrate our framework on two real world\nmulti-modal experimental settings: Drosophila whole-brain calcium imaging\nalongside tracked limb positions, and Manduca sexta spike train measurements\nfrom ten wing muscles as the animal tracks a visual stimulus.",
          "link": "http://arxiv.org/abs/2310.03111",
          "publishedOn": "2023-10-07T00:42:19.208Z",
          "wordCount": null,
          "title": "Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data. (arXiv:2310.03111v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javadinia_S/0/1/0/all/0/1\">Samaneh Javadinia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baniasadi_A/0/1/0/all/0/1\">Amirali Baniasadi</a>",
          "description": "Convolutional Neural Networks (CNNs) have produced state-of-the-art results\nfor image classification tasks. However, they are limited in their ability to\nhandle rotational and viewpoint variations due to information loss in\nmax-pooling layers. Capsule Networks (CapsNets) employ a\ncomputationally-expensive iterative process referred to as dynamic routing to\naddress these issues. CapsNets, however, often fall short on complex datasets\nand require more computational resources than CNNs. To overcome these\nchallenges, we introduce the Parallel Dynamic Routing CapsNet (PDR-CapsNet), a\ndeeper and more energy-efficient alternative to CapsNet that offers superior\nperformance, less energy consumption, and lower overfitting rates. By\nleveraging a parallelization strategy, PDR-CapsNet mitigates the computational\ncomplexity of CapsNet and increases throughput, efficiently using hardware\nresources. As a result, we achieve 83.55\\% accuracy while requiring 87.26\\%\nfewer parameters, 32.27\\% and 47.40\\% fewer MACs, and Flops, achieving 3x\nfaster inference and 7.29J less energy consumption on a 2080Ti GPU with 11GB\nVRAM compared to CapsNet and for the CIFAR-10 dataset.",
          "link": "http://arxiv.org/abs/2310.03212",
          "publishedOn": "2023-10-07T00:42:19.207Z",
          "wordCount": null,
          "title": "PDR-CapsNet: an Energy-Efficient Parallel Approach to Dynamic Routing in Capsule Networks. (arXiv:2310.03212v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03206",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chang_T/0/1/0/all/0/1\">Ting-Jui Chang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Shahrampour_S/0/1/0/all/0/1\">Shahin Shahrampour</a>",
          "description": "This paper addresses the distributed online control problem over a network of\nlinear time-invariant (LTI) systems (with possibly unknown dynamics) in the\npresence of adversarial perturbations. There exists a global network cost that\nis characterized by a time-varying convex function, which evolves in an\nadversarial manner and is sequentially and partially observed by local agents.\nThe goal of each agent is to generate a control sequence that can compete with\nthe best centralized control policy in hindsight, which has access to the\nglobal cost. This problem is formulated as a regret minimization. For the case\nof known dynamics, we propose a fully distributed disturbance feedback\ncontroller that guarantees a regret bound of $O(\\sqrt{T}\\log T)$, where $T$ is\nthe time horizon. For the unknown dynamics case, we design a distributed\nexplore-then-commit approach, where in the exploration phase all agents jointly\nlearn the system dynamics, and in the learning phase our proposed control\nalgorithm is applied using each agent system estimate. We establish a regret\nbound of $O(T^{2/3} \\text{poly}(\\log T))$ for this setting.",
          "link": "http://arxiv.org/abs/2310.03206",
          "publishedOn": "2023-10-07T00:42:19.203Z",
          "wordCount": null,
          "title": "Regret Analysis of Distributed Online Control for LTI Systems with Adversarial Disturbances. (arXiv:2310.03206v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1\">Philip M. Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Recent experiments have shown that, often, when training a neural network\nwith gradient descent (GD) with a step size $\\eta$, the operator norm of the\nHessian of the loss grows until it approximately reaches $2/\\eta$, after which\nit fluctuates around this value. The quantity $2/\\eta$ has been called the\n\"edge of stability\" based on consideration of a local quadratic approximation\nof the loss. We perform a similar calculation to arrive at an \"edge of\nstability\" for Sharpness-Aware Minimization (SAM), a variant of GD which has\nbeen shown to improve its generalization. Unlike the case for GD, the resulting\nSAM-edge depends on the norm of the gradient. Using three deep learning\ntraining tasks, we see empirically that SAM operates on the edge of stability\nidentified by this analysis.",
          "link": "http://arxiv.org/abs/2309.12488",
          "publishedOn": "2023-10-07T00:42:19.202Z",
          "wordCount": null,
          "title": "Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03027",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Prakash_M/0/1/0/all/0/1\">M V Sai Prakash</a>, <a href=\"http://arxiv.org/find/physics/1/au:+N_S/0/1/0/all/0/1\">Siddartha Reddy N</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Parab_G/0/1/0/all/0/1\">Ganesh Parab</a>, <a href=\"http://arxiv.org/find/physics/1/au:+V_V/0/1/0/all/0/1\">Varun V</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vaddina_V/0/1/0/all/0/1\">Vishal Vaddina</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gopalakrishnan_S/0/1/0/all/0/1\">Saisubramaniam Gopalakrishnan</a>",
          "description": "Molecular property prediction is a critical task in computational drug\ndiscovery. While recent advances in Graph Neural Networks (GNNs) and\nTransformers have shown to be effective and promising, they face the following\nlimitations: Transformer self-attention does not explicitly consider the\nunderlying molecule structure while GNN feature representation alone is not\nsufficient to capture granular and hidden interactions and characteristics that\ndistinguish similar molecules. To address these limitations, we propose SYN-\nFUSION, a novel approach that synergistically combines pre-trained features\nfrom GNNs and Transformers. This approach provides a comprehensive molecular\nrepresentation, capturing both the global molecule structure and the individual\natom characteristics. Experimental results on MoleculeNet benchmarks\ndemonstrate superior performance, surpassing previous models in 5 out of 7\nclassification datasets and 4 out of 6 regression datasets. The performance of\nSYN-FUSION has been compared with other Graph-Transformer models that have been\njointly trained using a combination of transformer and graph features, and it\nis found that our approach is on par with those models in terms of performance.\nExtensive analysis of the learned fusion model across aspects such as loss,\nlatent space, and weight distribution further validates the effectiveness of\nSYN-FUSION. Finally, an ablation study unequivocally demonstrates that the\nsynergy achieved by SYN-FUSION surpasses the performance of its individual\nmodel components and their ensemble, offering a substantial improvement in\npredicting molecular properties.",
          "link": "http://arxiv.org/abs/2310.03027",
          "publishedOn": "2023-10-07T00:42:19.201Z",
          "wordCount": null,
          "title": "Synergistic Fusion of Graph and Transformer Features for Enhanced Molecular Property Prediction. (arXiv:2310.03027v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bayazit_D/0/1/0/all/0/1\">Deniz Bayazit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foroutan_N/0/1/0/all/0/1\">Negar Foroutan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>",
          "description": "Pretrained language models (LMs) encode implicit representations of knowledge\nin their parameters. However, localizing these representations and\ndisentangling them from each other remains an open problem. In this work, we\ninvestigate whether pretrained language models contain various\nknowledge-critical subnetworks: particular sparse computational subgraphs\nresponsible for encoding specific knowledge the model has memorized. We propose\na multi-objective differentiable weight masking scheme to discover these\nsubnetworks and show that we can use them to precisely remove specific\nknowledge from models while minimizing adverse effects on the behavior of the\noriginal language model. We demonstrate our method on multiple GPT2 variants,\nuncovering highly sparse subnetworks (98%+) that are solely responsible for\nspecific collections of relational knowledge. When these subnetworks are\nremoved, the remaining network maintains most of its initial capacity (modeling\nlanguage and other memorized relational knowledge) but struggles to express the\nremoved knowledge, and suffers performance drops on examples needing this\nremoved knowledge on downstream tasks after finetuning.",
          "link": "http://arxiv.org/abs/2310.03084",
          "publishedOn": "2023-10-07T00:42:19.200Z",
          "wordCount": null,
          "title": "Discovering Knowledge-Critical Subnetworks in Pretrained Language Models. (arXiv:2310.03084v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Navratil_J/0/1/0/all/0/1\">Jiri Navratil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elder_B/0/1/0/all/0/1\">Benjamin Elder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1\">Matthew Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumya Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1\">Prasanna Sattigeri</a>",
          "description": "Accurate quantification of model uncertainty has long been recognized as a\nfundamental requirement for trusted AI. In regression tasks, uncertainty is\ntypically quantified using prediction intervals calibrated to an ad-hoc\noperating point, making evaluation and comparison across different studies\nrelatively difficult. Our work leverages: (1) the concept of operating\ncharacteristics curves and (2) the notion of a gain over a null reference, to\nderive a novel operating point agnostic assessment methodology for prediction\nintervals. The paper defines the Uncertainty Characteristics Curve and\ndemonstrates its utility in selected scenarios. We argue that the proposed\nmethod addresses the current need for comprehensive assessment of prediction\nintervals and thus represents a valuable addition to the uncertainty\nquantification toolbox.",
          "link": "http://arxiv.org/abs/2310.03158",
          "publishedOn": "2023-10-07T00:42:19.192Z",
          "wordCount": null,
          "title": "Assessment of Prediction Intervals Using Uncertainty Characteristics Curves. (arXiv:2310.03158v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Falas_S/0/1/0/all/0/1\">Solon Falas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asprou_M/0/1/0/all/0/1\">Markos Asprou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstantinou_C/0/1/0/all/0/1\">Charalambos Konstantinou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_M/0/1/0/all/0/1\">Maria K. Michael</a>",
          "description": "State estimation is the cornerstone of the power system control center since\nit provides the operating condition of the system in consecutive time\nintervals. This work investigates the application of physics-informed neural\nnetworks (PINNs) for accelerating power systems state estimation in monitoring\nthe operation of power systems. Traditional state estimation techniques often\nrely on iterative algorithms that can be computationally intensive,\nparticularly for large-scale power systems. In this paper, a novel approach\nthat leverages the inherent physical knowledge of power systems through the\nintegration of PINNs is proposed. By incorporating physical laws as prior\nknowledge, the proposed method significantly reduces the computational\ncomplexity associated with state estimation while maintaining high accuracy.\nThe proposed method achieves up to 11% increase in accuracy, 75% reduction in\nstandard deviation of results, and 30% faster convergence, as demonstrated by\ncomprehensive experiments on the IEEE 14-bus system.",
          "link": "http://arxiv.org/abs/2310.03088",
          "publishedOn": "2023-10-07T00:42:19.131Z",
          "wordCount": null,
          "title": "Physics-Informed Neural Networks for Accelerating Power System State Estimation. (arXiv:2310.03088v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03106",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nejat_P/0/1/0/all/0/1\">Peyman Nejat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alsaafin_A/0/1/0/all/0/1\">Areej Alsaafin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alabtah_G/0/1/0/all/0/1\">Ghazal Alabtah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Comfere_N/0/1/0/all/0/1\">Nneka Comfere</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mangold_A/0/1/0/all/0/1\">Aaron Mangold</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murphree_D/0/1/0/all/0/1\">Dennis Murphree</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zot_P/0/1/0/all/0/1\">Patricija Zot</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yasir_S/0/1/0/all/0/1\">Saba Yasir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garcia_J/0/1/0/all/0/1\">Joaquin J. Garcia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1\">H.R. Tizhoosh</a>",
          "description": "Patching gigapixel whole slide images (WSIs) is an important task in\ncomputational pathology. Some methods have been proposed to select a subset of\npatches as WSI representation for downstream tasks. While most of the\ncomputational pathology tasks are designed to classify or detect the presence\nof pathological lesions in each WSI, the confounding role and redundant nature\nof normal histology in tissue samples are generally overlooked in WSI\nrepresentations. In this paper, we propose and validate the concept of an\n\"atlas of normal tissue\" solely using samples of WSIs obtained from normal\ntissue biopsies. Such atlases can be employed to eliminate normal fragments of\ntissue samples and hence increase the representativeness collection of patches.\nWe tested our proposed method by establishing a normal atlas using 107 normal\nskin WSIs and demonstrated how established indexes and search engines like\nYottixel can be improved. We used 553 WSIs of cutaneous squamous cell carcinoma\n(cSCC) to show the advantage. We also validated our method applied to an\nexternal dataset of 451 breast WSIs. The number of selected WSI patches was\nreduced by 30% to 50% after utilizing the proposed normal atlas while\nmaintaining the same indexing and search performance in leave-one-patinet-out\nvalidation for both datasets. We show that the proposed normal atlas shows\npromise for unsupervised selection of the most representative patches of the\nabnormal/malignant WSI lesions.",
          "link": "http://arxiv.org/abs/2310.03106",
          "publishedOn": "2023-10-07T00:42:19.103Z",
          "wordCount": null,
          "title": "Creating an Atlas of Normal Tissue for Pruning WSI Patching Through Anomaly Detection. (arXiv:2310.03106v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_M/0/1/0/all/0/1\">Murong Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Liang Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Ziyu Yao</a>",
          "description": "Large language models (LLMs) such as GPT-4 have exhibited remarkable\nperformance in a variety of tasks, but this strong performance often comes with\nthe high expense of using paid API services. In this paper, we are motivated to\nstudy building an LLM cascade to save the cost of using LLMs, particularly for\nperforming reasoning (e.g., mathematical, causal) tasks. Our cascade pipeline\nfollows the intuition that simpler questions can be addressed by a weaker but\nmore affordable LLM, whereas only the challenging questions necessitate the\nstronger and more expensive LLM. To realize this decision-making, we consider\nthe \"answer consistency\" of the weaker LLM as a signal of the question\ndifficulty and propose several methods for the answer sampling and consistency\nchecking, including one leveraging a mixture of two thought representations\n(i.e., Chain-of-Thought and Program-of-Thought). Through experiments on six\nreasoning benchmark datasets, with GPT-3.5-turbo and GPT-4 being the weaker and\nstronger LLMs, respectively, we demonstrate that our proposed LLM cascades can\nachieve performance comparable to using solely the stronger LLM but require\nonly 40% of its cost.",
          "link": "http://arxiv.org/abs/2310.03094",
          "publishedOn": "2023-10-07T00:42:19.100Z",
          "wordCount": null,
          "title": "Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning. (arXiv:2310.03094v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kariyawasam_H/0/1/0/all/0/1\">Hasindu Kariyawasam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hettiarachchi_R/0/1/0/all/0/1\">Ramith Hettiarachchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadduwage_D/0/1/0/all/0/1\">Dushan Wadduwage</a>",
          "description": "Optical neural architectures (ONAs) use coding elements with optimized\nphysical parameters to perform intelligent measurements. However, fabricating\nONAs while maintaining design performances is challenging. Limitations in\nfabrication techniques often limit the realizable precision of the trained\nparameters. Physical constraints may also limit the range of values the\nphysical parameters can hold. Thus, ONAs should be trained within the\nimplementable constraints. However, such physics-based constraints reduce the\ntraining objective to a constrained optimization problem, making it harder to\noptimize with existing gradient-based methods. To alleviate these critical\nissues that degrade performance from simulation to realization we propose a\nphysics-informed quantization-aware training framework. Our approach accounts\nfor the physical constraints during the training process, leading to robust\ndesigns. We evaluate our approach on an ONA proposed in the literature, named a\ndiffractive deep neural network (D2NN), for all-optical phase imaging and for\nclassification of phase objects. With extensive experiments on different\nquantization levels and datasets, we show that our approach leads to ONA\ndesigns that are robust to quantization noise.",
          "link": "http://arxiv.org/abs/2310.03049",
          "publishedOn": "2023-10-07T00:42:19.099Z",
          "wordCount": null,
          "title": "QuATON: Quantization Aware Training of Optical Neurons. (arXiv:2310.03049v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berlyand_L/0/1/0/all/0/1\">Leonid Berlyand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandier_E/0/1/0/all/0/1\">Etienne Sandier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmalo_Y/0/1/0/all/0/1\">Yitzchak Shmalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>",
          "description": "In this study, we explore the applications of random matrix theory (RMT) in\nthe training of deep neural networks (DNNs), focusing on layer pruning to\nsimplify DNN architecture and loss landscape. RMT, recently used to address\noverfitting in deep learning, enables the examination of DNN's weight layer\nspectra. We use these techniques to optimally determine the number of singular\nvalues to be removed from the weight layers of a DNN during training via\nsingular value decomposition (SVD). This process aids in DNN simplification and\naccuracy enhancement, as evidenced by training simple DNN models on the MNIST\nand Fashion MNIST datasets.\n\nOur method can be applied to any fully connected or convolutional layer of a\npretrained DNN, decreasing the layer's parameters and simplifying the DNN\narchitecture while preserving or even enhancing the model's accuracy. By\ndiscarding small singular values based on RMT criteria, the accuracy of the\ntest set remains consistent, facilitating more efficient DNN training without\ncompromising performance.\n\nWe provide both theoretical and empirical evidence supporting our claim that\nthe elimination of small singular values based on RMT does not negatively\nimpact the DNN's accuracy. Our results offer valuable insights into the\npractical application of RMT for the creation of more efficient and accurate\ndeep-learning models.",
          "link": "http://arxiv.org/abs/2310.03165",
          "publishedOn": "2023-10-07T00:42:19.099Z",
          "wordCount": null,
          "title": "Enhancing Accuracy in Deep Learning Using Random Matrix Theory. (arXiv:2310.03165v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03480",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dabike_G/0/1/0/all/0/1\">Gerardo Roa Dabike</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Akeroyd_M/0/1/0/all/0/1\">Michael A. Akeroyd</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bannister_S/0/1/0/all/0/1\">Scott Bannister</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barker_J/0/1/0/all/0/1\">Jon Barker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cox_T/0/1/0/all/0/1\">Trevor J. Cox</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fazenda_B/0/1/0/all/0/1\">Bruno Fazenda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Firth_J/0/1/0/all/0/1\">Jennifer Firth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Graetzer_S/0/1/0/all/0/1\">Simone Graetzer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greasley_A/0/1/0/all/0/1\">Alinka Greasley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vos_R/0/1/0/all/0/1\">Rebecca Vos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Whitmer_W/0/1/0/all/0/1\">William Whitmer</a>",
          "description": "The Cadenza project aims to enhance the audio quality of music for\nindividuals with hearing loss. As part of this, the project is organizing the\nICASSP SP Cadenza Challenge: Music Demixing/Remixing for Hearing Aids. The\nchallenge can be tackled by decomposing the music at the hearing aid\nmicrophones into vocals, bass, drums, and other components. These can then be\nintelligently remixed in a personalized manner to improve audio quality.\nAlternatively, an end-to-end approach could be used. Processes need to consider\nthe music itself, the gain applied to each component, and the listener's\nhearing loss. The submitted entries will be evaluated using the intrusive\nobjective metric, the Hearing Aid Audio Quality Index (HAAQI). This paper\noutlines the challenge.",
          "link": "http://arxiv.org/abs/2310.03480",
          "publishedOn": "2023-10-07T00:42:19.099Z",
          "wordCount": null,
          "title": "The Cadenza ICASSP 2024 Grand Challenge. (arXiv:2310.03480v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wachi_A/0/1/0/all/0/1\">Akifumi Wachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_W/0/1/0/all/0/1\">Wataru Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_K/0/1/0/all/0/1\">Kazumune Hashimoto</a>",
          "description": "Safe exploration is essential for the practical use of reinforcement learning\n(RL) in many real-world scenarios. In this paper, we present a generalized safe\nexploration (GSE) problem as a unified formulation of common safe exploration\nproblems. We then propose a solution of the GSE problem in the form of a\nmeta-algorithm for safe exploration, MASE, which combines an unconstrained RL\nalgorithm with an uncertainty quantifier to guarantee safety in the current\nepisode while properly penalizing unsafe explorations before actual safety\nviolation to discourage them in future episodes. The advantage of MASE is that\nwe can optimize a policy while guaranteeing with a high probability that no\nsafety constraint will be violated under proper assumptions. Specifically, we\npresent two variants of MASE with different constructions of the uncertainty\nquantifier: one based on generalized linear models with theoretical guarantees\nof safety and near-optimality, and another that combines a Gaussian process to\nensure safety with a deep RL algorithm to maximize the reward. Finally, we\ndemonstrate that our proposed algorithm achieves better performance than\nstate-of-the-art algorithms on grid-world and Safety Gym benchmarks without\nviolating any safety constraints, even during training.",
          "link": "http://arxiv.org/abs/2310.03225",
          "publishedOn": "2023-10-07T00:42:19.098Z",
          "wordCount": null,
          "title": "Safe Exploration in Reinforcement Learning: A Generalized Formulation and Algorithms. (arXiv:2310.03225v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1\">Tony Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_M/0/1/0/all/0/1\">Mohit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ester_M/0/1/0/all/0/1\">Martin Ester</a>",
          "description": "We seek to automate the generation of drug-like compounds conditioned to\nspecific protein pocket targets. Most current methods approximate the\nprotein-molecule distribution of a finite dataset and, therefore struggle to\ngenerate molecules with significant binding improvement over the training\ndataset. We instead frame the pocket-conditioned molecular generation task as\nan RL problem and develop TacoGFN, a target conditional Generative Flow Network\nmodel. Our method is explicitly encouraged to generate molecules with desired\nproperties as opposed to fitting on a pre-existing data distribution. To this\nend, we develop transformer-based docking score prediction to speed up docking\nscore computation and propose TacoGFN to explore molecule space efficiently.\nFurthermore, we incorporate several rounds of active learning where generated\nsamples are queried using a docking oracle to improve the docking score\nprediction. This approach allows us to accurately explore as much of the\nmolecule landscape as we can afford computationally. Empirically, molecules\ngenerated using TacoGFN and its variants significantly outperform all baseline\nmethods across every property (Docking score, QED, SA, Lipinski), while being\norders of magnitude faster.",
          "link": "http://arxiv.org/abs/2310.03223",
          "publishedOn": "2023-10-07T00:42:19.097Z",
          "wordCount": null,
          "title": "TacoGFN: Target Conditioned GFlowNet for Structure-Based Drug Design. (arXiv:2310.03223v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Durand_J/0/1/0/all/0/1\">Jean-Guillaume Durand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubois_A/0/1/0/all/0/1\">Arthur Dubois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moss_R/0/1/0/all/0/1\">Robert J. Moss</a>",
          "description": "Over the past decade, machine learning has demonstrated impressive results,\noften surpassing human capabilities in sensing tasks relevant to autonomous\nflight. Unlike traditional aerospace software, the parameters of machine\nlearning models are not hand-coded nor derived from physics but learned from\ndata. They are automatically adjusted during a training phase, and their values\ndo not usually correspond to physical requirements. As a result, requirements\ncannot be directly traced to lines of code, hindering the current bottom-up\naerospace certification paradigm. This paper attempts to address this gap by 1)\ndemystifying the inner workings and processes to build machine learning models,\n2) formally establishing theoretical guarantees given by those processes, and\n3) complementing these formal elements with practical considerations to develop\na complete certification argument for safety-critical machine learning systems.\nBased on a scalable statistical verifier, our proposed framework is\nmodel-agnostic and tool-independent, making it adaptable to many use cases in\nthe industry. We demonstrate results on a widespread application in autonomous\nflight: vision-based landing.",
          "link": "http://arxiv.org/abs/2310.03217",
          "publishedOn": "2023-10-07T00:42:19.094Z",
          "wordCount": null,
          "title": "Formal and Practical Elements for the Certification of Machine Learning Systems. (arXiv:2310.03217v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luong_K/0/1/0/all/0/1\">Kha-Dinh Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Ambuj Singh</a>",
          "description": "Property prediction on molecular graphs is an important application of Graph\nNeural Networks (GNNs). Recently, unlabeled molecular data has become abundant,\nwhich facilitates the rapid development of self-supervised learning for GNNs in\nthe chemical domain. In this work, we propose pretraining GNNs at the fragment\nlevel, which serves as a promising middle ground to overcome the limitations of\nnode-level and graph-level pretraining. Borrowing techniques from recent work\non principle subgraph mining, we obtain a compact vocabulary of prevalent\nfragments that span a large pretraining dataset. From the extracted vocabulary,\nwe introduce several fragment-based contrastive and predictive pretraining\ntasks. The contrastive learning task jointly pretrains two different GNNs: one\nbased on molecular graphs and one based on fragment graphs, which represents\nhigh-order connectivity within molecules. By enforcing the consistency between\nthe fragment embedding and the aggregated embedding of the corresponding atoms\nfrom the molecular graphs, we ensure that both embeddings capture structural\ninformation at multiple resolutions. The structural information of the fragment\ngraphs is further exploited to extract auxiliary labels for the graph-level\npredictive pretraining. We employ both the pretrained molecular-based and\nfragment-based GNNs for downstream prediction, thus utilizing the fragment\ninformation during finetuning. Our models advance the performances on 5 out of\n8 common molecular benchmarks and improve the performances on long-range\nbiological benchmarks by at least 11.5%.",
          "link": "http://arxiv.org/abs/2310.03274",
          "publishedOn": "2023-10-07T00:42:19.094Z",
          "wordCount": null,
          "title": "Fragment-based Pretraining and Finetuning on Molecular Graphs. (arXiv:2310.03274v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishi_H/0/1/0/all/0/1\">Hideyuki Ishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "The symmetry and geometry of input data are considered to be encoded in the\ninternal data representation inside the neural network, but the specific\nencoding rule has been less investigated. By focusing on a joint group\ninvariant function on the data-parameter domain, we present a systematic rule\nto find a dual group action on the parameter domain from a group action on the\ndata domain. Further, we introduce generalized neural networks induced from the\njoint invariant functions, and present a new group theoretic proof of their\nuniversality theorems by using Schur's lemma. Since traditional universality\ntheorems were demonstrated based on functional analytical methods, this study\nsheds light on the group theoretic aspect of the approximation theory,\nconnecting geometric deep learning to abstract harmonic analysis.",
          "link": "http://arxiv.org/abs/2310.03530",
          "publishedOn": "2023-10-07T00:42:19.094Z",
          "wordCount": null,
          "title": "Joint Group Invariant Functions on Data-Parameter Domain Induce Universal Neural Networks. (arXiv:2310.03530v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03030",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Balaji_S/0/1/0/all/0/1\">Suryanarayanan Balaji</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Magar_R/0/1/0/all/0/1\">Rishikesh Magar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jadhav_Y/0/1/0/all/0/1\">Yayati Jadhav</a>, <a href=\"http://arxiv.org/find/physics/1/au:+BaratiFarimani_a/0/1/0/all/0/1\">and Amir BaratiFarimani</a>",
          "description": "With the emergence of Transformer architectures and their powerful\nunderstanding of textual data, a new horizon has opened up to predict the\nmolecular properties based on text description. While SMILES are the most\ncommon form of representation, they are lacking robustness, rich information\nand canonicity, which limit their effectiveness in becoming generalizable\nrepresentations. Here, we present GPT-MolBERTa, a self-supervised large\nlanguage model (LLM) which uses detailed textual descriptions of molecules to\npredict their properties. A text based description of 326000 molecules were\ncollected using ChatGPT and used to train LLM to learn the representation of\nmolecules. To predict the properties for the downstream tasks, both BERT and\nRoBERTa models were used in the finetuning stage. Experiments show that\nGPT-MolBERTa performs well on various molecule property benchmarks, and\napproaching state of the art performance in regression tasks. Additionally,\nfurther analysis of the attention mechanisms show that GPT-MolBERTa is able to\npick up important information from the input textual data, displaying the\ninterpretability of the model.",
          "link": "http://arxiv.org/abs/2310.03030",
          "publishedOn": "2023-10-07T00:42:19.093Z",
          "wordCount": null,
          "title": "GPT-MolBERTa: GPT Molecular Features Language Model for molecular property prediction. (arXiv:2310.03030v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianghong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1\">Joyce C. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agichtein_E/0/1/0/all/0/1\">Eugene Agichtein</a>",
          "description": "Interactive search can provide a better experience by incorporating\ninteraction feedback from the users. This can significantly improve search\naccuracy as it helps avoid irrelevant information and captures the users'\nsearch intents. Existing state-of-the-art (SOTA) systems use reinforcement\nlearning (RL) models to incorporate the interactions but focus on item-level\nfeedback, ignoring the fine-grained information found in sentence-level\nfeedback. Yet such feedback requires extensive RL action space exploration and\nlarge amounts of annotated data. This work addresses these challenges by\nproposing a new deep Q-learning (DQ) approach, DQrank. DQrank adapts BERT-based\nmodels, the SOTA in natural language processing, to select crucial sentences\nbased on users' engagement and rank the items to obtain more satisfactory\nresponses. We also propose two mechanisms to better explore optimal actions.\nDQrank further utilizes the experience replay mechanism in DQ to store the\nfeedback sentences to obtain a better initial ranking performance. We validate\nthe effectiveness of DQrank on three search datasets. The results show that\nDQRank performs at least 12% better than the previous SOTA RL approaches. We\nalso conduct detailed ablation studies. The ablation results demonstrate that\neach model component can efficiently extract and accumulate long-term\nengagement effects from the users' sentence-level feedback. This structure\noffers new technologies with promised performance to construct a search system\nwith sentence-level interaction.",
          "link": "http://arxiv.org/abs/2310.03043",
          "publishedOn": "2023-10-07T00:42:19.093Z",
          "wordCount": null,
          "title": "A Deep Reinforcement Learning Approach for Interactive Search with Sentence-level Feedback. (arXiv:2310.03043v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03047",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Zhu_S/0/1/0/all/0/1\">Shang Zhu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ramsundar_B/0/1/0/all/0/1\">Bharath Ramsundar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Annevelink_E/0/1/0/all/0/1\">Emil Annevelink</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lin_H/0/1/0/all/0/1\">Hongyi Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Dave_A/0/1/0/all/0/1\">Adarsh Dave</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guan_P/0/1/0/all/0/1\">Pin-Wen Guan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gering_K/0/1/0/all/0/1\">Kevin Gering</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Viswanathan_V/0/1/0/all/0/1\">Venkatasubramanian Viswanathan</a>",
          "description": "Chemical mixtures, satisfying multi-objective performance metrics and\nconstraints, enable their use in chemical processes and electrochemical\ndevices. In this work, we develop a differentiable chemical-physics framework\nfor modeling chemical mixtures, DiffMix, where geometric deep learning (GDL) is\nleveraged to map from molecular species, compositions and environment\nconditions, to physical coefficients in the mixture physics laws. In\nparticular, we extend mixture thermodynamic and transport laws by creating\nlearnable physical coefficients, where we use graph neural networks as the\nmolecule encoder and enforce component-wise permutation-invariance. We start\nour model evaluations with thermodynamics of binary mixtures, and further\nbenchmarked multicomponent electrolyte mixtures on their transport properties,\nin order to test the model generalizability. We show improved prediction\naccuracy and model robustness of DiffMix than its purely data-driven variants.\nFurthermore, we demonstrate the efficient optimization of electrolyte transport\nproperties, built on the gradient obtained using DiffMix auto-differentiation.\nOur simulation runs are then backed up by the data generated by a robotic\nexperimentation setup, Clio. By combining mixture physics and GDL, DiffMix\nexpands the predictive modeling methods for chemical mixtures and provides\nlow-cost optimization approaches in large chemical spaces.",
          "link": "http://arxiv.org/abs/2310.03047",
          "publishedOn": "2023-10-07T00:42:19.091Z",
          "wordCount": null,
          "title": "Differentiable Chemical Physics by Geometric Deep Learning for Gradient-based Property Optimization of Mixtures. (arXiv:2310.03047v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_R/0/1/0/all/0/1\">Ruturaj Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1\">Utkarsh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kale_I/0/1/0/all/0/1\">Ishaan Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shastri_A/0/1/0/all/0/1\">Apoorva Shastri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Anand J Kulkarni</a>",
          "description": "A modified LAB algorithm is introduced in this paper. It builds upon the\noriginal LAB algorithm (Reddy et al. 2023), which is a socio-inspired algorithm\nthat models competitive and learning behaviours within a group, establishing\nhierarchical roles. The proposed algorithm incorporates the roulette wheel\napproach and a reduction factor introducing inter-group competition and\niteratively narrowing down the sample space. The algorithm is validated by\nsolving the benchmark test problems from CEC 2005 and CEC 2017. The solutions\nare validated using standard statistical tests such as two-sided and pairwise\nsigned rank Wilcoxon test and Friedman rank test. The algorithm exhibited\nimproved and superior robustness as well as search space exploration\ncapabilities. Furthermore, a Clustering-Based Search Space Reduction (C-SSR)\nmethod is proposed, making the algorithm capable to solve constrained problems.\nThe C-SSR method enables the algorithm to identify clusters of feasible\nregions, satisfying the constraints and contributing to achieve the optimal\nsolution. This method demonstrates its effectiveness as a potential alternative\nto traditional constraint handling techniques. The results obtained using the\nModified LAB algorithm are then compared with those achieved by other recent\nmetaheuristic algorithms.",
          "link": "http://arxiv.org/abs/2310.03055",
          "publishedOn": "2023-10-07T00:42:19.087Z",
          "wordCount": null,
          "title": "Modified LAB Algorithm with Clustering-based Search Space Reduction Method for solving Engineering Design Problems. (arXiv:2310.03055v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_M/0/1/0/all/0/1\">Mosab Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alhoori_H/0/1/0/all/0/1\">Hamed Alhoori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahimi_M/0/1/0/all/0/1\">Mona Rahimi</a>",
          "description": "Frequent modifications of unit test cases are inevitable due to software's\ncontinuous underlying changes in source code, design, and requirements. Since\nmanually maintaining software test suites is tedious, timely, and costly,\nautomating the process of generation and maintenance of test units will\nsignificantly impact the effectiveness and efficiency of software testing\nprocesses.\n\nTo this end, we propose an automated approach which exploits both structural\nand semantic properties of source code methods and test cases to recommend the\nmost relevant and useful unit tests to the developers. The proposed approach\ninitially trains a neural network to transform method-level source code, as\nwell as unit tests, into distributed representations (embedded vectors) while\npreserving the importance of the structure in the code. Retrieving the semantic\nand structural properties of a given method, the approach computes cosine\nsimilarity between the method's embedding and the previously-embedded training\ninstances. Further, according to the similarity scores between the embedding\nvectors, the model identifies the closest methods of embedding and the\nassociated unit tests as the most similar recommendations.\n\nThe results on the Methods2Test dataset showed that, while there is no\nguarantee to have similar relevant test cases for the group of similar methods,\nthe proposed approach extracts the most similar existing test cases for a given\nmethod in the dataset, and evaluations show that recommended test cases\ndecrease the developers' effort to generating expected test cases.",
          "link": "http://arxiv.org/abs/2310.03174",
          "publishedOn": "2023-10-07T00:42:19.087Z",
          "wordCount": null,
          "title": "Test Case Recommendations with Distributed Representation of Code Syntactic Features. (arXiv:2310.03174v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yijia Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinecke_D/0/1/0/all/0/1\">Dylan Steinecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelletier_A/0/1/0/all/0/1\">Alexander Russell Pelletier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yushi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_P/0/1/0/all/0/1\">Peipei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>",
          "description": "Knowledge graphs (KGs) have emerged as a powerful framework for representing\nand integrating complex biomedical information. However, assembling KGs from\ndiverse sources remains a significant challenge in several aspects, including\nentity alignment, scalability, and the need for continuous updates to keep pace\nwith scientific advancements. Moreover, the representative power of KGs is\noften limited by the scarcity of multi-modal data integration. To overcome\nthese challenges, we propose Know2BIO, a general-purpose heterogeneous KG\nbenchmark for the biomedical domain. Know2BIO integrates data from 30 diverse\nsources, capturing intricate relationships across 11 biomedical categories. It\ncurrently consists of ~219,000 nodes and ~6,200,000 edges. Know2BIO is capable\nof user-directed automated updating to reflect the latest knowledge in\nbiomedical science. Furthermore, Know2BIO is accompanied by multi-modal data:\nnode features including text descriptions, protein and compound sequences and\nstructures, enabling the utilization of emerging natural language processing\nmethods and multi-modal data integration strategies. We evaluate KG\nrepresentation models on Know2BIO, demonstrating its effectiveness as a\nbenchmark for KG representation learning in the biomedical field. Data and\nsource code of Know2BIO are available at\nhttps://github.com/Yijia-Xiao/Know2BIO/.",
          "link": "http://arxiv.org/abs/2310.03221",
          "publishedOn": "2023-10-07T00:42:19.086Z",
          "wordCount": null,
          "title": "Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs. (arXiv:2310.03221v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_I/0/1/0/all/0/1\">Ivan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1\">Eric Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_R/0/1/0/all/0/1\">Ray Gu</a>",
          "description": "The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code will be released at\nhttps://github.com/EvenJoker/Point-PEFT.",
          "link": "http://arxiv.org/abs/2310.03059",
          "publishedOn": "2023-10-07T00:42:19.031Z",
          "wordCount": null,
          "title": "Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models. (arXiv:2310.03059v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Hui Shi</a> (IMB), <a href=\"http://arxiv.org/find/cs/1/au:+Traonmilin_Y/0/1/0/all/0/1\">Yann Traonmilin</a> (IMB), <a href=\"http://arxiv.org/find/cs/1/au:+Aujol_J/0/1/0/all/0/1\">J-F Aujol</a> (IMB)",
          "description": "We consider the problem of denoising with the help of prior information taken\nfrom a database of clean signals or images. Denoising with variational methods\nis very efficient if a regularizer well adapted to the nature of the data is\navailable. Thanks to the maximum a posteriori Bayesian framework, such\nregularizer can be systematically linked with the distribution of the data.\nWith deep neural networks (DNN), complex distributions can be recovered from a\nlarge training database.To reduce the computational burden of this task, we\nadapt the compressive learning framework to the learning of regularizers\nparametrized by DNN. We propose two variants of stochastic gradient descent\n(SGD) for the recovery of deep regularization parameters from a heavily\ncompressed database. These algorithms outperform the initially proposed method\nthat was limited to low-dimensional signals, each iteration using information\nfrom the whole database. They also benefit from classical SGD convergence\nguarantees. Thanks to these improvements we show that this method can be\napplied for patch based image denoising.}",
          "link": "http://arxiv.org/abs/2310.03085",
          "publishedOn": "2023-10-07T00:42:19.030Z",
          "wordCount": null,
          "title": "Batch-less stochastic gradient descent for compressive learning of deep regularization for image denoising. (arXiv:2310.03085v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasarathna_T/0/1/0/all/0/1\">Tharindu Lakshan Yasarathna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navanesan_L/0/1/0/all/0/1\">Lojenaa Navanesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barque_S/0/1/0/all/0/1\">Simon Barque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sayakkara_A/0/1/0/all/0/1\">Assanka Sayakkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Khac_N/0/1/0/all/0/1\">Nhien-An Le-Khac</a>",
          "description": "IoT (Internet of Things) refers to the network of interconnected physical\ndevices, vehicles, home appliances, and other items embedded with sensors,\nsoftware, and connectivity, enabling them to collect and exchange data. IoT\nForensics is collecting and analyzing digital evidence from IoT devices to\ninvestigate cybercrimes, security breaches, and other malicious activities that\nmay have taken place on these connected devices. In particular, EM-SCA has\nbecome an essential tool for IoT forensics due to its ability to reveal\nconfidential information about the internal workings of IoT devices without\ninterfering these devices or wiretapping their networks. However, the accuracy\nand reliability of EM-SCA results can be limited by device variability,\nenvironmental factors, and data collection and processing methods. Besides,\nthere is very few research on these limitations that affects significantly the\naccuracy of EM-SCA approaches for the crossed-IoT device portability as well as\nlimited research on the possible solutions to address such challenge.\nTherefore, this empirical study examines the impact of device variability on\nthe accuracy and reliability of EM-SCA approaches, in particular\nmachine-learning (ML) based approaches for EM-SCA. We firstly presents the\nbackground, basic concepts and techniques used to evaluate the limitations of\ncurrent EM-SCA approaches and datasets. Our study then addresses one of the\nmost important limitation, which is caused by the multi-core architecture of\nthe processors (SoC). We present an approach to collect the EM-SCA datasets and\ndemonstrate the feasibility of using transfer learning to obtain more\nmeaningful and reliable results from EM-SCA in IoT forensics of crossed-IoT\ndevices. Our study moreover contributes a new dataset for using deep learning\nmodels in analysing Electromagnetic Side-Channel data with regards to the\ncross-device portability matter.",
          "link": "http://arxiv.org/abs/2310.03119",
          "publishedOn": "2023-10-07T00:42:18.982Z",
          "wordCount": null,
          "title": "Crossed-IoT device portability of Electromagnetic Side Channel Analysis: Challenges and Dataset. (arXiv:2310.03119v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Csehi_A/0/1/0/all/0/1\">&#xc1;goston Istv&#xe1;n Csehi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jozsa_C/0/1/0/all/0/1\">Csaba M&#xe1;t&#xe9; J&#xf3;zsa</a>",
          "description": "We aim to improve the Inverted Neural Radiance Fields (iNeRF) algorithm which\ndefines the image pose estimation problem as a NeRF based iterative linear\noptimization. NeRFs are novel neural space representation models that can\nsynthesize photorealistic novel views of real-world scenes or objects. Our\ncontributions are as follows: we extend the localization optimization objective\nwith a depth-based loss function, we introduce a multi-image based loss\nfunction where a sequence of images with known relative poses are used without\nincreasing the computational complexity, we omit hierarchical sampling during\nvolumetric rendering, meaning only the coarse model is used for pose\nestimation, and we how that by extending the sampling interval convergence can\nbe achieved even or higher initial pose estimate errors. With the proposed\nmodifications the convergence speed is significantly improved, and the basin of\nconvergence is substantially extended.",
          "link": "http://arxiv.org/abs/2310.03563",
          "publishedOn": "2023-10-07T00:42:18.981Z",
          "wordCount": null,
          "title": "BID-NeRF: RGB-D image pose estimation with inverted Neural Radiance Fields. (arXiv:2310.03563v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yilue Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lifeng Fan</a>",
          "description": "Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories and unseen object categories.",
          "link": "http://arxiv.org/abs/2310.03325",
          "publishedOn": "2023-10-07T00:42:18.980Z",
          "wordCount": null,
          "title": "Learning Concept-Based Visual Causal Transition and Symbolic Reasoning for Visual Planning. (arXiv:2310.03325v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Woojun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jeonghye Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Youngchul Sung</a>",
          "description": "In this paper, a unified framework for exploration in reinforcement learning\n(RL) is proposed based on an option-critic model. The proposed framework learns\nto integrate a set of diverse exploration strategies so that the agent can\nadaptively select the most effective exploration strategy over time to realize\na relevant exploration-exploitation trade-off for each given task. The\neffectiveness of the proposed exploration framework is demonstrated by various\nexperiments in the MiniGrid and Atari environments.",
          "link": "http://arxiv.org/abs/2310.03342",
          "publishedOn": "2023-10-07T00:42:18.980Z",
          "wordCount": null,
          "title": "LESSON: Learning to Integrate Exploration Strategies for Reinforcement Learning via an Option Framework. (arXiv:2310.03342v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03054",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hagemann_P/0/1/0/all/0/1\">Paul Hagemann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hertrich_J/0/1/0/all/0/1\">Johannes Hertrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Altekruger_F/0/1/0/all/0/1\">Fabian Altekr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beinert_R/0/1/0/all/0/1\">Robert Beinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chemseddine_J/0/1/0/all/0/1\">Jannis Chemseddine</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steidl_G/0/1/0/all/0/1\">Gabriele Steidl</a>",
          "description": "We propose conditional flows of the maximum mean discrepancy (MMD) with the\nnegative distance kernel for posterior sampling and conditional generative\nmodeling. This MMD, which is also known as energy distance, has several\nadvantageous properties like efficient computation via slicing and sorting. We\napproximate the joint distribution of the ground truth and the observations\nusing discrete Wasserstein gradient flows and establish an error bound for the\nposterior distributions. Further, we prove that our particle flow is indeed a\nWasserstein gradient flow of an appropriate functional. The power of our method\nis demonstrated by numerical examples including conditional image generation\nand inverse problems like superresolution, inpainting and computed tomography\nin low-dose and limited-angle settings.",
          "link": "http://arxiv.org/abs/2310.03054",
          "publishedOn": "2023-10-07T00:42:18.973Z",
          "wordCount": null,
          "title": "Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Timothy Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>",
          "description": "In-context learning (ICL) is an astonishing emergent ability of large\nlanguage models (LLMs). By presenting a prompt that includes multiple\ninput-output pairs as examples and introducing a new query input, models can\ngenerate the corresponding output. However, the performance of models heavily\nrelies on the quality of the input prompt when implementing in-context\nlearning. Biased or imbalanced input prompts can significantly degrade the\nperformance of language models. To address this issue, we introduce a\nreweighted algorithm called RICL (Reweighted In-context Learning). This\nalgorithm fine-tunes language models using an unbiased validation set to\ndetermine the optimal weight for each input-output example to approximate\nunbiased in-context learning. Furthermore, we also introduce a low-cost\nreweighted algorithm, a linear optimal weight approximation algorithm called\nLARICL (Linear Approximation of Reweighted In-context Learning). This algorithm\nrequires minimal training cost while providing effective results. We prove the\nconvergence of our algorithm and validate its performance through experiments\nconducted on a numerical dataset. The experimental findings reveal a\nsubstantial improvement in comparison to benchmarks including the performance\nof casual prompt-based in-context learning and the performance of a classic\nfine-tuning method.",
          "link": "http://arxiv.org/abs/2310.03331",
          "publishedOn": "2023-10-07T00:42:18.972Z",
          "wordCount": null,
          "title": "Fine-tune Language Models to Approximate Unbiased In-context Learning. (arXiv:2310.03331v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahnama_A/0/1/0/all/0/1\">Amir Hossein Akhavan Rahnama</a>",
          "description": "The number of local model-agnostic explanation techniques proposed has grown\nrapidly recently. One main reason is that the bar for developing new\nexplainability techniques is low due to the lack of optimal evaluation\nmeasures. Without rigorous measures, it is hard to have concrete evidence of\nwhether the new explanation techniques can significantly outperform their\npredecessors. Our study proposes a new taxonomy for evaluating local\nexplanations: robustness, evaluation using ground truth from synthetic datasets\nand interpretable models, model randomization, and human-grounded evaluation.\nUsing this proposed taxonomy, we highlight that all categories of evaluation\nmethods, except those based on the ground truth from interpretable models,\nsuffer from a problem we call the \"blame problem.\" In our study, we argue that\nthis category of evaluation measure is a more reasonable method for evaluating\nlocal model-agnostic explanations. However, we show that even this category of\nevaluation measures has further limitations. The evaluation of local\nexplanations remains an open research problem.",
          "link": "http://arxiv.org/abs/2310.03466",
          "publishedOn": "2023-10-07T00:42:18.972Z",
          "wordCount": null,
          "title": "The Blame Problem in Evaluating Local Explanations, and How to Tackle it. (arXiv:2310.03466v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Minhua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Teng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "Graph Contrastive Learning (GCL) has emerged as a popular unsupervised graph\nrepresentation learning method. However, it has been shown that GCL is\nvulnerable to adversarial attacks on both the graph structure and node\nattributes. Although empirical approaches have been proposed to enhance the\nrobustness of GCL, the certifiable robustness of GCL is still remain\nunexplored. In this paper, we develop the first certifiably robust framework in\nGCL. Specifically, we first propose a unified criteria to evaluate and certify\nthe robustness of GCL. We then introduce a novel technique, RES (Randomized\nEdgedrop Smoothing), to ensure certifiable robustness for any GCL model, and\nthis certified robustness can be provably preserved in downstream tasks.\nFurthermore, an effective training method is proposed for robust GCL. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of our\nproposed method in providing effective certifiable robustness and enhancing the\nrobustness of any GCL model. The source code of RES is available at\nhttps://github.com/ventr1c/RES-GCL.",
          "link": "http://arxiv.org/abs/2310.03312",
          "publishedOn": "2023-10-07T00:42:18.844Z",
          "wordCount": null,
          "title": "Certifiably Robust Graph Contrastive Learning. (arXiv:2310.03312v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1\">Alexander Robey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1\">Eric Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>",
          "description": "Despite efforts to align large language models (LLMs) with human values,\nwidely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to\njailbreaking attacks, wherein an adversary fools a targeted LLM into generating\nobjectionable content. To address this vulnerability, we propose SmoothLLM, the\nfirst algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our\nfinding that adversarially-generated prompts are brittle to character-level\nchanges, our defense first randomly perturbs multiple copies of a given input\nprompt, and then aggregates the corresponding predictions to detect adversarial\ninputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to\nbelow one percentage point, avoids unnecessary conservatism, and admits\nprovable guarantees on attack mitigation. Moreover, our defense uses\nexponentially fewer queries than existing attacks and is compatible with any\nLLM.",
          "link": "http://arxiv.org/abs/2310.03684",
          "publishedOn": "2023-10-07T00:42:18.757Z",
          "wordCount": null,
          "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03485",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kollias_D/0/1/0/all/0/1\">Dimitrios Kollias</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vendal_K/0/1/0/all/0/1\">Karanjot Vendal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gadhavi_P/0/1/0/all/0/1\">Priyanka Gadhavi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Russom_S/0/1/0/all/0/1\">Solomon Russom</a>",
          "description": "Brain tumors pose significant health challenges worldwide, with glioblastoma\nbeing one of the most aggressive forms. Accurate determination of the\nO6-methylguanine-DNA methyltransferase (MGMT) promoter methylation status is\ncrucial for personalized treatment strategies. However, traditional methods are\nlabor-intensive and time-consuming. This paper proposes a novel multi-modal\napproach, BTDNet, leveraging multi-parametric MRI scans, including FLAIR, T1w,\nT1wCE, and T2 3D volumes, to predict MGMT promoter methylation status. BTDNet\naddresses two main challenges: the variable volume lengths (i.e., each volume\nconsists of a different number of slices) and the volume-level annotations\n(i.e., the whole 3D volume is annotated and not the independent slices that it\nconsists of). BTDNet consists of four components: i) the data augmentation one\n(that performs geometric transformations, convex combinations of data pairs and\ntest-time data augmentation); ii) the 3D analysis one (that performs global\nanalysis through a CNN-RNN); iii) the routing one (that contains a mask layer\nthat handles variable input feature lengths), and iv) the modality fusion one\n(that effectively enhances data representation, reduces ambiguities and\nmitigates data scarcity). The proposed method outperforms by large margins the\nstate-of-the-art methods in the RSNA-ASNR-MICCAI BraTS 2021 Challenge, offering\na promising avenue for enhancing brain tumor diagnosis and treatment.",
          "link": "http://arxiv.org/abs/2310.03485",
          "publishedOn": "2023-10-07T00:42:18.747Z",
          "wordCount": null,
          "title": "BTDNet: a Multi-Modal Approach for Brain Tumor Radiogenomic Classification. (arXiv:2310.03485v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shang_M/0/1/0/all/0/1\">Meng Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dedeyne_L/0/1/0/all/0/1\">Lenore Dedeyne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupont_J/0/1/0/all/0/1\">Jolan Dupont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vercauteren_L/0/1/0/all/0/1\">Laura Vercauteren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_N/0/1/0/all/0/1\">Nadjia Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapauw_L/0/1/0/all/0/1\">Laurence Lapauw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gielen_E/0/1/0/all/0/1\">Evelien Gielen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verschueren_S/0/1/0/all/0/1\">Sabine Verschueren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varon_C/0/1/0/all/0/1\">Carolina Varon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raedt_W/0/1/0/all/0/1\">Walter De Raedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanrumste_B/0/1/0/all/0/1\">Bart Vanrumste</a>",
          "description": "Otago Exercise Program (OEP) is a rehabilitation program for older adults to\nimprove frailty, sarcopenia, and balance. Accurate monitoring of patient\ninvolvement in OEP is challenging, as self-reports (diaries) are often\nunreliable. With the development of wearable sensors, Human Activity\nRecognition (HAR) systems using wearable sensors have revolutionized\nhealthcare. However, their usage for OEP still shows limited performance. The\nobjective of this study is to build an unobtrusive and accurate system to\nmonitor OEP for older adults. Data was collected from older adults wearing a\nsingle waist-mounted Inertial Measurement Unit (IMU). Two datasets were\ncollected, one in a laboratory setting, and one at the homes of the patients. A\nhierarchical system is proposed with two stages: 1) using a deep learning model\nto recognize whether the patients are performing OEP or activities of daily\nlife (ADLs) using a 10-minute sliding window; 2) based on stage 1, using a\n6-second sliding window to recognize the OEP sub-classes performed. The results\nshowed that in stage 1, OEP could be recognized with window-wise f1-scores over\n0.95 and Intersection-over-Union (IoU) f1-scores over 0.85 for both datasets.\nIn stage 2, for the home scenario, four activities could be recognized with\nf1-scores over 0.8: ankle plantarflexors, abdominal muscles, knee bends, and\nsit-to-stand. The results showed the potential of monitoring the compliance of\nOEP using a single IMU in daily life. Also, some OEP sub-classes are possible\nto be recognized for further analysis.",
          "link": "http://arxiv.org/abs/2310.03512",
          "publishedOn": "2023-10-07T00:42:18.747Z",
          "wordCount": null,
          "title": "Otago Exercises Monitoring for Older Adults by a Single IMU and Hierarchical Machine Learning Models. (arXiv:2310.03512v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03435",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magris_M/0/1/0/all/0/1\">Martin Magris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "The Bayesian estimation of GARCH-family models has been typically addressed\nthrough Monte Carlo sampling. Variational Inference is gaining popularity and\nattention as a robust approach for Bayesian inference in complex machine\nlearning models; however, its adoption in econometrics and finance is limited.\nThis paper discusses the extent to which Variational Inference constitutes a\nreliable and feasible alternative to Monte Carlo sampling for Bayesian\ninference in GARCH-like models. Through a large-scale experiment involving the\nconstituents of the S&P 500 index, several Variational Inference optimizers, a\nvariety of volatility models, and a case study, we show that Variational\nInference is an attractive, remarkably well-calibrated, and competitive method\nfor Bayesian learning.",
          "link": "http://arxiv.org/abs/2310.03435",
          "publishedOn": "2023-10-07T00:42:18.719Z",
          "wordCount": null,
          "title": "Variational Inference for GARCH-family Models. (arXiv:2310.03435v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.12766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>",
          "description": "Large language models (LLMs) have initiated a paradigm shift in transfer\nlearning. In contrast to the classic pretraining-then-finetuning procedure, in\norder to use LLMs for downstream prediction tasks, one only needs to provide a\nfew demonstrations, known as in-context examples, without adding more or\nupdating existing model parameters. This in-context learning (ICL) capability\nof LLMs is intriguing, and it is not yet fully understood how pretrained LLMs\nacquire such capabilities. In this paper, we investigate the reason why a\ntransformer-based language model can accomplish in-context learning after\npre-training on a general language corpus by proposing one hypothesis that LLMs\ncan simulate kernel regression with internal representations when faced with\nin-context examples. More concretely, we first prove that Bayesian inference on\nin-context prompts can be asymptotically understood as kernel regression $\\hat\ny = \\sum_i y_i K(x, x_i)/\\sum_i K(x, x_i)$ as the number of in-context\ndemonstrations grows. Then, we empirically investigate the in-context behaviors\nof language models. We find that during ICL, the attention and hidden features\nin LLMs match the behaviors of a kernel regression. Finally, our theory\nprovides insights into multiple phenomena observed in the ICL field: why\nretrieving demonstrative samples similar to test samples can help, why ICL\nperformance is sensitive to the output formats, and why ICL accuracy benefits\nfrom selecting in-distribution and representative samples.",
          "link": "http://arxiv.org/abs/2305.12766",
          "publishedOn": "2023-10-07T00:42:18.705Z",
          "wordCount": null,
          "title": "Explaining Emergent In-Context Learning as Kernel Regression. (arXiv:2305.12766v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelaleem_E/0/1/0/all/0/1\">Eslam Abdelaleem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nemenman_I/0/1/0/all/0/1\">Ilya Nemenman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martini_K/0/1/0/all/0/1\">K. Michael Martini</a>",
          "description": "Variational dimensionality reduction methods are known for their high\naccuracy, generative abilities, and robustness. These methods have many\ntheoretical justifications. Here we introduce a unifying principle rooted in\ninformation theory to rederive and generalize existing variational methods and\ndesign new ones. We base our framework on an interpretation of the multivariate\ninformation bottleneck, in which two Bayesian networks are traded off against\none another. We interpret the first network as an encoder graph, which\nspecifies what information to keep when compressing the data. We interpret the\nsecond network as a decoder graph, which specifies a generative model for the\ndata. Using this framework, we rederive existing dimensionality reduction\nmethods such as the deep variational information bottleneck (DVIB), beta\nvariational auto-encoders (beta-VAE), and deep variational canonical\ncorrelation analysis (DVCCA). The framework naturally introduces a trade-off\nparameter between compression and reconstruction in the DVCCA family of\nalgorithms, resulting in the new beta-DVCCA family. In addition, we derive a\nnew variational dimensionality reduction method, deep variational symmetric\ninformational bottleneck (DVSIB), which simultaneously compresses two variables\nto preserve information between their compressed representations. We implement\nall of these algorithms and evaluate their ability to produce shared low\ndimensional latent spaces on a modified noisy MNIST dataset. We show that\nalgorithms that are better matched to the structure of the data (beta-DVCCA and\nDVSIB) produce better latent spaces as measured by classification accuracy and\nthe dimensionality of the latent variables. We believe that this framework can\nbe used to unify other multi-view representation learning algorithms.\nAdditionally, it provides a straightforward framework for deriving\nproblem-specific loss functions.",
          "link": "http://arxiv.org/abs/2310.03311",
          "publishedOn": "2023-10-07T00:42:18.696Z",
          "wordCount": null,
          "title": "Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses. (arXiv:2310.03311v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.07454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Renanse_A/0/1/0/all/0/1\">Animesh Renanse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Alok Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Rohitash Chandra</a>",
          "description": "It is well known that canonical recurrent neural networks (RNNs) face\nlimitations in learning long-term dependencies which have been addressed by\nmemory structures in long short-term memory (LSTM) networks. Neural Turing\nmachines (NTMs) are novel RNNs that implement the notion of programmable\ncomputers with neural network controllers that can learn simple algorithmic\ntasks. Matrix neural networks feature matrix representation which inherently\npreserves the spatial structure of data when compared to canonical neural\nnetworks that use vector-based representation. One may then argue that neural\nnetworks with matrix representations may have the potential to provide better\nmemory capacity. In this paper, we define and study a probabilistic notion of\nmemory capacity based on Fisher information for matrix-based RNNs. We find\nbounds on memory capacity for such networks under various hypotheses and\ncompare them with their vector counterparts. In particular, we show that the\nmemory capacity of such networks is bounded by $N^2$ for $N\\times N$ state\nmatrix which generalizes the one known for vector networks. We also show and\nanalyze the increase in memory capacity for such networks which is introduced\nwhen one exhibits an external state memory, such as NTMs. Consequently, we\nconstruct NTMs with RNN controllers with matrix-based representation of\nexternal memory, leading us to introduce Matrix NTMs. We demonstrate the\nperformance of this class of memory networks under certain algorithmic learning\ntasks such as copying and recall and compare it with Matrix RNNs. We find an\nimprovement in the performance of Matrix NTMs by the addition of external\nmemory, in comparison to Matrix RNNs.",
          "link": "http://arxiv.org/abs/2104.07454",
          "publishedOn": "2023-10-07T00:42:18.664Z",
          "wordCount": null,
          "title": "Memory Capacity of Recurrent Neural Networks with Matrix Representation. (arXiv:2104.07454v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karchmer_A/0/1/0/all/0/1\">Ari Karchmer</a>",
          "description": "(Abridged) Carmosino et al. (2016) demonstrated that natural proofs of\ncircuit lower bounds for \\Lambda imply efficient algorithms for learning\n\\Lambda-circuits, but only over the uniform distribution, with membership\nqueries, and provided \\AC^0[p] \\subseteq \\Lambda. We consider whether this\nimplication can be generalized to \\Lambda \\not\\supseteq \\AC^0[p], and to\nlearning algorithms in Valiant's PAC model, which use only random examples and\nlearn over arbitrary example distributions. We give results of both positive\nand negative flavor.\n\nOn the negative side, we observe that if, for every circuit class \\Lambda,\nthe implication from natural proofs for \\Lambda to learning \\Lambda-circuits in\nValiant's PAC model holds, then there is a polynomial time solution to\nO(n^{1.5})-uSVP (unique Shortest Vector Problem), and polynomial time quantum\nsolutions to O(n^{1.5})-SVP (Shortest Vector Problem) and O(n^{1.5})-SIVP\n(Shortest Independent Vector Problem). This indicates that whether natural\nproofs for \\Lambda imply efficient learning algorithms for \\Lambda in Valiant's\nPAC model may depend on \\Lambda.\n\nOn the positive side, our main result is that specific natural proofs arising\nfrom a type of communication complexity argument (e.g., Nisan (1993), for\ndepth-2 majority circuits) imply PAC-learning algorithms in a new\ndistributional variant of Valiant's model. Our distributional PAC model is\nstronger than the average-case prediction model of Blum et al (1993) and the\nheuristic PAC model of Nanashima (2021), and has several important properties\nwhich make it of independent interest, such as being boosting-friendly. The\nmain applications of our result are new distributional PAC-learning algorithms\nfor depth-2 majority circuits, polytopes and DNFs over natural target\ndistributions, as well as the nonexistence of encoded-input weak PRFs that can\nbe evaluated by depth-2 majority circuits.",
          "link": "http://arxiv.org/abs/2310.03641",
          "publishedOn": "2023-10-07T00:42:18.659Z",
          "wordCount": null,
          "title": "Distributional PAC-Learning from Nisan's Natural Proofs. (arXiv:2310.03641v1 [cs.CC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edin_A/0/1/0/all/0/1\">Adrian Edin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>",
          "description": "Over-the-Air (OtA) Federated Learning (FL) refers to an FL system where\nmultiple agents apply OtA computation for transmitting model updates to a\ncommon edge server. Two important features of OtA computation, namely linear\nprocessing and signal-level superposition, motivate the use of linear\ncompression with compressed sensing (CS) methods to reduce the number of data\nsamples transmitted over the channel. The previous works on applying CS methods\nin OtA FL have primarily assumed that the original model update vectors are\nsparse, or they have been sparsified before compression. However, it is unclear\nwhether linear compression with CS-based reconstruction is more effective than\ndirectly sending the non-zero elements in the sparsified update vectors, under\nthe same total power constraint. In this study, we examine and compare several\ncommunication designs with or without sparsification. Our findings demonstrate\nthat sparsification before compression is not necessary. Alternatively,\nsparsification without linear compression can also achieve better performance\nthan the commonly considered setup that combines both.",
          "link": "http://arxiv.org/abs/2310.03410",
          "publishedOn": "2023-10-07T00:42:18.650Z",
          "wordCount": null,
          "title": "Over-the-Air Federated Learning with Compressed Sensing: Is Sparsification Necessary?. (arXiv:2310.03410v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Collyer_J/0/1/0/all/0/1\">Josh Collyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_T/0/1/0/all/0/1\">Tim Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_I/0/1/0/all/0/1\">Iain Phillips</a>",
          "description": "Being able to identify functions of interest in cross-architecture software\nis useful whether you are analysing for malware, securing the software supply\nchain or conducting vulnerability research. Cross-Architecture Binary Code\nSimilarity Search has been explored in numerous studies and has used a wide\nrange of different data sources to achieve its goals. The data sources\ntypically used draw on common structures derived from binaries such as function\ncontrol flow graphs or binary level call graphs, the output of the disassembly\nprocess or the outputs of a dynamic analysis approach. One data source which\nhas received less attention is binary intermediate representations. Binary\nIntermediate representations possess two interesting properties: they are cross\narchitecture by their very nature and encode the semantics of a function\nexplicitly to support downstream usage. Within this paper we propose Function\nas a String Encoded Representation (FASER) which combines long document\ntransformers with the use of intermediate representations to create a model\ncapable of cross architecture function search without the need for manual\nfeature engineering, pre-training or a dynamic analysis step. We compare our\napproach against a series of baseline approaches for two tasks; A general\nfunction search task and a targeted vulnerability search task. Our approach\ndemonstrates strong performance across both tasks, performing better than all\nbaseline approaches.",
          "link": "http://arxiv.org/abs/2310.03605",
          "publishedOn": "2023-10-07T00:42:18.639Z",
          "wordCount": null,
          "title": "FASER: Binary Code Similarity Search through the use of Intermediate Representations. (arXiv:2310.03605v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dacheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Rulin Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_A/0/1/0/all/0/1\">Anze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>",
          "description": "Increasing the context length of large language models (LLMs) unlocks\nfundamentally new capabilities, but also significantly increases the memory\nfootprints of training. Previous model-parallel systems such as Megatron-LM\npartition and compute different attention heads in parallel, resulting in large\ncommunication volumes, so they cannot scale beyond the number of attention\nheads, thereby hindering its adoption. In this paper, we introduce a new\napproach, LightSeq, for long-context LLMs training. LightSeq has many notable\nadvantages. First, LightSeq partitions over the sequence dimension, hence is\nagnostic to model architectures and readily applicable for models with varying\nnumbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query\nattention. Second, LightSeq not only requires up to 4.7x less communication\nthan Megatron-LM on popular LLMs but also overlaps the communication with\ncomputation. To further reduce the training time, LightSeq features a novel\ngradient checkpointing scheme to bypass an forward computation for\nmemory-efficient attention. We evaluate LightSeq on Llama-7B and its variants\nwith sequence lengths from 32K to 512K. Through comprehensive experiments on\nsingle and cross-node training, we show that LightSeq achieves up to 1.24-2.01x\nend-to-end speedup, and a 2-8x longer sequence length on models with fewer\nheads, compared to Megatron-LM. Codes will be available at\nhttps://github.com/RulinShao/LightSeq.",
          "link": "http://arxiv.org/abs/2310.03294",
          "publishedOn": "2023-10-07T00:42:18.625Z",
          "wordCount": null,
          "title": "LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers. (arXiv:2310.03294v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+George_V/0/1/0/all/0/1\">Victor Vadakechirayath George</a>",
          "description": "Inspired by recent developments in attention models for image classification\nand natural language processing, we present various Attention based\narchitectures in reinforcement learning (RL) domain, capable of performing well\non OpenAI Gym Atari-2600 game suite. In spite of the recent success of Deep\nReinforcement learning techniques in various fields like robotics, gaming and\nhealthcare, they suffer from a major drawback that neural networks are\ndifficult to interpret. We try to get around this problem with the help of\nAttention based models. In Attention based models, extracting and overlaying of\nattention map onto images allows for direct observation of information used by\nagent to select actions and easier interpretation of logic behind the chosen\nactions. Our models in addition to playing well on gym-Atari environments, also\nprovide insights on how agent perceives its environment. In addition, motivated\nby recent developments in attention based video-classification models using\nVision Transformer, we come up with an architecture based on Vision\nTransformer, for image-based RL domain too. Compared to previous works in\nVision Transformer, our model is faster to train and requires fewer\ncomputational resources. 3",
          "link": "http://arxiv.org/abs/2310.03161",
          "publishedOn": "2023-10-07T00:42:18.624Z",
          "wordCount": null,
          "title": "Neural architecture impact on identifying temporally extended Reinforcement Learning tasks. (arXiv:2310.03161v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03028",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Taub_R/0/1/0/all/0/1\">Ronen Taub</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Savir_Y/0/1/0/all/0/1\">Yonatan Savir</a>",
          "description": "Machine learning, and representation learning in particular, has the\npotential to facilitate drug discovery by screening a large chemical space in\nsilico. A successful approach for representing molecules is to treat them as a\ngraph and utilize graph neural networks. One of the key limitations of such\nmethods is the necessity to represent compounds with different numbers of\natoms, which requires aggregating the atom's information. Common aggregation\noperators, such as averaging, result in loss of information at the atom level.\nIn this work, we propose a novel aggregating approach where each atom is\nweighted non-linearly using the Boltzmann distribution with a hyperparameter\nanalogous to temperature. We show that using this weighted aggregation improves\nthe ability of the gold standard message-passing neural network to predict\nantibiotic activity. Moreover, by changing the temperature hyperparameter, our\napproach can reveal the atoms that are important for activity prediction in a\nsmooth and consistent way, thus providing a novel, regulated attention\nmechanism for graph neural networks. We further validate our method by showing\nthat it recapitulates the functional group in beta-Lactam antibiotics. The\nability of our approach to rank the atoms' importance for a desired function\ncan be used within any graph neural network to provide interpretability of the\nresults and predictions at the node level.",
          "link": "http://arxiv.org/abs/2310.03028",
          "publishedOn": "2023-10-07T00:42:18.612Z",
          "wordCount": null,
          "title": "SAF: Smart Aggregation Framework for Revealing Atoms Importance Rank and Improving Prediction Rates in Drug Discovery. (arXiv:2310.03028v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03234",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1\">Quanqi Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_D/0/1/0/all/0/1\">Dixian Zhu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "This paper investigates new families of compositional optimization problems,\ncalled $\\underline{\\bf n}$on-$\\underline{\\bf s}$mooth $\\underline{\\bf\nw}$eakly-$\\underline{\\bf c}$onvex $\\underline{\\bf f}$inite-sum $\\underline{\\bf\nc}$oupled $\\underline{\\bf c}$ompositional $\\underline{\\bf o}$ptimization (NSWC\nFCCO). There has been a growing interest in FCCO due to its wide-ranging\napplications in machine learning and AI, as well as its ability to address the\nshortcomings of stochastic algorithms based on empirical risk minimization.\nHowever, current research on FCCO presumes that both the inner and outer\nfunctions are smooth, limiting their potential to tackle a more diverse set of\nproblems. Our research expands on this area by examining non-smooth\nweakly-convex FCCO, where the outer function is weakly convex and\nnon-decreasing, and the inner function is weakly-convex. We analyze a\nsingle-loop algorithm and establish its complexity for finding an\n$\\epsilon$-stationary point of the Moreau envelop of the objective function.\nAdditionally, we also extend the algorithm to solving novel non-smooth\nweakly-convex tri-level finite-sum coupled compositional optimization problems,\nwhich feature a nested arrangement of three functions. Lastly, we explore the\napplications of our algorithms in deep learning for two-way partial AUC\nmaximization and multi-instance two-way partial AUC maximization, using\nempirical studies to showcase the effectiveness of the proposed algorithms.",
          "link": "http://arxiv.org/abs/2310.03234",
          "publishedOn": "2023-10-07T00:42:18.608Z",
          "wordCount": null,
          "title": "Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Cong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>",
          "description": "Embedding plays a critical role in modern recommender systems because they\nare virtual representations of real-world entities and the foundation for\nsubsequent decision models. In this paper, we propose a novel embedding update\nmechanism, Structure-aware Embedding Evolution (SEvo for short), to encourage\nrelated nodes to evolve similarly at each step. Unlike GNN (Graph Neural\nNetwork) that typically serves as an intermediate part, SEvo is able to\ndirectly inject the graph structure information into embedding with negligible\ncomputational overhead in training. The convergence properties of SEvo as well\nas its possible variants are theoretically analyzed to justify the validity of\nthe designs. Moreover, SEvo can be seamlessly integrated into existing\noptimizers for state-of-the-art performance. In particular, SEvo-enhanced AdamW\nwith moment estimate correction demonstrates consistent improvements across a\nspectrum of models and datasets, suggesting a novel technical route to\neffectively utilize graph structure information beyond explicit GNN modules.",
          "link": "http://arxiv.org/abs/2310.03032",
          "publishedOn": "2023-10-07T00:42:18.607Z",
          "wordCount": null,
          "title": "Graph-enhanced Optimizers for Structure-aware Recommendation Embedding Evolution. (arXiv:2310.03032v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zihao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yifan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xueqian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lifu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "With the blowout development of pre-trained models (PTMs), the efficient\ntuning of these models for diverse downstream applications has emerged as a\npivotal research concern. Although recent investigations into prompt tuning\nhave provided promising avenues, three salient challenges persist: (1) memory\nconstraint: the continuous growth in the size of open-source PTMs renders\nfine-tuning, even a fraction of their parameters, challenging for many\npractitioners. (2) model privacy: existing PTMs often function as public API\nservices, with their parameters inaccessible for effective or tailored\nfine-tuning. (3) data privacy: the fine-tuning of PTMs necessitates\nhigh-quality datasets, which are typically localized and not shared to public.\nTo optimally harness each local dataset while navigating memory constraints and\npreserving privacy, we propose Federated Black-Box Prompt Tuning (Fed-BBPT).\nThis innovative approach eschews reliance on parameter architectures and\nprivate dataset access, instead capitalizing on a central server that aids\nlocal users in collaboratively training a prompt generator through regular\naggregation. Local users leverage API-driven learning via a zero-order\noptimizer, obviating the need for PTM deployment. Relative to extensive\nfine-tuning, Fed-BBPT proficiently sidesteps memory challenges tied to PTM\nstorage and fine-tuning on local machines, tapping into comprehensive,\nhigh-quality, yet private training datasets. A thorough evaluation across 40\ndatasets spanning CV and NLP tasks underscores the robustness of our proposed\nmodel.",
          "link": "http://arxiv.org/abs/2310.03123",
          "publishedOn": "2023-10-07T00:42:18.605Z",
          "wordCount": null,
          "title": "Efficient Federated Prompt Tuning for Black-box Large Pre-trained Models. (arXiv:2310.03123v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Woisetschlager_H/0/1/0/all/0/1\">Herbert Woisetschl&#xe4;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isenko_A/0/1/0/all/0/1\">Alexander Isenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayer_R/0/1/0/all/0/1\">Ruben Mayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobsen_H/0/1/0/all/0/1\">Hans-Arno Jacobsen</a>",
          "description": "Large Language Models (LLM) and foundation models are popular as they offer\nnew opportunities for individuals and businesses to improve natural language\nprocessing, interact with data, and retrieve information faster. However,\ntraining or fine-tuning LLMs requires a vast amount of data, which can be\nchallenging to access due to legal or technical restrictions and may require\nprivate computing resources. Federated Learning (FL) is a solution designed to\novercome these challenges and expand data access for deep learning\napplications.\n\nThis paper takes a hardware-centric approach to explore how LLMs can be\nbrought to modern edge computing systems. Our study fine-tunes the FLAN-T5\nmodel family, ranging from 80M to 3B parameters, using FL for a text\nsummarization task. We provide a micro-level hardware benchmark, compare the\nmodel FLOP utilization to a state-of-the-art data center GPU, and study the\nnetwork utilization in realistic conditions. Our contribution is twofold:\nFirst, we evaluate the current capabilities of edge computing systems and their\npotential for LLM FL workloads. Second, by comparing these systems with a\ndata-center GPU, we demonstrate the potential for improvement and the next\nsteps toward achieving greater computational efficiency at the edge.",
          "link": "http://arxiv.org/abs/2310.03150",
          "publishedOn": "2023-10-07T00:42:18.602Z",
          "wordCount": null,
          "title": "Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly. (arXiv:2310.03150v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03178",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Liangqi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher G. Brinton</a>",
          "description": "The Internet of Things (IoT) consistently generates vast amounts of data,\nsparking increasing concern over the protection of data privacy and the\nlimitation of data misuse. Federated learning (FL) facilitates collaborative\ncapabilities among multiple parties by sharing machine learning (ML) model\nparameters instead of raw user data, and it has recently gained significant\nattention for its potential in privacy preservation and learning efficiency\nenhancement. In this paper, we highlight the digital ethics concerns that arise\nwhen human-centric devices serve as clients in FL. More specifically,\nchallenges of game dynamics, fairness, incentive, and continuity arise in FL\ndue to differences in perspectives and objectives between clients and the\nserver. We analyze these challenges and their solutions from the perspectives\nof both the client and the server, and through the viewpoints of centralized\nand decentralized FL. Finally, we explore the opportunities in FL for\nhuman-centric IoT as directions for future development.",
          "link": "http://arxiv.org/abs/2310.03178",
          "publishedOn": "2023-10-07T00:42:18.594Z",
          "wordCount": null,
          "title": "Digital Ethics in Federated Learning. (arXiv:2310.03178v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruiyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "Tabular data prediction is a fundamental machine learning task for many\napplications. Existing methods predominantly employ discriminative modeling and\noperate under the assumption of a fixed target column, necessitating\nre-training for every new predictive task. Inspired by the generative power of\nlarge language models (LLMs), this paper exploits the idea of building\nuniversal tabular data predictors based on generative modeling, namely\nUniPredict. Here, we show that scaling up an LLM to extensive tabular datasets\nwith the capability of comprehending diverse tabular inputs and predicting for\ntarget variables following the input instructions. Specifically, we train a\nsingle LLM on an aggregation of 169 tabular datasets with diverse targets and\ncompare its performance against baselines that are trained on each dataset\nseparately. We observe this versatile UniPredict model demonstrates an\nadvantage over other models, ranging from 5.4% to 13.4%, when compared with the\nbest tree-boosting baseline and the best neural network baseline, respectively.\nWe further test UniPredict in few-shot learning settings on another 62 tabular\ndatasets. Our method achieves strong performance in quickly adapting to new\ntasks, where our method outperforms XGBoost over 100% on the low-resource setup\nand shows a significant margin over all baselines. We envision that UniPredict\nsheds light on developing a universal tabular data prediction system that\nlearns from data at scale and serves a wide range of prediction tasks.",
          "link": "http://arxiv.org/abs/2310.03266",
          "publishedOn": "2023-10-07T00:42:18.585Z",
          "wordCount": null,
          "title": "UniPredict: Large Language Models are Universal Tabular Predictors. (arXiv:2310.03266v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03121",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Eastman_P/0/1/0/all/0/1\">Peter Eastman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Galvelis_R/0/1/0/all/0/1\">Raimondas Galvelis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pelaez_R/0/1/0/all/0/1\">Ra&#xfa;l P. Pel&#xe1;ez</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Abreu_C/0/1/0/all/0/1\">Charlles R. A. Abreu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Farr_S/0/1/0/all/0/1\">Stephen E. Farr</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gallicchio_E/0/1/0/all/0/1\">Emilio Gallicchio</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gorenko_A/0/1/0/all/0/1\">Anton Gorenko</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Henry_M/0/1/0/all/0/1\">Michael M. Henry</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hu_F/0/1/0/all/0/1\">Frank Hu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kramer_A/0/1/0/all/0/1\">Andreas Kr&#xe4;mer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Michel_J/0/1/0/all/0/1\">Julien Michel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mitchell_J/0/1/0/all/0/1\">Joshua A. Mitchell</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pande_V/0/1/0/all/0/1\">Vijay S. Pande</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rodrigues_J/0/1/0/all/0/1\">Jo&#xe3;o PGLM Rodrigues</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rodriguez_Guerra_J/0/1/0/all/0/1\">Jaime Rodriguez-Guerra</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Simmonett_A/0/1/0/all/0/1\">Andrew C. Simmonett</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Swails_J/0/1/0/all/0/1\">Jason Swails</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_I/0/1/0/all/0/1\">Ivy Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chodera_J/0/1/0/all/0/1\">John D. Chodera</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fabritiis_G/0/1/0/all/0/1\">Gianni De Fabritiis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Markland_T/0/1/0/all/0/1\">Thomas E. Markland</a>",
          "description": "Machine learning plays an important and growing role in molecular simulation.\nThe newest version of the OpenMM molecular dynamics toolkit introduces new\nfeatures to support the use of machine learning potentials. Arbitrary PyTorch\nmodels can be added to a simulation and used to compute forces and energy. A\nhigher-level interface allows users to easily model their molecules of interest\nwith general purpose, pretrained potential functions. A collection of optimized\nCUDA kernels and custom PyTorch operations greatly improves the speed of\nsimulations. We demonstrate these features on simulations of cyclin-dependent\nkinase 8 (CDK8) and the green fluorescent protein (GFP) chromophore in water.\nTaken together, these features make it practical to use machine learning to\nimprove the accuracy of simulations at only a modest increase in cost.",
          "link": "http://arxiv.org/abs/2310.03121",
          "publishedOn": "2023-10-07T00:42:18.546Z",
          "wordCount": null,
          "title": "OpenMM 8: Molecular Dynamics Simulation with Machine Learning Potentials. (arXiv:2310.03121v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gampa_P/0/1/0/all/0/1\">Phanideep Gampa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javadi_F/0/1/0/all/0/1\">Farnoosh Javadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayar_B/0/1/0/all/0/1\">Belhassen Bayar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yessenalina_A/0/1/0/all/0/1\">Ainur Yessenalina</a>",
          "description": "Various data imbalances that naturally arise in a multi-territory\npersonalized recommender system can lead to a significant item bias for\nglobally prevalent items. A locally popular item can be overshadowed by a\nglobally prevalent item. Moreover, users' viewership patterns/statistics can\ndrastically change from one geographic location to another which may suggest to\nlearn specific user embeddings. In this paper, we propose a multi-task learning\n(MTL) technique, along with an adaptive upsampling method to reduce popularity\nbias in multi-territory recommendations. Our proposed framework is designed to\nenrich training examples with active users representation through upsampling,\nand capable of learning geographic-based user embeddings by leveraging MTL.\nThrough experiments, we demonstrate the effectiveness of our framework in\nmultiple territories compared to a baseline not incorporating our proposed\ntechniques.~Noticeably, we show improved relative gain of up to $65.27\\%$ in\nPR-AUC metric. A case study is presented to demonstrate the advantages of our\nmethods in attenuating the popularity bias of global items.",
          "link": "http://arxiv.org/abs/2310.03148",
          "publishedOn": "2023-10-07T00:42:18.526Z",
          "wordCount": null,
          "title": "Multi-Task Learning For Reduced Popularity Bias In Multi-Territory Video Recommendations. (arXiv:2310.03148v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suresh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guruparan_D/0/1/0/all/0/1\">Dhanyashri Guruparan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aaron_P/0/1/0/all/0/1\">Pavithren Aaron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telajan_P/0/1/0/all/0/1\">Philemon Telajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_K/0/1/0/all/0/1\">Kavinesh Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davagandhi_D/0/1/0/all/0/1\">Dinesh Davagandhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_O/0/1/0/all/0/1\">Ong Xin Yue</a>",
          "description": "Deep learning has become a powerful tool in computational biology,\nrevolutionising the analysis and interpretation of biological data over time.\nIn our article review, we delve into various aspects of deep learning in\ncomputational biology. Specifically, we examine its history, advantages, and\nchallenges. Our focus is on two primary applications: DNA sequence\nclassification and prediction, as well as protein structure prediction from\nsequence data. Additionally, we provide insights into the outlook for this\nfield. To fully harness the potential of deep learning in computational\nbiology, it is crucial to address the challenges that come with it. These\nchallenges include the requirement for large, labelled datasets and the\ninterpretability of deep learning models. The use of deep learning in the\nanalysis of DNA sequences has brought about a significant transformation in the\ndetection of genomic variants and the analysis of gene expression. This has\ngreatly contributed to the advancement of personalised medicine and drug\ndiscovery. Convolutional neural networks (CNNs) have been shown to be highly\naccurate in predicting genetic variations and gene expression levels. Deep\nlearning techniques are used for analysing epigenetic data, including DNA\nmethylation and histone modifications. This provides valuable insights into\nmetabolic conditions and gene regulation. The field of protein structure\nprediction has been significantly impacted by deep learning, which has enabled\naccurate determination of the three-dimensional shape of proteins and\nprediction of their interactions. The future of deep learning in computational\nbiology looks promising. With the development of advanced deep learning models\nand interpretation techniques, there is potential to overcome current\nchallenges and further our understanding of biological systems.",
          "link": "http://arxiv.org/abs/2310.03086",
          "publishedOn": "2023-10-07T00:42:18.510Z",
          "wordCount": null,
          "title": "Deep Learning in Computational Biology: Advancements, Challenges, and Future Outlook. (arXiv:2310.03086v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_M/0/1/0/all/0/1\">Maziyar Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charter_T/0/1/0/all/0/1\">Todd Charter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaghoubi_M/0/1/0/all/0/1\">Marjan Yaghoubi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalayer_M/0/1/0/all/0/1\">Masoud Jalayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahang_M/0/1/0/all/0/1\">Maryam Ahang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shojaeinasab_A/0/1/0/all/0/1\">Ardeshir Shojaeinasab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najjaran_H/0/1/0/all/0/1\">Homayoun Najjaran</a>",
          "description": "Machine scheduling aims to optimize job assignments to machines while\nadhering to manufacturing rules and job specifications. This optimization leads\nto reduced operational costs, improved customer demand fulfillment, and\nenhanced production efficiency. However, machine scheduling remains a\nchallenging combinatorial problem due to its NP-hard nature. Deep Reinforcement\nLearning (DRL), a key component of artificial general intelligence, has shown\npromise in various domains like gaming and robotics. Researchers have explored\napplying DRL to machine scheduling problems since 1995. This paper offers a\ncomprehensive review and comparison of DRL-based approaches, highlighting their\nmethodology, applications, advantages, and limitations. It categorizes these\napproaches based on computational components: conventional neural networks,\nencoder-decoder architectures, graph neural networks, and metaheuristic\nalgorithms. Our review concludes that DRL-based methods outperform exact\nsolvers, heuristics, and tabular reinforcement learning algorithms in terms of\ncomputation speed and generating near-global optimal solutions. These DRL-based\napproaches have been successfully applied to static and dynamic scheduling\nacross diverse machine environments and job characteristics. However, DRL-based\nschedulers face limitations in handling complex operational constraints,\nconfigurable multi-objective optimization, generalization, scalability,\ninterpretability, and robustness. Addressing these challenges will be a crucial\nfocus for future research in this field. This paper serves as a valuable\nresource for researchers to assess the current state of DRL-based machine\nscheduling and identify research gaps. It also aids experts and practitioners\nin selecting the appropriate DRL approach for production scheduling.",
          "link": "http://arxiv.org/abs/2310.03195",
          "publishedOn": "2023-10-07T00:42:18.510Z",
          "wordCount": null,
          "title": "Deep reinforcement learning for machine scheduling: Methodology, the state-of-the-art, and future directions. (arXiv:2310.03195v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaxuan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in the field of generative modeling due to its\nflexibility in the formulation and strong modeling power of the latent space.\nHowever, the common practice of learning latent space EBMs with non-convergent\nshort-run MCMC for prior and posterior sampling is hindering the model from\nfurther progress; the degenerate MCMC sampling quality in practice often leads\nto degraded generation quality and instability in training, especially with\nhighly multi-modal and/or high-dimensional target distributions. To remedy this\nsampling issue, in this paper we introduce a simple but effective\ndiffusion-based amortization method for long-run MCMC sampling and develop a\nnovel learning algorithm for the latent space EBM based on it. We provide\ntheoretical evidence that the learned amortization of MCMC is a valid long-run\nMCMC sampler. Experiments on several image modeling benchmark datasets\ndemonstrate the superior performance of our method compared with strong\ncounterparts",
          "link": "http://arxiv.org/abs/2310.03218",
          "publishedOn": "2023-10-07T00:42:18.507Z",
          "wordCount": null,
          "title": "Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konz_N/0/1/0/all/0/1\">Nicholas Konz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1\">Charles Godfrey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shapiro_M/0/1/0/all/0/1\">Madelyn Shapiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1\">Jonathan Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Davis Brown</a>",
          "description": "By now there is substantial evidence that deep learning models learn certain\nhuman-interpretable features as part of their internal representations of data.\nAs having the right (or wrong) concepts is critical to trustworthy machine\nlearning systems, it is natural to ask which inputs from the model's original\ntraining set were most important for learning a concept at a given layer. To\nanswer this, we combine data attribution methods with methods for probing the\nconcepts learned by a model. Training network and probe ensembles for two\nconcept datasets on a range of network layers, we use the recently developed\nTRAK method for large-scale data attribution. We find some evidence for\nconvergence, where removing the 10,000 top attributing images for a concept and\nretraining the model does not change the location of the concept in the network\nnor the probing sparsity of the concept. This suggests that rather than being\nhighly dependent on a few specific examples, the features that inform the\ndevelopment of a concept are spread in a more diffuse manner across its\nexemplars, implying robustness in concept formation.",
          "link": "http://arxiv.org/abs/2310.03149",
          "publishedOn": "2023-10-07T00:42:18.499Z",
          "wordCount": null,
          "title": "Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Adam Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Son Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montillo_A/0/1/0/all/0/1\">Albert Montillo</a>",
          "description": "Traditional deep learning (DL) suffers from two core problems. Firstly, it\nassumes training samples are independent and identically distributed. However,\nnumerous real-world datasets group samples by shared measurements (e.g., study\nparticipants or cells), violating this assumption. In these scenarios, DL can\nshow compromised performance, limited generalization, and interpretability\nissues, coupled with cluster confounding causing Type 1 and 2 errors. Secondly,\nmodels are typically trained for overall accuracy, often neglecting\nunderrepresented groups and introducing biases in crucial areas like loan\napprovals or determining health insurance rates, such biases can significantly\nimpact one's quality of life. To address both of these challenges\nsimultaneously, we present a mixed effects deep learning (MEDL) framework. MEDL\nseparately quantifies cluster-invariant fixed effects (FE) and cluster-specific\nrandom effects (RE) through the introduction of: 1) a cluster adversary which\nencourages the learning of cluster-invariant FE, 2) a Bayesian neural network\nwhich quantifies the RE, and a mixing function combining the FE an RE into a\nmixed-effect prediction. We marry this MEDL with adversarial debiasing, which\npromotes equality-of-odds fairness across FE, RE, and ME predictions for\nfairness-sensitive variables. We evaluated our approach using three datasets:\ntwo from census/finance focusing on income classification and one from\nhealthcare predicting hospitalization duration, a regression task. Our\nframework notably enhances fairness across all sensitive variables-increasing\nfairness up to 82% for age, 43% for race, 86% for sex, and 27% for\nmarital-status. Besides promoting fairness, our method maintains the robust\nperformance and clarity of MEDL. It's versatile, suitable for various dataset\ntypes and tasks, making it broadly applicable. Our GitHub repository houses the\nimplementation.",
          "link": "http://arxiv.org/abs/2310.03146",
          "publishedOn": "2023-10-07T00:42:18.498Z",
          "wordCount": null,
          "title": "Fairness-enhancing mixed effects deep learning improves fairness on in- and out-of-distribution clustered (non-iid) data. (arXiv:2310.03146v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1\">An Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiwu Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zexue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_P/0/1/0/all/0/1\">Petros Karypis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gentili_A/0/1/0/all/0/1\">Amilcare Gentili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chun-Nan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>",
          "description": "Medical image classification is a critical problem for healthcare, with the\npotential to alleviate the workload of doctors and facilitate diagnoses of\npatients. However, two challenges arise when deploying deep learning models to\nreal-world healthcare applications. First, neural models tend to learn spurious\ncorrelations instead of desired features, which could fall short when\ngeneralizing to new domains (e.g., patients with different ages). Second, these\nblack-box models lack interpretability. When making diagnostic predictions, it\nis important to understand why a model makes a decision for trustworthy and\nsafety considerations. In this paper, to address these two limitations, we\npropose a new paradigm to build robust and interpretable medical image\nclassifiers with natural language concepts. Specifically, we first query\nclinical concepts from GPT-4, then transform latent image features into\nexplicit concepts with a vision-language model. We systematically evaluate our\nmethod on eight medical image classification datasets to verify its\neffectiveness. On challenging datasets with strong confounding factors, our\nmethod can mitigate spurious correlations thus substantially outperform\nstandard visual encoders and other baselines. Finally, we show how\nclassification with a small number of concepts brings a level of\ninterpretability for understanding model decisions through case studies in real\nmedical data.",
          "link": "http://arxiv.org/abs/2310.03182",
          "publishedOn": "2023-10-07T00:42:18.484Z",
          "wordCount": null,
          "title": "Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models. (arXiv:2310.03182v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeromela_J/0/1/0/all/0/1\">Jovan Jeromela</a>",
          "description": "Twitter is currently one of the biggest social media platforms. Its users may\nshare, read, and engage with short posts called tweets. For the ACM Recommender\nSystems Conference 2020, Twitter published a dataset around 70 GB in size for\nthe annual RecSys Challenge. In 2020, the RecSys Challenge invited\nparticipating teams to create models that would predict engagement likelihoods\nfor given user-tweet combinations. The submitted models predicting like, reply,\nretweet, and quote engagements were evaluated based on two metrics: area under\nthe precision-recall curve (PRAUC) and relative cross-entropy (RCE).\n\nIn this diploma thesis, we used the RecSys 2020 Challenge dataset and\nevaluation procedure to investigate how well context alone may be used to\npredict tweet engagement likelihood. In doing so, we employed the Spark engine\non TU Wien's Little Big Data Cluster to create scalable data preprocessing,\nfeature engineering, feature selection, and machine learning pipelines. We\nmanually created just under 200 additional features to describe tweet context.\n\nThe results indicate that features describing users' prior engagement history\nand the popularity of hashtags and links in the tweet were the most\ninformative. We also found that factors such as the prediction algorithm,\ntraining dataset size, training dataset sampling method, and feature selection\nsignificantly affect the results. After comparing the best results of our\ncontext-only prediction models with content-only models and with models\ndeveloped by the Challenge winners, we identified that the context-based models\nunderperformed in terms of the RCE score. This work thus concludes by situating\nthis discrepancy and proposing potential improvements to our implementation,\nwhich is shared in a public git repository.",
          "link": "http://arxiv.org/abs/2310.03147",
          "publishedOn": "2023-10-07T00:42:18.449Z",
          "wordCount": null,
          "title": "Context-Based Tweet Engagement Prediction. (arXiv:2310.03147v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03334",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roshan_K/0/1/0/all/0/1\">Khushnaseeb Roshan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafar_A/0/1/0/all/0/1\">Aasim Zafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haque_S/0/1/0/all/0/1\">Sheikh Burhan Ul Haque</a>",
          "description": "Network Intrusion Detection System (NIDS) is a key component in securing the\ncomputer network from various cyber security threats and network attacks.\nHowever, consider an unfortunate situation where the NIDS is itself attacked\nand vulnerable more specifically, we can say, How to defend the defender?. In\nAdversarial Machine Learning (AML), the malicious actors aim to fool the\nMachine Learning (ML) and Deep Learning (DL) models to produce incorrect\npredictions with intentionally crafted adversarial examples. These adversarial\nperturbed examples have become the biggest vulnerability of ML and DL based\nsystems and are major obstacles to their adoption in real-time and\nmission-critical applications such as NIDS. AML is an emerging research domain,\nand it has become a necessity for the in-depth study of adversarial attacks and\ntheir defence strategies to safeguard the computer network from various cyber\nsecurity threads. In this research work, we aim to cover important aspects\nrelated to NIDS, adversarial attacks and its defence mechanism to increase the\nrobustness of the ML and DL based NIDS. We implemented four powerful\nadversarial attack techniques, namely, Fast Gradient Sign Method (FGSM),\nJacobian Saliency Map Attack (JSMA), Projected Gradient Descent (PGD) and\nCarlini & Wagner (C&W) in NIDS. We analyzed its performance in terms of various\nperformance metrics in detail. Furthermore, the three heuristics defence\nstrategies, i.e., Adversarial Training (AT), Gaussian Data Augmentation (GDA)\nand High Confidence (HC), are implemented to improve the NIDS robustness under\nadversarial attack situations. The complete workflow is demonstrated in\nreal-time network with data packet flow. This research work provides the\noverall background for the researchers interested in AML and its implementation\nfrom a computer network security point of view.",
          "link": "http://arxiv.org/abs/2310.03334",
          "publishedOn": "2023-10-07T00:42:18.440Z",
          "wordCount": null,
          "title": "Untargeted White-box Adversarial Attack with Heuristic Defence Methods in Real-time Deep Learning based Network Intrusion Detection System. (arXiv:2310.03334v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03103",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1\">Guoyizhe Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Anshul Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1\">Rama Chellappa</a>",
          "description": "Federated learning is a distributed machine learning paradigm that allows\nmultiple clients to collaboratively train a shared model with their local data.\nNonetheless, conventional federated learning algorithms often struggle to\ngeneralize well due to the ubiquitous domain shift across clients. In this\nwork, we consider a challenging yet realistic federated learning scenario where\nthe training data of each client originates from different domains. We address\nthe challenges of domain shift by leveraging the technique of prompt learning,\nand propose a novel method called Federated Dual Prompt Tuning (Fed-DPT).\nSpecifically, Fed-DPT employs a pre-trained vision-language model and then\napplies both visual and textual prompt tuning to facilitate domain adaptation\nover decentralized data. Extensive experiments of Fed-DPT demonstrate its\nsignificant effectiveness in domain-aware federated learning. With a\npre-trained CLIP model (ViT-Base as image encoder), the proposed Fed-DPT\nattains 68.4% average accuracy over six domains in the DomainNet dataset, which\nimproves the original CLIP by a large margin of 14.8%.",
          "link": "http://arxiv.org/abs/2310.03103",
          "publishedOn": "2023-10-07T00:42:18.283Z",
          "wordCount": null,
          "title": "Dual Prompt Tuning for Domain-Aware Federated Learning. (arXiv:2310.03103v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_W/0/1/0/all/0/1\">Woojoo Na</a>",
          "description": "We introduce RACH-Space, a novel classification method in ensemble learning.\nIn particular, we show its applicability as a label model for weakly supervised\nlearning. RACH-Space offers simplicity in implementation with minimal\nassumptions on the data or weak signals. The model is well suited for scenarios\nwhere fully labeled data is not available. Our method is built upon geometrical\ninterpretation of the space spanned by weak signals. Our analysis of the high\ndimensional convex hull structure underlying general set of weak signals\nbridges geometry with machine learning. Empirical results also demonstrate that\nRACH-Space works well in practice and compares favorably to best existing label\nmodels for weakly supervised learning.",
          "link": "http://arxiv.org/abs/2307.04870",
          "publishedOn": "2023-09-30T00:41:35.123Z",
          "wordCount": 642,
          "title": "RACH-Space: Reconstructing Adaptive Convex Hull Space with applications in weak supervision. (arXiv:2307.04870v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1\">Mert Pilanci</a>",
          "description": "In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.",
          "link": "http://arxiv.org/abs/2309.16512",
          "publishedOn": "2023-09-30T00:41:32.940Z",
          "wordCount": 670,
          "title": "From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kishimoto_A/0/1/0/all/0/1\">Akihiro Kishimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1\">Hiroshi Kajino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirose_M/0/1/0/all/0/1\">Masataka Hirose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuchiwaki_J/0/1/0/all/0/1\">Junta Fuchiwaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadarsini_I/0/1/0/all/0/1\">Indra Priyadarsini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamada_L/0/1/0/all/0/1\">Lisa Hamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinohara_H/0/1/0/all/0/1\">Hajime Shinohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakano_D/0/1/0/all/0/1\">Daiju Nakano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_S/0/1/0/all/0/1\">Seiji Takeda</a>",
          "description": "Property prediction plays an important role in material discovery. As an\ninitial step to eventually develop a foundation model for material science, we\nintroduce a new autoencoder called the MHG-GNN, which combines graph neural\nnetwork (GNN) with Molecular Hypergraph Grammar (MHG). Results on a variety of\nproperty prediction tasks with diverse materials show that MHG-GNN is\npromising.",
          "link": "http://arxiv.org/abs/2309.16374",
          "publishedOn": "2023-09-30T00:41:32.934Z",
          "wordCount": 582,
          "title": "MHG-GNN: Combination of Molecular Hypergraph Grammar with Graph Neural Network. (arXiv:2309.16374v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.05135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kaiyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xiao-Jun Zeng</a>",
          "description": "It can largely benefit the reinforcement learning (RL) process of each agent\nif multiple geographically distributed agents perform their separate RL tasks\ncooperatively. Different from multi-agent reinforcement learning (MARL) where\nmultiple agents are in a common environment and should learn to cooperate or\ncompete with each other, in this case each agent has its separate environment\nand only communicates with others to share knowledge without any cooperative or\ncompetitive behaviour as a learning outcome. In fact, this scenario exists\nwidely in real life whose concept can be utilised in many applications, but is\nnot well understood yet and not well formulated. As the first effort, we\npropose group-agent system for RL as a formulation of this scenario and the\nthird type of RL system with respect to single-agent and multi-agent systems.\nWe then propose a distributed RL framework called DDAL (Decentralised\nDistributed Asynchronous Learning) designed for group-agent reinforcement\nlearning (GARL). We show through experiments that DDAL achieved desirable\nperformance with very stable training and has good scalability.",
          "link": "http://arxiv.org/abs/2202.05135",
          "publishedOn": "2023-09-30T00:41:32.875Z",
          "wordCount": 693,
          "title": "Group-Agent Reinforcement Learning. (arXiv:2202.05135v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1\">Jan Hendrik Metzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saranrittichai_P/0/1/0/all/0/1\">Piyapat Saranrittichai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mummadi_C/0/1/0/all/0/1\">Chaithanya Kumar Mummadi</a>",
          "description": "Classifiers built upon vision-language models such as CLIP have shown\nremarkable zero-shot performance across a broad range of image classification\ntasks. Prior work has studied different ways of automatically creating\ndescriptor sets for every class based on prompt templates, ranging from\nmanually engineered templates over templates obtained from a large language\nmodel to templates built from random words and characters. In contrast,\nderiving zero-shot classifiers from the respective encoded class descriptors\nhas remained nearly unchanged, that is: classify to the class that maximizes\nthe cosine similarity between its averaged encoded class descriptors and the\nencoded image. However, weighting all class descriptors equally can be\nsuboptimal when certain descriptors match visual clues on a given image better\nthan others. In this work, we propose AutoCLIP, a method for auto-tuning\nzero-shot classifiers. AutoCLIP assigns to each prompt template per-image\nweights, which are derived from statistics of class descriptor-image\nsimilarities at inference time. AutoCLIP is fully unsupervised, has very low\noverhead, and can be easily implemented in few lines of code. We show that for\na broad range of vision-language models, datasets, and prompt templates,\nAutoCLIP outperforms baselines consistently and by up to 3 percent point\naccuracy.",
          "link": "http://arxiv.org/abs/2309.16414",
          "publishedOn": "2023-09-30T00:41:32.841Z",
          "wordCount": 700,
          "title": "AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models. (arXiv:2309.16414v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.15963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moezzi_M/0/1/0/all/0/1\">Matin Moezzi</a>",
          "description": "Consistency regularization-based methods are prevalent in semi-supervised\nlearning (SSL) algorithms due to their exceptional performance. However, they\nmainly depend on domain-specific data augmentations, which are not usable in\ndomains where data augmentations are less practicable. On the other hand,\nPseudo-labeling (PL) is a general and domain-agnostic SSL approach that, unlike\nconsistency regularization-based methods, does not rely on the domain. PL\nunderperforms due to the erroneous high-confidence predictions from poorly\ncalibrated models. This paper proposes an uncertainty-aware pseudo-label\nselection framework that employs uncertainty sets yielded by the conformal\nregularization algorithm to fix the poor calibration neural networks, reducing\nnoisy training data. The codes of this work are available at:\nhttps://github.com/matinmoezzi/ups conformal classification",
          "link": "http://arxiv.org/abs/2309.15963",
          "publishedOn": "2023-09-30T00:41:32.829Z",
          "wordCount": 603,
          "title": "An Uncertainty-Aware Pseudo-Label Selection Framework using Regularized Conformal Prediction. (arXiv:2309.15963v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trawicki_S/0/1/0/all/0/1\">Stefan Trawicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hackett_W/0/1/0/all/0/1\">William Hackett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_L/0/1/0/all/0/1\">Lewis Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_N/0/1/0/all/0/1\">Neeraj Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garraghan_P/0/1/0/all/0/1\">Peter Garraghan</a>",
          "description": "Adversarial Machine Learning (AML) is a rapidly growing field of security\nresearch, with an often overlooked area being model attacks through\nside-channels. Previous works show such attacks to be serious threats, though\nlittle progress has been made on efficient remediation strategies that avoid\ncostly model re-engineering. This work demonstrates a new defense against AML\nside-channel attacks using model compilation techniques, namely tensor\noptimization. We show relative model attack effectiveness decreases of up to\n43% using tensor optimization, discuss the implications, and direction of\nfuture work.",
          "link": "http://arxiv.org/abs/2309.16577",
          "publishedOn": "2023-09-30T00:41:32.590Z",
          "wordCount": 617,
          "title": "Compilation as a Defense: Enhancing DL Model Attack Robustness via Tensor Optimization. (arXiv:2309.16577v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klinger_T/0/1/0/all/0/1\">Tim Klinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Luke Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1\">Soham Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crouse_M/0/1/0/all/0/1\">Maxwell Crouse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1\">Alexander Gray</a>",
          "description": "Compositional generalization is a key ability of humans that enables us to\nlearn new concepts from only a handful examples. Machine learning models,\nincluding the now ubiquitous transformers, struggle to generalize in this way,\nand typically require thousands of examples of a concept during training in\norder to generalize meaningfully. This difference in ability between humans and\nartificial neural architectures, motivates this study on a neuro-symbolic\narchitecture called the Compositional Program Generator (CPG). CPG has three\nkey features: modularity, type abstraction, and recursive composition, that\nenable it to generalize both systematically to new concepts in a few-shot\nmanner, as well as productively by length on various sequence-to-sequence\nlanguage tasks. For each input, CPG uses a grammar of the input domain and a\nparser to generate a type hierarchy in which each grammar rule is assigned its\nown unique semantic module, a probabilistic copy or substitution program.\nInstances with the same hierarchy are processed with the same composed program,\nwhile those with different hierarchies may be processed with different\nprograms. CPG learns parameters for the semantic modules and is able to learn\nthe semantics for new types incrementally. Given a context-free grammar of the\ninput language and a dictionary mapping each word in the source language to its\ninterpretation in the output language, CPG can achieve perfect generalization\non the SCAN and COGS benchmarks, in both standard and extreme few-shot\nsettings.",
          "link": "http://arxiv.org/abs/2309.16467",
          "publishedOn": "2023-09-30T00:41:32.535Z",
          "wordCount": 758,
          "title": "Compositional Program Generation for Systematic Generalization. (arXiv:2309.16467v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>",
          "description": "Semi-supervised learning (SSL) is a promising approach for training deep\nclassification models using labeled and unlabeled datasets. However, existing\nSSL methods rely on a large unlabeled dataset, which may not always be\navailable in many real-world applications due to legal constraints (e.g.,\nGDPR). In this paper, we investigate the research question: Can we train SSL\nmodels without real unlabeled datasets? Instead of using real unlabeled\ndatasets, we propose an SSL method using synthetic datasets generated from\ngenerative foundation models trained on datasets containing millions of samples\nin diverse domains (e.g., ImageNet). Our main concepts are identifying\nsynthetic samples that emulate unlabeled samples from generative foundation\nmodels and training classifiers using these synthetic samples. To achieve this,\nour method is formulated as an alternating optimization problem: (i)\nmeta-learning of generative foundation models and (ii) SSL of classifiers using\nreal labeled and synthetic unlabeled samples. For (i), we propose a\nmeta-learning objective that optimizes latent variables to generate samples\nthat resemble real labeled samples and minimize the validation loss. For (ii),\nwe propose a simple unsupervised loss function that regularizes the feature\nextractors of classifiers to maximize the performance improvement obtained from\nsynthetic samples. We confirm that our method outperforms baselines using\ngenerative foundation models on SSL. We also demonstrate that our methods\noutperform SSL using real unlabeled datasets in scenarios with extremely small\namounts of labeled datasets. This suggests that synthetic samples have the\npotential to provide improvement gains more efficiently than real unlabeled\ndata.",
          "link": "http://arxiv.org/abs/2309.16143",
          "publishedOn": "2023-09-30T00:41:32.460Z",
          "wordCount": 761,
          "title": "Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.05832",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mengti Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bowen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchini_B/0/1/0/all/0/1\">Bibit Bianchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_C/0/1/0/all/0/1\">Camillo Jose Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Posa_M/0/1/0/all/0/1\">Michael Posa</a>",
          "description": "This work presents an instance-agnostic learning framework that fuses vision\nwith dynamics to simultaneously learn shape, pose trajectories, and physical\nproperties via the use of geometry as a shared representation. Unlike many\ncontact learning approaches that assume motion capture input and a known shape\nprior for the collision model, our proposed framework learns an object's\ngeometric and dynamic properties from RGBD video, without requiring either\ncategory-level or instance-level shape priors. We integrate a vision system,\nBundleSDF, with a dynamics system, ContactNets, and propose a cyclic training\npipeline to use the output from the dynamics module to refine the poses and the\ngeometry from the vision module, using perspective reprojection. Experiments\ndemonstrate our framework's ability to learn the geometry and dynamics of rigid\nand convex objects and improve upon the current tracking framework.",
          "link": "http://arxiv.org/abs/2309.05832",
          "publishedOn": "2023-09-30T00:41:32.379Z",
          "wordCount": 662,
          "title": "Instance-Agnostic Geometry and Contact Dynamics Learning. (arXiv:2309.05832v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.02941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mamedov_S/0/1/0/all/0/1\">Shamil Mamedov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reiter_R/0/1/0/all/0/1\">Rudolf Reiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azad_S/0/1/0/all/0/1\">Seyed Mahdi Basiri Azad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1\">Joschka Boedecker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diehl_M/0/1/0/all/0/1\">Moritz Diehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swevers_J/0/1/0/all/0/1\">Jan Swevers</a>",
          "description": "Flexible robots may overcome some of the industry's major challenges, such as\nenabling intrinsically safe human-robot collaboration and achieving a higher\nload-to-mass ratio. However, controlling flexible robots is complicated due to\ntheir complex dynamics, which include oscillatory behavior and a\nhigh-dimensional state space. NMPC offers an effective means to control such\nrobots, but its extensive computational demands often limit its application in\nreal-time scenarios. To enable fast control of flexible robots, we propose a\nframework for a safe approximation of NMPC using imitation learning and a\npredictive safety filter. Our framework significantly reduces computation time\nwhile incurring a slight loss in performance. Compared to NMPC, our framework\nshows more than a eightfold improvement in computation time when controlling a\nthree-dimensional flexible robot arm in simulation, all while guaranteeing\nsafety constraints. Notably, our approach outperforms conventional\nreinforcement learning methods. The development of fast and safe approximate\nNMPC holds the potential to accelerate the adoption of flexible robots in\nindustry.",
          "link": "http://arxiv.org/abs/2212.02941",
          "publishedOn": "2023-09-30T00:41:32.351Z",
          "wordCount": 701,
          "title": "Safe Imitation Learning of Nonlinear Model Predictive Control for Flexible Robots. (arXiv:2212.02941v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.04811",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Zhang_C/0/1/0/all/0/1\">Cheng Zhang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Sjarif_N/0/1/0/all/0/1\">Nilam Nur Amir Sjarif</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Ibrahim_R/0/1/0/all/0/1\">Roslina Ibrahim</a>",
          "description": "Accurately predicting the prices of financial time series is essential and\nchallenging for the financial sector. Owing to recent advancements in deep\nlearning techniques, deep learning models are gradually replacing traditional\nstatistical and machine learning models as the first choice for price\nforecasting tasks. This shift in model selection has led to a notable rise in\nresearch related to applying deep learning models to price forecasting,\nresulting in a rapid accumulation of new knowledge. Therefore, we conducted a\nliterature review of relevant studies over the past three years with a view to\naiding researchers and practitioners in the field. This review delves deeply\ninto deep learning-based forecasting models, presenting information on model\narchitectures, practical applications, and their respective advantages and\ndisadvantages. In particular, detailed information is provided on advanced\nmodels for price forecasting, such as Transformers, generative adversarial\nnetworks (GANs), graph neural networks (GNNs), and deep quantum neural networks\n(DQNNs). The present contribution also includes potential directions for future\nresearch, such as examining the effectiveness of deep learning models with\ncomplex structures for price forecasting, extending from point prediction to\ninterval prediction using deep learning models, scrutinising the reliability\nand validity of decomposition ensembles, and exploring the influence of data\nvolume on model performance.",
          "link": "http://arxiv.org/abs/2305.04811",
          "publishedOn": "2023-09-30T00:41:31.998Z",
          "wordCount": 775,
          "title": "Deep learning models for price forecasting of financial time series: A review of recent advancements: 2020-2022. (arXiv:2305.04811v2 [q-fin.ST] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haoyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anicic_D/0/1/0/all/0/1\">Darko Anicic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1\">Thomas A. Runkler</a>",
          "description": "The field of Tiny Machine Learning (TinyML) has made substantial advancements\nin democratizing machine learning on low-footprint devices, such as\nmicrocontrollers. The prevalence of these miniature devices raises the question\nof whether aggregating their knowledge can benefit TinyML applications.\nFederated meta-learning is a promising answer to this question, as it addresses\nthe scarcity of labeled data and heterogeneous data distribution across devices\nin the real world. However, deploying TinyML hardware faces unique resource\nconstraints, making existing methods impractical due to energy, privacy, and\ncommunication limitations. We introduce TinyMetaFed, a model-agnostic\nmeta-learning framework suitable for TinyML. TinyMetaFed facilitates\ncollaborative training of a neural network initialization that can be quickly\nfine-tuned on new devices. It offers communication savings and privacy\nprotection through partial local reconstruction and Top-P% selective\ncommunication, computational efficiency via online learning, and robustness to\nclient heterogeneity through few-shot learning. The evaluations on three TinyML\nuse cases demonstrate that TinyMetaFed can significantly reduce energy\nconsumption and communication overhead, accelerate convergence, and stabilize\nthe training process.",
          "link": "http://arxiv.org/abs/2307.06822",
          "publishedOn": "2023-09-30T00:41:31.940Z",
          "wordCount": 716,
          "title": "TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16604",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1\">Junjie Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Labeau_M/0/1/0/all/0/1\">Matthieu Labeau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "Pairwise comparison of graphs is key to many applications in Machine learning\nranging from clustering, kernel-based classification/regression and more\nrecently supervised graph prediction. Distances between graphs usually rely on\ninformative representations of these structured objects such as bag of\nsubstructures or other graph embeddings. A recently popular solution consists\nin representing graphs as metric measure spaces, allowing to successfully\nleverage Optimal Transport, which provides meaningful distances allowing to\ncompare them: the Gromov-Wasserstein distances. However, this family of\ndistances overlooks edge attributes, which are essential for many structured\nobjects. In this work, we introduce an extension of Gromov-Wasserstein distance\nfor comparing graphs whose both nodes and edges have features. We propose novel\nalgorithms for distance and barycenter computation. We empirically show the\neffectiveness of the novel distance in learning tasks where graphs occur in\neither input space or output space, such as classification and graph\nprediction.",
          "link": "http://arxiv.org/abs/2309.16604",
          "publishedOn": "2023-09-30T00:41:31.859Z",
          "wordCount": 649,
          "title": "Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein Distance. (arXiv:2309.16604v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.15891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Keke Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xiong-bin Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Shi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zheng Ma</a>",
          "description": "In this paper, we introduce two types of novel Asymptotic-Preserving\nConvolutional Deep Operator Networks (APCONs) designed to address the\nmultiscale time-dependent linear transport problem. We observe that the vanilla\nphysics-informed DeepONets with modified MLP may exhibit instability in\nmaintaining the desired limiting macroscopic behavior. Therefore, this\nnecessitates the utilization of an asymptotic-preserving loss function. Drawing\ninspiration from the heat kernel in the diffusion equation, we propose a new\narchitecture called Convolutional Deep Operator Networks, which employ multiple\nlocal convolution operations instead of a global heat kernel, along with\npooling and activation operations in each filter layer. Our APCON methods\npossess a parameter count that is independent of the grid size and are capable\nof capturing the diffusive behavior of the linear transport problem. Finally,\nwe validate the effectiveness of our methods through several numerical\nexamples.",
          "link": "http://arxiv.org/abs/2306.15891",
          "publishedOn": "2023-09-30T00:41:31.421Z",
          "wordCount": 698,
          "title": "Capturing the Diffusive Behavior of the Multiscale Linear Transport Equations by Asymptotic-Preserving Convolutional DeepONets. (arXiv:2306.15891v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Neelesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aran_O/0/1/0/all/0/1\">Oya Aran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1\">Venugopal Vasudevan</a>",
          "description": "Automated diagnosis of eczema from digital camera images is crucial for\ndeveloping applications that allow patients to self-monitor their recovery. An\nimportant component of this is the segmentation of eczema region from such\nimages. Current methods for eczema segmentation rely on deep neural networks\nsuch as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While\neffective, these methods require high volume of annotated data, which can be\ndifficult to obtain. Here, we investigate the capabilities of visual in-context\nlearning that can perform few-shot eczema segmentation with just a handful of\nexamples and without any need for retraining models. Specifically, we propose a\nstrategy for applying in-context learning for eczema segmentation with a\ngeneralist vision model called SegGPT. When benchmarked on a dataset of\nannotated eczema images, we show that SegGPT with just 2 representative example\nimages from the training dataset performs better (mIoU: 36.69) than a CNN U-Net\ntrained on 428 images (mIoU: 32.60). We also discover that using more number of\nexamples for SegGPT may in fact be harmful to its performance. Our result\nhighlights the importance of visual in-context learning in developing faster\nand better solutions to skin imaging tasks. Our result also paves the way for\ndeveloping inclusive solutions that can cater to minorities in the demographics\nwho are typically heavily under-represented in the training data.",
          "link": "http://arxiv.org/abs/2309.16656",
          "publishedOn": "2023-09-30T00:41:31.401Z",
          "wordCount": 714,
          "title": "Visual In-Context Learning for Few-Shot Eczema Segmentation. (arXiv:2309.16656v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.06612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghebriout_M/0/1/0/all/0/1\">Mohamed Imed Eddine Ghebriout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouzidi_H/0/1/0/all/0/1\">Halima Bouzidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niar_S/0/1/0/all/0/1\">Smail Niar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouarnoughi_H/0/1/0/all/0/1\">Hamza Ouarnoughi</a>",
          "description": "The recent surge of interest surrounding Multimodal Neural Networks (MM-NN)\nis attributed to their ability to effectively process and integrate multiscale\ninformation from diverse data sources. MM-NNs extract and fuse features from\nmultiple modalities using adequate unimodal backbones and specific fusion\nnetworks. Although this helps strengthen the multimodal information\nrepresentation, designing such networks is labor-intensive. It requires tuning\nthe architectural parameters of the unimodal backbones, choosing the fusing\npoint, and selecting the operations for fusion. Furthermore, multimodality AI\nis emerging as a cutting-edge option in Internet of Things (IoT) systems where\ninference latency and energy consumption are critical metrics in addition to\naccuracy. In this paper, we propose Harmonic-NAS, a framework for the joint\noptimization of unimodal backbones and multimodal fusion networks with hardware\nawareness on resource-constrained devices. Harmonic-NAS involves a two-tier\noptimization approach for the unimodal backbone architectures and fusion\nstrategy and operators. By incorporating the hardware dimension into the\noptimization, evaluation results on various devices and multimodal datasets\nhave demonstrated the superiority of Harmonic-NAS over state-of-the-art\napproaches achieving up to 10.9% accuracy improvement, 1.91x latency reduction,\nand 2.14x energy efficiency gain.",
          "link": "http://arxiv.org/abs/2309.06612",
          "publishedOn": "2023-09-30T00:41:31.351Z",
          "wordCount": 732,
          "title": "Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on Resource-constrained Devices. (arXiv:2309.06612v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.13405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_J/0/1/0/all/0/1\">Jiaxi Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palomar_D/0/1/0/all/0/1\">Daniel P. Palomar</a>",
          "description": "This paper studies the problem of learning the large-scale Gaussian graphical\nmodels that are multivariate totally positive of order two ($\\text{MTP}_2$). By\nintroducing the concept of bridge, which commonly exists in large-scale sparse\ngraphs, we show that the entire problem can be equivalently optimized through\n(1) several smaller-scaled sub-problems induced by a \\emph{bridge-block\ndecomposition} on the thresholded sample covariance graph and (2) a set of\nexplicit solutions on entries corresponding to \\emph{bridges}. From practical\naspect, this simple and provable discipline can be applied to break down a\nlarge problem into small tractable ones, leading to enormous reduction on the\ncomputational complexity and substantial improvements for all existing\nalgorithms. The synthetic and real-world experiments demonstrate that our\nproposed method presents a significant speed-up compared to the\nstate-of-the-art benchmarks.",
          "link": "http://arxiv.org/abs/2309.13405",
          "publishedOn": "2023-09-30T00:41:31.272Z",
          "wordCount": 655,
          "title": "Learning Large-Scale MTP$_2$ Gaussian Graphical Models via Bridge-Block Decomposition. (arXiv:2309.13405v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1911.09307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>",
          "description": "Regularization plays a crucial role in machine learning models, especially\nfor deep neural networks. The existing regularization techniques mainly rely on\nthe i.i.d. assumption and only consider the knowledge from the current sample,\nwithout the leverage of the neighboring relationship between samples. In this\nwork, we propose a general regularizer called \\textbf{Patch-level Neighborhood\nInterpolation~(Pani)} that conducts a non-local representation in the\ncomputation of networks. Our proposal explicitly constructs patch-level graphs\nin different layers and then linearly interpolates neighborhood patch features,\nserving as a general and effective regularization strategy. Further, we\ncustomize our approach into two kinds of popular regularization methods, namely\nVirtual Adversarial Training (VAT) and MixUp as well as its variants. The first\nderived \\textbf{Pani VAT} presents a novel way to construct non-local\nadversarial smoothness by employing patch-level interpolated perturbations. The\nsecond derived \\textbf{Pani MixUp} method extends the MixUp, and achieves\nsuperiority over MixUp and competitive performance over state-of-the-art\nvariants of MixUp method with a significant advantage in computational\nefficiency. Extensive experiments have verified the effectiveness of our Pani\napproach in both supervised and semi-supervised settings.",
          "link": "http://arxiv.org/abs/1911.09307",
          "publishedOn": "2023-09-30T00:41:31.266Z",
          "wordCount": 729,
          "title": "Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.12414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Frank Po-Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1\">Seyyedali Hosseinalipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michelusi_N/0/1/0/all/0/1\">Nicol&#xf2; Michelusi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher Brinton</a>",
          "description": "Federated learning has gained popularity as a means of training models\ndistributed across the wireless edge. The paper introduces delay-aware\nhierarchical federated learning (DFL) to improve the efficiency of distributed\nmachine learning (ML) model training by accounting for communication delays\nbetween edge and cloud. Different from traditional federated learning, DFL\nleverages multiple stochastic gradient descent iterations on local datasets\nwithin each global aggregation period and intermittently aggregates model\nparameters through edge servers in local subnetworks. During global\nsynchronization, the cloud server consolidates local models with the outdated\nglobal model using a local-global combiner, thus preserving crucial elements of\nboth, enhancing learning efficiency under the presence of delay. A set of\nconditions is obtained to achieve the sub-linear convergence rate of O(1/k) for\nstrongly convex and smooth loss functions. Based on these findings, an adaptive\ncontrol algorithm is developed for DFL, implementing policies to mitigate\nenergy consumption and communication latency while aiming for sublinear\nconvergence. Numerical evaluations show DFL's superior performance in terms of\nfaster global model convergence, reduced resource consumption, and robustness\nagainst communication delays compared to existing FL algorithms. In summary,\nthis proposed method offers improved efficiency and results when dealing with\nboth convex and non-convex loss functions.",
          "link": "http://arxiv.org/abs/2303.12414",
          "publishedOn": "2023-09-30T00:41:31.246Z",
          "wordCount": 742,
          "title": "Delay-Aware Hierarchical Federated Learning. (arXiv:2303.12414v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "As machine learning models are increasingly being employed in various\nhigh-stakes settings, it becomes important to ensure that predictions of these\nmodels are not only adversarially robust, but also readily explainable to\nrelevant stakeholders. However, it is unclear if these two notions can be\nsimultaneously achieved or if there exist trade-offs between them. In this\nwork, we make one of the first attempts at studying the impact of adversarially\nrobust models on actionable explanations which provide end users with a means\nfor recourse. We theoretically and empirically analyze the cost (ease of\nimplementation) and validity (probability of obtaining a positive model\nprediction) of recourses output by state-of-the-art algorithms when the\nunderlying models are adversarially robust vs. non-robust. More specifically,\nwe derive theoretical bounds on the differences between the cost and the\nvalidity of the recourses generated by state-of-the-art algorithms for\nadversarially robust vs. non-robust linear and non-linear models. Our empirical\nresults with multiple real-world datasets validate our theoretical results and\nshow the impact of varying degrees of model robustness on the cost and validity\nof the resulting recourses. Our analyses demonstrate that adversarially robust\nmodels significantly increase the cost and reduce the validity of the resulting\nrecourses, thus shedding light on the inherent trade-offs between adversarial\nrobustness and actionable explanations",
          "link": "http://arxiv.org/abs/2309.16452",
          "publishedOn": "2023-09-30T00:41:31.211Z",
          "wordCount": 712,
          "title": "On the Trade-offs between Adversarial Robustness and Actionable Explanations. (arXiv:2309.16452v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16598",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zrnic_T/0/1/0/all/0/1\">Tijana Zrnic</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Candes_E/0/1/0/all/0/1\">Emmanuel J. Cand&#xe8;s</a>",
          "description": "While reliable data-driven decision-making hinges on high-quality labeled\ndata, the acquisition of quality labels often involves laborious human\nannotations or slow and expensive scientific measurements. Machine learning is\nbecoming an appealing alternative as sophisticated predictive techniques are\nbeing used to quickly and cheaply produce large amounts of predicted labels;\ne.g., predicted protein structures are used to supplement experimentally\nderived structures, predictions of socioeconomic indicators from satellite\nimagery are used to supplement accurate survey data, and so on. Since\npredictions are imperfect and potentially biased, this practice brings into\nquestion the validity of downstream inferences. We introduce cross-prediction:\na method for valid inference powered by machine learning. With a small labeled\ndataset and a large unlabeled dataset, cross-prediction imputes the missing\nlabels via machine learning and applies a form of debiasing to remedy the\nprediction inaccuracies. The resulting inferences achieve the desired error\nprobability and are more powerful than those that only leverage the labeled\ndata. Closely related is the recent proposal of prediction-powered inference,\nwhich assumes that a good pre-trained model is already available. We show that\ncross-prediction is consistently more powerful than an adaptation of\nprediction-powered inference in which a fraction of the labeled data is split\noff and used to train the model. Finally, we observe that cross-prediction\ngives more stable conclusions than its competitors; its confidence intervals\ntypically have significantly lower variability.",
          "link": "http://arxiv.org/abs/2309.16598",
          "publishedOn": "2023-09-30T00:41:31.189Z",
          "wordCount": 699,
          "title": "Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16286",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenke Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Mang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zekun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>",
          "description": "Federated learning is an important privacy-preserving multi-party learning\nparadigm, involving collaborative learning with others and local updating on\nprivate data. Model heterogeneity and catastrophic forgetting are two crucial\nchallenges, which greatly limit the applicability and generalizability. This\npaper presents a novel FCCL+, federated correlation and similarity learning\nwith non-target distillation, facilitating the both intra-domain\ndiscriminability and inter-domain generalization. For heterogeneity issue, we\nleverage irrelevant unlabeled public data for communication between the\nheterogeneous participants. We construct cross-correlation matrix and align\ninstance similarity distribution on both logits and feature levels, which\neffectively overcomes the communication barrier and improves the generalizable\nability. For catastrophic forgetting in local updating stage, FCCL+ introduces\nFederated Non Target Distillation, which retains inter-domain knowledge while\navoiding the optimization conflict issue, fulling distilling privileged\ninter-domain information through depicting posterior classes relation.\nConsidering that there is no standard benchmark for evaluating existing\nheterogeneous federated learning under the same setting, we present a\ncomprehensive benchmark with extensive representative methods under four domain\nshift scenarios, supporting both heterogeneous and homogeneous federated\nsettings. Empirical results demonstrate the superiority of our method and the\nefficiency of modules on various scenarios.",
          "link": "http://arxiv.org/abs/2309.16286",
          "publishedOn": "2023-09-30T00:41:31.183Z",
          "wordCount": 692,
          "title": "Generalizable Heterogeneous Federated Cross-Correlation and Instance Similarity Learning. (arXiv:2309.16286v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16235",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Janakarajan_N/0/1/0/all/0/1\">Nikita Janakarajan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Erdmann_T/0/1/0/all/0/1\">Tim Erdmann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Swaminathan_S/0/1/0/all/0/1\">Sarath Swaminathan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Laino_T/0/1/0/all/0/1\">Teodoro Laino</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Born_J/0/1/0/all/0/1\">Jannis Born</a>",
          "description": "The success of language models, especially transformer-based architectures,\nhas trickled into other domains giving rise to \"scientific language models\"\nthat operate on small molecules, proteins or polymers. In chemistry, language\nmodels contribute to accelerating the molecule discovery cycle as evidenced by\npromising recent findings in early-stage drug discovery. Here, we review the\nrole of language models in molecular discovery, underlining their strength in\nde novo drug design, property prediction and reaction chemistry. We highlight\nvaluable open-source software assets thus lowering the entry barrier to the\nfield of scientific language modeling. Last, we sketch a vision for future\nmolecular design that combines a chatbot interface with access to computational\nchemistry tools. Our contribution serves as a valuable resource for\nresearchers, chemists, and AI enthusiasts interested in understanding how\nlanguage models can and will be used to accelerate chemical discovery.",
          "link": "http://arxiv.org/abs/2309.16235",
          "publishedOn": "2023-09-30T00:41:31.148Z",
          "wordCount": 640,
          "title": "Language models in molecular discovery. (arXiv:2309.16235v1 [physics.chem-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.12405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chou_G/0/1/0/all/0/1\">Glen Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tedrake_R/0/1/0/all/0/1\">Russ Tedrake</a>",
          "description": "We present a method for synthesizing dynamic, reduced-order output-feedback\npolynomial control policies for control-affine nonlinear systems which\nguarantees runtime stability to a goal state, when using visual observations\nand a learned perception module in the feedback control loop. We leverage\nLyapunov analysis to formulate the problem of synthesizing such policies. This\nproblem is nonconvex in the policy parameters and the Lyapunov function that is\nused to prove the stability of the policy. To solve this problem approximately,\nwe propose two approaches: the first solves a sequence of sum-of-squares\noptimization problems to iteratively improve a policy which is provably-stable\nby construction, while the second directly performs gradient-based optimization\non the parameters of the polynomial policy, and its closed-loop stability is\nverified a posteriori. We extend our approach to provide stability guarantees\nin the presence of observation noise, which realistically arises due to errors\nin the learned perception module. We evaluate our approach on several\nunderactuated nonlinear systems, including pendula and quadrotors, showing that\nour guarantees translate to empirical stability when controlling these systems\nfrom images, while baseline approaches can fail to reliably stabilize the\nsystem.",
          "link": "http://arxiv.org/abs/2304.12405",
          "publishedOn": "2023-09-30T00:41:31.148Z",
          "wordCount": null,
          "title": "Synthesizing Stable Reduced-Order Visuomotor Policies for Nonlinear Systems via Sums-of-Squares Optimization. (arXiv:2304.12405v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1\">Leonardo Cotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yehuda_G/0/1/0/all/0/1\">Gal Yehuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_A/0/1/0/all/0/1\">Assaf Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1\">Chris J. Maddison</a>",
          "description": "Designing models that are both expressive and preserve known invariances of\ntasks is an increasingly hard problem. Existing solutions tradeoff invariance\nfor computational or memory resources. In this work, we show how to leverage\nrandomness and design models that are both expressive and invariant but use\nless resources. Inspired by randomized algorithms, our key insight is that\naccepting probabilistic notions of universal approximation and invariance can\nreduce our resource requirements. More specifically, we propose a class of\nbinary classification models called Randomized Linear Classifiers (RLCs). We\ngive parameter and sample size conditions in which RLCs can, with high\nprobability, approximate any (smooth) function while preserving invariance to\ncompact group transformations. Leveraging this result, we design three RLCs\nthat are provably probabilistic invariant for classification tasks over sets,\ngraphs, and spherical data. We show how these models can achieve probabilistic\ninvariance and universality using less resources than (deterministic) neural\nnetworks and their invariant counterparts. Finally, we empirically demonstrate\nthe benefits of this new class of models on invariant tasks where deterministic\ninvariant neural networks are known to struggle.",
          "link": "http://arxiv.org/abs/2308.04412",
          "publishedOn": "2023-09-30T00:41:31.114Z",
          "wordCount": null,
          "title": "Probabilistic Invariant Learning with Randomized Linear Classifiers. (arXiv:2308.04412v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muttenthaler_L/0/1/0/all/0/1\">Lukas Muttenthaler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandermeulen_R/0/1/0/all/0/1\">Robert A. Vandermeulen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiuyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>",
          "description": "Model overconfidence and poor calibration are common in machine learning and\ndifficult to account for when applying standard empirical risk minimization. In\nthis work, we propose a novel method to alleviate these problems that we call\nodd-$k$-out learning (OKO), which minimizes the cross-entropy error for sets\nrather than for single examples. This naturally allows the model to capture\ncorrelations across data examples and achieves both better accuracy and\ncalibration, especially in limited training data and class-imbalanced regimes.\nPerhaps surprisingly, OKO often yields better calibration even when training\nwith hard labels and dropping any additional calibration parameter tuning, such\nas temperature scaling. We provide theoretical justification, establishing that\nOKO naturally yields better calibration, and provide extensive experimental\nanalyses that corroborate our theoretical findings. We emphasize that OKO is a\ngeneral framework that can be easily adapted to many settings and the trained\nmodel can be applied to single examples at inference time, without introducing\nsignificant run-time overhead or architecture changes.",
          "link": "http://arxiv.org/abs/2307.02245",
          "publishedOn": "2023-09-30T00:41:31.103Z",
          "wordCount": null,
          "title": "Set Learning for Accurate and Calibrated Models. (arXiv:2307.02245v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Milling_M/0/1/0/all/0/1\">Manuel Milling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triantafyllopoulos_A/0/1/0/all/0/1\">Andreas Triantafyllopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsangko_I/0/1/0/all/0/1\">Iosif Tsangko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rampp_S/0/1/0/all/0/1\">Simon David Noel Rampp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn Wolfgang Schuller</a>",
          "description": "The correlation between the sharpness of loss minima and generalisation in\nthe context of deep neural networks has been subject to discussion for a long\ntime. Whilst mostly investigated in the context of selected benchmark data sets\nin the area of computer vision, we explore this aspect for the audio scene\nclassification task of the DCASE2020 challenge data. Our analysis is based on\ntwodimensional filter-normalised visualisations and a derived sharpness\nmeasure. Our exploratory analysis shows that sharper minima tend to show better\ngeneralisation than flat minima -even more so for out-of-domain data, recorded\nfrom previously unseen devices-, thus adding to the dispute about better\ngeneralisation capabilities of flat minima. We further find that, in\nparticular, the choice of optimisers is a main driver of the sharpness of\nminima and we discuss resulting limitations with respect to comparability. Our\ncode, trained model states and loss landscape visualisations are publicly\navailable.",
          "link": "http://arxiv.org/abs/2309.16369",
          "publishedOn": "2023-09-30T00:41:31.038Z",
          "wordCount": null,
          "title": "Bringing the Discussion of Minima Sharpness to the Audio Domain: a Filter-Normalised Evaluation for Acoustic Scene Classification. (arXiv:2309.16369v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.03559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xihong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Ke Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sihang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinwang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1\">En Zhu</a>",
          "description": "Contrastive deep graph clustering (CDGC) utilizes contrastive learning to\ngroup nodes into different clusters. Better augmentation techniques benefit the\nquality of the contrastive samples, thus being one of key factors to improve\nperformance. However, the augmentation samples in existing methods are always\npredefined by human experiences, and agnostic from the downstream task\nclustering, thus leading to high human resource costs and poor performance. To\nthis end, we propose an Attribute Graph Clustering method via Learnable\nAugmentation (\\textbf{AGCLA}), which introduces learnable augmentors for\nhigh-quality and suitable augmented samples for CDGC. Specifically, we design\ntwo learnable augmentors for attribute and structure information, respectively.\nBesides, two refinement matrices, including the high-confidence pseudo-label\nmatrix and the cross-view sample similarity matrix, are generated to improve\nthe reliability of the learned affinity matrix. During the training procedure,\nwe notice that there exist differences between the optimization goals for\ntraining learnable augmentors and contrastive learning networks. In other\nwords, we should both guarantee the consistency of the embeddings as well as\nthe diversity of the augmented samples. Thus, an adversarial learning mechanism\nis designed in our method. Moreover, a two-stage training strategy is leveraged\nfor the high-confidence refinement matrices. Extensive experimental results\ndemonstrate the effectiveness of AGCLA on six benchmark datasets.",
          "link": "http://arxiv.org/abs/2212.03559",
          "publishedOn": "2023-09-30T00:41:31.037Z",
          "wordCount": null,
          "title": "Attribute Graph Clustering via Learnable Augmentation. (arXiv:2212.03559v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dulny_A/0/1/0/all/0/1\">Andrzej Dulny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotho_A/0/1/0/all/0/1\">Andreas Hotho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Anna Krause</a>",
          "description": "Previous work on learning physical systems from data has focused on\nhigh-resolution grid-structured measurements. However, real-world knowledge of\nsuch systems (e.g. weather data) relies on sparsely scattered measuring\nstations. In this paper, we introduce a novel simulated benchmark dataset,\nDynaBench, for learning dynamical systems directly from sparsely scattered data\nwithout prior knowledge of the equations. The dataset focuses on predicting the\nevolution of a dynamical system from low-resolution, unstructured measurements.\nWe simulate six different partial differential equations covering a variety of\nphysical systems commonly used in the literature and evaluate several machine\nlearning models, including traditional graph neural networks and point cloud\nprocessing models, with the task of predicting the evolution of the system. The\nproposed benchmark dataset is expected to advance the state of art as an\nout-of-the-box easy-to-use tool for evaluating models in a setting where only\nunstructured low-resolution observations are available. The benchmark is\navailable at https://anonymous.4open.science/r/code-2022-dynabench/.",
          "link": "http://arxiv.org/abs/2306.05805",
          "publishedOn": "2023-09-30T00:41:31.036Z",
          "wordCount": null,
          "title": "DynaBench: A benchmark dataset for learning dynamical systems from low-resolution data. (arXiv:2306.05805v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.12814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yan Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_T/0/1/0/all/0/1\">Tianyuan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Yanhong Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuanqin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xiaozhou Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1\">Ye Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya-Qin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>",
          "description": "Vertical Federated Learning (VFL) is a federated learning setting where\nmultiple parties with different features about the same set of users jointly\ntrain machine learning models without exposing their raw data or model\nparameters. Motivated by the rapid growth in VFL research and real-world\napplications, we provide a comprehensive review of the concept and algorithms\nof VFL, as well as current advances and challenges in various aspects,\nincluding effectiveness, efficiency, and privacy. We provide an exhaustive\ncategorization for VFL settings and privacy-preserving protocols and\ncomprehensively analyze the privacy attacks and defense strategies for each\nprotocol. In the end, we propose a unified framework, termed VFLow, which\nconsiders the VFL problem under communication, computation, privacy, as well as\neffectiveness and fairness constraints. Finally, we review the most recent\nadvances in industrial applications, highlighting open challenges and future\ndirections for VFL.",
          "link": "http://arxiv.org/abs/2211.12814",
          "publishedOn": "2023-09-30T00:41:31.035Z",
          "wordCount": null,
          "title": "Vertical Federated Learning: Concepts, Advances and Challenges. (arXiv:2211.12814v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haichao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sateesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Heng Wang</a>",
          "description": "The quality of pre-training data plays a critical role in the performance of\nfoundation models. Popular foundation models often design their own recipe for\ndata filtering, which makes it hard to analyze and compare different data\nfiltering approaches. DataComp is a new benchmark dedicated to evaluating\ndifferent methods for data filtering. This paper describes our learning and\nsolution when participating in the DataComp challenge. Our filtering strategy\nincludes three stages: single-modality filtering, cross-modality filtering, and\ndata distribution alignment. We integrate existing methods and propose new\nsolutions, such as computing CLIP score on horizontally flipped images to\nmitigate the interference of scene text, using vision and language models to\nretrieve training samples for target downstream tasks, rebalancing the data\ndistribution to improve the efficiency of allocating the computational budget,\netc. We slice and dice our design choices, provide in-depth analysis, and\ndiscuss open questions. Our approach outperforms the best method from the\nDataComp paper by over 4% on the average performance of 38 tasks and by over 2%\non ImageNet.",
          "link": "http://arxiv.org/abs/2309.15954",
          "publishedOn": "2023-09-30T00:41:31.027Z",
          "wordCount": null,
          "title": "The Devil is in the Details: A Deep Dive into the Rabbit Hole of Data Filtering. (arXiv:2309.15954v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezapour_M/0/1/0/all/0/1\">Mostafa Rezapour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seymour_R/0/1/0/all/0/1\">Rachel B. Seymour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sims_S/0/1/0/all/0/1\">Stephen H. Sims</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karunakar_M/0/1/0/all/0/1\">Madhav A. Karunakar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habet_N/0/1/0/all/0/1\">Nahir Habet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurcan_M/0/1/0/all/0/1\">Metin Nafi Gurcan</a>",
          "description": "This study explored the potential of gait analysis as a tool for assessing\npost-injury complications, e.g., infection, malunion, or hardware irritation,\nin patients with lower extremity fractures. The research focused on the\nproficiency of supervised machine learning models predicting complications\nusing consecutive gait datasets. We identified patients with lower extremity\nfractures at an academic center. Patients underwent gait analysis with a\nchest-mounted IMU device. Using software, raw gait data was preprocessed,\nemphasizing 12 essential gait variables. Machine learning models including\nXGBoost, Logistic Regression, SVM, LightGBM, and Random Forest were trained,\ntested, and evaluated. Attention was given to class imbalance, addressed using\nSMOTE. We introduced a methodology to compute the Rate of Change (ROC) for gait\nvariables, independent of the time difference between gait analyses. XGBoost\nwas the optimal model both before and after applying SMOTE. Prior to SMOTE, the\nmodel achieved an average test AUC of 0.90 (95% CI: [0.79, 1.00]) and test\naccuracy of 86% (95% CI: [75%, 97%]). Feature importance analysis attributed\nimportance to the duration between injury and gait analysis. Data patterns\nshowed early physiological compensations, followed by stabilization phases,\nemphasizing prompt gait analysis. This study underscores the potential of\nmachine learning, particularly XGBoost, in gait analysis for orthopedic care.\nPredicting post-injury complications, early gait assessment becomes vital,\nrevealing intervention points. The findings support a shift in orthopedics\ntowards a data-informed approach, enhancing patient outcomes.",
          "link": "http://arxiv.org/abs/2309.15990",
          "publishedOn": "2023-09-30T00:41:31.027Z",
          "wordCount": null,
          "title": "Machine Learning Based Analytics for the Significance of Gait Analysis in Monitoring and Managing Lower Extremity Injuries. (arXiv:2309.15990v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiongye Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gengshuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1\">Gaurav Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaxing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Mingxi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1\">Paul Bogdan</a>",
          "description": "Integrating and processing information from various sources or modalities are\ncritical for obtaining a comprehensive and accurate perception of the real\nworld. Drawing inspiration from neuroscience, we develop the\nInformation-Theoretic Hierarchical Perception (ITHP) model, which utilizes the\nconcept of information bottleneck. Distinct from most traditional fusion models\nthat aim to incorporate all modalities as input, our model designates the prime\nmodality as input, while the remaining modalities act as detectors in the\ninformation pathway. Our proposed perception model focuses on constructing an\neffective and compact information flow by achieving a balance between the\nminimization of mutual information between the latent state and the input modal\nstate, and the maximization of mutual information between the latent states and\nthe remaining modal states. This approach leads to compact latent state\nrepresentations that retain relevant information while minimizing redundancy,\nthereby substantially enhancing the performance of downstream tasks.\nExperimental evaluations on both the MUStARD and CMU-MOSI datasets demonstrate\nthat our model consistently distills crucial information in multimodal learning\nscenarios, outperforming state-of-the-art benchmarks.",
          "link": "http://arxiv.org/abs/2309.15877",
          "publishedOn": "2023-09-30T00:41:31.026Z",
          "wordCount": null,
          "title": "Neuro-Inspired Hierarchical Multimodal Learning. (arXiv:2309.15877v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_Y/0/1/0/all/0/1\">Yash Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandal_M/0/1/0/all/0/1\">Murari Mandal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kankanhalli_M/0/1/0/all/0/1\">Mohan Kankanhalli</a>",
          "description": "Graph unlearning has emerged as a pivotal method to delete information from a\npre-trained graph neural network (GNN). One may delete nodes, a class of nodes,\nedges, or a class of edges. An unlearning method enables the GNN model to\ncomply with data protection regulations (i.e., the right to be forgotten),\nadapt to evolving data distributions, and reduce the GPU-hours carbon footprint\nby avoiding repetitive retraining. Existing partitioning and aggregation-based\nmethods have limitations due to their poor handling of local graph dependencies\nand additional overhead costs. More recently, GNNDelete offered a\nmodel-agnostic approach that alleviates some of these issues. Our work takes a\nnovel approach to address these challenges in graph unlearning through\nknowledge distillation, as it distills to delete in GNN (D2DGN). It is a\nmodel-agnostic distillation framework where the complete graph knowledge is\ndivided and marked for retention and deletion. It performs distillation with\nresponse-based soft targets and feature-based node embedding while minimizing\nKL divergence. The unlearned model effectively removes the influence of deleted\ngraph elements while preserving knowledge about the retained graph elements.\nD2DGN surpasses the performance of existing methods when evaluated on various\nreal-world graph datasets by up to $43.1\\%$ (AUC) in edge and node unlearning\ntasks. Other notable advantages include better efficiency, better performance\nin removing target elements, preservation of performance for the retained\nelements, and zero overhead costs. Notably, our D2DGN surpasses the\nstate-of-the-art GNNDelete in AUC by $2.4\\%$, improves membership inference\nratio by $+1.3$, requires $10.2\\times10^6$ fewer FLOPs per forward pass and up\nto $\\mathbf{3.2}\\times$ faster.",
          "link": "http://arxiv.org/abs/2309.16173",
          "publishedOn": "2023-09-30T00:41:31.026Z",
          "wordCount": null,
          "title": "Distill to Delete: Unlearning in Graph Networks with Knowledge Distillation. (arXiv:2309.16173v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16595",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingjian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1\">Qiaozhu Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaqi Ma</a>",
          "description": "This paper studies Large Language Models (LLMs) for structured\ndata--particularly graphs--a crucial data modality that remains underexplored\nin the LLM literature. We aim to understand when and why the incorporation of\nstructural information inherent in graph data can improve the prediction\nperformance of LLMs on node classification tasks. To address the ``when''\nquestion, we examine a variety of prompting methods for encoding structural\ninformation, in settings where textual node features are either rich or scarce.\nFor the ``why'' questions, we probe into two potential contributing factors to\nthe LLM performance: data leakage and homophily. Our exploration of these\nquestions reveals that (i) LLMs can benefit from structural information,\nespecially when textual node features are scarce; (ii) there is no substantial\nevidence indicating that the performance of LLMs is significantly attributed to\ndata leakage; and (iii) the performance of LLMs on a target node is strongly\npositively related to the local homophily ratio of the node.",
          "link": "http://arxiv.org/abs/2309.16595",
          "publishedOn": "2023-09-30T00:41:31.001Z",
          "wordCount": null,
          "title": "Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why. (arXiv:2309.16595v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seff_A/0/1/0/all/0/1\">Ari Seff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cera_B/0/1/0/all/0/1\">Brian Cera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1\">Mason Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aurick Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayakanti_N/0/1/0/all/0/1\">Nigamaa Nayakanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Refaat_K/0/1/0/all/0/1\">Khaled S. Refaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1\">Rami Al-Rfou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1\">Benjamin Sapp</a>",
          "description": "Reliable forecasting of the future behavior of road agents is a critical\ncomponent to safe planning in autonomous vehicles. Here, we represent\ncontinuous trajectories as sequences of discrete motion tokens and cast\nmulti-agent motion prediction as a language modeling task over this domain. Our\nmodel, MotionLM, provides several advantages: First, it does not require\nanchors or explicit latent variable optimization to learn multimodal\ndistributions. Instead, we leverage a single standard language modeling\nobjective, maximizing the average log probability over sequence tokens. Second,\nour approach bypasses post-hoc interaction heuristics where individual agent\ntrajectory generation is conducted prior to interactive scoring. Instead,\nMotionLM produces joint distributions over interactive agent futures in a\nsingle autoregressive decoding process. In addition, the model's sequential\nfactorization enables temporally causal conditional rollouts. The proposed\napproach establishes new state-of-the-art performance for multi-agent motion\nprediction on the Waymo Open Motion Dataset, ranking 1st on the interactive\nchallenge leaderboard.",
          "link": "http://arxiv.org/abs/2309.16534",
          "publishedOn": "2023-09-30T00:41:31.000Z",
          "wordCount": null,
          "title": "MotionLM: Multi-Agent Motion Forecasting as Language Modeling. (arXiv:2309.16534v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1\">Manish Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_M/0/1/0/all/0/1\">Moitreya Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1\">Kuan-Chuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lohit_S/0/1/0/all/0/1\">Suhas Lohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1\">Michael Jones</a>",
          "description": "The primary bottleneck towards obtaining good recognition performance in IR\nimages is the lack of sufficient labeled training data, owing to the cost of\nacquiring such data. Realizing that object detection methods for the RGB\nmodality are quite robust (at least for some commonplace classes, like person,\ncar, etc.), thanks to the giant training sets that exist, in this work we seek\nto leverage cues from the RGB modality to scale object detectors to the IR\nmodality, while preserving model performance in the RGB modality. At the core\nof our method, is a novel tensor decomposition method called TensorFact which\nsplits the convolution kernels of a layer of a Convolutional Neural Network\n(CNN) into low-rank factor matrices, with fewer parameters than the original\nCNN. We first pretrain these factor matrices on the RGB modality, for which\nplenty of training data are assumed to exist and then augment only a few\ntrainable parameters for training on the IR modality to avoid over-fitting,\nwhile encouraging them to capture complementary cues from those trained only on\nthe RGB modality. We validate our approach empirically by first assessing how\nwell our TensorFact decomposed network performs at the task of detecting\nobjects in RGB images vis-a-vis the original network and then look at how well\nit adapts to IR images of the FLIR ADAS v1 dataset. For the latter, we train\nmodels under scenarios that pose challenges stemming from data paucity. From\nthe experiments, we observe that: (i) TensorFact shows performance gains on RGB\nimages; (ii) further, this pre-trained model, when fine-tuned, outperforms a\nstandard state-of-the-art object detector on the FLIR ADAS v1 dataset by about\n4% in terms of mAP 50 score.",
          "link": "http://arxiv.org/abs/2309.16592",
          "publishedOn": "2023-09-30T00:41:30.999Z",
          "wordCount": null,
          "title": "Tensor Factorization for Leveraging Cross-Modal Knowledge in Data-Constrained Infrared Object Detection. (arXiv:2309.16592v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianci Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feijie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Lu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jing Gao</a>",
          "description": "Fair machine learning seeks to mitigate model prediction bias against certain\ndemographic subgroups such as elder and female. Recently, fair representation\nlearning (FRL) trained by deep neural networks has demonstrated superior\nperformance, whereby representations containing no demographic information are\ninferred from the data and then used as the input to classification or other\ndownstream tasks. Despite the development of FRL methods, their vulnerability\nunder data poisoning attack, a popular protocol to benchmark model robustness\nunder adversarial scenarios, is under-explored. Data poisoning attacks have\nbeen developed for classical fair machine learning methods which incorporate\nfairness constraints into shallow-model classifiers. Nonetheless, these attacks\nfall short in FRL due to notably different fairness goals and model\narchitectures. This work proposes the first data poisoning framework attacking\nFRL. We induce the model to output unfair representations that contain as much\ndemographic information as possible by injecting carefully crafted poisoning\nsamples into the training data. This attack entails a prohibitive bilevel\noptimization, wherefore an effective approximated solution is proposed. A\ntheoretical analysis on the needed number of poisoning samples is derived and\nsheds light on defending against the attack. Experiments on benchmark fairness\ndatasets and state-of-the-art fair representation learning models demonstrate\nthe superiority of our attack.",
          "link": "http://arxiv.org/abs/2309.16487",
          "publishedOn": "2023-09-30T00:41:30.998Z",
          "wordCount": null,
          "title": "Towards Poisoning Fair Representations. (arXiv:2309.16487v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cadambe_V/0/1/0/all/0/1\">Viveck R. Cadambe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devulapalli_A/0/1/0/all/0/1\">Ateet Devulapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1\">Haewon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>",
          "description": "We consider the problem of private distributed multi-party multiplication. It\nis well-established that Shamir secret-sharing coding strategies can enable\nperfect information-theoretic privacy in distributed computation via the\ncelebrated algorithm of Ben Or, Goldwasser and Wigderson (the \"BGW algorithm\").\nHowever, perfect privacy and accuracy require an honest majority, that is, $N\n\\geq 2t+1$ compute nodes are required to ensure privacy against any $t$\ncolluding adversarial nodes. By allowing for some controlled amount of\ninformation leakage and approximate multiplication instead of exact\nmultiplication, we study coding schemes for the setting where the number of\nhonest nodes can be a minority, that is $N< 2t+1.$ We develop a tight\ncharacterization privacy-accuracy trade-off for cases where $N < 2t+1$ by\nmeasuring information leakage using {differential} privacy instead of perfect\nprivacy, and using the mean squared error metric for accuracy. A novel\ntechnical aspect is an intricately layered noise distribution that merges ideas\nfrom differential privacy and Shamir secret-sharing at different layers.",
          "link": "http://arxiv.org/abs/2309.16105",
          "publishedOn": "2023-09-30T00:41:30.898Z",
          "wordCount": 699,
          "title": "Differentially Private Secure Multiplication: Hiding Information in the Rubble of Noise. (arXiv:2309.16105v1 [cs.IT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16409",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhang Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "The purpose of this work is to transport the information from multiple\nrandomized controlled trials to the target population where we only have the\ncontrol group data. Previous works rely critically on the mean exchangeability\nassumption. However, as pointed out by many current studies, the mean\nexchangeability assumption might be violated. Motivated by the synthetic\ncontrol method, we construct a synthetic treatment group for the target\npopulation by a weighted mixture of treatment groups of source populations. We\nestimate the weights by minimizing the conditional maximum mean discrepancy\nbetween the weighted control groups of source populations and the target\npopulation. We establish the asymptotic normality of the synthetic treatment\ngroup estimator based on the sieve semiparametric theory. Our method can serve\nas a novel complementary approach when the mean exchangeability assumption is\nviolated. Experiments are conducted on synthetic and real-world datasets to\ndemonstrate the effectiveness of our methods.",
          "link": "http://arxiv.org/abs/2309.16409",
          "publishedOn": "2023-09-30T00:41:30.881Z",
          "wordCount": 648,
          "title": "Constructing Synthetic Treatment Groups without the Mean Exchangeability Assumption. (arXiv:2309.16409v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhiwei Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Dawei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Fengzhe Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhuo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zongwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1\">Jidong Ge</a>",
          "description": "Large language models (LLMs) have demonstrated strong capabilities in various\naspects. However, when applying them to the highly specialized, safe-critical\nlegal domain, it is unclear how much legal knowledge they possess and whether\nthey can reliably perform legal-related tasks. To address this gap, we propose\na comprehensive evaluation benchmark LawBench. LawBench has been meticulously\ncrafted to have precise assessment of the LLMs' legal capabilities from three\ncognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize\nneeded legal concepts, articles and facts; (2) Legal knowledge understanding:\nwhether LLMs can comprehend entities, events and relationships within legal\ntext; (3) Legal knowledge applying: whether LLMs can properly utilize their\nlegal knowledge and make necessary reasoning steps to solve realistic legal\ntasks. LawBench contains 20 diverse tasks covering 5 task types: single-label\nclassification (SLC), multi-label classification (MLC), regression, extraction\nand generation. We perform extensive evaluations of 51 LLMs on LawBench,\nincluding 20 multilingual LLMs, 22 Chinese-oriented LLMs and 9 legal specific\nLLMs. The results show that GPT-4 remains the best-performing LLM in the legal\ndomain, surpassing the others by a significant margin. While fine-tuning LLMs\non legal specific text brings certain improvements, we are still a long way\nfrom obtaining usable and reliable LLMs in legal tasks. All data, model\npredictions and evaluation code are released in\nhttps://github.com/open-compass/LawBench/. We hope this benchmark provides\nin-depth understanding of the LLMs' domain-specified capabilities and speed up\nthe development of LLMs in the legal domain.",
          "link": "http://arxiv.org/abs/2309.16289",
          "publishedOn": "2023-09-30T00:41:30.860Z",
          "wordCount": 754,
          "title": "LawBench: Benchmarking Legal Knowledge of Large Language Models. (arXiv:2309.16289v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1\">Wenzhuo Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qu_A/0/1/0/all/0/1\">Annie Qu</a>",
          "description": "Batch reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data lacking exhaustive exploration. Worst-case optimality algorithms,\nwhich calibrate a value-function model class from logged experience and perform\nsome type of pessimistic evaluation under the learned model, have emerged as a\npromising paradigm for batch RL. However, contemporary works on this stream\nhave commonly overlooked the hierarchical decision-making structure hidden in\nthe optimization landscape. In this paper, we adopt a game-theoretical\nviewpoint and model the policy learning diagram as a two-player general-sum\ngame with a leader-follower structure. We propose a novel stochastic\ngradient-based learning algorithm: StackelbergLearner, in which the leader\nplayer updates according to the total derivative of its objective instead of\nthe usual individual gradient, and the follower player makes individual updates\nand ensures transition-consistent pessimistic reasoning. The derived learning\ndynamic naturally lends StackelbergLearner to a game-theoretic interpretation\nand provides a convergence guarantee to differentiable Stackelberg equilibria.\nFrom a theoretical standpoint, we provide instance-dependent regret bounds with\ngeneral function approximation, which shows that our algorithm can learn a\nbest-effort policy that is able to compete against any comparator policy that\nis covered by batch data. Notably, our theoretical regret guarantees only\nrequire realizability without any data coverage and strong function\napproximation conditions, e.g., Bellman closedness, which is in contrast to\nprior works lacking such guarantees. Through comprehensive experiments, we find\nthat our algorithm consistently performs as well or better as compared to\nstate-of-the-art methods in batch RL benchmark and real-world datasets.",
          "link": "http://arxiv.org/abs/2309.16188",
          "publishedOn": "2023-09-30T00:41:30.854Z",
          "wordCount": 724,
          "title": "Stackelberg Batch Policy Learning. (arXiv:2309.16188v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We study unconstrained Online Linear Optimization with Lipschitz losses. The\ngoal is to simultaneously achieve ($i$) second order gradient adaptivity; and\n($ii$) comparator norm adaptivity also known as \"parameter freeness\" in the\nliterature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and\nKoolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\\sqrt{V_T\\log\nV_T})$ dependence on the gradient variance $V_T$, while the present work\nimproves it to the optimal rate $O(\\sqrt{V_T})$ using a novel\ncontinuous-time-inspired algorithm, without any impractical doubling trick.\nThis result can be extended to the setting with unknown Lipschitz constant,\neliminating the range ratio problem from prior works (Mhammedi and Koolen,\n2020).\n\nConcretely, we first show that the aimed simultaneous adaptivity can be\nachieved fairly easily in a continuous time analogue of the problem, where the\nenvironment is modeled by an arbitrary continuous semimartingale. Then, our key\ninnovation is a new discretization argument that preserves such adaptivity in\nthe discrete time adversarial setting. This refines a non-gradient-adaptive\ndiscretization argument from (Harvey et al., 2023), both algorithmically and\nanalytically, which could be of independent interest.",
          "link": "http://arxiv.org/abs/2309.16044",
          "publishedOn": "2023-09-30T00:41:30.846Z",
          "wordCount": 680,
          "title": "Improving Adaptive Online Learning Using Refined Discretization. (arXiv:2309.16044v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kraus_O/0/1/0/all/0/1\">Oren Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenyon_Dean_K/0/1/0/all/0/1\">Kian Kenyon-Dean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saberian_S/0/1/0/all/0/1\">Saber Saberian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fallah_M/0/1/0/all/0/1\">Maryam Fallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McLean_P/0/1/0/all/0/1\">Peter McLean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_J/0/1/0/all/0/1\">Jess Leung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1\">Vasudev Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Ayla Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_J/0/1/0/all/0/1\">Jia Balakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celik_S/0/1/0/all/0/1\">Safiye Celik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sypetkowski_M/0/1/0/all/0/1\">Maciej Sypetkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Chi Vicky Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morse_K/0/1/0/all/0/1\">Kristen Morse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makes_M/0/1/0/all/0/1\">Maureen Makes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mabey_B/0/1/0/all/0/1\">Ben Mabey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Earnshaw_B/0/1/0/all/0/1\">Berton Earnshaw</a>",
          "description": "Inferring biological relationships from cellular phenotypes in high-content\nmicroscopy screens provides significant opportunity and challenge in biological\nresearch. Prior results have shown that deep vision models can capture\nbiological signal better than hand-crafted features. This work explores how\nweakly supervised and self-supervised deep learning approaches scale when\ntraining larger models on larger datasets. Our results show that both CNN- and\nViT-based masked autoencoders significantly outperform weakly supervised\nmodels. At the high-end of our scale, a ViT-L/8 trained on over 3.5-billion\nunique crops sampled from 95-million microscopy images achieves relative\nimprovements as high as 28% over our best weakly supervised models at inferring\nknown biological relationships curated from public databases.",
          "link": "http://arxiv.org/abs/2309.16064",
          "publishedOn": "2023-09-30T00:41:30.839Z",
          "wordCount": 645,
          "title": "Masked autoencoders are scalable learners of cellular morphology. (arXiv:2309.16064v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vahapoglu_C/0/1/0/all/0/1\">Cemil Vahapoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OShea_T/0/1/0/all/0/1\">Timothy J. O&#x27;Shea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_T/0/1/0/all/0/1\">Tamoghna Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulukus_S/0/1/0/all/0/1\">Sennur Ulukus</a>",
          "description": "The advancement of fifth generation (5G) wireless communication networks has\ncreated a greater demand for wireless resource management solutions that offer\nhigh data rates, extensive coverage, minimal latency and energy-efficient\nperformance. Nonetheless, traditional approaches have shortcomings when it\ncomes to computational complexity and their ability to adapt to dynamic\nconditions, creating a gap between theoretical analysis and the practical\nexecution of algorithmic solutions for managing wireless resources. Deep\nlearning-based techniques offer promising solutions for bridging this gap with\ntheir substantial representation capabilities. We propose a novel unsupervised\ndeep learning framework, which is called NNBF, for the design of uplink receive\nmulti-user single input multiple output (MU-SIMO) beamforming. The primary\nobjective is to enhance the throughput by focusing on maximizing the sum-rate\nwhile also offering computationally efficient solution, in contrast to\nestablished conventional methods. We conduct experiments for several antenna\nconfigurations. Our experimental results demonstrate that NNBF exhibits\nsuperior performance compared to our baseline methods, namely, zero-forcing\nbeamforming (ZFBF) and minimum mean square error (MMSE) equalizer.\nAdditionally, NNBF is scalable to the number of single-antenna user equipments\n(UEs) while baseline methods have significant computational burden due to\nmatrix pseudo-inverse operation.",
          "link": "http://arxiv.org/abs/2309.16603",
          "publishedOn": "2023-09-30T00:41:30.812Z",
          "wordCount": null,
          "title": "Deep Learning Based Uplink Multi-User SIMO Beamforming Design. (arXiv:2309.16603v1 [cs.IT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16316",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Pan_J/0/1/0/all/0/1\">Jia-Shu Pan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ting_Y/0/1/0/all/0/1\">Yuan-Sen Ting</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Yu_J/0/1/0/all/0/1\">Jie Yu</a>",
          "description": "Light curves of stars encapsulate a wealth of information about stellar\noscillations and granulation, thereby offering key insights into the internal\nstructure and evolutionary state of stars. Conventional asteroseismic\ntechniques have been largely confined to power spectral analysis, neglecting\nthe valuable phase information contained within light curves. While recent\nmachine learning applications in asteroseismology utilizing Convolutional\nNeural Networks (CNNs) have successfully inferred stellar attributes from light\ncurves, they are often limited by the local feature extraction inherent in\nconvolutional operations. To circumvent these constraints, we present\n$\\textit{Astroconformer}$, a Transformer-based deep learning framework designed\nto capture long-range dependencies in stellar light curves. Our empirical\nanalysis, which focuses on estimating surface gravity ($\\log g$), is grounded\nin a carefully curated dataset derived from $\\textit{Kepler}$ light curves.\nThese light curves feature asteroseismic $\\log g$ values spanning from 0.2 to\n4.4. Our results underscore that, in the regime where the training data is\nabundant, $\\textit{Astroconformer}$ attains a root-mean-square-error (RMSE) of\n0.017 dex around $\\log g \\approx 3 $. Even in regions where training data are\nsparse, the RMSE can reach 0.1 dex. It outperforms not only the K-nearest\nneighbor-based model ($\\textit{The SWAN}$) but also state-of-the-art CNNs.\nAblation studies confirm that the efficacy of the models in this particular\ntask is strongly influenced by the size of their receptive fields, with larger\nreceptive fields correlating with enhanced performance. Moreover, we find that\nthe attention mechanisms within $\\textit{Astroconformer}$ are well-aligned with\nthe inherent characteristics of stellar oscillations and granulation present in\nthe light curves.",
          "link": "http://arxiv.org/abs/2309.16316",
          "publishedOn": "2023-09-30T00:41:30.811Z",
          "wordCount": null,
          "title": "Astroconformer: The Prospects of Analyzing Stellar Light Curves with Transformer-Based Deep Learning Models. (arXiv:2309.16316v1 [astro-ph.SR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fred Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanda_N/0/1/0/all/0/1\">Neel Nanda</a>",
          "description": "Mechanistic interpretability seeks to understand the internal mechanisms of\nmachine learning models, where localization -- identifying the important model\ncomponents -- is a key step. Activation patching, also known as causal tracing\nor interchange intervention, is a standard technique for this task (Vig et al.,\n2020), but the literature contains many variants with little consensus on the\nchoice of hyperparameters or methodology. In this work, we systematically\nexamine the impact of methodological details in activation patching, including\nevaluation metrics and corruption methods. In several settings of localization\nand circuit discovery in language models, we find that varying these\nhyperparameters could lead to disparate interpretability results. Backed by\nempirical observations, we give conceptual arguments for why certain metrics or\nmethods may be preferred. Finally, we provide recommendations for the best\npractices of activation patching going forwards.",
          "link": "http://arxiv.org/abs/2309.16042",
          "publishedOn": "2023-09-30T00:41:30.810Z",
          "wordCount": null,
          "title": "Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. (arXiv:2309.16042v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cepeda_V/0/1/0/all/0/1\">Vicente Vivanco Cepeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1\">Gaurav Kumar Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Worldwide Geo-localization aims to pinpoint the precise location of images\ntaken anywhere on Earth. This task has considerable challenges due to immense\nvariation in geographic landscapes. The image-to-image retrieval-based\napproaches fail to solve this problem on a global scale as it is not feasible\nto construct a large gallery of images covering the entire world. Instead,\nexisting approaches divide the globe into discrete geographic cells,\ntransforming the problem into a classification task. However, their performance\nis limited by the predefined classes and often results in inaccurate\nlocalizations when an image's location significantly deviates from its class\ncenter. To overcome these limitations, we propose GeoCLIP, a novel\nCLIP-inspired Image-to-GPS retrieval approach that enforces alignment between\nthe image and its corresponding GPS locations. GeoCLIP's location encoder\nmodels the Earth as a continuous function by employing positional encoding\nthrough random Fourier features and constructing a hierarchical representation\nthat captures information at varying resolutions to yield a semantically rich\nhigh-dimensional feature suitable to use even beyond geo-localization. To the\nbest of our knowledge, this is the first work employing GPS encoding for\ngeo-localization. We demonstrate the efficacy of our method via extensive\nexperiments and ablations on benchmark datasets. We achieve competitive\nperformance with just 20% of training data, highlighting its effectiveness even\nin limited-data settings. Furthermore, we qualitatively demonstrate\ngeo-localization using a text query by leveraging CLIP backbone of our image\nencoder.",
          "link": "http://arxiv.org/abs/2309.16020",
          "publishedOn": "2023-09-30T00:41:30.809Z",
          "wordCount": null,
          "title": "GeoCLIP: Clip-Inspired Alignment between Locations and Images for Effective Worldwide Geo-localization. (arXiv:2309.16020v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rumack_A/0/1/0/all/0/1\">Aaron Rumack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenfeld_R/0/1/0/all/0/1\">Roni Rosenfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Townes_F/0/1/0/all/0/1\">F. William Townes</a>",
          "description": "Auxiliary data sources have become increasingly important in epidemiological\nsurveillance, as they are often available at a finer spatial and temporal\nresolution, larger coverage, and lower latency than traditional surveillance\nsignals. We describe the problem of spatial and temporal heterogeneity in these\nsignals derived from these data sources, where spatial and/or temporal biases\nare present. We present a method to use a ``guiding'' signal to correct for\nthese biases and produce a more reliable signal that can be used for modeling\nand forecasting. The method assumes that the heterogeneity can be approximated\nby a low-rank matrix and that the temporal heterogeneity is smooth over time.\nWe also present a hyperparameter selection algorithm to choose the parameters\nrepresenting the matrix rank and degree of temporal smoothness of the\ncorrections. In the absence of ground truth, we use maps and plots to argue\nthat this method does indeed reduce heterogeneity. Reducing heterogeneity from\nauxiliary data sources greatly increases their utility in modeling and\nforecasting epidemics.",
          "link": "http://arxiv.org/abs/2309.16546",
          "publishedOn": "2023-09-30T00:41:30.807Z",
          "wordCount": null,
          "title": "Correcting for heterogeneity in real-time epidemiological indicators. (arXiv:2309.16546v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16476",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Adomaityte_U/0/1/0/all/0/1\">Urte Adomaityte</a>, <a href=\"http://arxiv.org/find/math/1/au:+Defilippis_L/0/1/0/all/0/1\">Leonardo Defilippis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loureiro_B/0/1/0/all/0/1\">Bruno Loureiro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sicuro_G/0/1/0/all/0/1\">Gabriele Sicuro</a>",
          "description": "We investigate the high-dimensional properties of robust regression\nestimators in the presence of heavy-tailed contamination of both the covariates\nand response functions. In particular, we provide a sharp asymptotic\ncharacterisation of M-estimators trained on a family of elliptical covariate\nand noise data distributions including cases where second and higher moments do\nnot exist. We show that, despite being consistent, the Huber loss with\noptimally tuned location parameter $\\delta$ is suboptimal in the\nhigh-dimensional regime in the presence of heavy-tailed noise, highlighting the\nnecessity of further regularisation to achieve optimal performance. This result\nalso uncovers the existence of a curious transition in $\\delta$ as a function\nof the sample complexity and contamination. Moreover, we derive the decay rates\nfor the excess risk of ridge regression. We show that, while it is both optimal\nand universal for noise distributions with finite second moment, its decay rate\ncan be considerably faster when the covariates' second moment does not exist.\nFinally, we show that our formulas readily generalise to a richer family of\nmodels and data distributions, such as generalised linear estimation with\narbitrary convex regularisation trained on mixture models.",
          "link": "http://arxiv.org/abs/2309.16476",
          "publishedOn": "2023-09-30T00:41:30.710Z",
          "wordCount": null,
          "title": "High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality. (arXiv:2309.16476v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16131",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mingtao Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangting Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Q/0/1/0/all/0/1\">Qijing Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_T/0/1/0/all/0/1\">Tom Chou</a>",
          "description": "Rapidly developing machine learning methods has stimulated research interest\nin computationally reconstructing differential equations (DEs) from\nobservational data which may provide additional insight into underlying\ncausative mechanisms. In this paper, we propose a novel neural-ODE based method\nthat uses spectral expansions in space to learn spatiotemporal DEs. The major\nadvantage of our spectral neural DE learning approach is that it does not rely\non spatial discretization, thus allowing the target spatiotemporal equations to\ncontain long range, nonlocal spatial interactions that act on unbounded spatial\ndomains. Our spectral approach is shown to be as accurate as some of the latest\nmachine learning approaches for learning PDEs operating on bounded domains. By\ndeveloping a spectral framework for learning both PDEs and integro-differential\nequations, we extend machine learning methods to apply to unbounded DEs and a\nlarger class of problems.",
          "link": "http://arxiv.org/abs/2309.16131",
          "publishedOn": "2023-09-30T00:41:30.696Z",
          "wordCount": null,
          "title": "A Spectral Approach for Learning Spatiotemporal Neural Differential Equations. (arXiv:2309.16131v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.12499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xuelong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaisheng Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Bin Xiao</a>",
          "description": "Unrestricted adversarial attacks present a serious threat to deep learning\nmodels and adversarial defense techniques. They pose severe security problems\nfor deep learning applications because they can effectively bypass defense\nmechanisms. However, previous attack methods often utilize Generative\nAdversarial Networks (GANs), which are not theoretically provable and thus\ngenerate unrealistic examples by incorporating adversarial objectives,\nespecially for large-scale datasets like ImageNet. In this paper, we propose a\nnew method, called AdvDiff, to generate unrestricted adversarial examples with\ndiffusion models. We design two novel adversarial guidance techniques to\nconduct adversarial sampling in the reverse generation process of diffusion\nmodels. These two techniques are effective and stable to generate high-quality,\nrealistic adversarial examples by integrating gradients of the target\nclassifier interpretably. Experimental results on MNIST and ImageNet datasets\ndemonstrate that AdvDiff is effective to generate unrestricted adversarial\nexamples, which outperforms GAN-based methods in terms of attack performance\nand generation quality.",
          "link": "http://arxiv.org/abs/2307.12499",
          "publishedOn": "2023-09-30T00:41:30.672Z",
          "wordCount": null,
          "title": "AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion Models. (arXiv:2307.12499v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1\">Ambar Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sulam_J/0/1/0/all/0/1\">Jeremias Sulam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Ren&#xe9; Vidal</a>",
          "description": "The susceptibility of modern machine learning classifiers to adversarial\nexamples has motivated theoretical results suggesting that these might be\nunavoidable. However, these results can be too general to be applicable to\nnatural data distributions. Indeed, humans are quite robust for tasks involving\nvision. This apparent conflict motivates a deeper dive into the question: Are\nadversarial examples truly unavoidable? In this work, we theoretically\ndemonstrate that a key property of the data distribution -- concentration on\nsmall-volume subsets of the input space -- determines whether a robust\nclassifier exists. We further demonstrate that, for a data distribution\nconcentrated on a union of low-dimensional linear subspaces, exploiting data\nstructure naturally leads to classifiers that enjoy good robustness guarantees,\nimproving upon methods for provable certification in certain regimes.",
          "link": "http://arxiv.org/abs/2309.16096",
          "publishedOn": "2023-09-30T00:41:30.669Z",
          "wordCount": null,
          "title": "Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness. (arXiv:2309.16096v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feiyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zhaoyuan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hanran Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Anqi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Ye Zhao</a>",
          "description": "Enabling bipedal walking robots to learn how to maneuver over highly uneven,\ndynamically changing terrains is challenging due to the complexity of robot\ndynamics and interacted environments. Recent advancements in learning from\ndemonstrations have shown promising results for robot learning in complex\nenvironments. While imitation learning of expert policies has been\nwell-explored, the study of learning expert reward functions is largely\nunder-explored in legged locomotion. This paper brings state-of-the-art Inverse\nReinforcement Learning (IRL) techniques to solving bipedal locomotion problems\nover complex terrains. We propose algorithms for learning expert reward\nfunctions, and we subsequently analyze the learned functions. Through nonlinear\nfunction approximation, we uncover meaningful insights into the expert's\nlocomotion strategies. Furthermore, we empirically demonstrate that training a\nbipedal locomotion policy with the inferred reward functions enhances its\nwalking performance on unseen terrains, highlighting the adaptability offered\nby reward learning.",
          "link": "http://arxiv.org/abs/2309.16074",
          "publishedOn": "2023-09-30T00:41:30.668Z",
          "wordCount": null,
          "title": "Infer and Adapt: Bipedal Locomotion Reward Learning from Demonstrations via Inverse Reinforcement Learning. (arXiv:2309.16074v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16401",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Glusenkamp_T/0/1/0/all/0/1\">Thorsten Gl&#xfc;senkamp</a> (for the RNO-G collaboration)",
          "description": "The Radio Neutrino Observatory in Greenland (RNO-G) is a radio-based\nultra-high energy neutrino detector located at Summit Station, Greenland. It is\nstill being constructed, with 7 stations currently operational. Neutrino\ndetection works by measuring Askaryan radiation produced by neutrino-nucleon\ninteractions. A neutrino candidate must be found amidst other backgrounds which\nare recorded at much higher rates -- including cosmic-rays and anthropogenic\nnoise -- the origins of which are sometimes unknown. Here we describe a method\nto classify different noise classes using the latent space of a variational\nautoencoder. The latent space forms a compact representation that makes\nclassification tractable. We analyze data from a noisy and a silent station.\nThe method automatically detects and allows us to qualitatively separate\nmultiple event classes, including physical wind-induced signals, for both the\nnoisy and the quiet station.",
          "link": "http://arxiv.org/abs/2309.16401",
          "publishedOn": "2023-09-30T00:41:30.667Z",
          "wordCount": null,
          "title": "VAE-based latent-space classification of RNO-G data. (arXiv:2309.16401v1 [astro-ph.HE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.13104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kerdabadi_M/0/1/0/all/0/1\">Mohsen Nayebi Kerdabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moghaddam_A/0/1/0/all/0/1\">Arya Hadizadeh Moghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zijun Yao</a>",
          "description": "Survival analysis plays a crucial role in many healthcare decisions, where\nthe risk prediction for the events of interest can support an informative\noutlook for a patient's medical journey. Given the existence of data censoring,\nan effective way of survival analysis is to enforce the pairwise temporal\nconcordance between censored and observed data, aiming to utilize the time\ninterval before censoring as partially observed time-to-event labels for\nsupervised learning. Although existing studies mostly employed ranking methods\nto pursue an ordering objective, contrastive methods which learn a\ndiscriminative embedding by having data contrast against each other, have not\nbeen explored thoroughly for survival analysis. Therefore, in this paper, we\npropose a novel Ontology-aware Temporality-based Contrastive Survival (OTCSurv)\nanalysis framework that utilizes survival durations from both censored and\nobserved data to define temporal distinctiveness and construct negative sample\npairs with adjustable hardness for contrastive learning. Specifically, we first\nuse an ontological encoder and a sequential self-attention encoder to represent\nthe longitudinal EHR data with rich contexts. Second, we design a temporal\ncontrastive loss to capture varying survival durations in a supervised setting\nthrough a hardness-aware negative sampling mechanism. Last, we incorporate the\ncontrastive task into the time-to-event predictive task with multiple loss\ncomponents. We conduct extensive experiments using a large EHR dataset to\nforecast the risk of hospitalized patients who are in danger of developing\nacute kidney injury (AKI), a critical and urgent medical condition. The\neffectiveness and explainability of the proposed model are validated through\ncomprehensive quantitative and qualitative studies.",
          "link": "http://arxiv.org/abs/2308.13104",
          "publishedOn": "2023-09-30T00:41:30.666Z",
          "wordCount": null,
          "title": "Contrastive Learning of Temporal Distinctiveness for Survival Analysis in Electronic Health Records. (arXiv:2308.13104v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yariv_G/0/1/0/all/0/1\">Guy Yariv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benaim_S/0/1/0/all/0/1\">Sagie Benaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_I/0/1/0/all/0/1\">Idan Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>",
          "description": "We consider the task of generating diverse and realistic videos guided by\nnatural audio samples from a wide variety of semantic classes. For this task,\nthe videos are required to be aligned both globally and temporally with the\ninput audio: globally, the input audio is semantically associated with the\nentire output video, and temporally, each segment of the input audio is\nassociated with a corresponding segment of that video. We utilize an existing\ntext-conditioned video generation model and a pre-trained audio encoder model.\nThe proposed method is based on a lightweight adaptor network, which learns to\nmap the audio-based representation to the input representation expected by the\ntext-to-video generation model. As such, it also enables video generation\nconditioned on text, audio, and, for the first time as far as we can ascertain,\non both text and audio. We validate our method extensively on three datasets\ndemonstrating significant semantic diversity of audio-video samples and further\npropose a novel evaluation metric (AV-Align) to assess the alignment of\ngenerated videos with input audio samples. AV-Align is based on the detection\nand comparison of energy peaks in both modalities. In comparison to recent\nstate-of-the-art approaches, our method generates videos that are better\naligned with the input sound, both with respect to content and temporal axis.\nWe also show that videos produced by our method present higher visual quality\nand are more diverse.",
          "link": "http://arxiv.org/abs/2309.16429",
          "publishedOn": "2023-09-30T00:41:30.665Z",
          "wordCount": null,
          "title": "Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation. (arXiv:2309.16429v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skenderi_G/0/1/0/all/0/1\">Geri Skenderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cristani_M/0/1/0/all/0/1\">Marco Cristani</a>",
          "description": "Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a\nnovel and powerful technique for self-supervised representation learning. They\naim to learn an energy-based model by predicting the latent representation of a\ntarget signal $y$ from a context signal $x$. JEPAs bypass the need for data\naugmentation and negative samples, which are typically required by contrastive\nlearning, while avoiding the overfitting issues associated with\ngenerative-based pretraining. In this paper, we show that graph-level\nrepresentations can be effectively modeled using this paradigm and propose\nGraph-JEPA, the first JEPA for the graph domain. In particular, we employ\nmasked modeling to learn embeddings for different subgraphs of the input graph.\nTo endow the representations with the implicit hierarchy that is often present\nin graph-level concepts, we devise an alternative training objective that\nconsists of predicting the coordinates of the encoded subgraphs on the unit\nhyperbola in the 2D plane. Extensive validation shows that Graph-JEPA can learn\nrepresentations that are expressive and competitive in both graph\nclassification and regression problems.",
          "link": "http://arxiv.org/abs/2309.16014",
          "publishedOn": "2023-09-30T00:41:30.664Z",
          "wordCount": null,
          "title": "Graph-level Representation Learning with Joint-Embedding Predictive Architectures. (arXiv:2309.16014v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jiaheng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1\">Peter Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1\">Roberto Mart&#xed;n-Mart&#xed;n</a>",
          "description": "Developing the next generation of household robot helpers requires combining\nlocomotion and interaction capabilities, which is generally referred to as\nmobile manipulation (MoMa). MoMa tasks are difficult due to the large action\nspace of the robot and the common multi-objective nature of the task, e.g.,\nefficiently reaching a goal while avoiding obstacles. Current approaches often\nsegregate tasks into navigation without manipulation and stationary\nmanipulation without locomotion by manually matching parts of the action space\nto MoMa sub-objectives (e.g. learning base actions for locomotion objectives\nand learning arm actions for manipulation). This solution prevents simultaneous\ncombinations of locomotion and interaction degrees of freedom and requires\nhuman domain knowledge for both partitioning the action space and matching the\naction parts to the sub-objectives. In this paper, we introduce Causal MoMa, a\nnew reinforcement learning framework to train policies for typical MoMa tasks\nthat makes use of the most favorable subspace of the robot's action space to\naddress each sub-objective. Causal MoMa automatically discovers the causal\ndependencies between actions and terms of the reward function and exploits\nthese dependencies through causal policy gradient that reduces gradient\nvariance compared to previous state-of-the-art reinforcement learning\nalgorithms, improving convergence and results. We evaluate the performance of\nCausal MoMa on three types of simulated robots across different MoMa tasks and\ndemonstrate success in transferring the policies trained in simulation directly\nto a real robot, where our agent is able to follow moving goals and react to\ndynamic obstacles while simultaneously and synergistically controlling the\nwhole-body: base, arm, and head. More information at\nhttps://sites.google.com/view/causal-moma.",
          "link": "http://arxiv.org/abs/2305.04866",
          "publishedOn": "2023-09-30T00:41:30.663Z",
          "wordCount": null,
          "title": "Causal Policy Gradient for Whole-Body Mobile Manipulation. (arXiv:2305.04866v4 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iordanou_K/0/1/0/all/0/1\">Konstantinos Iordanou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atkinson_T/0/1/0/all/0/1\">Timothy Atkinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozer_E/0/1/0/all/0/1\">Emre Ozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kufel_J/0/1/0/all/0/1\">Jedrzej Kufel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggs_J/0/1/0/all/0/1\">John Biggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_G/0/1/0/all/0/1\">Gavin Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lujan_M/0/1/0/all/0/1\">Mikel Lujan</a>",
          "description": "A typical machine learning (ML) development cycle for edge computing is to\nmaximise the performance during model training and then minimise the\nmemory/area footprint of the trained model for deployment on edge devices\ntargeting CPUs, GPUs, microcontrollers, or custom hardware accelerators. This\npaper proposes a methodology for automatically generating predictor circuits\nfor classification of tabular data with comparable prediction performance to\nconventional ML techniques while using substantially fewer hardware resources\nand power. The proposed methodology uses an evolutionary algorithm to search\nover the space of logic gates and automatically generates a classifier circuit\nwith maximised training prediction accuracy. Classifier circuits are so tiny\n(i.e., consisting of no more than 300 logic gates) that they are called \"Tiny\nClassifier\" circuits, and can efficiently be implemented in ASIC or on an FPGA.\nWe empirically evaluate the automatic Tiny Classifier circuit generation\nmethodology or \"Auto Tiny Classifiers\" on a wide range of tabular datasets, and\ncompare it against conventional ML techniques such as Amazon's AutoGluon,\nGoogle's TabNet and a neural search over Multi-Layer Perceptrons. Despite Tiny\nClassifiers being constrained to a few hundred logic gates, we observe no\nstatistically significant difference in prediction performance in comparison to\nthe best-performing ML baseline. When synthesised as a Silicon chip, Tiny\nClassifiers use 8-18x less area and 4-8x less power. When implemented as an\nultra-low cost chip on a flexible substrate (i.e., FlexIC), they occupy 10-75x\nless area and consume 13-75x less power compared to the most hardware-efficient\nML baseline. On an FPGA, Tiny Classifiers consume 3-11x fewer resources.",
          "link": "http://arxiv.org/abs/2303.00031",
          "publishedOn": "2023-09-30T00:41:30.662Z",
          "wordCount": null,
          "title": "Tiny Classifier Circuits: Evolving Accelerators for Tabular Data. (arXiv:2303.00031v2 [cs.AR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.09979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_B/0/1/0/all/0/1\">Brent Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Sudharshan Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambeta_M/0/1/0/all/0/1\">Mike Lambeta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1\">Roberto Calandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1\">Jitendra Malik</a>",
          "description": "We introduce RotateIt, a system that enables fingertip-based object rotation\nalong multiple axes by leveraging multimodal sensory inputs. Our system is\ntrained in simulation, where it has access to ground-truth object shapes and\nphysical properties. Then we distill it to operate on realistic yet noisy\nsimulated visuotactile and proprioceptive sensory inputs. These multimodal\ninputs are fused via a visuotactile transformer, enabling online inference of\nobject shapes and physical properties during deployment. We show significant\nperformance improvements over prior methods and the importance of visual and\ntactile sensing.",
          "link": "http://arxiv.org/abs/2309.09979",
          "publishedOn": "2023-09-30T00:41:30.661Z",
          "wordCount": null,
          "title": "General In-Hand Object Rotation with Vision and Touch. (arXiv:2309.09979v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.10775",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Attia_A/0/1/0/all/0/1\">Ahmed Adel Attia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tiede_M/0/1/0/all/0/1\">Mark Tiede</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Espy_Wilson_C/0/1/0/all/0/1\">Carol Y. Espy-Wilson</a>",
          "description": "Accurate analysis of speech articulation is crucial for speech analysis.\nHowever, X-Y coordinates of articulators strongly depend on the anatomy of the\nspeakers and the variability of pellet placements, and existing methods for\nmapping anatomical landmarks in the X-ray Microbeam Dataset (XRMB) fail to\ncapture the entire anatomy of the vocal tract. In this paper, we propose a new\ngeometric transformation that improves the accuracy of these measurements. Our\ntransformation maps anatomical landmarks' X-Y coordinates along the midsagittal\nplane onto six relative measures: Lip Aperture (LA), Lip Protusion (LP), Tongue\nBody Constriction Location (TTCL), Degree (TBCD), Tongue Tip Constriction\nLocation (TTCL) and Degree (TTCD). Our novel contribution is the extension of\nthe palate trace towards the inferred anterior pharyngeal line, which improves\nmeasurements of tongue body constriction.",
          "link": "http://arxiv.org/abs/2305.10775",
          "publishedOn": "2023-09-30T00:41:30.604Z",
          "wordCount": null,
          "title": "Enhancing Speech Articulation Analysis using a Geometric Transformation of the X-ray Microbeam Dataset. (arXiv:2305.10775v3 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pinon_B/0/1/0/all/0/1\">Brieuc Pinon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jungers_R/0/1/0/all/0/1\">Rapha&#xeb;l Jungers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delvenne_J/0/1/0/all/0/1\">Jean-Charles Delvenne</a>",
          "description": "We prove a fundamental limitation on the efficiency of a wide class of\nReinforcement Learning (RL) algorithms. This limitation applies to model-free\nRL methods as well as a broad range of model-based methods, such as planning\nwith tree search.\n\nUnder an abstract definition of this class, we provide a family of RL\nproblems for which these methods suffer a lower bound exponential in the\nhorizon for their interactions with the environment to find an optimal\nbehavior. However, there exists a method, not tailored to this specific family\nof problems, which can efficiently solve the problems in the family.\n\nIn contrast, our limitation does not apply to several types of methods\nproposed in the literature, for instance, goal-conditioned methods or other\nalgorithms that construct an inverse dynamics model.",
          "link": "http://arxiv.org/abs/2309.16291",
          "publishedOn": "2023-09-30T00:41:30.601Z",
          "wordCount": 633,
          "title": "Efficiency Separation between RL Methods: Model-Free, Model-Based and Goal-Conditioned. (arXiv:2309.16291v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Han Bao</a>",
          "description": "Contrastive learning is a self-supervised representation learning framework,\nwhere two positive views generated through data augmentation are made similar\nby an attraction force in a data representation space, while a repulsive force\nmakes them far from negative examples. Non-contrastive learning, represented by\nBYOL and SimSiam, further gets rid of negative examples and improves\ncomputational efficiency. While learned representations may collapse into a\nsingle point due to the lack of the repulsive force at first sight, Tian et al.\n(2021) revealed through the learning dynamics analysis that the representations\ncan avoid collapse if data augmentation is sufficiently stronger than\nregularization. However, their analysis does not take into account\ncommonly-used feature normalization, a normalizer before measuring the\nsimilarity of representations, and hence excessively strong regularization may\ncollapse the dynamics, which is an unnatural behavior under the presence of\nfeature normalization. Therefore, we extend the previous theory based on the L2\nloss by considering the cosine loss, which involves feature normalization. We\nshow that the cosine loss induces sixth-order dynamics (while the L2 loss\ninduces a third-order one), in which a stable equilibrium dynamically emerges\neven if there are only collapsed solutions with given initial parameters. Thus,\nwe offer a new understanding that feature normalization plays an important role\nin robustly preventing the dynamics collapse.",
          "link": "http://arxiv.org/abs/2309.16109",
          "publishedOn": "2023-09-30T00:41:30.458Z",
          "wordCount": null,
          "title": "Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beretta_L/0/1/0/all/0/1\">Lorenzo Beretta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1\">Vincent Cohen-Addad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1\">Silvio Lattanzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1\">Nikos Parotsidis</a>",
          "description": "The $k$-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is often\nthe practitioners' choice algorithm for optimizing the popular $k$-means\nclustering objective and is known to give an $O(\\log k)$-approximation in\nexpectation. To obtain higher quality solutions, Lattanzi and Sohler (ICML\n2019) proposed augmenting $k$-means++ with $O(k \\log \\log k)$ local search\nsteps obtained through the $k$-means++ sampling distribution to yield a\n$c$-approximation to the $k$-means clustering problem, where $c$ is a large\nabsolute constant. Here we generalize and extend their local search algorithm\nby considering larger and more sophisticated local search neighborhoods hence\nallowing to swap multiple centers at the same time. Our algorithm achieves a $9\n+ \\varepsilon$ approximation ratio, which is the best possible for local\nsearch. Importantly we show that our approach yields substantial practical\nimprovements, we show significant quality improvements over the approach of\nLattanzi and Sohler (ICML 2019) on several datasets.",
          "link": "http://arxiv.org/abs/2309.16384",
          "publishedOn": "2023-09-30T00:41:30.458Z",
          "wordCount": null,
          "title": "Multi-Swap $k$-Means++. (arXiv:2309.16384v1 [cs.CG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16448",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zukovic_M/0/1/0/all/0/1\">Milan &#x17d;ukovi&#x10d;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hristopulos_D/0/1/0/all/0/1\">Dionissios T. Hristopulos</a>",
          "description": "We introduce the modified planar rotator method (MPRS), a physically inspired\nmachine learning method for spatial/temporal regression. MPRS is a\nnon-parametric model which incorporates spatial or temporal correlations via\nshort-range, distance-dependent ``interactions'' without assuming a specific\nform for the underlying probability distribution. Predictions are obtained by\nmeans of a fully autonomous learning algorithm which employs equilibrium\nconditional Monte Carlo simulations. MPRS is able to handle scattered data and\narbitrary spatial dimensions. We report tests on various synthetic and\nreal-word data in one, two and three dimensions which demonstrate that the MPRS\nprediction performance (without parameter tuning) is competitive with standard\ninterpolation methods such as ordinary kriging and inverse distance weighting.\nIn particular, MPRS is a particularly effective gap-filling method for rough\nand non-Gaussian data (e.g., daily precipitation time series). MPRS shows\nsuperior computational efficiency and scalability for large samples. Massive\ndata sets involving millions of nodes can be processed in a few seconds on a\nstandard personal computer.",
          "link": "http://arxiv.org/abs/2309.16448",
          "publishedOn": "2023-09-30T00:41:30.457Z",
          "wordCount": null,
          "title": "A parsimonious, computationally efficient machine learning method for spatial regression. (arXiv:2309.16448v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16465",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Boutet_D/0/1/0/all/0/1\">Dominic Boutet</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Baillet_S/0/1/0/all/0/1\">Sylvain Baillet</a> (Montreal Neurological Institute, McGill University, Montreal QC, Canada)",
          "description": "Parameter inference for dynamical models of (bio)physical systems remains a\nchallenging problem. Intractable gradients, high-dimensional spaces, and\nnon-linear model functions are typically problematic without large\ncomputational budgets. A recent body of work in that area has focused on\nBayesian inference methods, which consider parameters under their statistical\ndistributions and therefore, do not derive point estimates of optimal parameter\nvalues. Here we propose a new metaheuristic that drives dimensionality\nreductions from feature-informed transformations (DR-FFIT) to address these\nbottlenecks. DR-FFIT implements an efficient sampling strategy that facilitates\na gradient-free parameter search in high-dimensional spaces. We use artificial\nneural networks to obtain differentiable proxies for the model's features of\ninterest. The resulting gradients enable the estimation of a local active\nsubspace of the model within a defined sampling region. This approach enables\nefficient dimensionality reductions of highly non-linear search spaces at a low\ncomputational cost. Our test data show that DR-FFIT boosts the performances of\nrandom-search and simulated-annealing against well-established metaheuristics,\nand improves the goodness-of-fit of the model, all within contained run-time\ncosts.",
          "link": "http://arxiv.org/abs/2309.16465",
          "publishedOn": "2023-09-30T00:41:30.457Z",
          "wordCount": null,
          "title": "A Metaheuristic for Amortized Search in High-Dimensional Parameter Spaces. (arXiv:2309.16465v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15938",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jiang_X/0/1/0/all/0/1\">Xilin Jiang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1\">Cong Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yinghao Aaron Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mesgarani_N/0/1/0/all/0/1\">Nima Mesgarani</a>",
          "description": "In this study, we present a simple multi-channel framework for contrastive\nlearning (MC-SimCLR) to encode 'what' and 'where' of spatial audios. MC-SimCLR\nlearns joint spectral and spatial representations from unlabeled spatial\naudios, thereby enhancing both event classification and sound localization in\ndownstream tasks. At its core, we propose a multi-level data augmentation\npipeline that augments different levels of audio features, including waveforms,\nMel spectrograms, and generalized cross-correlation (GCC) features. In\naddition, we introduce simple yet effective channel-wise augmentation methods\nto randomly swap the order of the microphones and mask Mel and GCC channels. By\nusing these augmentations, we find that linear layers on top of the learned\nrepresentation significantly outperform supervised models in terms of both\nevent classification accuracy and localization error. We also perform a\ncomprehensive analysis of the effect of each augmentation method and a\ncomparison of the fine-tuning performance using different amounts of labeled\ndata.",
          "link": "http://arxiv.org/abs/2309.15938",
          "publishedOn": "2023-09-30T00:41:30.435Z",
          "wordCount": null,
          "title": "Exploring Self-Supervised Contrastive Learning of Spatial Sound Event Representation. (arXiv:2309.15938v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singhal_U/0/1/0/all/0/1\">Utkarsh Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteves_C/0/1/0/all/0/1\">Carlos Esteves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Stella X. Yu</a>",
          "description": "Computer vision research has long aimed to build systems that are robust to\nspatial transformations found in natural data. Traditionally, this is done\nusing data augmentation or hard-coding invariances into the architecture.\nHowever, too much or too little invariance can hurt, and the correct amount is\nunknown a priori and dependent on the instance. Ideally, the appropriate\ninvariance would be learned from data and inferred at test-time.\n\nWe treat invariance as a prediction problem. Given any image, we use a\nnormalizing flow to predict a distribution over transformations and average the\npredictions over them. Since this distribution only depends on the instance, we\ncan align instances before classifying them and generalize invariance across\nclasses. The same distribution can also be used to adapt to out-of-distribution\nposes. This normalizing flow is trained end-to-end and can learn a much larger\nrange of transformations than Augerino and InstaAug. When used as data\naugmentation, our method shows accuracy and robustness gains on CIFAR 10,\nCIFAR10-LT, and TinyImageNet.",
          "link": "http://arxiv.org/abs/2309.16672",
          "publishedOn": "2023-09-30T00:41:30.435Z",
          "wordCount": null,
          "title": "Learning to Transform for Generalizable Instance-wise Invariance. (arXiv:2309.16672v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jeffrey N. Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Small_E/0/1/0/all/0/1\">Edward A. Small</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keshtmand_N/0/1/0/all/0/1\">Nawid Keshtmand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_M/0/1/0/all/0/1\">Michelle W.L. Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayoral_E/0/1/0/all/0/1\">Elena Fillola Mayoral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werner_E/0/1/0/all/0/1\">Enrico Werner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourdeaux_C/0/1/0/all/0/1\">Christopher P. Bourdeaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Raul Santos-Rodriguez</a>",
          "description": "Counterfactual explanations, and their associated algorithmic recourse, are\ntypically leveraged to understand, explain, and potentially alter a prediction\ncoming from a black-box classifier. In this paper, we propose to extend the use\nof counterfactuals to evaluate progress in sequential decision making tasks. To\nthis end, we introduce a model-agnostic modular framework, TraCE (Trajectory\nCounterfactual Explanation) scores, which is able to distill and condense\nprogress in highly complex scenarios into a single value. We demonstrate\nTraCE's utility across domains by showcasing its main properties in two case\nstudies spanning healthcare and climate change.",
          "link": "http://arxiv.org/abs/2309.15965",
          "publishedOn": "2023-09-30T00:41:30.434Z",
          "wordCount": null,
          "title": "TraCE: Trajectory Counterfactual Explanation Scores. (arXiv:2309.15965v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungwhan Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagarajan_T/0/1/0/all/0/1\">Tushar Nagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Matt Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Shashank Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1\">Chun-Fu Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_P/0/1/0/all/0/1\">Prakash Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_P/0/1/0/all/0/1\">Peyman Heidari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinet_K/0/1/0/all/0/1\">Kavya Srinet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damavandi_B/0/1/0/all/0/1\">Babak Damavandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Anuj Kumar</a>",
          "description": "We present Any-Modality Augmented Language Model (AnyMAL), a unified model\nthat reasons over diverse input modality signals (i.e. text, image, video,\naudio, IMU motion sensor), and generates textual responses. AnyMAL inherits the\npowerful text-based reasoning abilities of the state-of-the-art LLMs including\nLLaMA-2 (70B), and converts modality-specific signals to the joint textual\nspace through a pre-trained aligner module. To further strengthen the\nmultimodal LLM's capabilities, we fine-tune the model with a multimodal\ninstruction set manually collected to cover diverse topics and tasks beyond\nsimple QAs. We conduct comprehensive empirical analysis comprising both human\nand automatic evaluations, and demonstrate state-of-the-art performance on\nvarious multimodal tasks.",
          "link": "http://arxiv.org/abs/2309.16058",
          "publishedOn": "2023-09-30T00:41:30.433Z",
          "wordCount": null,
          "title": "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model. (arXiv:2309.16058v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zenan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1\">Fan Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Qiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Da_F/0/1/0/all/0/1\">Fang Da</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hang Zhao</a>",
          "description": "Offline Reinforcement Learning (RL) has emerged as a promising framework for\nlearning policies without active interactions, making it especially appealing\nfor autonomous driving tasks. Recent successes of Transformers inspire casting\noffline RL as sequence modeling, which performs well in long-horizon tasks.\nHowever, they are overly optimistic in stochastic environments with incorrect\nassumptions that the same goal can be consistently achieved by identical\nactions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer\n(UNREST) for planning in stochastic driving environments without introducing\nadditional transition or complex generative models. Specifically, UNREST\nestimates state uncertainties by the conditional mutual information between\ntransitions and returns, and segments sequences accordingly. Discovering the\n`uncertainty accumulation' and `temporal locality' properties of driving\nenvironments, UNREST replaces the global returns in decision transformers with\nless uncertain truncated returns, to learn from true outcomes of agent actions\nrather than environment transitions. We also dynamically evaluate environmental\nuncertainty during inference for cautious planning. Extensive experimental\nresults demonstrate UNREST's superior performance in various driving scenarios\nand the power of our uncertainty estimation strategy.",
          "link": "http://arxiv.org/abs/2309.16397",
          "publishedOn": "2023-09-30T00:41:30.433Z",
          "wordCount": null,
          "title": "Uncertainty-Aware Decision Transformer for Stochastic Driving Environments. (arXiv:2309.16397v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.03890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biradar_G/0/1/0/all/0/1\">Gagan Biradar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izza_Y/0/1/0/all/0/1\">Yacine Izza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lobo_E/0/1/0/all/0/1\">Elita Lobo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1\">Vignesh Viswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zick_Y/0/1/0/all/0/1\">Yair Zick</a>",
          "description": "The recent criticisms of the robustness of post hoc model approximation\nexplanation methods (like LIME and SHAP) have led to the rise of model-precise\nabductive explanations. For each data point, abductive explanations provide a\nminimal subset of features that are sufficient to generate the outcome. While\ntheoretically sound and rigorous, abductive explanations suffer from a major\nissue -- there can be several valid abductive explanations for the same data\npoint. In such cases, providing a single abductive explanation can be\ninsufficient; on the other hand, providing all valid abductive explanations can\nbe incomprehensible due to their size. In this work, we solve this issue by\naggregating the many possible abductive explanations into feature importance\nscores. We propose three aggregation methods: two based on power indices from\ncooperative game theory and a third based on a well-known measure of causal\nstrength. We characterize these three methods axiomatically, showing that each\nof them uniquely satisfies a set of desirable properties. We also evaluate them\non multiple datasets and show that these explanations are robust to the attacks\nthat fool SHAP and LIME.",
          "link": "http://arxiv.org/abs/2109.03890",
          "publishedOn": "2023-09-30T00:41:30.431Z",
          "wordCount": null,
          "title": "Axiomatic Aggregations of Abductive Explanations. (arXiv:2109.03890v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuezhu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivaranjani_S/0/1/0/all/0/1\">S. Sivaranjani</a>",
          "description": "Consider an unknown nonlinear dynamical system that is known to be\ndissipative. The objective of this paper is to learn a neural dynamical model\nthat approximates this system, while preserving the dissipativity property in\nthe model. In general, imposing dissipativity constraints during neural network\ntraining is a hard problem for which no known techniques exist. In this work,\nwe address the problem of learning a dissipative neural dynamical system model\nin two stages. First, we learn an unconstrained neural dynamical model that\nclosely approximates the system dynamics. Next, we derive sufficient conditions\nto perturb the weights of the neural dynamical model to ensure dissipativity,\nfollowed by perturbation of the biases to retain the fit of the model to the\ntrajectories of the nonlinear system. We show that these two perturbation\nproblems can be solved independently to obtain a neural dynamical model that is\nguaranteed to be dissipative while closely approximating the nonlinear system.",
          "link": "http://arxiv.org/abs/2309.16032",
          "publishedOn": "2023-09-30T00:41:30.430Z",
          "wordCount": null,
          "title": "Learning Dissipative Neural Dynamical Systems. (arXiv:2309.16032v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andriopoulos_K/0/1/0/all/0/1\">Konstantinos Andriopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouwelse_J/0/1/0/all/0/1\">Johan Pouwelse</a>",
          "description": "Large pre-trained language models have demonstrated their proficiency in\nstoring factual knowledge within their parameters and achieving remarkable\nresults when fine-tuned for downstream natural language processing tasks.\nNonetheless, their capacity to access and manipulate knowledge with precision\nremains constrained, resulting in performance disparities on\nknowledge-intensive tasks when compared to task-specific architectures.\nAdditionally, the challenges of providing provenance for model decisions and\nmaintaining up-to-date world knowledge persist as open research frontiers. To\naddress these limitations, the integration of pre-trained models with\ndifferentiable access mechanisms to explicit non-parametric memory emerges as a\npromising solution. This survey delves into the realm of language models (LMs)\naugmented with the ability to tap into external knowledge sources, including\nexternal knowledge bases and search engines. While adhering to the standard\nobjective of predicting missing tokens, these augmented LMs leverage diverse,\npossibly non-parametric external modules to augment their contextual processing\ncapabilities, departing from the conventional language modeling paradigm.\nThrough an exploration of current advancements in augmenting large language\nmodels with knowledge, this work concludes that this emerging research\ndirection holds the potential to address prevalent issues in traditional LMs,\nsuch as hallucinations, un-grounded responses, and scalability challenges.",
          "link": "http://arxiv.org/abs/2309.16459",
          "publishedOn": "2023-09-30T00:41:30.430Z",
          "wordCount": null,
          "title": "Augmenting LLMs with Knowledge: A survey on hallucination prevention. (arXiv:2309.16459v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">David Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannengiesser_N/0/1/0/all/0/1\">Niclas Kannengie&#xdf;er</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rank_S/0/1/0/all/0/1\">Sascha Rank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunyaev_A/0/1/0/all/0/1\">Ali Sunyaev</a>",
          "description": "To leverage training data for the sufficient training of ML models from\nmultiple parties in a confidentiality-preserving way, various collaborative\ndistributed machine learning (CDML) system designs have been developed, for\nexample, to perform assisted learning, federated learning, and split learning.\nCDML system designs show different traits, for example, high agent autonomy,\nmachine learning (ML) model confidentiality, and fault tolerance. Facing a wide\nvariety of CDML system designs with different traits, it is difficult for\ndevelopers to design CDML systems with traits that match use case requirements\nin a targeted way. However, inappropriate CDML system designs may result in\nCDML systems failing their envisioned purposes. We developed a CDML design\ntoolbox that can guide the development of CDML systems. Based on the CDML\ndesign toolbox, we present CDML system archetypes with distinct key traits that\ncan support the design of CDML systems to meet use case requirements.",
          "link": "http://arxiv.org/abs/2309.16584",
          "publishedOn": "2023-09-30T00:41:30.430Z",
          "wordCount": null,
          "title": "A Design Toolbox for the Development of Collaborative Distributed Machine Learning Systems. (arXiv:2309.16584v1 [cs.MA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Ke Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albro_S/0/1/0/all/0/1\">Stephen Albro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeSalvo_G/0/1/0/all/0/1\">Giulia DeSalvo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kothawade_S/0/1/0/all/0/1\">Suraj Kothawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashwan_A/0/1/0/all/0/1\">Abdullah Rashwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavakkol_S/0/1/0/all/0/1\">Sasan Tavakkol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1\">Kayhan Batmanghelich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiaoqi Yin</a>",
          "description": "Training high-quality instance segmentation models requires an abundance of\nlabeled images with instance masks and classifications, which is often\nexpensive to procure. Active learning addresses this challenge by striving for\noptimum performance with minimal labeling cost by selecting the most\ninformative and representative images for labeling. Despite its potential,\nactive learning has been less explored in instance segmentation compared to\nother tasks like image classification, which require less labeling. In this\nstudy, we propose a post-hoc active learning algorithm that integrates\nuncertainty-based sampling with diversity-based sampling. Our proposed\nalgorithm is not only simple and easy to implement, but it also delivers\nsuperior performance on various datasets. Its practical application is\ndemonstrated on a real-world overhead imagery dataset, where it increases the\nlabeling efficiency fivefold.",
          "link": "http://arxiv.org/abs/2309.16139",
          "publishedOn": "2023-09-30T00:41:30.428Z",
          "wordCount": null,
          "title": "Two-Step Active Learning for Instance Segmentation with Uncertainty and Diversity Sampling. (arXiv:2309.16139v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiarui Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon Shaolei Du</a>",
          "description": "Currently, reinforcement learning (RL), especially deep RL, has received more\nand more attention in the research area. However, the security of RL has been\nan obvious problem due to the attack manners becoming mature. In order to\ndefend against such adversarial attacks, several practical approaches are\ndeveloped, such as adversarial training, data filtering, etc. However, these\nmethods are mostly based on empirical algorithms and experiments, without\nrigorous theoretical analysis of the robustness of the algorithms. In this\npaper, we develop an algorithm to certify the robustness of a given policy\noffline with random smoothing, which could be proven and conducted as\nefficiently as ones without random smoothing. Experiments on different\nenvironments confirm the correctness of our algorithm.",
          "link": "http://arxiv.org/abs/2309.16631",
          "publishedOn": "2023-09-30T00:41:30.423Z",
          "wordCount": null,
          "title": "Robust Offline Reinforcement Learning -- Certify the Confidence Interval. (arXiv:2309.16631v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.00723",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Luo_D/0/1/0/all/0/1\">Di Luo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Halverson_J/0/1/0/all/0/1\">James Halverson</a>",
          "description": "We study infinite limits of neural network quantum states ($\\infty$-NNQS),\nwhich exhibit representation power through ensemble statistics, and also\ntractable gradient descent dynamics. Ensemble averages of Renyi entropies are\nexpressed in terms of neural network correlators, and architectures that\nexhibit volume-law entanglement are presented. A general framework is developed\nfor studying the gradient descent dynamics of neural network quantum states\n(NNQS), using a quantum state neural tangent kernel (QS-NTK). For $\\infty$-NNQS\nthe training dynamics is simplified, since the QS-NTK becomes deterministic and\nconstant. An analytic solution is derived for quantum state supervised\nlearning, which allows an $\\infty$-NNQS to recover any target wavefunction.\nNumerical experiments on finite and infinite NNQS in the transverse field Ising\nmodel and Fermi Hubbard model demonstrate excellent agreement with theory.\n$\\infty$-NNQS opens up new opportunities for studying entanglement and training\ndynamics in other physics applications, such as in finding ground states.",
          "link": "http://arxiv.org/abs/2112.00723",
          "publishedOn": "2023-09-30T00:41:30.423Z",
          "wordCount": null,
          "title": "Infinite Neural Network Quantum States: Entanglement and Training Dynamics. (arXiv:2112.00723v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Satvik Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_S/0/1/0/all/0/1\">Shivam Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Somya Garg</a>",
          "description": "Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in\ndrug discovery and pharmaceutical research as they provide a structured way to\nintegrate diverse information sources, enhancing AI system interpretability.\nThis interpretability is crucial in healthcare, where trust and transparency\nmatter, and eXplainable AI (XAI) supports decision making for healthcare\nprofessionals. This overview summarizes recent literature on the impact of KGs\nin healthcare and their role in developing explainable AI models. We cover KG\nworkflow, including construction, relationship extraction, reasoning, and their\napplications in areas like Drug-Drug Interactions (DDI), Drug Target\nInteractions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and\nbioinformatics. We emphasize the importance of making KGs more interpretable\nthrough knowledge-infused learning in healthcare. Finally, we highlight\nresearch challenges and provide insights for future directions.",
          "link": "http://arxiv.org/abs/2309.16593",
          "publishedOn": "2023-09-30T00:41:30.417Z",
          "wordCount": null,
          "title": "Navigating Healthcare Insights: A Birds Eye View of Explainability with Knowledge Graphs. (arXiv:2309.16593v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16620",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Mufan Bill Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "The cost of hyperparameter tuning in deep learning has been rising with model\nsizes, prompting practitioners to find new tuning methods using a proxy of\nsmaller networks. One such proposal uses $\\mu$P parameterized networks, where\nthe optimal hyperparameters for small width networks transfer to networks with\narbitrarily large width. However, in this scheme, hyperparameters do not\ntransfer across depths. As a remedy, we study residual networks with a residual\nbranch scale of $1/\\sqrt{\\text{depth}}$ in combination with the $\\mu$P\nparameterization. We provide experiments demonstrating that residual\narchitectures including convolutional ResNets and Vision Transformers trained\nwith this parameterization exhibit transfer of optimal hyperparameters across\nwidth and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings\nare supported and motivated by theory. Using recent developments in the\ndynamical mean field theory (DMFT) description of neural network learning\ndynamics, we show that this parameterization of ResNets admits a well-defined\nfeature learning joint infinite-width and infinite-depth limit and show\nconvergence of finite-size network dynamics towards this limit.",
          "link": "http://arxiv.org/abs/2309.16620",
          "publishedOn": "2023-09-30T00:41:30.416Z",
          "wordCount": null,
          "title": "Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mallet_V/0/1/0/all/0/1\">Vincent Mallet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attaiki_S/0/1/0/all/0/1\">Souhaib Attaiki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovsjanikov_M/0/1/0/all/0/1\">Maks Ovsjanikov</a>",
          "description": "Recent advancements in Cryo-EM and protein structure prediction algorithms\nhave made large-scale protein structures accessible, paving the way for machine\nlearning-based functional annotations.The field of geometric deep learning\nfocuses on creating methods working on geometric data. An essential aspect of\nlearning from protein structures is representing these structures as a\ngeometric object (be it a grid, graph, or surface) and applying a learning\nmethod tailored to this representation. The performance of a given approach\nwill then depend on both the representation and its corresponding learning\nmethod.\n\nIn this paper, we investigate representing proteins as $\\textit{3D mesh\nsurfaces}$ and incorporate them into an established representation benchmark.\nOur first finding is that despite promising preliminary results, the surface\nrepresentation alone does not seem competitive with 3D grids. Building on this,\nwe introduce a synergistic approach, combining surface representations with\ngraph-based methods, resulting in a general framework that incorporates both\nrepresentations in learning. We show that using this combination, we are able\nto obtain state-of-the-art results across $\\textit{all tested tasks}$. Our code\nand data can be found online: https://github.com/Vincentx15/atom2D .",
          "link": "http://arxiv.org/abs/2309.16519",
          "publishedOn": "2023-09-30T00:41:30.381Z",
          "wordCount": null,
          "title": "AtomSurf : Surface Representation for Learning on Protein Structures. (arXiv:2309.16519v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16428",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bonassi_F/0/1/0/all/0/1\">Fabio Bonassi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bella_A/0/1/0/all/0/1\">Alessio La Bella</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Farina_M/0/1/0/all/0/1\">Marcello Farina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scattolini_R/0/1/0/all/0/1\">Riccardo Scattolini</a>",
          "description": "This brief addresses the design of a Nonlinear Model Predictive Control\n(NMPC) strategy for exponentially incremental Input-to-State Stable (ISS)\nsystems. In particular, a novel formulation is devised, which does not\nnecessitate the onerous computation of terminal ingredients, but rather relies\non the explicit definition of a minimum prediction horizon ensuring closed-loop\nstability. The designed methodology is particularly suited for the control of\nsystems learned by Recurrent Neural Networks (RNNs), which are known for their\nenhanced modeling capabilities and for which the incremental ISS properties can\nbe studied thanks to simple algebraic conditions. The approach is applied to\nGated Recurrent Unit (GRU) networks, providing also a method for the design of\na tailored state observer with convergence guarantees. The resulting control\narchitecture is tested on a benchmark system, demonstrating its good control\nperformances and efficient applicability.",
          "link": "http://arxiv.org/abs/2309.16428",
          "publishedOn": "2023-09-30T00:41:30.379Z",
          "wordCount": null,
          "title": "Nonlinear MPC design for incrementally ISS systems with application to GRU networks. (arXiv:2309.16428v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16536",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brown_D/0/1/0/all/0/1\">Donald Brown</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Syed_S/0/1/0/all/0/1\">Sana Syed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greene_A/0/1/0/all/0/1\">Adam Greene</a>",
          "description": "Eosinophilic Esophagitis (EoE) is an allergic condition increasing in\nprevalence. To diagnose EoE, pathologists must find 15 or more eosinophils\nwithin a single high-power field (400X magnification). Determining whether or\nnot a patient has EoE can be an arduous process and any medical imaging\napproaches used to assist diagnosis must consider both efficiency and\nprecision. We propose an improvement of Adorno et al's approach for quantifying\neosinphils using deep image segmentation. Our new approach leverages Monte\nCarlo Dropout, a common approach in deep learning to reduce overfitting, to\nprovide uncertainty quantification on current deep learning models. The\nuncertainty can be visualized in an output image to evaluate model performance,\nprovide insight to how deep learning algorithms function, and assist\npathologists in identifying eosinophils.",
          "link": "http://arxiv.org/abs/2309.16536",
          "publishedOn": "2023-09-30T00:41:30.379Z",
          "wordCount": null,
          "title": "Uncertainty Quantification for Eosinophil Segmentation. (arXiv:2309.16536v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16177",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lin_J/0/1/0/all/0/1\">Jerry Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yu_S/0/1/0/all/0/1\">Sungduk Yu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Beucler_T/0/1/0/all/0/1\">Tom Beucler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gentine_P/0/1/0/all/0/1\">Pierre Gentine</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Walling_D/0/1/0/all/0/1\">David Walling</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pritchard_M/0/1/0/all/0/1\">Mike Pritchard</a>",
          "description": "Progress in hybrid physics-machine learning (ML) climate simulations has been\nlimited by the difficulty of obtaining performant coupled (i.e. online)\nsimulations. While evaluating hundreds of ML parameterizations of subgrid\nclosures (here of convection and radiation) offline is straightforward, online\nevaluation at the same scale is technically challenging. Our software\nautomation achieves an order-of-magnitude larger sampling of online modeling\nerrors than has previously been examined. Using this, we evaluate the hybrid\nclimate model performance and define strategies to improve it. We show that\nmodel online performance improves when incorporating memory, a relative\nhumidity input feature transformation, and additional input variables. We also\nreveal substantial variation in online error and inconsistencies between\noffline vs. online error statistics. The implication is that hundreds of\ncandidate ML models should be evaluated online to detect the effects of\nparameterization design choices. This is considerably more sampling than tends\nto be reported in the current literature.",
          "link": "http://arxiv.org/abs/2309.16177",
          "publishedOn": "2023-09-30T00:41:30.378Z",
          "wordCount": null,
          "title": "Systematic Sampling and Validation of Machine Learning-Parameterizations in Climate Models. (arXiv:2309.16177v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hochuli_A/0/1/0/all/0/1\">Andre Gustavo Hochuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barddal_J/0/1/0/all/0/1\">Jean Paul Barddal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palhano_G/0/1/0/all/0/1\">Gillian Cezar Palhano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendes_L/0/1/0/all/0/1\">Leonardo Matheus Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_P/0/1/0/all/0/1\">Paulo Ricardo Lisboa de Almeida</a>",
          "description": "Searching for available parking spots in high-density urban centers is a\nstressful task for drivers that can be mitigated by systems that know in\nadvance the nearest parking space available.\n\nTo this end, image-based systems offer cost advantages over other\nsensor-based alternatives (e.g., ultrasonic sensors), requiring less physical\ninfrastructure for installation and maintenance.\n\nDespite recent deep learning advances, deploying intelligent parking\nmonitoring is still a challenge since most approaches involve collecting and\nlabeling large amounts of data, which is laborious and time-consuming. Our\nstudy aims to uncover the challenges in creating a global framework, trained\nusing publicly available labeled parking lot images, that performs accurately\nacross diverse scenarios, enabling the parking space monitoring as a\nready-to-use system to deploy in a new environment. Through exhaustive\nexperiments involving different datasets and deep learning architectures,\nincluding fusion strategies and ensemble methods, we found that models trained\non diverse datasets can achieve 95\\% accuracy without the burden of data\nannotation and model training on the target parking lot",
          "link": "http://arxiv.org/abs/2309.16495",
          "publishedOn": "2023-09-30T00:41:30.378Z",
          "wordCount": null,
          "title": "Deep Single Models vs. Ensembles: Insights for a Fast Deployment of Parking Monitoring Systems. (arXiv:2309.16495v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.12547",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Li_J/0/1/0/all/0/1\">Jin Li</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Luo_Y/0/1/0/all/0/1\">Ye Luo</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaowei Zhang</a>",
          "description": "This paper identifies and addresses dynamic selection problems in online\nlearning algorithms with endogenous data. In a contextual multi-armed bandit\nmodel, a novel bias (self-fulfilling bias) arises because the endogeneity of\nthe data influences the choices of decisions, affecting the distribution of\nfuture data to be collected and analyzed. We propose an\ninstrumental-variable-based algorithm to correct for the bias. It obtains true\nparameter values and attains low (logarithmic-like) regret levels. We also\nprove a central limit theorem for statistical inference. To establish the\ntheoretical properties, we develop a general technique that untangles the\ninterdependence between data and actions.",
          "link": "http://arxiv.org/abs/2108.12547",
          "publishedOn": "2023-09-30T00:41:30.377Z",
          "wordCount": null,
          "title": "Dynamic Selection in Algorithmic Decision-making. (arXiv:2108.12547v3 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meyarian_A/0/1/0/all/0/1\">Abolfazl Meyarian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaohui Yuan</a>",
          "description": "High-resolution aerial imagery allows fine details in the segmentation of\nfarmlands. However, small objects and features introduce distortions to the\ndelineation of object boundaries, and larger contextual views are needed to\nmitigate class confusion. In this work, we present an end-to-end trainable\nnetwork for segmenting farmlands with contour levees from high-resolution\naerial imagery. A fusion block is devised that includes multiple voting blocks\nto achieve image segmentation and classification. We integrate the fusion block\nwith a backbone and produce both semantic predictions and segmentation slices.\nThe segmentation slices are used to perform majority voting on the predictions.\nThe network is trained to assign the most likely class label of a segment to\nits pixels, learning the concept of farmlands rather than analyzing\nconstitutive pixels separately. We evaluate our method using images from the\nNational Agriculture Imagery Program. Our method achieved an average accuracy\nof 94.34\\%. Compared to the state-of-the-art methods, the proposed method\nobtains an improvement of 6.96% and 2.63% in the F1 score on average.",
          "link": "http://arxiv.org/abs/2309.16561",
          "publishedOn": "2023-09-30T00:41:30.375Z",
          "wordCount": null,
          "title": "Voting Network for Contour Levee Farmland Segmentation and Classification. (arXiv:2309.16561v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16412",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fishkov_A/0/1/0/all/0/1\">Alexander Fishkov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Prediction with the possibility of abstention (or selective prediction) is an\nimportant problem for error-critical machine learning applications. While\nwell-studied in the classification setup, selective approaches to regression\nare much less developed. In this work, we consider the nonparametric\nheteroskedastic regression problem and develop an abstention procedure via\ntesting the hypothesis on the value of the conditional variance at a given\npoint. Unlike existing methods, the proposed one allows to account not only for\nthe value of the variance itself but also for the uncertainty of the\ncorresponding variance predictor. We prove non-asymptotic bounds on the risk of\nthe resulting estimator and show the existence of several different convergence\nregimes. Theoretical analysis is illustrated with a series of experiments on\nsimulated and real-world data.",
          "link": "http://arxiv.org/abs/2309.16412",
          "publishedOn": "2023-09-30T00:41:30.314Z",
          "wordCount": null,
          "title": "Selective Nonparametric Regression via Testing. (arXiv:2309.16412v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aiello_E/0/1/0/all/0/1\">Emanuele Aiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lili Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1\">Armen Aghajanyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1\">Barlas Oguz</a>",
          "description": "In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.",
          "link": "http://arxiv.org/abs/2309.15564",
          "publishedOn": "2023-09-30T00:41:30.313Z",
          "wordCount": null,
          "title": "Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zixuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ze Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1\">Jing Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "Enabling robots to effectively imitate expert skills in longhorizon tasks\nsuch as locomotion, manipulation, and more, poses a long-standing challenge.\nExisting imitation learning (IL) approaches for robots still grapple with\nsub-optimal performance in complex tasks. In this paper, we consider how this\nchallenge can be addressed within the human cognitive priors. Heuristically, we\nextend the usual notion of action to a dual Cognition (high-level)-Action\n(low-level) architecture by introducing intuitive human cognitive priors, and\npropose a novel skill IL framework through human-robot interaction, called\nCognition-Action-based Skill Imitation Learning (CasIL), for the robotic agent\nto effectively cognize and imitate the critical skills from raw visual\ndemonstrations. CasIL enables both cognition and action imitation, while\nhigh-level skill cognition explicitly guides low-level primitive actions,\nproviding robustness and reliability to the entire skill IL process. We\nevaluated our method on MuJoCo and RLBench benchmarks, as well as on the\nobstacle avoidance and point-goal navigation tasks for quadrupedal robot\nlocomotion. Experimental results show that our CasIL consistently achieves\ncompetitive and robust skill imitation capability compared to other\ncounterparts in a variety of long-horizon robotic tasks.",
          "link": "http://arxiv.org/abs/2309.16299",
          "publishedOn": "2023-09-30T00:41:30.311Z",
          "wordCount": null,
          "title": "CasIL: Cognizing and Imitating Skills via a Dual Cognition-Action Architecture. (arXiv:2309.16299v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_J/0/1/0/all/0/1\">Joseph M. Mahoney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paniak_T/0/1/0/all/0/1\">Tomasz B. Paniak</a>",
          "description": "Daily fantasy sports (DFS) are weekly or daily online contests where\nreal-game performances of individual players are converted to fantasy points\n(FPTS). Users select players for their lineup to maximize their FPTS within a\nset player salary cap. This paper focuses on (1) the development of a method to\nforecast NFL player performance under uncertainty and (2) determining an\noptimal lineup to maximize FPTS under a set salary limit. A supervised learning\nneural network was created and used to project FPTS based on past player\nperformance (2018 NFL regular season for this work) prior to the upcoming week.\nThese projected FPTS were used in a mixed integer linear program to find the\noptimal lineup. The performance of resultant lineups was compared to\nrandomly-created lineups. On average, the optimal lineups outperformed the\nrandom lineups. The generated lineups were then compared to real-world lineups\nfrom users on DraftKings. The generated lineups generally fell in approximately\nthe 31st percentile (median). The FPTS methods and predictions presented here\ncan be further improved using this study as a baseline comparison.",
          "link": "http://arxiv.org/abs/2309.15253",
          "publishedOn": "2023-09-30T00:41:30.311Z",
          "wordCount": null,
          "title": "Method and Validation for Optimal Lineup Creation for Daily Fantasy Football Using Machine Learning and Linear Programming. (arXiv:2309.15253v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islakoglu_D/0/1/0/all/0/1\">Duygu Sezen Islakoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chekol_M/0/1/0/all/0/1\">Mel Chekol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velegrakis_Y/0/1/0/all/0/1\">Yannis Velegrakis</a>",
          "description": "Most knowledge graph completion (KGC) methods learn latent representations of\nentities and relations of a given graph by mapping them into a vector space.\nAlthough the majority of these methods focus on static knowledge graphs, a\nlarge number of publicly available KGs contain temporal information stating the\ntime instant/period over which a certain fact has been true. Such graphs are\noften known as temporal knowledge graphs. Furthermore, knowledge graphs may\nalso contain textual descriptions of entities and relations. Both temporal\ninformation and textual descriptions are not taken into account during\nrepresentation learning by static KGC methods, and only structural information\nof the graph is leveraged. Recently, some studies have used temporal\ninformation to improve link prediction, yet they do not exploit textual\ndescriptions and do not support inductive inference (prediction on entities\nthat have not been seen in training).\n\nWe propose a novel framework called TEMT that exploits the power of\npre-trained language models (PLMs) for text-enhanced temporal knowledge graph\ncompletion. The knowledge stored in the parameters of a PLM allows TEMT to\nproduce rich semantic representations of facts and to generalize on previously\nunseen entities. TEMT leverages textual and temporal information available in a\nKG, treats them separately, and fuses them to get plausibility scores of facts.\nUnlike previous approaches, TEMT effectively captures dependencies across\ndifferent time points and enables predictions on unseen entities. To assess the\nperformance of TEMT, we carried out several experiments including time interval\nprediction, both in transductive and inductive settings, and triple\nclassification. The experimental results show that TEMT is competitive with the\nstate-of-the-art.",
          "link": "http://arxiv.org/abs/2309.16357",
          "publishedOn": "2023-09-30T00:41:30.310Z",
          "wordCount": null,
          "title": "Leveraging Pre-trained Language Models for Time Interval Prediction in Text-Enhanced Temporal Knowledge Graphs. (arXiv:2309.16357v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO), while proved highly effective for many black-box\nfunction optimization tasks, requires practitioners to carefully select priors\nthat well model their functions of interest. Rather than specifying by hand,\nresearchers have investigated transfer learning based methods to automatically\nlearn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO\n(Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those\nprior learning methods typically assume that the input domains are the same for\nall tasks, weakening their ability to use observations on functions with\ndifferent domains or generalize the learned priors to BO on different search\nspaces. In this work, we present HyperBO+: a pre-training approach for\nhierarchical Gaussian processes that enables the same prior to work universally\nfor Bayesian optimization on functions with different domains. We propose a\ntwo-step pre-training method and analyze its appealing asymptotic properties\nand benefits to BO both theoretically and empirically. On real-world\nhyperparameter tuning tasks that involve multiple search spaces, we demonstrate\nthat HyperBO+ is able to generalize to unseen search spaces and achieves lower\nregrets than competitive baselines.",
          "link": "http://arxiv.org/abs/2212.10538",
          "publishedOn": "2023-09-30T00:41:30.310Z",
          "wordCount": null,
          "title": "HyperBO+: Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian processes. (arXiv:2212.10538v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.05625",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_G/0/1/0/all/0/1\">Guangxi Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhao_X/0/1/0/all/0/1\">Xuanqiang Zhao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "An emerging direction of quantum computing is to establish meaningful quantum\napplications in various fields of artificial intelligence, including natural\nlanguage processing (NLP). Although some efforts based on syntactic analysis\nhave opened the door to research in Quantum NLP (QNLP), limitations such as\nheavy syntactic preprocessing and syntax-dependent network architecture make\nthem impracticable on larger and real-world data sets. In this paper, we\npropose a new simple network architecture, called the quantum self-attention\nneural network (QSANN), which can compensate for these limitations.\nSpecifically, we introduce the self-attention mechanism into quantum neural\nnetworks and then utilize a Gaussian projected quantum self-attention serving\nas a sensible quantum version of self-attention. As a result, QSANN is\neffective and scalable on larger data sets and has the desirable property of\nbeing implementable on near-term quantum devices. In particular, our QSANN\noutperforms the best existing QNLP model based on syntactic analysis as well as\na simple classical self-attention neural network in numerical experiments of\ntext classification tasks on public data sets. We further show that our method\nexhibits robustness to low-level quantum noises and showcases resilience to\nquantum neural network architectures.",
          "link": "http://arxiv.org/abs/2205.05625",
          "publishedOn": "2023-09-30T00:41:30.304Z",
          "wordCount": null,
          "title": "Quantum Self-Attention Neural Networks for Text Classification. (arXiv:2205.05625v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scafarto_G/0/1/0/all/0/1\">Gregory Scafarto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciortan_M/0/1/0/all/0/1\">Madalina Ciortan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tihon_S/0/1/0/all/0/1\">Simon Tihon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferre_Q/0/1/0/all/0/1\">Quentin Ferre</a>",
          "description": "Unsupervised learning allows us to leverage unlabelled data, which has become\nabundantly available, and to create embeddings that are usable on a variety of\ndownstream tasks. However, the typical lack of interpretability of unsupervised\nrepresentation learning has become a limiting factor with regard to recent\ntransparent-AI regulations. In this paper, we study graph representation\nlearning and we show that data augmentation that preserves semantics can be\nlearned and used to produce interpretations. Our framework, which we named\nINGENIOUS, creates inherently interpretable embeddings and eliminates the need\nfor costly additional post-hoc analysis. We also introduce additional metrics\naddressing the lack of formalism and metrics in the understudied area of\nunsupervised-representation learning interpretability. Our results are\nsupported by an experimental study applied to both graph-level and node-level\ntasks and show that interpretable embeddings provide state-of-the-art\nperformance on subsequent downstream tasks.",
          "link": "http://arxiv.org/abs/2309.16564",
          "publishedOn": "2023-09-30T00:41:30.303Z",
          "wordCount": null,
          "title": "Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings. (arXiv:2309.16564v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1\">Adri&#xe1;n Bazaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1\">Gos Micklem</a>",
          "description": "Unsupervised fact verification aims to verify a claim using evidence from a\ntrustworthy knowledge base without any kind of data annotation. To address this\nchallenge, algorithms must produce features for every claim that are both\nsemantically meaningful, and compact enough to find a semantic alignment with\nthe source information. In contrast to previous work, which tackled the\nalignment problem by learning over annotated corpora of claims and their\ncorresponding labels, we propose SFAVEL (Self-supervised Fact Verification via\nLanguage Model Distillation), a novel unsupervised framework that leverages\npre-trained language models to distil self-supervised features into\nhigh-quality claim-fact alignments without the need for annotations. This is\nenabled by a novel contrastive loss function that encourages features to attain\nhigh-quality claim and evidence alignments whilst preserving the semantic\nrelationships across the corpora. Notably, we present results that achieve a\nnew state-of-the-art on the standard FEVER fact verification benchmark (+8%\naccuracy) with linear evaluation.",
          "link": "http://arxiv.org/abs/2309.16540",
          "publishedOn": "2023-09-30T00:41:30.302Z",
          "wordCount": null,
          "title": "Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pedersen_C/0/1/0/all/0/1\">Christian Pedersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tesileanu_T/0/1/0/all/0/1\">Tiberiu Tesileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tinghui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golkar_S/0/1/0/all/0/1\">Siavash Golkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cranmer_M/0/1/0/all/0/1\">Miles Cranmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1\">Shirley Ho</a>",
          "description": "In, Elmarakeby et al., \"Biologically informed deep neural network for\nprostate cancer discovery\", a feedforward neural network with biologically\ninformed, sparse connections (P-NET) was presented to model the state of\nprostate cancer. We verified the reproducibility of the study conducted by\nElmarakeby et al., using both their original codebase, and our own\nre-implementation using more up-to-date libraries. We quantified the\ncontribution of network sparsification by Reactome biological pathways, and\nconfirmed its importance to P-NET's superior performance. Furthermore, we\nexplored alternative neural architectures and approaches to incorporating\nbiological information into the networks. We experimented with three types of\ngraph neural networks on the same training data, and investigated the clinical\nprediction agreement between different models. Our analyses demonstrated that\ndeep neural networks with distinct architectures make incorrect predictions for\nindividual patient that are persistent across different initializations of a\nspecific neural architecture. This suggests that different neural architectures\nare sensitive to different aspects of the data, an important yet under-explored\nchallenge for clinical prediction tasks.",
          "link": "http://arxiv.org/abs/2309.16645",
          "publishedOn": "2023-09-30T00:41:30.296Z",
          "wordCount": null,
          "title": "Reusability report: Prostate cancer stratification with diverse biologically-informed neural architectures. (arXiv:2309.16645v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Basu_C/0/1/0/all/0/1\">Chumki Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_H/0/1/0/all/0/1\">Himanshu Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McIntosh_A/0/1/0/all/0/1\">Allen McIntosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sablak_S/0/1/0/all/0/1\">Sezai Sablak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wullert_J/0/1/0/all/0/1\">John R. Wullert II</a>",
          "description": "The onset of the COVID-19 pandemic accentuated the need for access to\nbiomedical literature to answer timely and disease-specific questions. During\nthe early days of the pandemic, one of the biggest challenges we faced was the\nlack of peer-reviewed biomedical articles on COVID-19 that could be used to\ntrain machine learning models for question answering (QA). In this paper, we\nexplore the roles weak supervision and data augmentation play in training deep\nneural network QA models. First, we investigate whether labels generated\nautomatically from the structured abstracts of scholarly papers using an\ninformation retrieval algorithm, BM25, provide a weak supervision signal to\ntrain an extractive QA model. We also curate new QA pairs using information\nretrieval techniques, guided by the clinicaltrials.gov schema and the\nstructured abstracts of articles, in the absence of annotated data from\nbiomedical domain experts. Furthermore, we explore augmenting the training data\nof a deep neural network model with linguistic features from external sources\nsuch as lexical databases to account for variations in word morphology and\nmeaning. To better utilize our training data, we apply curriculum learning to\ndomain adaptation, fine-tuning our QA model in stages based on characteristics\nof the QA pairs. We evaluate our methods in the context of QA models at the\ncore of a system to answer questions about COVID-19.",
          "link": "http://arxiv.org/abs/2309.16175",
          "publishedOn": "2023-09-30T00:41:30.295Z",
          "wordCount": null,
          "title": "Using Weak Supervision and Data Augmentation in Question Answering. (arXiv:2309.16175v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Habineza_T/0/1/0/all/0/1\">Theogene Habineza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ant&#xf4;nio H. Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gedon_D/0/1/0/all/0/1\">Daniel Gedon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behar_J/0/1/0/all/0/1\">Joachim A. Behar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Antonio Luiz P. Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1\">Thomas B. Sch&#xf6;n</a>",
          "description": "Background: Atrial fibrillation (AF) is one of the most common cardiac\narrhythmias that affects millions of people each year worldwide and it is\nclosely linked to increased risk of cardiovascular diseases such as stroke and\nheart failure. Machine learning methods have shown promising results in\nevaluating the risk of developing atrial fibrillation from the\nelectrocardiogram. We aim to develop and evaluate one such algorithm on a large\nCODE dataset collected in Brazil.\n\nResults: The deep neural network model identified patients without indication\nof AF in the presented ECG but who will develop AF in the future with an AUC\nscore of 0.845. From our survival model, we obtain that patients in the\nhigh-risk group (i.e. with the probability of a future AF case being greater\nthan 0.7) are 50% more likely to develop AF within 40 weeks, while patients\nbelonging to the minimal-risk group (i.e. with the probability of a future AF\ncase being less than or equal to 0.1) have more than 85% chance of remaining AF\nfree up until after seven years.\n\nConclusion: We developed and validated a model for AF risk prediction. If\napplied in clinical practice, the model possesses the potential of providing\nvaluable and useful information in decision-making and patient management\nprocesses.",
          "link": "http://arxiv.org/abs/2309.16335",
          "publishedOn": "2023-09-30T00:41:30.294Z",
          "wordCount": null,
          "title": "End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG by Deep Neural Networks. (arXiv:2309.16335v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhongtao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haiteng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yunzhe Liu</a>",
          "description": "Decoding memory content from brain activity during sleep has long been a goal\nin neuroscience. While spontaneous reactivation of memories during sleep in\nrodents is known to support memory consolidation and offline learning,\ncapturing memory replay in humans is challenging due to the absence of\nwell-annotated sleep datasets and the substantial differences in neural\npatterns between wakefulness and sleep. To address these challenges, we\ndesigned a novel cognitive neuroscience experiment and collected a\ncomprehensive, well-annotated electroencephalography (EEG) dataset from 52\nsubjects during both wakefulness and sleep. Leveraging this benchmark dataset,\nwe developed the Universal Sleep Decoder (USD) to align neural representations\nbetween wakefulness and sleep across subjects. Our model achieves up to 16.6%\ntop-1 zero-shot accuracy on unseen subjects, comparable to decoding\nperformances using individual sleep data. Furthermore, fine-tuning USD on test\nsubjects enhances decoding accuracy to 25.9% top-1 accuracy, a substantial\nimprovement over the baseline chance of 6.7%. Model comparison and ablation\nanalyses reveal that our design choices, including the use of (i) an additional\ncontrastive objective to integrate awake and sleep neural signals and (ii) the\npretrain-finetune paradigm to incorporate different subjects, significantly\ncontribute to these performances. Collectively, our findings and methodologies\nrepresent a significant advancement in the field of sleep decoding.",
          "link": "http://arxiv.org/abs/2309.16457",
          "publishedOn": "2023-09-30T00:41:30.294Z",
          "wordCount": null,
          "title": "Universal Sleep Decoder: Aligning awake and sleep neural representation across subjects. (arXiv:2309.16457v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akins_S/0/1/0/all/0/1\">Sapphira Akins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Frances Zhu</a>",
          "description": "Robots with increasing autonomy progress our space exploration capabilities,\nparticularly for in-situ exploration and sampling to stand in for human\nexplorers. Currently, humans drive robots to meet scientific objectives, but\ndepending on the robot's location, the exchange of information and driving\ncommands between the human operator and robot may cause undue delays in mission\nfulfillment. An autonomous robot encoded with a scientific objective and an\nexploration strategy incurs no communication delays and can fulfill missions\nmore quickly. Active learning algorithms offer this capability of intelligent\nexploration, but the underlying model structure varies the performance of the\nactive learning algorithm in accurately forming an understanding of the\nenvironment. In this paper, we investigate the performance differences between\nactive learning algorithms driven by Gaussian processes or Bayesian neural\nnetworks for exploration strategies encoded on agents that are constrained in\ntheir trajectories, like planetary surface rovers. These two active learning\nstrategies were tested in a simulation environment against science-blind\nstrategies to predict the spatial distribution of a variable of interest along\nmultiple datasets. The performance metrics of interest are model accuracy in\nroot mean squared (RMS) error, training time, model convergence, total distance\ntraveled until convergence, and total samples until convergence. Active\nlearning strategies encoded with Gaussian processes require less computation to\ntrain, converge to an accurate model more quickly, and propose trajectories of\nshorter distance, except in a few complex environments in which Bayesian neural\nnetworks achieve a more accurate model in the large data regime due to their\nmore expressive functional bases. The paper concludes with advice on when and\nhow to implement either exploration strategy for future space missions.",
          "link": "http://arxiv.org/abs/2309.16114",
          "publishedOn": "2023-09-30T00:41:30.293Z",
          "wordCount": null,
          "title": "Comparing Active Learning Performance Driven by Gaussian Processes or Bayesian Neural Networks for Constrained Trajectory Exploration. (arXiv:2309.16114v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karimzadeh_M/0/1/0/all/0/1\">Mohammad Karimzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakanski_A/0/1/0/all/0/1\">Aleksandar Vakanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Fei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinchang Zhang</a>",
          "description": "Additive manufacturing has revolutionized the manufacturing of complex parts\nby enabling direct material joining and offers several advantages such as\ncost-effective manufacturing of complex parts, reducing manufacturing waste,\nand opening new possibilities for manufacturing automation. One group of\nmaterials for which additive manufacturing holds great potential for enhancing\ncomponent performance and properties is Functionally Graded Materials (FGMs).\nFGMs are advanced composite materials that exhibit smoothly varying properties\nmaking them desirable for applications in aerospace, automobile, biomedical,\nand defense industries. Such composition differs from traditional composite\nmaterials, since the location-dependent composition changes gradually in FGMs,\nleading to enhanced properties. Recently, machine learning techniques have\nemerged as a promising means for fabrication of FGMs through optimizing\nprocessing parameters, improving product quality, and detecting manufacturing\ndefects. This paper first provides a brief literature review of works related\nto FGM fabrication, followed by reviewing works on employing machine learning\nin additive manufacturing, Afterward, we provide an overview of published works\nin the literature related to the application of machine learning methods in\nDirected Energy Deposition and for fabrication of FGMs.",
          "link": "http://arxiv.org/abs/2309.16571",
          "publishedOn": "2023-09-30T00:41:30.293Z",
          "wordCount": null,
          "title": "Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials. (arXiv:2309.16571v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiashi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Changwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Ming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shin Hwei Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xuetao Wei</a>",
          "description": "Recent advances in federated learning (FL) enable collaborative training of\nmachine learning (ML) models from large-scale and widely dispersed clients\nwhile protecting their privacy. However, when different clients' datasets are\nheterogeneous, traditional FL mechanisms produce a global model that does not\nadequately represent the poorer clients with limited data resources, resulting\nin lower accuracy and higher bias on their local data. According to the Matthew\neffect, which describes how the advantaged gain more advantage and the\ndisadvantaged lose more over time, deploying such a global model in client\napplications may worsen the resource disparity among the clients and harm the\nprinciples of social welfare and fairness. To mitigate the Matthew effect, we\npropose Egalitarian Fairness Federated Learning (EFFL), where egalitarian\nfairness refers to the global model learned from FL has: (1) equal accuracy\namong clients; (2) equal decision bias among clients. Besides achieving\negalitarian fairness among the clients, EFFL also aims for performance\noptimality, minimizing the empirical risk loss and the bias for each client;\nboth are essential for any ML model training, whether centralized or\ndecentralized. We formulate EFFL as a constrained multi-constrained\nmulti-objectives optimization (MCMOO) problem, with the decision bias and\negalitarian fairness as constraints and the minimization of the empirical risk\nlosses on all clients as multiple objectives to be optimized. We propose a\ngradient-based three-stage algorithm to obtain the Pareto optimal solutions\nwithin the constraint space. Extensive experiments demonstrate that EFFL\noutperforms other state-of-the-art FL algorithms in achieving a\nhigh-performance global model with enhanced egalitarian fairness among all\nclients.",
          "link": "http://arxiv.org/abs/2309.16338",
          "publishedOn": "2023-09-30T00:41:30.291Z",
          "wordCount": null,
          "title": "EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect. (arXiv:2309.16338v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1\">Xubo Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanyang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siriya_S/0/1/0/all/0/1\">Seth Siriya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1\">Ye Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mo Chen</a>",
          "description": "We present task-oriented Koopman-based control that utilizes end-to-end\nreinforcement learning and contrastive encoder to simultaneously learn the\nKoopman latent embedding, operator and associated linear controller within an\niterative loop. By prioritizing the task cost as main objective for controller\nlearning, we reduce the reliance of controller design on a well-identified\nmodel, which extends Koopman control beyond low-dimensional systems to\nhigh-dimensional, complex nonlinear systems, including pixel-based scenarios.",
          "link": "http://arxiv.org/abs/2309.16077",
          "publishedOn": "2023-09-30T00:41:30.288Z",
          "wordCount": null,
          "title": "Task-Oriented Koopman-Based Control with Contrastive Encoder. (arXiv:2309.16077v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizmalayeri_M/0/1/0/all/0/1\">Mohammad Azizmalayeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abu_Hanna_A/0/1/0/all/0/1\">Ameen Abu-Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cina_G/0/1/0/all/0/1\">Giovanni Cin&#xe1;</a>",
          "description": "Despite their success, Machine Learning (ML) models do not generalize\neffectively to data not originating from the training distribution. To reliably\nemploy ML models in real-world healthcare systems and avoid inaccurate\npredictions on out-of-distribution (OOD) data, it is crucial to detect OOD\nsamples. Numerous OOD detection approaches have been suggested in other fields\n- especially in computer vision - but it remains unclear whether the challenge\nis resolved when dealing with medical tabular data. To answer this pressing\nneed, we propose an extensive reproducible benchmark to compare different\nmethods across a suite of tests including both near and far OODs. Our benchmark\nleverages the latest versions of eICU and MIMIC-IV, two public datasets\nencompassing tens of thousands of ICU patients in several hospitals. We\nconsider a wide array of density-based methods and SOTA post-hoc detectors\nacross diverse predictive architectures, including MLP, ResNet, and\nTransformer. Our findings show that i) the problem appears to be solved for\nfar-OODs, but remains open for near-OODs; ii) post-hoc methods alone perform\npoorly, but improve substantially when coupled with distance-based mechanisms;\niii) the transformer architecture is far less overconfident compared to MLP and\nResNet.",
          "link": "http://arxiv.org/abs/2309.16220",
          "publishedOn": "2023-09-30T00:41:30.285Z",
          "wordCount": null,
          "title": "Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data. (arXiv:2309.16220v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garipov_T/0/1/0/all/0/1\">Timur Garipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peuter_S/0/1/0/all/0/1\">Sebastiaan De Peuter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Ge Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_V/0/1/0/all/0/1\">Vikas Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>",
          "description": "High training costs of generative models and the need to fine-tune them for\nspecific tasks have created a strong interest in model reuse and composition. A\nkey challenge in composing iterative generative processes, such as GFlowNets\nand diffusion models, is that to realize the desired target distribution, all\nsteps of the generative process need to be coordinated, and satisfy delicate\nbalance conditions. In this work, we propose Compositional Sculpting: a general\napproach for defining compositions of iterative generative processes. We then\nintroduce a method for sampling from these compositions built on classifier\nguidance. We showcase ways to accomplish compositional sculpting in both\nGFlowNets and diffusion models. We highlight two binary operations\n$\\unicode{x2014}$ the harmonic mean ($p_1 \\otimes p_2$) and the contrast ($p_1\n\\unicode{x25D1}\\,p_2$) between pairs, and the generalization of these\noperations to multiple component distributions. We offer empirical results on\nimage and molecular generation tasks.",
          "link": "http://arxiv.org/abs/2309.16115",
          "publishedOn": "2023-09-30T00:41:30.282Z",
          "wordCount": 649,
          "title": "Compositional Sculpting of Iterative Generative Processes. (arXiv:2309.16115v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Figueiredo_F/0/1/0/all/0/1\">Flavio Figueiredo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_J/0/1/0/all/0/1\">Jos&#xe9; Geraldo Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1\">Jackson Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assuncao_R/0/1/0/all/0/1\">Renato M. Assun&#xe7;&#xe3;o</a>",
          "description": "Copulas are a powerful statistical tool that captures dependencies across\ndata dimensions. When applying Copulas, we can estimate multivariate\ndistribution functions by initially estimating independent marginals, an easy\ntask, and then a single copulating function, $C$, to connect the marginals, a\nhard task. For two-dimensional data, a copula is a two-increasing function of\nthe form $C: (u,v)\\in \\mathbf{I}^2 \\rightarrow \\mathbf{I}$, where $\\mathbf{I} =\n[0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any\ntwo-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is\ninspired by the Physics-Informed Neural Networks and Sobolev Training\nliterature. Not only do we show that we can estimate the output of a 2d Copula\nbetter than the state-of-the-art, our approach is non-parametric and respects\nthe mathematical properties of a Copula $C$.",
          "link": "http://arxiv.org/abs/2309.16391",
          "publishedOn": "2023-09-30T00:41:30.274Z",
          "wordCount": null,
          "title": "Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks. (arXiv:2309.16391v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toshev_A/0/1/0/all/0/1\">Artur P. Toshev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galletti_G/0/1/0/all/0/1\">Gianluca Galletti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fritz_F/0/1/0/all/0/1\">Fabian Fritz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adami_S/0/1/0/all/0/1\">Stefan Adami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adams_N/0/1/0/all/0/1\">Nikolaus A. Adams</a>",
          "description": "Machine learning has been successfully applied to grid-based PDE modeling in\nvarious scientific applications. However, learned PDE solvers based on\nLagrangian particle discretizations, which are the preferred approach to\nproblems with free surfaces or complex physics, remain largely unexplored. We\npresent LagrangeBench, the first benchmarking suite for Lagrangian particle\nproblems, focusing on temporal coarse-graining. In particular, our contribution\nis: (a) seven new fluid mechanics datasets (four in 2D and three in 3D)\ngenerated with the Smoothed Particle Hydrodynamics (SPH) method including the\nTaylor-Green vortex, lid-driven cavity, reverse Poiseuille flow, and dam break,\neach of which includes different physics like solid wall interactions or free\nsurface, (b) efficient JAX-based API with various recent training strategies\nand neighbors search routine, and (c) JAX implementation of established Graph\nNeural Networks (GNNs) like GNS and SEGNN with baseline results. Finally, to\nmeasure the performance of learned surrogates we go beyond established position\nerrors and introduce physical metrics like kinetic energy MSE and Sinkhorn\ndistance for the particle distribution. Our codebase is available under the\nURL: https://github.com/tumaer/lagrangebench",
          "link": "http://arxiv.org/abs/2309.16342",
          "publishedOn": "2023-09-30T00:41:30.264Z",
          "wordCount": null,
          "title": "LagrangeBench: A Lagrangian Fluid Mechanics Benchmarking Suite. (arXiv:2309.16342v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO) is a popular black-box function optimization\nmethod, which makes sequential decisions based on a Bayesian model, typically a\nGaussian process (GP), of the function. To ensure the quality of the model,\ntransfer learning approaches have been developed to automatically design GP\npriors by learning from observations on \"training\" functions. These training\nfunctions are typically required to have the same domain as the \"test\" function\n(black-box function to be optimized). In this paper, we introduce MPHD, a model\npre-training method on heterogeneous domains, which uses a neural net mapping\nfrom domain-specific contexts to specifications of hierarchical GPs. MPHD can\nbe seamlessly integrated with BO to transfer knowledge across heterogeneous\nsearch spaces. Our theoretical and empirical results demonstrate the validity\nof MPHD and its superior performance on challenging black-box function\noptimization tasks.",
          "link": "http://arxiv.org/abs/2309.16597",
          "publishedOn": "2023-09-30T00:41:30.263Z",
          "wordCount": null,
          "title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaoqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yibo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxin Chen</a>",
          "description": "The increasing capabilities of large language models (LLMs) raise\nopportunities for artificial general intelligence but concurrently amplify\nsafety concerns, such as potential misuse of AI systems, necessitating\neffective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has\nemerged as a promising pathway towards AI alignment but brings forth challenges\ndue to its complexity and dependence on a separate reward model. Direct\nPreference Optimization (DPO) has been proposed as an alternative, and it\nremains equivalent to RLHF under the reverse KL regularization constraint. This\npaper presents $f$-DPO, a generalized approach to DPO by incorporating diverse\ndivergence constraints. We show that under certain $f$-divergences, including\nJensen-Shannon divergence, forward KL divergences and $\\alpha$-divergences, the\ncomplex relationship between the reward and optimal policy can also be\nsimplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the\nneed for estimating the normalizing constant in the Bradley-Terry model and\nenables a tractable mapping between the reward function and the optimal policy.\nOur approach optimizes LLMs to align with human preferences in a more efficient\nand supervised manner under a broad set of divergence constraints. Empirically,\nadopting these divergences ensures a balance between alignment performance and\ngeneration diversity. Importantly, $f$-DPO outperforms PPO-based methods in\ndivergence efficiency, and divergence constraints directly influence expected\ncalibration error (ECE).",
          "link": "http://arxiv.org/abs/2309.16240",
          "publishedOn": "2023-09-30T00:41:30.262Z",
          "wordCount": null,
          "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints. (arXiv:2309.16240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demelius_L/0/1/0/all/0/1\">Lea Demelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kern_R/0/1/0/all/0/1\">Roman Kern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trugler_A/0/1/0/all/0/1\">Andreas Tr&#xfc;gler</a>",
          "description": "Differential Privacy has become a widely popular method for data protection\nin machine learning, especially since it allows formulating strict mathematical\nprivacy guarantees. This survey provides an overview of the state-of-the-art of\ndifferentially private centralized deep learning, thorough analyses of recent\nadvances and open problems, as well as a discussion of potential future\ndevelopments in the field. Based on a systematic literature review, the\nfollowing topics are addressed: auditing and evaluation methods for private\nmodels, improvements of privacy-utility trade-offs, protection against a broad\nrange of threats and attacks, differentially private generative models, and\nemerging application domains.",
          "link": "http://arxiv.org/abs/2309.16398",
          "publishedOn": "2023-09-30T00:41:30.259Z",
          "wordCount": null,
          "title": "Recent Advances of Differential Privacy in Centralized Deep Learning: A Systematic Survey. (arXiv:2309.16398v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ismail_Fawaz_A/0/1/0/all/0/1\">Ali Ismail-Fawaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fawaz_H/0/1/0/all/0/1\">Hassan Ismail Fawaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petitjean_F/0/1/0/all/0/1\">Fran&#xe7;ois Petitjean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devanne_M/0/1/0/all/0/1\">Maxime Devanne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_J/0/1/0/all/0/1\">Jonathan Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berretti_S/0/1/0/all/0/1\">Stefano Berretti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1\">Geoffrey I. Webb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forestier_G/0/1/0/all/0/1\">Germain Forestier</a>",
          "description": "Time series data can be found in almost every domain, ranging from the\nmedical field to manufacturing and wireless communication. Generating realistic\nand useful exemplars and prototypes is a fundamental data analysis task. In\nthis paper, we investigate a novel approach to generating realistic and useful\nexemplars and prototypes for time series data. Our approach uses a new form of\ntime series average, the ShapeDTW Barycentric Average. We therefore turn our\nattention to accurately generating time series prototypes with a novel\napproach. The existing time series prototyping approaches rely on the Dynamic\nTime Warping (DTW) similarity measure such as DTW Barycentering Average (DBA)\nand SoftDBA. These last approaches suffer from a common problem of generating\nout-of-distribution artifacts in their prototypes. This is mostly caused by the\nDTW variant used and its incapability of detecting neighborhood similarities,\ninstead it detects absolute similarities. Our proposed method, ShapeDBA, uses\nthe ShapeDTW variant of DTW, that overcomes this issue. We chose time series\nclustering, a popular form of time series analysis to evaluate the outcome of\nShapeDBA compared to the other prototyping approaches. Coupled with the k-means\nclustering algorithm, and evaluated on a total of 123 datasets from the UCR\narchive, our proposed averaging approach is able to achieve new\nstate-of-the-art results in terms of Adjusted Rand Index.",
          "link": "http://arxiv.org/abs/2309.16353",
          "publishedOn": "2023-09-30T00:41:30.257Z",
          "wordCount": null,
          "title": "ShapeDBA: Generating Effective Time Series Prototypes using ShapeDTW Barycenter Averaging. (arXiv:2309.16353v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16314",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Arbel_J/0/1/0/all/0/1\">Julyan Arbel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pitas_K/0/1/0/all/0/1\">Konstantinos Pitas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vladimirova_M/0/1/0/all/0/1\">Mariia Vladimirova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>",
          "description": "Neural networks have achieved remarkable performance across various problem\ndomains, but their widespread applicability is hindered by inherent limitations\nsuch as overconfidence in predictions, lack of interpretability, and\nvulnerability to adversarial attacks. To address these challenges, Bayesian\nneural networks (BNNs) have emerged as a compelling extension of conventional\nneural networks, integrating uncertainty estimation into their predictive\ncapabilities.\n\nThis comprehensive primer presents a systematic introduction to the\nfundamental concepts of neural networks and Bayesian inference, elucidating\ntheir synergistic integration for the development of BNNs. The target audience\ncomprises statisticians with a potential background in Bayesian methods but\nlacking deep learning expertise, as well as machine learners proficient in deep\nneural networks but with limited exposure to Bayesian statistics. We provide an\noverview of commonly employed priors, examining their impact on model behavior\nand performance. Additionally, we delve into the practical considerations\nassociated with training and inference in BNNs.\n\nFurthermore, we explore advanced topics within the realm of BNN research,\nacknowledging the existence of ongoing debates and controversies. By offering\ninsights into cutting-edge developments, this primer not only equips\nresearchers and practitioners with a solid foundation in BNNs, but also\nilluminates the potential applications of this dynamic field. As a valuable\nresource, it fosters an understanding of BNNs and their promising prospects,\nfacilitating further advancements in the pursuit of knowledge and innovation.",
          "link": "http://arxiv.org/abs/2309.16314",
          "publishedOn": "2023-09-30T00:41:30.256Z",
          "wordCount": null,
          "title": "A Primer on Bayesian Neural Networks: Review and Debates. (arXiv:2309.16314v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bargiotas_I/0/1/0/all/0/1\">Ioannis Bargiotas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1\">Argyris Kalogeratos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "The standard paired-sample testing approach in the multidimensional setting\napplies multiple univariate tests on the individual features, followed by\np-value adjustments. Such an approach suffers when the data carry numerous\nfeatures. A number of studies have shown that classification accuracy can be\nseen as a proxy for two-sample testing. However, neither theoretical\nfoundations nor practical recipes have been proposed so far on how this\nstrategy could be extended to multidimensional paired-sample testing. In this\nwork, we put forward the idea that scoring functions can be produced by the\ndecision rules defined by the perpendicular bisecting hyperplanes of the line\nsegments connecting each pair of instances. Then, the optimal scoring function\ncan be obtained by the pseudomedian of those rules, which we estimate by\nextending naturally the Hodges-Lehmann estimator. We accordingly propose a\nframework of a two-step testing procedure. First, we estimate the bisecting\nhyperplanes for each pair of instances and an aggregated rule derived through\nthe Hodges-Lehmann estimator. The paired samples are scored by this aggregated\nrule to produce a unidimensional representation. Second, we perform a Wilcoxon\nsigned-rank test on the obtained representation. Our experiments indicate that\nour approach has substantial performance gains in testing accuracy compared to\nthe traditional multivariate and multiple testing, while at the same time\nestimates each feature's contribution to the final result.",
          "link": "http://arxiv.org/abs/2309.16274",
          "publishedOn": "2023-09-30T00:41:30.255Z",
          "wordCount": null,
          "title": "A framework for paired-sample hypothesis testing for high-dimensional data. (arXiv:2309.16274v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Luming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1\">Nataniel Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1\">Qinghao Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holynski_A/0/1/0/all/0/1\">Aleksander Holynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David E. Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1\">Bharath Hariharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1\">Yael Pritch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadhwa_N/0/1/0/all/0/1\">Neal Wadhwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1\">Kfir Aberman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_M/0/1/0/all/0/1\">Michael Rubinstein</a>",
          "description": "Recent advances in generative imagery have brought forth outpainting and\ninpainting models that can produce high-quality, plausible image content in\nunknown regions, but the content these models hallucinate is necessarily\ninauthentic, since the models lack sufficient context about the true scene. In\nthis work, we propose RealFill, a novel generative approach for image\ncompletion that fills in missing regions of an image with the content that\nshould have been there. RealFill is a generative inpainting model that is\npersonalized using only a few reference images of a scene. These reference\nimages do not have to be aligned with the target image, and can be taken with\ndrastically varying viewpoints, lighting conditions, camera apertures, or image\nstyles. Once personalized, RealFill is able to complete a target image with\nvisually compelling contents that are faithful to the original scene. We\nevaluate RealFill on a new image completion benchmark that covers a set of\ndiverse and challenging scenarios, and find that it outperforms existing\napproaches by a large margin. See more results on our project page:\nhttps://realfill.github.io",
          "link": "http://arxiv.org/abs/2309.16668",
          "publishedOn": "2023-09-30T00:41:30.252Z",
          "wordCount": null,
          "title": "RealFill: Reference-Driven Generation for Authentic Image Completion. (arXiv:2309.16668v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amara_K/0/1/0/all/0/1\">Kenza Amara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Assady_M/0/1/0/all/0/1\">Mennatallah El-Assady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rex Ying</a>",
          "description": "Diverse explainability methods of graph neural networks (GNN) have recently\nbeen developed to highlight the edges and nodes in the graph that contribute\nthe most to the model predictions. However, it is not clear yet how to evaluate\nthe correctness of those explanations, whether it is from a human or a model\nperspective. One unaddressed bottleneck in the current evaluation procedure is\nthe problem of out-of-distribution explanations, whose distribution differs\nfrom those of the training data. This important issue affects existing\nevaluation metrics such as the popular faithfulness or fidelity score. In this\npaper, we show the limitations of faithfulness metrics. We propose GInX-Eval\n(Graph In-distribution eXplanation Evaluation), an evaluation procedure of\ngraph explanations that overcomes the pitfalls of faithfulness and offers new\ninsights on explainability methods. Using a retraining strategy, the GInX score\nmeasures how informative removed edges are for the model and the EdgeRank score\nevaluates if explanatory edges are correctly ordered by their importance.\nGInX-Eval verifies if ground-truth explanations are instructive to the GNN\nmodel. In addition, it shows that many popular methods, including\ngradient-based methods, produce explanations that are not better than a random\ndesignation of edges as important subgraphs, challenging the findings of\ncurrent works in the area. Results with GInX-Eval are consistent across\nmultiple datasets and align with human evaluation.",
          "link": "http://arxiv.org/abs/2309.16223",
          "publishedOn": "2023-09-30T00:41:30.249Z",
          "wordCount": null,
          "title": "GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations. (arXiv:2309.16223v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yousif_M/0/1/0/all/0/1\">Maitham G. Yousif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_H/0/1/0/all/0/1\">Hector J. Castro</a>",
          "description": "The COVID-19 pandemic has globally posed numerous health challenges, notably\nthe emergence of post-COVID-19 cardiovascular complications. This study\naddresses this by utilizing data-driven machine learning models to predict such\ncomplications in 352 post-COVID-19 patients from Iraq. Clinical data, including\ndemographics, comorbidities, lab results, and imaging, were collected and used\nto construct predictive models. These models, leveraging various machine\nlearning algorithms, demonstrated commendable performance in identifying\npatients at risk. Early detection through these models promises timely\ninterventions and improved outcomes. In conclusion, this research underscores\nthe potential of data-driven machine learning for predicting post-COVID-19\ncardiovascular complications, emphasizing the need for continued validation and\nresearch in diverse clinical settings.",
          "link": "http://arxiv.org/abs/2309.16059",
          "publishedOn": "2023-09-30T00:41:30.248Z",
          "wordCount": null,
          "title": "Predicting Cardiovascular Complications in Post-COVID-19 Patients Using Data-Driven Machine Learning Models. (arXiv:2309.16059v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yilei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zijian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chongyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Juan Helen Zhou</a>",
          "description": "In representation learning, regression has traditionally received less\nattention than classification. Directly applying representation learning\ntechniques designed for classification to regression often results in\nfragmented representations in the latent space, yielding sub-optimal\nperformance. In this paper, we argue that the potential of contrastive learning\nfor regression has been overshadowed due to the neglect of two crucial aspects:\nordinality-awareness and hardness. To address these challenges, we advocate\n\"mixup your own contrastive pairs for supervised contrastive regression\",\ninstead of relying solely on real/augmented samples. Specifically, we propose\nSupervised Contrastive Learning for Regression with Mixup (SupReMix). It takes\nanchor-inclusive mixtures (mixup of the anchor and a distinct negative sample)\nas hard negative pairs and anchor-exclusive mixtures (mixup of two distinct\nnegative samples) as hard positive pairs at the embedding level. This strategy\nformulates harder contrastive pairs by integrating richer ordinal information.\nThrough extensive experiments on six regression datasets including 2D images,\nvolumetric images, text, tabular data, and time-series signals, coupled with\ntheoretical analysis, we demonstrate that SupReMix pre-training fosters\ncontinuous ordered representations of regression data, resulting in significant\nimprovement in regression performance. Furthermore, SupReMix is superior to\nother approaches in a range of regression challenges including transfer\nlearning, imbalanced training data, and scenarios with fewer training samples.",
          "link": "http://arxiv.org/abs/2309.16633",
          "publishedOn": "2023-09-30T00:41:30.245Z",
          "wordCount": null,
          "title": "Mixup Your Own Pairs. (arXiv:2309.16633v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lingfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linfeng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lifeng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1\">Haitao Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>",
          "description": "Standard practice within Reinforcement Learning from Human Feedback (RLHF)\ninvolves optimizing against a Reward Model (RM), which itself is trained to\nreflect human preferences for desirable generations. A notable subject that is\nunderstudied is the (in-)consistency of RMs -- whether they can recognize the\nsemantic changes to different prompts and appropriately adapt their reward\nassignments -- and their impact on the downstream RLHF model.\n\nIn this paper, we visit a series of research questions relevant to RM\ninconsistency: (1) How can we measure the consistency of reward models? (2) How\nconsistent are the existing RMs and how can we improve them? (3) In what ways\ndoes reward inconsistency influence the chatbots resulting from the RLHF model\ntraining?\n\nWe propose Contrast Instructions -- a benchmarking strategy for the\nconsistency of RM. Each example in Contrast Instructions features a pair of\nlexically similar instructions with different ground truth responses. A\nconsistent RM is expected to rank the corresponding instruction and response\nhigher than other combinations. We observe that current RMs trained with the\nstandard ranking objective fail miserably on Contrast Instructions compared to\naverage humans. To show that RM consistency can be improved efficiently without\nusing extra training budget, we propose two techniques ConvexDA and\nRewardFusion, which enhance reward consistency through extrapolation during the\nRM training and inference stage, respectively. We show that RLHF models trained\nwith a more consistent RM yield more useful responses, suggesting that reward\ninconsistency exhibits a trickle-down effect on the downstream RLHF process.",
          "link": "http://arxiv.org/abs/2309.16155",
          "publishedOn": "2023-09-30T00:41:30.243Z",
          "wordCount": null,
          "title": "The Trickle-down Impact of Reward (In-)consistency on RLHF. (arXiv:2309.16155v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinghua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Shaukat Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_T/0/1/0/all/0/1\">Tao Yue</a>",
          "description": "Anomaly detection is critical to ensure the security of cyber-physical\nsystems (CPS). However, due to the increasing complexity of attacks and CPS\nthemselves, anomaly detection in CPS is becoming more and more challenging. In\nour previous work, we proposed a digital twin-based anomaly detection method,\ncalled ATTAIN, which takes advantage of both historical and real-time data of\nCPS. However, such data vary significantly in terms of difficulty. Therefore,\nsimilar to human learning processes, deep learning models (e.g., ATTAIN) can\nbenefit from an easy-to-difficult curriculum. To this end, in this paper, we\npresent a novel approach, named digitaL twin-based Anomaly deTecTion wIth\nCurriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum\nlearning to optimize its learning paradigm. LATTICE attributes each sample with\na difficulty score, before being fed into a training scheduler. The training\nscheduler samples batches of training data based on these difficulty scores\nsuch that learning from easy to difficult data can be performed. To evaluate\nLATTICE, we use five publicly available datasets collected from five real-world\nCPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art\nanomaly detectors. Evaluation results show that LATTICE outperforms the three\nbaselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also,\non average, reduces the training time of ATTAIN by 4.2% on the five datasets\nand is on par with the baselines in terms of detection delay time.",
          "link": "http://arxiv.org/abs/2309.15995",
          "publishedOn": "2023-09-30T00:41:30.242Z",
          "wordCount": null,
          "title": "Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems. (arXiv:2309.15995v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yousif_M/0/1/0/all/0/1\">Maitham G. Yousif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Amran_F/0/1/0/all/0/1\">Fadhil G. Al-Amran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_H/0/1/0/all/0/1\">Hector J. Castro</a>",
          "description": "In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq",
          "link": "http://arxiv.org/abs/2309.16055",
          "publishedOn": "2023-09-30T00:41:30.233Z",
          "wordCount": null,
          "title": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A Machine Learning Perspective. (arXiv:2309.16055v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1812.00029",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Panda_S/0/1/0/all/0/1\">Sambit Panda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1\">Cencheng Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Decision forests are widely used for classification and regression tasks. A\nlesser known property of tree-based methods is that one can construct a\nproximity matrix from the tree(s), and these proximity matrices are induced\nkernels. While there has been extensive research on the applications and\nproperties of kernels, there is relatively little research on kernels induced\nby decision forests. We construct Kernel Mean Embedding Random Forests (KMERF),\nwhich induce kernels from random trees and/or forests using leaf-node\nproximity. We introduce the notion of an asymptotically characteristic kernel,\nand prove that KMERF kernels are asymptotically characteristic for both\ndiscrete and continuous data. Because KMERF is data-adaptive, we suspected it\nwould outperform kernels selected a priori on finite sample data. We illustrate\nthat KMERF nearly dominates current state-of-the-art kernel-based tests across\na diverse range of high-dimensional two-sample and independence testing\nsettings. Furthermore, our forest-based approach is interpretable, and provides\nfeature importance metrics that readily distinguish important dimensions,\nunlike other high-dimensional non-parametric testing procedures. Hence, this\nwork demonstrates the decision forest-based kernel can be more powerful and\nmore interpretable than existing methods, flying in the face of conventional\nwisdom of the trade-off between the two.",
          "link": "http://arxiv.org/abs/1812.00029",
          "publishedOn": "2023-09-30T00:41:30.233Z",
          "wordCount": null,
          "title": "Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaemmaghami_B/0/1/0/all/0/1\">Benjamin Ghaemmaghami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Ashish Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_B/0/1/0/all/0/1\">Benjamin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orshansky_L/0/1/0/all/0/1\">Leo Orshansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erez_M/0/1/0/all/0/1\">Mattan Erez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orshansky_M/0/1/0/all/0/1\">Michael Orshansky</a>",
          "description": "Modern DNN-based recommendation systems rely on training-derived embeddings\nof sparse features. Input sparsity makes obtaining high-quality embeddings for\nrarely-occurring categories harder as their representations are updated\ninfrequently. We demonstrate a training-time technique to produce superior\nembeddings via effective cross-category learning and theoretically explain its\nsurprising effectiveness. The scheme, termed the multi-layer embeddings\ntraining (MLET), trains embeddings using factorization of the embedding layer,\nwith an inner dimension higher than the target embedding dimension. For\ninference efficiency, MLET converts the trained two-layer embedding into a\nsingle-layer one thus keeping inference-time model size unchanged.\n\nEmpirical superiority of MLET is puzzling as its search space is not larger\nthan that of the single-layer embedding. The strong dependence of MLET on the\ninner dimension is even more surprising. We develop a theory that explains both\nof these behaviors by showing that MLET creates an adaptive update mechanism\nmodulated by the singular vectors of embeddings. When tested on multiple\nstate-of-the-art recommendation models for click-through rate (CTR) prediction\ntasks, MLET consistently produces better models, especially for rare items. At\nconstant model quality, MLET allows embedding dimension, and model size,\nreduction by up to 16x, and 5.8x on average, across the models.",
          "link": "http://arxiv.org/abs/2309.15881",
          "publishedOn": "2023-09-30T00:41:30.232Z",
          "wordCount": null,
          "title": "Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer Embedding Training. (arXiv:2309.15881v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16347",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Triantafyllidis_E/0/1/0/all/0/1\">Eleftherios Triantafyllidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhibin Li</a>",
          "description": "Current reinforcement learning algorithms struggle in sparse and complex\nenvironments, most notably in long-horizon manipulation tasks entailing a\nplethora of different sequences. In this work, we propose the Intrinsically\nGuided Exploration from Large Language Models (IGE-LLMs) framework. By\nleveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the\nexploratory process in reinforcement learning to address intricate long-horizon\nwith sparse rewards robotic manipulation tasks. We evaluate our framework and\nrelated intrinsic learning methods in an environment challenged with\nexploration, and a complex robotic manipulation task challenged by both\nexploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher\nperformance over related intrinsic methods and the direct use of LLMs in\ndecision-making, (ii) can be combined and complement existing learning methods\nhighlighting its modularity, (iii) are fairly insensitive to different\nintrinsic scaling parameters, and (iv) maintain robustness against increased\nlevels of uncertainty and horizons.",
          "link": "http://arxiv.org/abs/2309.16347",
          "publishedOn": "2023-09-30T00:41:30.232Z",
          "wordCount": null,
          "title": "Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks. (arXiv:2309.16347v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hegde_S/0/1/0/all/0/1\">Shashank Hegde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhehui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1\">Gaurav S. Sukhatme</a>",
          "description": "Models with fewer parameters are necessary for the neural control of\nmemory-limited, performant robots. Finding these smaller neural network\narchitectures can be time-consuming. We propose HyperPPO, an on-policy\nreinforcement learning algorithm that utilizes graph hypernetworks to estimate\nthe weights of multiple neural architectures simultaneously. Our method\nestimates weights for networks that are much smaller than those in common-use\nnetworks yet encode highly performant policies. We obtain multiple trained\npolicies at the same time while maintaining sample efficiency and provide the\nuser the choice of picking a network architecture that satisfies their\ncomputational constraints. We show that our method scales well - more training\nresources produce faster convergence to higher-performing architectures. We\ndemonstrate that the neural policies estimated by HyperPPO are capable of\ndecentralized control of a Crazyflie2.1 quadrotor. Website:\nhttps://sites.google.com/usc.edu/hyperppo",
          "link": "http://arxiv.org/abs/2309.16663",
          "publishedOn": "2023-09-30T00:41:30.232Z",
          "wordCount": null,
          "title": "HyperPPO: A scalable method for finding small policies for robotic control. (arXiv:2309.16663v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaoqin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poursoroush_A/0/1/0/all/0/1\">Asma Poursoroush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boland_M/0/1/0/all/0/1\">Michael V. Boland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_C/0/1/0/all/0/1\">Chris Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yousefi_S/0/1/0/all/0/1\">Siamak Yousefi</a>",
          "description": "Purpose: To identify ocular hypertension (OHT) subtypes with different trends\nof visual field (VF) progression based on unsupervised machine learning and to\ndiscover factors associated with fast VF progression. Participants: A total of\n3133 eyes of 1568 ocular hypertension treatment study (OHTS) participants with\nat least five follow-up VF tests were included in the study. Methods: We used a\nlatent class mixed model (LCMM) to identify OHT subtypes using standard\nautomated perimetry (SAP) mean deviation (MD) trajectories. We characterized\nthe subtypes based on demographic, clinical, ocular, and VF factors at the\nbaseline. We then identified factors driving fast VF progression using\ngeneralized estimating equation (GEE) and justified findings qualitatively and\nquantitatively. Results: The LCMM model discovered four clusters (subtypes) of\neyes with different trajectories of MD worsening. The number of eyes in\nclusters were 794 (25%), 1675 (54%), 531 (17%) and 133 (4%). We labelled the\nclusters as Improvers, Stables, Slow progressors, and Fast progressors based on\ntheir mean of MD decline, which were 0.08, -0.06, -0.21, and -0.45 dB/year,\nrespectively. Eyes with fast VF progression had higher baseline age,\nintraocular pressure (IOP), pattern standard deviation (PSD) and refractive\nerror (RE), but lower central corneal thickness (CCT). Fast progression was\nassociated with calcium channel blockers, being male, heart disease history,\ndiabetes history, African American race, stroke history, and migraine\nheadaches.",
          "link": "http://arxiv.org/abs/2309.15867",
          "publishedOn": "2023-09-30T00:41:30.231Z",
          "wordCount": null,
          "title": "Identifying factors associated with fast visual field progression in patients with ocular hypertension based on unsupervised machine learning. (arXiv:2309.15867v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1\">S&#xe9;bastien Ragot</a>",
          "description": "This work proposes to measure the scope of a patent claim as the reciprocal\nof the self-information contained in this claim. A probability of occurrence of\nthe claim is obtained from a language model and this probability is used to\ncompute the self-information. Grounded in information theory, this approach is\nbased on the assumption that an unlikely concept is more informative than a\nusual concept, insofar as it is more surprising. In turn, the more surprising\nthe information required to defined the claim, the narrower its scope. Five\nlanguage models are considered, ranging from simplest models (each word or\ncharacter is assigned an identical probability) to intermediate models (using\naverage word or character frequencies), to a large language model (GPT2).\nInterestingly, the scope resulting from the simplest language models is\nproportional to the reciprocal of the number of words or characters involved in\nthe claim, a metric already used in previous works. Application is made to\nmultiple series of patent claims directed to distinct inventions, where each\nseries consists of claims devised to have a gradually decreasing scope. The\nperformance of the language models is assessed with respect to several ad hoc\ntests. The more sophisticated the model, the better the results. I.e., the GPT2\nprobability model outperforms models based on word and character frequencies,\nwhich themselves outdo the simplest models based on word or character counts.\nStill, the character count appears to be a more reliable indicator than the\nword count.",
          "link": "http://arxiv.org/abs/2309.10003",
          "publishedOn": "2023-09-30T00:41:30.230Z",
          "wordCount": null,
          "title": "A novel approach to measuring patent claim scope based on probabilities obtained from (large) language models. (arXiv:2309.10003v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenfeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zehao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yixin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chamberlain_R/0/1/0/all/0/1\">Roger D. Chamberlain</a>",
          "description": "With the ever-growing popularity of Graph Neural Networks (GNNs), efficient\nGNN inference is gaining tremendous attention. Field-Programming Gate Arrays\n(FPGAs) are a promising execution platform due to their fine-grained\nparallelism, low-power consumption, reconfigurability, and concurrent\nexecution. Even better, High-Level Synthesis (HLS) tools bridge the gap between\nthe non-trivial FPGA development efforts and rapid emergence of new GNN models.\nIn this paper, we propose GNNHLS, an open-source framework to comprehensively\nevaluate GNN inference acceleration on FPGAs via HLS, containing a software\nstack for data generation and baseline deployment, and FPGA implementations of\n6 well-tuned GNN HLS kernels. We evaluate GNNHLS on 4 graph datasets with\ndistinct topologies and scales. The results show that GNNHLS achieves up to\n50.8x speedup and 423x energy reduction relative to the CPU baselines. Compared\nwith the GPU baselines, GNNHLS achieves up to 5.16x speedup and 74.5x energy\nreduction.",
          "link": "http://arxiv.org/abs/2309.16022",
          "publishedOn": "2023-09-30T00:41:30.229Z",
          "wordCount": null,
          "title": "GNNHLS: Evaluating Graph Neural Network Inference via High-Level Synthesis. (arXiv:2309.16022v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16210",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Mingjin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yongkang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1\">Yongyi Lu</a>",
          "description": "Abdominal multi-organ segmentation in computed tomography (CT) is crucial for\nmany clinical applications including disease detection and treatment planning.\nDeep learning methods have shown unprecedented performance in this perspective.\nHowever, it is still quite challenging to accurately segment different organs\nutilizing a single network due to the vague boundaries of organs, the complex\nbackground, and the substantially different organ size scales. In this work we\nused make transformer-based model for training. It was found through previous\nyears' competitions that basically all of the top 5 methods used CNN-based\nmethods, which is likely due to the lack of data volume that prevents\ntransformer-based methods from taking full advantage. The thousands of samples\nin this competition may enable the transformer-based model to have more\nexcellent results. The results on the public validation set also show that the\ntransformer-based model can achieve an acceptable result and inference time.",
          "link": "http://arxiv.org/abs/2309.16210",
          "publishedOn": "2023-09-30T00:41:30.229Z",
          "wordCount": null,
          "title": "Abdominal multi-organ segmentation in CT using Swinunter. (arXiv:2309.16210v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junjie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jiahao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yingheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1\">Volodymyr Kuleshov</a>",
          "description": "We propose a memory-efficient finetuning algorithm for large language models\n(LLMs) that supports finetuning LLMs with 65B parameters in 3-bit or 4-bit\nprecision on as little as one 48GB GPU. Our method, modular low-rank adaptation\n(ModuLoRA), integrates any user-specified weight quantizer with finetuning via\nlow-rank adapters (LoRAs). Our approach relies on a simple\nquantization-agnostic backward pass that adaptively materializes low-precision\nLLM weights from a custom black-box quantization module. This approach enables\nfinetuning 3-bit LLMs for the first time--leveraging state-of-the-art 3-bit\nOPTQ quantization often outperforms finetuning that relies on less\nsophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains\ncompetitive performance on text classification, natural language infernece, and\ninstruction following tasks using significantly less memory than existing\napproaches, and we also surpass the state-of-the-art ROUGE score on a popular\nsummarization task. We release ModuLoRA together with a series of low-precision\nmodels--including the first family of 3-bit instruction following Alpaca\nLLMs--as part of LLMTOOLS, a user-friendly library for quantizing, running, and\nfinetuning LLMs on consumer GPUs.",
          "link": "http://arxiv.org/abs/2309.16119",
          "publishedOn": "2023-09-30T00:41:30.228Z",
          "wordCount": null,
          "title": "ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers. (arXiv:2309.16119v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wenxuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chendi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_X/0/1/0/all/0/1\">Xueli An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xueqiang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carle_G/0/1/0/all/0/1\">Georg Carle</a>",
          "description": "Integrating native AI support into the network architecture is an essential\nobjective of 6G. Federated Learning (FL) emerges as a potential paradigm,\nfacilitating decentralized AI model training across a diverse range of devices\nunder the coordination of a central server. However, several challenges hinder\nits wide application in the 6G context, such as malicious attacks and privacy\nsnooping on local model updates, and centralization pitfalls. This work\nproposes a trusted architecture for supporting FL, which utilizes Distributed\nLedger Technology (DLT) and Graph Neural Network (GNN), including three key\nfeatures. First, a pre-processing layer employing homomorphic encryption is\nincorporated to securely aggregate local models, preserving the privacy of\nindividual models. Second, given the distributed nature and graph structure\nbetween clients and nodes in the pre-processing layer, GNN is leveraged to\nidentify abnormal local models, enhancing system security. Third, DLT is\nutilized to decentralize the system by selecting one of the candidates to\nperform the central server's functions. Additionally, DLT ensures reliable data\nmanagement by recording data exchanges in an immutable and transparent ledger.\nThe feasibility of the novel architecture is validated through simulations,\ndemonstrating improved performance in anomalous model detection and global\nmodel accuracy compared to relevant baselines.",
          "link": "http://arxiv.org/abs/2309.05525",
          "publishedOn": "2023-09-30T00:41:30.227Z",
          "wordCount": null,
          "title": "Advancing Federated Learning in 6G: A Trusted Architecture with Graph-based Analysis. (arXiv:2309.05525v3 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kevin Han Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orbanz_P/0/1/0/all/0/1\">Peter Orbanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austern_M/0/1/0/all/0/1\">Morgane Austern</a>",
          "description": "We provide results that exactly quantify how data augmentation affects the\nvariance and limiting distribution of estimates, and analyze several specific\nmodels in detail. The results confirm some observations made in machine\nlearning practice, but also lead to unexpected findings: Data augmentation may\nincrease rather than decrease the uncertainty of estimates, such as the\nempirical prediction risk. It can act as a regularizer, but fails to do so in\ncertain high-dimensional problems, and it may shift the double-descent peak of\nan empirical risk. Overall, the analysis shows that several properties data\naugmentation has been attributed with are not either true or false, but rather\ndepend on a combination of factors -- notably the data distribution, the\nproperties of the estimator, and the interplay of sample size, number of\naugmentations, and dimension. Our main theoretical tool is a limit theorem for\nfunctions of randomly transformed, high-dimensional random vectors. The proof\ndraws on work in probability on noise stability of functions of many variables.",
          "link": "http://arxiv.org/abs/2202.09134",
          "publishedOn": "2023-09-30T00:41:30.224Z",
          "wordCount": null,
          "title": "Data Augmentation in the Underparameterized and Overparameterized Regimes. (arXiv:2202.09134v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pascual_G/0/1/0/all/0/1\">Guillem Pascual</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemic_F/0/1/0/all/0/1\">Filip Lemic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delgado_C/0/1/0/all/0/1\">Carmen Delgado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_Perez_X/0/1/0/all/0/1\">Xavier Costa-Perez</a>",
          "description": "Advancements in nanotechnology and material science are paving the way toward\nnanoscale devices that combine sensing, computing, data and energy storage, and\nwireless communication. In precision medicine, these nanodevices show promise\nfor disease diagnostics, treatment, and monitoring from within the patients'\nbloodstreams. Assigning the location of a sensed biological event with the\nevent itself, which is the main proposition of flow-guided in-body nanoscale\nlocalization, would be immensely beneficial from the perspective of precision\nmedicine. The nanoscale nature of the nanodevices and the challenging\nenvironment that the bloodstream represents, result in current flow-guided\nlocalization approaches being constrained in their communication and\nenergy-related capabilities. The communication and energy constraints of the\nnanodevices result in different features of raw data for flow-guided\nlocalization, in turn affecting its performance. An analytical modeling of the\neffects of imperfect communication and constrained energy causing intermittent\noperation of the nanodevices on the raw data produced by the nanodevices would\nbe beneficial. Hence, we propose an analytical model of raw data for\nflow-guided localization, where the raw data is modeled as a function of\ncommunication and energy-related capabilities of the nanodevice. We evaluate\nthe model by comparing its output with the one obtained through the utilization\nof a simulator for objective evaluation of flow-guided localization, featuring\ncomparably higher level of realism. Our results across a number of scenarios\nand heterogeneous performance metrics indicate high similarity between the\nmodel and simulator-generated raw datasets.",
          "link": "http://arxiv.org/abs/2309.16034",
          "publishedOn": "2023-09-30T00:41:30.221Z",
          "wordCount": null,
          "title": "Analytical Modelling of Raw Data for Flow-Guided In-body Nanoscale Localization. (arXiv:2309.16034v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Mingqi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zequn Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shihao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>",
          "description": "We present RLLTE: a long-term evolution, extremely modular, and open-source\nframework for reinforcement learning (RL) research and application. Beyond\ndelivering top-notch algorithm implementations, RLLTE also serves as a toolkit\nfor developing algorithms. More specifically, RLLTE decouples the RL algorithms\ncompletely from the exploitation-exploration perspective, providing a large\nnumber of components to accelerate algorithm development and evolution. In\nparticular, RLLTE is the first RL framework to build a complete and luxuriant\necosystem, which includes model training, evaluation, deployment, benchmark\nhub, and large language model (LLM)-empowered copilot. RLLTE is expected to set\nstandards for RL engineering practice and be highly stimulative for industry\nand academia.",
          "link": "http://arxiv.org/abs/2309.16382",
          "publishedOn": "2023-09-30T00:41:30.220Z",
          "wordCount": null,
          "title": "RLLTE: Long-Term Evolution Project of Reinforcement Learning. (arXiv:2309.16382v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08079",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1\">Likun Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_X/0/1/0/all/0/1\">Xiaoyu Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wikle_C/0/1/0/all/0/1\">Christopher K. Wikle</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huser_R/0/1/0/all/0/1\">Rapha&#xeb;l Huser</a>",
          "description": "Many real-world processes have complex tail dependence structures that cannot\nbe characterized using classical Gaussian processes. More flexible spatial\nextremes models exhibit appealing extremal dependence properties but are often\nexceedingly prohibitive to fit and simulate from in high dimensions. In this\npaper, we develop a new spatial extremes model that has flexible and\nnon-stationary dependence properties, and we integrate it in the\nencoding-decoding structure of a variational autoencoder (XVAE), whose\nparameters are estimated via variational Bayes combined with deep learning. The\nXVAE can be used as a spatio-temporal emulator that characterizes the\ndistribution of potential mechanistic model output states and produces outputs\nthat have the same statistical properties as the inputs, especially in the\ntail. As an aside, our approach also provides a novel way of making fast\ninference with complex extreme-value processes. Through extensive simulation\nstudies, we show that our XVAE is substantially more time-efficient than\ntraditional Bayesian inference while also outperforming many spatial extremes\nmodels with a stationary dependence structure. To further demonstrate the\ncomputational power of the XVAE, we analyze a high-resolution satellite-derived\ndataset of sea surface temperature in the Red Sea, which includes 30 years of\ndaily measurements at 16703 grid cells. We find that the extremal dependence\nstrength is weaker in the interior of Red Sea and it has decreased slightly\nover time.",
          "link": "http://arxiv.org/abs/2307.08079",
          "publishedOn": "2023-09-30T00:41:30.216Z",
          "wordCount": null,
          "title": "Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tushar/0/1/0/all/0/1\">Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Souvik Chakraborty</a>",
          "description": "The well-known governing physics in science and engineering is often based on\ncertain assumptions and approximations. Therefore, analyses and designs carried\nout based on these equations are also approximate. The emergence of data-driven\nmodels has, to a certain degree, addressed this challenge; however, the purely\ndata-driven models often (a) lack interpretability, (b) are data-hungry, and\n(c) do not generalize beyond the training window. Operator learning has\nrecently been proposed as a potential alternative to address the aforementioned\nchallenges; however, the challenges are still persistent. We here argue that\none of the possible solutions resides in data-physics fusion, where the\ndata-driven model is used to correct/identify the missing physics. To that end,\nwe propose a novel Differentiable Physics Augmented Wavelet Neural Operator\n(DPA-WNO). The proposed DPA-WNO blends a differentiable physics solver with the\nWavelet Neural Operator (WNO), where the role of WNO is to model the missing\nphysics. This empowers the proposed framework to exploit the capability of WNO\nto learn from data while retaining the interpretability and generalizability\nassociated with physics-based solvers. We illustrate the applicability of the\nproposed approach in solving time-dependent uncertainty quantification problems\ndue to randomness in the initial condition. Four benchmark uncertainty\nquantification and reliability analysis examples from various fields of science\nand engineering are solved using the proposed approach. The results presented\nillustrate interesting features of the proposed approach.",
          "link": "http://arxiv.org/abs/2309.15128",
          "publishedOn": "2023-09-30T00:41:30.215Z",
          "wordCount": null,
          "title": "DPA-WNO: A gray box model for a class of stochastic mechanics problem. (arXiv:2309.15128v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.16735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gyorfi_L/0/1/0/all/0/1\">L&#xe1;szl&#xf3; Gy&#xf6;rfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linder_T/0/1/0/all/0/1\">Tam&#xe1;s Linder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walk_H/0/1/0/all/0/1\">Harro Walk</a>",
          "description": "We study the excess minimum risk in statistical inference, defined as the\ndifference between the minimum expected loss in estimating a random variable\nfrom an observed feature vector and the minimum expected loss in estimating the\nsame random variable from a transformation (statistic) of the feature vector.\nAfter characterizing lossless transformations, i.e., transformations for which\nthe excess risk is zero for all loss functions, we construct a partitioning\ntest statistic for the hypothesis that a given transformation is lossless and\nshow that for i.i.d. data the test is strongly consistent. More generally, we\ndevelop information-theoretic upper bounds on the excess risk that uniformly\nhold over fairly general classes of loss functions. Based on these bounds, we\nintroduce the notion of a delta-lossless transformation and give sufficient\nconditions for a given transformation to be universally delta-lossless.\nApplications to classification, nonparametric regression, portfolio strategies,\ninformation bottleneck, and deep learning, are also surveyed.",
          "link": "http://arxiv.org/abs/2307.16735",
          "publishedOn": "2023-09-30T00:41:30.214Z",
          "wordCount": null,
          "title": "Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15123",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chen_D/0/1/0/all/0/1\">Dingshuo Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Du_Y/0/1/0/all/0/1\">Yuanqi Du</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_Z/0/1/0/all/0/1\">Zhixun Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Molecular Representation Learning (MRL) has emerged as a powerful tool for\ndrug and materials discovery in a variety of tasks such as virtual screening\nand inverse design. While there has been a surge of interest in advancing\nmodel-centric techniques, the influence of both data quantity and quality on\nmolecular representations is not yet clearly understood within this field. In\nthis paper, we delve into the neural scaling behaviors of MRL from a\ndata-centric viewpoint, examining four key dimensions: (1) data modalities, (2)\ndataset splitting, (3) the role of pre-training, and (4) model capacity. Our\nempirical studies confirm a consistent power-law relationship between data\nvolume and MRL performance across these dimensions. Additionally, through\ndetailed analysis, we identify potential avenues for improving learning\nefficiency. To challenge these scaling laws, we adapt seven popular data\npruning strategies to molecular data and benchmark their performance. Our\nfindings underline the importance of data-centric MRL and highlight possible\ndirections for future research.",
          "link": "http://arxiv.org/abs/2309.15123",
          "publishedOn": "2023-09-30T00:41:30.211Z",
          "wordCount": null,
          "title": "Uncovering Neural Scaling Laws in Molecular Representation Learning. (arXiv:2309.15123v2 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_A/0/1/0/all/0/1\">Andr&#xe9; Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leznik_M/0/1/0/all/0/1\">Mark Leznik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stenger_M/0/1/0/all/0/1\">Michael Stenger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leppich_R/0/1/0/all/0/1\">Robert Leppich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herbst_N/0/1/0/all/0/1\">Nikolas Herbst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kounev_S/0/1/0/all/0/1\">Samuel Kounev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>",
          "description": "In many areas of decision-making, forecasting is an essential pillar.\nConsequently, many different forecasting methods have been proposed. From our\nexperience, recently presented forecasting methods are computationally\nintensive, poorly automated, tailored to a particular data set, or they lack a\npredictable time-to-result. To this end, we introduce Telescope, a novel\nmachine learning-based forecasting approach that automatically retrieves\nrelevant information from a given time series and splits it into parts,\nhandling each of them separately. In contrast to deep learning methods, our\napproach doesn't require parameterization or the need to train and fit a\nmultitude of parameters. It operates with just one time series and provides\nforecasts within seconds without any additional setup. Our experiments show\nthat Telescope outperforms recent methods by providing accurate and reliable\nforecasts while making no assumptions about the analyzed time series.",
          "link": "http://arxiv.org/abs/2309.15871",
          "publishedOn": "2023-09-30T00:41:30.210Z",
          "wordCount": null,
          "title": "Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing Field. (arXiv:2309.15871v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.10425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hangchen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zheng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1\">Renhe Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiewen Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jinliang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Quanjun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xuan Song</a>",
          "description": "With the rapid development of the Intelligent Transportation System (ITS),\naccurate traffic forecasting has emerged as a critical challenge. The key\nbottleneck lies in capturing the intricate spatio-temporal traffic patterns. In\nrecent years, numerous neural networks with complicated architectures have been\nproposed to address this issue. However, the advancements in network\narchitectures have encountered diminishing performance gains. In this study, we\npresent a novel component called spatio-temporal adaptive embedding that can\nyield outstanding results with vanilla transformers. Our proposed\nSpatio-Temporal Adaptive Embedding transformer (STAEformer) achieves\nstate-of-the-art performance on five real-world traffic forecasting datasets.\nFurther experiments demonstrate that spatio-temporal adaptive embedding plays a\ncrucial role in traffic forecasting by effectively capturing intrinsic\nspatio-temporal relations and chronological information in traffic time series.",
          "link": "http://arxiv.org/abs/2308.10425",
          "publishedOn": "2023-09-30T00:41:30.204Z",
          "wordCount": null,
          "title": "STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting. (arXiv:2308.10425v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zijun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1\">Qiujian Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jinyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1\">Degang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasquier_T/0/1/0/all/0/1\">Thomas Pasquier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xueyuan Han</a>",
          "description": "Provenance graphs are structured audit logs that describe the history of a\nsystem's execution. Recent studies have explored a variety of techniques to\nanalyze provenance graphs for automated host intrusion detection, focusing\nparticularly on advanced persistent threats. Sifting through their design\ndocuments, we identify four common dimensions that drive the development of\nprovenance-based intrusion detection systems (PIDSes): scope (can PIDSes detect\nmodern attacks that infiltrate across application boundaries?), attack\nagnosticity (can PIDSes detect novel attacks without a priori knowledge of\nattack characteristics?), timeliness (can PIDSes efficiently monitor host\nsystems as they run?), and attack reconstruction (can PIDSes distill attack\nactivity from large provenance graphs so that sysadmins can easily understand\nand quickly respond to system intrusion?). We present KAIROS, the first PIDS\nthat simultaneously satisfies the desiderata in all four dimensions, whereas\nexisting approaches sacrifice at least one and struggle to achieve comparable\ndetection performance.\n\nKairos leverages a novel graph neural network-based encoder-decoder\narchitecture that learns the temporal evolution of a provenance graph's\nstructural changes to quantify the degree of anomalousness for each system\nevent. Then, based on this fine-grained information, Kairos reconstructs attack\nfootprints, generating compact summary graphs that accurately describe\nmalicious activity over a stream of system audit logs. Using state-of-the-art\nbenchmark datasets, we demonstrate that Kairos outperforms previous approaches.",
          "link": "http://arxiv.org/abs/2308.05034",
          "publishedOn": "2023-09-30T00:41:30.203Z",
          "wordCount": null,
          "title": "Kairos: Practical Intrusion Detection and Investigation using Whole-system Provenance. (arXiv:2308.05034v3 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michelson_J/0/1/0/all/0/1\">James Michelson</a>",
          "description": "Fair machine learning research has been primarily concerned with\nclassification tasks that result in discrimination. However, as machine\nlearning algorithms are applied in new contexts the harms and injustices that\nresult are qualitatively different than those presently studied. The existing\nresearch paradigm in machine learning which develops metrics and definitions of\nfairness cannot account for these qualitatively different types of injustice.\nOne example of this is the problem of algorithmic collusion and market\nfairness. The negative consequences of algorithmic collusion affect all\nconsumers, not only particular members of a protected class. Drawing on this\ncase study, I propose an ethical framework for researchers and practitioners in\nmachine learning seeking to develop and apply fairness metrics that extends to\nnew domains. This contribution ties the development of formal metrics of\nfairness to specifically scoped normative principles. This enables fairness\nmetrics to reflect different concerns from discrimination. I conclude with the\nlimitations of my proposal and discuss promising avenues for future research.",
          "link": "http://arxiv.org/abs/2208.06308",
          "publishedOn": "2023-09-30T00:41:30.199Z",
          "wordCount": null,
          "title": "Developing a Philosophical Framework for Fair Machine Learning: Lessons From The Case of Algorithmic Collusion. (arXiv:2208.06308v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11475",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Truong_T/0/1/0/all/0/1\">Tuyen Trung Truong</a>",
          "description": "In root finding and optimization, there are many cases where there is a\nclosed set $A$ one likes that the sequence constructed by one's favourite\nmethod will not converge to A (here, we do not assume extra properties on $A$\nsuch as being convex or connected). For example, if one wants to find roots,\nand one chooses initial points in the basin of attraction for 1 root $x^*$ (a\nfact which one may not know before hand), then one will always end up in that\nroot. In this case, one would like to have a mechanism to avoid this point\n$z^*$ in the next runs of one's algorithm.\n\nIn this paper, we propose two new methods aiming to achieve this. In the\nfirst method, we divide the cost function by an appropriate power of the\ndistance function to $A$. This idea is inspired by how one would try to find\nall roots of a function in 1 variable. In the second method, which is more\nsuitable for constrained optimization, we redefine the value of the function to\nbe a big constant on $A$. We also propose, based on this, an algorithm to\nescape the basin of attraction of a component of positive dimension to reach\nanother component. As an application, we prove a rigorous guarantee for finding\nroots of a meromorphic function of 1 complex variable in a given domain.\n\nAlong the way, we compare with main existing relevant methods in the current\nliterature. We provide several examples in various different settings to\nillustrate the usefulness of the new approach.",
          "link": "http://arxiv.org/abs/2309.11475",
          "publishedOn": "2023-09-30T00:41:30.198Z",
          "wordCount": null,
          "title": "Creating walls to avoid unwanted points in root finding and optimization. (arXiv:2309.11475v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.13752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yao Liang</a>",
          "description": "The current learning process of deep learning, regardless of any deep neural\nnetwork (DNN) architecture and/or learning algorithm used, is essentially a\nsingle resolution training. We explore multiresolution learning and show that\nmultiresolution learning can significantly improve robustness of DNN models for\nboth 1D signal and 2D signal (image) prediction problems. We demonstrate this\nimprovement in terms of both noise and adversarial robustness as well as with\nsmall training dataset size. Our results also suggest that it may not be\nnecessary to trade standard accuracy for robustness with multiresolution\nlearning, which is, interestingly, contrary to the observation obtained from\nthe traditional single resolution learning setting.",
          "link": "http://arxiv.org/abs/2309.13752",
          "publishedOn": "2023-09-30T00:41:30.196Z",
          "wordCount": null,
          "title": "Improving Robustness of Deep Convolutional Neural Networks via Multiresolution Learning. (arXiv:2309.13752v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenxuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bowen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1\">Chris Paxton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1\">David Held</a>",
          "description": "Manipulating objects without grasping them is an essential component of human\ndexterity, referred to as non-prehensile manipulation. Non-prehensile\nmanipulation may enable more complex interactions with the objects, but also\npresents challenges in reasoning about gripper-object interactions. In this\nwork, we introduce Hybrid Actor-Critic Maps for Manipulation (HACMan), a\nreinforcement learning approach for 6D non-prehensile manipulation of objects\nusing point cloud observations. HACMan proposes a temporally-abstracted and\nspatially-grounded object-centric action representation that consists of\nselecting a contact location from the object point cloud and a set of motion\nparameters describing how the robot will move after making contact. We modify\nan existing off-policy RL algorithm to learn in this hybrid discrete-continuous\naction representation. We evaluate HACMan on a 6D object pose alignment task in\nboth simulation and in the real world. On the hardest version of our task, with\nrandomized initial poses, randomized 6D goals, and diverse object categories,\nour policy demonstrates strong generalization to unseen object categories\nwithout a performance drop, achieving an 89% success rate on unseen objects in\nsimulation and 50% success rate with zero-shot transfer in the real world.\nCompared to alternative action representations, HACMan achieves a success rate\nmore than three times higher than the best baseline. With zero-shot sim2real\ntransfer, our policy can successfully manipulate unseen objects in the real\nworld for challenging non-planar goals, using dynamic and contact-rich\nnon-prehensile skills. Videos can be found on the project website:\nhttps://hacman-2023.github.io.",
          "link": "http://arxiv.org/abs/2305.03942",
          "publishedOn": "2023-09-30T00:41:30.195Z",
          "wordCount": null,
          "title": "HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation. (arXiv:2305.03942v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.13978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rizvee_R/0/1/0/all/0/1\">Redwan Ahmed Rizvee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Md. Mosaddek Khan</a>",
          "description": "Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to\nmodel various NP-hard combinatorial optimization problems in the form of binary\nvariables. The Hamiltonian function is often used to formulate QUBO problems\nwhere it is used as the objective function in the context of optimization.\nRecently, PI-GNN, a generic scalable framework, has been proposed to address\nthe Combinatorial Optimization (CO) problems over graphs based on a simple\nGraph Neural Network (GNN) architecture. Their novel contribution was a generic\nQUBO-formulated Hamiltonian-inspired loss function that was optimized using\nGNN. In this study, we address a crucial issue related to the aforementioned\nsetup especially observed in denser graphs. The reinforcement learning-based\nparadigm has also been widely used to address numerous CO problems. Here we\nalso formulate and empirically evaluate the compatibility of the\nQUBO-formulated Hamiltonian as the generic reward function in the Reinforcement\nLearning paradigm to directly integrate the actual node projection status\nduring training as the form of rewards. In our experiments, we observed up to\n44% improvement in the RL-based setup compared to the PI-GNN algorithm. Our\nimplementation can be found in\nhttps://github.com/rizveeredwan/learning-graph-structure.",
          "link": "http://arxiv.org/abs/2308.13978",
          "publishedOn": "2023-09-30T00:41:30.194Z",
          "wordCount": null,
          "title": "A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss Function for Combinatorial Optimization using Reinforcement Learning. (arXiv:2308.13978v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shenyang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poursafaei_F/0/1/0/all/0/1\">Farimah Poursafaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danovitch_J/0/1/0/all/0/1\">Jacob Danovitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1\">Matthias Fey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weihua Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_E/0/1/0/all/0/1\">Emanuele Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1\">Guillaume Rabusseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbany_R/0/1/0/all/0/1\">Reihaneh Rabbany</a>",
          "description": "We present the Temporal Graph Benchmark (TGB), a collection of challenging\nand diverse benchmark datasets for realistic, reproducible, and robust\nevaluation of machine learning models on temporal graphs. TGB datasets are of\nlarge scale, spanning years in duration, incorporate both node and edge-level\nprediction tasks and cover a diverse set of domains including social, trade,\ntransaction, and transportation networks. For both tasks, we design evaluation\nprotocols based on realistic use-cases. We extensively benchmark each dataset\nand find that the performance of common models can vary drastically across\ndatasets. In addition, on dynamic node property prediction tasks, we show that\nsimple methods often achieve superior performance compared to existing temporal\ngraph models. We believe that these findings open up opportunities for future\nresearch on temporal graphs. Finally, TGB provides an automated machine\nlearning pipeline for reproducible and accessible temporal graph research,\nincluding data loading, experiment setup and performance evaluation. TGB will\nbe maintained and updated on a regular basis and welcomes community feedback.\nTGB datasets, data loaders, example codes, evaluation setup, and leaderboards\nare publicly available at https://tgb.complexdatalab.com/.",
          "link": "http://arxiv.org/abs/2307.01026",
          "publishedOn": "2023-09-30T00:41:30.193Z",
          "wordCount": null,
          "title": "Temporal Graph Benchmark for Machine Learning on Temporal Graphs. (arXiv:2307.01026v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.04934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jinghan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiancheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gaowen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Pranay Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "In response to recent data regulation requirements, machine unlearning (MU)\nhas emerged as a critical process to remove the influence of specific examples\nfrom a given model. Although exact unlearning can be achieved through complete\nmodel retraining using the remaining dataset, the associated computational\ncosts have driven the development of efficient, approximate unlearning\ntechniques. Moving beyond data-centric MU approaches, our study introduces a\nnovel model-based perspective: model sparsification via weight pruning, which\nis capable of reducing the gap between exact unlearning and approximate\nunlearning. We show in both theory and practice that model sparsity can boost\nthe multi-criteria unlearning performance of an approximate unlearner, closing\nthe approximation gap, while continuing to be efficient. This leads to a new MU\nparadigm, termed prune first, then unlearn, which infuses a sparse model prior\ninto the unlearning process. Building on this insight, we also develop a\nsparsity-aware unlearning method that utilizes sparsity regularization to\nenhance the training process of approximate unlearning. Extensive experiments\nshow that our proposals consistently benefit MU in various unlearning\nscenarios. A notable highlight is the 77% unlearning efficacy gain of\nfine-tuning (one of the simplest unlearning methods) when using sparsity-aware\nunlearning. Furthermore, we demonstrate the practical impact of our proposed MU\nmethods in addressing other machine learning challenges, such as defending\nagainst backdoor attacks and enhancing transfer learning. Codes are available\nat https://github.com/OPTML-Group/Unlearn-Sparse.",
          "link": "http://arxiv.org/abs/2304.04934",
          "publishedOn": "2023-09-30T00:41:30.192Z",
          "wordCount": null,
          "title": "Model Sparsity Can Simplify Machine Unlearning. (arXiv:2304.04934v8 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.18471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huishuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhi-Ming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "We provide a simple convergence proof for AdaGrad optimizing non-convex\nobjectives under only affine noise variance and bounded smoothness assumptions.\nThe proof is essentially based on a novel auxiliary function $\\xi$ that helps\neliminate the complexity of handling the correlation between the numerator and\ndenominator of AdaGrad's update. Leveraging simple proofs, we are able to\nobtain tighter results than existing results \\citep{faw2022power} and extend\nthe analysis to several new and important cases. Specifically, for the\nover-parameterized regime, we show that AdaGrad needs only\n$\\mathcal{O}(\\frac{1}{\\varepsilon^2})$ iterations to ensure the gradient norm\nsmaller than $\\varepsilon$, which matches the rate of SGD and significantly\ntighter than existing rates $\\mathcal{O}(\\frac{1}{\\varepsilon^4})$ for AdaGrad.\nWe then discard the bounded smoothness assumption and consider a realistic\nassumption on smoothness called $(L_0,L_1)$-smooth condition, which allows\nlocal smoothness to grow with the gradient norm. Again based on the auxiliary\nfunction $\\xi$, we prove that AdaGrad succeeds in converging under\n$(L_0,L_1)$-smooth condition as long as the learning rate is lower than a\nthreshold. Interestingly, we further show that the requirement on learning rate\nunder the $(L_0,L_1)$-smooth condition is necessary via proof by contradiction,\nin contrast with the case of uniform smoothness conditions where convergence is\nguaranteed regardless of learning rate choices. Together, our analyses broaden\nthe understanding of AdaGrad and demonstrate the power of the new auxiliary\nfunction in the investigations of AdaGrad.",
          "link": "http://arxiv.org/abs/2305.18471",
          "publishedOn": "2023-09-30T00:41:30.175Z",
          "wordCount": null,
          "title": "Convergence of AdaGrad for Non-convex Objectives: Simple Proofs and Relaxed Assumptions. (arXiv:2305.18471v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lingle_L/0/1/0/all/0/1\">Lucas D. Lingle</a>",
          "description": "We introduce Transformer-VQ, a decoder-only transformer computing\nsoftmax-based dense self-attention in linear time. Transformer-VQ's efficient\nattention is enabled by vector-quantized keys and a novel caching mechanism. In\nlarge-scale experiments, Transformer-VQ is shown highly competitive in quality,\nwith strong results on Enwik8 (0.99 bpb), PG-19 (26.6 ppl), and ImageNet64\n(3.16 bpb). Code: https://github.com/transformer-vq/transformer_vq",
          "link": "http://arxiv.org/abs/2309.16354",
          "publishedOn": "2023-09-30T00:41:30.173Z",
          "wordCount": null,
          "title": "Transformer-VQ: Linear-Time Transformers via Vector Quantization. (arXiv:2309.16354v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1\">Andrew Lowy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1\">Meisam Razaviyayn</a>",
          "description": "We study differentially private (DP) stochastic optimization (SO) with loss\nfunctions whose worst-case Lipschitz parameter over all data points may be\nextremely large. To date, the vast majority of work on DP SO assumes that the\nloss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are\nuniformly bounded over all data points). While this assumption is convenient,\nit often leads to pessimistic excess risk bounds. In many practical problems,\nthe worst-case (uniform) Lipschitz parameter of the loss over all data points\nmay be extremely large due to outliers. In such cases, the error bounds for DP\nSO, which scale with the worst-case Lipschitz parameter of the loss, are\nvacuous. To address these limitations, this work provides near-optimal excess\nrisk bounds that do not depend on the uniform Lipschitz parameter of the loss.\nBuilding on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we\nassume that stochastic gradients have bounded $k$-th order moments for some $k\n\\geq 2$. Compared with works on uniformly Lipschitz DP SO, our excess risk\nscales with the $k$-th moment bound instead of the uniform Lipschitz parameter\nof the loss, allowing for significantly faster rates in the presence of\noutliers and/or heavy-tailed data. For convex and strongly convex loss\nfunctions, we provide the first asymptotically optimal excess risk bounds (up\nto a logarithmic factor). In contrast to (Wang et al., 2020; Kamath et al.,\n2022), our bounds do not require the loss function to be differentiable/smooth.\nWe also devise a linear-time algorithm for smooth losses that has excess risk\nthat is tight in certain practical parameter regimes. Additionally, our work is\nthe first to address non-convex non-uniformly Lipschitz loss functions\nsatisfying the Proximal-PL inequality; this covers some practical machine\nlearning models. Our Proximal-PL algorithm has near-optimal excess risk.",
          "link": "http://arxiv.org/abs/2209.07403",
          "publishedOn": "2023-09-30T00:41:30.171Z",
          "wordCount": null,
          "title": "Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wei Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weijia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min-Ling Zhang</a>",
          "description": "In many real-world tasks, the concerned objects can be represented as a\nmulti-instance bag associated with a candidate label set, which consists of one\nground-truth label and several false positive labels. Multi-instance\npartial-label learning (MIPL) is a learning paradigm to deal with such tasks\nand has achieved favorable performances. Existing MIPL approach follows the\ninstance-space paradigm by assigning augmented candidate label sets of bags to\neach instance and aggregating bag-level labels from instance-level labels.\nHowever, this scheme may be suboptimal as global bag-level information is\nignored and the predicted labels of bags are sensitive to predictions of\nnegative instances. In this paper, we study an alternative scheme where a\nmulti-instance bag is embedded into a single vector representation.\nAccordingly, an intuitive algorithm named DEMIPL, i.e., Disambiguated attention\nEmbedding for Multi-Instance Partial-Label learning, is proposed. DEMIPL\nemploys a disambiguation attention mechanism to aggregate a multi-instance bag\ninto a single vector representation, followed by a momentum-based\ndisambiguation strategy to identify the ground-truth label from the candidate\nlabel set. Furthermore, we introduce a real-world MIPL dataset for colorectal\ncancer classification. Experimental results on benchmark and real-world\ndatasets validate the superiority of DEMIPL against the compared MIPL and\npartial-label learning approaches.",
          "link": "http://arxiv.org/abs/2305.16912",
          "publishedOn": "2023-09-30T00:41:30.170Z",
          "wordCount": null,
          "title": "Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning. (arXiv:2305.16912v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.09916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Rachel Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_R/0/1/0/all/0/1\">Rohan Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yixiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hindy_A/0/1/0/all/0/1\">Ali Hindy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shengjia Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmerling_E/0/1/0/all/0/1\">Edward Schmerling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1\">Marco Pavone</a>",
          "description": "When deploying modern machine learning-enabled robotic systems in high-stakes\napplications, detecting distribution shift is critical. However, most existing\nmethods for detecting distribution shift are not well-suited to robotics\nsettings, where data often arrives in a streaming fashion and may be very\nhigh-dimensional. In this work, we present an online method for detecting\ndistribution shift with guarantees on the false positive rate - i.e., when\nthere is no distribution shift, our system is very unlikely (with probability\n$< \\epsilon$) to falsely issue an alert; any alerts that are issued should\ntherefore be heeded. Our method is specifically designed for efficient\ndetection even with high dimensional data, and it empirically achieves up to\n11x faster detection on realistic robotics settings compared to prior work\nwhile maintaining a low false negative rate in practice (whenever there is a\ndistribution shift in our experiments, our method indeed emits an alert). We\ndemonstrate our approach in both simulation and hardware for a visual servoing\ntask, and show that our method indeed issues an alert before a failure occurs.",
          "link": "http://arxiv.org/abs/2211.09916",
          "publishedOn": "2023-09-30T00:41:30.169Z",
          "wordCount": null,
          "title": "Online Distribution Shift Detection via Recency Prediction. (arXiv:2211.09916v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">A. Feder Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choksi_M/0/1/0/all/0/1\">Madiha Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barocas_S/0/1/0/all/0/1\">Solon Barocas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimmelmann_J/0/1/0/all/0/1\">James Grimmelmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1\">Jon Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1\">Siddhartha Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baobao Zhang</a>",
          "description": "Variance in predictions across different trained models is a significant,\nunder-explored source of error in fair classification. In practice, the\nvariance on some data examples is so large that decisions can be effectively\narbitrary. To investigate this problem, we take an experimental approach and\nmake four overarching contributions: We 1) Define a metric called\nself-consistency, derived from variance, which we use as a proxy for measuring\nand reducing arbitrariness; 2) Develop an ensembling algorithm that abstains\nfrom classification when a prediction would be arbitrary; 3) Conduct the\nlargest to-date empirical study of the role of variance (vis-a-vis\nself-consistency and arbitrariness) in fair classification; and, 4) Release a\ntoolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily\nusable for future research. Altogether, our experiments reveal shocking\ninsights about the reliability of conclusions on benchmark datasets. Most\nfairness classification benchmarks are close-to-fair when taking into account\nthe amount of arbitrariness present in predictions -- before we even try to\napply common fairness interventions. This finding calls into question the\npractical utility of common algorithmic fairness methods, and in turn suggests\nthat we should fundamentally reconsider how we choose to measure fairness in\nmachine learning.",
          "link": "http://arxiv.org/abs/2301.11562",
          "publishedOn": "2023-09-30T00:41:30.165Z",
          "wordCount": null,
          "title": "Is My Prediction Arbitrary? Confounding Effects of Variance in Fair Classification. (arXiv:2301.11562v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jothishwaran_C/0/1/0/all/0/1\">C. A. Jothishwaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1\">Biplav Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_J/0/1/0/all/0/1\">Jitin Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangopadhyay_S/0/1/0/all/0/1\">Sugata Gangopadhyay</a>",
          "description": "The logical analysis of data, LAD, is a technique that yields two-class\nclassifiers based on Boolean functions having disjunctive normal form (DNF)\nrepresentation. Although LAD algorithms employ optimization techniques, the\nresulting binary classifiers or binary rules do not lead to overfitting. We\npropose a theoretical justification for the absence of overfitting by\nestimating the Vapnik-Chervonenkis dimension (VC dimension) for LAD models\nwhere hypothesis sets consist of DNFs with a small number of cubic monomials.\nWe illustrate and confirm our observations empirically.",
          "link": "http://arxiv.org/abs/2309.16630",
          "publishedOn": "2023-09-30T00:41:30.164Z",
          "wordCount": null,
          "title": "On Learning with LAD. (arXiv:2309.16630v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vidhyadhiraja_A/0/1/0/all/0/1\">Advika Vidhyadhiraja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiagarajan_A/0/1/0/all/0/1\">Arun Pa Thiagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1\">Venkat Viswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramsundar_B/0/1/0/all/0/1\">Bharath Ramsundar</a>",
          "description": "Learning exchange correlation functionals, used in quantum chemistry\ncalculations, from data has become increasingly important in recent years, but\ntraining such a functional requires sophisticated software infrastructure. For\nthis reason, we build open source infrastructure to train neural exchange\ncorrelation functionals. We aim to standardize the processing pipeline by\nadapting state-of-the-art techniques from work done by multiple groups. We have\nopen sourced the model in the DeepChem library to provide a platform for\nadditional research on differentiable quantum chemistry methods.",
          "link": "http://arxiv.org/abs/2309.15985",
          "publishedOn": "2023-09-30T00:41:30.163Z",
          "wordCount": null,
          "title": "Open Source Infrastructure for Differentiable Density Functional Theory. (arXiv:2309.15985v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.16296",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popordanoska_T/0/1/0/all/0/1\">Teodora Popordanoska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertels_J/0/1/0/all/0/1\">Jeroen Bertels</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemmens_R/0/1/0/all/0/1\">Robin Lemmens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1\">Matthew B. Blaschko</a>",
          "description": "The soft Dice loss (SDL) has taken a pivotal role in numerous automated\nsegmentation pipelines in the medical imaging community. Over the last years,\nsome reasons behind its superior functioning have been uncovered and further\noptimizations have been explored. However, there is currently no implementation\nthat supports its direct utilization in scenarios involving soft labels. Hence,\na synergy between the use of SDL and research leveraging the use of soft\nlabels, also in the context of model calibration, is still missing. In this\nwork, we introduce Dice semimetric losses (DMLs), which (i) are by design\nidentical to SDL in a standard setting with hard labels, but (ii) can be\nemployed in settings with soft labels. Our experiments on the public QUBIQ,\nLiTS and KiTS benchmarks confirm the potential synergy of DMLs with soft labels\n(e.g.\\ averaging, label smoothing, and knowledge distillation) over hard labels\n(e.g.\\ majority voting and random selection). As a result, we obtain superior\nDice scores and model calibration, which supports the wider adoption of DMLs in\npractice. The code is available at\n\\href{https://github.com/zifuwanggg/JDTLosses}{https://github.com/zifuwanggg/JDTLosses}.",
          "link": "http://arxiv.org/abs/2303.16296",
          "publishedOn": "2023-09-30T00:41:30.161Z",
          "wordCount": null,
          "title": "Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels. (arXiv:2303.16296v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12586",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Rupe_A/0/1/0/all/0/1\">Adam Rupe</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kashinath_K/0/1/0/all/0/1\">Karthik Kashinath</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kumar_N/0/1/0/all/0/1\">Nalini Kumar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Crutchfield_J/0/1/0/all/0/1\">James P. Crutchfield</a>",
          "description": "Spontaneous self-organization is ubiquitous in systems far from thermodynamic\nequilibrium. While organized structures that emerge dominate transport\nproperties, universal representations that identify and describe these key\nobjects remain elusive. Here, we introduce a theoretically-grounded framework\nfor describing emergent organization that, via data-driven algorithms, is\nconstructive in practice. Its building blocks are spacetime lightcones that\nembody how information propagates across a system through local interactions.\nWe show that predictive equivalence classes of lightcones -- local causal\nstates -- capture organized behaviors and coherent structures in complex\nspatiotemporal systems. Employing an unsupervised physics-informed machine\nlearning algorithm and a high-performance computing implementation, we\ndemonstrate automatically discovering coherent structures in two real world\ndomain science problems. We show that local causal states identify vortices and\ntrack their power-law decay behavior in two-dimensional fluid turbulence. We\nthen show how to detect and track familiar extreme weather events -- hurricanes\nand atmospheric rivers -- and discover other novel coherent structures\nassociated with precipitation extremes in high-resolution climate data at the\ngrid-cell level.",
          "link": "http://arxiv.org/abs/2304.12586",
          "publishedOn": "2023-09-30T00:41:30.160Z",
          "wordCount": null,
          "title": "Unsupervised Discovery of Extreme Weather Events Using Universal Representations of Emergent Organization. (arXiv:2304.12586v2 [physics.comp-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16521",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schurch_M/0/1/0/all/0/1\">Manuel Sch&#xfc;rch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allam_A/0/1/0/all/0/1\">Ahmed Allam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rathmes_G/0/1/0/all/0/1\">Giulia Rathmes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mollaysa_A/0/1/0/all/0/1\">Amina Mollaysa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cavelti_Weder_C/0/1/0/all/0/1\">Claudia Cavelti-Weder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krauthammer_M/0/1/0/all/0/1\">Michael Krauthammer</a>",
          "description": "We propose a novel framework that combines deep generative time series models\nwith decision theory for generating personalized treatment strategies. It\nleverages historical patient trajectory data to jointly learn the generation of\nrealistic personalized treatment and future outcome trajectories through deep\ngenerative time series models. In particular, our framework enables the\ngeneration of novel multivariate treatment strategies tailored to the\npersonalized patient history and trained for optimal expected future outcomes\nbased on conditional expected utility maximization. We demonstrate our\nframework by generating personalized insulin treatment strategies and blood\nglucose predictions for hospitalized diabetes patients, showcasing the\npotential of our approach for generating improved personalized treatment\nstrategies. Keywords: deep generative model, probabilistic decision support,\npersonalized treatment generation, insulin and blood glucose prediction",
          "link": "http://arxiv.org/abs/2309.16521",
          "publishedOn": "2023-09-30T00:41:30.159Z",
          "wordCount": null,
          "title": "Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models. (arXiv:2309.16521v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06807",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_X/0/1/0/all/0/1\">Xiran Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1\">Chun-Hao Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vemuri_B/0/1/0/all/0/1\">Baba C. Vemuri</a>",
          "description": "Hyperbolic spaces have been quite popular in the recent past for representing\nhierarchically organized data. Further, several classification algorithms for\ndata in these spaces have been proposed in the literature. These algorithms\nmainly use either hyperplanes or geodesics for decision boundaries in a large\nmargin classifiers setting leading to a non-convex optimization problem. In\nthis paper, we propose a novel large margin classifier based on horospherical\ndecision boundaries that leads to a geodesically convex optimization problem\nthat can be optimized using any Riemannian gradient descent technique\nguaranteeing a globally optimal solution. We present several experiments\ndepicting the competitive performance of our classifier in comparison to SOTA.",
          "link": "http://arxiv.org/abs/2302.06807",
          "publishedOn": "2023-09-30T00:41:30.156Z",
          "wordCount": null,
          "title": "Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.16808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tooba Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhukar_K/0/1/0/all/0/1\">Kumar Madhukar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Subodh Vishnu Sharma</a>",
          "description": "The generation of adversarial inputs has become a crucial issue in\nestablishing the robustness and trustworthiness of deep neural nets, especially\nwhen they are used in safety-critical application domains such as autonomous\nvehicles and precision medicine. However, the problem poses multiple practical\nchallenges, including scalability issues owing to large-sized networks, and the\ngeneration of adversarial inputs that lack important qualities such as\nnaturalness and output-impartiality. This problem shares its end goal with the\ntask of patching neural nets where small changes in some of the network's\nweights need to be discovered so that upon applying these changes, the modified\nnet produces the desirable output for a given set of inputs. We exploit this\nconnection by proposing to obtain an adversarial input from a patch, with the\nunderlying observation that the effect of changing the weights can also be\nbrought about by changing the inputs instead. Thus, this paper presents a novel\nway to generate input perturbations that are adversarial for a given network by\nusing an efficient network patching technique. We note that the proposed method\nis significantly more effective than the prior state-of-the-art techniques.",
          "link": "http://arxiv.org/abs/2211.16808",
          "publishedOn": "2023-09-30T00:41:30.155Z",
          "wordCount": null,
          "title": "Efficient Adversarial Input Generation via Neural Net Patching. (arXiv:2211.16808v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16578",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1\">Siyuan Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_J/0/1/0/all/0/1\">Jiacheng You</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_S/0/1/0/all/0/1\">Shuxin Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_Z/0/1/0/all/0/1\">Ziheng Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_N/0/1/0/all/0/1\">Nanning Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shao_B/0/1/0/all/0/1\">Bin Shao</a>",
          "description": "Orbital-free density functional theory (OFDFT) is a quantum chemistry\nformulation that has a lower cost scaling than the prevailing Kohn-Sham DFT,\nwhich is increasingly desired for contemporary molecular research. However, its\naccuracy is limited by the kinetic energy density functional, which is\nnotoriously hard to approximate for non-periodic molecular systems. In this\nwork, we propose M-OFDFT, an OFDFT approach capable of solving molecular\nsystems using a deep-learning functional model. We build the essential\nnonlocality into the model, which is made affordable by the concise density\nrepresentation as expansion coefficients under an atomic basis. With techniques\nto address unconventional learning challenges therein, M-OFDFT achieves a\ncomparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched\nby OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much\nlarger than those in training, which unleashes the appealing scaling for\nstudying large molecules including proteins, representing an advancement of the\naccuracy-efficiency trade-off frontier in quantum chemistry.",
          "link": "http://arxiv.org/abs/2309.16578",
          "publishedOn": "2023-09-30T00:41:30.148Z",
          "wordCount": null,
          "title": "M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingtong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1\">Katherine Driggs-Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunzhu Li</a>",
          "description": "Scene representation has been a crucial design choice in robotic manipulation\nsystems. An ideal representation should be 3D, dynamic, and semantic to meet\nthe demands of diverse manipulation tasks. However, previous works often lack\nall three properties simultaneously. In this work, we introduce D$^3$Fields -\ndynamic 3D descriptor fields. These fields capture the dynamics of the\nunderlying 3D environment and encode both semantic features and instance masks.\nSpecifically, we project arbitrary 3D points in the workspace onto multi-view\n2D visual observations and interpolate features derived from foundational\nmodels. The resulting fused descriptor fields allow for flexible goal\nspecifications using 2D images with varied contexts, styles, and instances. To\nevaluate the effectiveness of these descriptor fields, we apply our\nrepresentation to a wide range of robotic manipulation tasks in a zero-shot\nmanner. Through extensive evaluation in both real-world scenarios and\nsimulations, we demonstrate that D$^3$Fields are both generalizable and\neffective for zero-shot robotic manipulation tasks. In quantitative comparisons\nwith state-of-the-art dense descriptors, such as Dense Object Nets and DINO,\nD$^3$Fields exhibit significantly better generalization abilities and\nmanipulation accuracy.",
          "link": "http://arxiv.org/abs/2309.16118",
          "publishedOn": "2023-09-30T00:41:30.144Z",
          "wordCount": null,
          "title": "D$^3$Fields: Dynamic 3D Descriptor Fields for Zero-Shot Generalizable Robotic Manipulation. (arXiv:2309.16118v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feiyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhi_C/0/1/0/all/0/1\">Chen Zhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xueqiang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shuiguang Deng</a>",
          "description": "Existing approaches defend against backdoor attacks in federated learning\n(FL) mainly through a) mitigating the impact of infected models, or b)\nexcluding infected models. The former negatively impacts model accuracy, while\nthe latter usually relies on globally clear boundaries between benign and\ninfected model updates. However, model updates are easy to be mixed and\nscattered throughout in reality due to the diverse distributions of local data.\nThis work focuses on excluding infected models in FL. Unlike previous\nperspectives from a global view, we propose Snowball, a novel anti-backdoor FL\nframework through bidirectional elections from an individual perspective\ninspired by one principle deduced by us and two principles in FL and deep\nlearning. It is characterized by a) bottom-up election, where each candidate\nmodel update votes to several peer ones such that a few model updates are\nelected as selectees for aggregation; and b) top-down election, where selectees\nprogressively enlarge themselves through picking up from the candidates. We\ncompare Snowball with state-of-the-art defenses to backdoor attacks in FL on\nfive real-world datasets, demonstrating its superior resistance to backdoor\nattacks and slight impact on the accuracy of the global model.",
          "link": "http://arxiv.org/abs/2309.16456",
          "publishedOn": "2023-09-30T00:41:30.131Z",
          "wordCount": null,
          "title": "Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective. (arXiv:2309.16456v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Danieli_F/0/1/0/all/0/1\">Federico Danieli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarabia_M/0/1/0/all/0/1\">Miguel Sarabia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suau_X/0/1/0/all/0/1\">Xavier Suau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1\">Pau Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zappella_L/0/1/0/all/0/1\">Luca Zappella</a>",
          "description": "Parallelization techniques have become ubiquitous for accelerating inference\nand training of deep neural networks. Despite this, several operations are\nstill performed in a sequential manner. For instance, the forward and backward\npasses are executed layer-by-layer, and the output of diffusion models is\nproduced by applying a sequence of denoising steps. This sequential approach\nresults in a computational cost proportional to the number of steps involved,\npresenting a potential bottleneck as the number of steps increases. In this\nwork, we introduce DeepPCR, a novel algorithm which parallelizes typically\nsequential operations used in inference and training of neural networks.\nDeepPCR is based on interpreting a sequence of $L$ steps as the solution of a\nspecific system of equations, which we recover using the Parallel Cyclic\nReduction algorithm. This reduces the complexity of computing the sequential\noperations from $\\mathcal{O}(L)$ to $\\mathcal{O}(\\log_2L)$, thus yielding a\nspeedup for large $L$. To verify the theoretical lower complexity of the\nalgorithm, and to identify regimes for speedup, we test the effectiveness of\nDeepPCR in parallelizing the forward and backward pass in multi-layer\nperceptrons, and reach speedups of up to $30\\times$ for forward and $200\\times$\nfor backward pass. We additionally showcase the flexibility of DeepPCR by\nparallelizing training of ResNets with as many as 1024 layers, and generation\nin diffusion models, enabling up to $7\\times$ faster training and $11\\times$\nfaster generation, respectively, when compared to the sequential approach.",
          "link": "http://arxiv.org/abs/2309.16318",
          "publishedOn": "2023-09-30T00:41:30.130Z",
          "wordCount": null,
          "title": "DeepPCR: Parallelizing Sequential Operations in Neural Networks. (arXiv:2309.16318v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Agrawal_S/0/1/0/all/0/1\">Shubhada Agrawal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mathieu_T/0/1/0/all/0/1\">Timoth&#xe9;e Mathieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maillard_O/0/1/0/all/0/1\">Odalric-Ambrym Maillard</a>",
          "description": "We investigate the regret-minimisation problem in a multi-armed bandit\nsetting with arbitrary corruptions. Similar to the classical setup, the agent\nreceives rewards generated independently from the distribution of the arm\nchosen at each time. However, these rewards are not directly observed. Instead,\nwith a fixed $\\varepsilon\\in (0,\\frac{1}{2})$, the agent observes a sample from\nthe chosen arm's distribution with probability $1-\\varepsilon$, or from an\narbitrary corruption distribution with probability $\\varepsilon$. Importantly,\nwe impose no assumptions on these corruption distributions, which can be\nunbounded. In this setting, accommodating potentially unbounded corruptions, we\nestablish a problem-dependent lower bound on regret for a given family of arm\ndistributions. We introduce CRIMED, an asymptotically-optimal algorithm that\nachieves the exact lower bound on regret for bandits with Gaussian\ndistributions with known variance. Additionally, we provide a finite-sample\nanalysis of CRIMED's regret performance. Notably, CRIMED can effectively handle\ncorruptions with $\\varepsilon$ values as high as $\\frac{1}{2}$. Furthermore, we\ndevelop a tight concentration result for medians in the presence of arbitrary\ncorruptions, even with $\\varepsilon$ values up to $\\frac{1}{2}$, which may be\nof independent interest. We also discuss an extension of the algorithm for\nhandling misspecification in Gaussian model.",
          "link": "http://arxiv.org/abs/2309.16563",
          "publishedOn": "2023-09-30T00:41:30.121Z",
          "wordCount": null,
          "title": "CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">RuiQi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_B/0/1/0/all/0/1\">Boyu Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Libo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1\">Zhulin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yongjun Xu</a>",
          "description": "Continual Learning methods are designed to learn new tasks without erasing\nprevious knowledge. However, Continual Learning often requires massive\ncomputational power and storage capacity for satisfactory performance. In this\npaper, we propose a resource-efficient continual learning method called the\nElastic Expansion Network (E2Net). Leveraging core subnet distillation and\nprecise replay sample selection, E2Net achieves superior average accuracy and\ndiminished forgetting within the same computational and storage constraints,\nall while minimizing processing time. In E2Net, we propose Representative\nNetwork Distillation to identify the representative core subnet by assessing\nparameter quantity and output similarity with the working network, distilling\nanalogous subnets within the working network to mitigate reliance on rehearsal\nbuffers and facilitating knowledge transfer across previous tasks. To enhance\nstorage resource utilization, we then propose Subnet Constraint Experience\nReplay to optimize rehearsal efficiency through a sample storage strategy based\non the structures of representative networks. Extensive experiments conducted\npredominantly on cloud environments with diverse datasets and also spanning the\nedge environment demonstrate that E2Net consistently outperforms\nstate-of-the-art methods. In addition, our method outperforms competitors in\nterms of both storage and computational requirements.",
          "link": "http://arxiv.org/abs/2309.16117",
          "publishedOn": "2023-09-30T00:41:30.103Z",
          "wordCount": null,
          "title": "E2Net: Resource-Efficient Continual Learning with Elastic Expansion Network. (arXiv:2309.16117v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1\">Adele Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_C/0/1/0/all/0/1\">Caitlin Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_E/0/1/0/all/0/1\">Emily Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miolane_N/0/1/0/all/0/1\">Nina Miolane</a>",
          "description": "Women are at higher risk of Alzheimer's and other neurological diseases after\nmenopause, and yet research connecting female brain health to sex hormone\nfluctuations is limited. We seek to investigate this connection by developing\ntools that quantify 3D shape changes that occur in the brain during sex hormone\nfluctuations. Geodesic regression on the space of 3D discrete surfaces offers a\nprincipled way to characterize the evolution of a brain's shape. However, in\nits current form, this approach is too computationally expensive for practical\nuse. In this paper, we propose approximation schemes that accelerate geodesic\nregression on shape spaces of 3D discrete surfaces. We also provide rules of\nthumb for when each approximation can be used. We test our approach on\nsynthetic data to quantify the speed-accuracy trade-off of these approximations\nand show that practitioners can expect very significant speed-up while only\nsacrificing little accuracy. Finally, we apply the method to real brain shape\ndata and produce the first characterization of how the female hippocampus\nchanges shape during the menstrual cycle as a function of progesterone: a\ncharacterization made (practically) possible by our approximation schemes. Our\nwork paves the way for comprehensive, practical shape analyses in the fields of\nbio-medicine and computer vision. Our implementation is publicly available on\nGitHub: https://github.com/bioshape-lab/my28brains.",
          "link": "http://arxiv.org/abs/2309.16662",
          "publishedOn": "2023-09-30T00:41:30.103Z",
          "wordCount": null,
          "title": "Geodesic Regression Characterizes 3D Shape Changes in the Female Brain During Menstruation. (arXiv:2309.16662v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_Y/0/1/0/all/0/1\">Youbin Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pack_S/0/1/0/all/0/1\">Sangheon Pack</a>",
          "description": "5G introduced modularized network functions (NFs) to support emerging\nservices in a more flexible and elastic manner. To mitigate the complexity in\nsuch modularized NF management, automated network operation and management are\nindispensable, and thus the 3rd generation partnership project (3GPP) has\nintroduced a network data analytics function (NWDAF). However, a conventional\nNWDAF needs to conduct both inference and training tasks, and thus it is\ndifficult to provide the analytics results to NFs in a timely manner for an\nincreased number of analytics requests. In this article, we propose a\nhierarchical network data analytics framework (H-NDAF) where inference tasks\nare distributed to multiple leaf NWDAFs and training tasks are conducted at the\nroot NWDAF. Extensive simulation results using open-source software (i.e.,\nfree5GC) demonstrate that H-NDAF can provide sufficiently accurate analytics\nand faster analytics provision time compared to the conventional NWDAF.",
          "link": "http://arxiv.org/abs/2309.16269",
          "publishedOn": "2023-09-30T00:41:30.095Z",
          "wordCount": null,
          "title": "Hierarchical Network Data Analytics Framework for B5G Network Automation: Design and Implementation. (arXiv:2309.16269v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tanveer_M/0/1/0/all/0/1\">M. Tanveer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_R/0/1/0/all/0/1\">Ritik Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richhariya_B/0/1/0/all/0/1\">Bharat Richhariya</a>",
          "description": "Class imbalance is a major problem in many real world classification tasks.\nDue to the imbalance in the number of samples, the support vector machine (SVM)\nclassifier gets biased toward the majority class. Furthermore, these samples\nare often observed with a certain degree of noise. Therefore, to remove these\nproblems we propose a novel fuzzy based approach to deal with class imbalanced\nas well noisy datasets. We propose two approaches to address these problems.\nThe first approach is based on the intuitionistic fuzzy membership, termed as\nrobust energy-based intuitionistic fuzzy least squares twin support vector\nmachine (IF-RELSTSVM). Furthermore, we introduce the concept of\nhyperplane-based fuzzy membership in our second approach, where the final\nclassifier is termed as robust energy-based fuzzy least square twin support\nvector machine (F-RELSTSVM). By using this technique, the membership values are\nbased on a projection based approach, where the data points are projected on\nthe hyperplanes. The performance of the proposed algorithms is evaluated on\nseveral benchmark and synthetic datasets. The experimental results show that\nthe proposed IF-RELSTSVM and F-RELSTSVM models outperform the baseline\nalgorithms. Statistical tests are performed to check the significance of the\nproposed algorithms. The results show the applicability of the proposed\nalgorithms on noisy as well as imbalanced datasets.",
          "link": "http://arxiv.org/abs/2309.15886",
          "publishedOn": "2023-09-30T00:41:30.092Z",
          "wordCount": null,
          "title": "Projection based fuzzy least squares twin support vector machine for class imbalance problems. (arXiv:2309.15886v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yujia Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivanandan_S/0/1/0/all/0/1\">Srinivasan Sivanandan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karaletsos_T/0/1/0/all/0/1\">Theofanis Karaletsos</a>",
          "description": "Vision Transformer (ViT) has emerged as a powerful architecture in the realm\nof modern computer vision. However, its application in certain imaging fields,\nsuch as microscopy and satellite imaging, presents unique challenges. In these\ndomains, images often contain multiple channels, each carrying semantically\ndistinct and independent information. Furthermore, the model must demonstrate\nrobustness to sparsity in input channels, as they may not be densely available\nduring training or testing. In this paper, we propose a modification to the ViT\narchitecture that enhances reasoning across the input channels and introduce\nHierarchical Channel Sampling (HCS) as an additional regularization technique\nto ensure robustness when only partial channels are presented during test time.\nOur proposed model, ChannelViT, constructs patch tokens independently from each\ninput channel and utilizes a learnable channel embedding that is added to the\npatch tokens, similar to positional embeddings. We evaluate the performance of\nChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat\n(satellite imaging). Our results show that ChannelViT outperforms ViT on\nclassification tasks and generalizes well, even when a subset of input channels\nis used during testing. Across our experiments, HCS proves to be a powerful\nregularizer, independent of the architecture employed, suggesting itself as a\nstraightforward technique for robust ViT training. Lastly, we find that\nChannelViT generalizes effectively even when there is limited access to all\nchannels during training, highlighting its potential for multi-channel imaging\nunder real-world conditions with sparse sensors.",
          "link": "http://arxiv.org/abs/2309.16108",
          "publishedOn": "2023-09-30T00:41:30.084Z",
          "wordCount": null,
          "title": "Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words. (arXiv:2309.16108v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cyranka_J/0/1/0/all/0/1\">Jacek Cyranka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haponiuk_S/0/1/0/all/0/1\">Szymon Haponiuk</a>",
          "description": "In order to support the advancement of machine learning methods for\npredicting time-series data, we present a comprehensive dataset designed\nexplicitly for long-term time-series forecasting. We incorporate a collection\nof datasets obtained from diverse, dynamic systems and real-life records. Each\ndataset is standardized by dividing it into training and test trajectories with\npredetermined lookback lengths. We include trajectories of length up to $2000$\nto ensure a reliable evaluation of long-term forecasting capabilities. To\ndetermine the most effective model in diverse scenarios, we conduct an\nextensive benchmarking analysis using classical and state-of-the-art models,\nnamely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings\nreveal intriguing performance comparisons among these models, highlighting the\ndataset-dependent nature of model effectiveness. Notably, we introduce a custom\nlatent NLinear model and enhance DeepAR with a curriculum learning phase. Both\nconsistently outperform their vanilla counterparts.",
          "link": "http://arxiv.org/abs/2309.15946",
          "publishedOn": "2023-09-30T00:41:30.074Z",
          "wordCount": null,
          "title": "Unified Long-Term Time-Series Forecasting Benchmark. (arXiv:2309.15946v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsur_D/0/1/0/all/0/1\">Dor Tsur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldfeld_Z/0/1/0/all/0/1\">Ziv Goldfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>",
          "description": "Quantifying the dependence between high-dimensional random variables is\ncentral to statistical learning and inference. Two classical methods are\ncanonical correlation analysis (CCA), which identifies maximally correlated\nprojected versions of the original variables, and Shannon's mutual information,\nwhich is a universal dependence measure that also captures high-order\ndependencies. However, CCA only accounts for linear dependence, which may be\ninsufficient for certain applications, while mutual information is often\ninfeasible to compute/estimate in high dimensions. This work proposes a middle\nground in the form of a scalable information-theoretic generalization of CCA,\ntermed max-sliced mutual information (mSMI). mSMI equals the maximal mutual\ninformation between low-dimensional projections of the high-dimensional\nvariables, which reduces back to CCA in the Gaussian case. It enjoys the best\nof both worlds: capturing intricate dependencies in the data while being\namenable to fast computation and scalable estimation from samples. We show that\nmSMI retains favorable structural properties of Shannon's mutual information,\nlike variational forms and identification of independence. We then study\nstatistical estimation of mSMI, propose an efficiently computable neural\nestimator, and couple it with formal non-asymptotic error bounds. We present\nexperiments that demonstrate the utility of mSMI for several tasks,\nencompassing independence testing, multi-view representation learning,\nalgorithmic fairness, and generative modeling. We observe that mSMI\nconsistently outperforms competing methods with little-to-no computational\noverhead.",
          "link": "http://arxiv.org/abs/2309.16200",
          "publishedOn": "2023-09-30T00:41:30.068Z",
          "wordCount": null,
          "title": "Max-Sliced Mutual Information. (arXiv:2309.16200v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharifi_I/0/1/0/all/0/1\">Iman Sharifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1\">Saber Fallah</a>",
          "description": "Current methods of imitation learning (IL), primarily based on deep neural\nnetworks, offer efficient means for obtaining driving policies from real-world\ndata but suffer from significant limitations in interpretability and\ngeneralizability. These shortcomings are particularly concerning in\nsafety-critical applications like autonomous driving. In this paper, we address\nthese limitations by introducing Symbolic Imitation Learning (SIL), a\ngroundbreaking method that employs Inductive Logic Programming (ILP) to learn\ndriving policies which are transparent, explainable and generalisable from\navailable datasets. Utilizing the real-world highD dataset, we subject our\nmethod to a rigorous comparative analysis against prevailing\nneural-network-based IL methods. Our results demonstrate that SIL not only\nenhances the interpretability of driving policies but also significantly\nimproves their applicability across varied driving situations. Hence, this work\noffers a novel pathway to more reliable and safer autonomous driving systems,\nunderscoring the potential of integrating ILP into the domain of IL.",
          "link": "http://arxiv.org/abs/2309.16025",
          "publishedOn": "2023-09-30T00:41:30.064Z",
          "wordCount": null,
          "title": "Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies. (arXiv:2309.16025v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suh_Y/0/1/0/all/0/1\">Yehyun Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_P/0/1/0/all/0/1\">Peter Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1\">J.Ryan Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moyer_D/0/1/0/all/0/1\">Daniel Moyer</a>",
          "description": "This work reports the empirical performance of an automated medical landmark\ndetection method for predict clinical markers in hip radiograph images.\nNotably, the detection method was trained using a label-only augmentation\nscheme; our results indicate that this form of augmentation outperforms\ntraditional data augmentation and produces highly sample efficient estimators.\nWe train a generic U-Net-based architecture under a curriculum consisting of\ntwo phases: initially relaxing the landmarking task by enlarging the label\npoints to regions, then gradually eroding these label regions back to the base\ntask. We measure the benefits of this approach on six datasets of radiographs\nwith gold-standard expert annotations.",
          "link": "http://arxiv.org/abs/2309.16066",
          "publishedOn": "2023-09-30T00:41:30.058Z",
          "wordCount": 616,
          "title": "Label Augmentation Method for Medical Landmark Detection in Hip Radiograph Images. (arXiv:2309.16066v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.09175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+S_P/0/1/0/all/0/1\">Priya.S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivakumar_H/0/1/0/all/0/1\">Haribharathi Sivakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_V/0/1/0/all/0/1\">Vijay Arvind.R</a>",
          "description": "Modern streaming data categorization faces significant challenges from\nconcept drift and class imbalanced data. This negatively impacts the output of\nthe classifier, leading to improper classification. Furthermore, other factors\nsuch as the overlapping of multiple classes limit the extent of the correctness\nof the output. This work proposes a novel framework for integrating data\npre-processing and dynamic ensemble selection, by formulating the\nclassification framework for the nonstationary drifting imbalanced data stream,\nwhich employs the data pre-processing and dynamic ensemble selection\ntechniques. The proposed framework was evaluated using six artificially\ngenerated data streams with differing imbalance ratios in combination with two\ndifferent types of concept drifts. Each stream is composed of 200 chunks of 500\nobjects described by eight features and contains five concept drifts. Seven\npre-processing techniques and two dynamic ensemble selection methods were\nconsidered. According to experimental results, data pre-processing combined\nwith Dynamic Ensemble Selection techniques significantly delivers more accuracy\nwhen dealing with imbalanced data streams.",
          "link": "http://arxiv.org/abs/2309.09175",
          "publishedOn": "2023-09-30T00:41:30.039Z",
          "wordCount": null,
          "title": "Imbalanced Data Stream Classification using Dynamic Ensemble Selection. (arXiv:2309.09175v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.05856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1\">Zhangkai Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoliang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shurun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwong_S/0/1/0/all/0/1\">Sam Kwong</a>",
          "description": "High-quality face images are required to guarantee the stability and\nreliability of automatic face recognition (FR) systems in surveillance and\nsecurity scenarios. However, a massive amount of face data is usually\ncompressed before being analyzed due to limitations on transmission or storage.\nThe compressed images may lose the powerful identity information, resulting in\nthe performance degradation of the FR system. Herein, we make the first attempt\nto study just noticeable difference (JND) for the FR system, which can be\ndefined as the maximum distortion that the FR system cannot notice. More\nspecifically, we establish a JND dataset including 3530 original images and\n137,670 compressed images generated by advanced reference encoding/decoding\nsoftware based on the Versatile Video Coding (VVC) standard (VTM-15.0).\nSubsequently, we develop a novel JND prediction model to directly infer JND\nimages for the FR system. In particular, in order to maximum redundancy removal\nwithout impairment of robust identity information, we apply the encoder with\nmultiple feature extraction and attention-based feature decomposition modules\nto progressively decompose face features into two uncorrelated components,\ni.e., identity and residual features, via self-supervised learning. Then, the\nresidual feature is fed into the decoder to generate the residual map. Finally,\nthe predicted JND map is obtained by subtracting the residual map from the\noriginal image. Experimental results have demonstrated that the proposed model\nachieves higher accuracy of JND map prediction compared with the\nstate-of-the-art JND models, and is capable of saving more bits while\nmaintaining the performance of the FR system compared with VTM-15.0.",
          "link": "http://arxiv.org/abs/2209.05856",
          "publishedOn": "2023-09-30T00:41:30.024Z",
          "wordCount": null,
          "title": "Just Noticeable Difference Modeling for Face Recognition System. (arXiv:2209.05856v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15889",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yilmaz_S/0/1/0/all/0/1\">Selim F. Yilmaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niu_X/0/1/0/all/0/1\">Xueyan Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bai_B/0/1/0/all/0/1\">Bo Bai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_W/0/1/0/all/0/1\">Wei Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_L/0/1/0/all/0/1\">Lei Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz Gunduz</a>",
          "description": "We consider the image transmission problem over a noisy wireless channel via\ndeep learning-based joint source-channel coding (DeepJSCC) along with a\ndenoising diffusion probabilistic model (DDPM) at the receiver. Specifically,\nwe are interested in the perception-distortion trade-off in the practical\nfinite block length regime, in which separate source and channel coding can be\nhighly suboptimal. We introduce a novel scheme that utilizes the range-null\nspace decomposition of the target image. We transmit the range-space of the\nimage after encoding and employ DDPM to progressively refine its null space\ncontents. Through extensive experiments, we demonstrate significant\nimprovements in distortion and perceptual quality of reconstructed images\ncompared to standard DeepJSCC and the state-of-the-art generative\nlearning-based method. We will publicly share our source code to facilitate\nfurther research and reproducibility.",
          "link": "http://arxiv.org/abs/2309.15889",
          "publishedOn": "2023-09-30T00:41:30.020Z",
          "wordCount": null,
          "title": "High Perceptual Quality Wireless Image Delivery with Denoising Diffusion Models. (arXiv:2309.15889v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.14708",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Juhyeon Kim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Huh_J/0/1/0/all/0/1\">Joonsuk Huh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Park_D/0/1/0/all/0/1\">Daniel K. Park</a>",
          "description": "Machine learning using quantum convolutional neural networks (QCNNs) has\ndemonstrated success in both quantum and classical data classification. In\nprevious studies, QCNNs attained a higher classification accuracy than their\nclassical counterparts under the same training conditions in the few-parameter\nregime. However, the general performance of large-scale quantum models is\ndifficult to examine because of the limited size of quantum circuits, which can\nbe reliably implemented in the near future. We propose transfer learning as an\neffective strategy for utilizing small QCNNs in the noisy intermediate-scale\nquantum era to the full extent. In the classical-to-quantum transfer learning\nframework, a QCNN can solve complex classification problems without requiring a\nlarge-scale quantum circuit by utilizing a pre-trained classical convolutional\nneural network (CNN). We perform numerical simulations of QCNN models with\nvarious sets of quantum convolution and pooling operations for MNIST data\nclassification under transfer learning, in which a classical CNN is trained\nwith Fashion-MNIST data. The results show that transfer learning from classical\nto quantum CNN performs considerably better than purely classical transfer\nlearning models under similar training conditions.",
          "link": "http://arxiv.org/abs/2208.14708",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Classical-to-quantum convolutional neural network transfer learning. (arXiv:2208.14708v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.09976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuzina_A/0/1/0/all/0/1\">Anna Kuzina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1\">Jakub M. Tomczak</a>",
          "description": "Hierarchical Variational Autoencoders (VAEs) are among the most popular\nlikelihood-based generative models. There is a consensus that the top-down\nhierarchical VAEs allow effective learning of deep latent structures and avoid\nproblems like posterior collapse. Here, we show that this is not necessarily\nthe case, and the problem of collapsing posteriors remains. To discourage this\nissue, we propose a deep hierarchical VAE with a context on top. Specifically,\nwe use a Discrete Cosine Transform to obtain the last latent variable. In a\nseries of experiments, we observe that the proposed modification allows us to\nachieve better utilization of the latent space and does not harm the model's\ngenerative abilities.",
          "link": "http://arxiv.org/abs/2302.09976",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Discouraging posterior collapse in hierarchical Variational Autoencoders using context. (arXiv:2302.09976v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03666",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1\">Shide Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fang_Z/0/1/0/all/0/1\">Zihan Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lan_S/0/1/0/all/0/1\">Shiyang Lan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_Y/0/1/0/all/0/1\">Yanchao Tan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gunther_M/0/1/0/all/0/1\">Manuel G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shiping Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guo_W/0/1/0/all/0/1\">Wenzhong Guo</a>",
          "description": "As researchers strive to narrow the gap between machine intelligence and\nhuman through the development of artificial intelligence technologies, it is\nimperative that we recognize the critical importance of trustworthiness in\nopen-world, which has become ubiquitous in all aspects of daily life for\neveryone. However, several challenges may create a crisis of trust in current\nartificial intelligence systems that need to be bridged: 1) Insufficient\nexplanation of predictive results; 2) Inadequate generalization for learning\nmodels; 3) Poor adaptability to uncertain environments. Consequently, we\nexplore a neural program to bridge trustworthiness and open-world learning,\nextending from single-modal to multi-modal scenarios for readers. 1) To enhance\ndesign-level interpretability, we first customize trustworthy networks with\nspecific physical meanings; 2) We then design environmental well-being\ntask-interfaces via flexible learning regularizers for improving the\ngeneralization of trustworthy learning; 3) We propose to increase the\nrobustness of trustworthy learning by integrating open-world recognition losses\nwith agent mechanisms. Eventually, we enhance various trustworthy properties\nthrough the establishment of design-level explainability, environmental\nwell-being task-interfaces and open-world recognition programs. These designed\nopen-world protocols are applicable across a wide range of surroundings, under\nopen-world multimedia recognition scenarios with significant performance\nimprovements observed.",
          "link": "http://arxiv.org/abs/2308.03666",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koloski_B/0/1/0/all/0/1\">Boshko Koloski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1\">Bla&#x17e; &#x160;krlj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1\">Senja Pollak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavrac_N/0/1/0/all/0/1\">Nada Lavra&#x10d;</a>",
          "description": "In the domain of semi-supervised learning, the current approaches\ninsufficiently exploit the potential of considering inter-instance\nrelationships among (un)labeled data. In this work, we address this limitation\nby providing an approach for inferring latent graphs that capture the intrinsic\ndata relationships. By leveraging graph-based representations, our approach\nfacilitates the seamless propagation of information throughout the graph,\nenabling the effective incorporation of global and local knowledge. Through\nevaluations on biomedical tabular datasets, we compare the capabilities of our\napproach to other contemporary methods. Our work demonstrates the significance\nof inter-instance relationship discovery as practical means for constructing\nrobust latent graphs to enhance semi-supervised learning techniques. Our method\nachieves state-of-the-art results on three biomedical datasets.",
          "link": "http://arxiv.org/abs/2309.15757",
          "publishedOn": "2023-09-30T00:41:30.014Z",
          "wordCount": null,
          "title": "Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data. (arXiv:2309.15757v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1\">Georgios B. Giannakis</a>",
          "description": "Sharpness-aware minimization (SAM) has well documented merits in enhancing\ngeneralization of deep neural networks, even without sizable data augmentation.\nEmbracing the geometry of the loss function, where neighborhoods of 'flat\nminima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing\nthe maximum loss caused by an adversary perturbing parameters within the\nneighborhood. Although critical to account for sharpness of the loss function,\nsuch an 'over-friendly adversary' can curtail the outmost level of\ngeneralization. The novel approach of this contribution fosters stabilization\nof adversaries through variance suppression (VaSSO) to avoid such friendliness.\nVaSSO's provable stability safeguards its numerical improvement over SAM in\nmodel-agnostic tasks, including image classification and machine translation.\nIn addition, experiments confirm that VaSSO endows SAM with robustness against\nhigh levels of label noise.",
          "link": "http://arxiv.org/abs/2309.15639",
          "publishedOn": "2023-09-30T00:41:30.012Z",
          "wordCount": null,
          "title": "Enhancing Sharpness-Aware Optimization Through Variance Suppression. (arXiv:2309.15639v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.01253",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Hess_P/0/1/0/all/0/1\">Philipp Hess</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lange_S/0/1/0/all/0/1\">Stefan Lange</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schotz_C/0/1/0/all/0/1\">Christof Sch&#xf6;tz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Boers_N/0/1/0/all/0/1\">Niklas Boers</a>",
          "description": "The accurate representation of precipitation in Earth system models (ESMs) is\ncrucial for reliable projections of the ecological and socioeconomic impacts in\nresponse to anthropogenic global warming. The complex cross-scale interactions\nof processes that produce precipitation are challenging to model, however,\ninducing potentially strong biases in ESM fields, especially regarding\nextremes. State-of-the-art bias correction methods only address errors in the\nsimulated frequency distributions locally at every individual grid cell.\nImproving unrealistic spatial patterns of the ESM output, which would require\nspatial context, has not been possible so far. Here, we show that a\npost-processing method based on physically constrained generative adversarial\nnetworks (cGANs) can correct biases of a state-of-the-art, CMIP6-class ESM both\nin local frequency distributions and in the spatial patterns at once. While our\nmethod improves local frequency distributions equally well as gold-standard\nbias-adjustment frameworks, it strongly outperforms any existing methods in the\ncorrection of spatial patterns, especially in terms of the characteristic\nspatial intermittency of precipitation extremes.",
          "link": "http://arxiv.org/abs/2301.01253",
          "publishedOn": "2023-09-30T00:41:30.011Z",
          "wordCount": null,
          "title": "Deep learning for bias-correcting CMIP6-class Earth system models. (arXiv:2301.01253v3 [physics.ao-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.05516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wenhua Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Haihao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yiyang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_K/0/1/0/all/0/1\">Kaokao Lv</a>",
          "description": "Large Language Models (LLMs) have proven their exceptional capabilities in\nperforming language-related tasks. However, their deployment poses significant\nchallenges due to their considerable memory and storage requirements. In\nresponse to this issue, weight-only quantization, particularly 3 and 4-bit\nweight-only quantization, has emerged as one of the most viable solutions. As\nthe number of bits decreases, the quantization grid broadens, thus emphasizing\nthe importance of up and down rounding. While previous studies have\ndemonstrated that fine-tuning up and down rounding with the addition of\nperturbations can enhance accuracy in some scenarios, our study is driven by\nthe precise and limited boundary of these perturbations, where only the\nthreshold for altering the rounding value is of significance. Consequently, we\npropose a concise and highly effective approach for optimizing the weight\nrounding task. Our method, named SignRound, involves lightweight block-wise\ntuning using signed gradient descent, enabling us to achieve outstanding\nresults within 400 steps. SignRound competes impressively against recent\nmethods without introducing additional inference overhead. The source code will\nbe publicly available at \\url{https://github.com/intel/neural-compressor} soon.",
          "link": "http://arxiv.org/abs/2309.05516",
          "publishedOn": "2023-09-30T00:41:30.007Z",
          "wordCount": null,
          "title": "Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs. (arXiv:2309.05516v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.00147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghobrial_A/0/1/0/all/0/1\">Abanoub Ghobrial</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hond_D/0/1/0/all/0/1\">Darryl Hond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgari_H/0/1/0/all/0/1\">Hamid Asgari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eder_K/0/1/0/all/0/1\">Kerstin Eder</a>",
          "description": "Autonomous systems (AS) often use Deep Neural Network (DNN) classifiers to\nallow them to operate in complex, high-dimensional, non-linear, and dynamically\nchanging environments. Due to the complexity of these environments, DNN\nclassifiers may output misclassifications during operation when they face\ndomains not identified during development. Removing a system from operation for\nretraining becomes impractical as the number of such AS increases. To increase\nAS reliability and overcome this limitation, DNN classifiers need to have the\nability to adapt during operation when faced with different operational domains\nusing a few samples (e.g. 100 samples). However, retraining DNNs on a few\nsamples is known to cause catastrophic forgetting. In this paper, we introduce\nDynamic Incremental Regularised Adaptation (DIRA), a framework for operational\ndomain adaption of DNN classifiers using regularisation techniques to overcome\ncatastrophic forgetting and achieve adaptation when retraining using a few\nsamples of the target domain. Our approach shows improvements on different\nimage classification benchmarks aimed at evaluating robustness to distribution\nshifts (e.g.CIFAR-10C/100C, ImageNet-C), and produces state-of-the-art\nperformance in comparison with other frameworks from the literature.",
          "link": "http://arxiv.org/abs/2205.00147",
          "publishedOn": "2023-09-30T00:41:30.006Z",
          "wordCount": null,
          "title": "DIRA: Dynamic Domain Incremental Regularised Adaptation. (arXiv:2205.00147v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.15875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiawen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Quan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Deze Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhuo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Minyi Guo</a>",
          "description": "Many emerging user-facing services adopt Graph Neural Networks (GNNs) to\nimprove serving accuracy. When the graph used by a GNN model changes,\nrepresentations (embedding) of nodes in the graph should be updated\naccordingly. However, the node representation update is too slow, resulting in\neither long response latency of user queries (the inference is performed after\nthe update completes) or high staleness problem (the inference is performed\nbased on stale data). Our in-depth analysis shows that the slow update is\nmainly due to neighbor explosion problem in graphs and duplicated computation.\nBased on such findings, we propose STAG, a GNN serving framework that enables\nlow latency and low staleness of GNN-based services. It comprises a\ncollaborative serving mechanism and an additivity-based incremental propagation\nstrategy. With the collaborative serving mechanism, only part of node\nrepresentations are updated during the update phase, and the final\nrepresentations are calculated in the inference phase. It alleviates the\nneighbor explosion problem. The additivity-based incremental propagation\nstrategy reuses intermediate data during the update phase, eliminating\nduplicated computation problem. Experimental results show that STAG accelerates\nthe update phase by 1.3x~90.1x, and greatly reduces staleness time with a\nslight increase in response latency.",
          "link": "http://arxiv.org/abs/2309.15875",
          "publishedOn": "2023-09-30T00:41:29.952Z",
          "wordCount": null,
          "title": "STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs. (arXiv:2309.15875v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bathla_S/0/1/0/all/0/1\">Shivani Bathla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1\">Vinita Vasudevan</a>",
          "description": "Exact computation of the partition function is known to be intractable,\nnecessitating approximate inference techniques. Existing methods for\napproximate inference are slow to converge for many benchmarks. The control of\naccuracy-complexity trade-off is also non-trivial in many of these methods. We\npropose a novel incremental build-infer-approximate (IBIA) framework for\napproximate inference that addresses these issues. In this framework, the\nprobabilistic graphical model is converted into a sequence of clique tree\nforests (SCTF) with bounded clique sizes. We show that the SCTF can be used to\nefficiently compute the partition function. We propose two new algorithms which\nare used to construct the SCTF and prove the correctness of both. The first is\nan algorithm for incremental construction of CTFs that is guaranteed to give a\nvalid CTF with bounded clique sizes and the second is an approximation\nalgorithm that takes a calibrated CTF as input and yields a valid and\ncalibrated CTF with reduced clique sizes as the output. We have evaluated our\nmethod using several benchmark sets from recent UAI competitions and our\nresults show good accuracies with competitive runtimes.",
          "link": "http://arxiv.org/abs/2304.06366",
          "publishedOn": "2023-09-30T00:41:29.831Z",
          "wordCount": null,
          "title": "IBIA: An Incremental Build-Infer-Approximate Framework for Approximate Inference of Partition Function. (arXiv:2304.06366v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golowich_N/0/1/0/all/0/1\">Noah Golowich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haghtalab_N/0/1/0/all/0/1\">Nika Haghtalab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shetty_A/0/1/0/all/0/1\">Abhishek Shetty</a>",
          "description": "A fundamental shortcoming of the concept of Nash equilibrium is its\ncomputational intractability: approximating Nash equilibria in normal-form\ngames is PPAD-hard. In this paper, inspired by the ideas of smoothed analysis,\nwe introduce a relaxed variant of Nash equilibrium called $\\sigma$-smooth Nash\nequilibrium, for a smoothness parameter $\\sigma$. In a $\\sigma$-smooth Nash\nequilibrium, players only need to achieve utility at least as high as their\nbest deviation to a $\\sigma$-smooth strategy, which is a distribution that does\nnot put too much mass (as parametrized by $\\sigma$) on any fixed action. We\ndistinguish two variants of $\\sigma$-smooth Nash equilibria: strong\n$\\sigma$-smooth Nash equilibria, in which players are required to play\n$\\sigma$-smooth strategies under equilibrium play, and weak $\\sigma$-smooth\nNash equilibria, where there is no such requirement.\n\nWe show that both weak and strong $\\sigma$-smooth Nash equilibria have\nsuperior computational properties to Nash equilibria: when $\\sigma$ as well as\nan approximation parameter $\\epsilon$ and the number of players are all\nconstants, there is a constant-time randomized algorithm to find a weak\n$\\epsilon$-approximate $\\sigma$-smooth Nash equilibrium in normal-form games.\nIn the same parameter regime, there is a polynomial-time deterministic\nalgorithm to find a strong $\\epsilon$-approximate $\\sigma$-smooth Nash\nequilibrium in a normal-form game. These results stand in contrast to the\noptimal algorithm for computing $\\epsilon$-approximate Nash equilibria, which\ncannot run in faster than quasipolynomial-time. We complement our upper bounds\nby showing that when either $\\sigma$ or $\\epsilon$ is an inverse polynomial,\nfinding a weak $\\epsilon$-approximate $\\sigma$-smooth Nash equilibria becomes\ncomputationally intractable.",
          "link": "http://arxiv.org/abs/2309.12226",
          "publishedOn": "2023-09-23T00:40:40.997Z",
          "wordCount": 759,
          "title": "Smooth Nash Equilibria: Algorithms and Complexity. (arXiv:2309.12226v1 [cs.GT])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11995",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Roeder_E/0/1/0/all/0/1\">Eduardo Augusto Roeder</a>",
          "description": "Pneumonia is the leading infectious cause of infant death in the world. When\nidentified early, it is possible to alter the prognosis of the patient, one\ncould use imaging exams to help in the diagnostic confirmation. Performing and\ninterpreting the exams as soon as possible is vital for a good treatment, with\nthe most common exam for this pathology being chest X-ray. The objective of\nthis study was to develop a software that identify the presence or absence of\npneumonia in chest radiographs. The software was developed as a computational\nmodel based on machine learning using transfer learning technique. For the\ntraining process, images were collected from a database available online with\nchildren's chest X-rays images taken at a hospital in China. After training,\nthe model was then exposed to new images, achieving relevant results on\nidentifying such pathology, reaching 98% sensitivity and 97.3% specificity for\nthe sample used for testing. It can be concluded that it is possible to develop\na software that identifies pneumonia in chest X-ray images.",
          "link": "http://arxiv.org/abs/2309.11995",
          "publishedOn": "2023-09-23T00:40:40.974Z",
          "wordCount": 699,
          "title": "Identification of pneumonia on chest x-ray images through machine learning. (arXiv:2309.11995v1 [eess.IV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuweiyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1\">Shengyi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madaan_N/0/1/0/all/0/1\">Nikhil Madaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyengar_M/0/1/0/all/0/1\">Madhavan Iyengar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fouhey_D/0/1/0/all/0/1\">David F. Fouhey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1\">Joyce Chai</a>",
          "description": "3D visual grounding is a critical skill for household robots, enabling them\nto navigate, manipulate objects, and answer questions based on their\nenvironment. While existing approaches often rely on extensive labeled data or\nexhibit limitations in handling complex language queries, we propose\nLLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model\n(LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to\ndecompose complex natural language queries into semantic constituents and\nemploys a visual grounding tool, such as OpenScene or LERF, to identify objects\nin a 3D scene. The LLM then evaluates the spatial and commonsense relations\namong the proposed objects to make a final grounding decision. Our method does\nnot require any labeled training data and can generalize to novel 3D scenes and\narbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and\ndemonstrate state-of-the-art zero-shot grounding accuracy. Our findings\nindicate that LLMs significantly improve the grounding capability, especially\nfor complex language queries, making LLM-Grounder an effective approach for 3D\nvision-language tasks in robotics. Videos and interactive demos can be found on\nthe project website https://chat-with-nerf.github.io/ .",
          "link": "http://arxiv.org/abs/2309.12311",
          "publishedOn": "2023-09-23T00:40:40.924Z",
          "wordCount": 724,
          "title": "LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent. (arXiv:2309.12311v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.10916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tonni_S/0/1/0/all/0/1\">Shakila Mahjabin Tonni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dras_M/0/1/0/all/0/1\">Mark Dras</a>",
          "description": "Adversarial examples, deliberately crafted using small perturbations to fool\ndeep neural networks, were first studied in image processing and more recently\nin NLP. While approaches to detecting adversarial examples in NLP have largely\nrelied on search over input perturbations, image processing has seen a range of\ntechniques that aim to characterise adversarial subspaces over the learned\nrepresentations.\n\nIn this paper, we adapt two such approaches to NLP, one based on nearest\nneighbors and influence functions and one on Mahalanobis distances. The former\nin particular produces a state-of-the-art detector when compared against\nseveral strong baselines; moreover, the novel use of influence functions\nprovides insight into how the nature of adversarial example subspaces in NLP\nrelate to those in image processing, and also how they differ depending on the\nkind of NLP task.",
          "link": "http://arxiv.org/abs/2309.10916",
          "publishedOn": "2023-09-23T00:40:40.917Z",
          "wordCount": 675,
          "title": "What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples. (arXiv:2309.10916v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.01682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Phan_Trong_D/0/1/0/all/0/1\">Dat Phan-Trong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_The_H/0/1/0/all/0/1\">Hung Tran-The</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Sunil Gupta</a>",
          "description": "Bayesian Optimization (BO) is an effective approach for global optimization\nof black-box functions when function evaluations are expensive. Most prior\nworks use Gaussian processes to model the black-box function, however, the use\nof kernels in Gaussian processes leads to two problems: first, the kernel-based\nmethods scale poorly with the number of data points and second, kernel methods\nare usually not effective on complex structured high dimensional data due to\ncurse of dimensionality. Therefore, we propose a novel black-box optimization\nalgorithm where the black-box function is modeled using a neural network. Our\nalgorithm does not need a Bayesian neural network to estimate predictive\nuncertainty and is therefore computationally favorable. We analyze the\ntheoretical behavior of our algorithm in terms of regret bound using advances\nin NTK theory showing its efficient convergence. We perform experiments with\nboth synthetic and real-world optimization tasks and show that our algorithm is\nmore sample efficient compared to existing methods.",
          "link": "http://arxiv.org/abs/2303.01682",
          "publishedOn": "2023-09-23T00:40:40.069Z",
          "wordCount": 676,
          "title": "Neural-BO: A Black-box Optimization Algorithm using Deep Neural Networks. (arXiv:2303.01682v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Priyanshu Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khare_A/0/1/0/all/0/1\">Avishree Khare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajpai_Y/0/1/0/all/0/1\">Yasharth Bajpai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saikat Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1\">Sumit Gulwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanade_A/0/1/0/all/0/1\">Aditya Kanade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishna_A/0/1/0/all/0/1\">Arjun Radhakrishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soares_G/0/1/0/all/0/1\">Gustavo Soares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1\">Ashish Tiwari</a>",
          "description": "Developers expend a significant amount of time in editing code for a variety\nof reasons such as bug fixing or adding new features. Designing effective\nmethods to predict code edits has been an active yet challenging area of\nresearch due to the diversity of code edits and the difficulty of capturing the\ndeveloper intent. In this work, we address these challenges by endowing\npre-trained large language models (LLMs) of code with the knowledge of prior,\nrelevant edits. The generative capability of the LLMs helps address the\ndiversity in code changes and conditioning code generation on prior edits helps\ncapture the latent developer intent. We evaluate two well-known LLMs, Codex and\nCodeT5, in zero-shot and fine-tuning settings respectively. In our experiments\nwith two datasets, the knowledge of prior edits boosts the performance of the\nLLMs significantly and enables them to generate 29% and 54% more correctly\nedited code in top-1 suggestions relative to the current state-of-the-art\nsymbolic and neural approaches, respectively.",
          "link": "http://arxiv.org/abs/2305.14129",
          "publishedOn": "2023-09-23T00:40:39.921Z",
          "wordCount": 687,
          "title": "GrACE: Generation using Associated Code Edits. (arXiv:2305.14129v3 [cs.SE] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.06908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1\">Zhen Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wei Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qifeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>",
          "description": "Denoising diffusion probabilistic models (DDPMs) have shown promising\nperformance for speech synthesis. However, a large number of iterative steps\nare required to achieve high sample quality, which restricts the inference\nspeed. Maintaining sample quality while increasing sampling speed has become a\nchallenging task. In this paper, we propose a \"Co\"nsistency \"Mo\"del-based\n\"Speech\" synthesis method, CoMoSpeech, which achieve speech synthesis through a\nsingle diffusion sampling step while achieving high audio quality. The\nconsistency constraint is applied to distill a consistency model from a\nwell-designed diffusion-based teacher model, which ultimately yields superior\nperformances in the distilled CoMoSpeech. Our experiments show that by\ngenerating audio recordings by a single sampling step, the CoMoSpeech achieves\nan inference speed more than 150 times faster than real-time on a single NVIDIA\nA100 GPU, which is comparable to FastSpeech2, making diffusion-sampling based\nspeech synthesis truly practical. Meanwhile, objective and subjective\nevaluations on text-to-speech and singing voice synthesis show that the\nproposed teacher models yield the best audio quality, and the one-step sampling\nbased CoMoSpeech achieves the best inference speed with better or comparable\naudio quality to other conventional multi-step diffusion model baselines. Audio\nsamples are available at https://comospeech.github.io/.",
          "link": "http://arxiv.org/abs/2305.06908",
          "publishedOn": "2023-09-23T00:40:39.916Z",
          "wordCount": 751,
          "title": "CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model. (arXiv:2305.06908v3 [cs.SD] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tondo_G/0/1/0/all/0/1\">Gledson Rodrigo Tondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rau_S/0/1/0/all/0/1\">Sebastian Rau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kavrakov_I/0/1/0/all/0/1\">Igor Kavrakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morgenthal_G/0/1/0/all/0/1\">Guido Morgenthal</a>",
          "description": "Machine learning models trained with structural health monitoring data have\nbecome a powerful tool for system identification. This paper presents a\nphysics-informed Gaussian process (GP) model for Timoshenko beam elements. The\nmodel is constructed as a multi-output GP with covariance and cross-covariance\nkernels analytically derived based on the differential equations for\ndeflections, rotations, strains, bending moments, shear forces and applied\nloads. Stiffness identification is performed in a Bayesian format by maximising\na posterior model through a Markov chain Monte Carlo method, yielding a\nstochastic model for the structural parameters. The optimised GP model is\nfurther employed for probabilistic predictions of unobserved responses.\nAdditionally, an entropy-based method for physics-informed sensor placement\noptimisation is presented, exploiting heterogeneous sensor position information\nand structural boundary conditions built into the GP model. Results demonstrate\nthat the proposed approach is effective at identifying structural parameters\nand is capable of fusing data from heterogeneous and multi-fidelity sensors.\nProbabilistic predictions of structural responses and internal forces are in\ncloser agreement with measured data. We validate our model with an experimental\nsetup and discuss the quality and uncertainty of the obtained results. The\nproposed approach has potential applications in the field of structural health\nmonitoring (SHM) for both mechanical and structural systems.",
          "link": "http://arxiv.org/abs/2309.11875",
          "publishedOn": "2023-09-23T00:40:39.876Z",
          "wordCount": 752,
          "title": "Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes. (arXiv:2309.11875v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giordani_L/0/1/0/all/0/1\">Luiz Giordani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daru_G/0/1/0/all/0/1\">Gilsiley Dar&#xfa;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Queiroz_R/0/1/0/all/0/1\">Rhenan Queiroz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buzinaro_V/0/1/0/all/0/1\">Vitor Buzinaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiva_D/0/1/0/all/0/1\">Davi Keglevich Neiva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzman_D/0/1/0/all/0/1\">Daniel Camilo Fuentes Guzm&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_M/0/1/0/all/0/1\">Marcos Jardel Henriques</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junior_O/0/1/0/all/0/1\">Oilson Alberto Gonzatto Junior</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louzada_F/0/1/0/all/0/1\">Francisco Louzada</a>",
          "description": "The proliferation of fake news has become a significant concern in recent\ntimes due to its potential to spread misinformation and manipulate public\nopinion. This paper presents a comprehensive study on detecting fake news in\nBrazilian Portuguese, focusing on journalistic-type news. We propose a machine\nlearning-based approach that leverages natural language processing techniques,\nincluding TF-IDF and Word2Vec, to extract features from textual data. We\nevaluate the performance of various classification algorithms, such as logistic\nregression, support vector machine, random forest, AdaBoost, and LightGBM, on a\ndataset containing both true and fake news articles. The proposed approach\nachieves high accuracy and F1-Score, demonstrating its effectiveness in\nidentifying fake news. Additionally, we developed a user-friendly web platform,\nfakenewsbr.com, to facilitate the verification of news articles' veracity. Our\nplatform provides real-time analysis, allowing users to assess the likelihood\nof fake news articles. Through empirical analysis and comparative studies, we\ndemonstrate the potential of our approach to contribute to the fight against\nthe spread of fake news and promote more informed media consumption.",
          "link": "http://arxiv.org/abs/2309.11052",
          "publishedOn": "2023-09-23T00:40:39.871Z",
          "wordCount": 766,
          "title": "fakenewsbr: A Fake News Detection Platform for Brazilian Portuguese. (arXiv:2309.11052v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jamie Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yusen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayssen_H/0/1/0/all/0/1\">Hilary Hayssen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Englum_B/0/1/0/all/0/1\">Brain Englum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kankaria_A/0/1/0/all/0/1\">Aman Kankaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayorga_Carlin_M/0/1/0/all/0/1\">Minerva Mayorga-Carlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahoo_S/0/1/0/all/0/1\">Shalini Sahoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorkin_J/0/1/0/all/0/1\">John Sorkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_B/0/1/0/all/0/1\">Brajesh Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yesha_Y/0/1/0/all/0/1\">Yelena Yesha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>",
          "description": "Rapid and accurate identification of Venous thromboembolism (VTE), a severe\ncardiovascular condition including deep vein thrombosis (DVT) and pulmonary\nembolism (PE), is important for effective treatment. Leveraging Natural\nLanguage Processing (NLP) on radiology reports, automated methods have shown\npromising advancements in identifying VTE events from retrospective data\ncohorts or aiding clinical experts in identifying VTE events from radiology\nreports. However, effectively training Deep Learning (DL) and the NLP models is\nchallenging due to limited labeled medical text data, the complexity and\nheterogeneity of radiology reports, and data imbalance. This study proposes\nnovel method combinations of DL methods, along with data augmentation, adaptive\npre-trained NLP model selection, and a clinical expert NLP rule-based\nclassifier, to improve the accuracy of VTE identification in unstructured\n(free-text) radiology reports. Our experimental results demonstrate the model's\nefficacy, achieving an impressive 97\\% accuracy and 97\\% F1 score in predicting\nDVT, and an outstanding 98.3\\% accuracy and 98.4\\% F1 score in predicting PE.\nThese findings emphasize the model's robustness and its potential to\nsignificantly contribute to VTE research.",
          "link": "http://arxiv.org/abs/2309.12273",
          "publishedOn": "2023-09-23T00:40:39.859Z",
          "wordCount": 719,
          "title": "Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports. (arXiv:2309.12273v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suwala_A/0/1/0/all/0/1\">Adrian Suwa&#x142;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojcik_B/0/1/0/all/0/1\">Bartosz W&#xf3;jcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proszewska_M/0/1/0/all/0/1\">Magdalena Proszewska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1\">Przemys&#x142;aw Spurek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1\">Marek &#x15a;mieja</a>",
          "description": "Conditional GANs are frequently used for manipulating the attributes of face\nimages, such as expression, hairstyle, pose, or age. Even though the\nstate-of-the-art models successfully modify the requested attributes, they\nsimultaneously modify other important characteristics of the image, such as a\nperson's identity. In this paper, we focus on solving this problem by\nintroducing PluGeN4Faces, a plugin to StyleGAN, which explicitly disentangles\nface attributes from a person's identity. Our key idea is to perform training\non images retrieved from movie frames, where a given person appears in various\nposes and with different attributes. By applying a type of contrastive loss, we\nencourage the model to group images of the same person in similar regions of\nlatent space. Our experiments demonstrate that the modifications of face\nattributes performed by PluGeN4Faces are significantly less invasive on the\nremaining characteristics of the image than in the existing state-of-the-art\nmodels.",
          "link": "http://arxiv.org/abs/2309.12033",
          "publishedOn": "2023-09-23T00:40:39.843Z",
          "wordCount": 640,
          "title": "Face Identity-Aware Disentanglement in StyleGAN. (arXiv:2309.12033v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.01918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1\">Kevin C. Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1\">Shuchin Aeron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1\">Michael C. Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_E/0/1/0/all/0/1\">Eric L. Miller</a>",
          "description": "We consider probabilistic models for sequential observations which exhibit\ngradual transitions among a finite number of states. We are particularly\nmotivated by applications such as human activity analysis where observed\naccelerometer time series contains segments representing distinct activities,\nwhich we call pure states, as well as periods characterized by continuous\ntransition among these pure states. To capture this transitory behavior, the\ndynamical Wasserstein barycenter (DWB) model of Cheng et al. in 2021 [1]\nassociates with each pure state a data-generating distribution and models the\ncontinuous transitions among these states as a Wasserstein barycenter of these\ndistributions with dynamically evolving weights. Focusing on the univariate\ncase where Wasserstein distances and barycenters can be computed in closed\nform, we extend [1] specifically relaxing the parameterization of the pure\nstates as Gaussian distributions. We highlight issues related to the uniqueness\nin identifying the model parameters as well as uncertainties induced when\nestimating a dynamically evolving distribution from a limited number of\nsamples. To ameliorate non-uniqueness, we introduce regularization that imposes\ntemporal smoothness on the dynamics of the barycentric weights. A\nquantile-based approximation of the pure state distributions yields a finite\ndimensional estimation problem which we numerically solve using cyclic descent\nalternating between updates to the pure-state quantile functions and the\nbarycentric weights. We demonstrate the utility of the proposed algorithm in\nsegmenting both simulated and real world human activity time series.",
          "link": "http://arxiv.org/abs/2210.01918",
          "publishedOn": "2023-09-23T00:40:39.836Z",
          "wordCount": 797,
          "title": "Nonparametric and Regularized Dynamical Wasserstein Barycenters for Sequential Observations. (arXiv:2210.01918v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1\">Akshay J Dave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vilim_R/0/1/0/all/0/1\">Richard B. Vilim</a>",
          "description": "This work introduces Physics-informed State-space neural network Models\n(PSMs), a novel solution to achieving real-time optimization, flexibility, and\nfault tolerance in autonomous systems, particularly in transport-dominated\nsystems such as chemical, biomedical, and power plants. Traditional data-driven\nmethods fall short due to a lack of physical constraints like mass\nconservation; PSMs address this issue by training deep neural networks with\nsensor data and physics-informing using components' Partial Differential\nEquations (PDEs), resulting in a physics-constrained, end-to-end differentiable\nforward dynamics model. Through two in silico experiments - a heated channel\nand a cooling system loop - we demonstrate that PSMs offer a more accurate\napproach than purely data-driven models.\n\nBeyond accuracy, there are several compelling use cases for PSMs. In this\nwork, we showcase two: the creation of a nonlinear supervisory controller\nthrough a sequentially updated state-space representation and the proposal of a\ndiagnostic algorithm using residuals from each of the PDEs. The former\ndemonstrates the ability of PSMs to handle both constant and time-dependent\nconstraints, while the latter illustrates their value in system diagnostics and\nfault detection. We further posit that PSMs could serve as a foundation for\nDigital Twins, constantly updated digital representations of physical systems.",
          "link": "http://arxiv.org/abs/2309.12211",
          "publishedOn": "2023-09-23T00:40:39.831Z",
          "wordCount": 714,
          "title": "Physics-informed State-space Neural Networks for Transport Phenomena. (arXiv:2309.12211v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alagoz_C/0/1/0/all/0/1\">Celal Alagoz</a>",
          "description": "This study introduces a novel hierarchical divisive clustering approach with\nstochastic splitting functions (SSFs) to enhance classification performance in\nmulti-class datasets through hierarchical classification (HC). The method has\nthe unique capability of generating hierarchy without requiring explicit\ninformation, making it suitable for datasets lacking prior knowledge of\nhierarchy. By systematically dividing classes into two subsets based on their\ndiscriminability according to the classifier, the proposed approach constructs\na binary tree representation of hierarchical classes. The approach is evaluated\non 46 multi-class time series datasets using popular classifiers (svm and\nrocket) and SSFs (potr, srtr, and lsoo). The results reveal that the approach\nsignificantly improves classification performance in approximately half and a\nthird of the datasets when using rocket and svm as the classifier,\nrespectively. The study also explores the relationship between dataset features\nand HC performance. While the number of classes and flat classification (FC)\nscore show consistent significance, variations are observed with different\nsplitting functions. Overall, the proposed approach presents a promising\nstrategy for enhancing classification by generating hierarchical structure in\nmulti-class time series datasets. Future research directions involve exploring\ndifferent splitting functions, classifiers, and hierarchy structures, as well\nas applying the approach to diverse domains beyond time series data. The source\ncode is made openly available to facilitate reproducibility and further\nexploration of the method.",
          "link": "http://arxiv.org/abs/2309.11963",
          "publishedOn": "2023-09-23T00:40:39.819Z",
          "wordCount": 719,
          "title": "Generating Hierarchical Structures for Improved Time Series Classification Using Stochastic Splitting Functions. (arXiv:2309.11963v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.08587",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ajay_A/0/1/0/all/0/1\">Anurag Ajay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Seungwook Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yilun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhi Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Josh Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1\">Leslie Kaelbling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Akash Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>",
          "description": "To make effective decisions in novel environments with long-horizon goals, it\nis crucial to engage in hierarchical reasoning across spatial and temporal\nscales. This entails planning abstract subgoal sequences, visually reasoning\nabout the underlying plans, and executing actions in accordance with the\ndevised plan through visual-motor control. We propose Compositional Foundation\nModels for Hierarchical Planning (HiP), a foundation model which leverages\nmultiple expert foundation model trained on language, vision and action data\nindividually jointly together to solve long-horizon tasks. We use a large\nlanguage model to construct symbolic plans that are grounded in the environment\nthrough a large video diffusion model. Generated video plans are then grounded\nto visual-motor control, through an inverse dynamics model that infers actions\nfrom generated videos. To enable effective reasoning within this hierarchy, we\nenforce consistency between the models via iterative refinement. We illustrate\nthe efficacy and adaptability of our approach in three different long-horizon\ntable-top manipulation tasks.",
          "link": "http://arxiv.org/abs/2309.08587",
          "publishedOn": "2023-09-23T00:40:39.814Z",
          "wordCount": 689,
          "title": "Compositional Foundation Models for Hierarchical Planning. (arXiv:2309.08587v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruida Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_R/0/1/0/all/0/1\">Raymond Chi-Wing Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weile Tan</a>",
          "description": "Session-based recommendation, aiming at making the prediction of the user's\nnext item click based on the information in a single session only even in the\npresence of some random user's behavior, is a complex problem. This complex\nproblem requires a high-capability model of predicting the user's next action.\nMost (if not all) existing models follow the encoder-predictor paradigm where\nall studies focus on how to optimize the encoder module extensively in the\nparadigm but they ignore how to optimize the predictor module. In this paper,\nwe discover the existing critical issue of the low-capability predictor module\namong existing models. Motivated by this, we propose a novel framework called\n\\emph{\\underline{S}ession-based \\underline{R}ecommendation with\n\\underline{Pred}ictor \\underline{A}dd-\\underline{O}n} (SR-PredictAO). In this\nframework, we propose a high-capability predictor module which could alleviate\nthe effect of random user's behavior for prediction. It is worth mentioning\nthat this framework could be applied to any existing models, which could give\nopportunities for further optimizing the framework. Extensive experiments on\ntwo real benchmark datasets for three state-of-the-art models show that\n\\emph{SR-PredictAO} out-performs the current state-of-the-art model by up to\n2.9\\% in HR@20 and 2.3\\% in MRR@20. More importantly, the improvement is\nconsistent across almost all the existing models on all datasets, which could\nbe regarded as a significant contribution in the field.",
          "link": "http://arxiv.org/abs/2309.12218",
          "publishedOn": "2023-09-23T00:40:39.807Z",
          "wordCount": 703,
          "title": "SR-PredictAO: Session-based Recommendation with High-Capability Predictor Add-On. (arXiv:2309.12218v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seweryn_K/0/1/0/all/0/1\">Karolina Seweryn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wroblewska_A/0/1/0/all/0/1\">Anna Wr&#xf3;blewska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasik_S/0/1/0/all/0/1\">Szymon &#x141;ukasik</a>",
          "description": "Action scene understanding in soccer is a challenging task due to the complex\nand dynamic nature of the game, as well as the interactions between players.\nThis article provides a comprehensive overview of this task divided into action\nrecognition, spotting, and spatio-temporal action localization, with a\nparticular emphasis on the modalities used and multimodal methods. We explore\nthe publicly available data sources and metrics used to evaluate models'\nperformance. The article reviews recent state-of-the-art methods that leverage\ndeep learning techniques and traditional methods. We focus on multimodal\nmethods, which integrate information from multiple sources, such as video and\naudio data, and also those that represent one source in various ways. The\nadvantages and limitations of methods are discussed, along with their potential\nfor improving the accuracy and robustness of models. Finally, the article\nhighlights some of the open research questions and future directions in the\nfield of soccer action recognition, including the potential for multimodal\nmethods to advance this field. Overall, this survey provides a valuable\nresource for researchers interested in the field of action scene understanding\nin soccer.",
          "link": "http://arxiv.org/abs/2309.12067",
          "publishedOn": "2023-09-23T00:40:39.791Z",
          "wordCount": 715,
          "title": "Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer -- Current Trends and Research Perspectives. (arXiv:2309.12067v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhimin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1\">Taiping Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bangjie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_R/0/1/0/all/0/1\">Ran Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1\">Shouhong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lizhuang Ma</a>",
          "description": "The challenge in sourcing attribution for forgery faces has gained widespread\nattention due to the rapid development of generative techniques. While many\nrecent works have taken essential steps on GAN-generated faces, more\nthreatening attacks related to identity swapping or expression transferring are\nstill overlooked. And the forgery traces hidden in unknown attacks from the\nopen-world unlabeled faces still remain under-explored. To push the related\nfrontier research, we introduce a new benchmark called Open-World DeepFake\nAttribution (OW-DFA), which aims to evaluate attribution performance against\nvarious types of fake faces under open-world scenarios. Meanwhile, we propose a\nnovel framework named Contrastive Pseudo Learning (CPL) for the OW-DFA task\nthrough 1) introducing a Global-Local Voting module to guide the feature\nalignment of forged faces with different manipulated regions, 2) designing a\nConfidence-based Soft Pseudo-label strategy to mitigate the pseudo-noise caused\nby similar methods in unlabeled set. In addition, we extend the CPL framework\nwith a multi-stage paradigm that leverages pre-train technique and iterative\nlearning to further enhance traceability performance. Extensive experiments\nverify the superiority of our proposed method on the OW-DFA and also\ndemonstrate the interpretability of deepfake attribution task and its impact on\nimproving the security of deepfake detection area.",
          "link": "http://arxiv.org/abs/2309.11132",
          "publishedOn": "2023-09-23T00:40:39.746Z",
          "wordCount": 715,
          "title": "Contrastive Pseudo Learning for Open-World DeepFake Attribution. (arXiv:2309.11132v1 [cs.CV] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lim_Y/0/1/0/all/0/1\">Yi Heng Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selfridge_J/0/1/0/all/0/1\">Joshua Selfridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasim_M/0/1/0/all/0/1\">Muhammad Firmansyah Kasim</a>",
          "description": "Sequential models, such as Recurrent Neural Networks and Neural Ordinary\nDifferential Equations, have long suffered from slow training due to their\ninherent sequential nature. For many years this bottleneck has persisted, as\nmany thought sequential models could not be parallelized. We challenge this\nlong-held belief with our parallel algorithm that accelerates GPU evaluation of\nsequential models by up to 3 orders of magnitude faster without compromising\noutput accuracy. The algorithm does not need any special structure in the\nsequential models' architecture, making it applicable to a wide range of\narchitectures. Using our method, training sequential models can be more than 10\ntimes faster than the common sequential method without any meaningful\ndifference in the training results. Leveraging this accelerated training, we\ndiscovered the efficacy of the Gated Recurrent Unit in a long time series\nclassification problem with 17k time samples. By overcoming the training\nbottleneck, our work serves as the first step to unlock the potential of\nnon-linear sequential models for long sequence problems.",
          "link": "http://arxiv.org/abs/2309.12252",
          "publishedOn": "2023-09-23T00:40:39.735Z",
          "wordCount": 681,
          "title": "Parallelizing non-linear sequential models over the sequence length. (arXiv:2309.12252v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.00216",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deng_R/0/1/0/all/0/1\">Ruining Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cui_C/0/1/0/all/0/1\">Can Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Remedios_L/0/1/0/all/0/1\">Lucas W. Remedios</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bao_S/0/1/0/all/0/1\">Shunxing Bao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Womick_R/0/1/0/all/0/1\">R. Michael Womick</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chiron_S/0/1/0/all/0/1\">Sophie Chiron</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Roland_J/0/1/0/all/0/1\">Joseph T. Roland</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lau_K/0/1/0/all/0/1\">Ken S. Lau</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wilson_K/0/1/0/all/0/1\">Keith T. Wilson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yaohong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Coburn_L/0/1/0/all/0/1\">Lori A. Coburn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huo_Y/0/1/0/all/0/1\">Yuankai Huo</a>",
          "description": "Analyzing high resolution whole slide images (WSIs) with regard to\ninformation across multiple scales poses a significant challenge in digital\npathology. Multi-instance learning (MIL) is a common solution for working with\nhigh resolution images by classifying bags of objects (i.e. sets of smaller\nimage patches). However, such processing is typically performed at a single\nscale (e.g., 20x magnification) of WSIs, disregarding the vital inter-scale\ninformation that is key to diagnoses by human pathologists. In this study, we\npropose a novel cross-scale MIL algorithm to explicitly aggregate inter-scale\nrelationships into a single MIL network for pathological image diagnosis. The\ncontribution of this paper is three-fold: (1) A novel cross-scale MIL (CS-MIL)\nalgorithm that integrates the multi-scale information and the inter-scale\nrelationships is proposed; (2) A toy dataset with scale-specific morphological\nfeatures is created and released to examine and visualize differential\ncross-scale attention; (3) Superior performance on both in-house and public\ndatasets is demonstrated by our simple cross-scale MIL strategy. The official\nimplementation is publicly available at https://github.com/hrlblab/CS-MIL.",
          "link": "http://arxiv.org/abs/2304.00216",
          "publishedOn": "2023-09-23T00:40:39.699Z",
          "wordCount": 724,
          "title": "Cross-scale Multi-instance Learning for Pathological Image Diagnosis. (arXiv:2304.00216v2 [eess.IV] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yusen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yesha_Y/0/1/0/all/0/1\">Yelena Yesha</a>",
          "description": "Stochastic Gradient Descent (SGD), a widely used optimization algorithm in\ndeep learning, is often limited to converging to local optima due to the\nnon-convex nature of the problem. Leveraging these local optima to improve\nmodel performance remains a challenging task. Given the inherent complexity of\nneural networks, the simple arithmetic averaging of the obtained local optima\nmodels in undesirable results. This paper proposes a {\\em soft merging} method\nthat facilitates rapid merging of multiple models, simplifies the merging of\nspecific parts of neural networks, and enhances robustness against malicious\nmodels with extreme values. This is achieved by learning gate parameters\nthrough a surrogate of the $l_0$ norm using hard concrete distribution without\nmodifying the model weights of the given local optima models. This merging\nprocess not only enhances the model performance by converging to a better local\noptimum, but also minimizes computational costs, offering an efficient and\nexplicit learning process integrated with stochastic gradient descent. Thorough\nexperiments underscore the effectiveness and superior performance of the merged\nneural networks.",
          "link": "http://arxiv.org/abs/2309.12259",
          "publishedOn": "2023-09-23T00:40:39.608Z",
          "wordCount": null,
          "title": "Soft Merging: A Flexible and Robust Soft Model Merging Approach for Enhanced Neural Network Performance. (arXiv:2309.12259v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12245",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Saad_M/0/1/0/all/0/1\">Muhammad Muneeb Saad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rehmani_M/0/1/0/all/0/1\">Mubashir Husain Rehmani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OReilly_R/0/1/0/all/0/1\">Ruairi O&#x27;Reilly</a>",
          "description": "Biomedical image datasets can be imbalanced due to the rarity of targeted\ndiseases. Generative Adversarial Networks play a key role in addressing this\nimbalance by enabling the generation of synthetic images to augment datasets.\nIt is important to generate synthetic images that incorporate a diverse range\nof features to accurately represent the distribution of features present in the\ntraining imagery. Furthermore, the absence of diverse features in synthetic\nimages can degrade the performance of machine learning classifiers. The mode\ncollapse problem impacts Generative Adversarial Networks' capacity to generate\ndiversified images. Mode collapse comes in two varieties: intra-class and\ninter-class. In this paper, both varieties of the mode collapse problem are\ninvestigated, and their subsequent impact on the diversity of synthetic X-ray\nimages is evaluated. This work contributes an empirical demonstration of the\nbenefits of integrating the adaptive input-image normalization with the Deep\nConvolutional GAN and Auxiliary Classifier GAN to alleviate the mode collapse\nproblems. Synthetically generated images are utilized for data augmentation and\ntraining a Vision Transformer model. The classification performance of the\nmodel is evaluated using accuracy, recall, and precision scores. Results\ndemonstrate that the DCGAN and the ACGAN with adaptive input-image\nnormalization outperform the DCGAN and ACGAN with un-normalized X-ray images as\nevidenced by the superior diversity scores and classification scores.",
          "link": "http://arxiv.org/abs/2309.12245",
          "publishedOn": "2023-09-23T00:40:39.602Z",
          "wordCount": null,
          "title": "Adaptive Input-image Normalization for Solving Mode Collapse Problem in GAN-based X-ray Images. (arXiv:2309.12245v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.13019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCarthy_R/0/1/0/all/0/1\">Robert McCarthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulens_D/0/1/0/all/0/1\">David Cordova Bulens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_F/0/1/0/all/0/1\">Francisco Roldan Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGuinness_K/0/1/0/all/0/1\">Kevin McGuinness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1\">Noel E. O&#x27;Connor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redmond_S/0/1/0/all/0/1\">Stephen J. Redmond</a>",
          "description": "This paper presents our solution for the Real Robot Challenge (RRC) III, a\ncompetition featured in the NeurIPS 2022 Competition Track, aimed at addressing\ndexterous robotic manipulation tasks through learning from pre-collected\noffline data. Participants were provided with two types of datasets for each\ntask: expert and mixed datasets with varying skill levels. While the simplest\noffline policy learning algorithm, Behavioral Cloning (BC), performed\nremarkably well when trained on expert datasets, it outperformed even the most\nadvanced offline reinforcement learning (RL) algorithms. However, BC's\nperformance deteriorated when applied to mixed datasets, and the performance of\noffline RL algorithms was also unsatisfactory. Upon examining the mixed\ndatasets, we observed that they contained a significant amount of expert data,\nalthough this data was unlabeled. To address this issue, we proposed a\nsemi-supervised learning-based classifier to identify the underlying expert\nbehavior within mixed datasets, effectively isolating the expert data. To\nfurther enhance BC's performance, we leveraged the geometric symmetry of the\nRRC arena to augment the training dataset through mathematical transformations.\nIn the end, our submission surpassed that of all other participants, even those\nwho employed complex offline RL algorithms and intricate data processing and\nfeature engineering techniques.",
          "link": "http://arxiv.org/abs/2301.13019",
          "publishedOn": "2023-09-23T00:40:39.602Z",
          "wordCount": null,
          "title": "Identifying Expert Behavior in Offline Training Datasets Improves Behavioral Cloning of Robotic Manipulation Policies. (arXiv:2301.13019v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12202",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jafari_M/0/1/0/all/0/1\">Mahboobeh Jafari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sadeghi_D/0/1/0/all/0/1\">Delaram Sadeghi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shoeibi_A/0/1/0/all/0/1\">Afshin Shoeibi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alinejad_Rokny_H/0/1/0/all/0/1\">Hamid Alinejad-Rokny</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beheshti_A/0/1/0/all/0/1\">Amin Beheshti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garcia_D/0/1/0/all/0/1\">David L&#xf3;pez Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zhaolin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Acharya_U/0/1/0/all/0/1\">U. Rajendra Acharya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gorriz_J/0/1/0/all/0/1\">Juan M. Gorriz</a>",
          "description": "Schizophrenia (SZ) is a prevalent mental disorder characterized by cognitive,\nemotional, and behavioral changes. Symptoms of SZ include hallucinations,\nillusions, delusions, lack of motivation, and difficulties in concentration.\nDiagnosing SZ involves employing various tools, including clinical interviews,\nphysical examinations, psychological evaluations, the Diagnostic and\nStatistical Manual of Mental Disorders (DSM), and neuroimaging techniques.\nElectroencephalography (EEG) recording is a significant functional neuroimaging\nmodality that provides valuable insights into brain function during SZ.\nHowever, EEG signal analysis poses challenges for neurologists and scientists\ndue to the presence of artifacts, long-term recordings, and the utilization of\nmultiple channels. To address these challenges, researchers have introduced\nartificial intelligence (AI) techniques, encompassing conventional machine\nlearning (ML) and deep learning (DL) methods, to aid in SZ diagnosis. This\nstudy reviews papers focused on SZ diagnosis utilizing EEG signals and AI\nmethods. The introduction section provides a comprehensive explanation of SZ\ndiagnosis methods and intervention techniques. Subsequently, review papers in\nthis field are discussed, followed by an introduction to the AI methods\nemployed for SZ diagnosis and a summary of relevant papers presented in tabular\nform. Additionally, this study reports on the most significant challenges\nencountered in SZ diagnosis, as identified through a review of papers in this\nfield. Future directions to overcome these challenges are also addressed. The\ndiscussion section examines the specific details of each paper, culminating in\nthe presentation of conclusions and findings.",
          "link": "http://arxiv.org/abs/2309.12202",
          "publishedOn": "2023-09-23T00:40:39.601Z",
          "wordCount": null,
          "title": "Empowering Precision Medicine: AI-Driven Schizophrenia Diagnosis via EEG Signals: A Comprehensive Review from 2002-2023. (arXiv:2309.12202v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.16524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patil_S/0/1/0/all/0/1\">Saurabh Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zijie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1\">Amir Barati Farimani</a>",
          "description": "Numerically solving partial differential equations typically requires fine\ndiscretization to resolve necessary spatiotemporal scales, which can be\ncomputationally expensive. Recent advances in deep learning have provided a new\napproach to solving partial differential equations that involves the use of\nneural operators. Neural operators are neural network architectures that learn\nmappings between function spaces and have the capability to solve partial\ndifferential equations based on data. This study utilizes a novel neural\noperator called Hyena, which employs a long convolutional filter that is\nparameterized by a multilayer perceptron. The Hyena operator is an operation\nthat enjoys sub-quadratic complexity and state space model to parameterize long\nconvolution that enjoys a global receptive field. This mechanism enhances the\nmodel's comprehension of the input's context and enables data-dependent weight\nfor different partial differential equations instances. To measure how\neffective the layers are in solving partial differential equations, we conduct\nexperiments on Diffusion-Reaction equation and Navier Stokes equation. Our\nfindings indicate Hyena Neural operator can serve as an efficient and accurate\nmodel for learning partial differential equations solution operator. The data\nand code used can be found at:\nhttps://github.com/Saupatil07/Hyena-Neural-Operator",
          "link": "http://arxiv.org/abs/2306.16524",
          "publishedOn": "2023-09-23T00:40:39.601Z",
          "wordCount": 709,
          "title": "Hyena Neural Operator for Partial Differential Equations. (arXiv:2306.16524v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.10457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1\">Xinpeng Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kuncan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhili Chen</a>",
          "description": "Federated Learning (FL) is a distributed machine learning technique that\nallows model training among multiple devices or organizations by sharing\ntraining parameters instead of raw data. However, adversaries can still infer\nindividual information through inference attacks (e.g. differential attacks) on\nthese training parameters. As a result, Differential Privacy (DP) has been\nwidely used in FL to prevent such attacks. We consider differentially private\nfederated learning in a resource-constrained scenario, where both privacy\nbudget and communication round are constrained. By theoretically analyzing the\nconvergence, we can find the optimal number of differentially private local\niterations for clients between any two sequential global updates. Based on\nthis, we design an algorithm of differentially private federated learning with\nadaptive local iterations (ALI-DPFL). We experiment our algorithm on the\nFashionMNIST and CIFAR10 datasets, and demonstrate significantly better\nperformances than previous work in the resource-constraint scenario.",
          "link": "http://arxiv.org/abs/2308.10457",
          "publishedOn": "2023-09-23T00:40:39.601Z",
          "wordCount": null,
          "title": "ALI-DPFL: Differentially Private Federated Learning with Adaptive Local Iterations. (arXiv:2308.10457v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04474",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Xie_J/0/1/0/all/0/1\">Jianan Xie</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Liu_J/0/1/0/all/0/1\">Ji Liu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhang_C/0/1/0/all/0/1\">Chi Zhang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Chen_X/0/1/0/all/0/1\">Xihui Chen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Huai_P/0/1/0/all/0/1\">Ping Huai</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zheng_J/0/1/0/all/0/1\">Jie Zheng</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaofeng Zhang</a>",
          "description": "Serial femtosecond crystallography at X-ray free electron laser facilities\nopens a new era for the determination of crystal structure. However, the data\nprocessing of those experiments is facing unprecedented challenge, because the\ntotal number of diffraction patterns needed to determinate a high-resolution\nstructure is huge. Machine learning methods are very likely to play important\nroles in dealing with such a large volume of data. Convolutional neural\nnetworks have made a great success in the field of pattern classification,\nhowever, training of the networks need very large datasets with labels. Th is\nheavy dependence on labeled datasets will seriously restrict the application of\nnetworks, because it is very costly to annotate a large number of diffraction\npatterns. In this article we present our job on the classification of\ndiffraction pattern by weakly supervised algorithms, with the aim of reducing\nas much as possible the size of the labeled dataset required for training. Our\nresult shows that weakly supervised methods can significantly reduce the need\nfor the number of labeled patterns while achieving comparable accuracy to fully\nsupervised methods.",
          "link": "http://arxiv.org/abs/2309.04474",
          "publishedOn": "2023-09-23T00:40:39.601Z",
          "wordCount": null,
          "title": "Weakly supervised learning for pattern classification in serial femtosecond crystallography. (arXiv:2309.04474v2 [cond-mat.mtrl-sci] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.03392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rauniyar_A/0/1/0/all/0/1\">Ashish Rauniyar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagos_D/0/1/0/all/0/1\">Desta Haileselassie Hagos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_D/0/1/0/all/0/1\">Debesh Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haakegaard_J/0/1/0/all/0/1\">Jan Erik H&#xe5;keg&#xe5;rd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagci_U/0/1/0/all/0/1\">Ulas Bagci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawat_D/0/1/0/all/0/1\">Danda B. Rawat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlassov_V/0/1/0/all/0/1\">Vladimir Vlassov</a>",
          "description": "With the advent of the IoT, AI and ML/DL algorithms, the landscape of\ndata-driven medical applications has emerged as a promising avenue for\ndesigning robust and scalable diagnostic and prognostic models from medical\ndata. Consequently, the realm of data-driven medical applications has garnered\nsignificant attention spanning academia and industry, ushering in marked\nenhancements in healthcare delivery quality. Despite these strides, the\nadoption of AI-driven medical applications remains hindered by formidable\nchallenges, including the arduous task of meeting security, privacy, and\nquality of service (QoS) standards. Recent developments in federated learning\nhave made it possible to train complex machine-learned models in a distributed\nmanner and has become an active research domain, particularly processing the\nmedical data at the edge of the network in a decentralized way to preserve\nprivacy and address security concerns. To this end, this survey paper\nhighlights the current and future of FL technology in medical applications\nwhere data sharing is a significant burden. We delve into the contemporary\nresearch trends and their outcomes, unravelling the intricacies of designing\nreliable and scalable FL models. Our survey outlines the foundational\nstatistical predicaments of FL, confronts device-related obstacles, delves into\nsecurity challenges, and navigates the intricate terrain of privacy concerns,\nall while spotlighting its transformative potential within the medical domain.\nA primary focus of our study rests on medical applications, where we underscore\nthe weighty burden of global cancer and illuminate the potency of FL in\nengendering computer-aided diagnosis tools that address this challenge with\nheightened efficacy.",
          "link": "http://arxiv.org/abs/2208.03392",
          "publishedOn": "2023-09-23T00:40:39.589Z",
          "wordCount": null,
          "title": "Federated Learning for Medical Applications: A Taxonomy, Current Trends, Challenges, and Future Research Directions. (arXiv:2208.03392v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.08617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1\">Bla&#x17e; &#x160;krlj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ki_Tov_N/0/1/0/all/0/1\">Nir Ki-Tov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edelist_L/0/1/0/all/0/1\">Lee Edelist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silberstein_N/0/1/0/all/0/1\">Natalia Silberstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weisman_Zohar_H/0/1/0/all/0/1\">Hila Weisman-Zohar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mramor_B/0/1/0/all/0/1\">Bla&#x17e; Mramor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopic_D/0/1/0/all/0/1\">Davorin Kopi&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziporin_N/0/1/0/all/0/1\">Naama Ziporin</a>",
          "description": "Real-world production systems often grapple with maintaining data quality in\nlarge-scale, dynamic streams. We introduce Drifter, an efficient and\nlightweight system for online feature monitoring and verification in\nrecommendation use cases. Drifter addresses limitations of existing methods by\ndelivering agile, responsive, and adaptable data quality monitoring, enabling\nreal-time root cause analysis, drift detection and insights into problematic\nproduction events. Integrating state-of-the-art online feature ranking for\nsparse data and anomaly detection ideas, Drifter is highly scalable and\nresource-efficient, requiring only two threads and less than a gigabyte of RAM\nper production deployments that handle millions of instances per minute.\nEvaluation on real-world data sets demonstrates Drifter's effectiveness in\nalerting and mitigating data quality issues, substantially improving\nreliability and performance of real-time live recommender systems.",
          "link": "http://arxiv.org/abs/2309.08617",
          "publishedOn": "2023-09-23T00:40:39.589Z",
          "wordCount": null,
          "title": "Drifter: Efficient Online Feature Monitoring for Improved Data Integrity in Large-Scale Recommendation Systems. (arXiv:2309.08617v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCarthy_R/0/1/0/all/0/1\">Robert McCarthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulens_D/0/1/0/all/0/1\">David Cordova Bulens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGuinness_K/0/1/0/all/0/1\">Kevin McGuinness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1\">Noel E. O&#x27;Connor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurtler_N/0/1/0/all/0/1\">Nico G&#xfc;rtler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widmaier_F/0/1/0/all/0/1\">Felix Widmaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_F/0/1/0/all/0/1\">Francisco Roldan Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redmond_S/0/1/0/all/0/1\">Stephen J. Redmond</a>",
          "description": "Learning control policies offline from pre-recorded datasets is a promising\navenue for solving challenging real-world problems. However, available datasets\nare typically of mixed quality, with a limited number of the trajectories that\nwe would consider as positive examples; i.e., high-quality demonstrations.\nTherefore, we propose a novel iterative learning algorithm for identifying\nexpert trajectories in unlabeled mixed-quality robotics datasets given a\nminimal set of positive examples, surpassing existing algorithms in terms of\naccuracy. We show that applying behavioral cloning to the resulting filtered\ndataset outperforms several competitive offline reinforcement learning and\nimitation learning baselines. We perform experiments on a range of simulated\nlocomotion tasks and on two challenging manipulation tasks on a real robotic\nsystem; in these experiments, our method showcases state-of-the-art\nperformance. Our website:\n\\url{https://sites.google.com/view/offline-policy-learning-pubc}.",
          "link": "http://arxiv.org/abs/2301.11734",
          "publishedOn": "2023-09-23T00:40:39.580Z",
          "wordCount": null,
          "title": "Improving Behavioural Cloning with Positive Unlabeled Learning. (arXiv:2301.11734v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nan_Z/0/1/0/all/0/1\">Zheng Nan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1\">Ting Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethu_V/0/1/0/all/0/1\">Vidhyasaharan Sethu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_B/0/1/0/all/0/1\">Beena Ahmed</a>",
          "description": "Connectionist temporal classification (CTC) is commonly adopted for sequence\nmodeling tasks like speech recognition, where it is necessary to preserve order\nbetween the input and target sequences. However, CTC is only applied to\ndeterministic sequence models, where the latent space is discontinuous and\nsparse, which in turn makes them less capable of handling data variability when\ncompared to variational models. In this paper, we integrate CTC with a\nvariational model and derive loss functions that can be used to train more\ngeneralizable sequence models that preserve order. Specifically, we derive two\nversions of the novel variational CTC based on two reasonable assumptions, the\nfirst being that the variational latent variables at each time step are\nconditionally independent; and the second being that these latent variables are\nMarkovian. We show that both loss functions allow direct optimization of the\nvariational lower bound for the model log-likelihood, and present\ncomputationally tractable forms for implementing them.",
          "link": "http://arxiv.org/abs/2309.11983",
          "publishedOn": "2023-09-23T00:40:39.579Z",
          "wordCount": null,
          "title": "Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling. (arXiv:2309.11983v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weng_X/0/1/0/all/0/1\">Xu Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_K/0/1/0/all/0/1\">Keck Voon Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>",
          "description": "We present a neural network for mitigating pseudorange bias to improve\nlocalization performance with data collected from Android smartphones. We\nrepresent pseudorange bias using a pragmatic satellite-wise Multiple Layer\nPerceptron (MLP), the inputs of which are six\nsatellite-receiver-context-related features derived from Android raw Global\nNavigation Satellite System (GNSS) measurements. To supervise the training\nprocess, we carefully calculate the target values of pseudorange bias using\nlocation ground truth and smoothing techniques and optimize a loss function\ncontaining the estimation residuals of smartphone clock bias. During the\ninference process, we employ model-based localization engines to compute\nlocations with pseudoranges corrected by the neural network. Consequently, this\nhybrid pipeline can attend to both pseudorange bias and noise. We evaluate the\nframework on an open dataset and consider four application scenarios for\ninvestigating fingerprinting and cross-trace localization in rural and urban\nareas. Extensive experiments demonstrate that the proposed framework\noutperforms model-based and state-of-the-art data-driven approaches.",
          "link": "http://arxiv.org/abs/2309.12204",
          "publishedOn": "2023-09-23T00:40:39.579Z",
          "wordCount": null,
          "title": "PrNet: A Neural Network for Correcting Pseudoranges to Improve Positioning with Android Raw GNSS Measurements. (arXiv:2309.12204v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12223",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Polo_Lopez_L/0/1/0/all/0/1\">Lucas Polo-L&#xf3;pez</a> (IETR, INSA Rennes), <a href=\"http://arxiv.org/find/eess/1/au:+Magoarou_L/0/1/0/all/0/1\">Luc Le Magoarou</a> (INSA Rennes, IETR), <a href=\"http://arxiv.org/find/eess/1/au:+Contreres_R/0/1/0/all/0/1\">Romain Contreres</a> (CNES), <a href=\"http://arxiv.org/find/eess/1/au:+Garcia_Vigueras_M/0/1/0/all/0/1\">Mar&#xed;a Garc&#xed;a-Vigueras</a> (IETR, INSA Rennes)",
          "description": "This work presents a deep learning surrogate model for the fast simulation of\nhigh-dimensional frequency selective surfaces. We consider unit-cells which are\nbuilt as multiple concatenated stacks of screens and their design requires the\ncontrol over many geometrical degrees of freedom. Thanks to the introduction of\nphysical insight into the model, it can produce accurate predictions of the\nS-parameters of a certain structure after training with a reduced dataset.The\nproposed model is highly versatile and it can be used with any kind of\nfrequency selective surface, based on either perforations or patches of any\narbitrary geometry. Numeric examples are presented here for the case of\nfrequency selective surfaces composed of screens with rectangular perforations,\nshowing an excellent agreement between the predicted performance and such\nobtained with a full-wave simulator.",
          "link": "http://arxiv.org/abs/2309.12223",
          "publishedOn": "2023-09-23T00:40:39.579Z",
          "wordCount": null,
          "title": "Model-based Deep Learning for High-Dimensional Periodic Structures. (arXiv:2309.12223v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.10310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Hindawi_F/0/1/0/all/0/1\">Firas Al-Hindawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddiquee_M/0/1/0/all/0/1\">Md Mahfuzur Rahman Siddiquee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Teresa Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Ying Sun</a>",
          "description": "The ability to classify images is dependent on having access to large labeled\ndatasets and testing on data from the same domain that the model can train on.\nClassification becomes more challenging when dealing with new data from a\ndifferent domain, where gathering and especially labeling a larger image\ndataset for retraining a classification model requires a labor-intensive human\neffort. Cross-domain classification frameworks were developed to handle this\ndata domain shift problem by utilizing unsupervised image-to-image translation\nmodels to translate an input image from the unlabeled domain to the labeled\ndomain. The problem with these unsupervised models lies in their unsupervised\nnature. For lack of annotations, it is not possible to use the traditional\nsupervised metrics to evaluate these translation models to pick the best-saved\ncheckpoint model. This paper introduces a new method called Domain-knowledge\nInspired Pseudo Supervision (DIPS) which utilizes domain-informed Gaussian\nMixture Models to generate pseudo annotations to enable the use of traditional\nsupervised metrics. This method was designed specifically to support\ncross-domain classification applications contrary to other typically used\nmetrics such as the FID which were designed to evaluate the model in terms of\nthe quality of the generated image from a human-eye perspective. DIPS proves\nits effectiveness by outperforming various GAN evaluation metrics, including\nFID, when selecting the optimal saved checkpoint model. It is also evaluated\nagainst truly supervised metrics. Furthermore, DIPS showcases its robustness\nand interpretability by demonstrating a strong correlation with truly\nsupervised metrics, highlighting its superiority over existing state-of-the-art\nalternatives. The code and data to replicate the results can be found on the\nofficial Github repository: https://github.com/Hindawi91/DIPS",
          "link": "http://arxiv.org/abs/2303.10310",
          "publishedOn": "2023-09-23T00:40:39.579Z",
          "wordCount": null,
          "title": "Domain-knowledge Inspired Pseudo Supervision (DIPS) for Unsupervised Image-to-Image Translation Models to Support Cross-Domain Classification. (arXiv:2303.10310v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.03414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seah Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_H/0/1/0/all/0/1\">Hyoukjun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jinook Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1\">Jihyuck Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Hsin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Liangzhen Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>",
          "description": "Emerging real-time multi-model ML (RTMM) workloads such as AR/VR and drone\ncontrol involve dynamic behaviors in various granularity; task, model, and\nlayers within a model. Such dynamic behaviors introduce new challenges to the\nsystem software in an ML system since the overall system load is not completely\npredictable, unlike traditional ML workloads. In addition, RTMM workloads\nrequire real-time processing, involve highly heterogeneous models, and target\nresource-constrained devices. Under such circumstances, developing an effective\nscheduler gains more importance to better utilize underlying hardware\nconsidering the unique characteristics of RTMM workloads. Therefore, we propose\na new scheduler, DREAM, which effectively handles various dynamicity in RTMM\nworkloads targeting multi-accelerator systems. DREAM quantifies the unique\nrequirements for RTMM workloads and utilizes the quantified scores to drive\nscheduling decisions, considering the current system load and other inference\njobs on different models and input frames. DREAM utilizes tunable parameters\nthat provide fast and effective adaptivity to dynamic workload changes. In our\nevaluation of five scenarios of RTMM workload, DREAM reduces the overall\nUXCost, which is an equivalent metric of the energy-delay product (EDP) for\nRTMM defined in the paper, by 32.2% and 50.0% in the geometric mean (up to\n80.8% and 97.6%) compared to state-of-the-art baselines, which shows the\nefficacy of our scheduling methodology.",
          "link": "http://arxiv.org/abs/2212.03414",
          "publishedOn": "2023-09-23T00:40:39.578Z",
          "wordCount": null,
          "title": "DREAM: A Dynamic Scheduler for Dynamic Real-time Multi-model ML Workloads. (arXiv:2212.03414v2 [cs.DC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Minder_J/0/1/0/all/0/1\">Julian Minder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grotschla_F/0/1/0/all/0/1\">Florian Gr&#xf6;tschla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathys_J/0/1/0/all/0/1\">Jo&#xeb;l Mathys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>",
          "description": "We introduce an extension to the CLRS algorithmic learning benchmark,\nprioritizing scalability and the utilization of sparse representations. Many\nalgorithms in CLRS require global memory or information exchange, mirrored in\nits execution model, which constructs fully connected (not sparse) graphs based\non the underlying problem. Despite CLRS's aim of assessing how effectively\nlearned algorithms can generalize to larger instances, the existing execution\nmodel becomes a significant constraint due to its demanding memory requirements\nand runtime (hard to scale). However, many important algorithms do not demand a\nfully connected graph; these algorithms, primarily distributed in nature, align\nclosely with the message-passing paradigm employed by Graph Neural Networks.\nHence, we propose SALSA-CLRS, an extension of the current CLRS benchmark\nspecifically with scalability and sparseness in mind. Our approach includes\nadapted algorithms from the original CLRS benchmark and introduces new problems\nfrom distributed and randomized algorithms. Moreover, we perform a thorough\nempirical evaluation of our benchmark. Code is publicly available at\nhttps://github.com/jkminder/SALSA-CLRS.",
          "link": "http://arxiv.org/abs/2309.12253",
          "publishedOn": "2023-09-23T00:40:39.573Z",
          "wordCount": null,
          "title": "SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning. (arXiv:2309.12253v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09879",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masuyama_N/0/1/0/all/0/1\">Naoki Masuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nojima_Y/0/1/0/all/0/1\">Yusuke Nojima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawood_F/0/1/0/all/0/1\">Farhan Dawood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zongying Liu</a>",
          "description": "This paper proposes a supervised classification algorithm capable of\ncontinual learning by utilizing an Adaptive Resonance Theory (ART)-based\ngrowing self-organizing clustering algorithm. The ART-based clustering\nalgorithm is theoretically capable of continual learning, and the proposed\nalgorithm independently applies it to each class of training data for\ngenerating classifiers. Whenever an additional training data set from a new\nclass is given, a new ART-based clustering will be defined in a different\nlearning space. Thanks to the above-mentioned features, the proposed algorithm\nrealizes continual learning capability. Simulation experiments showed that the\nproposed algorithm has superior classification performance compared with\nstate-of-the-art clustering-based classification algorithms capable of\ncontinual learning.",
          "link": "http://arxiv.org/abs/2203.09879",
          "publishedOn": "2023-09-23T00:40:39.572Z",
          "wordCount": null,
          "title": "Class-wise Classifier Design Capable of Continual Learning using Adaptive Resonance Theory-based Topological Clustering. (arXiv:2203.09879v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.11278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jumin Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1\">Shuyuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lujun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miroshnichenko_A/0/1/0/all/0/1\">Andrey Miroshnichenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dejian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tingting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tianbao Yu</a>",
          "description": "The ultimate goal of artificial intelligence is to mimic the human brain to\nperform decision-making and control directly from high-dimensional sensory\ninput. Diffractive optical networks provide a promising solution for\nimplementing artificial intelligence with high-speed and low-power consumption.\nMost of the reported diffractive optical networks focus on single or multiple\ntasks that do not involve environmental interaction, such as object recognition\nand image classification. In contrast, the networks capable of performing\ndecision-making and control have not yet been developed to our knowledge. Here,\nwe propose using deep reinforcement learning to implement diffractive optical\nnetworks that imitate human-level decision-making and control capability. Such\nnetworks taking advantage of a residual architecture, allow for finding optimal\ncontrol policies through interaction with the environment and can be readily\nimplemented with existing optical devices. The superior performance of these\nnetworks is verified by engaging three types of classic games, Tic-Tac-Toe,\nSuper Mario Bros., and Car Racing. Finally, we present an experimental\ndemonstration of playing Tic-Tac-Toe by leveraging diffractive optical networks\nbased on a spatial light modulator. Our work represents a solid step forward in\nadvancing diffractive optical networks, which promises a fundamental shift from\nthe target-driven control of a pre-designed state for simple recognition or\nclassification tasks to the high-level sensory capability of artificial\nintelligence. It may find exciting applications in autonomous driving,\nintelligent robots, and intelligent manufacturing.",
          "link": "http://arxiv.org/abs/2212.11278",
          "publishedOn": "2023-09-23T00:40:39.572Z",
          "wordCount": null,
          "title": "Decision-making and control with diffractive optical networks. (arXiv:2212.11278v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04281",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Schindler_D/0/1/0/all/0/1\">Dominik J. Schindler</a>, <a href=\"http://arxiv.org/find/math/1/au:+Barahona_M/0/1/0/all/0/1\">Mauricio Barahona</a>",
          "description": "In many applications in data clustering, it is desirable to find not just a\nsingle partition into clusters but a sequence of partitions describing the data\nat different scales, or levels of coarseness. A natural problem then is to\nanalyse and compare the (not necessarily hierarchical) sequences of partitions\nthat underpin such multiscale descriptions of data. Here, we introduce a\nfiltration of abstract simplicial complexes, denoted the Multiscale Clustering\nFiltration (MCF), which encodes arbitrary patterns of cluster assignments\nacross scales, and we prove that the MCF produces stable persistence diagrams.\nWe then show that the zero-dimensional persistent homology of the MCF measures\nthe degree of hierarchy in the sequence of partitions, and that the\nhigher-dimensional persistent homology tracks the emergence and resolution of\nconflicts between cluster assignments across the sequence of partitions. To\nbroaden the theoretical foundations of the MCF, we also provide an equivalent\nconstruction via a nerve complex filtration, and we show that in the\nhierarchical case, the MCF reduces to a Vietoris-Rips filtration of an\nultrametric space. We briefly illustrate how the MCF can serve to characterise\nmultiscale clustering structures in numerical experiments on synthetic data.",
          "link": "http://arxiv.org/abs/2305.04281",
          "publishedOn": "2023-09-23T00:40:39.572Z",
          "wordCount": null,
          "title": "Persistent Homology of the Multiscale Clustering Filtration. (arXiv:2305.04281v2 [math.AT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stalder_S/0/1/0/all/0/1\">Steven Stalder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Volpi_M/0/1/0/all/0/1\">Michele Volpi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buttner_N/0/1/0/all/0/1\">Nicolas B&#xfc;ttner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_S/0/1/0/all/0/1\">Stephen Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harttgen_K/0/1/0/all/0/1\">Kenneth Harttgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suel_E/0/1/0/all/0/1\">Esra Suel</a>",
          "description": "Cities around the world face a critical shortage of affordable and decent\nhousing. Despite its critical importance for policy, our ability to effectively\nmonitor and track progress in urban housing is limited. Deep learning-based\ncomputer vision methods applied to street-level images have been successful in\nthe measurement of socioeconomic and environmental inequalities but did not\nfully utilize temporal images to track urban change as time-varying labels are\noften unavailable. We used self-supervised methods to measure change in London\nusing 15 million street images taken between 2008 and 2021. Our novel\nadaptation of Barlow Twins, Street2Vec, embeds urban structure while being\ninvariant to seasonal and daily changes without manual annotations. It\noutperformed generic embeddings, successfully identified point-level change in\nLondon's housing supply from street-level images, and distinguished between\nmajor and minor change. This capability can provide timely information for\nurban planning and policy decisions toward more liveable, equitable, and\nsustainable cities.",
          "link": "http://arxiv.org/abs/2309.11354",
          "publishedOn": "2023-09-23T00:40:39.572Z",
          "wordCount": null,
          "title": "Self-supervised learning unveils change in urban housing from street-level images. (arXiv:2309.11354v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smeu_S/0/1/0/all/0/1\">Stefan Smeu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burceanu_E/0/1/0/all/0/1\">Elena Burceanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haller_E/0/1/0/all/0/1\">Emanuela Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicolicioiu_A/0/1/0/all/0/1\">Andrei Liviu Nicolicioiu</a>",
          "description": "We tackle the problem of robust novelty detection, where we aim to detect\nnovelties in terms of semantic content while being invariant to changes in\nother, irrelevant factors. Specifically, we operate in a setup with multiple\nenvironments, where we determine the set of features that are associated more\nwith the environments, rather than to the content relevant for the task. Thus,\nwe propose a method that starts with a pretrained embedding and a multi-env\nsetup and manages to rank the features based on their environment-focus. First,\nwe compute a per-feature score based on the feature distribution variance\nbetween envs. Next, we show that by dropping the highly scored ones, we manage\nto remove spurious correlations and improve the overall performance by up to\n6%, both in covariance and sub-population shift cases, both for a real and a\nsynthetic benchmark, that we introduce for this task.",
          "link": "http://arxiv.org/abs/2309.12301",
          "publishedOn": "2023-09-23T00:40:39.571Z",
          "wordCount": null,
          "title": "Environment-biased Feature Ranking for Novelty Detection Robustness. (arXiv:2309.12301v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chaejeong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jayoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_N/0/1/0/all/0/1\">Noseong Park</a>",
          "description": "With growing attention to tabular data these days, the attempt to apply a\nsynthetic table to various tasks has been expanded toward various scenarios.\nOwing to the recent advances in generative modeling, fake data generated by\ntabular data synthesis models become sophisticated and realistic. However,\nthere still exists a difficulty in modeling discrete variables (columns) of\ntabular data. In this work, we propose to process continuous and discrete\nvariables separately (but being conditioned on each other) by two diffusion\nmodels. The two diffusion models are co-evolved during training by reading\nconditions from each other. In order to further bind the diffusion models,\nmoreover, we introduce a contrastive learning method with a negative sampling\nmethod. In our experiments with 11 real-world tabular datasets and 8 baseline\nmethods, we prove the efficacy of the proposed method, called CoDi.",
          "link": "http://arxiv.org/abs/2304.12654",
          "publishedOn": "2023-09-23T00:40:39.571Z",
          "wordCount": null,
          "title": "CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis. (arXiv:2304.12654v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sclocchi_A/0/1/0/all/0/1\">Antonio Sclocchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Modern deep networks are trained with stochastic gradient descent (SGD) whose\nkey parameters are the number of data considered at each step or batch size\n$B$, and the step size or learning rate $\\eta$. For small $B$ and large $\\eta$,\nSGD corresponds to a stochastic evolution of the parameters, whose noise\namplitude is governed by the `temperature' $T\\equiv \\eta/B$. Yet this\ndescription is observed to break down for sufficiently large batches $B\\geq\nB^*$, or simplifies to gradient descent (GD) when the temperature is\nsufficiently small. Understanding where these cross-overs take place remains a\ncentral challenge. Here we resolve these questions for a teacher-student\nperceptron classification model, and show empirically that our key predictions\nstill apply to deep networks. Specifically, we obtain a phase diagram in the\n$B$-$\\eta$ plane that separates three dynamical phases: $\\textit{(i)}$ a\nnoise-dominated SGD governed by temperature, $\\textit{(ii)}$ a\nlarge-first-step-dominated SGD and $\\textit{(iii)}$ GD. These different phases\nalso corresponds to different regimes of generalization error. Remarkably, our\nanalysis reveals that the batch size $B^*$ separating regimes $\\textit{(i)}$\nand $\\textit{(ii)}$ scale with the size $P$ of the training set, with an\nexponent that characterizes the hardness of the classification problem.",
          "link": "http://arxiv.org/abs/2309.10688",
          "publishedOn": "2023-09-23T00:40:39.571Z",
          "wordCount": null,
          "title": "On the different regimes of Stochastic Gradient Descent. (arXiv:2309.10688v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.05355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_L/0/1/0/all/0/1\">Luciana Ferrer</a>",
          "description": "A variety of different performance metrics are commonly used in the machine\nlearning literature for the evaluation of classification systems. Some of the\nmost common ones for measuring quality of hard decisions are standard and\nbalanced accuracy, standard and balanced error rate, F-beta score, and Matthews\ncorrelation coefficient (MCC). In this document, we review the definition of\nthese and other metrics and compare them with the expected cost (EC), a metric\nintroduced in every statistical learning course but rarely used in the machine\nlearning literature. We show that both the standard and balanced error rates\nare special cases of the EC. Further, we show its relation with F-beta score\nand MCC and argue that EC is superior to these traditional metrics for being\nbased on first principles from statistics, and for being more general,\ninterpretable, and adaptable to any application scenario. The metrics mentioned\nabove measure the quality of hard decisions. Yet, most modern classification\nsystems output continuous scores for the classes which we may want to evaluate\ndirectly. Metrics for measuring the quality of system scores include the area\nunder the ROC curve, equal error rate, cross-entropy, Brier score, and Bayes EC\nor Bayes risk, among others. The last three metrics are special cases of a\nfamily of metrics given by the expected value of proper scoring rules (PSRs).\nWe review the theory behind these metrics, showing that they are a principled\nway to measure the quality of the posterior probabilities produced by a system.\nFinally, we show how to use these metrics to compute a system's calibration\nloss and compare this metric with the widely-used expected calibration error\n(ECE), arguing that calibration loss based on PSRs is superior to the ECE for\nbeing more interpretable, more general, and directly applicable to the\nmulti-class case, among other reasons.",
          "link": "http://arxiv.org/abs/2209.05355",
          "publishedOn": "2023-09-23T00:40:39.570Z",
          "wordCount": null,
          "title": "Analysis and Comparison of Classification Metrics. (arXiv:2209.05355v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_B/0/1/0/all/0/1\">Bo Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_K/0/1/0/all/0/1\">Kai Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tong Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min-Ling Zhang</a>",
          "description": "In open-world semi-supervised learning, a machine learning model is tasked\nwith uncovering novel categories from unlabeled data while maintaining\nperformance on seen categories from labeled data. The central challenge is the\nsubstantial learning gap between seen and novel categories, as the model learns\nthe former faster due to accurate supervisory information. To address this, we\nintroduce 1) an adaptive margin loss based on estimated class distribution,\nwhich encourages a large negative margin for samples in seen classes, to\nsynchronize learning paces, and 2) pseudo-label contrastive clustering, which\npulls together samples which are likely from the same class in the output\nspace, to enhance novel class discovery. Our extensive evaluations on multiple\ndatasets demonstrate that existing models still hinder novel class learning,\nwhereas our approach strikingly balances both seen and novel classes, achieving\na remarkable 3% average accuracy increase on the ImageNet dataset compared to\nthe prior state-of-the-art. Additionally, we find that fine-tuning the\nself-supervised pre-trained backbone significantly boosts performance over the\ndefault in prior literature. After our paper is accepted, we will release the\ncode.",
          "link": "http://arxiv.org/abs/2309.11930",
          "publishedOn": "2023-09-23T00:40:39.554Z",
          "wordCount": null,
          "title": "Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning. (arXiv:2309.11930v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Buskulic_N/0/1/0/all/0/1\">Nathan Buskulic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fadili_J/0/1/0/all/0/1\">Jalal Fadili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Queau_Y/0/1/0/all/0/1\">Yvain Qu&#xe9;au</a>",
          "description": "Neural networks have become a prominent approach to solve inverse problems in\nrecent years. While a plethora of such methods was developed to solve inverse\nproblems empirically, we are still lacking clear theoretical guarantees for\nthese methods. On the other hand, many works proved convergence to optimal\nsolutions of neural networks in a more general setting using\noverparametrization as a way to control the Neural Tangent Kernel. In this work\nwe investigate how to bridge these two worlds and we provide deterministic\nconvergence and recovery guarantees for the class of unsupervised feedforward\nmultilayer neural networks trained to solve inverse problems. We also derive\noverparametrization bounds under which a two-layers Deep Inverse Prior network\nwith smooth activation function will benefit from our guarantees.",
          "link": "http://arxiv.org/abs/2309.12128",
          "publishedOn": "2023-09-23T00:40:39.554Z",
          "wordCount": null,
          "title": "Convergence and Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems. (arXiv:2309.12128v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ha_D/0/1/0/all/0/1\">Dung T.K. Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_C/0/1/0/all/0/1\">Canh V. Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Tan D. Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_H/0/1/0/all/0/1\">Huan X. Hoang</a>",
          "description": "The problem of non-monotone $k$-submodular maximization under a knapsack\nconstraint ($\\kSMK$) over the ground set size $n$ has been raised in many\napplications in machine learning, such as data summarization, information\npropagation, etc. However, existing algorithms for the problem are facing\nquestioning of how to overcome the non-monotone case and how to fast return a\ngood solution in case of the big size of data. This paper introduces two\ndeterministic approximation algorithms for the problem that competitively\nimprove the query complexity of existing algorithms.\n\nOur first algorithm, $\\LAA$, returns an approximation ratio of $1/19$ within\n$O(nk)$ query complexity. The second one, $\\RLA$, improves the approximation\nratio to $1/5-\\epsilon$ in $O(nk)$ queries, where $\\epsilon$ is an input\nparameter.\n\nOur algorithms are the first ones that provide constant approximation ratios\nwithin only $O(nk)$ query complexity for the non-monotone objective. They,\ntherefore, need fewer the number of queries than state-of-the-the-art ones by a\nfactor of $\\Omega(\\log n)$.\n\nBesides the theoretical analysis, we have evaluated our proposed ones with\nseveral experiments in some instances: Influence Maximization and Sensor\nPlacement for the problem. The results confirm that our algorithms ensure\ntheoretical quality as the cutting-edge techniques and significantly reduce the\nnumber of queries.",
          "link": "http://arxiv.org/abs/2309.12025",
          "publishedOn": "2023-09-23T00:40:39.552Z",
          "wordCount": null,
          "title": "Robust Approximation Algorithms for Non-monotone $k$-Submodular Maximization under a Knapsack Constraint. (arXiv:2309.12025v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11745",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cao_X/0/1/0/all/0/1\">Xu Cao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liao_K/0/1/0/all/0/1\">Kuei-Da Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_T/0/1/0/all/0/1\">Tianren Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zhengyu Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nama_T/0/1/0/all/0/1\">Tejas Nama</a>",
          "description": "Disease progression simulation is a crucial area of research that has\nsignificant implications for clinical diagnosis, prognosis, and treatment. One\nmajor challenge in this field is the lack of continuous medical imaging\nmonitoring of individual patients over time. To address this issue, we develop\na novel framework termed Progressive Image Editing (PIE) that enables\ncontrolled manipulation of disease-related image features, facilitating precise\nand realistic disease progression simulation. Specifically, we leverage recent\nadvancements in text-to-image generative models to simulate disease progression\naccurately and personalize it for each patient. We theoretically analyze the\niterative refining process in our framework as a gradient descent with an\nexponentially decayed learning rate. To validate our framework, we conduct\nexperiments in three medical imaging domains. Our results demonstrate the\nsuperiority of PIE over existing methods such as Stable Diffusion Walk and\nStyle-Based Manifold Extrapolation based on CLIP score (Realism) and Disease\nClassification Confidence (Alignment). Our user study collected feedback from\n35 veteran physicians to assess the generated progressions. Remarkably, 76.2%\nof the feedback agrees with the fidelity of the generated progressions. To our\nbest knowledge, PIE is the first of its kind to generate disease progression\nimages meeting real-world standards. It is a promising tool for medical\nresearch and clinical practice, potentially allowing healthcare providers to\nmodel disease trajectories over time, predict future treatment responses, and\nimprove patient outcomes.",
          "link": "http://arxiv.org/abs/2309.11745",
          "publishedOn": "2023-09-23T00:40:39.550Z",
          "wordCount": null,
          "title": "PIE: Simulating Disease Progression via Progressive Image Editing. (arXiv:2309.11745v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chajewska_U/0/1/0/all/0/1\">Urszula Chajewska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_H/0/1/0/all/0/1\">Harsh Shrivastava</a>",
          "description": "Federated Learning (FL) addresses the need to create models based on\nproprietary data in such a way that multiple clients retain exclusive control\nover their data, while all benefit from improved model accuracy due to pooled\nresources. Recently proposed Neural Graphical Models (NGMs) are Probabilistic\nGraphical models that utilize the expressive power of neural networks to learn\ncomplex non-linear dependencies between the input features. They learn to\ncapture the underlying data distribution and have efficient algorithms for\ninference and sampling. We develop a FL framework which maintains a global NGM\nmodel that learns the averaged information from the local NGM models while\nkeeping the training data within the client's environment. Our design, FedNGMs,\navoids the pitfalls and shortcomings of neuron matching frameworks like\nFederated Matched Averaging that suffers from model parameter explosion. Our\nglobal model size remains constant throughout the process. In the cases where\nclients have local variables that are not part of the combined global\ndistribution, we propose a `Stitching' algorithm, which personalizes the global\nNGM models by merging the additional variables using the client's data. FedNGM\nis robust to data heterogeneity, large number of participants, and limited\ncommunication bandwidth.",
          "link": "http://arxiv.org/abs/2309.11680",
          "publishedOn": "2023-09-23T00:40:39.549Z",
          "wordCount": null,
          "title": "Federated Learning with Neural Graphical Models. (arXiv:2309.11680v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11979",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Lou_J/0/1/0/all/0/1\">Jiashu Lou</a>",
          "description": "With the rapid development of big data and computing devices, low-latency\nautomatic trading platforms based on real-time information acquisition have\nbecome the main components of the stock trading market, so the topic of\nquantitative trading has received widespread attention. And for non-strongly\nefficient trading markets, human emotions and expectations always dominate\nmarket trends and trading decisions. Therefore, this paper starts from the\ntheory of emotion, taking East Money as an example, crawling user comment\ntitles data from its corresponding stock bar and performing data cleaning.\nSubsequently, a natural language processing model BERT was constructed, and the\nBERT model was fine-tuned using existing annotated data sets. The experimental\nresults show that the fine-tuned model has different degrees of performance\nimprovement compared to the original model and the baseline model.\nSubsequently, based on the above model, the user comment data crawled is\nlabeled with emotional polarity, and the obtained label information is combined\nwith the Alpha191 model to participate in regression, and significant\nregression results are obtained. Subsequently, the regression model is used to\npredict the average price change for the next five days, and use it as a signal\nto guide automatic trading. The experimental results show that the\nincorporation of emotional factors increased the return rate by 73.8\\% compared\nto the baseline during the trading period, and by 32.41\\% compared to the\noriginal alpha191 model. Finally, we discuss the advantages and disadvantages\nof incorporating emotional factors into quantitative trading, and give possible\ndirections for further research in the future.",
          "link": "http://arxiv.org/abs/2309.11979",
          "publishedOn": "2023-09-23T00:40:39.536Z",
          "wordCount": null,
          "title": "Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT. (arXiv:2309.11979v1 [q-fin.CP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1\">Mahya Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alandihallaj_M/0/1/0/all/0/1\">M. Amin Alandihallaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Lopez_J/0/1/0/all/0/1\">Jose Luis Sanchez-Lopez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_A/0/1/0/all/0/1\">Andreas Hein</a>",
          "description": "This paper presents a Hierarchical Reinforcement Learning methodology\ntailored for optimizing CubeSat task scheduling in Low Earth Orbits (LEO).\nIncorporating a high-level policy for global task distribution and a low-level\npolicy for real-time adaptations as a safety mechanism, our approach integrates\nthe Similarity Attention-based Encoder (SABE) for task prioritization and an\nMLP estimator for energy consumption forecasting. Integrating this mechanism\ncreates a safe and fault-tolerant system for CubeSat task scheduling.\nSimulation results validate the Hierarchical Reinforcement Learning superior\nconvergence and task success rate, outperforming both the MADDPG model and\ntraditional random scheduling across multiple CubeSat configurations.",
          "link": "http://arxiv.org/abs/2309.12004",
          "publishedOn": "2023-09-23T00:40:39.535Z",
          "wordCount": 621,
          "title": "Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption. (arXiv:2309.12004v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11987",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jalali_A/0/1/0/all/0/1\">Anahid Jalali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haslhofer_B/0/1/0/all/0/1\">Bernhard Haslhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kriglstein_S/0/1/0/all/0/1\">Simone Kriglstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rauber_A/0/1/0/all/0/1\">Andreas Rauber</a>",
          "description": "Post-hoc explainability methods aim to clarify predictions of black-box\nmachine learning models. However, it is still largely unclear how well users\ncomprehend the provided explanations and whether these increase the users\nability to predict the model behavior. We approach this question by conducting\na user study to evaluate comprehensibility and predictability in two widely\nused tools: LIME and SHAP. Moreover, we investigate the effect of\ncounterfactual explanations and misclassifications on users ability to\nunderstand and predict the model behavior. We find that the comprehensibility\nof SHAP is significantly reduced when explanations are provided for samples\nnear a model's decision boundary. Furthermore, we find that counterfactual\nexplanations and misclassifications can significantly increase the users\nunderstanding of how a machine learning model is making decisions. Based on our\nfindings, we also derive design recommendations for future post-hoc\nexplainability methods with increased comprehensibility and predictability.",
          "link": "http://arxiv.org/abs/2309.11987",
          "publishedOn": "2023-09-23T00:40:39.530Z",
          "wordCount": null,
          "title": "Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis. (arXiv:2309.11987v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhengang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1\">Geng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamauchi_T/0/1/0/all/0/1\">Tomoharu Yamauchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masoud_Z/0/1/0/all/0/1\">Zabihi Masoud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yanyue Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_P/0/1/0/all/0/1\">Peiyan Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xulong Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_N/0/1/0/all/0/1\">Nobuyuki Yoshikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_D/0/1/0/all/0/1\">Devesh Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_O/0/1/0/all/0/1\">Olivia Chen</a>",
          "description": "Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with\nextremely high energy efficiency. By employing the distinct polarity of current\nto denote logic `0' and `1', AQFP devices serve as excellent carriers for\nbinary neural network (BNN) computations. Although recent research has made\ninitial strides toward developing an AQFP-based BNN accelerator, several\ncritical challenges remain, preventing the design from being a comprehensive\nsolution. In this paper, we propose SupeRBNN, an AQFP-based randomized BNN\nacceleration framework that leverages software-hardware co-optimization to\neventually make the AQFP devices a feasible solution for BNN acceleration.\nSpecifically, we investigate the randomized behavior of the AQFP devices and\nanalyze the impact of crossbar size on current attenuation, subsequently\nformulating the current amplitude into the values suitable for use in BNN\ncomputation. To tackle the accumulation problem and improve overall hardware\nperformance, we propose a stochastic computing-based accumulation module and a\nclocking scheme adjustment-based circuit optimization method. We validate our\nSupeRBNN framework across various datasets and network architectures, comparing\nit with implementations based on different technologies, including CMOS, ReRAM,\nand superconducting RSFQ/ERSFQ. Experimental results demonstrate that our\ndesign achieves an energy efficiency of approximately 7.8x10^4 times higher\nthan that of the ReRAM-based BNN framework while maintaining a similar level of\nmodel accuracy. Furthermore, when compared with superconductor-based\ncounterparts, our framework demonstrates at least two orders of magnitude\nhigher energy efficiency.",
          "link": "http://arxiv.org/abs/2309.12212",
          "publishedOn": "2023-09-23T00:40:39.452Z",
          "wordCount": 756,
          "title": "SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices. (arXiv:2309.12212v1 [cs.ET])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_N/0/1/0/all/0/1\">Nolan Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soboleva_D/0/1/0/all/0/1\">Daria Soboleva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Khateeb_F/0/1/0/all/0/1\">Faisal Al-Khateeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bowen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathria_R/0/1/0/all/0/1\">Ribhu Pathria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khachane_H/0/1/0/all/0/1\">Hemant Khachane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1\">Shaheer Muhammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhiming/0/1/0/all/0/1\">Zhiming</a> (Charles) <a href=\"http://arxiv.org/find/cs/1/au:+Chen/0/1/0/all/0/1\">Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_R/0/1/0/all/0/1\">Robert Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steeves_J/0/1/0/all/0/1\">Jacob Robert Steeves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassilieva_N/0/1/0/all/0/1\">Natalia Vassilieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tom_M/0/1/0/all/0/1\">Marvin Tom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1\">Joel Hestness</a>",
          "description": "We introduce the Bittensor Language Model, called \"BTLM-3B-8K\", a new\nstate-of-the-art 3 billion parameter open-source language model. BTLM-3B-8K was\ntrained on 627B tokens from the SlimPajama dataset with a mixture of 2,048 and\n8,192 context lengths. BTLM-3B-8K outperforms all existing 3B parameter models\nby 2-5.5% across downstream tasks. BTLM-3B-8K is even competitive with some 7B\nparameter models. Additionally, BTLM-3B-8K provides excellent long context\nperformance, outperforming MPT-7B-8K and XGen-7B-8K on tasks up to 8,192\ncontext length. We trained the model on a cleaned and deduplicated SlimPajama\ndataset; aggressively tuned the \\textmu P hyperparameters and schedule; used\nALiBi position embeddings; and adopted the SwiGLU nonlinearity.\n\nOn Hugging Face, the most popular models have 7B parameters, indicating that\nusers prefer the quality-size ratio of 7B models. Compacting the 7B parameter\nmodel to one with 3B parameters, with little performance impact, is an\nimportant milestone. BTLM-3B-8K needs only 3GB of memory with 4-bit precision\nand takes 2.5x less inference compute than 7B models, helping to open up access\nto a powerful language model on mobile and edge devices. BTLM-3B-8K is\navailable under an Apache 2.0 license on Hugging Face:\nhttps://huggingface.co/cerebras/btlm-3b-8k-base.",
          "link": "http://arxiv.org/abs/2309.11568",
          "publishedOn": "2023-09-23T00:40:39.442Z",
          "wordCount": null,
          "title": "BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model. (arXiv:2309.11568v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shilova_V/0/1/0/all/0/1\">Veronika Shilova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1\">Ludovic Dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasile_F/0/1/0/all/0/1\">Flavian Vasile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Racic_G/0/1/0/all/0/1\">Ga&#xeb;tan Racic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanielian_U/0/1/0/all/0/1\">Ugo Tanielian</a>",
          "description": "In digital advertising, the selection of the optimal item (recommendation)\nand its best creative presentation (creative optimization) have traditionally\nbeen considered separate disciplines. However, both contribute significantly to\nuser satisfaction, underpinning our assumption that it relies on both an item's\nrelevance and its presentation, particularly in the case of visual creatives.\nIn response, we introduce the task of {\\itshape Generative Creative\nOptimization (GCO)}, which proposes the use of generative models for creative\ngeneration that incorporate user interests, and {\\itshape AdBooster}, a model\nfor personalized ad creatives based on the Stable Diffusion outpainting\narchitecture. This model uniquely incorporates user interests both during\nfine-tuning and at generation time. To further improve AdBooster's performance,\nwe also introduce an automated data augmentation pipeline. Through our\nexperiments on simulated data, we validate AdBooster's effectiveness in\ngenerating more relevant creatives than default product images, showing its\npotential of enhancing user engagement.",
          "link": "http://arxiv.org/abs/2309.11507",
          "publishedOn": "2023-09-23T00:40:39.441Z",
          "wordCount": null,
          "title": "AdBooster: Personalized Ad Creative Generation using Stable Diffusion Outpainting. (arXiv:2309.11507v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.11941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Calvo_Fullana_M/0/1/0/all/0/1\">Miguel Calvo-Fullana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paternain_S/0/1/0/all/0/1\">Santiago Paternain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chamon_L/0/1/0/all/0/1\">Luiz F. O. Chamon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>",
          "description": "A common formulation of constrained reinforcement learning involves multiple\nrewards that must individually accumulate to given thresholds. In this class of\nproblems, we show a simple example in which the desired optimal policy cannot\nbe induced by any weighted linear combination of rewards. Hence, there exist\nconstrained reinforcement learning problems for which neither regularized nor\nclassical primal-dual methods yield optimal policies. This work addresses this\nshortcoming by augmenting the state with Lagrange multipliers and\nreinterpreting primal-dual methods as the portion of the dynamics that drives\nthe multipliers evolution. This approach provides a systematic state\naugmentation procedure that is guaranteed to solve reinforcement learning\nproblems with constraints. Thus, as we illustrate by an example, while previous\nmethods can fail at finding optimal policies, running the dual dynamics while\nexecuting the augmented policy yields an algorithm that provably samples\nactions from the optimal policy.",
          "link": "http://arxiv.org/abs/2102.11941",
          "publishedOn": "2023-09-23T00:40:39.441Z",
          "wordCount": 703,
          "title": "State Augmented Constrained Reinforcement Learning: Overcoming the Limitations of Learning with Rewards. (arXiv:2102.11941v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.02108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1\">Ruohan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1\">Emma Brunskill</a>",
          "description": "Simple regret minimization is a critical problem in learning optimal\ntreatment assignment policies across various domains, including healthcare and\ne-commerce. However, it remains understudied in the contextual bandit setting.\nWe propose a new family of computationally efficient bandit algorithms for the\nstochastic contextual bandit settings, with the flexibility to be adapted for\ncumulative regret minimization (with near-optimal minimax guarantees) and\nsimple regret minimization (with SOTA guarantees). Furthermore, our algorithms\nadapt to model misspecification and extend to the continuous arm settings.\nThese advantages come from constructing and relying on \"conformal arm sets\"\n(CASs), which provide a set of arms at every context that encompass the\ncontext-specific optimal arm with some probability across the context\ndistribution. Our positive results on simple and cumulative regret guarantees\nare contrasted by a negative result, which shows that an algorithm can't\nachieve instance-dependent simple regret guarantees while simultaneously\nachieving minimax optimal cumulative regret guarantees.",
          "link": "http://arxiv.org/abs/2307.02108",
          "publishedOn": "2023-09-23T00:40:39.441Z",
          "wordCount": null,
          "title": "Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengliang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinrun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_H/0/1/0/all/0/1\">Haojian Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiying Li</a>",
          "description": "In the analysis of optical coherence tomography angiography (OCTA) images,\nthe operation of segmenting specific targets is necessary. Existing methods\ntypically train on supervised datasets with limited samples (approximately a\nfew hundred), which can lead to overfitting. To address this, the low-rank\nadaptation technique is adopted for foundation model fine-tuning and proposed\ncorresponding prompt point generation strategies to process various\nsegmentation tasks on OCTA datasets. This method is named SAM-OCTA and has been\nexperimented on the publicly available OCTA-500 dataset. While achieving\nstate-of-the-art performance metrics, this method accomplishes local vessel\nsegmentation as well as effective artery-vein segmentation, which was not\nwell-solved in previous works. The code is available at:\nhttps://github.com/ShellRedia/SAM-OCTA.",
          "link": "http://arxiv.org/abs/2309.11758",
          "publishedOn": "2023-09-23T00:40:39.436Z",
          "wordCount": null,
          "title": "SAM-OCTA: A Fine-Tuning Strategy for Applying Foundation Model to OCTA Image Segmentation Tasks. (arXiv:2309.11758v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.13773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pacheco_B/0/1/0/all/0/1\">Bruno Machado Pacheco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seman_L/0/1/0/all/0/1\">Laio Oriel Seman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigo_C/0/1/0/all/0/1\">Cezar Antonio Rigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camponogara_E/0/1/0/all/0/1\">Eduardo Camponogara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezerra_E/0/1/0/all/0/1\">Eduardo Augusto Bezerra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coelho_L/0/1/0/all/0/1\">Leandro dos Santos Coelho</a>",
          "description": "This study investigates how to schedule nanosatellite tasks more efficiently\nusing Graph Neural Networks (GNNs). In the Offline Nanosatellite Task\nScheduling (ONTS) problem, the goal is to find the optimal schedule for tasks\nto be carried out in orbit while taking into account Quality-of-Service (QoS)\nconsiderations such as priority, minimum and maximum activation events,\nexecution time-frames, periods, and execution windows, as well as constraints\non the satellite's power resources and the complexity of energy harvesting and\nmanagement. The ONTS problem has been approached using conventional\nmathematical formulations and exact methods, but their applicability to\nchallenging cases of the problem is limited. This study examines the use of\nGNNs in this context, which has been effectively applied to optimization\nproblems such as the traveling salesman, scheduling, and facility placement\nproblems. More specifically, we investigate whether GNNs can learn the complex\nstructure of the ONTS problem with respect to feasibility and optimality of\ncandidate solutions. Furthermore, we evaluate using GNN-based heuristic\nsolutions to provide better solutions (w.r.t. the objective value) to the ONTS\nproblem and reduce the optimization cost. Our experiments show that GNNs are\nnot only able to learn feasibility and optimality for instances of the ONTS\nproblem, but they can generalize to harder instances than those seen during\ntraining. Furthermore, the GNN-based heuristics improved the expected objective\nvalue of the best solution found under the time limit in 45%, and reduced the\nexpected time to find a feasible solution in 35%, when compared to the SCIP\n(Solving Constraint Integer Programs) solver in its off-the-shelf configuration",
          "link": "http://arxiv.org/abs/2303.13773",
          "publishedOn": "2023-09-23T00:40:39.436Z",
          "wordCount": null,
          "title": "Graph Neural Networks for the Offline Nanosatellite Task Scheduling Problem. (arXiv:2303.13773v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.10280",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_F/0/1/0/all/0/1\">Forsad Al Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonmoy_T/0/1/0/all/0/1\">Tanjid Hasan Tonmoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lover_A/0/1/0/all/0/1\">Andrew A. Lover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corey_G/0/1/0/all/0/1\">George A. Corey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Mohammad Arif Ul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1\">Tauhidur Rahman</a>",
          "description": "Privacy-preserving crowd density analysis finds application across a wide\nrange of scenarios, substantially enhancing smart building operation and\nmanagement while upholding privacy expectations in various spaces. We propose a\nnon-speech audio-based approach for crowd analytics, leveraging a\ntransformer-based model. Our results demonstrate that non-speech audio alone\ncan be used to conduct such analysis with remarkable accuracy. To the best of\nour knowledge, this is the first time when non-speech audio signals are\nproposed for predicting occupancy. As far as we know, there has been no other\nsimilar approach of its kind prior to this. To accomplish this, we deployed our\nsensor-based platform in the waiting room of a large hospital with IRB approval\nover a period of several months to capture non-speech audio and thermal images\nfor the training and evaluation of our models. The proposed non-speech-based\napproach outperformed the thermal camera-based model and all other baselines.\nIn addition to demonstrating superior performance without utilizing speech\naudio, we conduct further analysis using differential privacy techniques to\nprovide additional privacy guarantees. Overall, our work demonstrates the\nviability of employing non-speech audio data for accurate occupancy estimation,\nwhile also ensuring the exclusion of speech-related content and providing\nrobust privacy protections through differential privacy guarantees.",
          "link": "http://arxiv.org/abs/2309.10280",
          "publishedOn": "2023-09-23T00:40:39.436Z",
          "wordCount": null,
          "title": "Crowdotic: A Privacy-Preserving Hospital Waiting Room Crowd Density Estimation with Non-speech Audio. (arXiv:2309.10280v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.17366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Voelcker_C/0/1/0/all/0/1\">Claas A Voelcker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmadian_A/0/1/0/all/0/1\">Arash Ahmadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abachi_R/0/1/0/all/0/1\">Romina Abachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilitschenski_I/0/1/0/all/0/1\">Igor Gilitschenski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahmand_A/0/1/0/all/0/1\">Amir-massoud Farahmand</a>",
          "description": "The idea of decision-aware model learning, that models should be accurate\nwhere it matters for decision-making, has gained prominence in model-based\nreinforcement learning. While promising theoretical results have been\nestablished, the empirical performance of algorithms leveraging a\ndecision-aware loss has been lacking, especially in continuous control\nproblems. In this paper, we present a study on the necessary components for\ndecision-aware reinforcement learning models and we showcase design choices\nthat enable well-performing algorithms. To this end, we provide a theoretical\nand empirical investigation into prominent algorithmic ideas in the field. We\nhighlight that empirical design decisions established in the MuZero line of\nworks are vital to achieving good performance for related algorithms, and we\nshowcase differences in behavior between different instantiations of\nvalue-aware algorithms in stochastic environments. Using these insights, we\npropose the Latent Model-Based Decision-Aware Actor-Critic framework\n($\\lambda$-AC) for decision-aware model-based reinforcement learning in\ncontinuous state-spaces and highlight important design choices in different\nenvironments.",
          "link": "http://arxiv.org/abs/2306.17366",
          "publishedOn": "2023-09-23T00:40:39.435Z",
          "wordCount": null,
          "title": "$\\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces. (arXiv:2306.17366v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12162",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1\">Jiafeng Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Andrews_I/0/1/0/all/0/1\">Isaiah Andrews</a>",
          "description": "We study batched bandit experiments and consider the problem of inference\nconditional on the realized stopping time, assignment probabilities, and target\nparameter, where all of these may be chosen adaptively using information up to\nthe last batch of the experiment. Absent further restrictions on the\nexperiment, we show that inference using only the results of the last batch is\noptimal. When the adaptive aspects of the experiment are known to be\nlocation-invariant, in the sense that they are unchanged when we shift all\nbatch-arm means by a constant, we show that there is additional information in\nthe data, captured by one additional linear function of the batch-arm means. In\nthe more restrictive case where the stopping time, assignment probabilities,\nand target parameter are known to depend on the data only through a collection\nof polyhedral events, we derive computationally tractable and optimal\nconditional inference procedures.",
          "link": "http://arxiv.org/abs/2309.12162",
          "publishedOn": "2023-09-23T00:40:39.433Z",
          "wordCount": 647,
          "title": "Optimal Conditional Inference in Adaptive Experiments. (arXiv:2309.12162v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1\">Tomi Kinnunen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kong Aik Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tak_H/0/1/0/all/0/1\">Hemlata Tak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_N/0/1/0/all/0/1\">Nicholas Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nautsch_A/0/1/0/all/0/1\">Andreas Nautsch</a>",
          "description": "Presentation attack (spoofing) detection (PAD) typically operates alongside\nbiometric verification to improve reliablity in the face of spoofing attacks.\nEven though the two sub-systems operate in tandem to solve the single task of\nreliable biometric verification, they address different detection tasks and are\nhence typically evaluated separately. Evidence shows that this approach is\nsuboptimal. We introduce a new metric for the joint evaluation of PAD solutions\noperating in situ with biometric verification. In contrast to the tandem\ndetection cost function proposed recently, the new tandem equal error rate\n(t-EER) is parameter free. The combination of two classifiers nonetheless leads\nto a \\emph{set} of operating points at which false alarm and miss rates are\nequal and also dependent upon the prevalence of attacks. We therefore introduce\nthe \\emph{concurrent} t-EER, a unique operating point which is invariable to\nthe prevalence of attacks. Using both modality (and even application) agnostic\nsimulated scores, as well as real scores for a voice biometrics application, we\ndemonstrate application of the t-EER to a wide range of biometric system\nevaluations under attack. The proposed approach is a strong candidate metric\nfor the tandem evaluation of PAD systems and biometric comparators.",
          "link": "http://arxiv.org/abs/2309.12237",
          "publishedOn": "2023-09-23T00:40:39.420Z",
          "wordCount": null,
          "title": "t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators. (arXiv:2309.12237v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Collins_J/0/1/0/all/0/1\">Jeremy A. Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houff_C/0/1/0/all/0/1\">Cody Houff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">You Liang Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kemp_C/0/1/0/all/0/1\">Charles C. Kemp</a>",
          "description": "We present ForceSight, a system for text-guided mobile manipulation that\npredicts visual-force goals using a deep neural network. Given a single RGBD\nimage combined with a text prompt, ForceSight determines a target end-effector\npose in the camera frame (kinematic goal) and the associated forces (force\ngoal). Together, these two components form a visual-force goal. Prior work has\ndemonstrated that deep models outputting human-interpretable kinematic goals\ncan enable dexterous manipulation by real robots. Forces are critical to\nmanipulation, yet have typically been relegated to lower-level execution in\nthese systems. When deployed on a mobile manipulator equipped with an\neye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps,\ndrawer opening, and object handovers with an 81% success rate in unseen\nenvironments with object instances that differed significantly from the\ntraining data. In a separate experiment, relying exclusively on visual servoing\nand ignoring force goals dropped the success rate from 90% to 45%,\ndemonstrating that force goals can significantly enhance performance. The\nappendix, videos, code, and trained models are available at\nhttps://force-sight.github.io/.",
          "link": "http://arxiv.org/abs/2309.12312",
          "publishedOn": "2023-09-23T00:40:39.420Z",
          "wordCount": null,
          "title": "ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals. (arXiv:2309.12312v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12217",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Smedemark_Margulies_N/0/1/0/all/0/1\">Niklas Smedemark-Margulies</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bicer_Y/0/1/0/all/0/1\">Yunus Bicer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sunger_E/0/1/0/all/0/1\">Elifnur Sunger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Naufel_S/0/1/0/all/0/1\">Stephanie Naufel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Imbiriba_T/0/1/0/all/0/1\">Tales Imbiriba</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tunik_E/0/1/0/all/0/1\">Eugene Tunik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Erdogmus_D/0/1/0/all/0/1\">Deniz Erdo&#x11f;mu&#x15f;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yarossi_M/0/1/0/all/0/1\">Mathew Yarossi</a>",
          "description": "Objective: The objective of the study is to efficiently increase the\nexpressivity of surface electromyography-based (sEMG) gesture recognition\nsystems. Approach: We use a problem transformation approach, in which actions\nwere subset into two biomechanically independent components - a set of wrist\ndirections and a set of finger modifiers. To maintain fast calibration time, we\ntrain models for each component using only individual gestures, and extrapolate\nto the full product space of combination gestures by generating synthetic data.\nWe collected a supervised dataset with high-confidence ground truth labels in\nwhich subjects performed combination gestures while holding a joystick, and\nconducted experiments to analyze the impact of model architectures, classifier\nalgorithms, and synthetic data generation strategies on the performance of the\nproposed approach. Main Results: We found that a problem transformation\napproach using a parallel model architecture in combination with a non-linear\nclassifier, along with restricted synthetic data generation, shows promise in\nincreasing the expressivity of sEMG-based gestures with a short calibration\ntime. Significance: sEMG-based gesture recognition has applications in\nhuman-computer interaction, virtual reality, and the control of robotic and\nprosthetic devices. Existing approaches require exhaustive model calibration.\nThe proposed approach increases expressivity without requiring users to\ndemonstrate all combination gesture classes. Our results may be extended to\nlarger gesture vocabularies and more complicated model architectures.",
          "link": "http://arxiv.org/abs/2309.12217",
          "publishedOn": "2023-09-23T00:40:39.419Z",
          "wordCount": 743,
          "title": "A Multi-label Classification Approach to Increase Expressivity of EMG-based Gesture Recognition. (arXiv:2309.12217v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blasiok_J/0/1/0/all/0/1\">Jaros&#x142;aw B&#x142;asiok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>",
          "description": "Calibration measures and reliability diagrams are two fundamental tools for\nmeasuring and interpreting the calibration of probabilistic predictors.\nCalibration measures quantify the degree of miscalibration, and reliability\ndiagrams visualize the structure of this miscalibration. However, the most\ncommon constructions of reliability diagrams and calibration measures --\nbinning and ECE -- both suffer from well-known flaws (e.g. discontinuity). We\nshow that a simple modification fixes both constructions: first smooth the\nobservations using an RBF kernel, then compute the Expected Calibration Error\n(ECE) of this smoothed function. We prove that with a careful choice of\nbandwidth, this method yields a calibration measure that is well-behaved in the\nsense of (B{\\l}asiok, Gopalan, Hu, and Nakkiran 2023a) -- a consistent\ncalibration measure. We call this measure the SmoothECE. Moreover, the\nreliability diagram obtained from this smoothed function visually encodes the\nSmoothECE, just as binned reliability diagrams encode the BinnedECE.\n\nWe also provide a Python package with simple, hyperparameter-free methods for\nmeasuring and plotting calibration: `pip install relplot\\`.",
          "link": "http://arxiv.org/abs/2309.12236",
          "publishedOn": "2023-09-23T00:40:39.381Z",
          "wordCount": null,
          "title": "Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing. (arXiv:2309.12236v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verhelst_T/0/1/0/all/0/1\">Th&#xe9;o Verhelst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petit_R/0/1/0/all/0/1\">Robin Petit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbeke_W/0/1/0/all/0/1\">Wouter Verbeke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontempi_G/0/1/0/all/0/1\">Gianluca Bontempi</a>",
          "description": "Despite the growing popularity of machine-learning techniques in\ndecision-making, the added value of causal-oriented strategies with respect to\npure machine-learning approaches has rarely been quantified in the literature.\nThese strategies are crucial for practitioners in various domains, such as\nmarketing, telecommunications, health care and finance. This paper presents a\ncomprehensive treatment of the subject, starting from firm theoretical\nfoundations and highlighting the parameters that influence the performance of\nthe uplift and predictive approaches. The focus of the paper is on a binary\noutcome case and a binary action, and the paper presents a theoretical analysis\nof uplift modeling, comparing it with the classical predictive approach. The\nmain research contributions of the paper include a new formulation of the\nmeasure of profit, a formal proof of the convergence of the uplift curve to the\nmeasure of profit ,and an illustration, through simulations, of the conditions\nunder which predictive approaches still outperform uplift modeling. We show\nthat the mutual information between the features and the outcome plays a\nsignificant role, along with the variance of the estimators, the distribution\nof the potential outcomes and the underlying costs and benefits of the\ntreatment and the outcome.",
          "link": "http://arxiv.org/abs/2309.12036",
          "publishedOn": "2023-09-23T00:40:39.379Z",
          "wordCount": 694,
          "title": "Uplift vs. predictive modeling: a theoretical analysis. (arXiv:2309.12036v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yusen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jamie Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yesha_Y/0/1/0/all/0/1\">Yelena Yesha</a>",
          "description": "Federated Learning (FL) has revolutionized how we train deep neural networks\nby enabling decentralized collaboration while safeguarding sensitive data and\nimproving model performance. However, FL faces two crucial challenges: the\ndiverse nature of data held by individual clients and the vulnerability of the\nFL system to security breaches. This paper introduces an innovative solution\nnamed Estimated Mean Aggregation (EMA) that not only addresses these challenges\nbut also provides a fundamental reference point as a $\\mathsf{baseline}$ for\nadvanced aggregation techniques in FL systems. EMA's significance lies in its\ndual role: enhancing model security by effectively handling malicious outliers\nthrough trimmed means and uncovering data heterogeneity to ensure that trained\nmodels are adaptable across various client datasets. Through a wealth of\nexperiments, EMA consistently demonstrates high accuracy and area under the\ncurve (AUC) compared to alternative methods, establishing itself as a robust\nbaseline for evaluating the effectiveness and security of FL aggregation\nmethods. EMA's contributions thus offer a crucial step forward in advancing the\nefficiency, security, and versatility of decentralized deep learning in the\ncontext of FL.",
          "link": "http://arxiv.org/abs/2309.12267",
          "publishedOn": "2023-09-23T00:40:39.373Z",
          "wordCount": 691,
          "title": "Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications. (arXiv:2309.12267v1 [cs.CR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yukang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1\">Shengju Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haotian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_X/0/1/0/all/0/1\">Xin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhijian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jiaya Jia</a>",
          "description": "We present LongLoRA, an efficient fine-tuning approach that extends the\ncontext sizes of pre-trained large language models (LLMs), with limited\ncomputation cost. Typically, training LLMs with long context sizes is\ncomputationally expensive, requiring extensive training hours and GPU\nresources. For example, training on the context length of 8192 needs 16x\ncomputational costs in self-attention layers as that of 2048. In this paper, we\nspeed up the context extension of LLMs in two aspects. On the one hand,\nalthough dense global attention is needed during inference, fine-tuning the\nmodel can be effectively and efficiently done by sparse local attention. The\nproposed shift short attention effectively enables context extension, leading\nto non-trivial computation saving with similar performance to fine-tuning with\nvanilla attention. Particularly, it can be implemented with only two lines of\ncode in training, while being optional in inference. On the other hand, we\nrevisit the parameter-efficient fine-tuning regime for context expansion.\nNotably, we find that LoRA for context extension works well under the premise\nof trainable embedding and normalization. LongLoRA demonstrates strong\nempirical results on various tasks on LLaMA2 models from 7B/13B to 70B.\nLongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a\nsingle 8x A100 machine. LongLoRA extends models' context while retaining their\noriginal architectures, and is compatible with most existing techniques, like\nFlashAttention-2. In addition, to make LongLoRA practical, we collect a\ndataset, LongQA, for supervised fine-tuning. It contains more than 3k long\ncontext question-answer pairs.",
          "link": "http://arxiv.org/abs/2309.12307",
          "publishedOn": "2023-09-23T00:40:39.366Z",
          "wordCount": 767,
          "title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models. (arXiv:2309.12307v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12193",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Misu_R/0/1/0/all/0/1\">Razia Sultana Misu</a>",
          "description": "Brain tumors are collections of abnormal cells that can develop into masses\nor clusters. Because they have the potential to infiltrate other tissues, they\npose a risk to the patient. The main imaging technique used, MRI, may be able\nto identify a brain tumor with accuracy. The fast development of Deep Learning\nmethods for use in computer vision applications has been facilitated by a vast\namount of training data and improvements in model construction that offer\nbetter approximations in a supervised setting. The need for these approaches\nhas been the main driver of this expansion. Deep learning methods have shown\npromise in improving the precision of brain tumor detection and classification\nusing magnetic resonance imaging (MRI). The study on the use of deep learning\ntechniques, especially ResNet50, for brain tumor identification is presented in\nthis abstract. As a result, this study investigates the possibility of\nautomating the detection procedure using deep learning techniques. In this\nstudy, I utilized five transfer learning models which are VGG16, VGG19,\nDenseNet121, ResNet50 and YOLO V4 where ResNet50 provide the best or highest\naccuracy 99.54%. The goal of the study is to guide researchers and medical\nprofessionals toward powerful brain tumor detecting systems by employing deep\nlearning approaches by way of this evaluation and analysis.",
          "link": "http://arxiv.org/abs/2309.12193",
          "publishedOn": "2023-09-23T00:40:39.354Z",
          "wordCount": 715,
          "title": "Brain Tumor Detection Using Deep Learning Approaches. (arXiv:2309.12193v1 [eess.IV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1\">Josh Susskind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbe_E/0/1/0/all/0/1\">Emmanuel Abb&#xe9;</a>",
          "description": "In this work, we introduce Boolformer, the first Transformer architecture\ntrained to perform end-to-end symbolic regression of Boolean functions. First,\nwe show that it can predict compact formulas for complex functions which were\nnot seen during training, when provided a clean truth table. Then, we\ndemonstrate its ability to find approximate expressions when provided\nincomplete and noisy observations. We evaluate the Boolformer on a broad set of\nreal-world binary classification datasets, demonstrating its potential as an\ninterpretable alternative to classic machine learning methods. Finally, we\napply it to the widespread task of modelling the dynamics of gene regulatory\nnetworks. Using a recent benchmark, we show that Boolformer is competitive with\nstate-of-the art genetic algorithms with a speedup of several orders of\nmagnitude. Our code and models are available publicly.",
          "link": "http://arxiv.org/abs/2309.12207",
          "publishedOn": "2023-09-23T00:40:39.349Z",
          "wordCount": 637,
          "title": "Boolformer: Symbolic Regression of Logic Functions with Transformers. (arXiv:2309.12207v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.03044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenzhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zichuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zongqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1\">Deheng Ye</a>",
          "description": "Transformer has been considered the dominating neural architecture in NLP and\nCV, mostly under supervised settings. Recently, a similar surge of using\nTransformers has appeared in the domain of reinforcement learning (RL), but it\nis faced with unique design choices and challenges brought by the nature of RL.\nHowever, the evolution of Transformers in RL has not yet been well unraveled.\nIn this paper, we seek to systematically review motivations and progress on\nusing Transformers in RL, provide a taxonomy on existing works, discuss each\nsub-field, and summarize future prospects.",
          "link": "http://arxiv.org/abs/2301.03044",
          "publishedOn": "2023-09-23T00:40:39.344Z",
          "wordCount": 625,
          "title": "A Survey on Transformers in Reinforcement Learning. (arXiv:2301.03044v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.10505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Muah Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fritschek_R/0/1/0/all/0/1\">Rick Fritschek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaefer_R/0/1/0/all/0/1\">Rafael F. Schaefer</a>",
          "description": "The training of neural encoders via deep learning necessitates a\ndifferentiable channel model due to the backpropagation algorithm. This\nrequirement can be sidestepped by approximating either the channel distribution\nor its gradient through pilot signals in real-world scenarios. The initial\napproach draws upon the latest advancements in image generation, utilizing\ngenerative adversarial networks (GANs) or their enhanced variants to generate\nchannel distributions. In this paper, we address this channel approximation\nchallenge with diffusion models, which have demonstrated high sample quality in\nimage generation. We offer an end-to-end channel coding framework underpinned\nby diffusion models and propose an efficient training algorithm. Our\nsimulations with various channel models establish that our diffusion models\nlearn the channel distribution accurately, thereby achieving near-optimal\nend-to-end symbol error rates (SERs). We also note a significant advantage of\ndiffusion models: A robust generalization capability in high signal-to-noise\nratio regions, in contrast to GAN variants that suffer from error floor.\nFurthermore, we examine the trade-off between sample quality and sampling\nspeed, when an accelerated sampling algorithm is deployed, and investigate the\neffect of the noise scheduling on this trade-off. With an apt choice of noise\nscheduling, sampling time can be significantly reduced with a minor increase in\nSER.",
          "link": "http://arxiv.org/abs/2309.10505",
          "publishedOn": "2023-09-23T00:40:39.339Z",
          "wordCount": 713,
          "title": "Learning End-to-End Channel Coding with Diffusion Models. (arXiv:2309.10505v2 [cs.IT] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiazheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanchun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quevedo_D/0/1/0/all/0/1\">Daniel Quevedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yonghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vucetic_B/0/1/0/all/0/1\">Branka Vucetic</a>",
          "description": "For cyber-physical systems in the 6G era, semantic communications connecting\ndistributed devices for dynamic control and remote state estimation are\nrequired to guarantee application-level performance, not merely focus on\ncommunication-centric performance. Semantics here is a measure of the\nusefulness of information transmissions. Semantic-aware transmission scheduling\nof a large system often involves a large decision-making space, and the optimal\npolicy cannot be obtained by existing algorithms effectively. In this paper, we\nfirst investigate the fundamental properties of the optimal semantic-aware\nscheduling policy and then develop advanced deep reinforcement learning (DRL)\nalgorithms by leveraging the theoretical guidelines. Our numerical results show\nthat the proposed algorithms can substantially reduce training time and enhance\ntraining performance compared to benchmark algorithms.",
          "link": "http://arxiv.org/abs/2305.13706",
          "publishedOn": "2023-09-23T00:40:39.327Z",
          "wordCount": null,
          "title": "Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach. (arXiv:2305.13706v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rasul_R/0/1/0/all/0/1\">Rownak Ara Rasul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_P/0/1/0/all/0/1\">Promy Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bala_D/0/1/0/all/0/1\">Diponkor Bala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karim_S/0/1/0/all/0/1\">S M Rakib Ul Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_I/0/1/0/all/0/1\">Ibrahim Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_B/0/1/0/all/0/1\">Bishwajit Saha</a>",
          "description": "Autistic Spectrum Disorder (ASD) is a neurological disease characterized by\ndifficulties with social interaction, communication, and repetitive activities.\nThe severity of these difficulties varies, and those with this diagnosis face\nunique challenges. While its primary origin lies in genetics, identifying and\naddressing it early can contribute to the enhancement of the condition. In\nrecent years, machine learning-driven intelligent diagnosis has emerged as a\nsupplement to conventional clinical approaches, aiming to address the potential\ndrawbacks of time-consuming and costly traditional methods. In this work, we\nutilize different machine learning algorithms to find the most significant\ntraits responsible for ASD and to automate the diagnostic process. We study six\nclassification models to see which model works best to identify ASD and also\nstudy five popular clustering methods to get a meaningful insight of these ASD\ndatasets. To find the best classifier for these binary datasets, we evaluate\nthe models using accuracy, precision, recall, specificity, F1-score, AUC, kappa\nand log loss metrics. Our evaluation demonstrates that five out of the six\nselected models perform exceptionally, achieving a 100% accuracy rate on the\nASD datasets when hyperparameters are meticulously tuned for each model. As\nalmost all classification models are able to get 100% accuracy, we become\ninterested in observing the underlying insights of the datasets by implementing\nsome popular clustering algorithms on these datasets. We calculate Normalized\nMutual Information (NMI), Adjusted Rand Index (ARI) & Silhouette Coefficient\n(SC) metrics to select the best clustering models. Our evaluation finds that\nspectral clustering outperforms all other benchmarking clustering models in\nterms of NMI & ARI metrics and it also demonstrates comparability to the\noptimal SC achieved by k-means.",
          "link": "http://arxiv.org/abs/2309.11646",
          "publishedOn": "2023-09-23T00:40:39.326Z",
          "wordCount": null,
          "title": "Early diagnosis of autism spectrum disorder using machine learning approaches. (arXiv:2309.11646v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.02900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yataka_R/0/1/0/all/0/1\">Ryoma Yataka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiraishi_M/0/1/0/all/0/1\">Masashi Shiraishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirashima_K/0/1/0/all/0/1\">Kazuki Hirashima</a>",
          "description": "Recently, studies on machine learning have focused on methods that use\nsymmetry implicit in a specific manifold as an inductive bias. Grassmann\nmanifolds provide the ability to handle fundamental shapes represented as shape\nspaces, enabling stable shape analysis. In this paper, we present a novel\napproach in which we establish the theoretical foundations for learning\ndistributions on the Grassmann manifold via continuous normalization flows,\nwith the explicit goal of generating stable shapes. Our approach facilitates\nmore robust generation by effectively eliminating the influence of extraneous\ntransformations, such as rotations and inversions, through learning and\ngenerating within a Grassmann manifolds designed to accommodate the essential\nshape information of the object. The experimental results indicated that the\nproposed method can generate high-quality samples by capturing the data\nstructure. Furthermore, the proposed method significantly outperformed\nstate-of-the-art methods in terms of the log-likelihood or evidence lower\nbound. The results obtained are expected to stimulate further research in this\nfield, leading to advances for stable shape generation and analysis.",
          "link": "http://arxiv.org/abs/2211.02900",
          "publishedOn": "2023-09-23T00:40:39.326Z",
          "wordCount": null,
          "title": "Grassmann Manifold Flows for Stable Shape Generation. (arXiv:2211.02900v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yusheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1\">Wei Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1\">Xian-Sheng Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>",
          "description": "This paper studies the problem of traffic flow forecasting, which aims to\npredict future traffic conditions on the basis of road networks and traffic\nconditions in the past. The problem is typically solved by modeling complex\nspatio-temporal correlations in traffic data using spatio-temporal graph neural\nnetworks (GNNs). However, the performance of these methods is still far from\nsatisfactory since GNNs usually have limited representation capacity when it\ncomes to complex traffic networks. Graphs, by nature, fall short in capturing\nnon-pairwise relations. Even worse, existing methods follow the paradigm of\nmessage passing that aggregates neighborhood information linearly, which fails\nto capture complicated spatio-temporal high-order interactions. To tackle these\nissues, in this paper, we propose a novel model named Dynamic Hypergraph\nStructure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise\nrelationships, our DyHSL extracts hypergraph structural information to model\ndynamics in the traffic networks, and updates each node representation by\naggregating messages from its associated hyperedges. Additionally, to capture\nhigh-order spatio-temporal relations in the road network, we introduce an\ninteractive graph convolution block, which further models the neighborhood\ninteraction for each node. Finally, we integrate these two views into a\nholistic multi-scale correlation extraction module, which conducts temporal\npooling with different scales to model different temporal patterns. Extensive\nexperiments on four popular traffic benchmark datasets demonstrate the\neffectiveness of our proposed DyHSL compared with a broad range of competing\nbaselines.",
          "link": "http://arxiv.org/abs/2309.12028",
          "publishedOn": "2023-09-23T00:40:39.325Z",
          "wordCount": 758,
          "title": "Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting. (arXiv:2309.12028v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_L/0/1/0/all/0/1\">Luis Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Washuttl_T/0/1/0/all/0/1\">Tobias Wash&#xfc;ttl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1\">Gerhard Widmer</a>",
          "description": "Linking sheet music images to audio recordings remains a key problem for the\ndevelopment of efficient cross-modal music retrieval systems. One of the\nfundamental approaches toward this task is to learn a cross-modal embedding\nspace via deep neural networks that is able to connect short snippets of audio\nand sheet music. However, the scarcity of annotated data from real musical\ncontent affects the capability of such methods to generalize to real retrieval\nscenarios. In this work, we investigate whether we can mitigate this limitation\nwith self-supervised contrastive learning, by exposing a network to a large\namount of real music data as a pre-training step, by contrasting randomly\naugmented views of snippets of both modalities, namely audio and sheet images.\nThrough a number of experiments on synthetic and real piano data, we show that\npre-trained models are able to retrieve snippets with better precision in all\nscenarios and pre-training configurations. Encouraged by these results, we\nemploy the snippet embeddings in the higher-level task of cross-modal piece\nidentification and conduct more experiments on several retrieval\nconfigurations. In this task, we observe that the retrieval quality improves\nfrom 30% up to 100% when real music data is present. We then conclude by\narguing for the potential of self-supervised contrastive learning for\nalleviating the annotated data scarcity in multi-modal music retrieval models.",
          "link": "http://arxiv.org/abs/2309.12134",
          "publishedOn": "2023-09-23T00:40:39.317Z",
          "wordCount": null,
          "title": "Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems. (arXiv:2309.12134v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Travis Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1\">Katie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phoo_C/0/1/0/all/0/1\">Cheng Perng Phoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yurong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1\">Wei-Lun Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1\">Bharath Hariharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1\">Mark Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>",
          "description": "The rapid development of 3D object detection systems for self-driving cars\nhas significantly improved accuracy. However, these systems struggle to\ngeneralize across diverse driving environments, which can lead to\nsafety-critical failures in detecting traffic participants. To address this, we\npropose a method that utilizes unlabeled repeated traversals of multiple\nlocations to adapt object detectors to new driving environments. By\nincorporating statistics computed from repeated LiDAR scans, we guide the\nadaptation process effectively. Our approach enhances LiDAR-based detection\nmodels using spatial quantized historical features and introduces a lightweight\nregression head to leverage the statistics for feature regularization.\nAdditionally, we leverage the statistics for a novel self-training process to\nstabilize the training. The framework is detector model-agnostic and\nexperiments on real-world datasets demonstrate significant improvements,\nachieving up to a 20-point performance gain, especially in detecting\npedestrians and distant objects. Code is available at\nhttps://github.com/zhangtravis/Hist-DA.",
          "link": "http://arxiv.org/abs/2309.12140",
          "publishedOn": "2023-09-23T00:40:39.317Z",
          "wordCount": null,
          "title": "Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features. (arXiv:2309.12140v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11647",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Sweke_R/0/1/0/all/0/1\">Ryan Sweke</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Recio_E/0/1/0/all/0/1\">Erik Recio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jerbi_S/0/1/0/all/0/1\">Sofiene Jerbi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gil_Fuster_E/0/1/0/all/0/1\">Elies Gil-Fuster</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Fuller_B/0/1/0/all/0/1\">Bryce Fuller</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1\">Jens Eisert</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Meyer_J/0/1/0/all/0/1\">Johannes Jakob Meyer</a>",
          "description": "Quantum machine learning is arguably one of the most explored applications of\nnear-term quantum devices. Much focus has been put on notions of variational\nquantum machine learning where parameterized quantum circuits (PQCs) are used\nas learning models. These PQC models have a rich structure which suggests that\nthey might be amenable to efficient dequantization via random Fourier features\n(RFF). In this work, we establish necessary and sufficient conditions under\nwhich RFF does indeed provide an efficient dequantization of variational\nquantum machine learning for regression. We build on these insights to make\nconcrete suggestions for PQC architecture design, and to identify structures\nwhich are necessary for a regression problem to admit a potential quantum\nadvantage via PQC based optimization.",
          "link": "http://arxiv.org/abs/2309.11647",
          "publishedOn": "2023-09-23T00:40:39.316Z",
          "wordCount": null,
          "title": "Potential and limitations of random Fourier features for dequantizing quantum machine learning. (arXiv:2309.11647v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Meng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Ke Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dayu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1\">Lingyuan Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1\">Wenxuan Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sihang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinwang Liu</a>",
          "description": "Audiovisual data is everywhere in this digital age, which raises higher\nrequirements for the deep learning models developed on them. To well handle the\ninformation of the multi-modal data is the key to a better audiovisual modal.\nWe observe that these audiovisual data naturally have temporal attributes, such\nas the time information for each frame in the video. More concretely, such data\nis inherently multi-modal according to both audio and visual cues, which\nproceed in a strict chronological order. It indicates that temporal information\nis important in multi-modal acoustic event modeling for both intra- and\ninter-modal. However, existing methods deal with each modal feature\nindependently and simply fuse them together, which neglects the mining of\ntemporal relation and thus leads to sub-optimal performance. With this\nmotivation, we propose a Temporal Multi-modal graph learning method for\nAcoustic event Classification, called TMac, by modeling such temporal\ninformation via graph learning techniques. In particular, we construct a\ntemporal graph for each acoustic event, dividing its audio data and video data\ninto multiple segments. Each segment can be considered as a node, and the\ntemporal relationships between nodes can be considered as timestamps on their\nedges. In this case, we can smoothly capture the dynamic information in\nintra-modal and inter-modal. Several experiments are conducted to demonstrate\nTMac outperforms other SOTA models in performance. Our code is available at\nhttps://github.com/MGitHubL/TMac.",
          "link": "http://arxiv.org/abs/2309.11845",
          "publishedOn": "2023-09-23T00:40:39.316Z",
          "wordCount": null,
          "title": "TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification. (arXiv:2309.11845v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karakaya_O/0/1/0/all/0/1\">Onur Karakaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kilimci_Z/0/1/0/all/0/1\">Zeynep Hilal Kilimci</a>",
          "description": "Anticancer peptides (ACPs) are a group of peptides that exhibite\nantineoplastic properties. The utilization of ACPs in cancer prevention can\npresent a viable substitute for conventional cancer therapeutics, as they\npossess a higher degree of selectivity and safety. Recent scientific\nadvancements generate an interest in peptide-based therapies which offer the\nadvantage of efficiently treating intended cells without negatively impacting\nnormal cells. However, as the number of peptide sequences continues to increase\nrapidly, developing a reliable and precise prediction model becomes a\nchallenging task. In this work, our motivation is to advance an efficient model\nfor categorizing anticancer peptides employing the consolidation of word\nembedding and deep learning models. First, Word2Vec and FastText are evaluated\nas word embedding techniques for the purpose of extracting peptide sequences.\nThen, the output of word embedding models are fed into deep learning approaches\nCNN, LSTM, BiLSTM. To demonstrate the contribution of proposed framework,\nextensive experiments are carried on widely-used datasets in the literature,\nACPs250 and Independent. Experiment results show the usage of proposed model\nenhances classification accuracy when compared to the state-of-the-art studies.\nThe proposed combination, FastText+BiLSTM, exhibits 92.50% of accuracy for\nACPs250 dataset, and 96.15% of accuracy for Independent dataset, thence\ndetermining new state-of-the-art.",
          "link": "http://arxiv.org/abs/2309.12058",
          "publishedOn": "2023-09-23T00:40:39.315Z",
          "wordCount": null,
          "title": "An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM. (arXiv:2309.12058v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.08228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramanaik_C/0/1/0/all/0/1\">Chethan Krishnamurthy Ramanaik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardona_J/0/1/0/all/0/1\">Juan-Esteban Suarez Cardona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willmann_A/0/1/0/all/0/1\">Anna Willmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanfeld_P/0/1/0/all/0/1\">Pia Hanfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_N/0/1/0/all/0/1\">Nico Hoffmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hecht_M/0/1/0/all/0/1\">Michael Hecht</a>",
          "description": "We formulate a data independent latent space regularisation constraint for\ngeneral unsupervised autoencoders. The regularisation rests on sampling the\nautoencoder Jacobian in Legendre nodes, being the centre of the Gauss-Legendre\nquadrature. Revisiting this classic enables to prove that regularised\nautoencoders ensure a one-to-one re-embedding of the initial data manifold to\nits latent representation. Demonstrations show that prior proposed\nregularisation strategies, such as contractive autoencoding, cause topological\ndefects already for simple examples, and so do convolutional based\n(variational) autoencoders. In contrast, topological preservation is ensured\nalready by standard multilayer perceptron neural networks when being\nregularised due to our contribution. This observation extends through the\nclassic FashionMNIST dataset up to real world encoding problems for MRI brain\nscans, suggesting that, across disciplines, reliable low dimensional\nrepresentations of complex high-dimensional datasets can be delivered due to\nthis regularisation technique.",
          "link": "http://arxiv.org/abs/2309.08228",
          "publishedOn": "2023-09-23T00:40:39.315Z",
          "wordCount": 697,
          "title": "Ensuring Topological Data-Structure Preservation under Autoencoder Compression due to Latent Space Regularization in Gauss--Legendre nodes. (arXiv:2309.08228v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12200",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yuan_R/0/1/0/all/0/1\">Ruihao Yuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kaixuan Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_P/0/1/0/all/0/1\">Pan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1\">Shunqing Zhang</a>",
          "description": "Indoor localization is getting increasing demands for various cutting-edged\ntechnologies, like Virtual/Augmented reality and smart home. Traditional\nmodel-based localization suffers from significant computational overhead, so\nfingerprint localization is getting increasing attention, which needs lower\ncomputation cost after the fingerprint database is built. However, the accuracy\nof indoor localization is limited by the complicated indoor environment which\nbrings the multipath signal refraction. In this paper, we provided a scheme to\nimprove the accuracy of indoor fingerprint localization from the frequency\ndomain by predicting the channel state information (CSI) values from another\ntransmitting channel and spliced the multi-band information together to get\nmore precise localization results. We tested our proposed scheme on COST 2100\nsimulation data and real time orthogonal frequency division multiplexing (OFDM)\nWiFi data collected from an office scenario.",
          "link": "http://arxiv.org/abs/2309.12200",
          "publishedOn": "2023-09-23T00:40:39.281Z",
          "wordCount": 647,
          "title": "A Variational Auto-Encoder Enabled Multi-Band Channel Prediction Scheme for Indoor Localization. (arXiv:2309.12200v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Ruizhao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Peng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1\">Eshed Ohn-Bar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saligrama_V/0/1/0/all/0/1\">Venkatesh Saligrama</a>",
          "description": "Human drivers can seamlessly adapt their driving decisions across\ngeographical locations with diverse conditions and rules of the road, e.g.,\nleft vs. right-hand traffic. In contrast, existing models for autonomous\ndriving have been thus far only deployed within restricted operational domains,\ni.e., without accounting for varying driving behaviors across locations or\nmodel scalability. In this work, we propose AnyD, a single geographically-aware\nconditional imitation learning (CIL) model that can efficiently learn from\nheterogeneous and globally distributed data with dynamic environmental,\ntraffic, and social characteristics. Our key insight is to introduce a\nhigh-capacity geo-location-based channel attention mechanism that effectively\nadapts to local nuances while also flexibly modeling similarities among regions\nin a data-driven manner. By optimizing a contrastive imitation objective, our\nproposed approach can efficiently scale across inherently imbalanced data\ndistributions and location-dependent events. We demonstrate the benefits of our\nAnyD agent across multiple datasets, cities, and scalable deployment paradigms,\ni.e., centralized, semi-supervised, and distributed agent training.\nSpecifically, AnyD outperforms CIL baselines by over 14% in open-loop\nevaluation and 30% in closed-loop testing on CARLA.",
          "link": "http://arxiv.org/abs/2309.12295",
          "publishedOn": "2023-09-23T00:40:39.276Z",
          "wordCount": 679,
          "title": "Learning to Drive Anywhere. (arXiv:2309.12295v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12095",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Markovic_D/0/1/0/all/0/1\">Dimitrije Markovi&#x107;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Friston_K/0/1/0/all/0/1\">Karl J. Friston</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kiebel_S/0/1/0/all/0/1\">Stefan J. Kiebel</a>",
          "description": "Deep learning's immense capabilities are often constrained by the complexity\nof its models, leading to an increasing demand for effective sparsification\ntechniques. Bayesian sparsification for deep learning emerges as a crucial\napproach, facilitating the design of models that are both computationally\nefficient and competitive in terms of performance across various deep learning\napplications. The state-of-the-art -- in Bayesian sparsification of deep neural\nnetworks -- combines structural shrinkage priors on model weights with an\napproximate inference scheme based on black-box stochastic variational\ninference. However, model inversion of the full generative model is\nexceptionally computationally demanding, especially when compared to standard\ndeep learning of point estimates. In this context, we advocate for the use of\nBayesian model reduction (BMR) as a more efficient alternative for pruning of\nmodel weights. As a generalization of the Savage-Dickey ratio, BMR allows a\npost-hoc elimination of redundant model weights based on the posterior\nestimates under a straightforward (non-hierarchical) generative model. Our\ncomparative study highlights the computational efficiency and the pruning rate\nof the BMR method relative to the established stochastic variational inference\n(SVI) scheme, when applied to the full hierarchical generative model. We\nillustrate the potential of BMR to prune model parameters across various deep\nlearning architectures, from classical networks like LeNet to modern frameworks\nsuch as Vision Transformers and MLP-Mixers.",
          "link": "http://arxiv.org/abs/2309.12095",
          "publishedOn": "2023-09-23T00:40:39.181Z",
          "wordCount": null,
          "title": "Bayesian sparsification for deep neural networks with Bayesian model reduction. (arXiv:2309.12095v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.00997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tsai_C/0/1/0/all/0/1\">Chung-En Tsai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_H/0/1/0/all/0/1\">Hao-Chung Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yen-Huan Li</a>",
          "description": "Consider an online convex optimization problem where the loss functions are\nself-concordant barriers, smooth relative to a convex function $h$, and\npossibly non-Lipschitz. We analyze the regret of online mirror descent with\n$h$. Then, based on the result, we prove the following in a unified manner.\nDenote by $T$ the time horizon and $d$ the parameter dimension. 1. For online\nportfolio selection, the regret of $\\widetilde{\\text{EG}}$, a variant of\nexponentiated gradient due to Helmbold et al., is $\\tilde{O} ( T^{2/3} d^{1/3}\n)$ when $T > 4 d / \\log d$. This improves on the original $\\tilde{O} ( T^{3/4}\nd^{1/2} )$ regret bound for $\\widetilde{\\text{EG}}$. 2. For online portfolio\nselection, the regret of online mirror descent with the logarithmic barrier is\n$\\tilde{O}(\\sqrt{T d})$. The regret bound is the same as that of Soft-Bayes due\nto Orseau et al. up to logarithmic terms. 3. For online learning quantum states\nwith the logarithmic loss, the regret of online mirror descent with the\nlog-determinant function is also $\\tilde{O} ( \\sqrt{T d} )$. Its per-iteration\ntime is shorter than all existing algorithms we know.",
          "link": "http://arxiv.org/abs/2210.00997",
          "publishedOn": "2023-09-23T00:40:39.178Z",
          "wordCount": 778,
          "title": "Online Self-Concordant and Relatively Smooth Minimization, With Applications to Online Portfolio Selection and Learning Quantum States. (arXiv:2210.00997v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.09517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Q/0/1/0/all/0/1\">Qiying Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Ruofan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tengfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yifei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiqiang Wang</a>",
          "description": "Federated training of Graph Neural Networks (GNN) has become popular in\nrecent years due to its ability to perform graph-related tasks under data\nisolation scenarios while preserving data privacy. However, graph heterogeneity\nissues in federated GNN systems continue to pose challenges. Existing\nframeworks address the problem by representing local tasks using different\nstatistics and relating them through a simple aggregation mechanism. However,\nthese approaches suffer from limited efficiency from two aspects: low quality\nof task-relatedness quantification and inefficacy of exploiting the\ncollaboration structure. To address these issues, we propose FedGKD, a novel\nfederated GNN framework that utilizes a novel client-side graph dataset\ndistillation method to extract task features that better describe\ntask-relatedness, and introduces a novel server-side aggregation mechanism that\nis aware of the global collaboration structure. We conduct extensive\nexperiments on six real-world datasets of different scales, demonstrating our\nframework's outperformance.",
          "link": "http://arxiv.org/abs/2309.09517",
          "publishedOn": "2023-09-23T00:40:39.045Z",
          "wordCount": null,
          "title": "FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural Networks. (arXiv:2309.09517v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1\">Hao Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoqun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aimin Zhou</a>",
          "description": "Surrogate-assisted evolutionary algorithms (SAEAs) hold significant\nimportance in resolving expensive optimization problems~(EOPs). Extensive\nefforts have been devoted to improving the efficacy of SAEAs through the\ndevelopment of proficient model-assisted selection methods. However, generating\nhigh-quality solutions is a prerequisite for selection. The fundamental\nparadigm of evaluating a limited number of solutions in each generation within\nSAEAs reduces the variance of adjacent populations, thus impacting the quality\nof offspring solutions. This is a frequently encountered issue, yet it has not\ngained widespread attention. This paper presents a framework using unevaluated\nsolutions to enhance the efficiency of SAEAs. The surrogate model is employed\nto identify high-quality solutions for direct generation of new solutions\nwithout evaluation. To ensure dependable selection, we have introduced two\ntailored relation models for the selection of the optimal solution and the\nunevaluated population. A comprehensive experimental analysis is performed on\ntwo test suites, which showcases the superiority of the relation model over\nregression and classification models in the selection phase. Furthermore, the\nsurrogate-selected unevaluated solutions with high potential have been shown to\nsignificantly enhance the efficiency of the algorithm.",
          "link": "http://arxiv.org/abs/2309.11994",
          "publishedOn": "2023-09-23T00:40:39.044Z",
          "wordCount": null,
          "title": "Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model for Expensive Optimization. (arXiv:2309.11994v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gabburo_M/0/1/0/all/0/1\">Matteo Gabburo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Siddhant Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kedziorski_R/0/1/0/all/0/1\">Rik Koncel Kedziorski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moschitti_A/0/1/0/all/0/1\">Alessandro Moschitti</a>",
          "description": "Evaluation of QA systems is very challenging and expensive, with the most\nreliable approach being human annotations of correctness of answers for\nquestions. Recent works (AVA, BEM) have shown that transformer LM encoder based\nsimilarity metrics transfer well for QA evaluation, but they are limited by the\nusage of a single correct reference answer. We propose a new evaluation metric:\nSQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference\nanswers (combining multiple correct and incorrect references) for sentence-form\nQA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and\ngenerative (GenQA) QA systems, across multiple academic and industrial\ndatasets, and show that it outperforms previous baselines and obtains the\nhighest correlation with human annotations.",
          "link": "http://arxiv.org/abs/2309.12250",
          "publishedOn": "2023-09-23T00:40:39.044Z",
          "wordCount": null,
          "title": "SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References. (arXiv:2309.12250v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.10424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vedder_K/0/1/0/all/0/1\">Kyle Vedder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peri_N/0/1/0/all/0/1\">Neehar Peri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chodosh_N/0/1/0/all/0/1\">Nathaniel Chodosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khatri_I/0/1/0/all/0/1\">Ishan Khatri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1\">Dinesh Jayaraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hays_J/0/1/0/all/0/1\">James Hays</a>",
          "description": "Scene flow estimation is the task of describing the 3D motion field between\ntemporally successive point clouds. State-of-the-art methods use strong priors\nand test-time optimization techniques, but require on the order of tens of\nseconds to process large-scale point clouds, making them unusable as computer\nvision primitives for real-time applications such as open world object\ndetection. Feed forward methods are considerably faster, running on the order\nof tens to hundreds of milliseconds for large-scale point clouds, but require\nexpensive human supervision. To address both limitations, we propose Scene Flow\nvia Distillation, a simple, scalable distillation framework that uses a\nlabel-free optimization method to produce pseudo-labels to supervise a feed\nforward model. Our instantiation of this framework, ZeroFlow, achieves\nstate-of-the-art performance on the Argoverse 2 Self-Supervised Scene Flow\nChallenge while using zero human labels by simply training on large-scale,\ndiverse unlabeled data. At test-time, ZeroFlow is over 1000$\\times$ faster than\nlabel-free state-of-the-art optimization-based methods on large-scale point\nclouds and over 1000$\\times$ cheaper to train on unlabeled data compared to the\ncost of human annotation of that data. To facilitate further research, we will\nrelease our code, trained model weights, and high quality pseudo-labels for the\nArgoverse 2 and Waymo Open datasets.",
          "link": "http://arxiv.org/abs/2305.10424",
          "publishedOn": "2023-09-23T00:40:39.037Z",
          "wordCount": null,
          "title": "ZeroFlow: Fast, Zero Label, Scalable Scene Flow via Distillation. (arXiv:2305.10424v5 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.07929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gallego_V/0/1/0/all/0/1\">Victor Gallego</a>",
          "description": "Recently, large multimodal models, such as CLIP and Stable Diffusion have\nexperimented tremendous successes in both foundations and applications.\nHowever, as these models increase in parameter size and computational\nrequirements, it becomes more challenging for users to personalize them for\nspecific tasks or preferences. In this work, we address the problem of adapting\nthe previous models towards sets of particular human preferences, aligning the\nretrieved or generated images with the preferences of the user. We leverage the\nBradley-Terry preference model to develop a fast adaptation method that\nefficiently fine-tunes the original model, with few examples and with minimal\ncomputing resources. Extensive evidence of the capabilities of this framework\nis provided through experiments in different domains related to multimodal text\nand image understanding, including preference prediction as a reward model, and\ngeneration tasks.",
          "link": "http://arxiv.org/abs/2308.07929",
          "publishedOn": "2023-09-23T00:40:39.037Z",
          "wordCount": null,
          "title": "Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation. (arXiv:2308.07929v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guzey_I/0/1/0/all/0/1\">Irmak Guzey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yinlong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_B/0/1/0/all/0/1\">Ben Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chintala_S/0/1/0/all/0/1\">Soumith Chintala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_L/0/1/0/all/0/1\">Lerrel Pinto</a>",
          "description": "Equipping multi-fingered robots with tactile sensing is crucial for achieving\nthe precise, contact-rich, and dexterous manipulation that humans excel at.\nHowever, relying solely on tactile sensing fails to provide adequate cues for\nreasoning about objects' spatial configurations, limiting the ability to\ncorrect errors and adapt to changing situations. In this paper, we present\nTactile Adaptation from Visual Incentives (TAVI), a new framework that enhances\ntactile-based dexterity by optimizing dexterous policies using vision-based\nrewards. First, we use a contrastive-based objective to learn visual\nrepresentations. Next, we construct a reward function using these visual\nrepresentations through optimal-transport based matching on one human\ndemonstration. Finally, we use online reinforcement learning on our robot to\noptimize tactile-based policies that maximize the visual reward. On six\nchallenging tasks, such as peg pick-and-place, unstacking bowls, and flipping\nslender objects, TAVI achieves a success rate of 73% using our four-fingered\nAllegro robot hand. The increase in performance is 108% higher than policies\nusing tactile and vision-based rewards and 135% higher than policies without\ntactile observational input. Robot videos are best viewed on our project\nwebsite: https://see-to-touch.github.io/.",
          "link": "http://arxiv.org/abs/2309.12300",
          "publishedOn": "2023-09-23T00:40:39.036Z",
          "wordCount": null,
          "title": "See to Touch: Learning Tactile Dexterity through Visual Incentives. (arXiv:2309.12300v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maman_B/0/1/0/all/0/1\">Ben Maman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeitler_J/0/1/0/all/0/1\">Johannes Zeitler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1\">Meinard M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1\">Amit H. Bermano</a>",
          "description": "Generating multi-instrument music from symbolic music representations is an\nimportant task in Music Information Retrieval (MIR). A central but still\nlargely unsolved problem in this context is musically and acoustically informed\ncontrol in the generation process. As the main contribution of this work, we\npropose enhancing control of multi-instrument synthesis by conditioning a\ngenerative model on a specific performance and recording environment, thus\nallowing for better guidance of timbre and style. Building on state-of-the-art\ndiffusion-based music generative models, we introduce performance conditioning\n- a simple tool indicating the generative model to synthesize music with style\nand timbre of specific instruments taken from specific performances. Our\nprototype is evaluated using uncurated performances with diverse\ninstrumentation and achieves state-of-the-art FAD realism scores while allowing\nnovel timbre and style control. Our project page, including samples and\ndemonstrations, is available at benadar293.github.io/midipm",
          "link": "http://arxiv.org/abs/2309.12283",
          "publishedOn": "2023-09-23T00:40:39.035Z",
          "wordCount": null,
          "title": "Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis. (arXiv:2309.12283v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blanc_G/0/1/0/all/0/1\">Guy Blanc</a>",
          "description": "Ensuring that analyses performed on a dataset are representative of the\nentire population is one of the central problems in statistics. Most classical\ntechniques assume that the dataset is independent of the analyst's query and\nbreak down in the common setting where a dataset is reused for multiple,\nadaptively chosen, queries. This problem of \\emph{adaptive data analysis} was\nformalized in the seminal works of Dwork et al. (STOC, 2015) and Hardt and\nUllman (FOCS, 2014).\n\nWe identify a remarkably simple set of assumptions under which the queries\nwill continue to be representative even when chosen adaptively: The only\nrequirements are that each query takes as input a random subsample and outputs\nfew bits. This result shows that the noise inherent in subsampling is\nsufficient to guarantee that query responses generalize. The simplicity of this\nsubsampling-based framework allows it to model a variety of real-world\nscenarios not covered by prior work.\n\nIn addition to its simplicity, we demonstrate the utility of this framework\nby designing mechanisms for two foundational tasks, statistical queries and\nmedian finding. In particular, our mechanism for answering the broadly\napplicable class of statistical queries is both extremely simple and state of\nthe art in many parameter regimes.",
          "link": "http://arxiv.org/abs/2302.08661",
          "publishedOn": "2023-09-23T00:40:39.031Z",
          "wordCount": null,
          "title": "Subsampling Suffices for Adaptive Data Analysis. (arXiv:2302.08661v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1\">Ilias Diakonikolas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1\">Sushrut Karmalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jongho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1\">Christos Tzamos</a>",
          "description": "We demonstrate the first algorithms for the problem of regression for\ngeneralized linear models (GLMs) in the presence of additive oblivious noise.\nWe assume we have sample access to examples $(x, y)$ where $y$ is a noisy\nmeasurement of $g(w^* \\cdot x)$. In particular, \\new{the noisy labels are of\nthe form} $y = g(w^* \\cdot x) + \\xi + \\epsilon$, where $\\xi$ is the oblivious\nnoise drawn independently of $x$ \\new{and satisfies} $\\Pr[\\xi = 0] \\geq o(1)$,\nand $\\epsilon \\sim \\mathcal N(0, \\sigma^2)$. Our goal is to accurately recover\na \\new{parameter vector $w$ such that the} function $g(w \\cdot x)$ \\new{has}\narbitrarily small error when compared to the true values $g(w^* \\cdot x)$,\nrather than the noisy measurements $y$.\n\nWe present an algorithm that tackles \\new{this} problem in its most general\ndistribution-independent setting, where the solution may not \\new{even} be\nidentifiable. \\new{Our} algorithm returns \\new{an accurate estimate of} the\nsolution if it is identifiable, and otherwise returns a small list of\ncandidates, one of which is close to the true solution. Furthermore, we\n\\new{provide} a necessary and sufficient condition for identifiability, which\nholds in broad settings. \\new{Specifically,} the problem is identifiable when\nthe quantile at which $\\xi + \\epsilon = 0$ is known, or when the family of\nhypotheses does not contain candidates that are nearly equal to a translated\n$g(w^* \\cdot x) + A$ for some real number $A$, while also having large error\nwhen compared to $g(w^* \\cdot x)$.\n\nThis is the first \\new{algorithmic} result for GLM regression \\new{with\noblivious noise} which can handle more than half the samples being arbitrarily\ncorrupted. Prior work focused largely on the setting of linear regression, and\ngave algorithms under restrictive assumptions.",
          "link": "http://arxiv.org/abs/2309.11657",
          "publishedOn": "2023-09-23T00:40:38.978Z",
          "wordCount": null,
          "title": "GLM Regression with Oblivious Corruptions. (arXiv:2309.11657v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12041",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kirsche_M/0/1/0/all/0/1\">Moritz Kirsche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peinemann_T/0/1/0/all/0/1\">Thorsten Peinemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stock_J/0/1/0/all/0/1\">Joshua Stock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotrini_C/0/1/0/all/0/1\">Carlos Cotrini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_E/0/1/0/all/0/1\">Esfandiar Mohammadi</a>",
          "description": "Privacy-preserving learning of gradient boosting decision trees (GBDT) has\nthe potential for strong utility-privacy tradeoffs for tabular data, such as\ncensus data or medical meta data: classical GBDT learners can extract\nnon-linear patterns from small sized datasets. The state-of-the-art notion for\nprovable privacy-properties is differential privacy, which requires that the\nimpact of single data points is limited and deniable. We introduce a novel\ndifferentially private GBDT learner and utilize four main techniques to improve\nthe utility-privacy tradeoff. (1) We use an improved noise scaling approach\nwith tighter accounting of privacy leakage of a decision tree leaf compared to\nprior work, resulting in noise that in expectation scales with $O(1/n)$, for\n$n$ data points. (2) We integrate individual R\\'enyi filters to our method to\nlearn from data points that have been underutilized during an iterative\ntraining process, which -- potentially of independent interest -- results in a\nnatural yet effective insight to learning streams of non-i.i.d. data. (3) We\nincorporate the concept of random decision tree splits to concentrate privacy\nbudget on learning leaves. (4) We deploy subsampling for privacy amplification.\nOur evaluation shows for the Abalone dataset ($<4k$ training data points) a\n$R^2$-score of $0.39$ for $\\varepsilon=0.15$, which the closest prior work only\nachieved for $\\varepsilon=10.0$. On the Adult dataset ($50k$ training data\npoints) we achieve test error of $18.7\\,\\%$ for $\\varepsilon=0.07$ which the\nclosest prior work only achieved for $\\varepsilon=1.0$. For the Abalone dataset\nfor $\\varepsilon=0.54$ we achieve $R^2$-score of $0.47$ which is very close to\nthe $R^2$-score of $0.54$ for the nonprivate version of GBDT. For the Adult\ndataset for $\\varepsilon=0.54$ we achieve test error $17.1\\,\\%$ which is very\nclose to the test error $13.7\\,\\%$ of the nonprivate version of GBDT.",
          "link": "http://arxiv.org/abs/2309.12041",
          "publishedOn": "2023-09-23T00:40:38.978Z",
          "wordCount": null,
          "title": "S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees. (arXiv:2309.12041v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhonglin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sciabola_S/0/1/0/all/0/1\">Simone Sciabola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye Wang</a>",
          "description": "Virtual screening of large compound libraries to identify potential hit\ncandidates is one of the earliest steps in drug discovery. As the size of\ncommercially available compound collections grows exponentially to the scale of\nbillions, brute-force virtual screening using traditional tools such as docking\nbecomes infeasible in terms of time and computational resources. Active\nlearning and Bayesian optimization has recently been proven as effective\nmethods of narrowing down the search space. An essential component in those\nmethods is a surrogate machine learning model that is trained with a small\nsubset of the library to predict the desired properties of compounds. Accurate\nmodel can achieve high sample efficiency by finding the most promising\ncompounds with only a fraction of the whole library being virtually screened.\nIn this study, we examined the performance of pretrained transformer-based\nlanguage model and graph neural network in Bayesian optimization active\nlearning framework. The best pretrained models identifies 58.97% of the\ntop-50000 by docking score after screening only 0.6% of an ultra-large library\ncontaining 99.5 million compounds, improving 8% over previous state-of-the-art\nbaseline. Through extensive benchmarks, we show that the superior performance\nof pretrained models persists in both structure-based and ligand-based drug\ndiscovery. Such model can serve as a boost to the accuracy and sample\nefficiency of active learning based molecule virtual screening.",
          "link": "http://arxiv.org/abs/2309.11687",
          "publishedOn": "2023-09-23T00:40:38.977Z",
          "wordCount": null,
          "title": "Large-scale Pretraining Improves Sample Efficiency of Active Learning based Molecule Virtual Screening. (arXiv:2309.11687v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Rajesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isik_C/0/1/0/all/0/1\">Can Isik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_C/0/1/0/all/0/1\">Chilukuri K. Mohan</a>",
          "description": "We present a novel adversarial model for authentication systems that use gait\npatterns recorded by the inertial measurement unit (IMU) built into\nsmartphones. The attack idea is inspired by and named after the concept of a\ndictionary attack on knowledge (PIN or password) based authentication systems.\nIn particular, this work investigates whether it is possible to build a\ndictionary of IMUGait patterns and use it to launch an attack or find an\nimitator who can actively reproduce IMUGait patterns that match the target's\nIMUGait pattern. Nine physically and demographically diverse individuals walked\nat various levels of four predefined controllable and adaptable gait factors\n(speed, step length, step width, and thigh-lift), producing 178 unique IMUGait\npatterns. Each pattern attacked a wide variety of user authentication models.\nThe deeper analysis of error rates (before and after the attack) challenges the\nbelief that authentication systems based on IMUGait patterns are the most\ndifficult to spoof; further research is needed on adversarial models and\nassociated countermeasures.",
          "link": "http://arxiv.org/abs/2309.11766",
          "publishedOn": "2023-09-23T00:40:38.977Z",
          "wordCount": null,
          "title": "Dictionary Attack on IMU-based Gait Authentication. (arXiv:2309.11766v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brack_M/0/1/0/all/0/1\">Manuel Brack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schramowski_P/0/1/0/all/0/1\">Patrick Schramowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "Text-conditioned image generation models have recently achieved astonishing\nimage quality and alignment results. Consequently, they are employed in a\nfast-growing number of applications. Since they are highly data-driven, relying\non billion-sized datasets randomly scraped from the web, they also produce\nunsafe content. As a contribution to the Adversarial Nibbler challenge, we\ndistill a large set of over 1,000 potential adversarial inputs from existing\nsafety benchmarks. Our analysis of the gathered prompts and corresponding\nimages demonstrates the fragility of input filters and provides further\ninsights into systematic safety issues in current generative image models.",
          "link": "http://arxiv.org/abs/2309.11575",
          "publishedOn": "2023-09-23T00:40:38.965Z",
          "wordCount": null,
          "title": "Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge. (arXiv:2309.11575v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sen_A/0/1/0/all/0/1\">Anuvab Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_A/0/1/0/all/0/1\">Arul Rhik Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_U/0/1/0/all/0/1\">Udayon Sen</a>",
          "description": "Accurate load forecasting plays a vital role in numerous sectors, but\naccurately capturing the complex dynamics of dynamic power systems remains a\nchallenge for traditional statistical models. For these reasons, time-series\nmodels (ARIMA) and deep-learning models (ANN, LSTM, GRU, etc.) are commonly\ndeployed and often experience higher success. In this paper, we analyze the\nefficacy of the recently developed Transformer-based Neural Network model in\nLoad forecasting. Transformer models have the potential to improve Load\nforecasting because of their ability to learn long-range dependencies derived\nfrom their Attention Mechanism. We apply several metaheuristics namely\nDifferential Evolution to find the optimal hyperparameters of the\nTransformer-based Neural Network to produce accurate forecasts. Differential\nEvolution provides scalable, robust, global solutions to non-differentiable,\nmulti-objective, or constrained optimization problems. Our work compares the\nproposed Transformer based Neural Network model integrated with different\nmetaheuristic algorithms by their performance in Load forecasting based on\nnumerical metrics such as Mean Squared Error (MSE) and Mean Absolute Percentage\nError (MAPE). Our findings demonstrate the potential of metaheuristic-enhanced\nTransformer-based Neural Network models in Load forecasting accuracy and\nprovide optimal hyperparameters for each model.",
          "link": "http://arxiv.org/abs/2307.15299",
          "publishedOn": "2023-09-23T00:40:38.965Z",
          "wordCount": null,
          "title": "Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting. (arXiv:2307.15299v3 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhen Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guangquan Zhang</a>",
          "description": "Out-of-distribution (OOD) detection is crucial to modern deep learning\napplications by identifying and alerting about the OOD samples that should not\nbe tested or used for making predictions. Current OOD detection methods have\nmade significant progress when in-distribution (ID) and OOD samples are drawn\nfrom static distributions. However, this can be unrealistic when applied to\nreal-world systems which often undergo continuous variations and shifts in ID\nand OOD distributions over time. Therefore, for an effective application in\nreal-world systems, the development of OOD detection methods that can adapt to\nthese dynamic and evolving distributions is essential. In this paper, we\npropose a novel and more realistic setting called continuously adaptive\nout-of-distribution (CAOOD) detection which targets on developing an OOD\ndetection model that enables dynamic and quick adaptation to a new arriving\ndistribution, with insufficient ID samples during deployment time. To address\nCAOOD, we develop meta OOD learning (MOL) by designing a learning-to-adapt\ndiagram such that a good initialized OOD detection model is learned during the\ntraining process. In the testing process, MOL ensures OOD detection performance\nover shifting distributions by quickly adapting to new distributions with a few\nadaptations. Extensive experiments on several OOD benchmarks endorse the\neffectiveness of our method in preserving both ID classification accuracy and\nOOD detection performance on continuously shifting distributions.",
          "link": "http://arxiv.org/abs/2309.11705",
          "publishedOn": "2023-09-23T00:40:38.952Z",
          "wordCount": null,
          "title": "Meta OOD Learning for Continuously Adaptive OOD Detection. (arXiv:2309.11705v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berglund_L/0/1/0/all/0/1\">Lukas Berglund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1\">Meg Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_M/0/1/0/all/0/1\">Max Kaufmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balesni_M/0/1/0/all/0/1\">Mikita Balesni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stickland_A/0/1/0/all/0/1\">Asa Cooper Stickland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_O/0/1/0/all/0/1\">Owain Evans</a>",
          "description": "We expose a surprising failure of generalization in auto-regressive large\nlanguage models (LLMs). If a model is trained on a sentence of the form \"A is\nB\", it will not automatically generalize to the reverse direction \"B is A\".\nThis is the Reversal Curse. For instance, if a model is trained on \"Olaf Scholz\nwas the ninth Chancellor of Germany\", it will not automatically be able to\nanswer the question, \"Who was the ninth Chancellor of Germany?\". Moreover, the\nlikelihood of the correct answer (\"Olaf Scholz\") will not be higher than for a\nrandom name. Thus, models exhibit a basic failure of logical deduction and do\nnot generalize a prevalent pattern in their training set (i.e. if \"A is B''\noccurs, \"B is A\" is more likely to occur). We provide evidence for the Reversal\nCurse by finetuning GPT-3 and Llama-1 on fictitious statements such as \"Uriah\nHawthorne is the composer of 'Abyssal Melodies'\" and showing that they fail to\ncorrectly answer \"Who composed 'Abyssal Melodies?'\". The Reversal Curse is\nrobust across model sizes and model families and is not alleviated by data\naugmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about\nreal-world celebrities, such as \"Who is Tom Cruise's mother? [A: Mary Lee\nPfeiffer]\" and the reverse \"Who is Mary Lee Pfeiffer's son?\". GPT-4 correctly\nanswers questions like the former 79% of the time, compared to 33% for the\nlatter. This shows a failure of logical deduction that we hypothesize is caused\nby the Reversal Curse. Code is available at\nhttps://github.com/lukasberglund/reversal_curse.",
          "link": "http://arxiv.org/abs/2309.12288",
          "publishedOn": "2023-09-23T00:40:38.950Z",
          "wordCount": null,
          "title": "The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\". (arXiv:2309.12288v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.02998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Beidi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Boxin Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>",
          "description": "Graph Neural Networks (GNNs) have achieved tremendous success in a variety of\nreal-world applications by relying on the fixed graph data as input. However,\nthe initial input graph might not be optimal in terms of specific downstream\ntasks, because of information scarcity, noise, adversarial attacks, or\ndiscrepancies between the distribution in graph topology, features, and\ngroundtruth labels. In this paper, we propose a bi-level optimization approach\nfor learning the optimal graph structure via directly learning the Personalized\nPageRank propagation matrix as well as the downstream semi-supervised node\nclassification simultaneously. We also explore a low-rank approximation model\nfor further reducing the time complexity. Empirical evaluations show the\nsuperior efficacy and robustness of the proposed model over all baseline\nmethods.",
          "link": "http://arxiv.org/abs/2205.02998",
          "publishedOn": "2023-09-23T00:40:38.949Z",
          "wordCount": null,
          "title": "Optimal Propagation for Graph Neural Networks. (arXiv:2205.02998v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kouzelis_T/0/1/0/all/0/1\">Theodoros Kouzelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katsouros_V/0/1/0/all/0/1\">Vassilis Katsouros</a>",
          "description": "In recent years, datasets of paired audio and captions have enabled\nremarkable success in automatically generating descriptions for audio clips,\nnamely Automated Audio Captioning (AAC). However, it is labor-intensive and\ntime-consuming to collect a sufficient number of paired audio and captions.\nMotivated by the recent advances in Contrastive Language-Audio Pretraining\n(CLAP), we propose a weakly-supervised approach to train an AAC model assuming\nonly text data and a pre-trained CLAP model, alleviating the need for paired\ntarget data. Our approach leverages the similarity between audio and text\nembeddings in CLAP. During training, we learn to reconstruct the text from the\nCLAP text embedding, and during inference, we decode using the audio\nembeddings. To mitigate the modality gap between the audio and text embeddings\nwe employ strategies to bridge the gap during training and inference stages. We\nevaluate our proposed method on Clotho and AudioCaps datasets demonstrating its\nability to achieve a relative performance of up to ~$83\\%$ compared to fully\nsupervised approaches trained with paired target data.",
          "link": "http://arxiv.org/abs/2309.12242",
          "publishedOn": "2023-09-23T00:40:38.948Z",
          "wordCount": null,
          "title": "Weakly-supervised Automated Audio Captioning via text only training. (arXiv:2309.12242v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_T/0/1/0/all/0/1\">Tiago da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_E/0/1/0/all/0/1\">Eliezer Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ad&#xe8;le Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gois_A/0/1/0/all/0/1\">Ant&#xf3;nio G&#xf3;is</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heider_D/0/1/0/all/0/1\">Dominik Heider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mesquita_D/0/1/0/all/0/1\">Diego Mesquita</a>",
          "description": "Structure learning is the crux of causal inference. Notably, causal discovery\n(CD) algorithms are brittle when data is scarce, possibly inferring imprecise\ncausal relations that contradict expert knowledge -- especially when\nconsidering latent confounders. To aggravate the issue, most CD methods do not\nprovide uncertainty estimates, making it hard for users to interpret results\nand improve the inference process. Surprisingly, while CD is a human-centered\naffair, no works have focused on building methods that both 1) output\nuncertainty estimates that can be verified by experts and 2) interact with\nthose experts to iteratively refine CD. To solve these issues, we start by\nproposing to sample (causal) ancestral graphs proportionally to a belief\ndistribution based on a score function, such as the Bayesian information\ncriterion (BIC), using generative flow networks. Then, we leverage the\ndiversity in candidate graphs and introduce an optimal experimental design to\niteratively probe the expert about the relations among variables, effectively\nreducing the uncertainty of our belief over ancestral graphs. Finally, we\nupdate our samples to incorporate human feedback via importance sampling.\nImportantly, our method does not require causal sufficiency (i.e., unobserved\nconfounders may exist). Experiments with synthetic observational data show that\nour method can accurately sample from distributions over ancestral graphs and\nthat we can greatly improve inference quality with human aid.",
          "link": "http://arxiv.org/abs/2309.12032",
          "publishedOn": "2023-09-23T00:40:38.946Z",
          "wordCount": null,
          "title": "Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets. (arXiv:2309.12032v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12078",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamers_C/0/1/0/all/0/1\">Christiaan Lamers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Rene Vidal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belbachir_N/0/1/0/all/0/1\">Nabil Belbachir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stein_N/0/1/0/all/0/1\">Niki van Stein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baeck_T/0/1/0/all/0/1\">Thomas Baeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giampouras_P/0/1/0/all/0/1\">Paris Giampouras</a>",
          "description": "We consider the problem of learning multiple tasks in a continual learning\nsetting in which data from different tasks is presented to the learner in a\nstreaming fashion. A key challenge in this setting is the so-called\n\"catastrophic forgetting problem\", in which the performance of the learner in\nan \"old task\" decreases when subsequently trained on a \"new task\". Existing\ncontinual learning methods, such as Averaged Gradient Episodic Memory (A-GEM)\nand Orthogonal Gradient Descent (OGD), address catastrophic forgetting by\nminimizing the loss for the current task without increasing the loss for\nprevious tasks. However, these methods assume the learner knows when the task\nchanges, which is unrealistic in practice. In this paper, we alleviate the need\nto provide the algorithm with information about task changes by using an online\nclustering-based approach on a dynamically updated finite pool of samples or\ngradients. We thereby successfully counteract catastrophic forgetting in one of\nthe hardest settings, namely: domain-incremental learning, a setting for which\nthe problem was previously unsolved. We showcase the benefits of our approach\nby applying these ideas to projection-based methods, such as A-GEM and OGD,\nwhich lead to task-agnostic versions of them. Experiments on real datasets\ndemonstrate the effectiveness of the proposed strategy and its promising\nperformance compared to state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2309.12078",
          "publishedOn": "2023-09-23T00:40:38.944Z",
          "wordCount": null,
          "title": "Clustering-based Domain-Incremental Learning. (arXiv:2309.12078v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.05237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prabowo_A/0/1/0/all/0/1\">Arian Prabowo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1\">Piotr Koniusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>",
          "description": "New roads are being constructed all the time. However, the capabilities of\nprevious deep forecasting models to generalize to new roads not seen in the\ntraining data (unseen roads) are rarely explored. In this paper, we introduce a\nnovel setup called a spatio-temporal (ST) split to evaluate the models'\ncapabilities to generalize to unseen roads. In this setup, the models are\ntrained on data from a sample of roads, but tested on roads not seen in the\ntraining data. Moreover, we also present a novel framework called Spatial\nContrastive Pre-Training (SCPT) where we introduce a spatial encoder module to\nextract latent features from unseen roads during inference time. This spatial\nencoder is pre-trained using contrastive learning. During inference, the\nspatial encoder only requires two days of traffic data on the new roads and\ndoes not require any re-training. We also show that the output from the spatial\nencoder can be used effectively to infer latent node embeddings on unseen roads\nduring inference time. The SCPT framework also incorporates a new layer, named\nthe spatially gated addition (SGA) layer, to effectively combine the latent\nfeatures from the output of the spatial encoder to existing backbones.\nAdditionally, since there is limited data on the unseen roads, we argue that it\nis better to decouple traffic signals to trivial-to-capture periodic signals\nand difficult-to-capture Markovian signals, and for the spatial encoder to only\nlearn the Markovian signals. Finally, we empirically evaluated SCPT using the\nST split setup on four real-world datasets. The results showed that adding SCPT\nto a backbone consistently improves forecasting performance on unseen roads.\nMore importantly, the improvements are greater when forecasting further into\nthe future. The codes are available on GitHub:\nhttps://github.com/cruiseresearchgroup/forecasting-on-new-roads .",
          "link": "http://arxiv.org/abs/2305.05237",
          "publishedOn": "2023-09-23T00:40:38.943Z",
          "wordCount": null,
          "title": "Traffic Forecasting on New Roads Using Spatial Contrastive Pre-Training (SCPT). (arXiv:2305.05237v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11714",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jiao_J/0/1/0/all/0/1\">Jie Jiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Meiyan Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Q/0/1/0/all/0/1\">Qingqing Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1\">Hefan Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_W/0/1/0/all/0/1\">Wangliang Zhou</a>",
          "description": "There is a correlation between adjacent channels of electroencephalogram\n(EEG), and how to represent this correlation is an issue that is currently\nbeing explored. In addition, due to inter-individual differences in EEG\nsignals, this discrepancy results in new subjects need spend a amount of\ncalibration time for EEG-based motor imagery brain-computer interface. In order\nto solve the above problems, we propose a Dynamic Domain Adaptation Based Deep\nLearning Network (DADL-Net). First, the EEG data is mapped to the\nthree-dimensional geometric space and its temporal-spatial features are learned\nthrough the 3D convolution module, and then the spatial-channel attention\nmechanism is used to strengthen the features, and the final convolution module\ncan further learn the spatial-temporal information of the features. Finally, to\naccount for inter-subject and cross-sessions differences, we employ a dynamic\ndomain-adaptive strategy, the distance between features is reduced by\nintroducing a Maximum Mean Discrepancy loss function, and the classification\nlayer is fine-tuned by using part of the target domain data. We verify the\nperformance of the proposed method on BCI competition IV 2a and OpenBMI\ndatasets. Under the intra-subject experiment, the accuracy rates of 70.42% and\n73.91% were achieved on the OpenBMI and BCIC IV 2a datasets.",
          "link": "http://arxiv.org/abs/2309.11714",
          "publishedOn": "2023-09-23T00:40:38.939Z",
          "wordCount": null,
          "title": "A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification. (arXiv:2309.11714v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_L/0/1/0/all/0/1\">Luis Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1\">Gerhard Widmer</a>",
          "description": "A range of applications of multi-modal music information retrieval is centred\naround the problem of connecting large collections of sheet music (images) to\ncorresponding audio recordings, that is, identifying pairs of audio and score\nexcerpts that refer to the same musical content. One of the typical and most\nrecent approaches to this task employs cross-modal deep learning architectures\nto learn joint embedding spaces that link the two distinct modalities - audio\nand sheet music images. While there has been steady improvement on this front\nover the past years, a number of open problems still prevent large-scale\nemployment of this methodology. In this article we attempt to provide an\ninsightful examination of the current developments on audio-sheet music\nretrieval via deep learning methods. We first identify a set of main challenges\non the road towards robust and large-scale cross-modal music retrieval in real\nscenarios. We then highlight the steps we have taken so far to address some of\nthese challenges, documenting step-by-step improvement along several\ndimensions. We conclude by analysing the remaining challenges and present ideas\nfor solving these, in order to pave the way to a unified and robust methodology\nfor cross-modal music retrieval.",
          "link": "http://arxiv.org/abs/2309.12158",
          "publishedOn": "2023-09-23T00:40:38.939Z",
          "wordCount": null,
          "title": "Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval. (arXiv:2309.12158v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12201",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhu_X/0/1/0/all/0/1\">Xin Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_H/0/1/0/all/0/1\">Hongyi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rong_S/0/1/0/all/0/1\">Shuaiang Rong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cetin_A/0/1/0/all/0/1\">Ahmet Enis Cetin</a>",
          "description": "Electroencephalogram (EEG) data compression is necessary for wireless\nrecording applications to reduce the amount of data that needs to be\ntransmitted. In this paper, an asymmetrical sparse autoencoder with a discrete\ncosine transform (DCT) layer is proposed to compress EEG signals. The encoder\nmodule of the autoencoder has a combination of a fully connected linear layer\nand the DCT layer to reduce redundant data using hard-thresholding\nnonlinearity. Furthermore, the DCT layer includes trainable hard-thresholding\nparameters and scaling layers to give emphasis or de-emphasis on individual DCT\ncoefficients. Finally, the one-by-one convolutional layer generates the latent\nspace. The sparsity penalty-based cost function is employed to keep the feature\nmap as sparse as possible in the latent space. The latent space data is\ntransmitted to the receiver. The decoder module of the autoencoder is designed\nusing the inverse DCT and two fully connected linear layers to improve the\naccuracy of data reconstruction. In comparison to other state-of-the-art\nmethods, the proposed method significantly improves the average quality score\nin various data compression experiments.",
          "link": "http://arxiv.org/abs/2309.12201",
          "publishedOn": "2023-09-23T00:40:38.939Z",
          "wordCount": null,
          "title": "Electroencephalogram Sensor Data Compression Using An Asymmetrical Sparse Autoencoder With A Discrete Cosine Transform Layer. (arXiv:2309.12201v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chien_J/0/1/0/all/0/1\">Jennifer Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danks_D/0/1/0/all/0/1\">David Danks</a>",
          "description": "The applications of personalized recommender systems are rapidly expanding:\nencompassing social media, online shopping, search engine results, and more.\nThese systems offer a more efficient way to navigate the vast array of items\navailable. However, alongside this growth, there has been increased recognition\nof the potential for algorithmic systems to exhibit and perpetuate biases,\nrisking unfairness in personalized domains. In this work, we explicate the\ninherent tension between personalization and conventional implementations of\nfairness. As an alternative, we propose equity to achieve fairness in the\ncontext of epistemic utility. We provide a mapping between goals and practical\nimplementations and detail policy recommendations across key stakeholders to\nforge a path towards achieving fairness in personalized systems.",
          "link": "http://arxiv.org/abs/2309.11503",
          "publishedOn": "2023-09-23T00:40:38.938Z",
          "wordCount": null,
          "title": "Fairness Vs. Personalization: Towards Equity in Epistemic Utility. (arXiv:2309.11503v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03303",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cuchiero_C/0/1/0/all/0/1\">Christa Cuchiero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmocker_P/0/1/0/all/0/1\">Philipp Schmocker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1\">Josef Teichmann</a>",
          "description": "We introduce so-called functional input neural networks defined on a possibly\ninfinite dimensional weighted space with values also in a possibly infinite\ndimensional output space. To this end, we use an additive family as hidden\nlayer maps and a non-linear activation function applied to each hidden layer.\nRelying on Stone-Weierstrass theorems on weighted spaces, we can prove a global\nuniversal approximation result for generalizations of continuous functions\ngoing beyond the usual approximation on compact sets. This then applies in\nparticular to approximation of (non-anticipative) path space functionals via\nfunctional input neural networks. As a further application of the weighted\nStone-Weierstrass theorem we prove a global universal approximation result for\nlinear functions of the signature. We also introduce the viewpoint of Gaussian\nprocess regression in this setting and show that the reproducing kernel Hilbert\nspace of the signature kernels are Cameron-Martin spaces of certain Gaussian\nprocesses. This paves the way towards uncertainty quantification for signature\nkernel regression.",
          "link": "http://arxiv.org/abs/2306.03303",
          "publishedOn": "2023-09-23T00:40:38.937Z",
          "wordCount": null,
          "title": "Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhepei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chuanhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haifeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>",
          "description": "Most existing works on federated bandits take it for granted that all clients\nare altruistic about sharing their data with the server for the collective good\nwhenever needed. Despite their compelling theoretical guarantee on performance\nand communication efficiency, this assumption is overly idealistic and\noftentimes violated in practice, especially when the algorithm is operated over\nself-interested clients, who are reluctant to share data without explicit\nbenefits. Negligence of such self-interested behaviors can significantly affect\nthe learning efficiency and even the practical operability of federated bandit\nlearning. In light of this, we aim to spark new insights into this\nunder-explored research area by formally introducing an incentivized\ncommunication problem for federated bandits, where the server shall motivate\nclients to share data by providing incentives. Without loss of generality, we\ninstantiate this bandit problem with the contextual linear setting and propose\nthe first incentivized communication protocol, namely, Inc-FedUCB, that\nachieves near-optimal regret with provable communication and incentive cost\nguarantees. Extensive empirical experiments on both synthetic and real-world\ndatasets further validate the effectiveness of the proposed method across\nvarious environments.",
          "link": "http://arxiv.org/abs/2309.11702",
          "publishedOn": "2023-09-23T00:40:38.931Z",
          "wordCount": null,
          "title": "Incentivized Communication for Federated Bandits. (arXiv:2309.11702v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_M/0/1/0/all/0/1\">Mengda Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Genjiu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1\">Jianjun Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingqiang Li</a>",
          "description": "Federated learning is a distributed machine learning system that uses\nparticipants' data to train an improved global model. In federated learning,\nparticipants cooperatively train a global model, and they will receive the\nglobal model and payments. Rational participants try to maximize their\nindividual utility, and they will not input their high-quality data truthfully\nunless they are provided with satisfactory payments based on their data\nquality. Furthermore, federated learning benefits from the cooperative\ncontributions of participants. Accordingly, how to establish an incentive\nmechanism that both incentivizes inputting data truthfully and promotes stable\ncooperation has become an important issue to consider. In this paper, we\nintroduce a data sharing game model for federated learning and employ\ngame-theoretic approaches to design a core-selecting incentive mechanism by\nutilizing a popular concept in cooperative games, the core. In federated\nlearning, the core can be empty, resulting in the core-selecting mechanism\nbecoming infeasible. To address this, our core-selecting mechanism employs a\nrelaxation method and simultaneously minimizes the benefits of inputting false\ndata for all participants. However, this mechanism is computationally expensive\nbecause it requires aggregating exponential models for all possible coalitions,\nwhich is infeasible in federated learning. To address this, we propose an\nefficient core-selecting mechanism based on sampling approximation that only\naggregates models on sampled coalitions to approximate the exact result.\nExtensive experiments verify that the efficient core-selecting mechanism can\nincentivize inputting high-quality data and stable cooperation, while it\nreduces computational overhead compared to the core-selecting mechanism.",
          "link": "http://arxiv.org/abs/2309.11722",
          "publishedOn": "2023-09-23T00:40:38.931Z",
          "wordCount": null,
          "title": "Efficient Core-selecting Incentive Mechanism for Data Sharing in Federated Learning. (arXiv:2309.11722v1 [cs.GT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ning_S/0/1/0/all/0/1\">Songlai Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiakang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yonggang Lu</a>",
          "description": "The study of complex networks has significantly advanced our understanding of\ncommunity structures which serves as a crucial feature of real-world graphs.\nDetecting communities in graphs is a challenging problem with applications in\nsociology, biology, and computer science. Despite the efforts of an\ninterdisciplinary community of scientists, a satisfactory solution to this\nproblem has not yet been achieved. This review article delves into the topic of\ncommunity detection in graphs, which serves as a crucial role in understanding\nthe organization and functioning of complex systems. We begin by introducing\nthe concept of community structure, which refers to the arrangement of vertices\ninto clusters, with strong internal connections and weaker connections between\nclusters. Then, we provide a thorough exposition of various community detection\nmethods, including a new method designed by us. Additionally, we explore\nreal-world applications of community detection in diverse networks. In\nconclusion, this comprehensive review provides a deep understanding of\ncommunity detection in graphs. It serves as a valuable resource for researchers\nand practitioners in multiple disciplines, offering insights into the\nchallenges, methodologies, and applications of community detection in complex\nnetworks.",
          "link": "http://arxiv.org/abs/2309.11798",
          "publishedOn": "2023-09-23T00:40:38.931Z",
          "wordCount": null,
          "title": "A Comprehensive Review of Community Detection in Graphs. (arXiv:2309.11798v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharjee_A/0/1/0/all/0/1\">Amrita Bhattacharjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumarage_T/0/1/0/all/0/1\">Tharindu Kumarage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1\">Raha Moraffah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "Large language models (LLMs) are increasingly being used for generating text\nin a variety of use cases, including journalistic news articles. Given the\npotential malicious nature in which these LLMs can be used to generate\ndisinformation at scale, it is important to build effective detectors for such\nAI-generated text. Given the surge in development of new LLMs, acquiring\nlabeled training data for supervised detectors is a bottleneck. However, there\nmight be plenty of unlabeled text data available, without information on which\ngenerator it came from. In this work we tackle this data problem, in detecting\nAI-generated news text, and frame the problem as an unsupervised domain\nadaptation task. Here the domains are the different text generators, i.e. LLMs,\nand we assume we have access to only the labeled source data and unlabeled\ntarget data. We develop a Contrastive Domain Adaptation framework, called\nConDA, that blends standard domain adaptation techniques with the\nrepresentation power of contrastive learning to learn domain invariant\nrepresentations that are effective for the final unsupervised detection task.\nOur experiments demonstrate the effectiveness of our framework, resulting in\naverage performance gains of 31.7% from the best performing baselines, and\nwithin 0.8% margin of a fully supervised detector. All our code and data is\navailable at https://github.com/AmritaBh/ConDA-gen-text-detection.",
          "link": "http://arxiv.org/abs/2309.03992",
          "publishedOn": "2023-09-23T00:40:38.930Z",
          "wordCount": null,
          "title": "ConDA: Contrastive Domain Adaptation for AI-generated Text Detection. (arXiv:2309.03992v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11782",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1\">Trung Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_T/0/1/0/all/0/1\">Tung Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Thang Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>",
          "description": "Self-supervised learning (SSL) has gained remarkable success, for which\ncontrastive learning (CL) plays a key role. However, the recent development of\nnew non-CL frameworks has achieved comparable or better performance with high\nimprovement potential, prompting researchers to enhance these frameworks\nfurther. Assimilating CL into non-CL frameworks has been thought to be\nbeneficial, but empirical evidence indicates no visible improvements. In view\nof that, this paper proposes a strategy of performing CL along the dimensional\ndirection instead of along the batch direction as done in conventional\ncontrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL\naims to enhance the feature diversity, and it can serve as a regularizer to\nprior SSL frameworks. DimCL has been found to be effective, and the\nhardness-aware property is identified as a critical reason for its success.\nExtensive experimental results reveal that assimilating DimCL into SSL\nframeworks leads to performance improvement by a non-trivial margin on various\ndatasets and backbone architectures.",
          "link": "http://arxiv.org/abs/2309.11782",
          "publishedOn": "2023-09-23T00:40:38.928Z",
          "wordCount": null,
          "title": "DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning. (arXiv:2309.11782v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xinyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_R/0/1/0/all/0/1\">Richard Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1\">Huseyin A. Inan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manoel_A/0/1/0/all/0/1\">Andre Manoel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mireshghallah_F/0/1/0/all/0/1\">Fatemehsadat Mireshghallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zinan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1\">Sivakanth Gopi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>",
          "description": "We study the problem of in-context learning (ICL) with large language models\n(LLMs) on private datasets. This scenario poses privacy risks, as LLMs may leak\nor regurgitate the private examples demonstrated in the prompt. We propose a\nnovel algorithm that generates synthetic few-shot demonstrations from the\nprivate dataset with formal differential privacy (DP) guarantees, and show\nempirically that it can achieve effective ICL. We conduct extensive experiments\non standard benchmarks and compare our algorithm with non-private ICL and\nzero-shot solutions. Our results demonstrate that our algorithm can achieve\ncompetitive performance with strong privacy levels. These results open up new\npossibilities for ICL with privacy protection for a broad range of\napplications.",
          "link": "http://arxiv.org/abs/2309.11765",
          "publishedOn": "2023-09-23T00:40:38.927Z",
          "wordCount": 629,
          "title": "Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation. (arXiv:2309.11765v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.03398",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Park_S/0/1/0/all/0/1\">Sangwoo Park</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Simeone_O/0/1/0/all/0/1\">Osvaldo Simeone</a>",
          "description": "Quantum machine learning is a promising programming paradigm for the\noptimization of quantum algorithms in the current era of noisy intermediate\nscale quantum (NISQ) computers. A fundamental challenge in quantum machine\nlearning is generalization, as the designer targets performance under testing\nconditions, while having access only to limited training data. Existing\ngeneralization analyses, while identifying important general trends and scaling\nlaws, cannot be used to assign reliable and informative \"error bars\" to the\ndecisions made by quantum models. In this article, we propose a general\nmethodology that can reliably quantify the uncertainty of quantum models,\nirrespective of the amount of training data, of the number of shots, of the\nansatz, of the training algorithm, and of the presence of quantum hardware\nnoise. The approach, which builds on probabilistic conformal prediction, turns\nan arbitrary, possibly small, number of shots from a pre-trained quantum model\ninto a set prediction, e.g., an interval, that provably contains the true\ntarget with any desired coverage level. Experimental results confirm the\ntheoretical calibration guarantees of the proposed framework, referred to as\nquantum conformal prediction.",
          "link": "http://arxiv.org/abs/2304.03398",
          "publishedOn": "2023-09-23T00:40:38.919Z",
          "wordCount": null,
          "title": "Quantum Conformal Prediction for Reliable Uncertainty Quantification in Quantum Machine Learning. (arXiv:2304.03398v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_A/0/1/0/all/0/1\">Arun Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopparapu_K/0/1/0/all/0/1\">Kavya Kopparapu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1\">Rob Fergus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1\">Ishita Dasgupta</a>",
          "description": "Hierarchical reinforcement learning has been a compelling approach for\nachieving goal directed behavior over long sequences of actions. However, it\nhas been challenging to implement in realistic or open-ended environments. A\nmain challenge has been to find the right space of sub-goals over which to\ninstantiate a hierarchy. We present a novel approach where we use data from\nhumans solving these tasks to softly supervise the goal space for a set of long\nrange tasks in a 3D embodied environment. In particular, we use unconstrained\nnatural language to parameterize this space. This has two advantages: first, it\nis easy to generate this data from naive human participants; second, it is\nflexible enough to represent a vast range of sub-goals in human-relevant tasks.\nOur approach outperforms agents that clone expert behavior on these tasks, as\nwell as HRL from scratch without this supervised sub-goal space. Our work\npresents a novel approach to combining human expert supervision with the\nbenefits and flexibility of reinforcement learning.",
          "link": "http://arxiv.org/abs/2309.11564",
          "publishedOn": "2023-09-23T00:40:38.917Z",
          "wordCount": null,
          "title": "Hierarchical reinforcement learning with natural language subgoals. (arXiv:2309.11564v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gkolemis_V/0/1/0/all/0/1\">Vasilis Gkolemis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzerefos_A/0/1/0/all/0/1\">Anargiros Tzerefos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalamagas_T/0/1/0/all/0/1\">Theodore Dalamagas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1\">Eirini Ntoutsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diou_C/0/1/0/all/0/1\">Christos Diou</a>",
          "description": "Generalized Additive Models (GAMs) are widely used explainable-by-design\nmodels in various applications. GAMs assume that the output can be represented\nas a sum of univariate functions, referred to as components. However, this\nassumption fails in ML problems where the output depends on multiple features\nsimultaneously. In these cases, GAMs fail to capture the interaction terms of\nthe underlying function, leading to subpar accuracy. To (partially) address\nthis issue, we propose Regionally Additive Models (RAMs), a novel class of\nexplainable-by-design models. RAMs identify subregions within the feature space\nwhere interactions are minimized. Within these regions, it is more accurate to\nexpress the output as a sum of univariate functions (components). Consequently,\nRAMs fit one component per subregion of each feature instead of one component\nper feature. This approach yields a more expressive model compared to GAMs\nwhile retaining interpretability. The RAM framework consists of three steps.\nFirstly, we train a black-box model. Secondly, using Regional Effect Plots, we\nidentify subregions where the black-box model exhibits near-local additivity.\nLastly, we fit a GAM component for each identified subregion. We validate the\neffectiveness of RAMs through experiments on both synthetic and real-world\ndatasets. The results confirm that RAMs offer improved expressiveness compared\nto GAMs while maintaining interpretability.",
          "link": "http://arxiv.org/abs/2309.12215",
          "publishedOn": "2023-09-23T00:40:38.912Z",
          "wordCount": null,
          "title": "Regionally Additive Models: Explainable-by-design models minimizing feature interactions. (arXiv:2309.12215v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Defazio_A/0/1/0/all/0/1\">Aaron Defazio</a>",
          "description": "We consider the problem of estimating the learning rate in adaptive methods,\nsuch as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to\nprovably estimate the distance to the solution $D$, which is needed to set the\nlearning rate optimally. Our techniques are modifications of the D-Adaptation\nmethod for learning-rate-free learning. Our methods improve upon the\nconvergence rate of D-Adaptation by a factor of $O(\\sqrt{\\log(D/d_0)})$, where\n$d_0$ is the initial estimate of $D$. We test our methods on 12 common\nlogistic-regression benchmark datasets, VGG11 and ResNet-50 training on\nCIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on\nCriteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT\ntransformer training on BookWiki. Our experimental results show that our\napproaches consistently outperform D-Adaptation and reach test accuracy values\nclose to that of hand-tuned Adam.",
          "link": "http://arxiv.org/abs/2306.06101",
          "publishedOn": "2023-09-23T00:40:38.910Z",
          "wordCount": null,
          "title": "Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.03269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiayu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haliem_M/0/1/0/all/0/1\">Marina Haliem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_T/0/1/0/all/0/1\">Tian Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>",
          "description": "The use of skills (a.k.a., options) can greatly accelerate exploration in\nreinforcement learning, especially when only sparse reward signals are\navailable. While option discovery methods have been proposed for individual\nagents, in multi-agent reinforcement learning settings, discovering\ncollaborative options that can coordinate the behavior of multiple agents and\nencourage them to visit the under-explored regions of their joint state space\nhas not been considered. In this case, we propose Multi-agent Deep Covering\nOption Discovery, which constructs the multi-agent options through minimizing\nthe expected cover time of the multiple agents' joint state space. Also, we\npropose a novel framework to adopt the multi-agent options in the MARL process.\nIn practice, a multi-agent task can usually be divided into some sub-tasks,\neach of which can be completed by a sub-group of the agents. Therefore, our\nalgorithm framework first leverages an attention mechanism to find\ncollaborative agent sub-groups that would benefit most from coordinated\nactions. Then, a hierarchical algorithm, namely HA-MSAC, is developed to learn\nthe multi-agent options for each sub-group to complete their sub-tasks first,\nand then to integrate them through a high-level policy as the solution of the\nwhole task. This hierarchical option construction allows our framework to\nstrike a balance between scalability and effective collaboration among the\nagents. The evaluation based on multi-agent collaborative tasks shows that the\nproposed algorithm can effectively capture the agent interactions with the\nattention mechanism, successfully identify multi-agent options, and\nsignificantly outperforms prior works using single-agent options or no options,\nin terms of both faster exploration and higher task rewards.",
          "link": "http://arxiv.org/abs/2210.03269",
          "publishedOn": "2023-09-23T00:40:38.909Z",
          "wordCount": null,
          "title": "Multi-agent Deep Covering Skill Discovery. (arXiv:2210.03269v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.06424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pabbaraju_C/0/1/0/all/0/1\">Chirag Pabbaraju</a>",
          "description": "A hypothesis class admits a sample compression scheme, if for every sample\nlabeled by a hypothesis from the class, it is possible to retain only a small\nsubsample, using which the labels on the entire sample can be inferred. The\nsize of the compression scheme is an upper bound on the size of the subsample\nproduced. Every learnable binary hypothesis class (which must necessarily have\nfinite VC dimension) admits a sample compression scheme of size only a finite\nfunction of its VC dimension, independent of the sample size. For multiclass\nhypothesis classes, the analog of VC dimension is the DS dimension. We show\nthat the analogous statement pertaining to sample compression is not true for\nmulticlass hypothesis classes: every learnable multiclass hypothesis class,\nwhich must necessarily have finite DS dimension, does not admit a sample\ncompression scheme of size only a finite function of its DS dimension.",
          "link": "http://arxiv.org/abs/2308.06424",
          "publishedOn": "2023-09-23T00:40:38.907Z",
          "wordCount": null,
          "title": "Multiclass Learnability Does Not Imply Sample Compression. (arXiv:2308.06424v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianbao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Siheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chen Henry Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1\">Qian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yanchao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>",
          "description": "Designing reward functions is a longstanding challenge in reinforcement\nlearning (RL); it requires specialized knowledge or domain data, leading to\nhigh costs for development. To address this, we introduce Text2Reward, a\ndata-free framework that automates the generation of dense reward functions\nbased on large language models (LLMs). Given a goal described in natural\nlanguage, Text2Reward generates dense reward functions as an executable program\ngrounded in a compact representation of the environment. Unlike inverse RL and\nrecent work that uses LLMs to write sparse reward codes, Text2Reward produces\ninterpretable, free-form dense reward codes that cover a wide range of tasks,\nutilize existing packages, and allow iterative refinement with human feedback.\nWe evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2,\nMetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17\nmanipulation tasks, policies trained with generated reward codes achieve\nsimilar or better task success rates and convergence speed than expert-written\nreward codes. For locomotion tasks, our method learns six novel locomotion\nbehaviors with a success rate exceeding 94%. Furthermore, we show that the\npolicies trained in the simulator with our method can be deployed in the real\nworld. Finally, Text2Reward further improves the policies by refining their\nreward functions with human feedback. Video results are available at\nhttps://text-to-reward.github.io",
          "link": "http://arxiv.org/abs/2309.11489",
          "publishedOn": "2023-09-23T00:40:38.903Z",
          "wordCount": null,
          "title": "Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning. (arXiv:2309.11489v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00215",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Veeravalli_T/0/1/0/all/0/1\">Tanya Veeravalli</a>, <a href=\"http://arxiv.org/find/math/1/au:+Raginsky_M/0/1/0/all/0/1\">Maxim Raginsky</a>",
          "description": "The problem of function approximation by neural dynamical systems has\ntypically been approached in a top-down manner: Any continuous function can be\napproximated to an arbitrary accuracy by a sufficiently complex model with a\ngiven architecture. This can lead to high-complexity controls which are\nimpractical in applications. In this paper, we take the opposite, constructive\napproach: We impose various structural restrictions on system dynamics and\nconsequently characterize the class of functions that can be realized by such a\nsystem. The systems are implemented as a cascade interconnection of a neural\nstochastic differential equation (Neural SDE), a deterministic dynamical\nsystem, and a readout map. Both probabilistic and geometric (Lie-theoretic)\nmethods are used to characterize the classes of functions realized by such\nsystems.",
          "link": "http://arxiv.org/abs/2307.00215",
          "publishedOn": "2023-09-23T00:40:38.902Z",
          "wordCount": null,
          "title": "A Constructive Approach to Function Realization by Neural Stochastic Differential Equations. (arXiv:2307.00215v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Capogrosso_L/0/1/0/all/0/1\">Luigi Capogrosso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunico_F/0/1/0/all/0/1\">Federico Cunico</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1\">Dong Seon Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fummi_F/0/1/0/all/0/1\">Franco Fummi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+cristani_M/0/1/0/all/0/1\">Marco cristani</a>",
          "description": "The emergence of Tiny Machine Learning (TinyML) has positively revolutionized\nthe field of Artificial Intelligence by promoting the joint design of\nresource-constrained IoT hardware devices and their learning-based software\narchitectures. TinyML carries an essential role within the fourth and fifth\nindustrial revolutions in helping societies, economies, and individuals employ\neffective AI-infused computing technologies (e.g., smart cities, automotive,\nand medical robotics). Given its multidisciplinary nature, the field of TinyML\nhas been approached from many different angles: this comprehensive survey\nwishes to provide an up-to-date overview focused on all the learning algorithms\nwithin TinyML-based solutions. The survey is based on the Preferred Reporting\nItems for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,\nallowing for a systematic and complete literature survey. In particular,\nfirstly we will examine the three different workflows for implementing a\nTinyML-based system, i.e., ML-oriented, HW-oriented, and co-design. Secondly,\nwe propose a taxonomy that covers the learning panorama under the TinyML lens,\nexamining in detail the different families of model optimization and design, as\nwell as the state-of-the-art learning techniques. Thirdly, this survey will\npresent the distinct features of hardware devices and software tools that\nrepresent the current state-of-the-art for TinyML intelligent edge\napplications. Finally, we discuss the challenges and future directions.",
          "link": "http://arxiv.org/abs/2309.11932",
          "publishedOn": "2023-09-23T00:40:38.867Z",
          "wordCount": null,
          "title": "A Machine Learning-oriented Survey on Tiny Machine Learning. (arXiv:2309.11932v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11942",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1\">Jose M. Pe&#xf1;a</a>",
          "description": "This work is devoted to the study of the probability of immunity, i.e. the\neffect occurs whether exposed or not. We derive necessary and sufficient\nconditions for non-immunity and $\\epsilon$-bounded immunity, i.e. the\nprobability of immunity is zero and $\\epsilon$-bounded, respectively. The\nformer allows us to estimate the probability of benefit (i.e., the effect\noccurs if and only if exposed) from a randomized controlled trial, and the\nlatter allows us to produce bounds of the probability of benefit that are\ntighter than the existing ones. We also introduce the concept of indirect\nimmunity (i.e., through a mediator) and repeat our previous analysis for it.\nFinally, we propose a method for sensitivity analysis of the probability of\nimmunity under unmeasured confounding.",
          "link": "http://arxiv.org/abs/2309.11942",
          "publishedOn": "2023-09-23T00:40:38.867Z",
          "wordCount": null,
          "title": "On the Probability of Immunity. (arXiv:2309.11942v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11713",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1\">Khai Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bariletto_N/0/1/0/all/0/1\">Nicola Bariletto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>",
          "description": "Monte Carlo (MC) approximation has been used as the standard computation\napproach for the Sliced Wasserstein (SW) distance, which has an intractable\nexpectation in its analytical form. However, the MC method is not optimal in\nterms of minimizing the absolute approximation error. To provide a better class\nof empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that\nrely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of\nQMC for SW, we focus on the 3D setting, specifically computing the SW between\nprobability measures in three dimensions. In greater detail, we empirically\nverify various ways of constructing QMC points sets on the 3D unit-hypersphere,\nincluding Gaussian-based mapping, equal area mapping, generalized spiral\npoints, and optimizing discrepancy energies. Furthermore, to obtain an unbiased\nestimation for stochastic optimization, we extend QSW into Randomized\nQuasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed\nlow-discrepancy sequences. For theoretical properties, we prove the asymptotic\nconvergence of QSW and the unbiasedness of RQSW. Finally, we conduct\nexperiments on various 3D tasks, such as point-cloud comparison, point-cloud\ninterpolation, image style transfer, and training deep point-cloud\nautoencoders, to demonstrate the favorable performance of the proposed QSW and\nRQSW variants.",
          "link": "http://arxiv.org/abs/2309.11713",
          "publishedOn": "2023-09-23T00:40:38.850Z",
          "wordCount": 693,
          "title": "Quasi-Monte Carlo for 3D Sliced Wasserstein. (arXiv:2309.11713v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gordon_O/0/1/0/all/0/1\">Ofir Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habi_H/0/1/0/all/0/1\">Hai Victor Habi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Netzer_A/0/1/0/all/0/1\">Arnon Netzer</a>",
          "description": "Quantization of deep neural networks (DNN) has become a key element in the\nefforts of embedding such networks on end-user devices. However, current\nquantization methods usually suffer from costly accuracy degradation. In this\npaper, we propose a new method for Enhanced Post Training Quantization named\nEPTQ. The method is based on knowledge distillation with an adaptive weighting\nof layers. In addition, we introduce a new label-free technique for\napproximating the Hessian trace of the task loss, named Label-Free Hessian.\nThis technique removes the requirement of a labeled dataset for computing the\nHessian. The adaptive knowledge distillation uses the Label-Free Hessian\ntechnique to give greater attention to the sensitive parts of the model while\nperforming the optimization. Empirically, by employing EPTQ we achieve\nstate-of-the-art results on a wide variety of models, tasks, and datasets,\nincluding ImageNet classification, COCO object detection, and Pascal-VOC for\nsemantic segmentation. We demonstrate the performance and compatibility of EPTQ\non an extended set of architectures, including CNNs, Transformers, hybrid, and\nMLP-only models.",
          "link": "http://arxiv.org/abs/2309.11531",
          "publishedOn": "2023-09-23T00:40:38.842Z",
          "wordCount": 665,
          "title": "EPTQ: Enhanced Post-Training Quantization via Label-Free Hessian. (arXiv:2309.11531v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.07037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Graves_A/0/1/0/all/0/1\">Alex Graves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_R/0/1/0/all/0/1\">Rupesh Kumar Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atkinson_T/0/1/0/all/0/1\">Timothy Atkinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_F/0/1/0/all/0/1\">Faustino Gomez</a>",
          "description": "This paper introduces Bayesian Flow Networks (BFNs), a new class of\ngenerative model in which the parameters of a set of independent distributions\nare modified with Bayesian inference in the light of noisy data samples, then\npassed as input to a neural network that outputs a second, interdependent\ndistribution. Starting from a simple prior and iteratively updating the two\ndistributions yields a generative procedure similar to the reverse process of\ndiffusion models; however it is conceptually simpler in that no forward process\nis required. Discrete and continuous-time loss functions are derived for\ncontinuous, discretised and discrete data, along with sample generation\nprocedures. Notably, the network inputs for discrete data lie on the\nprobability simplex, and are therefore natively differentiable, paving the way\nfor gradient-based sample guidance and few-step generation in discrete domains\nsuch as language modelling. The loss function directly optimises data\ncompression and places no restrictions on the network architecture. In our\nexperiments BFNs achieve competitive log-likelihoods for image modelling on\ndynamically binarized MNIST and CIFAR-10, and outperform all known discrete\ndiffusion models on the text8 character-level language modelling task.",
          "link": "http://arxiv.org/abs/2308.07037",
          "publishedOn": "2023-09-23T00:40:38.837Z",
          "wordCount": null,
          "title": "Bayesian Flow Networks. (arXiv:2308.07037v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhihang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yunqiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Wen Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xiaoliang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1\">Zhiqiang Zou</a>",
          "description": "The recommendation of appropriate development pathways, also known as\necological civilization patterns for achieving Sustainable Development Goals\n(namely, sustainable development patterns), are of utmost importance for\npromoting ecological, economic, social, and resource sustainability in a\nspecific region. To achieve this, the recommendation process must carefully\nconsider the region's natural, environmental, resource, and economic\ncharacteristics. However, current recommendation algorithms in the field of\ncomputer science fall short in adequately addressing the spatial heterogeneity\nrelated to environment and sparsity of regional historical interaction data,\nwhich limits their effectiveness in recommending sustainable development\npatterns. To overcome these challenges, this paper proposes a method called\nUser Graph after Pruning and Intent Graph (UGPIG). Firstly, we utilize the\nhigh-density linking capability of the pruned User Graph to address the issue\nof spatial heterogeneity neglect in recommendation algorithms. Secondly, we\nconstruct an Intent Graph by incorporating the intent network, which captures\nthe preferences for attributes including environmental elements of target\nregions. This approach effectively alleviates the problem of sparse historical\ninteraction data in the region. Through extensive experiments, we demonstrate\nthat UGPIG outperforms state-of-the-art recommendation algorithms like KGCN,\nKGAT, and KGIN in sustainable development pattern recommendations, with a\nmaximum improvement of 9.61% in Top-3 recommendation performance.",
          "link": "http://arxiv.org/abs/2309.11741",
          "publishedOn": "2023-09-23T00:40:38.830Z",
          "wordCount": 733,
          "title": "Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph Pruning and Intent Graph for Effective Recommendations. (arXiv:2309.11741v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11587",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinmeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Song Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Sijia Zhu</a>",
          "description": "The prevalence of ubiquitous location-aware devices and mobile Internet\nenables us to collect massive individual-level trajectory dataset from users.\nSuch trajectory big data bring new opportunities to human mobility research but\nalso raise public concerns with regard to location privacy. In this work, we\npresent the Conditional Adversarial Trajectory Synthesis (CATS), a\ndeep-learning-based GeoAI methodological framework for privacy-preserving\ntrajectory data generation and publication. CATS applies K-anonymity to the\nunderlying spatiotemporal distributions of human movements, which provides a\ndistributional-level strong privacy guarantee. By leveraging conditional\nadversarial training on K-anonymized human mobility matrices, trajectory global\ncontext learning using the attention-based mechanism, and recurrent bipartite\ngraph matching of adjacent trajectory points, CATS is able to reconstruct\ntrajectory topology from conditionally sampled locations and generate\nhigh-quality individual-level synthetic trajectory data, which can serve as\nsupplements or alternatives to raw data for privacy-preserving trajectory data\npublication. The experiment results on over 90k GPS trajectories show that our\nmethod has a better performance in privacy preservation, spatiotemporal\ncharacteristic preservation, and downstream utility compared with baseline\nmethods, which brings new insights into privacy-preserving human mobility\nresearch using generative AI techniques and explores data ethics issues in\nGIScience.",
          "link": "http://arxiv.org/abs/2309.11587",
          "publishedOn": "2023-09-23T00:40:38.810Z",
          "wordCount": null,
          "title": "CATS: Conditional Adversarial Trajectory Synthesis for Privacy-Preserving Trajectory Data Publication Using Deep Learning Approaches. (arXiv:2309.11587v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11651",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ata_B/0/1/0/all/0/1\">Baris Ata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harrison_J/0/1/0/all/0/1\">J. Michael Harrison</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Si_N/0/1/0/all/0/1\">Nian Si</a>",
          "description": "Motivated by applications in queueing theory, we consider a stochastic\ncontrol problem whose state space is the $d$-dimensional positive orthant. The\ncontrolled process $Z$ evolves as a reflected Brownian motion whose covariance\nmatrix is exogenously specified, as are its directions of reflection from the\northant's boundary surfaces. A system manager chooses a drift vector\n$\\theta(t)$ at each time $t$ based on the history of $Z$, and the cost rate at\ntime $t$ depends on both $Z(t)$ and $\\theta(t)$. In our initial problem\nformulation, the objective is to minimize expected discounted cost over an\ninfinite planning horizon, after which we treat the corresponding ergodic\ncontrol problem. Extending earlier work by Han et al. (Proceedings of the\nNational Academy of Sciences, 2018, 8505-8510), we develop and illustrate a\nsimulation-based computational method that relies heavily on deep neural\nnetwork technology. For test problems studied thus far, our method is accurate\nto within a fraction of one percent, and is computationally feasible in\ndimensions up to at least $d=30$.",
          "link": "http://arxiv.org/abs/2309.11651",
          "publishedOn": "2023-09-23T00:40:38.810Z",
          "wordCount": null,
          "title": "Drift Control of High-Dimensional RBM: A Computational Method Based on Neural Networks. (arXiv:2309.11651v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Curmei_M/0/1/0/all/0/1\">Mihaela Curmei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krichene_W/0/1/0/all/0/1\">Walid Krichene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundararajan_M/0/1/0/all/0/1\">Mukund Sundararajan</a>",
          "description": "We consider the problem of training private recommendation models with access\nto public item features. Training with Differential Privacy (DP) offers strong\nprivacy guarantees, at the expense of loss in recommendation quality. We show\nthat incorporating public item features during training can help mitigate this\nloss in quality. We propose a general approach based on collective matrix\nfactorization (CMF), that works by simultaneously factorizing two matrices: the\nuser feedback matrix (representing sensitive data) and an item feature matrix\nthat encodes publicly available (non-sensitive) item information.\n\nThe method is conceptually simple, easy to tune, and highly scalable. It can\nbe applied to different types of public item data, including: (1) categorical\nitem features; (2) item-item similarities learned from public sources; and (3)\npublicly available user feedback. Furthermore, these data modalities can be\ncollectively utilized to fully leverage public data.\n\nEvaluating our method on a standard DP recommendation benchmark, we find that\nusing public item features significantly narrows the quality gap between\nprivate models and their non-private counterparts. As privacy constraints\nbecome more stringent, models rely more heavily on public side features for\nrecommendation. This results in a smooth transition from collaborative\nfiltering to item-based contextual recommendations.",
          "link": "http://arxiv.org/abs/2309.11516",
          "publishedOn": "2023-09-23T00:40:38.804Z",
          "wordCount": null,
          "title": "Private Matrix Factorization with Public Item Features. (arXiv:2309.11516v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.10792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Linfeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Runyi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>",
          "description": "This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), a crucial technique to enhance the capabilities and\ncontrollability of large language models (LLMs). Instruction tuning refers to\nthe process of further training LLMs on a dataset consisting of\n\\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the\ngap between the next-word prediction objective of LLMs and the users' objective\nof having LLMs adhere to human instructions. In this work, we make a systematic\nreview of the literature, including the general methodology of IT, the\nconstruction of IT datasets, the training of IT models, and applications to\ndifferent modalities, domains and applications, along with an analysis on\naspects that influence the outcome of IT (e.g., generation of instruction\noutputs, size of the instruction dataset, etc). We also review the potential\npitfalls of IT along with criticism against it, along with efforts pointing out\ncurrent deficiencies of existing strategies and suggest some avenues for\nfruitful research.",
          "link": "http://arxiv.org/abs/2308.10792",
          "publishedOn": "2023-09-23T00:40:38.769Z",
          "wordCount": null,
          "title": "Instruction Tuning for Large Language Models: A Survey. (arXiv:2308.10792v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Machhamer_R/0/1/0/all/0/1\">R&#xfc;diger Machhamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazlic_L/0/1/0/all/0/1\">Lejla Begic Fazlic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guven_E/0/1/0/all/0/1\">Eray Guven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junk_D/0/1/0/all/0/1\">David Junk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurt_G/0/1/0/all/0/1\">Gunes Karabulut Kurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumann_S/0/1/0/all/0/1\">Stefan Naumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Didas_S/0/1/0/all/0/1\">Stephan Didas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollmer_K/0/1/0/all/0/1\">Klaus-Uwe Gollmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergmann_R/0/1/0/all/0/1\">Ralph Bergmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timm_I/0/1/0/all/0/1\">Ingo J. Timm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dartmann_G/0/1/0/all/0/1\">Guido Dartmann</a>",
          "description": "An important task in the field of sensor technology is the efficient\nimplementation of adaptation procedures of measurements from one sensor to\nanother sensor of identical design. One idea is to use the estimation of an\naffine transformation between different systems, which can be improved by the\nknowledge of experts. This paper presents an improved solution from Glacier\nResearch that was published back in 1973. It is shown that this solution can be\nadapted for software calibration of sensors, implementation of expert-based\nadaptation, and federated learning methods. We evaluate our research with\nsimulations and also with real measured data of a multi-sensor board with 8\nidentical sensors. The results show an improvement for both the simulation and\nthe experiments with real data.",
          "link": "http://arxiv.org/abs/2309.11526",
          "publishedOn": "2023-09-23T00:40:38.760Z",
          "wordCount": null,
          "title": "Likelihood-based Sensor Calibration for Expert-Supported Distributed Learning Algorithms in IoT Systems. (arXiv:2309.11526v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seshadri_P/0/1/0/all/0/1\">Pavan Seshadri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knees_P/0/1/0/all/0/1\">Peter Knees</a>",
          "description": "Music streaming services heavily rely on their recommendation engines to\ncontinuously provide content to their consumers. Sequential recommendation\nconsequently has seen considerable attention in current literature, where state\nof the art approaches focus on self-attentive models leveraging contextual\ninformation such as long and short-term user history and item features;\nhowever, most of these studies focus on long-form content domains (retail,\nmovie, etc.) rather than short-form, such as music. Additionally, many do not\nexplore incorporating negative session-level feedback during training. In this\nstudy, we investigate the use of transformer-based self-attentive architectures\nto learn implicit session-level information for sequential music\nrecommendation. We additionally propose a contrastive learning task to\nincorporate negative feedback (e.g skipped tracks) to promote positive hits and\npenalize negative hits. This task is formulated as a simple loss term that can\nbe incorporated into a variety of deep learning architectures for sequential\nrecommendation. Our experiments show that this results in consistent\nperformance gains over the baseline architectures ignoring negative user\nfeedback.",
          "link": "http://arxiv.org/abs/2309.11623",
          "publishedOn": "2023-09-23T00:40:38.673Z",
          "wordCount": null,
          "title": "Leveraging Negative Signals with Self-Attention for Sequential Music Recommendation. (arXiv:2309.11623v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guyet_T/0/1/0/all/0/1\">Thomas Guyet</a>",
          "description": "A sequential pattern with negation, or negative sequential pattern, takes the\nform of a sequential pattern for which the negation symbol may be used in front\nof some of the pattern's itemsets. Intuitively, such a pattern occurs in a\nsequence if negated itemsets are absent in the sequence. Recent work has shown\nthat different semantics can be attributed to these pattern forms, and that\nstate-of-the-art algorithms do not extract the same sets of patterns. This\nraises the important question of the interpretability of sequential pattern\nwith negation. In this study, our focus is on exploring how potential users\nperceive negation in sequential patterns. Our aim is to determine whether\nspecific semantics are more \"intuitive\" than others and whether these align\nwith the semantics employed by one or more state-of-the-art algorithms. To\nachieve this, we designed a questionnaire to reveal the semantics' intuition of\neach user. This article presents both the design of the questionnaire and an\nin-depth analysis of the 124 responses obtained. The outcomes indicate that two\nof the semantics are predominantly intuitive; however, neither of them aligns\nwith the semantics of the primary state-of-the-art algorithms. As a result, we\nprovide recommendations to account for this disparity in the conclusions drawn.",
          "link": "http://arxiv.org/abs/2309.11638",
          "publishedOn": "2023-09-23T00:40:38.598Z",
          "wordCount": null,
          "title": "A survey on the semantics of sequential patterns with negation. (arXiv:2309.11638v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khanmohammadi_R/0/1/0/all/0/1\">Reza Khanmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alhanai_T/0/1/0/all/0/1\">Tuka Alhanai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Mohammad M. Ghassemi</a>",
          "description": "Initialization of neural network weights plays a pivotal role in determining\ntheir performance. Feature Imitating Networks (FINs) offer a novel strategy by\ninitializing weights to approximate specific closed-form statistical features,\nsetting a promising foundation for deep learning architectures. While the\napplicability of FINs has been chiefly tested in biomedical domains, this study\nextends its exploration into other time series datasets. Three different\nexperiments are conducted in this study to test the applicability of imitating\nTsallis entropy for performance enhancement: Bitcoin price prediction, speech\nemotion recognition, and chronic neck pain detection. For the Bitcoin price\nprediction, models embedded with FINs reduced the root mean square error by\naround 1000 compared to the baseline. In the speech emotion recognition task,\nthe FIN-augmented model increased classification accuracy by over 3 percent.\nLastly, in the CNP detection experiment, an improvement of about 7 percent was\nobserved compared to established classifiers. These findings validate the broad\nutility and potency of FINs in diverse applications.",
          "link": "http://arxiv.org/abs/2309.12279",
          "publishedOn": "2023-09-23T00:40:38.595Z",
          "wordCount": 687,
          "title": "The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains. (arXiv:2309.12279v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Renda_A/0/1/0/all/0/1\">Alex Renda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yi Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carbin_M/0/1/0/all/0/1\">Michael Carbin</a>",
          "description": "Programmers and researchers are increasingly developing surrogates of\nprograms, models of a subset of the observable behavior of a given program, to\nsolve a variety of software development challenges. Programmers train\nsurrogates from measurements of the behavior of a program on a dataset of input\nexamples. A key challenge of surrogate construction is determining what\ntraining data to use to train a surrogate of a given program.\n\nWe present a methodology for sampling datasets to train neural-network-based\nsurrogates of programs. We first characterize the proportion of data to sample\nfrom each region of a program's input space (corresponding to different\nexecution paths of the program) based on the complexity of learning a surrogate\nof the corresponding execution path. We next provide a program analysis to\ndetermine the complexity of different paths in a program. We evaluate these\nresults on a range of real-world programs, demonstrating that complexity-guided\nsampling results in empirical improvements in accuracy.",
          "link": "http://arxiv.org/abs/2309.11726",
          "publishedOn": "2023-09-23T00:40:38.525Z",
          "wordCount": 677,
          "title": "Turaco: Complexity-Guided Data Sampling for Training Neural Surrogates of Programs. (arXiv:2309.11726v1 [cs.PL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yinpeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huanran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiawei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhengwei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Multimodal Large Language Models (MLLMs) that integrate text and other\nmodalities (especially vision) have achieved unprecedented performance in\nvarious multimodal tasks. However, due to the unsolved adversarial robustness\nproblem of vision models, MLLMs can have more severe safety and security risks\nby introducing the vision inputs. In this work, we study the adversarial\nrobustness of Google's Bard, a competitive chatbot to ChatGPT that released its\nmultimodal capability recently, to better understand the vulnerabilities of\ncommercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs,\nthe generated adversarial examples can mislead Bard to output wrong image\ndescriptions with a 22% success rate based solely on the transferability. We\nshow that the adversarial examples can also attack other MLLMs, e.g., a 26%\nattack success rate against Bing Chat and a 86% attack success rate against\nERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face\ndetection and toxicity detection of images. We design corresponding attacks to\nevade these defenses, demonstrating that the current defenses of Bard are also\nvulnerable. We hope this work can deepen our understanding on the robustness of\nMLLMs and facilitate future research on defenses. Our code is available at\nhttps://github.com/thu-ml/Attack-Bard.",
          "link": "http://arxiv.org/abs/2309.11751",
          "publishedOn": "2023-09-23T00:40:38.519Z",
          "wordCount": 724,
          "title": "How Robust is Google's Bard to Adversarial Image Attacks?. (arXiv:2309.11751v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brenig_J/0/1/0/all/0/1\">Jonas Brenig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>",
          "description": "Self-supervised representation learning has seen remarkable progress in the\nlast few years, with some of the recent methods being able to learn useful\nimage representations without labels. These methods are trained using\nbackpropagation, the de facto standard. Recently, Geoffrey Hinton proposed the\nforward-forward algorithm as an alternative training method. It utilizes two\nforward passes and a separate loss function for each layer to train the network\nwithout backpropagation.\n\nIn this study, for the first time, we study the performance of\nforward-forward vs. backpropagation for self-supervised representation learning\nand provide insights into the learned representation spaces. Our benchmark\nemploys four standard datasets, namely MNIST, F-MNIST, SVHN and CIFAR-10, and\nthree commonly used self-supervised representation learning techniques, namely\nrotation, flip and jigsaw.\n\nOur main finding is that while the forward-forward algorithm performs\ncomparably to backpropagation during (self-)supervised training, the transfer\nperformance is significantly lagging behind in all the studied settings. This\nmay be caused by a combination of factors, including having a loss function for\neach layer and the way the supervised training is realized in the\nforward-forward paradigm. In comparison to backpropagation, the forward-forward\nalgorithm focuses more on the boundaries and drops part of the information\nunnecessary for making decisions which harms the representation learning goal.\nFurther investigation and research are necessary to stabilize the\nforward-forward strategy for self-supervised learning, to work beyond the\ndatasets and configurations demonstrated by Geoffrey Hinton.",
          "link": "http://arxiv.org/abs/2309.11955",
          "publishedOn": "2023-09-23T00:40:38.512Z",
          "wordCount": 737,
          "title": "A Study of Forward-Forward Algorithm for Self-Supervised Learning. (arXiv:2309.11955v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xia Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruiji Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saluz_U/0/1/0/all/0/1\">Ueli Saluz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiavon_S/0/1/0/all/0/1\">Stefano Schiavon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geyer_P/0/1/0/all/0/1\">Philipp Geyer</a>",
          "description": "The decision-making process in real-world implementations has been affected\nby a growing reliance on data-driven models. We investigated the synergetic\npattern between the data-driven methods, empirical domain knowledge, and\nfirst-principles simulations. We showed the potential risk of biased results\nwhen using data-driven models without causal analysis. Using a case study\nassessing the implication of several design solutions on the energy consumption\nof a building, we proved the necessity of causal analysis during the\ndata-driven modeling process. We concluded that: (a) Data-driven models'\naccuracy assessment or domain knowledge screening may not rule out biased and\nspurious results; (b) Data-driven models' feature selection should involve\ncareful consideration of causal relationships, especially colliders; (c) Causal\nanalysis results can be used as an aid to first-principles simulation design\nand parameter checking to avoid cognitive biases. We proved the benefits of\ncausal analysis when applied to data-driven models in building engineering.",
          "link": "http://arxiv.org/abs/2309.11509",
          "publishedOn": "2023-09-23T00:40:38.507Z",
          "wordCount": 714,
          "title": "Using causal inference to avoid fallouts in data-driven parametric analysis: a case study in the architecture, engineering, and construction industry. (arXiv:2309.11509v1 [cs.CE])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_L/0/1/0/all/0/1\">Luis Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1\">Gerhard Widmer</a>",
          "description": "Many applications of cross-modal music retrieval are related to connecting\nsheet music images to audio recordings. A typical and recent approach to this\nis to learn, via deep neural networks, a joint embedding space that correlates\nshort fixed-size snippets of audio and sheet music by means of an appropriate\nsimilarity structure. However, two challenges that arise out of this strategy\nare the requirement of strongly aligned data to train the networks, and the\ninherent discrepancies of musical content between audio and sheet music\nsnippets caused by local and global tempo differences. In this paper, we\naddress these two shortcomings by designing a cross-modal recurrent network\nthat learns joint embeddings that can summarize longer passages of\ncorresponding audio and sheet music. The benefits of our method are that it\nonly requires weakly aligned audio-sheet music pairs, as well as that the\nrecurrent network handles the non-linearities caused by tempo variations\nbetween audio and sheet music. We conduct a number of experiments on synthetic\nand real piano data and scores, showing that our proposed recurrent method\nleads to more accurate retrieval in all possible configurations.",
          "link": "http://arxiv.org/abs/2309.12111",
          "publishedOn": "2023-09-23T00:40:38.490Z",
          "wordCount": 705,
          "title": "Passage Summarization with Recurrent Models for Audio-Sheet Music Retrieval. (arXiv:2309.12111v1 [cs.SD])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yuxiang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djemili_K/0/1/0/all/0/1\">Karim Djemili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elezi_D/0/1/0/all/0/1\">Denis Elezi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalman_A/0/1/0/all/0/1\">Aaneel Shalman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Ortiz_M/0/1/0/all/0/1\">Mar&#xed;a P&#xe9;rez-Ortiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulathwela_S/0/1/0/all/0/1\">Sahan Bulathwela</a>",
          "description": "This work describes the TrueLearn Python library, which contains a family of\nonline learning Bayesian models for building educational (or more generally,\ninformational) recommendation systems. This family of models was designed\nfollowing the \"open learner\" concept, using humanly-intuitive user\nrepresentations. For the sake of interpretability and putting the user in\ncontrol, the TrueLearn library also contains different representations to help\nend-users visualise the learner models, which may in the future facilitate user\ninteraction with their own models. Together with the library, we include a\npreviously publicly released implicit feedback educational dataset with\nevaluation metrics to measure the performance of the models. The extensive\ndocumentation and coding examples make the library highly accessible to both\nmachine learning developers and educational data mining and learning analytic\npractitioners. The library and the support documentation with examples are\navailable at https://truelearn.readthedocs.io/en/latest.",
          "link": "http://arxiv.org/abs/2309.11527",
          "publishedOn": "2023-09-23T00:40:38.472Z",
          "wordCount": 681,
          "title": "TrueLearn: A Python Library for Personalised Informational Recommendations with (Implicit) Feedback. (arXiv:2309.11527v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11856",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Eliassen_S/0/1/0/all/0/1\">Sebastian Eliassen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Selvan_R/0/1/0/all/0/1\">Raghavendra Selvan</a>",
          "description": "Efficient training of large-scale graph neural networks (GNNs) has been\nstudied with a specific focus on reducing their memory consumption. Work by Liu\net al. (2022) proposed extreme activation compression (EXACT) which\ndemonstrated drastic reduction in memory consumption by performing quantization\nof the intermediate activation maps down to using INT2 precision. They showed\nlittle to no reduction in performance while achieving large reductions in GPU\nmemory consumption. In this work, we present an improvement to the EXACT\nstrategy by using block-wise quantization of the intermediate activation maps.\nWe experimentally analyze different block sizes and show further reduction in\nmemory consumption (>15%), and runtime speedup per epoch (about 5%) even when\nperforming extreme extents of quantization with similar performance trade-offs\nas with the original EXACT. Further, we present a correction to the assumptions\non the distribution of intermediate activation maps in EXACT (assumed to be\nuniform) and show improved variance estimations of the quantization and\ndequantization steps.",
          "link": "http://arxiv.org/abs/2309.11856",
          "publishedOn": "2023-09-23T00:40:38.129Z",
          "wordCount": 675,
          "title": "Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization. (arXiv:2309.11856v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rondao_D/0/1/0/all/0/1\">Duarte Rondao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aouf_N/0/1/0/all/0/1\">Nabil Aouf</a>",
          "description": "Cameras are rapidly becoming the choice for on-board sensors towards space\nrendezvous due to their small form factor and inexpensive power, mass, and\nvolume costs. When it comes to docking, however, they typically serve a\nsecondary role, whereas the main work is done by active sensors such as lidar.\nThis paper documents the development of a proposed AI-based (artificial\nintelligence) navigation algorithm intending to mature the use of on-board\nvisible wavelength cameras as a main sensor for docking and on-orbit servicing\n(OOS), reducing the dependency on lidar and greatly reducing costs.\nSpecifically, the use of AI enables the expansion of the relative navigation\nsolution towards multiple classes of scenarios, e.g., in terms of targets or\nillumination conditions, which would otherwise have to be crafted on a\ncase-by-case manner using classical image processing methods. Multiple\nconvolutional neural network (CNN) backbone architectures are benchmarked on\nsynthetically generated data of docking manoeuvres with the International Space\nStation (ISS), achieving position and attitude estimates close to 1%\nrange-normalised and 1 deg, respectively. The integration of the solution with\na physical prototype of the refuelling mechanism is validated in laboratory\nusing a robotic arm to simulate a berthing procedure.",
          "link": "http://arxiv.org/abs/2309.11648",
          "publishedOn": "2023-09-23T00:40:38.119Z",
          "wordCount": 694,
          "title": "Orbital AI-based Autonomous Refuelling Solution. (arXiv:2309.11648v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trainor_A/0/1/0/all/0/1\">April Trainor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turnbull_D/0/1/0/all/0/1\">Douglas Turnbull</a>",
          "description": "In this paper, we study the effect of popularity degradation bias in the\ncontext of local music recommendations. Specifically, we examine how accurate\ntwo top-performing recommendation algorithms, Weight Relevance Matrix\nFactorization (WRMF) and Multinomial Variational Autoencoder (Mult-VAE), are at\nrecommending artists as a function of artist popularity. We find that both\nalgorithms improve recommendation performance for more popular artists and, as\nsuch, exhibit popularity degradation bias. While both algorithms produce a\nsimilar level of performance for more popular artists, Mult-VAE shows better\nrelative performance for less popular artists. This suggests that this\nalgorithm should be preferred for local (long-tail) music artist\nrecommendation.",
          "link": "http://arxiv.org/abs/2309.11671",
          "publishedOn": "2023-09-23T00:40:38.112Z",
          "wordCount": 597,
          "title": "Popularity Degradation Bias in Local Music Recommendation. (arXiv:2309.11671v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11512",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ummel_K/0/1/0/all/0/1\">Kevin Ummel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Poblete_Cazenave_M/0/1/0/all/0/1\">Miguel Poblete-Cazenave</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akkiraju_K/0/1/0/all/0/1\">Karthik Akkiraju</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Graetz_N/0/1/0/all/0/1\">Nick Graetz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ashman_H/0/1/0/all/0/1\">Hero Ashman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kingdon_C/0/1/0/all/0/1\">Cora Kingdon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tenorio_S/0/1/0/all/0/1\">Steven Herrera Tenorio</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Singhal_A/0/1/0/all/0/1\">Aaryaman &quot;Sunny&quot; Singhal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cohen_D/0/1/0/all/0/1\">Daniel Aldana Cohen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rao_N/0/1/0/all/0/1\">Narasimha D. Rao</a>",
          "description": "Social science often relies on surveys of households and individuals. Dozens\nof such surveys are regularly administered by the U.S. government. However,\nthey field independent, unconnected samples with specialized questions,\nlimiting research questions to those that can be answered by a single survey.\nThe fusionACS project seeks to integrate data from multiple U.S. household\nsurveys by statistically \"fusing\" variables from \"donor\" surveys onto American\nCommunity Survey (ACS) microdata. This results in an integrated microdataset of\nhousehold attributes and well-being dimensions that can be analyzed to address\nresearch questions in ways that are not currently possible. The presented data\ncomprise the fusion onto the ACS of select donor variables from the Residential\nEnergy Consumption Survey (RECS) of 2015, the National Household Transportation\nSurvey (NHTS) of 2017, the American Housing Survey (AHS) of 2019, and the\nConsumer Expenditure Survey - Interview (CEI) for the years 2015-2019. The\nunderlying statistical techniques are included in an open-source $R$ package,\nfusionModel, that provides generic tools for the creation, analysis, and\nvalidation of fused microdata.",
          "link": "http://arxiv.org/abs/2309.11512",
          "publishedOn": "2023-09-23T00:40:38.090Z",
          "wordCount": 713,
          "title": "Multidimensional well-being of US households at a fine spatial scale using fused household surveys: fusionACS. (arXiv:2309.11512v1 [stat.AP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baharlouei_S/0/1/0/all/0/1\">Sina Baharlouei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1\">Meisam Razaviyayn</a>",
          "description": "While training fair machine learning models has been studied extensively in\nrecent years, most developed methods rely on the assumption that the training\nand test data have similar distributions. In the presence of distribution\nshifts, fair models may behave unfairly on test data. There have been some\ndevelopments for fair learning robust to distribution shifts to address this\nshortcoming. However, most proposed solutions are based on the assumption of\nhaving access to the causal graph describing the interaction of different\nfeatures. Moreover, existing algorithms require full access to data and cannot\nbe used when small batches are used (stochastic/batch implementation). This\npaper proposes the first stochastic distributionally robust fairness framework\nwith convergence guarantees that do not require knowledge of the causal graph.\nMore specifically, we formulate the fair inference in the presence of the\ndistribution shift as a distributionally robust optimization problem under\n$L_p$ norm uncertainty sets with respect to the Exponential Renyi Mutual\nInformation (ERMI) as the measure of fairness violation. We then discuss how\nthe proposed method can be implemented in a stochastic fashion. We have\nevaluated the presented framework's performance and efficiency through\nextensive experiments on real datasets consisting of distribution shifts.",
          "link": "http://arxiv.org/abs/2309.11682",
          "publishedOn": "2023-09-23T00:40:38.085Z",
          "wordCount": 722,
          "title": "Dr. FERMI: A Stochastic Distributionally Robust Fair Empirical Risk Minimization Framework. (arXiv:2309.11682v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sagtani_H/0/1/0/all/0/1\">Hitesh Sagtani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhawar_M/0/1/0/all/0/1\">Madan Jhawar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrotra_R/0/1/0/all/0/1\">Rishabh Mehrotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeunen_O/0/1/0/all/0/1\">Olivier Jeunen</a>",
          "description": "Ad-load balancing is a critical challenge in online advertising systems,\nparticularly in the context of social media platforms, where the goal is to\nmaximize user engagement and revenue while maintaining a satisfactory user\nexperience. This requires the optimization of conflicting objectives, such as\nuser satisfaction and ads revenue. Traditional approaches to ad-load balancing\nrely on static allocation policies, which fail to adapt to changing user\npreferences and contextual factors. In this paper, we present an approach that\nleverages off-policy learning and evaluation from logged bandit feedback. We\nstart by presenting a motivating analysis of the ad-load balancing problem,\nhighlighting the conflicting objectives between user satisfaction and ads\nrevenue. We emphasize the nuances that arise due to user heterogeneity and the\ndependence on the user's position within a session. Based on this analysis, we\ndefine the problem as determining the optimal ad-load for a particular feed\nfetch. To tackle this problem, we propose an off-policy learning framework that\nleverages unbiased estimators such as Inverse Propensity Scoring (IPS) and\nDoubly Robust (DR) to learn and estimate the policy values using offline\ncollected stochastic data. We present insights from online A/B experiments\ndeployed at scale across over 80 million users generating over 200 million\nsessions, where we find statistically significant improvements in both user\nsatisfaction metrics and ads revenue for the platform.",
          "link": "http://arxiv.org/abs/2309.11518",
          "publishedOn": "2023-09-23T00:40:38.080Z",
          "wordCount": 728,
          "title": "Ad-load Balancing via Off-policy Learning in a Content Marketplace. (arXiv:2309.11518v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wentao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hui Fang</a>",
          "description": "With increasing frequency of high-profile privacy breaches in various online\nplatforms, users are becoming more concerned about their privacy. And\nrecommender system is the core component of online platforms for providing\npersonalized service, consequently, its privacy preservation has attracted\ngreat attention. As the gold standard of privacy protection, differential\nprivacy has been widely adopted to preserve privacy in recommender systems.\nHowever, existing differentially private recommender systems only consider\nstatic and independent interactions, so they cannot apply to sequential\nrecommendation where behaviors are dynamic and dependent. Meanwhile, little\nattention has been paid on the privacy risk of sensitive user features, most of\nthem only protect user feedbacks. In this work, we propose a novel\nDIfferentially Private Sequential recommendation framework with a noisy Graph\nNeural Network approach (denoted as DIPSGNN) to address these limitations. To\nthe best of our knowledge, we are the first to achieve differential privacy in\nsequential recommendation with dependent interactions. Specifically, in\nDIPSGNN, we first leverage piecewise mechanism to protect sensitive user\nfeatures. Then, we innovatively add calibrated noise into aggregation step of\ngraph neural network based on aggregation perturbation mechanism. And this\nnoisy graph neural network can protect sequentially dependent interactions and\ncapture user preferences simultaneously. Extensive experiments demonstrate the\nsuperiority of our method over state-of-the-art differentially private\nrecommender systems in terms of better balance between privacy and accuracy.",
          "link": "http://arxiv.org/abs/2309.11515",
          "publishedOn": "2023-09-23T00:40:38.061Z",
          "wordCount": 736,
          "title": "Towards Differential Privacy in Sequential Recommendation: A Noisy Graph Neural Network Approach. (arXiv:2309.11515v1 [cs.CR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herron_E/0/1/0/all/0/1\">Ethan Herron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rade_J/0/1/0/all/0/1\">Jaydeep Rade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jignasu_A/0/1/0/all/0/1\">Anushrut Jignasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganapathysubramanian_B/0/1/0/all/0/1\">Baskar Ganapathysubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balu_A/0/1/0/all/0/1\">Aditya Balu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Soumik Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1\">Adarsh Krishnamurthy</a>",
          "description": "Recent advances in generative modeling, namely Diffusion models, have\nrevolutionized generative modeling, enabling high-quality image generation\ntailored to user needs. This paper proposes a framework for the generative\ndesign of structural components. Specifically, we employ a Latent Diffusion\nmodel to generate potential designs of a component that can satisfy a set of\nproblem-specific loading conditions. One of the distinct advantages our\napproach offers over other generative approaches, such as generative\nadversarial networks (GANs), is that it permits the editing of existing\ndesigns. We train our model using a dataset of geometries obtained from\nstructural topology optimization utilizing the SIMP algorithm. Consequently,\nour framework generates inherently near-optimal designs. Our work presents\nquantitative results that support the structural performance of the generated\ndesigns and the variability in potential candidate designs. Furthermore, we\nprovide evidence of the scalability of our framework by operating over voxel\ndomains with resolutions varying from $32^3$ to $128^3$. Our framework can be\nused as a starting point for generating novel near-optimal designs similar to\ntopology-optimized designs.",
          "link": "http://arxiv.org/abs/2309.11601",
          "publishedOn": "2023-09-23T00:40:38.042Z",
          "wordCount": 670,
          "title": "Latent Diffusion Models for Structural Component Design. (arXiv:2309.11601v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.06604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1\">Ahmad Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rayz_J/0/1/0/all/0/1\">Julia T. Rayz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matson_E/0/1/0/all/0/1\">Eric T. Matson</a>",
          "description": "Algorithm selection and hyperparameter tuning are critical steps in both\nacademic and applied machine learning. On the other hand, these steps are\nbecoming ever increasingly delicate due to the extensive rise in the number,\ndiversity, and distributedness of machine learning resources. Multi-agent\nsystems, when applied to the design of machine learning platforms, bring about\nseveral distinctive characteristics such as scalability, flexibility, and\nrobustness, just to name a few. This paper proposes a fully automatic and\ncollaborative agent-based mechanism for selecting distributedly organized\nmachine learning algorithms and simultaneously tuning their hyperparameters.\nOur method builds upon an existing agent-based hierarchical machine-learning\nplatform and augments its query structure to support the aforementioned\nfunctionalities without being limited to specific learning, selection, and\ntuning mechanisms. We have conducted theoretical assessments, formal\nverification, and analytical study to demonstrate the correctness, resource\nutilization, and computational efficiency of our technique. According to the\nresults, our solution is totally correct and exhibits linear time and space\ncomplexity in relation to the size of available resources. To provide concrete\nexamples of how the proposed methodologies can effectively adapt and perform\nacross a range of algorithmic options and datasets, we have also conducted a\nseries of experiments using a system comprised of 24 algorithms and 9 datasets.",
          "link": "http://arxiv.org/abs/2309.06604",
          "publishedOn": "2023-09-16T00:40:58.245Z",
          "wordCount": 761,
          "title": "Hybrid Algorithm Selection and Hyperparameter Tuning on Distributed Machine Learning Resources: A Hierarchical Agent-based Approach. (arXiv:2309.06604v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.12814",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cook_A/0/1/0/all/0/1\">Andrew Cook</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hammerlindl_A/0/1/0/all/0/1\">Andy Hammerlindl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tucker_W/0/1/0/all/0/1\">Warwick Tucker</a>",
          "description": "We define a family of $C^1$ functions which we call \"nowhere coexpanding\nfunctions\" that is closed under composition and includes all $C^3$ functions\nwith non-positive Schwarzian derivative. We establish results on the number and\nnature of the fixed points of these functions, including a generalisation of a\nclassic result of Singer.",
          "link": "http://arxiv.org/abs/2303.12814",
          "publishedOn": "2023-09-16T00:40:58.227Z",
          "wordCount": 570,
          "title": "Nowhere coexpanding functions. (arXiv:2303.12814v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.06800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1\">Hao Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junxian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zhiming Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guanjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Hua Wei</a>",
          "description": "Traffic prediction is a crucial topic because of its broad scope of\napplications in the transportation domain. Recently, various studies have\nachieved promising results. However, most studies assume the prediction\nlocations have complete or at least partial historical records and cannot be\nextended to non-historical recorded locations. In real-life scenarios, the\ndeployment of sensors could be limited due to budget limitations and\ninstallation availability, which makes most current models not applicable.\nThough few pieces of literature tried to impute traffic states at the missing\nlocations, these methods need the data simultaneously observed at the locations\nwith sensors, making them not applicable to prediction tasks. Another drawback\nis the lack of measurement of uncertainty in prediction, making prior works\nunsuitable for risk-sensitive tasks or involving decision-making. To fill the\ngap, inspired by the previous inductive graph neural network, this work\nproposed an uncertainty-aware framework with the ability to 1) extend\nprediction to missing locations with no historical records and significantly\nextend spatial coverage of prediction locations while reducing deployment of\nsensors and 2) generate probabilistic prediction with uncertainty\nquantification to help the management of risk and decision making in the\ndown-stream tasks. Through extensive experiments on real-life datasets, the\nresult shows our method achieved promising results on prediction tasks, and the\nuncertainty quantification gives consistent results which highly correlated\nwith the locations with and without historical data. We also show that our\nmodel could help support sensor deployment tasks in the transportation field to\nachieve higher accuracy with a limited sensor deployment budget.",
          "link": "http://arxiv.org/abs/2309.06800",
          "publishedOn": "2023-09-16T00:40:58.195Z",
          "wordCount": 791,
          "title": "Uncertainty-aware Traffic Prediction under Missing Data. (arXiv:2309.06800v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1\">Federico Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cococcioni_M/0/1/0/all/0/1\">Marco Cococcioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibanez_R/0/1/0/all/0/1\">Roger Ferrer Ib&#xe0;&#xf1;ez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1\">Jes&#xf9;s Labarta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mantovani_F/0/1/0/all/0/1\">Filippo Mantovani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_M/0/1/0/all/0/1\">Marc Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruffaldi_E/0/1/0/all/0/1\">Emanuele Ruffaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saponara_S/0/1/0/all/0/1\">Sergio Saponara</a>",
          "description": "As recently demonstrated, Deep Neural Networks (DNN), usually trained using\nsingle precision IEEE 754 floating point numbers (binary32), can also work\nusing lower precision. Therefore, 16-bit and 8-bit compressed format have\nattracted considerable attention. In this paper, we focused on two families of\nformats that have already achieved interesting results in compressing binary32\nnumbers in machine learning applications, without sensible degradation of the\naccuracy: bfloat and posit. Even if 16-bit and 8-bit bfloat/posit are routinely\nused for reducing the storage of the weights/biases of trained DNNs, the\ninference still often happens on the 32-bit FPU of the CPU (especially if GPUs\nare not available). In this paper we propose a way to decompress a tensor of\nbfloat/posits just before computations, i.e., after the compressed operands\nhave been loaded within the vector registers of a vector capable CPU, in order\nto save bandwidth usage and increase cache efficiency. Finally, we show the\narchitectural parameters and considerations under which this solution is\nadvantageous with respect to the uncompressed one.",
          "link": "http://arxiv.org/abs/2309.07158",
          "publishedOn": "2023-09-16T00:40:58.094Z",
          "wordCount": 696,
          "title": "Compressed Real Numbers for AI: a case-study using a RISC-V CPU. (arXiv:2309.07158v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.00964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1\">Minsik Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vahid_K/0/1/0/all/0/1\">Keivan A. Vahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qichen Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adya_S/0/1/0/all/0/1\">Saurabh Adya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundo_C/0/1/0/all/0/1\">Carlo C Del Mundo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1\">Mohammad Rastegari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_D/0/1/0/all/0/1\">Devang Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zatloukal_P/0/1/0/all/0/1\">Peter Zatloukal</a>",
          "description": "Since Large Language Models or LLMs have demonstrated high-quality\nperformance on many complex language tasks, there is a great interest in\nbringing these LLMs to mobile devices for faster responses and better privacy\nprotection. However, the size of LLMs (i.e., billions of parameters) requires\nhighly effective compression to fit into storage-limited devices. Among many\ncompression techniques, weight-clustering, a form of non-linear quantization,\nis one of the leading candidates for LLM compression, and supported by modern\nsmartphones. Yet, its training overhead is prohibitively significant for LLM\nfine-tuning. Especially, Differentiable KMeans Clustering, or DKM, has shown\nthe state-of-the-art trade-off between compression ratio and accuracy\nregression, but its large memory complexity makes it nearly impossible to apply\nto train-time LLM compression. In this paper, we propose a memory-efficient DKM\nimplementation, eDKM powered by novel techniques to reduce the memory footprint\nof DKM by orders of magnitudes. For a given tensor to be saved on CPU for the\nbackward pass of DKM, we compressed the tensor by applying uniquification and\nsharding after checking if there is no duplicated tensor previously copied to\nCPU. Our experimental results demonstrate that \\prjname can fine-tune and\ncompress a pretrained LLaMA 7B model from 12.6 GB to 2.5 GB (3bit/weight) with\nthe Alpaca dataset by reducing the train-time memory footprint of a decoder\nlayer by 130$\\times$, while delivering good accuracy on broader LLM benchmarks\n(i.e., 77.7% for PIQA, 66.1% for Winograde, and so on).",
          "link": "http://arxiv.org/abs/2309.00964",
          "publishedOn": "2023-09-16T00:40:57.913Z",
          "wordCount": 788,
          "title": "eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models. (arXiv:2309.00964v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.08841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Savage_T/0/1/0/all/0/1\">Tom Savage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basha_N/0/1/0/all/0/1\">Nausheen Basha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonough_J/0/1/0/all/0/1\">Jonathan McDonough</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matar_O/0/1/0/all/0/1\">Omar K Matar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanona_E/0/1/0/all/0/1\">Ehecatl Antonio del Rio Chanona</a>",
          "description": "Additive manufacturing has enabled the fabrication of advanced reactor\ngeometries, permitting larger, more complex design spaces. Identifying\npromising configurations within such spaces presents a significant challenge\nfor current approaches. Furthermore, existing parameterisations of reactor\ngeometries are low-dimensional with expensive optimisation limiting more\ncomplex solutions. To address this challenge, we establish a machine\nlearning-assisted approach for the design of the next-generation of chemical\nreactors, combining the application of high-dimensional parameterisations,\ncomputational fluid dynamics, and multi-fidelity Bayesian optimisation. We\nassociate the development of mixing-enhancing vortical flow structures in novel\ncoiled reactors with performance, and use our approach to identify key\ncharacteristics of optimal designs. By appealing to fluid mechanical\nprinciples, we rationalise the selection of novel design features that lead to\nexperimental performance improvements of ~60% over conventional designs. Our\nresults demonstrate that coupling advanced manufacturing techniques with\n`augmented-intelligence' approaches can lead to superior design performance\nand, consequently, emissions-reduction and sustainability.",
          "link": "http://arxiv.org/abs/2308.08841",
          "publishedOn": "2023-09-16T00:40:57.899Z",
          "wordCount": 678,
          "title": "Machine Learning-Assisted Discovery of Novel Reactor Designs. (arXiv:2308.08841v2 [cs.CE] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01921",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ren_Y/0/1/0/all/0/1\">Yihui Ren</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kagawa_A/0/1/0/all/0/1\">Ai Kagawa</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Carbone_M/0/1/0/all/0/1\">Matthew R. Carbone</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1\">Samuel Yen-Chi Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qu_X/0/1/0/all/0/1\">Xiaohui Qu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yoo_S/0/1/0/all/0/1\">Shinjae Yoo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ramanathan_A/0/1/0/all/0/1\">Arvind Ramanathan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Stevens_R/0/1/0/all/0/1\">Rick L. Stevens</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dam_H/0/1/0/all/0/1\">Hubertus J. J. van Dam</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_D/0/1/0/all/0/1\">Deyu Liu</a>",
          "description": "Fast screening of drug molecules based on the ligand binding affinity is an\nimportant step in the drug discovery pipeline. Graph neural fingerprint is a\npromising method for developing molecular docking surrogates with high\nthroughput and great fidelity. In this study, we built a COVID-19 drug docking\ndataset of about 300,000 drug candidates on 23 coronavirus protein targets.\nWith this dataset, we trained graph neural fingerprint docking models for\nhigh-throughput virtual COVID-19 drug screening. The graph neural fingerprint\nmodels yield high prediction accuracy on docking scores with the mean squared\nerror lower than $0.21$ kcal/mol for most of the docking targets, showing\nsignificant improvement over conventional circular fingerprint methods. To make\nthe neural fingerprints transferable for unknown targets, we also propose a\ntransferable graph neural fingerprint method trained on multiple targets. With\ncomparable accuracy to target-specific graph neural fingerprint models, the\ntransferable model exhibits superb training and data efficiency. We highlight\nthat the impact of this study extends beyond COVID-19 dataset, as our approach\nfor fast virtual ligand screening can be easily adapted and integrated into a\ngeneral machine learning-accelerated pipeline to battle future bio-threats.",
          "link": "http://arxiv.org/abs/2308.01921",
          "publishedOn": "2023-09-16T00:40:57.886Z",
          "wordCount": 795,
          "title": "Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats. (arXiv:2308.01921v2 [q-bio.BM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jinhao Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Edward Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamm_M/0/1/0/all/0/1\">Matthew Stamm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>",
          "description": "Traditional adversarial attacks concentrate on manipulating clean examples in\nthe pixel space by adding adversarial perturbations. By contrast, semantic\nadversarial attacks focus on changing semantic attributes of clean examples,\nsuch as color, context, and features, which are more feasible in the real\nworld. In this paper, we propose a framework to quickly generate a semantic\nadversarial attack by leveraging recent diffusion models since semantic\ninformation is included in the latent space of well-trained diffusion models.\nThen there are two variants of this framework: 1) the Semantic Transformation\n(ST) approach fine-tunes the latent space of the generated image and/or the\ndiffusion model itself; 2) the Latent Masking (LM) approach masks the latent\nspace with another target image and local backpropagation-based interpretation\nmethods. Additionally, the ST approach can be applied in either white-box or\nblack-box settings. Extensive experiments are conducted on CelebA-HQ and AFHQ\ndatasets, and our framework demonstrates great fidelity, generalizability, and\ntransferability compared to other baselines. Our approaches achieve\napproximately 100% attack success rate in multiple settings with the best FID\nas 36.61. Code is available at\nhttps://github.com/steven202/semantic_adv_via_dm.",
          "link": "http://arxiv.org/abs/2309.07398",
          "publishedOn": "2023-09-16T00:40:57.567Z",
          "wordCount": 695,
          "title": "Semantic Adversarial Attacks via Diffusion Models. (arXiv:2309.07398v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.11110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1\">Ning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ruijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1\">Ngo Anh Vien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1\">Hanna Ziesche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "Grasping inhomogeneous objects in real-world applications remains a\nchallenging task due to the unknown physical properties such as mass\ndistribution and coefficient of friction. In this study, we propose a\nmeta-learning algorithm called ConDex, which incorporates Conditional Neural\nProcesses (CNP) with DexNet-2.0 to autonomously discern the underlying physical\nproperties of objects using depth images. ConDex efficiently acquires physical\nembeddings from limited trials, enabling precise grasping point estimation.\nFurthermore, ConDex is capable of updating the predicted grasping quality\niteratively from new trials in an online fashion. To the best of our knowledge,\nwe are the first who generate two object datasets focusing on inhomogeneous\nphysical properties with varying mass distributions and friction coefficients.\nExtensive evaluations in simulation demonstrate ConDex's superior performance\nover DexNet-2.0 and existing meta-learning-based grasping pipelines.\nFurthermore, ConDex shows robust generalization to previously unseen real-world\nobjects despite training solely in the simulation. The synthetic and real-world\ndatasets will be published as well.",
          "link": "http://arxiv.org/abs/2205.11110",
          "publishedOn": "2023-09-16T00:40:57.474Z",
          "wordCount": 685,
          "title": "Meta-Learning Regrasping Strategies for Physical-Agnostic Objects. (arXiv:2205.11110v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.03420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tiehua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuze Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhishu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Rui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaowei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xi Zheng</a>",
          "description": "Spatial-temporal data contains rich information and has been widely studied\nin recent years due to the rapid development of relevant applications in many\nfields. For instance, medical institutions often use electrodes attached to\ndifferent parts of a patient to analyse the electorencephal data rich with\nspatial and temporal features for health assessment and disease diagnosis.\nExisting research has mainly used deep learning techniques such as\nconvolutional neural network (CNN) or recurrent neural network (RNN) to extract\nhidden spatial-temporal features. Yet, it is challenging to incorporate both\ninter-dependencies spatial information and dynamic temporal changes\nsimultaneously. In reality, for a model that leverages these spatial-temporal\nfeatures to fulfil complex prediction tasks, it often requires a colossal\namount of training data in order to obtain satisfactory model performance.\nConsidering the above-mentioned challenges, we propose an adaptive federated\nrelevance framework, namely FedRel, for spatial-temporal graph learning in this\npaper. After transforming the raw spatial-temporal data into high quality\nfeatures, the core Dynamic Inter-Intra Graph (DIIG) module in the framework is\nable to use these features to generate the spatial-temporal graphs capable of\ncapturing the hidden topological and long-term temporal correlation information\nin these graphs. To improve the model generalization ability and performance\nwhile preserving the local data privacy, we also design a relevance-driven\nfederated learning module in our framework to leverage diverse data\ndistributions from different participants with attentive aggregations of their\nmodels.",
          "link": "http://arxiv.org/abs/2206.03420",
          "publishedOn": "2023-09-16T00:40:57.474Z",
          "wordCount": null,
          "title": "An Adaptive Federated Relevance Framework for Spatial Temporal Graph Learning. (arXiv:2206.03420v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ying_W/0/1/0/all/0/1\">Wangyang Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kunpeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanjie Fu</a>",
          "description": "Feature generation aims to generate new and meaningful features to create a\ndiscriminative representation space.A generated feature is meaningful when the\ngenerated feature is from a feature pair with inherent feature interaction. In\nthe real world, experienced data scientists can identify potentially useful\nfeature-feature interactions, and generate meaningful dimensions from an\nexponentially large search space, in an optimal crossing form over an optimal\ngeneration path. But, machines have limited human-like abilities.We generalize\nsuch learning tasks as self-optimizing feature generation. Self-optimizing\nfeature generation imposes several under-addressed challenges on existing\nsystems: meaningful, robust, and efficient generation. To tackle these\nchallenges, we propose a principled and generic representation-crossing\nframework to solve self-optimizing feature generation.To achieve hashing\nrepresentation, we propose a three-step approach: feature discretization,\nfeature hashing, and descriptive summarization. To achieve reinforcement\ncrossing, we develop a hierarchical reinforcement feature crossing approach.We\npresent extensive experimental results to demonstrate the effectiveness and\nefficiency of the proposed method. The code is available at\nhttps://github.com/yingwangyang/HRC_feature_cross.git.",
          "link": "http://arxiv.org/abs/2309.04612",
          "publishedOn": "2023-09-16T00:40:57.469Z",
          "wordCount": 696,
          "title": "Self-optimizing Feature Generation via Categorical Hashing Representation and Hierarchical Reinforcement Crossing. (arXiv:2309.04612v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongkuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_A/0/1/0/all/0/1\">Aifen Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_W/0/1/0/all/0/1\">Wei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Letian Shi</a>",
          "description": "More research attention has recently been given to end-to-end autonomous\ndriving technologies where the entire driving pipeline is replaced with a\nsingle neural network because of its simpler structure and faster inference\ntime. Despite this appealing approach largely reducing the components in\ndriving pipeline, its simplicity also leads to interpretability problems and\nsafety issues arXiv:2003.06404. The trained policy is not always compliant with\nthe traffic rules and it is also hard to discover the reason for the\nmisbehavior because of the lack of intermediate outputs. Meanwhile, Sensors are\nalso critical to autonomous driving's security and feasibility to perceive the\nsurrounding environment under complex driving scenarios. In this paper, we\nproposed P-CSG, a novel penalty-based imitation learning approach with cross\nsemantics generation sensor fusion technologies to increase the overall\nperformance of End-to-End Autonomous Driving. We conducted an assessment of our\nmodel's performance using the Town 05 Long benchmark, achieving an impressive\ndriving score improvement of over 15%. Furthermore, we conducted robustness\nevaluations against adversarial attacks like FGSM and Dot attacks, revealing a\nsubstantial increase in robustness compared to baseline models.More detailed\ninformation, such as code-based resources, ablation studies and videos can be\nfound at https://hk-zh.github.io/p-csg-plus.",
          "link": "http://arxiv.org/abs/2309.07808",
          "publishedOn": "2023-09-16T00:40:57.464Z",
          "wordCount": 732,
          "title": "What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving. (arXiv:2309.07808v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkat_A/0/1/0/all/0/1\">Aarthi Venkat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chew_J/0/1/0/all/0/1\">Joyce Chew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_F/0/1/0/all/0/1\">Ferran Cardoso Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tape_C/0/1/0/all/0/1\">Christopher J. Tape</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlmutter_M/0/1/0/all/0/1\">Michael Perlmutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnaswamy_S/0/1/0/all/0/1\">Smita Krishnaswamy</a>",
          "description": "Directed graphs are a natural model for many phenomena, in particular\nscientific knowledge graphs such as molecular interaction or chemical reaction\nnetworks that define cellular signaling relationships. In these situations,\nsource nodes typically have distinct biophysical properties from sinks. Due to\ntheir ordered and unidirectional relationships, many such networks also have\nhierarchical and multiscale structure. However, the majority of methods\nperforming node- and edge-level tasks in machine learning do not take these\nproperties into account, and thus have not been leveraged effectively for\nscientific tasks such as cellular signaling network inference. We propose a new\nframework called Directed Scattering Autoencoder (DSAE) which uses a directed\nversion of a geometric scattering transform, combined with the non-linear\ndimensionality reduction properties of an autoencoder and the geometric\nproperties of the hyperbolic space to learn latent hierarchies. We show this\nmethod outperforms numerous others on tasks such as embedding directed graphs\nand learning cellular signaling networks.",
          "link": "http://arxiv.org/abs/2309.07813",
          "publishedOn": "2023-09-16T00:40:57.459Z",
          "wordCount": 670,
          "title": "Directed Scattering for Knowledge Graph-based Cellular Signaling Analysis. (arXiv:2309.07813v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinmei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuanning Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>",
          "description": "Accurately labeling biomedical data presents a challenge. Traditional\nsemi-supervised learning methods often under-utilize available unlabeled data.\nTo address this, we propose a novel reliability-based training data cleaning\nmethod employing inductive conformal prediction (ICP). This method capitalizes\non a small set of accurately labeled training data and leverages ICP-calculated\nreliability metrics to rectify mislabeled data and outliers within vast\nquantities of noisy training data. The efficacy of the method is validated\nacross three classification tasks within distinct modalities: filtering\ndrug-induced-liver-injury (DILI) literature with title and abstract, predicting\nICU admission of COVID-19 patients through CT radiomics and electronic health\nrecords, and subtyping breast cancer using RNA-sequencing data. Varying levels\nof noise to the training labels were introduced through label permutation.\nResults show significant enhancements in classification performance: accuracy\nenhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC\nenhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and\naccuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing\nexperiments (up to 74.6% and 89.0%). Our method offers the potential to\nsubstantially boost classification performance in multi-modal biomedical\nmachine learning tasks. Importantly, it accomplishes this without necessitating\nan excessive volume of meticulously curated training data.",
          "link": "http://arxiv.org/abs/2309.07332",
          "publishedOn": "2023-09-16T00:40:57.448Z",
          "wordCount": 803,
          "title": "Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining. (arXiv:2309.07332v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Villegas_D/0/1/0/all/0/1\">Danae S&#xe1;nchez Villegas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preo&#x163;iuc-Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>",
          "description": "Effectively leveraging multimodal information from social media posts is\nessential to various downstream tasks such as sentiment analysis, sarcasm\ndetection and hate speech classification. However, combining text and image\ninformation is challenging because of the idiosyncratic cross-modal semantics\nwith hidden or complementary information present in matching image-text pairs.\nIn this work, we aim to directly model this by proposing the use of two\nauxiliary losses jointly with the main task when fine-tuning any pre-trained\nmultimodal model. Image-Text Contrastive (ITC) brings image-text\nrepresentations of a post closer together and separates them from different\nposts, capturing underlying dependencies. Image-Text Matching (ITM) facilitates\nthe understanding of semantic correspondence between images and text by\npenalizing unrelated pairs. We combine these objectives with five multimodal\nmodels, demonstrating consistent improvements across four popular social media\ndatasets. Furthermore, through detailed analysis, we shed light on the specific\nscenarios and cases where each auxiliary task proves to be most effective.",
          "link": "http://arxiv.org/abs/2309.07794",
          "publishedOn": "2023-09-16T00:40:57.443Z",
          "wordCount": 675,
          "title": "Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary tasks. (arXiv:2309.07794v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.16834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hoang Viet Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thinh Gia Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_C/0/1/0/all/0/1\">Chuong Dinh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_A/0/1/0/all/0/1\">An Dinh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1\">Hien Bich Vo</a>",
          "description": "Innovative enhancement in embedded system platforms, specifically hardware\naccelerations, significantly influence the application of deep learning in\nreal-world scenarios. These innovations translate human labor efforts into\nautomated intelligent systems employed in various areas such as autonomous\ndriving, robotics, Internet-of-Things (IoT), and numerous other impactful\napplications. NVIDIA's Jetson platform is one of the pioneers in offering\noptimal performance regarding energy efficiency and throughput in the execution\nof deep learning algorithms. Previously, most benchmarking analysis was based\non 2D images with a single deep learning model for each comparison result. In\nthis paper, we implement an end-to-end video-based crime-scene anomaly\ndetection system inputting from surveillance videos and the system is deployed\nand completely operates on multiple Jetson edge devices (Nano, AGX Xavier, Orin\nNano). The comparison analysis includes the integration of Torch-TensorRT as a\nsoftware developer kit from NVIDIA for the model performance optimisation. The\nsystem is built based on the PySlowfast open-source project from Facebook as\nthe coding template. The end-to-end system process comprises the videos from\ncamera, data preprocessing pipeline, feature extractor and the anomaly\ndetection. We provide the experience of an AI-based system deployment on\nvarious Jetson Edge devices with Docker technology. Regarding anomaly\ndetectors, a weakly supervised video-based deep learning model called Robust\nTemporal Feature Magnitude Learning (RTFM) is applied in the system. The\napproach system reaches 47.56 frames per second (FPS) inference speed on a\nJetson edge device with only 3.11 GB RAM usage total. We also discover the\npromising Jetson device that the AI system achieves 15% better performance than\nthe previous version of Jetson devices while consuming 50% less energy power.",
          "link": "http://arxiv.org/abs/2307.16834",
          "publishedOn": "2023-09-16T00:40:57.436Z",
          "wordCount": 840,
          "title": "Benchmarking Jetson Edge Devices with an End-to-end Video-based Anomaly Detection System. (arXiv:2307.16834v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Wenyang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xv_C/0/1/0/all/0/1\">Chongxuan Xv</a>",
          "description": "Chlorophyll concentration can well reflect the nutritional status and algal\nblooms of water bodies, and is an important indicator for evaluating water\nquality. The prediction of chlorophyll concentration change trend is of great\nsignificance to environmental protection and aquaculture. However, there is a\ncomplex and indistinguishable nonlinear relationship between many factors\naffecting chlorophyll concentration. In order to effectively mine the nonlinear\nfeatures contained in the data. This paper proposes a time-series decomposition\nadaptive graph-time convolutional network ( AGTCNSD ) prediction model.\nFirstly, the original sequence is decomposed into trend component and periodic\ncomponent by moving average method. Secondly, based on the graph convolutional\nneural network, the water quality parameter data is modeled, and a parameter\nembedding matrix is defined. The idea of matrix decomposition is used to assign\nweight parameters to each node. The adaptive graph convolution learns the\nrelationship between different water quality parameters, updates the state\ninformation of each parameter, and improves the learning ability of the update\nrelationship between nodes. Finally, time dependence is captured by time\nconvolution to achieve multi-step prediction of chlorophyll concentration. The\nvalidity of the model is verified by the water quality data of the coastal city\nBeihai. The results show that the prediction effect of this method is better\nthan other methods. It can be used as a scientific resource for environmental\nmanagement decision-making.",
          "link": "http://arxiv.org/abs/2309.07187",
          "publishedOn": "2023-09-16T00:40:57.431Z",
          "wordCount": 758,
          "title": "Multi-step prediction of chlorophyll concentration based on Adaptive Graph-Temporal Convolutional Network with Series Decomposition. (arXiv:2309.07187v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.09597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions. Resources are\navailable at https://github.com/zjunlp/Prompt4ReasoningPapers (updated\nperiodically).",
          "link": "http://arxiv.org/abs/2212.09597",
          "publishedOn": "2023-09-16T00:40:57.424Z",
          "wordCount": 671,
          "title": "Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v7 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leite_J/0/1/0/all/0/1\">Jo&#xe3;o A. Leite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razuvayevskaya_O/0/1/0/all/0/1\">Olesya Razuvayevskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>",
          "description": "Credibility signals represent a wide range of heuristics that are typically\nused by journalists and fact-checkers to assess the veracity of online content.\nAutomating the task of credibility signal extraction, however, is very\nchallenging as it requires high-accuracy signal-specific extractors to be\ntrained, while there are currently no sufficiently large datasets annotated\nwith all credibility signals. This paper investigates whether large language\nmodels (LLMs) can be prompted effectively with a set of 18 credibility signals\nto produce weak labels for each signal. We then aggregate these potentially\nnoisy labels using weak supervision in order to predict content veracity. We\ndemonstrate that our approach, which combines zero-shot LLM credibility signal\nlabeling and weak supervision, outperforms state-of-the-art classifiers on two\nmisinformation datasets without using any ground-truth labels for training. We\nalso analyse the contribution of the individual credibility signals towards\npredicting content veracity, which provides new valuable insights into their\nrole in misinformation detection.",
          "link": "http://arxiv.org/abs/2309.07601",
          "publishedOn": "2023-09-16T00:40:57.411Z",
          "wordCount": 663,
          "title": "Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision. (arXiv:2309.07601v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yumeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraj_S/0/1/0/all/0/1\">Soumya Jayaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludmir_E/0/1/0/all/0/1\">Ethan B Ludmir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_K/0/1/0/all/0/1\">Kirk Roberts</a>",
          "description": "Automatic identification of clinical trials for which a patient is eligible\nis complicated by the fact that trial eligibility is stated in natural\nlanguage. A potential solution to this problem is to employ text classification\nmethods for common types of eligibility criteria. In this study, we focus on\nseven common exclusion criteria in cancer trials: prior malignancy, human\nimmunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness,\ndrug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase\nIII cancer trials with these exclusions annotated at the trial level. We\nexperiment with common transformer models as well as a new pre-trained clinical\ntrial BERT model. Our results demonstrate the feasibility of automatically\nclassifying common exclusion criteria. Additionally, we demonstrate the value\nof a pre-trained language model specifically for clinical trials, which yields\nthe highest average performance across all criteria.",
          "link": "http://arxiv.org/abs/2309.07812",
          "publishedOn": "2023-09-16T00:40:57.405Z",
          "wordCount": 645,
          "title": "Text Classification of Cancer Clinical Trial Eligibility Criteria. (arXiv:2309.07812v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valle_M/0/1/0/all/0/1\">Marcos Eduardo Valle</a>",
          "description": "Despite the many successful applications of deep learning models for\nmultidimensional signal and image processing, most traditional neural networks\nprocess data represented by (multidimensional) arrays of real numbers. The\nintercorrelation between feature channels is usually expected to be learned\nfrom the training data, requiring numerous parameters and careful training. In\ncontrast, vector-valued neural networks are conceived to process arrays of\nvectors and naturally consider the intercorrelation between feature channels.\nConsequently, they usually have fewer parameters and often undergo more robust\ntraining than traditional neural networks. This paper aims to present a broad\nframework for vector-valued neural networks, referred to as V-nets. In this\ncontext, hypercomplex-valued neural networks are regarded as vector-valued\nmodels with additional algebraic properties. Furthermore, this paper explains\nthe relationship between vector-valued and traditional neural networks.\nPrecisely, a vector-valued neural network can be obtained by placing\nrestrictions on a real-valued model to consider the intercorrelation between\nfeature channels. Finally, we show how V-nets, including hypercomplex-valued\nneural networks, can be implemented in current deep-learning libraries as\nreal-valued networks.",
          "link": "http://arxiv.org/abs/2309.07716",
          "publishedOn": "2023-09-16T00:40:57.401Z",
          "wordCount": 687,
          "title": "Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks. (arXiv:2309.07716v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07134",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Belyaev_M/0/1/0/all/0/1\">Maksim Belyaev</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murugappan_M/0/1/0/all/0/1\">Murugappan Murugappan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Velichko_A/0/1/0/all/0/1\">Andrei Velichko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korzun_D/0/1/0/all/0/1\">Dmitry Korzun</a>",
          "description": "The study presents the concept of a computationally efficient machine\nlearning (ML) model for diagnosing and monitoring Parkinson's disease (PD) in\nan Internet of Things (IoT) environment using rest-state EEG signals (rs-EEG).\nWe computed different types of entropy from EEG signals and found that Fuzzy\nEntropy performed the best in diagnosing and monitoring PD using rs-EEG. We\nalso investigated different combinations of signal frequency ranges and EEG\nchannels to accurately diagnose PD. Finally, with a fewer number of features\n(11 features), we achieved a maximum classification accuracy (ARKF) of ~99.9%.\nThe most prominent frequency range of EEG signals has been identified, and we\nhave found that high classification accuracy depends on low-frequency signal\ncomponents (0-4 Hz). Moreover, the most informative signals were mainly\nreceived from the right hemisphere of the head (F8, P8, T8, FC6). Furthermore,\nwe assessed the accuracy of the diagnosis of PD using three different lengths\nof EEG data (150-1000 samples). Because the computational complexity is reduced\nby reducing the input data. As a result, we have achieved a maximum mean\naccuracy of 99.9% for a sample length (LEEG) of 1000 (~7.8 seconds), 98.2% with\na LEEG of 800 (~6.2 seconds), and 79.3% for LEEG = 150 (~1.2 seconds). By\nreducing the number of features and segment lengths, the computational cost of\nclassification can be reduced. Lower-performance smart ML sensors can be used\nin IoT environments for enhances human resilience to PD.",
          "link": "http://arxiv.org/abs/2309.07134",
          "publishedOn": "2023-09-16T00:40:57.396Z",
          "wordCount": 781,
          "title": "Entropy-based machine learning model for diagnosis and monitoring of Parkinson's Disease in smart IoT environment. (arXiv:2309.07134v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.07626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "In this work, we provide a characterization of the feature-learning process\nin two-layer ReLU networks trained by gradient descent on the logistic loss\nfollowing random initialization. We consider data with binary labels that are\ngenerated by an XOR-like function of the input features. We permit a constant\nfraction of the training labels to be corrupted by an adversary. We show that,\nalthough linear classifiers are no better than random guessing for the\ndistribution we consider, two-layer ReLU networks trained by gradient descent\nachieve generalization error close to the label noise rate. We develop a novel\nproof technique that shows that at initialization, the vast majority of neurons\nfunction as random features that are only weakly correlated with useful\nfeatures, and the gradient descent dynamics 'amplify' these weak, random\nfeatures to strong, useful features.",
          "link": "http://arxiv.org/abs/2202.07626",
          "publishedOn": "2023-09-16T00:40:57.383Z",
          "wordCount": 697,
          "title": "Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Firoozsalari_A/0/1/0/all/0/1\">Ali Nosrati Firoozsalari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazraeh_H/0/1/0/all/0/1\">Hassan Dana Mazraeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghaei_A/0/1/0/all/0/1\">Alireza Afzal Aghaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parand_K/0/1/0/all/0/1\">Kourosh Parand</a>",
          "description": "The primary goal of this research is to propose a novel architecture for a\ndeep neural network that can solve fractional differential equations\naccurately. A Gaussian integration rule and a $L_1$ discretization technique\nare used in the proposed design. In each equation, a deep neural network is\nused to approximate the unknown function. Three forms of fractional\ndifferential equations have been examined to highlight the method's\nversatility: a fractional ordinary differential equation, a fractional order\nintegrodifferential equation, and a fractional order partial differential\nequation. The results show that the proposed architecture solves different\nforms of fractional differential equations with excellent precision.",
          "link": "http://arxiv.org/abs/2309.07684",
          "publishedOn": "2023-09-16T00:40:57.362Z",
          "wordCount": 631,
          "title": "deepFDEnet: A Novel Neural Network Architecture for Solving Fractional Differential Equations. (arXiv:2309.07684v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.07097",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hagos_M/0/1/0/all/0/1\">Misgina Tsighe Hagos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Belton_N/0/1/0/all/0/1\">Niamh Belton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Killeen_R/0/1/0/all/0/1\">Ronan P. Killeen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Curran_K/0/1/0/all/0/1\">Kathleen M. Curran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>",
          "description": "Alzheimer's Disease (AD) is a progressive disease preceded by Mild Cognitive\nImpairment (MCI). Early detection of AD is crucial for making treatment\ndecisions. However, most of the literature on computer-assisted detection of AD\nfocuses on classifying brain images into one of three major categories:\nhealthy, MCI, and AD; or categorizing MCI patients into (1) progressive: those\nwho progress from MCI to AD at a future examination time, and (2) stable: those\nwho stay as MCI and never progress to AD. This misses the opportunity to\naccurately identify the trajectory of progressive MCI patients. In this paper,\nwe revisit the brain image classification task for AD identification and\nre-frame it as an ordinal classification task to predict how close a patient is\nto the severe AD stage. To this end, we select progressive MCI patients from\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset and construct an\nordinal dataset with a prediction target that indicates the time to progression\nto AD. We train a Siamese network model to predict the time to onset of AD\nbased on MRI brain images. We also propose a Weighted variety of Siamese\nnetwork and compare its performance to a baseline model. Our evaluations show\nthat incorporating a weighting factor to Siamese networks brings considerable\nperformance gain at predicting how close input brain MRI images are to\nprogressing to AD. Moreover, we complement our results with an interpretation\nof the learned embedding space of the Siamese networks using a model\nexplainability technique.",
          "link": "http://arxiv.org/abs/2304.07097",
          "publishedOn": "2023-09-16T00:40:57.357Z",
          "wordCount": 828,
          "title": "Interpretable Weighted Siamese Network to Predict the Time to Onset of Alzheimer's Disease from MRI Images. (arXiv:2304.07097v2 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.10851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ringstrom_T/0/1/0/all/0/1\">Thomas J. Ringstrom</a>",
          "description": "Reinforcement Learning views the maximization of rewards and avoidance of\npunishments as central to explaining goal-directed behavior. However, over a\nlife, organisms will need to learn about many different aspects of the world's\nstructure: the states of the world and state-vector transition dynamics. The\nnumber of combinations of states grows exponentially as an agent incorporates\nnew knowledge, and there is no obvious weighted combination of pre-existing\nrewards or costs defined for a given combination of states, as such a weighting\nwould need to encode information about good and bad combinations prior to an\nagent's experience in the world. Therefore, we must develop more naturalistic\naccounts of behavior and motivation in large state-spaces. We show that it is\npossible to use only the intrinsic motivation metric of empowerment, which\nmeasures the agent's capacity to realize many possible futures under a\ntransition operator. We propose to scale empowerment to hierarchical\nstate-spaces by using Operator Bellman Equations. These equations produce\nstate-time feasibility functions, which are compositional hierarchical\nstate-time transition operators that map an initial state and time when an\nagent begins a policy to the final states and times of completing a goal.\nBecause these functions are hierarchical operators we can define hierarchical\nempowerment measures on them. An agent can then optimize plans to distant\nstates and times to maximize its hierarchical empowerment-gain, allowing it to\ndiscover goals that bring about a more favorable coupling of its internal\nstructure (physiological states) to its external environment (world structure &\nspatial state). Life-long agents could therefore be primarily animated by\nprinciples of compositionality and empowerment, exhibiting self-concern for the\ngrowth & maintenance of their own structural integrity without recourse to\nreward-maximization.",
          "link": "http://arxiv.org/abs/2211.10851",
          "publishedOn": "2023-09-16T00:40:57.352Z",
          "wordCount": 816,
          "title": "Reward is not Necessary: How to Create a Compositional Self-Preserving Agent for Life-Long Learning. (arXiv:2211.10851v3 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07136",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1\">Ya Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diao_X/0/1/0/all/0/1\">Xiaolin Diao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huo_Y/0/1/0/all/0/1\">Yanni Huo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_X/0/1/0/all/0/1\">Xiaohan Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_W/0/1/0/all/0/1\">Wei Zhao</a>",
          "description": "Electrocardiogram (ECG) is one of the most important diagnostic tools in\nclinical applications. With the advent of advanced algorithms, various deep\nlearning models have been adopted for ECG tasks. However, the potential of\nTransformers for ECG data is not yet realized, despite their widespread success\nin computer vision and natural language processing. In this work, we present a\nuseful masked Transformer method for ECG classification referred to as MTECG,\nwhich expands the application of masked autoencoders to ECG time series. We\nconstruct a dataset comprising 220,251 ECG recordings with a broad range of\ndiagnoses annoated by medical experts to explore the properties of MTECG. Under\nthe proposed training strategies, a lightweight model with 5.7M parameters\nperforms stably well on a broad range of masking ratios (5%-75%). The ablation\nstudies highlight the importance of fluctuated reconstruction targets, training\nschedule length, layer-wise LR decay and DropPath rate. The experiments on both\nprivate and public ECG datasets demonstrate that MTECG-T significantly\noutperforms the recent state-of-the-art algorithms in ECG classification.",
          "link": "http://arxiv.org/abs/2309.07136",
          "publishedOn": "2023-09-16T00:40:57.344Z",
          "wordCount": 668,
          "title": "Masked Transformer for Electrocardiogram Classification. (arXiv:2309.07136v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seraphim_M/0/1/0/all/0/1\">Mathieu Seraphim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lechervy_A/0/1/0/all/0/1\">Alexis Lechervy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yger_F/0/1/0/all/0/1\">Florian Yger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brun_L/0/1/0/all/0/1\">Luc Brun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etard_O/0/1/0/all/0/1\">Olivier Etard</a>",
          "description": "In recent years, Transformer-based auto-attention mechanisms have been\nsuccessfully applied to the analysis of a variety of context-reliant data\ntypes, from texts to images and beyond, including data from non-Euclidean\ngeometries. In this paper, we present such a mechanism, designed to classify\nsequences of Symmetric Positive Definite matrices while preserving their\nRiemannian geometry throughout the analysis. We apply our method to automatic\nsleep staging on timeseries of EEG-derived covariance matrices from a standard\ndataset, obtaining high levels of stage-wise performance.",
          "link": "http://arxiv.org/abs/2309.07579",
          "publishedOn": "2023-09-16T00:40:57.321Z",
          "wordCount": null,
          "title": "Structure-Preserving Transformers for Sequences of SPD Matrices. (arXiv:2309.07579v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1\">Davinder Pal Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_L/0/1/0/all/0/1\">Lala Shakti Swarup Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_S/0/1/0/all/0/1\">Sungho Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukowicz_P/0/1/0/all/0/1\">Paul Lukowicz</a>",
          "description": "We present a novel local-global feature fusion framework for body-weight\nexercise recognition with floor-based dynamic pressure maps. One step further\nfrom the existing studies using deep neural networks mainly focusing on global\nfeature extraction, the proposed framework aims to combine local and global\nfeatures using image processing techniques and the YOLO object detection to\nlocalize pressure profiles from different body parts and consider physical\nconstraints. The proposed local feature extraction method generates two sets of\nhigh-level local features consisting of cropped pressure mapping and numerical\nfeatures such as angular orientation, location on the mat, and pressure area.\nIn addition, we adopt a knowledge distillation for regularization to preserve\nthe knowledge of the global feature extraction and improve the performance of\nthe exercise recognition. Our experimental results demonstrate a notable 11\npercent improvement in F1 score for exercise recognition while preserving\nlabel-specific features.",
          "link": "http://arxiv.org/abs/2309.07888",
          "publishedOn": "2023-09-16T00:40:57.307Z",
          "wordCount": 677,
          "title": "A Novel Local-Global Feature Fusion Framework for Body-weight Exercise Recognition with Pressure Mapping Sensors. (arXiv:2309.07888v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.10848",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Boettcher_S/0/1/0/all/0/1\">Stefan Boettcher</a> (Emory U)",
          "description": "In Changjun Fan et al. [Nature Communications\nhttps://doi.org/10.1038/s41467-023-36363-w (2023)], the authors present a deep\nreinforced learning approach to augment combinatorial optimization heuristics.\nIn particular, they present results for several spin glass ground state\nproblems, for which instances on non-planar networks are generally NP-hard, in\ncomparison with several Monte Carlo based methods, such as simulated annealing\n(SA) or parallel tempering (PT). Indeed, those results demonstrate that the\nreinforced learning improves the results over those obtained with SA or PT, or\nat least allows for reduced runtimes for the heuristics before results of\ncomparable quality have been obtained relative to those other methods. To\nfacilitate the conclusion that their method is ''superior'', the authors pursue\ntwo basic strategies: (1) A commercial GUROBI solver is called on to procure a\nsample of exact ground states as a testbed to compare with, and (2) a\nhead-to-head comparison between the heuristics is given for a sample of larger\ninstances where exact ground states are hard to ascertain. Here, we put these\nstudies into a larger context, showing that the claimed superiority is at best\nmarginal for smaller samples and becomes essentially irrelevant with respect to\nany sensible approximation of true ground states in the larger samples. For\nexample, this method becomes irrelevant as a means to determine stiffness\nexponents $\\theta$ in $d>2$, as mentioned by the authors, where the problem is\nnot only NP-hard but requires the subtraction of two almost equal ground-state\nenergies and systemic errors in each of $\\approx 1\\%$ found here are\nunacceptable. This larger picture on the method arises from a straightforward\nfinite-size corrections study over the spin glass ensembles the authors employ,\nusing data that has been available for decades.",
          "link": "http://arxiv.org/abs/2302.10848",
          "publishedOn": "2023-09-16T00:40:57.259Z",
          "wordCount": null,
          "title": "Deep reinforced learning heuristic tested on spin-glass ground states: The larger picture. (arXiv:2302.10848v2 [cond-mat.dis-nn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Wei-Wei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei-Yao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Chih Peng</a>",
          "description": "The marketplace system connecting demands and supplies has been explored to\ndevelop unbiased decision-making in valuing properties. Real estate appraisal\nserves as one of the high-cost property valuation tasks for financial\ninstitutions since it requires domain experts to appraise the estimation based\non the corresponding knowledge and the judgment of the market. Existing\nautomated valuation models reducing the subjectivity of domain experts require\na large number of transactions for effective evaluation, which is predominantly\nlimited to not only the labeling efforts of transactions but also the\ngeneralizability of new developing and rural areas. To learn representations\nfrom unlabeled real estate sets, existing self-supervised learning (SSL) for\ntabular data neglects various important features, and fails to incorporate\ndomain knowledge. In this paper, we propose DoRA, a Domain-based\nself-supervised learning framework for low-resource Real estate Appraisal. DoRA\nis pre-trained with an intra-sample geographic prediction as the pretext task\nbased on the metadata of the real estate for equipping the real estate\nrepresentations with prior domain knowledge. Furthermore, inter-sample\ncontrastive learning is employed to generalize the representations to be robust\nfor limited transactions of downstream tasks. Our benchmark results on three\nproperty types of real-world transactions show that DoRA significantly\noutperforms the SSL baselines for tabular data, the graph-based methods, and\nthe supervised approaches in the few-shot scenarios by at least 7.6% for MAPE,\n11.59% for MAE, and 3.34% for HR10%. We expect DoRA to be useful to other\nfinancial practitioners with similar marketplace applications who need general\nmodels for properties that are newly built and have limited records. The source\ncode is available at https://github.com/wwweiwei/DoRA.",
          "link": "http://arxiv.org/abs/2309.00855",
          "publishedOn": "2023-09-16T00:40:57.252Z",
          "wordCount": null,
          "title": "DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource Real Estate Appraisal. (arXiv:2309.00855v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dumont_M/0/1/0/all/0/1\">Mathieu Dumont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hector_K/0/1/0/all/0/1\">Kevin Hector</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moellic_P/0/1/0/all/0/1\">Pierre-Alain Moellic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutertre_J/0/1/0/all/0/1\">Jean-Max Dutertre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pontie_S/0/1/0/all/0/1\">Simon Ponti&#xe9;</a>",
          "description": "Upcoming certification actions related to the security of machine learning\n(ML) based systems raise major evaluation challenges that are amplified by the\nlarge-scale deployment of models in many hardware platforms. Until recently,\nmost of research works focused on API-based attacks that consider a ML model as\na pure algorithmic abstraction. However, new implementation-based threats have\nbeen revealed, emphasizing the urgency to propose both practical and\nsimulation-based methods to properly evaluate the robustness of models. A major\nconcern is parameter-based attacks (such as the Bit-Flip Attack, BFA) that\nhighlight the lack of robustness of typical deep neural network models when\nconfronted by accurate and optimal alterations of their internal parameters\nstored in memory. Setting in a security testing purpose, this work practically\nreports, for the first time, a successful variant of the BFA on a 32-bit\nCortex-M microcontroller using laser fault injection. It is a standard fault\ninjection means for security evaluation, that enables to inject spatially and\ntemporally accurate faults. To avoid unrealistic brute-force strategies, we\nshow how simulations help selecting the most sensitive set of bits from the\nparameters taking into account the laser fault model.",
          "link": "http://arxiv.org/abs/2304.12876",
          "publishedOn": "2023-09-16T00:40:57.222Z",
          "wordCount": null,
          "title": "Evaluation of Parameter-based Attacks against Embedded Neural Networks with Laser Injection. (arXiv:2304.12876v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yafei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jianguo Liu</a>",
          "description": "Score-based methods for learning Bayesain networks(BN) aim to maximizing the\nglobal score functions. However, if local variables have direct and indirect\ndependence simultaneously, the global optimization on score functions misses\nedges between variables with indirect dependent relationship, of which scores\nare smaller than those with direct dependent relationship. In this paper, we\npresent an identifiability condition based on a determined subset of parents to\nidentify the underlying DAG. By the identifiability condition, we develop a\ntwo-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the\nglobal optimization. In the optimal phase, an optimization problem based on\nfirst-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated\nskeleton as the initial determined parents subset. In the tuning phase, the\nskeleton is locally tuned by deletion, addition and DAG-formalization\nstrategies using the theoretically proved incremental properties of high-order\nHSIC. Numerical experiments for different synthetic datasets and real-world\ndatasets show that the OT algorithm outperforms existing methods. Especially in\nSigmoid Mix model with the size of the graph being ${\\rm\\bf d=40}$, the\nstructure intervention distance (SID) of the OT algorithm is 329.7 smaller than\nthe one obtained by CAM, which indicates that the graph estimated by the OT\nalgorithm misses fewer edges compared with CAM.Source code of the OT algorithm\nis available at https://github.com/YafeiannWang/optimal-tune-algorithm.",
          "link": "http://arxiv.org/abs/2308.05969",
          "publishedOn": "2023-09-16T00:40:57.208Z",
          "wordCount": null,
          "title": "Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andrecut_M/0/1/0/all/0/1\">M. Andrecut</a>",
          "description": "Predicting the dynamics of chaotic systems is one of the most challenging\ntasks for neural networks, and machine learning in general. Here we aim to\npredict the spatiotemporal chaotic dynamics of a high-dimensional non-linear\nsystem. In our attempt we use the TensorFlow library, representing the state of\nthe art for deep neural networks training and prediction. While our results are\nencouraging, and show that the dynamics of the considered system can be\npredicted for short time, we also indirectly discovered an unexpected and\nundesirable behavior of the TensorFlow library. More specifically, the longer\nterm prediction of the system's chaotic behavior quickly deteriorates and blows\nup due to the nondeterministic behavior of the TensorFlow library. Here we\nprovide numerical evidence of the short time prediction ability, and of the\nlonger term predictability blow up.",
          "link": "http://arxiv.org/abs/2309.07450",
          "publishedOn": "2023-09-16T00:40:57.207Z",
          "wordCount": null,
          "title": "TensorFlow Chaotic Prediction and Blow Up. (arXiv:2309.07450v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.06724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wangni_J/0/1/0/all/0/1\">Jianqiao Wangni</a>",
          "description": "We aim to provide a general framework of for computational photography that\nrecovers the real scene from imperfect images, via the Deep Nonparametric\nConvexified Filtering (DNCF). It is consists of a nonparametric deep network to\nresemble the physical equations behind the image formation, such as denoising,\nsuper-resolution, inpainting, and flash. DNCF has no parameterization dependent\non training data, therefore has a strong generalization and robustness to\nadversarial image manipulation. During inference, we also encourage the network\nparameters to be nonnegative and create a bi-convex function on the input and\nparameters, and this adapts to second-order optimization algorithms with\ninsufficient running time, having 10X acceleration over Deep Image Prior. With\nthese tools, we empirically verify its capability to defend image\nclassification deep networks against adversary attack algorithms in real-time.",
          "link": "http://arxiv.org/abs/2309.06724",
          "publishedOn": "2023-09-16T00:40:57.197Z",
          "wordCount": null,
          "title": "Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense. (arXiv:2309.06724v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xingfu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paramasivam_P/0/1/0/all/0/1\">Praveen Paramasivam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_V/0/1/0/all/0/1\">Valerie Taylor</a>",
          "description": "Apache TVM (Tensor Virtual Machine), an open source machine learning compiler\nframework designed to optimize computations across various hardware platforms,\nprovides an opportunity to improve the performance of dense matrix\nfactorizations such as LU (Lower Upper) decomposition and Cholesky\ndecomposition on GPUs and AI (Artificial Intelligence) accelerators. In this\npaper, we propose a new TVM autotuning framework using Bayesian Optimization\nand use the TVM tensor expression language to implement linear algebra kernels\nsuch as LU, Cholesky, and 3mm. We use these scientific computation kernels to\nevaluate the effectiveness of our methods on a GPU cluster, called Swing, at\nArgonne National Laboratory. We compare the proposed autotuning framework with\nthe TVM autotuning framework AutoTVM with four tuners and find that our\nframework outperforms AutoTVM in most cases.",
          "link": "http://arxiv.org/abs/2309.07235",
          "publishedOn": "2023-09-16T00:40:57.196Z",
          "wordCount": null,
          "title": "Autotuning Apache TVM-based Scientific Applications Using Bayesian Optimization. (arXiv:2309.07235v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marconato_E/0/1/0/all/0/1\">Emanuele Marconato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1\">Andrea Passerini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teso_S/0/1/0/all/0/1\">Stefano Teso</a>",
          "description": "Focus in Explainable AI is shifting from explanations defined in terms of\nlow-level elements, such as input features, to explanations encoded in terms of\ninterpretable concepts learned from data. How to reliably acquire such concepts\nis, however, still fundamentally unclear. An agreed-upon notion of concept\ninterpretability is missing, with the result that concepts used by both\npost-hoc explainers and concept-based neural networks are acquired through a\nvariety of mutually incompatible strategies. Critically, most of these neglect\nthe human side of the problem: a representation is understandable only insofar\nas it can be understood by the human at the receiving end. The key challenge in\nHuman-interpretable Representation Learning (HRL) is how to model and\noperationalize this human element. In this work, we propose a mathematical\nframework for acquiring interpretable representations suitable for both\npost-hoc explainers and concept-based neural networks. Our formalization of HRL\nbuilds on recent advances in causal representation learning and explicitly\nmodels a human stakeholder as an external observer. This allows us to derive a\nprincipled notion of alignment between the machine representation and the\nvocabulary of concepts understood by the human. In doing so, we link alignment\nand interpretability through a simple and intuitive name transfer game, and\nclarify the relationship between alignment and a well-known property of\nrepresentations, namely disentanglment. We also show that alignment is linked\nto the issue of undesirable correlations among concepts, also known as concept\nleakage, and to content-style separation, all through a general\ninformation-theoretic reformulation of these properties. Our conceptualization\naims to bridge the gap between the human and algorithmic sides of\ninterpretability and establish a stepping stone for new research on\nhuman-interpretable representations.",
          "link": "http://arxiv.org/abs/2309.07742",
          "publishedOn": "2023-09-16T00:40:57.048Z",
          "wordCount": null,
          "title": "Interpretability is in the Mind of the Beholder: A Causal Framework for Human-interpretable Representation Learning. (arXiv:2309.07742v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07835",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Sambharya_R/0/1/0/all/0/1\">Rajiv Sambharya</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hall_G/0/1/0/all/0/1\">Georgina Hall</a>, <a href=\"http://arxiv.org/find/math/1/au:+Amos_B/0/1/0/all/0/1\">Brandon Amos</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stellato_B/0/1/0/all/0/1\">Bartolomeo Stellato</a>",
          "description": "We introduce a machine-learning framework to warm-start fixed-point\noptimization algorithms. Our architecture consists of a neural network mapping\nproblem parameters to warm starts, followed by a predefined number of\nfixed-point iterations. We propose two loss functions designed to either\nminimize the fixed-point residual or the distance to a ground truth solution.\nIn this way, the neural network predicts warm starts with the end-to-end goal\nof minimizing the downstream loss. An important feature of our architecture is\nits flexibility, in that it can predict a warm start for fixed-point algorithms\nrun for any number of steps, without being limited to the number of steps it\nhas been trained on. We provide PAC-Bayes generalization bounds on unseen data\nfor common classes of fixed-point operators: contractive, linearly convergent,\nand averaged. Applying this framework to well-known applications in control,\nstatistics, and signal processing, we observe a significant reduction in the\nnumber of iterations and solution time required to solve these problems,\nthrough learned warm starts.",
          "link": "http://arxiv.org/abs/2309.07835",
          "publishedOn": "2023-09-16T00:40:57.042Z",
          "wordCount": null,
          "title": "Learning to Warm-Start Fixed-Point Optimization Algorithms. (arXiv:2309.07835v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.00331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We consider nonconvex-concave minimax problems, $\\min_{\\mathbf{x}}\n\\max_{\\mathbf{y} \\in \\mathcal{Y}} f(\\mathbf{x}, \\mathbf{y})$, where $f$ is\nnonconvex in $\\mathbf{x}$ but concave in $\\mathbf{y}$ and $\\mathcal{Y}$ is a\nconvex and bounded set. One of the most popular algorithms for solving this\nproblem is the celebrated gradient descent ascent (GDA) algorithm, which has\nbeen widely used in machine learning, control theory and economics. Despite the\nextensive convergence results for the convex-concave setting, GDA with equal\nstepsize can converge to limit cycles or even diverge in a general setting. In\nthis paper, we present the complexity results on two-time-scale GDA for solving\nnonconvex-concave minimax problems, showing that the algorithm can find a\nstationary point of the function $\\Phi(\\cdot) := \\max_{\\mathbf{y} \\in\n\\mathcal{Y}} f(\\cdot, \\mathbf{y})$ efficiently. To the best our knowledge, this\nis the first nonasymptotic analysis for two-time-scale GDA in this setting,\nshedding light on its superior practical performance in training generative\nadversarial networks (GANs) and other real applications.",
          "link": "http://arxiv.org/abs/1906.00331",
          "publishedOn": "2023-09-16T00:40:57.040Z",
          "wordCount": null,
          "title": "On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. (arXiv:1906.00331v9 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1\">Francisco Nunes Ferreira Quialheiro Simoes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dastani_M/0/1/0/all/0/1\">Mehdi Dastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommen_T/0/1/0/all/0/1\">Thijs van Ommen</a>",
          "description": "Artificial intelligence models and methods commonly lack causal\ninterpretability. Despite the advancements in interpretable machine learning\n(IML) methods, they frequently assign importance to features which lack causal\ninfluence on the outcome variable. Selecting causally relevant features among\nthose identified as relevant by these methods, or even before model training,\nwould offer a solution. Feature selection methods utilizing information\ntheoretical quantities have been successful in identifying statistically\nrelevant features. However, the information theoretical quantities they are\nbased on do not incorporate causality, rendering them unsuitable for such\nscenarios. To address this challenge, this article proposes information\ntheoretical quantities that incorporate the causal structure of the system,\nwhich can be used to evaluate causal importance of features for some given\noutcome variable. Specifically, we introduce causal versions of entropy and\nmutual information, termed causal entropy and causal information gain, which\nare designed to assess how much control a feature provides over the outcome\nvariable. These newly defined quantities capture changes in the entropy of a\nvariable resulting from interventions on other variables. Fundamental results\nconnecting these quantities to the existence of causal effects are derived. The\nuse of causal information gain in feature selection is demonstrated,\nhighlighting its superiority over standard mutual information in revealing\nwhich features provide control over a chosen outcome variable. Our\ninvestigation paves the way for the development of methods with improved\ninterpretability in domains involving causation.",
          "link": "http://arxiv.org/abs/2309.07703",
          "publishedOn": "2023-09-16T00:40:57.038Z",
          "wordCount": null,
          "title": "Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brecht_R/0/1/0/all/0/1\">R&#xfc;diger Brecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popovych_D/0/1/0/all/0/1\">Dmytro R. Popovych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bihlo_A/0/1/0/all/0/1\">Alex Bihlo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popovych_R/0/1/0/all/0/1\">Roman O. Popovych</a>",
          "description": "Current physics-informed (standard or operator) neural networks still rely on\naccurately learning the initial conditions of the system they are solving. In\ncontrast, standard numerical methods evolve such initial conditions without\nneeding to learn these. In this study, we propose to improve current\nphysics-informed deep learning strategies such that initial conditions do not\nneed to be learned and are represented exactly in the predicted solution.\nMoreover, this method guarantees that when a DeepONet is applied multiple times\nto time step a solution, the resulting function is continuous.",
          "link": "http://arxiv.org/abs/2309.07899",
          "publishedOn": "2023-09-16T00:40:57.037Z",
          "wordCount": null,
          "title": "Improving physics-informed DeepONets with hard constraints. (arXiv:2309.07899v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07860",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Forestano_R/0/1/0/all/0/1\">Roy T. Forestano</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Matchev_K/0/1/0/all/0/1\">Konstantin T. Matchev</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Matcheva_K/0/1/0/all/0/1\">Katia Matcheva</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Roman_A/0/1/0/all/0/1\">Alexander Roman</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Unlu_E/0/1/0/all/0/1\">Eyup B. Unlu</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Verner_S/0/1/0/all/0/1\">Sarunas Verner</a>",
          "description": "Deep learning was recently successfully used in deriving symmetry\ntransformations that preserve important physics quantities. Being completely\nagnostic, these techniques postpone the identification of the discovered\nsymmetries to a later stage. In this letter we propose methods for examining\nand identifying the group-theoretic structure of such machine-learned\nsymmetries. We design loss functions which probe the subalgebra structure\neither during the deep learning stage of symmetry discovery or in a subsequent\npost-processing stage. We illustrate the new methods with examples from the\nU(n) Lie group family, obtaining the respective subalgebra decompositions. As\nan application to particle physics, we demonstrate the identification of the\nresidual symmetries after the spontaneous breaking of non-Abelian gauge\nsymmetries like SU(3) and SU(5) which are commonly used in model building.",
          "link": "http://arxiv.org/abs/2309.07860",
          "publishedOn": "2023-09-16T00:40:57.008Z",
          "wordCount": null,
          "title": "Identifying the Group-Theoretic Structure of Machine-Learned Symmetries. (arXiv:2309.07860v1 [hep-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07690",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1\">Xiran Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1\">Yujie Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xihong Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Jing Chen</a>",
          "description": "Auditory spatial attention detection (ASAD) aims to decode the attended\nspatial location with EEG in a multiple-speaker setting. ASAD methods are\ninspired by the brain lateralization of cortical neural responses during the\nprocessing of auditory spatial attention, and show promising performance for\nthe task of auditory attention decoding (AAD) with neural recordings. In the\nprevious ASAD methods, the spatial distribution of EEG electrodes is not fully\nexploited, which may limit the performance of these methods. In the present\nwork, by transforming the original EEG channels into a two-dimensional (2D)\nspatial topological map, the EEG data is transformed into a three-dimensional\n(3D) arrangement containing spatial-temporal information. And then a 3D deep\nconvolutional neural network (DenseNet-3D) is used to extract temporal and\nspatial features of the neural representation for the attended locations. The\nresults show that the proposed method achieves higher decoding accuracy than\nthe state-of-the-art (SOTA) method (94.4% compared to XANet's 90.6%) with\n1-second decision window for the widely used KULeuven (KUL) dataset, and the\ncode to implement our work is available on Github:\n\nhttps://github.com/xuxiran/ASAD_DenseNet",
          "link": "http://arxiv.org/abs/2309.07690",
          "publishedOn": "2023-09-16T00:40:57.000Z",
          "wordCount": null,
          "title": "A DenseNet-based method for decoding auditory spatial attention with EEG. (arXiv:2309.07690v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "Adversarial robustness, which primarily comprises sensitivity-based\nrobustness and spatial robustness, plays an integral part in achieving robust\ngeneralization. In this paper, we endeavor to design strategies to achieve\nuniversal adversarial robustness. To achieve this, we first investigate the\nrelatively less-explored realm of spatial robustness. Then, we integrate the\nexisting spatial robustness methods by incorporating both local and global\nspatial vulnerability into a unified spatial attack and adversarial training\napproach. Furthermore, we present a comprehensive relationship between natural\naccuracy, sensitivity-based robustness, and spatial robustness, supported by\nstrong evidence from the perspective of robust representation. Crucially, to\nreconcile the interplay between the mutual impacts of various robustness\ncomponents into one unified framework, we incorporate the \\textit{Pareto\ncriterion} into the adversarial robustness analysis, yielding a novel strategy\ncalled Pareto Adversarial Training for achieving universal robustness. The\nresulting Pareto front, which delineates the set of optimal solutions, provides\nan optimal balance between natural accuracy and various adversarial robustness.\nThis sheds light on solutions for achieving universal robustness in the future.\nTo the best of our knowledge, we are the first to consider universal\nadversarial robustness via multi-objective optimization.",
          "link": "http://arxiv.org/abs/2111.01996",
          "publishedOn": "2023-09-16T00:40:56.999Z",
          "wordCount": null,
          "title": "Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness. (arXiv:2111.01996v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zadem_M/0/1/0/all/0/1\">Mehdi Zadem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mover_S/0/1/0/all/0/1\">Sergio Mover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Sao Mai Nguyen</a>",
          "description": "Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this paper, we propose a\ndevelopmental mechanism for goal discovery via an emergent representation that\nabstracts (i.e., groups together) sets of environment states that have similar\nroles in the task. We introduce a Feudal HRL algorithm that concurrently learns\nboth the goal representation and a hierarchical policy. The algorithm uses\nsymbolic reachability analysis for neural networks to approximate the\ntransition relation among sets of states and to refine the goal representation.\nWe evaluate our approach on complex navigation tasks, showing the learned\nrepresentation is interpretable, transferrable and results in data efficient\nlearning.",
          "link": "http://arxiv.org/abs/2309.07675",
          "publishedOn": "2023-09-16T00:40:56.985Z",
          "wordCount": null,
          "title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis. (arXiv:2309.07675v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jiaren Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Quanyu Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xiaochen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jing Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_J/0/1/0/all/0/1\">James Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_K/0/1/0/all/0/1\">Ka-Wai Kwok</a>",
          "description": "Label scarcity in a graph is frequently encountered in real-world\napplications due to the high cost of data labeling. To this end,\nsemi-supervised domain adaptation (SSDA) on graphs aims to leverage the\nknowledge of a labeled source graph to aid in node classification on a target\ngraph with limited labels. SSDA tasks need to overcome the domain gap between\nthe source and target graphs. However, to date, this challenging research\nproblem has yet to be formally considered by the existing approaches designed\nfor cross-graph node classification. To tackle the SSDA problem on graphs, a\nnovel method called SemiGCL is proposed, which benefits from graph contrastive\nlearning and minimax entropy training. SemiGCL generates informative node\nrepresentations by contrasting the representations learned from a graph's local\nand global views. Additionally, SemiGCL is adversarially optimized with the\nentropy loss of unlabeled target nodes to reduce domain divergence.\nExperimental results on benchmark datasets demonstrate that SemiGCL outperforms\nthe state-of-the-art baselines on the SSDA tasks.",
          "link": "http://arxiv.org/abs/2309.07402",
          "publishedOn": "2023-09-16T00:40:56.981Z",
          "wordCount": null,
          "title": "Semi-supervised Domain Adaptation on Graphs with Contrastive Learning and Minimax Entropy. (arXiv:2309.07402v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>",
          "description": "We introduce beta diffusion, a novel generative modeling method that\nintegrates demasking and denoising to generate data within bounded ranges.\nUsing scaled and shifted beta distributions, beta diffusion utilizes\nmultiplicative transitions over time to create both forward and reverse\ndiffusion processes, maintaining beta distributions in both the forward\nmarginals and the reverse conditionals, given the data at any point in time.\nUnlike traditional diffusion-based generative models relying on additive\nGaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is\nmultiplicative and optimized with KL-divergence upper bounds (KLUBs) derived\nfrom the convexity of the KL divergence. We demonstrate that the proposed KLUBs\nare more effective for optimizing beta diffusion compared to negative ELBOs,\nwhich can also be derived as the KLUBs of the same KL divergence with its two\narguments swapped. The loss function of beta diffusion, expressed in terms of\nBregman divergence, further supports the efficacy of KLUBs for optimization.\nExperimental results on both synthetic data and natural images demonstrate the\nunique capabilities of beta diffusion in generative modeling of range-bounded\ndata and validate the effectiveness of KLUBs in optimizing diffusion models,\nthereby making them valuable additions to the family of diffusion-based\ngenerative models and the optimization techniques used to train them.",
          "link": "http://arxiv.org/abs/2309.07867",
          "publishedOn": "2023-09-16T00:40:56.981Z",
          "wordCount": null,
          "title": "Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.03778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuijk_K/0/1/0/all/0/1\">Kristian van Kuijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dirksen_M/0/1/0/all/0/1\">Mark Dirksen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seiler_C/0/1/0/all/0/1\">Christof Seiler</a>",
          "description": "UCI WorldTour races, the premier men's elite road cycling tour, are grueling\nevents that put physical fitness and endurance of riders to the test. The\ncoaches of Team Jumbo-Visma have long been responsible for predicting the\nenergy needs of each rider of the Dutch team for every race on the calendar.\nThose must be estimated to ensure riders have the energy and resources\nnecessary to maintain a high level of performance throughout a race. This task,\nhowever, is both time-consuming and challenging, as it requires precise\nestimates of race speed and power output. Traditionally, the approach to\npredicting energy needs has relied on judgement and experience of coaches, but\nthis method has its limitations and often leads to inaccurate predictions. In\nthis paper, we propose a new, more effective approach to predicting energy\nneeds for cycling races. By predicting the speed and power with regression\nmodels, we provide the coaches with calorie needs estimates for each individual\nrider per stage instantly. In addition, we compare methods to quantify\nuncertainty using conformal prediction. The empirical analysis of the\njackknife+, jackknife-minmax, jackknife-minmax-after-bootstrap, CV+, CV-minmax,\nconformalized quantile regression, and inductive conformal prediction methods\nin conformal prediction reveals that all methods achieve valid prediction\nintervals. All but minmax-based methods also produce sufficiently narrow\nprediction intervals for decision-making. Furthermore, methods computing\nprediction intervals of fixed size produce tighter intervals for low\nsignificance values. Among the methods computing intervals of varying length\nacross the input space, inductive conformal prediction computes narrower\nprediction intervals at larger significance level.",
          "link": "http://arxiv.org/abs/2304.03778",
          "publishedOn": "2023-09-16T00:40:56.981Z",
          "wordCount": null,
          "title": "Conformal Regression in Calorie Prediction for Team Jumbo-Visma. (arXiv:2304.03778v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "In this paper, we consider the intersection of two problems in machine\nlearning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD).\nOn the one hand, the first considers adapting multiple heterogeneous labeled\nsource domains to an unlabeled target domain. On the other hand, the second\nattacks the problem of synthesizing a small summary containing all the\ninformation about the datasets. We thus consider a new problem called MSDA-DD.\nTo solve it, we adapt previous works in the MSDA literature, such as\nWasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD\nmethod Distribution Matching. We thoroughly experiment with this novel problem\non four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous\nStirred Tank Reactor, and Case Western Reserve University), where we show that,\neven with as little as 1 sample per class, one achieves state-of-the-art\nadaptation performance.",
          "link": "http://arxiv.org/abs/2309.07666",
          "publishedOn": "2023-09-16T00:40:56.976Z",
          "wordCount": null,
          "title": "Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning. (arXiv:2309.07666v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagai_J/0/1/0/all/0/1\">James S. Nagai</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Costa_I/0/1/0/all/0/1\">Ivan G. Costa</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1\">Michael T. Schaub</a> (2) ((1) Institute for Computational Genomics, RWTH Aachen Medical Faculty, Germany, (2) Department of Computer Science, RWTH Aachen University, Germany)",
          "description": "Comparing graphs by means of optimal transport has recently gained\nsignificant attention, as the distances induced by optimal transport provide\nboth a principled metric between graphs as well as an interpretable description\nof the associated changes between graphs in terms of a transport plan. As the\nlack of symmetry introduces challenges in the typically considered\nformulations, optimal transport distances for graphs have mostly been developed\nfor undirected graphs. Here, we propose two distance measures to compare\ndirected graphs based on variants of optimal transport: (i) an earth movers\ndistance (Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance. We evaluate\nthese two distances and discuss their relative performance for both simulated\ngraph data and real-world directed cell-cell communication graphs, inferred\nfrom single-cell RNA-seq data.",
          "link": "http://arxiv.org/abs/2309.07030",
          "publishedOn": "2023-09-16T00:40:56.976Z",
          "wordCount": null,
          "title": "Optimal transport distances for directed, weighted graphs: a case study with cell-cell communication networks. (arXiv:2309.07030v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04100",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dong_S/0/1/0/all/0/1\">Siyuan Dong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feyter_H/0/1/0/all/0/1\">Henk M. De Feyter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thomas_M/0/1/0/all/0/1\">Monique A. Thomas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Graaf_R/0/1/0/all/0/1\">Robin A. de Graaf</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duncan_J/0/1/0/all/0/1\">James S. Duncan</a>",
          "description": "Purpose: Common to most MRSI techniques, the spatial resolution and the\nminimal scan duration of Deuterium Metabolic Imaging (DMI) are limited by the\nachievable SNR. This work presents a deep learning method for sensitivity\nenhancement of DMI.\n\nMethods: A convolutional neural network (CNN) was designed to estimate the\n2H-labeled metabolite concentrations from low SNR and distorted DMI FIDs. The\nCNN was trained with synthetic data that represent a range of SNR levels\ntypically encountered in vivo. The estimation precision was further improved by\nfine-tuning the CNN with MRI-based edge-preserving regularization for each DMI\ndataset. The proposed processing method, PReserved Edge ConvolutIonal neural\nnetwork for Sensitivity Enhanced DMI (PRECISE-DMI), was applied to simulation\nstudies and in vivo experiments to evaluate the anticipated improvements in SNR\nand investigate the potential for inaccuracies.\n\nResults: PRECISE-DMI visually improved the metabolic maps of low SNR\ndatasets, and quantitatively provided higher precision than the standard\nFourier reconstruction. Processing of DMI data acquired in rat brain tumor\nmodels resulted in more precise determination of 2H-labeled lactate and\nglutamate + glutamine levels, at increased spatial resolution (from >8 to 2\n$\\mu$L) or shortened scan time (from 32 to 4 min) compared to standard\nacquisitions. However, rigorous SD-bias analyses showed that overuse of the\nedge-preserving regularization can compromise the accuracy of the results.\n\nConclusion: PRECISE-DMI allows a flexible trade-off between enhancing the\nsensitivity of DMI and minimizing the inaccuracies. With typical settings, the\nDMI sensitivity can be improved by 3-fold while retaining the capability to\ndetect local signal variations.",
          "link": "http://arxiv.org/abs/2309.04100",
          "publishedOn": "2023-09-16T00:40:56.973Z",
          "wordCount": null,
          "title": "Preserved Edge Convolutional Neural Network for Sensitivity Enhancement of Deuterium Metabolic Imaging (DMI). (arXiv:2309.04100v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aghamolaei_S/0/1/0/all/0/1\">Sepideh Aghamolaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_M/0/1/0/all/0/1\">Mohammad Ghodsi</a>",
          "description": "Given a set of points labeled with $k$ labels, we introduce the heat map\nsorting problem as reordering and merging the points and dimensions while\npreserving the clusters (labels). A cluster is preserved if it remains\nconnected, i.e., if it is not split into several clusters and no two clusters\nare merged.\n\nWe prove the problem is NP-hard and we give a fixed-parameter algorithm with\na constant number of rounds in the massively parallel computation model, where\neach machine has a sublinear memory and the total memory of the machines is\nlinear. We give an approximation algorithm for a NP-hard special case of the\nproblem. We empirically compare our algorithm with k-means and density-based\nclustering (DBSCAN) using a dimensionality reduction via locality-sensitive\nhashing on several directed and undirected graphs of email and computer\nnetworks.",
          "link": "http://arxiv.org/abs/2309.07486",
          "publishedOn": "2023-09-16T00:40:56.972Z",
          "wordCount": null,
          "title": "Massively-Parallel Heat Map Sorting and Applications To Explainable Clustering. (arXiv:2309.07486v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.02048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Muyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Ji Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>",
          "description": "During image editing, existing deep generative models tend to re-synthesize\nthe entire output from scratch, including the unedited regions. This leads to a\nsignificant waste of computation, especially for minor editing operations. In\nthis work, we present Spatially Sparse Inference (SSI), a general-purpose\ntechnique that selectively performs computation for edited regions and\naccelerates various generative models, including both conditional GANs and\ndiffusion models. Our key observation is that users prone to gradually edit the\ninput image. This motivates us to cache and reuse the feature maps of the\noriginal image. Given an edited image, we sparsely apply the convolutional\nfilters to the edited regions while reusing the cached features for the\nunedited areas. Based on our algorithm, we further propose Sparse Incremental\nGenerative Engine (SIGE) to convert the computation reduction to latency\nreduction on off-the-shelf hardware. With about $1\\%$-area edits, SIGE\naccelerates DDPM by $3.0\\times$ on NVIDIA RTX 3090 and $4.6\\times$ on Apple M1\nPro GPU, Stable Diffusion by $7.2\\times$ on 3090, and GauGAN by $5.6\\times$ on\n3090 and $5.2\\times$ on M1 Pro GPU. Compared to our conference version, we\nextend SIGE to accommodate attention layers and apply it to Stable Diffusion.\nAdditionally, we offer support for Apple M1 Pro GPU and include more results\nwith large and sequential edits.",
          "link": "http://arxiv.org/abs/2211.02048",
          "publishedOn": "2023-09-16T00:40:56.941Z",
          "wordCount": null,
          "title": "Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models. (arXiv:2211.02048v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pepino_L/0/1/0/all/0/1\">Leonardo Pepino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riera_P/0/1/0/all/0/1\">Pablo Riera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_L/0/1/0/all/0/1\">Luciana Ferrer</a>",
          "description": "The goal of universal audio representation learning is to obtain foundational\nmodels that can be used for a variety of downstream tasks involving speech,\nmusic or environmental sounds. To approach this problem, methods inspired by\nself-supervised models from NLP, like BERT, are often used and adapted to\naudio. These models rely on the discrete nature of text, hence adopting this\ntype of approach for audio processing requires either a change in the learning\nobjective or mapping the audio signal to a set of discrete classes. In this\nwork, we explore the use of EnCodec, a neural audio codec, to generate discrete\ntargets for learning an universal audio model based on a masked autoencoder\n(MAE). We evaluate this approach, which we call EncodecMAE, on a wide range of\naudio tasks spanning speech, music and environmental sounds, achieving\nperformances comparable or better than leading audio representation models.",
          "link": "http://arxiv.org/abs/2309.07391",
          "publishedOn": "2023-09-16T00:40:56.940Z",
          "wordCount": null,
          "title": "EnCodecMAE: Leveraging neural codecs for universal audio representation learning. (arXiv:2309.07391v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Benign overfitting, the phenomenon where interpolating models generalize well\nin the presence of noisy data, was first observed in neural network models\ntrained with gradient descent. To better understand this empirical observation,\nwe consider the generalization error of two-layer neural networks trained to\ninterpolation by gradient descent on the logistic loss following random\ninitialization. We assume the data comes from well-separated class-conditional\nlog-concave distributions and allow for a constant fraction of the training\nlabels to be corrupted by an adversary. We show that in this setting, neural\nnetworks exhibit benign overfitting: they can be driven to zero training error,\nperfectly fitting any noisy training labels, and simultaneously achieve minimax\noptimal test error. In contrast to previous work on benign overfitting that\nrequire linear or kernel-based predictors, our analysis holds in a setting\nwhere both the model and learning dynamics are fundamentally nonlinear.",
          "link": "http://arxiv.org/abs/2202.05928",
          "publishedOn": "2023-09-16T00:40:56.940Z",
          "wordCount": null,
          "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. (arXiv:2202.05928v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_J/0/1/0/all/0/1\">Jin-Hong Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1\">Larry Wasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roeder_K/0/1/0/all/0/1\">Kathryn Roeder</a>",
          "description": "Tens of thousands of simultaneous hypothesis tests are routinely performed in\ngenomic studies to identify differentially expressed genes. However, due to\nunmeasured confounders, many standard statistical approaches may be\nsubstantially biased. This paper investigates the large-scale hypothesis\ntesting problem for multivariate generalized linear models in the presence of\nconfounding effects. Under arbitrary confounding mechanisms, we propose a\nunified statistical estimation and inference framework that harnesses\northogonal structures and integrates linear projections into three key stages.\nIt first leverages multivariate responses to separate marginal and uncorrelated\nconfounding effects, recovering the confounding coefficients' column space.\nSubsequently, latent factors and primary effects are jointly estimated,\nutilizing $\\ell_1$-regularization for sparsity while imposing orthogonality\nonto confounding coefficients. Finally, we incorporate projected and weighted\nbias-correction steps for hypothesis testing. Theoretically, we establish\nvarious effects' identification conditions and non-asymptotic error bounds. We\nshow effective Type-I error control of asymptotic $z$-tests as sample and\nresponse sizes approach infinity. Numerical experiments demonstrate that the\nproposed method controls the false discovery rate by the Benjamini-Hochberg\nprocedure and is more powerful than alternative methods. By comparing\nsingle-cell RNA-seq counts from two groups of samples, we demonstrate the\nsuitability of adjusting confounding effects when significant covariates are\nabsent from the model.",
          "link": "http://arxiv.org/abs/2309.07261",
          "publishedOn": "2023-09-16T00:40:56.939Z",
          "wordCount": null,
          "title": "Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07147",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fan_C/0/1/0/all/0/1\">Cunhang Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jun Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_J/0/1/0/all/0/1\">Jiangyan Yi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_Z/0/1/0/all/0/1\">Zhao Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xiaopei Wu</a>",
          "description": "Auditory Attention Detection (AAD) aims to detect target speaker from brain\nsignals in a multi-speaker environment. Although EEG-based AAD methods have\nshown promising results in recent years, current approaches primarily rely on\ntraditional convolutional neural network designed for processing Euclidean data\nlike images. This makes it challenging to handle EEG signals, which possess\nnon-Euclidean characteristics. In order to address this problem, this paper\nproposes a dynamical graph self-distillation (DGSD) approach for AAD, which\ndoes not require speech stimuli as input. Specifically, to effectively\nrepresent the non-Euclidean properties of EEG signals, dynamical graph\nconvolutional networks are applied to represent the graph structure of EEG\nsignals, which can also extract crucial features related to auditory spatial\nattention in EEG signals. In addition, to further improve AAD detection\nperformance, self-distillation, consisting of feature distillation and\nhierarchical distillation strategies at each layer, is integrated. These\nstrategies leverage features and classification results from the deepest\nnetwork layers to guide the learning of shallow layers. Our experiments are\nconducted on two publicly available datasets, KUL and DTU. Under a 1-second\ntime window, we achieve results of 90.0\\% and 79.6\\% accuracy on KUL and DTU,\nrespectively. We compare our DGSD method with competitive baselines, and the\nexperimental results indicate that the detection performance of our proposed\nDGSD method is not only superior to the best reproducible baseline but also\nsignificantly reduces the number of trainable parameters by approximately 100\ntimes.",
          "link": "http://arxiv.org/abs/2309.07147",
          "publishedOn": "2023-09-16T00:40:56.938Z",
          "wordCount": null,
          "title": "DGSD: Dynamical Graph Self-Distillation for EEG-Based Auditory Spatial Attention Detection. (arXiv:2309.07147v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07163",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+KN_V/0/1/0/all/0/1\">Vishnu KN</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gupta_C/0/1/0/all/0/1\">Cota Navin Gupta</a>",
          "description": "This article summarizes a systematic review of the electroencephalography\n(EEG)-based cognitive workload (CWL) estimation. The focus of the article is\ntwofold: identify the disparate experimental paradigms used for reliably\neliciting discreet and quantifiable levels of cognitive load and the specific\nnature and representational structure of the commonly used input formulations\nin deep neural networks (DNNs) used for signal classification. The analysis\nrevealed a number of studies using EEG signals in its native representation of\na two-dimensional matrix for offline classification of CWL. However, only a few\nstudies adopted an online or pseudo-online classification strategy for\nreal-time CWL estimation. Further, only a couple of interpretable DNNs and a\nsingle generative model were employed for cognitive load detection till date\nduring this review. More often than not, researchers were using DNNs as\nblack-box type models. In conclusion, DNNs prove to be valuable tools for\nclassifying EEG signals, primarily due to the substantial modeling power\nprovided by the depth of their network architecture. It is further suggested\nthat interpretable and explainable DNN models must be employed for cognitive\nworkload estimation since existing methods are limited in the face of the\nnon-stationary nature of the signal.",
          "link": "http://arxiv.org/abs/2309.07163",
          "publishedOn": "2023-09-16T00:40:56.937Z",
          "wordCount": null,
          "title": "Systematic Review of Experimental Paradigms and Deep Neural Networks for Electroencephalography-Based Cognitive Workload Detection. (arXiv:2309.07163v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mince_F/0/1/0/all/0/1\">Fraser Mince</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_D/0/1/0/all/0/1\">Dzung Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kgomo_J/0/1/0/all/0/1\">Jonas Kgomo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_N/0/1/0/all/0/1\">Neil Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1\">Sara Hooker</a>",
          "description": "Pushing the boundaries of machine learning often requires exploring different\nhardware and software combinations. However, the freedom to experiment across\ndifferent tooling stacks can be at odds with the drive for efficiency, which\nhas produced increasingly specialized AI hardware and incentivized\nconsolidation around a narrow set of ML frameworks. Exploratory research can be\nrestricted if software and hardware are co-evolving, making it even harder to\nstray away from mainstream ideas that work well with popular tooling stacks.\nWhile this friction increasingly impacts the rate of innovation in machine\nlearning, to our knowledge the lack of portability in tooling has not been\nquantified. In this work, we ask: How portable are popular ML software\nframeworks? We conduct a large-scale study of the portability of mainstream ML\nframeworks across different hardware types. Our findings paint an uncomfortable\npicture -- frameworks can lose more than 40% of their key functions when ported\nto other hardware. Worse, even when functions are portable, the slowdown in\ntheir performance can be extreme and render performance untenable.\nCollectively, our results reveal how costly straying from a narrow set of\nhardware-software combinations can be - and suggest that specialization of\nhardware impedes innovation in machine learning research.",
          "link": "http://arxiv.org/abs/2309.07181",
          "publishedOn": "2023-09-16T00:40:56.937Z",
          "wordCount": null,
          "title": "The Grand Illusion: The Myth of Software Portability and Implications for ML Progress. (arXiv:2309.07181v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07192",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Turrisi_R/0/1/0/all/0/1\">Rosanna Turrisi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Verri_A/0/1/0/all/0/1\">Alessandro Verri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barla_A/0/1/0/all/0/1\">Annalisa Barla</a>",
          "description": "Machine Learning (ML) has emerged as a promising approach in healthcare,\noutperforming traditional statistical techniques. However, to establish ML as a\nreliable tool in clinical practice, adherence to best practices regarding data\nhandling, experimental design, and model evaluation is crucial. This work\nsummarizes and strictly observes such practices to ensure reproducible and\nreliable ML. Specifically, we focus on Alzheimer's Disease (AD) detection,\nwhich serves as a paradigmatic example of challenging problem in healthcare. We\ninvestigate the impact of different data augmentation techniques and model\ncomplexity on the overall performance. We consider MRI data from ADNI dataset\nto address a classification problem employing 3D Convolutional Neural Network\n(CNN). The experiments are designed to compensate for data scarcity and initial\nrandom parameters by utilizing cross-validation and multiple training trials.\nWithin this framework, we train 15 predictive models, considering three\ndifferent data augmentation strategies and five distinct 3D CNN architectures,\neach varying in the number of convolutional layers. Specifically, the\naugmentation strategies are based on affine transformations, such as zoom,\nshift, and rotation, applied concurrently or separately. The combined effect of\ndata augmentation and model complexity leads to a variation in prediction\nperformance up to 10% of accuracy. When affine transformation are applied\nseparately, the model is more accurate, independently from the adopted\narchitecture. For all strategies, the model accuracy followed a concave\nbehavior at increasing number of convolutional layers, peaking at an\nintermediate value of layers. The best model (8 CL, (B)) is the most stable\nacross cross-validation folds and training trials, reaching excellent\nperformance both on the testing set and on an external test set.",
          "link": "http://arxiv.org/abs/2309.07192",
          "publishedOn": "2023-09-16T00:40:56.937Z",
          "wordCount": null,
          "title": "The effect of data augmentation and 3D-CNN depth on Alzheimer's Disease detection. (arXiv:2309.07192v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baggenstoss_P/0/1/0/all/0/1\">Paul M Baggenstoss</a>",
          "description": "In this paper, we exploit the unique properties of a deterministic projected\nbelief network (D-PBN) to take full advantage of trainable compound activation\nfunctions (TCAs). A D-PBN is a type of auto-encoder that operates by \"backing\nup\" through a feed-forward neural network. TCAs are activation functions with\ncomplex monotonic-increasing shapes that change the distribution of the data so\nthat the linear transformation that follows is more effective. Because a D-PBN\noperates by \"backing up\", the TCAs are inverted in the reconstruction process,\nrestoring the original distribution of the data, thus taking advantage of a\ngiven TCA in both analysis and reconstruction. In this paper, we show that a\nD-PBN auto-encoder with TCAs can significantly out-perform standard\nauto-encoders including variational auto-encoders.",
          "link": "http://arxiv.org/abs/2309.07481",
          "publishedOn": "2023-09-16T00:40:56.931Z",
          "wordCount": null,
          "title": "Improved Auto-Encoding using Deterministic Projected Belief Networks. (arXiv:2309.07481v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chamma_A/0/1/0/all/0/1\">Ahmad Chamma</a> (1 and 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Engemann_D/0/1/0/all/0/1\">Denis A. Engemann</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Thirion_B/0/1/0/all/0/1\">Bertrand Thirion</a> (1 and 2 and 3) ((1) Inria, (2) Universite Paris Saclay, (3) CEA, (4) Roche Pharma Research and Early Development, Neuroscience and Rare Diseases, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd., Basel, Switzerland)",
          "description": "Variable importance assessment has become a crucial step in machine-learning\napplications when using complex learners, such as deep neural networks, on\nlarge-scale data. Removal-based importance assessment is currently the\nreference approach, particularly when statistical guarantees are sought to\njustify variable inclusion. It is often implemented with variable permutation\nschemes. On the flip side, these approaches risk misidentifying unimportant\nvariables as important in the presence of correlations among covariates. Here\nwe develop a systematic approach for studying Conditional Permutation\nImportance (CPI) that is model agnostic and computationally lean, as well as\nreusable benchmarks of state-of-the-art variable importance estimators. We show\ntheoretically and empirically that $\\textit{CPI}$ overcomes the limitations of\nstandard permutation importance by providing accurate type-I error control.\nWhen used with a deep neural network, $\\textit{CPI}$ consistently showed top\naccuracy across benchmarks. An empirical benchmark on real-world data analysis\nin a large-scale medical dataset showed that $\\textit{CPI}$ provides a more\nparsimonious selection of statistically significant variables. Our results\nsuggest that $\\textit{CPI}$ can be readily used as drop-in replacement for\npermutation-based methods.",
          "link": "http://arxiv.org/abs/2309.07593",
          "publishedOn": "2023-09-16T00:40:56.931Z",
          "wordCount": null,
          "title": "Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07778",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bozkurt_A/0/1/0/all/0/1\">Alican Bozkurt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Casson_A/0/1/0/all/0/1\">Adam Casson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shaikovski_G/0/1/0/all/0/1\">George Shaikovski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelechowski_M/0/1/0/all/0/1\">Michal Zelechowski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mathieu_P/0/1/0/all/0/1\">Philippe Mathieu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eck_A/0/1/0/all/0/1\">Alexander van Eck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1\">Donghun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Viret_J/0/1/0/all/0/1\">Julian Viret</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Robert_E/0/1/0/all/0/1\">Eric Robert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Kan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kun_J/0/1/0/all/0/1\">Jeremy D. Kun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Le_M/0/1/0/all/0/1\">Matthew C. H. Le</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bernhard_J/0/1/0/all/0/1\">Jan Bernhard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Godrich_R/0/1/0/all/0/1\">Ran A. Godrich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oakley_G/0/1/0/all/0/1\">Gerard Oakley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Millar_E/0/1/0/all/0/1\">Ewan Millar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hanna_M/0/1/0/all/0/1\">Matthew Hanna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Retamero_J/0/1/0/all/0/1\">Juan Retamero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moye_W/0/1/0/all/0/1\">William A. Moye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yousfi_R/0/1/0/all/0/1\">Razik Yousfi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanan_C/0/1/0/all/0/1\">Christopher Kanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klimstra_D/0/1/0/all/0/1\">David Klimstra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rothrock_B/0/1/0/all/0/1\">Brandon Rothrock</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuchs_T/0/1/0/all/0/1\">Thomas J. Fuchs</a>",
          "description": "Computational pathology uses artificial intelligence to enable precision\nmedicine and decision support systems through the analysis of whole slide\nimages. It has the potential to revolutionize the diagnosis and treatment of\ncancer. However, a major challenge to this objective is that for many specific\ncomputational pathology tasks the amount of data is inadequate for development.\nTo address this challenge, we created Virchow, a 632 million parameter deep\nneural network foundation model for computational pathology. Using\nself-supervised learning, Virchow is trained on 1.5 million hematoxylin and\neosin stained whole slide images from diverse tissue groups, which is orders of\nmagnitude more data than previous works. When evaluated on downstream tasks\nincluding tile-level pan-cancer detection and subtyping and slide-level\nbiomarker prediction, Virchow outperforms state-of-the-art systems both on\ninternal datasets drawn from the same population as the pretraining data as\nwell as external public datasets. Virchow achieves 93% balanced accuracy for\npancancer tile classification, and AUCs of 0.983 for colon microsatellite\ninstability status prediction and 0.967 for breast CDH1 status prediction. The\ngains in performance highlight the importance of pretraining on massive\npathology image datasets, suggesting pretraining on even larger datasets could\ncontinue improving performance for many high-impact applications where limited\namounts of training data are available, such as drug outcome prediction.",
          "link": "http://arxiv.org/abs/2309.07778",
          "publishedOn": "2023-09-16T00:40:56.931Z",
          "wordCount": null,
          "title": "Virchow: A Million-Slide Digital Pathology Foundation Model. (arXiv:2309.07778v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Minh_A/0/1/0/all/0/1\">Anh Pham Thi Minh</a>",
          "description": "Large pre-trained vision-language models such as CLIP have demonstrated great\npotential in zero-shot transferability to downstream tasks. However, to attain\noptimal performance, the manual selection of prompts is necessary to improve\nalignment between the downstream image distribution and the textual class\ndescriptions. This manual prompt engineering is the major challenge for\ndeploying such models in practice since it requires domain expertise and is\nextremely time-consuming. To avoid non-trivial prompt engineering, recent work\nContext Optimization (CoOp) introduced the concept of prompt learning to the\nvision domain using learnable textual tokens. While CoOp can achieve\nsubstantial improvements over manual prompts, its learned context is worse\ngeneralizable to wider unseen classes within the same dataset. In this work, we\npresent Prompt Learning with Reparameterization Encoder (PRE) - a simple and\nefficient method that enhances the generalization ability of the learnable\nprompt to unseen classes while maintaining the capacity to learn Base classes.\nInstead of directly optimizing the prompts, PRE employs a prompt encoder to\nreparameterize the input prompt embeddings, enhancing the exploration of\ntask-specific knowledge from few-shot samples. Experiments and extensive\nablation studies on 8 benchmarks demonstrate that our approach is an efficient\nmethod for prompt learning. Specifically, PRE achieves a notable enhancement of\n5.60% in average accuracy on New classes and 3% in Harmonic mean compared to\nCoOp in the 16-shot setting, all achieved within a good training time.",
          "link": "http://arxiv.org/abs/2309.07760",
          "publishedOn": "2023-09-16T00:40:56.930Z",
          "wordCount": null,
          "title": "PRE: Vision-Language Prompt Learning with Reparameterization Encoder. (arXiv:2309.07760v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1\">Ting-Han Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1\">Ta-Chung Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander I. Rudnicky</a>",
          "description": "In recent studies, linear recurrent neural networks (LRNNs) have achieved\nTransformer-level performance in natural language modeling and long-range\nmodeling while offering rapid parallel training and constant inference costs.\nWith the resurged interest in LRNNs, we study whether they can learn the hidden\nrules in training sequences, such as the grammatical structures of regular\nlanguage. We theoretically analyze some existing LRNNs and discover their\nlimitations on regular language. Motivated by the analysis, we propose a new\nLRNN equipped with a block-diagonal and input-dependent transition matrix.\nExperiments suggest that the proposed model is the only LRNN that can perform\nlength extrapolation on regular language tasks such as Sum, Even Pair, and\nModular Arithmetic.",
          "link": "http://arxiv.org/abs/2309.07412",
          "publishedOn": "2023-09-16T00:40:56.924Z",
          "wordCount": null,
          "title": "Advancing Regular Language Reasoning in Linear Recurrent Neural Networks. (arXiv:2309.07412v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atienza_A/0/1/0/all/0/1\">Adrian Atienza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bardram_J/0/1/0/all/0/1\">Jakob Bardram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puthusserypady_S/0/1/0/all/0/1\">Sadasivan Puthusserypady</a>",
          "description": "By identifying similarities between successive inputs, Self-Supervised\nLearning (SSL) methods for time series analysis have demonstrated their\neffectiveness in encoding the inherent static characteristics of temporal data.\nHowever, an exclusive emphasis on similarities might result in representations\nthat overlook the dynamic attributes critical for modeling cardiovascular\ndiseases within a confined subject cohort. Introducing Distilled Encoding\nBeyond Similarities (DEBS), this paper pioneers an SSL approach that transcends\nmere similarities by integrating dissimilarities among positive pairs. The\nframework is applied to electrocardiogram (ECG) signals, leading to a notable\nenhancement of +10\\% in the detection accuracy of Atrial Fibrillation (AFib)\nacross diverse subjects. DEBS underscores the potential of attaining a more\nrefined representation by encoding the dynamic characteristics of time series\ndata, tapping into dissimilarities during the optimization process. Broadly,\nthe strategy delineated in this study holds the promise of unearthing novel\navenues for advancing SSL methodologies tailored to temporal data.",
          "link": "http://arxiv.org/abs/2309.07526",
          "publishedOn": "2023-09-16T00:40:56.924Z",
          "wordCount": null,
          "title": "Learning Beyond Similarities: Incorporating Dissimilarities between Positive Pairs in Self-Supervised Time Series Learning. (arXiv:2309.07526v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_H/0/1/0/all/0/1\">Harrison Rosenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Shimaa Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_G/0/1/0/all/0/1\">Guruprasad V Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinayak_R/0/1/0/all/0/1\">Ramya Korlakai Vinayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fawaz_K/0/1/0/all/0/1\">Kassem Fawaz</a>",
          "description": "Text-to-image diffusion models have achieved widespread popularity due to\ntheir unprecedented image generation capability. In particular, their ability\nto synthesize and modify human faces has spurred research into using generated\nface images in both training data augmentation and model performance\nassessments. In this paper, we study the efficacy and shortcomings of\ngenerative models in the context of face generation. Utilizing a combination of\nqualitative and quantitative measures, including embedding-based metrics and\nuser studies, we present a framework to audit the characteristics of generated\nfaces conditioned on a set of social attributes. We applied our framework on\nfaces generated through state-of-the-art text-to-image diffusion models. We\nidentify several limitations of face image generation that include faithfulness\nto the text prompt, demographic disparities, and distributional shifts.\nFurthermore, we present an analytical model that provides insights into how\ntraining data selection contributes to the performance of generative models.",
          "link": "http://arxiv.org/abs/2309.07277",
          "publishedOn": "2023-09-16T00:40:56.922Z",
          "wordCount": null,
          "title": "Unbiased Face Synthesis With Diffusion Models: Are We There Yet?. (arXiv:2309.07277v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07453",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Navarro_M/0/1/0/all/0/1\">Madeline Navarro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "The myriad complex systems with multiway interactions motivate the extension\nof graph-based pairwise connections to higher-order relations. In particular,\nthe simplicial complex has inspired generalizations of graph neural networks\n(GNNs) to simplicial complex-based models. Learning on such systems requires\nlarge amounts of data, which can be expensive or impossible to obtain. We\npropose data augmentation of simplicial complexes through both linear and\nnonlinear mixup mechanisms that return mixtures of existing labeled samples. In\naddition to traditional pairwise mixup, we present a convex clustering mixup\napproach for a data-driven relationship among several simplicial complexes. We\ntheoretically demonstrate that the resultant synthetic simplicial complexes\ninterpolate among existing data with respect to homomorphism densities. Our\nmethod is demonstrated on both synthetic and real-world datasets for simplicial\ncomplex classification.",
          "link": "http://arxiv.org/abs/2309.07453",
          "publishedOn": "2023-09-16T00:40:56.922Z",
          "wordCount": null,
          "title": "SC-MAD: Mixtures of Higher-order Networks for Data Augmentation. (arXiv:2309.07453v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07197",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Queyrut_S/0/1/0/all/0/1\">Simon Queyrut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiavoni_V/0/1/0/all/0/1\">Valerio Schiavoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felber_P/0/1/0/all/0/1\">Pascal Felber</a>",
          "description": "The main premise of federated learning (FL) is that machine learning model\nupdates are computed locally to preserve user data privacy. This approach\navoids by design user data to ever leave the perimeter of their device. Once\nthe updates aggregated, the model is broadcast to all nodes in the federation.\nHowever, without proper defenses, compromised nodes can probe the model inside\ntheir local memory in search for adversarial examples, which can lead to\ndangerous real-world scenarios. For instance, in image-based applications,\nadversarial examples consist of images slightly perturbed to the human eye\ngetting misclassified by the local model. These adversarial images are then\nlater presented to a victim node's counterpart model to replay the attack.\nTypical examples harness dissemination strategies such as altered traffic signs\n(patch attacks) no longer recognized by autonomous vehicles or seemingly\nunaltered samples that poison the local dataset of the FL scheme to undermine\nits robustness. Pelta is a novel shielding mechanism leveraging Trusted\nExecution Environments (TEEs) that reduce the ability of attackers to craft\nadversarial samples. Pelta masks inside the TEE the first part of the\nback-propagation chain rule, typically exploited by attackers to craft the\nmalicious samples. We evaluate Pelta on state-of-the-art accurate models using\nthree well-established datasets: CIFAR-10, CIFAR-100 and ImageNet. We show the\neffectiveness of Pelta in mitigating six white-box state-of-the-art adversarial\nattacks, such as Projected Gradient Descent, Momentum Iterative Method, Auto\nProjected Gradient Descent, the Carlini & Wagner attack. In particular, Pelta\nconstitutes the first attempt at defending an ensemble model against the\nSelf-Attention Gradient attack to the best of our knowledge. Our code is\navailable to the research community at https://github.com/queyrusi/Pelta.",
          "link": "http://arxiv.org/abs/2309.07197",
          "publishedOn": "2023-09-16T00:40:56.917Z",
          "wordCount": null,
          "title": "Mitigating Adversarial Attacks in Federated Learning with Trusted Execution Environments. (arXiv:2309.07197v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1\">Ian Horrocks</a>",
          "description": "This work investigates the applicability of recent generative Large Language\nModels (LLMs), such as the GPT series and Flan-T5, to ontology alignment for\nidentifying concept equivalence mappings across ontologies. To test the\nzero-shot performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging\nsubsets from two equivalence matching datasets of the OAEI Bio-ML track, taking\ninto account concept labels and structural contexts. Preliminary findings\nsuggest that LLMs have the potential to outperform existing ontology alignment\nsystems like BERTMap, given careful framework and prompt design.",
          "link": "http://arxiv.org/abs/2309.07172",
          "publishedOn": "2023-09-16T00:40:56.903Z",
          "wordCount": null,
          "title": "Exploring Large Language Models for Ontology Alignment. (arXiv:2309.07172v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07169",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_P/0/1/0/all/0/1\">Purui Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jian_X/0/1/0/all/0/1\">Xingchao Jian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_F/0/1/0/all/0/1\">Feng Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tay_W/0/1/0/all/0/1\">Wee Peng Tay</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wen_B/0/1/0/all/0/1\">Bihan Wen</a>",
          "description": "Topological signal processing (TSP) utilizes simplicial complexes to model\nstructures with higher order than vertices and edges. In this paper, we study\nthe transferability of TSP via a generalized higher-order version of graphon,\nknown as complexon. We recall the notion of a complexon as the limit of a\nsimplicial complex sequence [1]. Inspired by the integral operator form of\ngraphon shift operators, we construct a marginal complexon and complexon shift\noperator (CSO) according to components of all possible dimensions from the\ncomplexon. We investigate the CSO's eigenvalues and eigenvectors, and relate\nthem to a new family of weighted adjacency matrices. We prove that when a\nsimplicial complex sequence converges to a complexon, the eigenvalues of the\ncorresponding CSOs converge to that of the limit complexon. These results hint\nat learning transferability on large simplicial complexes or simplicial complex\nsequences, which generalize the graphon signal processing framework.",
          "link": "http://arxiv.org/abs/2309.07169",
          "publishedOn": "2023-09-16T00:40:56.890Z",
          "wordCount": null,
          "title": "Frequency Convergence of Complexon Shift Operators. (arXiv:2309.07169v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07183",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Casado_C/0/1/0/all/0/1\">Constantino &#xc1;lvarez Casado</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Canellas_M/0/1/0/all/0/1\">Manuel Lage Ca&#xf1;ellas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedone_M/0/1/0/all/0/1\">Matteo Pedone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoting Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopez_M/0/1/0/all/0/1\">Miguel Bordallo L&#xf3;pez</a>",
          "description": "In global healthcare, respiratory diseases are a leading cause of mortality,\nunderscoring the need for rapid and accurate diagnostics. To advance rapid\nscreening techniques via auscultation, our research focuses on employing one of\nthe largest publicly available medical database of respiratory sounds to train\nmultiple machine learning models able to classify different health conditions.\nOur method combines Empirical Mode Decomposition (EMD) and spectral analysis to\nextract physiologically relevant biosignals from acoustic data, closely tied to\ncardiovascular and respiratory patterns, making our approach apart in its\ndeparture from conventional audio feature extraction practices. We use Power\nSpectral Density analysis and filtering techniques to select Intrinsic Mode\nFunctions (IMFs) strongly correlated with underlying physiological phenomena.\nThese biosignals undergo a comprehensive feature extraction process for\npredictive modeling. Initially, we deploy a binary classification model that\ndemonstrates a balanced accuracy of 87% in distinguishing between healthy and\ndiseased individuals. Subsequently, we employ a six-class classification model\nthat achieves a balanced accuracy of 72% in diagnosing specific respiratory\nconditions like pneumonia and chronic obstructive pulmonary disease (COPD). For\nthe first time, we also introduce regression models that estimate age and body\nmass index (BMI) based solely on acoustic data, as well as a model for gender\nclassification. Our findings underscore the potential of this approach to\nsignificantly enhance assistive and remote diagnostic capabilities.",
          "link": "http://arxiv.org/abs/2309.07183",
          "publishedOn": "2023-09-16T00:40:56.889Z",
          "wordCount": null,
          "title": "Audio-Based Classification of Respiratory Diseases using Advanced Signal Processing and Machine Learning for Assistive Diagnosis Support. (arXiv:2309.07183v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zang_Z/0/1/0/all/0/1\">Zelin Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Panpan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan.Z Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "Unsupervised contrastive learning methods have recently seen significant\nimprovements, particularly through data augmentation strategies that aim to\nproduce robust and generalizable representations. However, prevailing data\naugmentation methods, whether hand designed or based on foundation models, tend\nto rely heavily on prior knowledge or external data. This dependence often\ncompromises their effectiveness and efficiency. Furthermore, the applicability\nof most existing data augmentation strategies is limited when transitioning to\nother research domains, especially science-related data. This limitation stems\nfrom the paucity of prior knowledge and labeled data available in these\ndomains. To address these challenges, we introduce DiffAug-a novel and\nefficient Diffusion-based data Augmentation technique. DiffAug aims to ensure\nthat the augmented and original data share a smoothed latent space, which is\nachieved through diffusion steps. Uniquely, unlike traditional methods, DiffAug\nfirst mines sufficient prior semantic knowledge about the neighborhood. This\nprovides a constraint to guide the diffusion steps, eliminating the need for\nlabels, external data/models, or prior knowledge. Designed as an\narchitecture-agnostic framework, DiffAug provides consistent improvements.\nSpecifically, it improves image classification and clustering accuracy by\n1.6%~4.5%. When applied to biological data, DiffAug improves performance by up\nto 10.1%, with an average improvement of 5.8%. DiffAug shows good performance\nin both vision and biological domains.",
          "link": "http://arxiv.org/abs/2309.07909",
          "publishedOn": "2023-09-16T00:40:56.888Z",
          "wordCount": null,
          "title": "Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data Augmentation From Scratch. (arXiv:2309.07909v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chenhan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yizheng Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Y/0/1/0/all/0/1\">Yang Weng</a>",
          "description": "Line outage identification in distribution grids is essential for sustainable\ngrid operation. In this work, we propose a practical yet robust detection\napproach that utilizes only readily available voltage magnitudes, eliminating\nthe need for costly phase angles or power flow data. Given the sensor data,\nmany existing detection methods based on change-point detection require prior\nknowledge of outage patterns, which are unknown for real-world outage\nscenarios. To remove this impractical requirement, we propose a data-driven\nmethod to learn the parameters of the post-outage distribution through gradient\ndescent. However, directly using gradient descent presents feasibility issues.\nTo address this, we modify our approach by adding a Bregman divergence\nconstraint to control the trajectory of the parameter updates, which eliminates\nthe feasibility problems. As timely operation is the key nowadays, we prove\nthat the optimal parameters can be learned with convergence guarantees via\nleveraging the statistical and physical properties of voltage data. We evaluate\nour approach using many representative distribution grids and real load\nprofiles with 17 outage configurations. The results show that we can detect and\nlocalize the outage in a timely manner with only voltage magnitudes and without\nassuming a prior knowledge of outage patterns.",
          "link": "http://arxiv.org/abs/2309.07157",
          "publishedOn": "2023-09-16T00:40:56.884Z",
          "wordCount": null,
          "title": "Distribution Grid Line Outage Identification with Unknown Pattern and Performance Guarantee. (arXiv:2309.07157v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrevaya_G/0/1/0/all/0/1\">Germ&#xe1;n Abrevaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezanian_Panahi_M/0/1/0/all/0/1\">Mahta Ramezanian-Panahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gagnon_Audet_J/0/1/0/all/0/1\">Jean-Christophe Gagnon-Audet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polosecki_P/0/1/0/all/0/1\">Pablo Polosecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawson_S/0/1/0/all/0/1\">Silvina Ponce Dawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1\">Guillermo Cecchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dumas_G/0/1/0/all/0/1\">Guillaume Dumas</a>",
          "description": "Scientific Machine Learning (SciML) is a burgeoning field that\nsynergistically combines domain-aware and interpretable models with agnostic\nmachine learning techniques. In this work, we introduce GOKU-UI, an evolution\nof the SciML generative model GOKU-nets. GOKU-UI not only broadens the original\nmodel's spectrum to incorporate other classes of differential equations, such\nas Stochastic Differential Equations (SDEs), but also integrates attention\nmechanisms and a novel multiple shooting training strategy in the latent space.\nThese modifications have led to a significant increase in its performance in\nboth reconstruction and forecast tasks, as demonstrated by our evaluation of\nsimulated and empirical data. Specifically, GOKU-UI outperformed all baseline\nmodels on synthetic datasets even with a training set 16-fold smaller,\nunderscoring its remarkable data efficiency. Furthermore, when applied to\nempirical human brain data, while incorporating stochastic Stuart-Landau\noscillators into its dynamical core, our proposed enhancements markedly\nincreased the model's effectiveness in capturing complex brain dynamics. This\naugmented version not only surpassed all baseline methods in the reconstruction\ntask, but also demonstrated lower prediction error of future brain activity up\nto 15 seconds ahead. By training GOKU-UI on resting state fMRI data, we encoded\nwhole-brain dynamics into a latent representation, learning a low-dimensional\ndynamical system model that could offer insights into brain functionality and\nopen avenues for practical applications such as the classification of mental\nstates or psychiatric conditions. Ultimately, our research provides further\nimpetus for the field of Scientific Machine Learning, showcasing the potential\nfor advancements when established scientific insights are interwoven with\nmodern machine learning.",
          "link": "http://arxiv.org/abs/2307.05735",
          "publishedOn": "2023-09-16T00:40:56.884Z",
          "wordCount": null,
          "title": "Effective Latent Differential Equation Models via Attention and Multiple Shooting. (arXiv:2307.05735v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07159",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ouahidi_Y/0/1/0/all/0/1\">Yassine El Ouahidi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gripon_V/0/1/0/all/0/1\">Vincent Gripon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pasdeloup_B/0/1/0/all/0/1\">Bastien Pasdeloup</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bouallegue_G/0/1/0/all/0/1\">Ghaith Bouallegue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Farrugia_N/0/1/0/all/0/1\">Nicolas Farrugia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lioi_G/0/1/0/all/0/1\">Giulia Lioi</a>",
          "description": "We propose EEG-SimpleConv, a straightforward 1D convolutional neural network\nfor Motor Imagery decoding in BCI. Our main motivation is to propose a very\nsimple baseline to compare to, using only very standard ingredients from the\nliterature. We evaluate its performance on four EEG Motor Imagery datasets,\nincluding simulated online setups, and compare it to recent Deep Learning and\nMachine Learning approaches. EEG-SimpleConv is at least as good or far more\nefficient than other approaches, showing strong knowledge-transfer capabilities\nacross subjects, at the cost of a low inference time. We advocate that using\noff-the-shelf ingredients rather than coming with ad-hoc solutions can\nsignificantly help the adoption of Deep Learning approaches for BCI. We make\nthe code of the models and the experiments accessible.",
          "link": "http://arxiv.org/abs/2309.07159",
          "publishedOn": "2023-09-16T00:40:56.883Z",
          "wordCount": null,
          "title": "A Strong and Simple Deep Learning Baseline for BCI MI Decoding. (arXiv:2309.07159v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16874",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoli Chen</a>",
          "description": "Many complex real world phenomena exhibit abrupt, intermittent or jumping\nbehaviors, which are more suitable to be described by stochastic differential\nequations under non-Gaussian L\\'evy noise. Among these complex phenomena, the\nmost likely transition paths between metastable states are important since\nthese rare events may have a high impact in certain scenarios. Based on the\nlarge deviation principle, the most likely transition path could be treated as\nthe minimizer of the rate function upon paths that connect two points. One of\nthe challenges to calculate the most likely transition path for stochastic\ndynamical systems under non-Gaussian L\\'evy noise is that the associated rate\nfunction can not be explicitly expressed by paths. For this reason, we\nformulate an optimal control problem to obtain the optimal state as the most\nlikely transition path. We then develop a neural network method to solve this\nissue. Several experiments are investigated for both Gaussian and non-Gaussian\ncases.",
          "link": "http://arxiv.org/abs/2203.16874",
          "publishedOn": "2023-09-16T00:40:56.883Z",
          "wordCount": null,
          "title": "An Optimal Control Method to Compute the Most Likely Transition Path for Stochastic Dynamical Systems with Jumps. (arXiv:2203.16874v2 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07149",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ferrante_M/0/1/0/all/0/1\">Matteo Ferrante</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boccato_T/0/1/0/all/0/1\">Tommaso Boccato</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bargione_S/0/1/0/all/0/1\">Stefano Bargione</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Toschi_N/0/1/0/all/0/1\">Nicola Toschi</a>",
          "description": "Decoding visual representations from human brain activity has emerged as a\nthriving research domain, particularly in the context of brain-computer\ninterfaces. Our study presents an innovative method that employs to classify\nand reconstruct images from the ImageNet dataset using electroencephalography\n(EEG) data from subjects that had viewed the images themselves (i.e. \"brain\ndecoding\"). We analyzed EEG recordings from 6 participants, each exposed to 50\nimages spanning 40 unique semantic categories. These EEG readings were\nconverted into spectrograms, which were then used to train a convolutional\nneural network (CNN), integrated with a knowledge distillation procedure based\non a pre-trained Contrastive Language-Image Pre-Training (CLIP)-based image\nclassification teacher network. This strategy allowed our model to attain a\ntop-5 accuracy of 80%, significantly outperforming a standard CNN and various\nRNN-based benchmarks. Additionally, we incorporated an image reconstruction\nmechanism based on pre-trained latent diffusion models, which allowed us to\ngenerate an estimate of the images which had elicited EEG activity. Therefore,\nour architecture not only decodes images from neural activity but also offers a\ncredible image reconstruction from EEG only, paving the way for e.g. swift,\nindividualized feedback experiments. Our research represents a significant step\nforward in connecting neural signals with visual cognition.",
          "link": "http://arxiv.org/abs/2309.07149",
          "publishedOn": "2023-09-16T00:40:56.882Z",
          "wordCount": null,
          "title": "Decoding visual brain representations from electroencephalography through Knowledge Distillation and latent diffusion models. (arXiv:2309.07149v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07550",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jayjun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiers_A/0/1/0/all/0/1\">Adam J. Spiers</a>",
          "description": "The integration of manipulator robots in household environments suggests a\nneed for more predictable and human-like robot motion. This holds especially\ntrue for wheelchair-mounted assistive robots that can support the independence\nof people with paralysis. One method of generating naturalistic motion\ntrajectories is via the imitation of human demonstrators. This paper explores a\nself-supervised imitation learning method using an autoregressive\nspatio-temporal graph neural network for an assistive drinking task. We address\nlearning from diverse human motion trajectory data that were captured via\nwearable IMU sensors on a human arm as the action-free task demonstrations.\nObserved arm motion data from several participants is used to generate natural\nand functional drinking motion trajectories for a UR5e robot arm.",
          "link": "http://arxiv.org/abs/2309.07550",
          "publishedOn": "2023-09-16T00:40:56.880Z",
          "wordCount": null,
          "title": "Naturalistic Robot Arm Trajectory Generation via Representation Learning. (arXiv:2309.07550v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akrami_H/0/1/0/all/0/1\">Haleh Akrami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamzam_O/0/1/0/all/0/1\">Omar Zamzam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Anand Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aydore_S/0/1/0/all/0/1\">Sergul Aydore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leahy_R/0/1/0/all/0/1\">Richard Leahy</a>",
          "description": "Quantile Regression (QR) can be used to estimate aleatoric uncertainty in\ndeep neural networks and can generate prediction intervals. Quantifying\nuncertainty is particularly important in critical applications such as clinical\ndiagnosis, where a realistic assessment of uncertainty is essential in\ndetermining disease status and planning the appropriate treatment. The most\ncommon application of quantile regression models is in cases where the\nparametric likelihood cannot be specified. Although quantile regression is\nquite robust to outlier response observations, it can be sensitive to outlier\ncovariate observations (features). Outlier features can compromise the\nperformance of deep learning regression problems such as style translation,\nimage reconstruction, and deep anomaly detection, potentially leading to\nmisleading conclusions. To address this problem, we propose a robust solution\nfor quantile regression that incorporates concepts from robust divergence. We\ncompare the performance of our proposed method with (i) least trimmed quantile\nregression and (ii) robust regression based on the regularization of\ncase-specific parameters in a simple real dataset in the presence of outlier.\nThese methods have not been applied in a deep learning framework. We also\ndemonstrate the applicability of the proposed method by applying it to a\nmedical imaging translation task using diffusion models.",
          "link": "http://arxiv.org/abs/2309.07374",
          "publishedOn": "2023-09-16T00:40:56.879Z",
          "wordCount": null,
          "title": "Beta quantile regression for robust estimation of uncertainty in the presence of outliers. (arXiv:2309.07374v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hamad_R/0/1/0/all/0/1\">Rebeen Ali Hamad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wei_B/0/1/0/all/0/1\">Bo Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_L/0/1/0/all/0/1\">Longzhi Yang</a>",
          "description": "Human activity recognition (HAR) is an essential research field that has been\nused in different applications including home and workplace automation,\nsecurity and surveillance as well as healthcare. Starting from conventional\nmachine learning methods to the recently developing deep learning techniques\nand the Internet of things, significant contributions have been shown in the\nHAR area in the last decade. Even though several review and survey studies have\nbeen published, there is a lack of sensor-based HAR overview studies focusing\non summarising the usage of wearable sensors and smart home sensors data as\nwell as applications of HAR and deep learning techniques. Hence, we overview\nsensor-based HAR, discuss several important applications that rely on HAR, and\nhighlight the most common machine learning methods that have been used for HAR.\nFinally, several challenges of HAR are explored that should be addressed to\nfurther improve the robustness of HAR.",
          "link": "http://arxiv.org/abs/2309.07170",
          "publishedOn": "2023-09-16T00:40:56.878Z",
          "wordCount": null,
          "title": "Overview of Human Activity Recognition Using Sensor Data. (arXiv:2309.07170v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07352",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Altmann_A/0/1/0/all/0/1\">Andre Altmann</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Aquila_A/0/1/0/all/0/1\">Ana C Lawry Aquila</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jahanshad_N/0/1/0/all/0/1\">Neda Jahanshad</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Thompson_P/0/1/0/all/0/1\">Paul M Thompson</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lorenzi_M/0/1/0/all/0/1\">Marco Lorenzi</a>",
          "description": "A major challenge in imaging genetics and similar fields is to link\nhigh-dimensional data in one domain, e.g., genetic data, to high dimensional\ndata in a second domain, e.g., brain imaging data. The standard approach in the\narea are mass univariate analyses across genetic factors and imaging\nphenotypes. That entails executing one genome-wide association study (GWAS) for\neach pre-defined imaging measure. Although this approach has been tremendously\nsuccessful, one shortcoming is that phenotypes must be pre-defined.\nConsequently, effects that are not confined to pre-selected regions of interest\nor that reflect larger brain-wide patterns can easily be missed. In this work\nwe introduce a Partial Least Squares (PLS)-based framework, which we term\nCluster-Bootstrap PLS (CLUB-PLS), that can work with large input dimensions in\nboth domains as well as with large sample sizes. One key factor of the\nframework is to use cluster bootstrap to provide robust statistics for single\ninput features in both domains. We applied CLUB-PLS to investigating the\ngenetic basis of surface area and cortical thickness in a sample of 33,000\nsubjects from the UK Biobank. We found 107 genome-wide significant\nlocus-phenotype pairs that are linked to 386 different genes. We found that a\nvast majority of these loci could be technically validated at a high rate:\nusing classic GWAS or Genome-Wide Inferred Statistics (GWIS) we found that 85\nlocus-phenotype pairs exceeded the genome-wide suggestive (P<1e-05) threshold.",
          "link": "http://arxiv.org/abs/2309.07352",
          "publishedOn": "2023-09-16T00:40:56.878Z",
          "wordCount": null,
          "title": "Tackling the dimensions in imaging genetics with CLUB-PLS. (arXiv:2309.07352v1 [q-bio.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07182",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ardeshir_H/0/1/0/all/0/1\">Hassan Ardeshir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Araghi_M/0/1/0/all/0/1\">Mohammad Araghi</a>",
          "description": "One of the common human diseases is sleep disorders. The classification of\nsleep stages plays a fundamental role in diagnosing sleep disorders, monitoring\ntreatment effectiveness, and understanding the relationship between sleep\nstages and various health conditions. A precise and efficient classification of\nthese stages can significantly enhance our understanding of sleep-related\nphenomena and ultimately lead to improved health outcomes and disease\ntreatment.\n\nModels others propose are often time-consuming and lack sufficient accuracy,\nespecially in stage N1. The main objective of this research is to present a\nmachine-learning model called \"EEGMobile\". This model utilizes pre-trained\nmodels and learns from electroencephalogram (EEG) spectrograms of brain\nsignals. The model achieved an accuracy of 86.97% on a publicly available\ndataset named \"Sleep-EDF20\", outperforming other models proposed by different\nresearchers. Moreover, it recorded an accuracy of 56.4% in stage N1, which is\nbetter than other models. These findings demonstrate that this model has the\npotential to achieve better results for the treatment of this disease.",
          "link": "http://arxiv.org/abs/2309.07182",
          "publishedOn": "2023-09-16T00:40:56.877Z",
          "wordCount": null,
          "title": "Sleep Stage Classification Using a Pre-trained Deep Learning Model. (arXiv:2309.07182v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07679",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Pedicillo_E/0/1/0/all/0/1\">Edoardo Pedicillo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pasquale_A/0/1/0/all/0/1\">Andrea Pasquale</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Carrazza_S/0/1/0/all/0/1\">Stefano Carrazza</a>",
          "description": "Quantum computing is a growing field where the information is processed by\ntwo-levels quantum states known as qubits. Current physical realizations of\nqubits require a careful calibration, composed by different experiments, due to\nnoise and decoherence phenomena. Among the different characterization\nexperiments, a crucial step is to develop a model to classify the measured\nstate by discriminating the ground state from the excited state. In this\nproceedings we benchmark multiple classification techniques applied to real\nquantum devices.",
          "link": "http://arxiv.org/abs/2309.07679",
          "publishedOn": "2023-09-16T00:40:56.875Z",
          "wordCount": null,
          "title": "Benchmarking machine learning models for quantum state classification. (arXiv:2309.07679v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07141",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_Z/0/1/0/all/0/1\">Zhuo-yong Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_Y/0/1/0/all/0/1\">Ye-tao Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_K/0/1/0/all/0/1\">Ke-xin Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1\">Ding-han Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_L/0/1/0/all/0/1\">Long-meng Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yong Wu</a>",
          "description": "With the rapid development of electronic science and technology, the research\non wearable devices is constantly updated, but for now, it is not comprehensive\nfor wearable devices to recognize and analyze the movement of specific sports.\nBased on this, this paper improves wearable devices of table tennis sport, and\nrealizes the pattern recognition and evaluation of table tennis players' motor\nskills through artificial intelligence. Firstly, a device is designed to\ncollect the movement information of table tennis players and the actual\nmovement data is processed. Secondly, a sliding window is made to divide the\ncollected motion data into a characteristic database of six table tennis\nbenchmark movements. Thirdly, motion features were constructed based on feature\nengineering, and motor skills were identified for different models after\ndimensionality reduction. Finally, the hierarchical evaluation system of motor\nskills is established with the loss functions of different evaluation indexes.\nThe results show that in the recognition of table tennis players' motor skills,\nthe feature-based BP neural network proposed in this paper has higher\nrecognition accuracy and stronger generalization ability than the traditional\nconvolutional neural network.",
          "link": "http://arxiv.org/abs/2309.07141",
          "publishedOn": "2023-09-16T00:40:56.872Z",
          "wordCount": null,
          "title": "Design of Recognition and Evaluation System for Table Tennis Players' Motor Skills Based on Artificial Intelligence. (arXiv:2309.07141v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongzhi Zhang</a>",
          "description": "Maximizing influences in complex networks is a practically important but\ncomputationally challenging task for social network analysis, due to its NP-\nhard nature. Most current approximation or heuristic methods either require\ntremendous human design efforts or achieve unsatisfying balances between\neffectiveness and efficiency. Recent machine learning attempts only focus on\nspeed but lack performance enhancement. In this paper, different from previous\nattempts, we propose an effective deep reinforcement learning model that\nachieves superior performances over traditional best influence maximization\nalgorithms. Specifically, we design an end-to-end learning framework that\ncombines graph neural network as the encoder and reinforcement learning as the\ndecoder, named DREIM. Trough extensive training on small synthetic graphs,\nDREIM outperforms the state-of-the-art baseline methods on very large synthetic\nand real-world networks on solution quality, and we also empirically show its\nlinear scalability with regard to the network size, which demonstrates its\nsuperiority in solving this problem.",
          "link": "http://arxiv.org/abs/2309.07153",
          "publishedOn": "2023-09-16T00:40:56.870Z",
          "wordCount": null,
          "title": "Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach. (arXiv:2309.07153v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07156",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maiti_S/0/1/0/all/0/1\">Suvadeep Maiti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mythirayee_S/0/1/0/all/0/1\">S.Mythirayee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rajendran_S/0/1/0/all/0/1\">Srijithesh Rajendran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Raju_B/0/1/0/all/0/1\">Bapi Raju</a>",
          "description": "Sleep, a fundamental physiological process, occupies a significant portion of\nour lives. Accurate classification of sleep stages serves as a crucial tool for\nevaluating sleep quality and identifying probable sleep disorders. This work\nintroduces a novel methodology that utilises a SE-Resnet-Bi-LSTM architecture\nto classify sleep into five separate stages. The classification process is\nbased on the analysis of single-channel electroencephalograms (EEGs). The\nframework that has been suggested consists of two fundamental elements: a\nfeature extractor that utilises SE-ResNet, and a temporal context encoder that\nuse stacks of Bi-LSTM units.The effectiveness of our approach is substantiated\nby thorough assessments conducted on three different datasets, namely\nSLeepEDF-20, SleepEDF-78, and SHHS. Significantly, our methodology attains\nnotable levels of accuracy, specifically 87.5\\%, 83.9\\%, and 87.8\\%, along with\nmacro-F1 scores of 82.5, 78.9, and 81.9 for the corresponding datasets.\nNotably, we introduce the utilization of 1D-GradCAM visualization to shed light\non the decision-making process of our model in the realm of sleep stage\nclassification. This visualization method not only provides valuable insights\ninto the model's classification rationale but also aligns its outcomes with the\nannotations made by sleep experts. One notable feature of our research is the\nintegration of an expedited training approach, which effectively preserves the\nmodel's resilience in terms of performance. The experimental evaluations\nconducted provide a comprehensive evaluation of the effectiveness of our\nproposed model in comparison to existing approaches, highlighting its potential\nfor practical applications.",
          "link": "http://arxiv.org/abs/2309.07156",
          "publishedOn": "2023-09-16T00:40:56.870Z",
          "wordCount": null,
          "title": "A Deep Dive into Sleep: Single-Channel EEG-Based Sleep Stage Classification with Model Interpretability. (arXiv:2309.07156v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mingote_V/0/1/0/all/0/1\">Victoria Mingote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimeno_P/0/1/0/all/0/1\">Pablo Gimeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_L/0/1/0/all/0/1\">Luis Vicente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurent_A/0/1/0/all/0/1\">Antoine Laurent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duret_J/0/1/0/all/0/1\">Jarod Duret</a>",
          "description": "This paper proposes a direct text to speech translation system using discrete\nacoustic units. This framework employs text in different source languages as\ninput to generate speech in the target language without the need for text\ntranscriptions in this language. Motivated by the success of acoustic units in\nprevious works for direct speech to speech translation systems, we use the same\npipeline to extract the acoustic units using a speech encoder combined with a\nclustering algorithm. Once units are obtained, an encoder-decoder architecture\nis trained to predict them. Then a vocoder generates speech from units. Our\napproach for direct text to speech translation was tested on the new CVSS\ncorpus with two different text mBART models employed as initialisation. The\nsystems presented report competitive performance for most of the language pairs\nevaluated. Besides, results show a remarkable improvement when initialising our\nproposed architecture with a model pre-trained with more languages.",
          "link": "http://arxiv.org/abs/2309.07478",
          "publishedOn": "2023-09-16T00:40:56.869Z",
          "wordCount": null,
          "title": "Direct Text to Speech Translation System using Acoustic Units. (arXiv:2309.07478v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Memery_S/0/1/0/all/0/1\">Sean Memery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cedron_O/0/1/0/all/0/1\">Osmar Cedron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subr_K/0/1/0/all/0/1\">Kartic Subr</a>",
          "description": "Artistic authoring of 3D environments is a laborious enterprise that also\nrequires skilled content creators. There have been impressive improvements in\nusing machine learning to address different aspects of generating 3D content,\nsuch as generating meshes, arranging geometry, synthesizing textures, etc. In\nthis paper we develop a model to generate Bidirectional Reflectance\nDistribution Functions (BRDFs) from descriptive textual prompts. BRDFs are four\ndimensional probability distributions that characterize the interaction of\nlight with surface materials. They are either represented parametrically, or by\ntabulating the probability density associated with every pair of incident and\noutgoing angles. The former lends itself to artistic editing while the latter\nis used when measuring the appearance of real materials. Numerous works have\nfocused on hypothesizing BRDF models from images of materials. We learn a\nmapping from textual descriptions of materials to parametric BRDFs. Our model\nis first trained using a semi-supervised approach before being tuned via an\nunsupervised scheme. Although our model is general, in this paper we\nspecifically generate parameters for MDL materials, conditioned on natural\nlanguage descriptions, within NVIDIA's Omniverse platform. This enables use\ncases such as real-time text prompts to change materials of objects in 3D\nenvironments such as \"dull plastic\" or \"shiny iron\". Since the output of our\nmodel is a parametric BRDF, rather than an image of the material, it may be\nused to render materials using any shape under arbitrarily specified viewing\nand lighting conditions.",
          "link": "http://arxiv.org/abs/2306.15679",
          "publishedOn": "2023-09-16T00:40:56.868Z",
          "wordCount": null,
          "title": "Generating Parametric BRDFs from Natural Language Descriptions. (arXiv:2306.15679v2 [cs.GR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "In data-rich domains such as vision, language, and speech, deep learning\nprevails to deliver high-performance task-specific models and can even learn\ngeneral task-agnostic representations for efficient finetuning to downstream\ntasks. However, deep learning in resource-limited domains still faces multiple\nchallenges including (i) limited data, (ii) constrained model development cost,\nand (iii) lack of adequate pre-trained models for effective finetuning. This\npaper provides an overview of model reprogramming to bridge this gap. Model\nreprogramming enables resource-efficient cross-domain machine learning by\nrepurposing and reusing a well-developed pre-trained model from a source domain\nto solve tasks in a target domain without model finetuning, where the source\nand target domains can be vastly different. In many applications, model\nreprogramming outperforms transfer learning and training from scratch. This\npaper elucidates the methodology of model reprogramming, summarizes existing\nuse cases, provides a theoretical explanation of the success of model\nreprogramming, and concludes with a discussion on open-ended research questions\nand opportunities. A list of model reprogramming studies is actively maintained\nand updated at https://github.com/IBM/model-reprogramming.",
          "link": "http://arxiv.org/abs/2202.10629",
          "publishedOn": "2023-09-16T00:40:56.858Z",
          "wordCount": null,
          "title": "Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning. (arXiv:2202.10629v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07193",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Forootani_A/0/1/0/all/0/1\">Ali Forootani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/math/1/au:+Benner_P/0/1/0/all/0/1\">Peter Benner</a>",
          "description": "The discovery of governing equations from data has been an active field of\nresearch for decades. One widely used methodology for this purpose is sparse\nregression for nonlinear dynamics, known as SINDy. Despite several attempts,\nnoisy and scarce data still pose a severe challenge to the success of the SINDy\napproach. In this work, we discuss a robust method to discover nonlinear\ngoverning equations from noisy and scarce data. To do this, we make use of\nneural networks to learn an implicit representation based on measurement data\nso that not only it produces the output in the vicinity of the measurements but\nalso the time-evolution of output can be described by a dynamical system.\nAdditionally, we learn such a dynamic system in the spirit of the SINDy\nframework. Leveraging the implicit representation using neural networks, we\nobtain the derivative information -- required for SINDy -- using an automatic\ndifferentiation tool. To enhance the robustness of our methodology, we further\nincorporate an integral condition on the output of the implicit networks.\nFurthermore, we extend our methodology to handle data collected from multiple\ninitial conditions. We demonstrate the efficiency of the proposed methodology\nto discover governing equations under noisy and scarce data regimes by means of\nseveral examples and compare its performance with existing methods.",
          "link": "http://arxiv.org/abs/2309.07193",
          "publishedOn": "2023-09-16T00:40:56.811Z",
          "wordCount": null,
          "title": "A Robust SINDy Approach by Combining Neural Networks and an Integral Form. (arXiv:2309.07193v1 [math.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11322",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiechen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangwoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1\">Osvaldo Simeone</a>",
          "description": "Spiking neural networks (SNNs) process time-series data via internal\nevent-driven neural dynamics whose energy consumption depends on the number of\nspikes exchanged between neurons over the course of the input presentation. In\ntypical implementations of an SNN classifier, decisions are produced after the\nentire input sequence has been processed, resulting in latency and energy\nconsumption levels that are fairly uniform across inputs. Recently introduced\ndelay-adaptive SNNs tailor the inference latency -- and, with it, the energy\nconsumption -- to the difficulty of each example, by producing an early\ndecision when the SNN model is sufficiently ``confident''. In this paper, we\nstart by observing that, as an SNN processes input samples, its classification\ndecisions tend to be first under-confident and then over-confident with respect\nto the decision's ground-truth, unknown, test accuracy. This makes it difficult\nto determine a stopping time that ensures a desired level of accuracy. To\naddress this problem, we introduce a novel delay-adaptive SNN-based inference\nmethodology that, wrapping around any pre-trained SNN classifier, provides\nguaranteed reliability for the decisions produced at input-dependent stopping\ntimes. The approach entails minimal added complexity as compared to the\nunderlying SNN, requiring only thresholding and counting operations at run\ntime, and it leverages tools from conformal prediction (CP).",
          "link": "http://arxiv.org/abs/2305.11322",
          "publishedOn": "2023-09-16T00:40:56.809Z",
          "wordCount": null,
          "title": "SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal Prediction. (arXiv:2305.11322v3 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mo_S/0/1/0/all/0/1\">Shentong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_M/0/1/0/all/0/1\">Miao Xin</a>",
          "description": "While the recently introduced Tree of Thoughts (ToT) has heralded\nadvancements in allowing Large Language Models (LLMs) to reason through\nforesight and backtracking for global decision-making, it has overlooked the\ninherent local uncertainties in intermediate decision points or \"thoughts\".\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\nresponses, remain a significant concern in the reasoning process. Addressing\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\nCarlo Dropout to quantify uncertainty scores associated with LLMs' diverse\nlocal responses at these intermediate steps. By marrying this local uncertainty\nquantification with global search algorithms, TouT enhances the model's\nprecision in response generation. We substantiate our approach with rigorous\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\nThe empirical evidence underscores TouT's superiority over both ToT and\nchain-of-thought prompting methods.",
          "link": "http://arxiv.org/abs/2309.07694",
          "publishedOn": "2023-09-16T00:40:56.806Z",
          "wordCount": null,
          "title": "Tree of Uncertain Thoughts Reasoning for Large Language Models. (arXiv:2309.07694v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pinneri_C/0/1/0/all/0/1\">Cristina Pinneri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bechtle_S/0/1/0/all/0/1\">Sarah Bechtle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulfmeier_M/0/1/0/all/0/1\">Markus Wulfmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byravan_A/0/1/0/all/0/1\">Arunkumar Byravan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1\">William F. Whitney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>",
          "description": "We present a novel approach to address the challenge of generalization in\noffline reinforcement learning (RL), where the agent learns from a fixed\ndataset without any additional interaction with the environment. Specifically,\nwe aim to improve the agent's ability to generalize to out-of-distribution\ngoals. To achieve this, we propose to learn a dynamics model and check if it is\nequivariant with respect to a fixed type of transformation, namely translations\nin the state space. We then use an entropy regularizer to increase the\nequivariant set and augment the dataset with the resulting transformed samples.\nFinally, we learn a new policy offline based on the augmented dataset, with an\noff-the-shelf offline RL algorithm. Our experimental results demonstrate that\nour approach can greatly improve the test performance of the policy on the\nconsidered environments.",
          "link": "http://arxiv.org/abs/2309.07578",
          "publishedOn": "2023-09-16T00:40:56.805Z",
          "wordCount": null,
          "title": "Equivariant Data Augmentation for Generalization in Offline Reinforcement Learning. (arXiv:2309.07578v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.00495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xinglong Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dost_K/0/1/0/all/0/1\">Katharina Dost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kaiqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1\">Ambra Demontis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1\">Fabio Roli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobbie_G/0/1/0/all/0/1\">Gill Dobbie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wicker_J/0/1/0/all/0/1\">J&#xf6;rg Wicker</a>",
          "description": "Adversarial defenses protect machine learning models from adversarial\nattacks, but are often tailored to one type of model or attack. The lack of\ninformation on unknown potential attacks makes detecting adversarial examples\nchallenging. Additionally, attackers do not need to follow the rules made by\nthe defender. To address this problem, we take inspiration from the concept of\nApplicability Domain in cheminformatics. Cheminformatics models struggle to\nmake accurate predictions because only a limited number of compounds are known\nand available for training. Applicability Domain defines a domain based on the\nknown compounds and rejects any unknown compound that falls outside the domain.\nSimilarly, adversarial examples start as harmless inputs, but can be\nmanipulated to evade reliable classification by moving outside the domain of\nthe classifier. We are the first to identify the similarity between\nApplicability Domain and adversarial detection. Instead of focusing on unknown\nattacks, we focus on what is known, the training data. We propose a simple yet\nrobust triple-stage data-driven framework that checks the input globally and\nlocally, and confirms that they are coherent with the model's output. This\nframework can be applied to any classification model and is not limited to\nspecific attacks. We demonstrate these three stages work as one unit,\neffectively detecting various attacks, even for a white-box scenario.",
          "link": "http://arxiv.org/abs/2105.00495",
          "publishedOn": "2023-09-16T00:40:56.803Z",
          "wordCount": null,
          "title": "BAARD: Blocking Adversarial Examples by Testing for Applicability, Reliability and Decidability. (arXiv:2105.00495v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.06031",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1\">Yifeng Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khoo_Y/0/1/0/all/0/1\">Yuehaw Khoo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhizhen Zhao</a>",
          "description": "In the presence of heterogeneous data, where randomly rotated objects fall\ninto multiple underlying categories, it is challenging to simultaneously\nclassify them into clusters and synchronize them based on pairwise relations.\nThis gives rise to the joint problem of community detection and\nsynchronization. We propose a series of semidefinite relaxations, and prove\ntheir exact recovery when extending the celebrated stochastic block model to\nthis new setting where both rotations and cluster identities are to be\ndetermined. Numerical experiments demonstrate the efficacy of our proposed\nalgorithms and confirm our theoretical result which indicates a sharp phase\ntransition for exact recovery.",
          "link": "http://arxiv.org/abs/2105.06031",
          "publishedOn": "2023-09-16T00:40:56.803Z",
          "wordCount": null,
          "title": "Joint Community Detection and Rotational Synchronization via Semidefinite Programming. (arXiv:2105.06031v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hui Jiang</a>",
          "description": "Languages are not created randomly but rather to communicate information.\nThere is a strong association between languages and their underlying meanings,\nresulting in a sparse joint distribution that is heavily peaked according to\ntheir correlations. Moreover, these peak values happen to match with the\nmarginal distribution of languages due to the sparsity. With the advent of LLMs\ntrained on big data and large models, we can now precisely assess the marginal\ndistribution of languages, providing a convenient means of exploring the sparse\nstructures in the joint distribution for effective inferences. In this paper,\nwe categorize languages as either unambiguous or {\\epsilon}-ambiguous and\npresent quantitative results to demonstrate that the emergent abilities of\nLLMs, such as language understanding, in-context learning, chain-of-thought\nprompting, and effective instruction fine-tuning, can all be attributed to\nBayesian inference on the sparse joint distribution of languages.",
          "link": "http://arxiv.org/abs/2304.09960",
          "publishedOn": "2023-09-16T00:40:56.803Z",
          "wordCount": null,
          "title": "A Latent Space Theory for Emergent Abilities in Large Language Models. (arXiv:2304.09960v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellon_F/0/1/0/all/0/1\">Fabiola Espinosa Castellon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayoue_A/0/1/0/all/0/1\">Aur&#xe9;lien Mayoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gouy_Pallier_C/0/1/0/all/0/1\">C&#xe9;dric Gouy-Pallier</a>",
          "description": "In this article, we propose an approach for federated domain adaptation, a\nsetting where distributional shift exists among clients and some have unlabeled\ndata. The proposed framework, FedDaDiL, tackles the resulting challenge through\ndictionary learning of empirical distributions. In our setting, clients'\ndistributions represent particular domains, and FedDaDiL collectively trains a\nfederated dictionary of empirical distributions. In particular, we build upon\nthe Dataset Dictionary Learning framework by designing collaborative\ncommunication protocols and aggregation operations. The chosen protocols keep\nclients' data private, thus enhancing overall privacy compared to its\ncentralized counterpart. We empirically demonstrate that our approach\nsuccessfully generates labeled data on the target domain with extensive\nexperiments on (i) Caltech-Office, (ii) TEP, and (iii) CWRU benchmarks.\nFurthermore, we compare our method to its centralized counterpart and other\nbenchmarks in federated domain adaptation.",
          "link": "http://arxiv.org/abs/2309.07670",
          "publishedOn": "2023-09-16T00:40:56.798Z",
          "wordCount": null,
          "title": "Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation. (arXiv:2309.07670v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhouri_M/0/1/0/all/0/1\">Mohamed Aziz Bhouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joly_M/0/1/0/all/0/1\">Michael Joly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Robert Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Soumalya Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>",
          "description": "Several fundamental problems in science and engineering consist of global\noptimization tasks involving unknown high-dimensional (black-box) functions\nthat map a set of controllable variables to the outcomes of an expensive\nexperiment. Bayesian Optimization (BO) techniques are known to be effective in\ntackling global optimization problems using a relatively small number objective\nfunction evaluations, but their performance suffers when dealing with\nhigh-dimensional outputs. To overcome the major challenge of dimensionality,\nhere we propose a deep learning framework for BO and sequential decision making\nbased on bootstrapped ensembles of neural architectures with randomized priors.\nUsing appropriate architecture choices, we show that the proposed framework can\napproximate functional relationships between design variables and quantities of\ninterest, even in cases where the latter take values in high-dimensional vector\nspaces or even infinite-dimensional function spaces. In the context of BO, we\naugmented the proposed probabilistic surrogates with re-parameterized Monte\nCarlo approximations of multiple-point (parallel) acquisition functions, as\nwell as methodological extensions for accommodating black-box constraints and\nmulti-fidelity information sources. We test the proposed framework against\nstate-of-the-art methods for BO and demonstrate superior performance across\nseveral challenging tasks with high-dimensional outputs, including a\nconstrained multi-fidelity optimization task involving shape optimization of\nrotor blades in turbo-machinery.",
          "link": "http://arxiv.org/abs/2302.07260",
          "publishedOn": "2023-09-16T00:40:56.798Z",
          "wordCount": null,
          "title": "Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.05558",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1\">Amir Ali Ahmadi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>",
          "description": "We show that unless P=NP, there cannot be a polynomial-time algorithm that\nfinds a point within Euclidean distance $c^n$ (for any constant $c \\ge 0$) of a\nlocal minimizer of an $n$-variate quadratic function over a polytope. This\nresult (even with $c=0$) answers a question of Pardalos and Vavasis that\nappeared in 1992 on a list of seven open problems in complexity theory for\nnumerical optimization. Our proof technique also implies that the problem of\ndeciding whether a quadratic function has a local minimizer over an (unbounded)\npolyhedron, and that of deciding if a quartic polynomial has a local minimizer\nare NP-hard.",
          "link": "http://arxiv.org/abs/2008.05558",
          "publishedOn": "2023-09-16T00:40:56.789Z",
          "wordCount": null,
          "title": "On the complexity of finding a local minimizer of a quadratic function over a polytope. (arXiv:2008.05558v5 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengge Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1\">Longfeng Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_S/0/1/0/all/0/1\">Siyu Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chenc_Y/0/1/0/all/0/1\">Yuntian Chenc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongxiao Zhang</a>",
          "description": "Unveiling the underlying governing equations of nonlinear dynamic systems\nremains a significant challenge, especially when encountering noisy\nobservations and no prior knowledge available. This study proposes R-DISCOVER,\na framework designed to robustly uncover open-form partial differential\nequations (PDEs) from limited and noisy data. The framework operates through\ntwo alternating update processes: discovering and embedding. The discovering\nphase employs symbolic representation and a reinforcement learning (RL)-guided\nhybrid PDE generator to efficiently produce diverse open-form PDEs with tree\nstructures. A neural network-based predictive model fits the system response\nand serves as the reward evaluator for the generated PDEs. PDEs with superior\nfits are utilized to iteratively optimize the generator via the RL method and\nthe best-performing PDE is selected by a parameter-free stability metric. The\nembedding phase integrates the initially identified PDE from the discovering\nprocess as a physical constraint into the predictive model for robust training.\nThe traversal of PDE trees automates the construction of the computational\ngraph and the embedding process without human intervention. Numerical\nexperiments demonstrate our framework's capability to uncover governing\nequations from nonlinear dynamic systems with limited and highly noisy data and\noutperform other physics-informed neural network-based discovery methods. This\nwork opens new potential for exploring real-world systems with limited\nunderstanding.",
          "link": "http://arxiv.org/abs/2309.07672",
          "publishedOn": "2023-09-16T00:40:56.784Z",
          "wordCount": null,
          "title": "Physics-constrained robust learning of open-form PDEs from limited and noisy data. (arXiv:2309.07672v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.13049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mengxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Q/0/1/0/all/0/1\">Qian Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lei Jiang</a>",
          "description": "Vision Transformers (ViTs) have demonstrated the state-of-the-art performance\nin various vision-related tasks. The success of ViTs motivates adversaries to\nperform backdoor attacks on ViTs. Although the vulnerability of traditional\nCNNs to backdoor attacks is well-known, backdoor attacks on ViTs are\nseldom-studied. Compared to CNNs capturing pixel-wise local features by\nconvolutions, ViTs extract global context information through patches and\nattentions. Na\\\"ively transplanting CNN-specific backdoor attacks to ViTs\nyields only a low clean data accuracy and a low attack success rate. In this\npaper, we propose a stealth and practical ViT-specific backdoor attack\n$TrojViT$. Rather than an area-wise trigger used by CNN-specific backdoor\nattacks, TrojViT generates a patch-wise trigger designed to build a Trojan\ncomposed of some vulnerable bits on the parameters of a ViT stored in DRAM\nmemory through patch salience ranking and attention-target loss. TrojViT\nfurther uses minimum-tuned parameter update to reduce the bit number of the\nTrojan. Once the attacker inserts the Trojan into the ViT model by flipping the\nvulnerable bits, the ViT model still produces normal inference accuracy with\nbenign inputs. But when the attacker embeds a trigger into an input, the ViT\nmodel is forced to classify the input to a predefined target class. We show\nthat flipping only few vulnerable bits identified by TrojViT on a ViT model\nusing the well-known RowHammer can transform the model into a backdoored one.\nWe perform extensive experiments of multiple datasets on various ViT models.\nTrojViT can classify $99.64\\%$ of test images to a target class by flipping\n$345$ bits on a ViT for ImageNet.Our codes are available at\nhttps://github.com/mxzheng/TrojViT",
          "link": "http://arxiv.org/abs/2208.13049",
          "publishedOn": "2023-09-16T00:40:56.784Z",
          "wordCount": null,
          "title": "TrojViT: Trojan Insertion in Vision Transformers. (arXiv:2208.13049v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagib_A/0/1/0/all/0/1\">Ahmad M. Nagib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abou_Zeid_H/0/1/0/all/0/1\">Hatem Abou-Zeid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassanein_H/0/1/0/all/0/1\">Hossam S. Hassanein</a>",
          "description": "The open radio access network (O-RAN) architecture supports intelligent\nnetwork control algorithms as one of its core capabilities. Data-driven\napplications incorporate such algorithms to optimize radio access network (RAN)\nfunctions via RAN intelligent controllers (RICs). Deep reinforcement learning\n(DRL) algorithms are among the main approaches adopted in the O-RAN literature\nto solve dynamic radio resource management problems. However, despite the\nbenefits introduced by the O-RAN RICs, the practical adoption of DRL algorithms\nin real network deployments falls behind. This is primarily due to the slow\nconvergence and unstable performance exhibited by DRL agents upon deployment\nand when facing previously unseen network conditions. In this paper, we address\nthese challenges by proposing transfer learning (TL) as a core component of the\ntraining and deployment workflows for the DRL-based closed-loop control of\nO-RAN functionalities. To this end, we propose and design a hybrid TL-aided\napproach that leverages the advantages of both policy reuse and distillation TL\nmethods to provide safe and accelerated convergence in DRL-based O-RAN slicing.\nWe conduct a thorough experiment that accommodates multiple services, including\nreal VR gaming traffic to reflect practical scenarios of O-RAN slicing. We also\npropose and implement policy reuse and distillation-aided DRL and non-TL-aided\nDRL as three separate baselines. The proposed hybrid approach shows at least:\n7.7% and 20.7% improvements in the average initial reward value and the\npercentage of converged scenarios, and a 64.6% decrease in reward variance\nwhile maintaining fast convergence and enhancing the generalizability compared\nwith the baselines.",
          "link": "http://arxiv.org/abs/2309.07265",
          "publishedOn": "2023-09-16T00:40:56.766Z",
          "wordCount": null,
          "title": "Safe and Accelerated Deep Reinforcement Learning-based O-RAN Slicing: A Hybrid Transfer Learning Approach. (arXiv:2309.07265v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07138",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Webster_M/0/1/0/all/0/1\">Matthew B. Webster</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Joonnyong Lee</a>",
          "description": "The task of blind source separation (BSS) involves separating sources from a\nmixture without prior knowledge of the sources or the mixing system. This is a\nchallenging problem that often requires making restrictive assumptions about\nboth the mixing system and the sources. In this paper, we propose a novel\nmethod for addressing BSS of non-linear mixtures by leveraging the natural\nfeature subspace specialization ability of multi-encoder autoencoders with\nfully self-supervised learning without strong priors. During the training\nphase, our method unmixes the input into the separate encoding spaces of the\nmulti-encoder network and then remixes these representations within the decoder\nfor a reconstruction of the input. Then to perform source inference, we\nintroduce a novel encoding masking technique whereby masking out all but one of\nthe encodings enables the decoder to estimate a source signal. To this end, we\nalso introduce a so-called pathway separation loss that encourages sparsity\nbetween the unmixed encoding spaces throughout the decoder's layers and a\nso-called zero reconstruction loss on the decoder for coherent source\nestimations. In order to carefully evaluate our method, we conduct experiments\non a toy dataset and with real-world biosignal recordings from a\npolysomnography sleep study for extracting respiration.",
          "link": "http://arxiv.org/abs/2309.07138",
          "publishedOn": "2023-09-16T00:40:56.727Z",
          "wordCount": null,
          "title": "Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders. (arXiv:2309.07138v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ichikawa_Y/0/1/0/all/0/1\">Yuma Ichikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hukushima_K/0/1/0/all/0/1\">Koji Hukushima</a>",
          "description": "In the Variational Autoencoder (VAE), the variational posterior often aligns\nclosely with the prior, which is known as posterior collapse and hinders the\nquality of representation learning. To mitigate this problem, an adjustable\nhyperparameter beta has been introduced in the VAE. This paper presents a\nclosed-form expression to assess the relationship between the beta in VAE, the\ndataset size, the posterior collapse, and the rate-distortion curve by\nanalyzing a minimal VAE in a high-dimensional limit. These results clarify that\na long plateau in the generalization error emerges with a relatively larger\nbeta. As the beta increases, the length of the plateau extends and then becomes\ninfinite beyond a certain beta threshold. This implies that the choice of beta,\nunlike the usual regularization parameters, can induce posterior collapse\nregardless of the dataset size. Thus, beta is a risky parameter that requires\ncareful tuning. Furthermore, considering the dataset-size dependence on the\nrate-distortion curve, a relatively large dataset is required to obtain a\nrate-distortion curve with high rates. Extensive numerical experiments support\nour analysis.",
          "link": "http://arxiv.org/abs/2309.07663",
          "publishedOn": "2023-09-16T00:40:56.725Z",
          "wordCount": null,
          "title": "Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE. (arXiv:2309.07663v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07339",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_S/0/1/0/all/0/1\">Samuel Yen-Chi Chen</a>",
          "description": "Quantum reinforcement learning (QRL) has emerged as a framework to solve\nsequential decision-making tasks, showcasing empirical quantum advantages. A\nnotable development is through quantum recurrent neural networks (QRNNs) for\nmemory-intensive tasks such as partially observable environments. However, QRL\nmodels incorporating QRNN encounter challenges such as inefficient training of\nQRL with QRNN, given that the computation of gradients in QRNN is both\ncomputationally expensive and time-consuming. This work presents a novel\napproach to address this challenge by constructing QRL agents utilizing\nQRNN-based reservoirs, specifically employing quantum long short-term memory\n(QLSTM). QLSTM parameters are randomly initialized and fixed without training.\nThe model is trained using the asynchronous advantage actor-aritic (A3C)\nalgorithm. Through numerical simulations, we validate the efficacy of our\nQLSTM-Reservoir RL framework. Its performance is assessed on standard\nbenchmarks, demonstrating comparable results to a fully trained QLSTM RL model\nwith identical architecture and training settings.",
          "link": "http://arxiv.org/abs/2309.07339",
          "publishedOn": "2023-09-16T00:40:56.724Z",
          "wordCount": null,
          "title": "Efficient quantum recurrent reinforcement learning via quantum reservoir computing. (arXiv:2309.07339v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07611",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Zheng_H/0/1/0/all/0/1\">Han Zheng</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_Z/0/1/0/all/0/1\">Zimu Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Strelchuk_S/0/1/0/all/0/1\">Sergii Strelchuk</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>",
          "description": "We develop a theoretical framework for $S_n$-equivariant convolutional\nquantum circuits with SU$(d)$-symmetry, building on and significantly\ngeneralizing Jordan's Permutational Quantum Computing (PQC) formalism based on\nSchur-Weyl duality connecting both SU$(d)$ and $S_n$ actions on qudits. In\nparticular, we utilize the Okounkov-Vershik approach to prove Harrow's\nstatement (Ph.D. Thesis 2005 p.160) on the equivalence between\n$\\operatorname{SU}(d)$ and $S_n$ irrep bases and to establish the\n$S_n$-equivariant Convolutional Quantum Alternating Ans\\\"atze ($S_n$-CQA) using\nYoung-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA is able to generate\nany unitary in any given $S_n$ irrep sector, which may serve as a universal\nmodel for a wide array of quantum machine learning problems with the presence\nof SU($d$) symmetry. Our method provides another way to prove the universality\nof Quantum Approximate Optimization Algorithm (QAOA) and verifies that 4-local\nSU($d$) symmetric unitaries are sufficient to build generic SU($d$) symmetric\nquantum circuits up to relative phase factors. We present numerical simulations\nto showcase the effectiveness of the ans\\\"atze to find the ground state energy\nof the $J_1$--$J_2$ antiferromagnetic Heisenberg model on the rectangular and\nKagome lattices. Our work provides the first application of the celebrated\nOkounkov-Vershik's $S_n$ representation theory to quantum physics and machine\nlearning, from which to propose quantum variational ans\\\"atze that strongly\nsuggests to be classically intractable tailored towards a specific optimization\nproblem.",
          "link": "http://arxiv.org/abs/2112.07611",
          "publishedOn": "2023-09-16T00:40:56.720Z",
          "wordCount": null,
          "title": "Speeding up Learning Quantum States through Group Equivariant Convolutional Quantum Ans\\\"atze. (arXiv:2112.07611v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07548",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Akiyama_Y/0/1/0/all/0/1\">Yuki Akiyama</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Slavakis_K/0/1/0/all/0/1\">Konstantinos Slavakis</a>",
          "description": "This paper aims at the algorithmic/theoretical core of reinforcement learning\n(RL) by introducing the novel class of proximal Bellman mappings. These\nmappings are defined in reproducing kernel Hilbert spaces (RKHSs), to benefit\nfrom the rich approximation properties and inner product of RKHSs, they are\nshown to belong to the powerful Hilbertian family of (firmly) nonexpansive\nmappings, regardless of the values of their discount factors, and possess ample\ndegrees of design freedom to even reproduce attributes of the classical Bellman\nmappings and to pave the way for novel RL designs. An approximate\npolicy-iteration scheme is built on the proposed class of mappings to solve the\nproblem of selecting online, at every time instance, the \"optimal\" exponent $p$\nin a $p$-norm loss to combat outliers in linear adaptive filtering, without\ntraining data and any knowledge on the statistical properties of the outliers.\nNumerical tests on synthetic data showcase the superior performance of the\nproposed framework over several non-RL and kernel-based RL schemes.",
          "link": "http://arxiv.org/abs/2309.07548",
          "publishedOn": "2023-09-16T00:40:56.719Z",
          "wordCount": null,
          "title": "Proximal Bellman mappings for reinforcement learning and their application to robust adaptive filtering. (arXiv:2309.07548v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nasim_M/0/1/0/all/0/1\">Md Nasim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yexiang Xue</a>",
          "description": "Accelerating the learning of Partial Differential Equations (PDEs) from\nexperimental data will speed up the pace of scientific discovery. Previous\nrandomized algorithms exploit sparsity in PDE updates for acceleration. However\nsuch methods are applicable to a limited class of decomposable PDEs, which have\nsparse features in the value domain. We propose Reel, which accelerates the\nlearning of PDEs via random projection and has much broader applicability. Reel\nexploits the sparsity by decomposing dense updates into sparse ones in both the\nvalue and frequency domains. This decomposition enables efficient learning when\nthe source of the updates consists of gradually changing terms across large\nareas (sparse in the frequency domain) in addition to a few rapid updates\nconcentrated in a small set of \"interfacial\" regions (sparse in the value\ndomain). Random projection is then applied to compress the sparse signals for\nlearning. To expand the model applicability, Taylor series expansion is used in\nReel to approximate the nonlinear PDE updates with polynomials in the\ndecomposable form. Theoretically, we derive a constant factor approximation\nbetween the projected loss function and the original one with poly-logarithmic\nnumber of projected dimensions. Experimentally, we provide empirical evidence\nthat our proposed Reel can lead to faster learning of PDE models (70-98%\nreduction in training time when the data is compressed to 1% of its original\nsize) with comparable quality as the non-compressed models.",
          "link": "http://arxiv.org/abs/2309.07344",
          "publishedOn": "2023-09-16T00:40:56.671Z",
          "wordCount": null,
          "title": "Efficient Learning of PDEs via Taylor Expansion and Sparse Decomposition into Value and Fourier Domains. (arXiv:2309.07344v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lianke Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baocheng Sun</a>",
          "description": "A rising trend in theoretical deep learning is to understand why deep\nlearning works through Neural Tangent Kernel (NTK) [jgh18], a kernel method\nthat is equivalent to using gradient descent to train a multi-layer\ninfinitely-wide neural network. NTK is a major step forward in the theoretical\ndeep learning because it allows researchers to use traditional mathematical\ntools to analyze properties of deep neural networks and to explain various\nneural network techniques from a theoretical view. A natural extension of NTK\non graph learning is \\textit{Graph Neural Tangent Kernel (GNTK)}, and\nresearchers have already provide GNTK formulation for graph-level regression\nand show empirically that this kernel method can achieve similar accuracy as\nGNNs on various bioinformatics datasets [dhs+19]. The remaining question now is\nwhether solving GNTK regression is equivalent to training an infinite-wide\nmulti-layer GNN using gradient descent. In this paper, we provide three new\ntheoretical results. First, we formally prove this equivalence for graph-level\nregression. Second, we present the first GNTK formulation for node-level\nregression. Finally, we prove the equivalence for node-level regression.",
          "link": "http://arxiv.org/abs/2309.07452",
          "publishedOn": "2023-09-16T00:40:56.645Z",
          "wordCount": null,
          "title": "Is Solving Graph Neural Tangent Kernel Equivalent to Training Graph Neural Network?. (arXiv:2309.07452v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07383",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bouland_A/0/1/0/all/0/1\">Ali Bouland</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niu_S/0/1/0/all/0/1\">Shengyuan Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Paruchuri_S/0/1/0/all/0/1\">Sai Tej Paruchuri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurdila_A/0/1/0/all/0/1\">Andrew Kurdila</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1\">John Burns</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schuster_E/0/1/0/all/0/1\">Eugenio Schuster</a>",
          "description": "This paper studies convergence rates for some value function approximations\nthat arise in a collection of reproducing kernel Hilbert spaces (RKHS)\n$H(\\Omega)$. By casting an optimal control problem in a specific class of\nnative spaces, strong rates of convergence are derived for the operator\nequation that enables offline approximations that appear in policy iteration.\nExplicit upper bounds on error in value function approximations are derived in\nterms of power function $\\Pwr_{H,N}$ for the space of finite dimensional\napproximants $H_N$ in the native space $H(\\Omega)$. These bounds are geometric\nin nature and refine some well-known, now classical results concerning\nconvergence of approximations of value functions.",
          "link": "http://arxiv.org/abs/2309.07383",
          "publishedOn": "2023-09-16T00:40:56.643Z",
          "wordCount": null,
          "title": "Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning. (arXiv:2309.07383v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jingcai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaocheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Song Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_P/0/1/0/all/0/1\">Peiran Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiewei Zhang</a>",
          "description": "This paper investigates a challenging problem of zero-shot learning in the\nmulti-label scenario (MLZSL), wherein, the model is trained to recognize\nmultiple unseen classes within a sample (e.g., an image) based on seen classes\nand auxiliary knowledge, e.g., semantic information. Existing methods usually\nresort to analyzing the relationship of various seen classes residing in a\nsample from the dimension of spatial or semantic characteristics, and transfer\nthe learned model to unseen ones. But they ignore the effective integration of\nlocal and global features. That is, in the process of inferring unseen classes,\nglobal features represent the principal direction of the image in the feature\nspace, while local features should maintain uniqueness within a certain range.\nThis integrated neglect will make the model lose its grasp of the main\ncomponents of the image. Relying only on the local existence of seen classes\nduring the inference stage introduces unavoidable bias. In this paper, we\npropose a novel and effective group bi-enhancement framework for MLZSL, dubbed\nGBE-MLZSL, to fully make use of such properties and enable a more accurate and\nrobust visual-semantic projection. Specifically, we split the feature maps into\nseveral feature groups, of which each feature group can be trained\nindependently with the Local Information Distinguishing Module (LID) to ensure\nuniqueness. Meanwhile, a Global Enhancement Module (GEM) is designed to\npreserve the principal direction. Besides, a static graph structure is designed\nto construct the correlation of local features. Experiments on large-scale\nMLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the\nproposed GBE-MLZSL outperforms other state-of-the-art methods with large\nmargins.",
          "link": "http://arxiv.org/abs/2309.00923",
          "publishedOn": "2023-09-16T00:40:56.615Z",
          "wordCount": null,
          "title": "GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot Learning. (arXiv:2309.00923v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07145",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Che Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wan_Z/0/1/0/all/0/1\">Zhongwei Wan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_S/0/1/0/all/0/1\">Sibo Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_M/0/1/0/all/0/1\">Mi Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arcucci_R/0/1/0/all/0/1\">Rossella Arcucci</a>",
          "description": "In the domain of cardiovascular healthcare, the Electrocardiogram (ECG)\nserves as a critical, non-invasive diagnostic tool. Although recent strides in\nself-supervised learning (SSL) have been promising for ECG representation\nlearning, these techniques often require annotated samples and struggle with\nclasses not present in the fine-tuning stages. To address these limitations, we\nintroduce ECG-Text Pre-training (ETP), an innovative framework designed to\nlearn cross-modal representations that link ECG signals with textual reports.\nFor the first time, this framework leverages the zero-shot classification task\nin the ECG domain. ETP employs an ECG encoder along with a pre-trained language\nmodel to align ECG signals with their corresponding textual reports. The\nproposed framework excels in both linear evaluation and zero-shot\nclassification tasks, as demonstrated on the PTB-XL and CPSC2018 datasets,\nshowcasing its ability for robust and generalizable cross-modal ECG feature\nlearning.",
          "link": "http://arxiv.org/abs/2309.07145",
          "publishedOn": "2023-09-16T00:40:56.604Z",
          "wordCount": null,
          "title": "ETP: Learning Transferable ECG Representations via ECG-Text Pre-training. (arXiv:2309.07145v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yashchuk_I/0/1/0/all/0/1\">Ivan Yashchuk</a>",
          "description": "Partial differential equations (PDEs) are used to describe a variety of\nphysical phenomena. Often these equations do not have analytical solutions and\nnumerical approximations are used instead. One of the common methods to solve\nPDEs is the finite element method. Computing derivative information of the\nsolution with respect to the input parameters is important in many tasks in\nscientific computing. We extend JAX automatic differentiation library with an\ninterface to Firedrake finite element library. High-level symbolic\nrepresentation of PDEs allows bypassing differentiating through low-level\npossibly many iterations of the underlying nonlinear solvers. Differentiating\nthrough Firedrake solvers is done using tangent-linear and adjoint equations.\nThis enables the efficient composition of finite element solvers with arbitrary\ndifferentiable programs. The code is available at\ngithub.com/IvanYashchuk/jax-firedrake.",
          "link": "http://arxiv.org/abs/2309.07137",
          "publishedOn": "2023-09-16T00:40:56.594Z",
          "wordCount": null,
          "title": "Bringing PDEs to JAX with forward and reverse modes automatic differentiation. (arXiv:2309.07137v1 [cs.MS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07937",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Rittig_J/0/1/0/all/0/1\">Jan G. Rittig</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Felton_K/0/1/0/all/0/1\">Kobi C. Felton</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lapkin_A/0/1/0/all/0/1\">Alexei A. Lapkin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mitsos_A/0/1/0/all/0/1\">Alexander Mitsos</a>",
          "description": "We propose Gibbs-Duhem-informed neural networks for the prediction of binary\nactivity coefficients at varying compositions. That is, we include the\nGibbs-Duhem equation explicitly in the loss function for training neural\nnetworks, which is straightforward in standard machine learning (ML) frameworks\nenabling automatic differentiation. In contrast to recent hybrid ML approaches,\nour approach does not rely on embedding a specific thermodynamic model inside\nthe neural network and corresponding prediction limitations. Rather,\nGibbs-Duhem consistency serves as regularization, with the flexibility of ML\nmodels being preserved. Our results show increased thermodynamic consistency\nand generalization capabilities for activity coefficient predictions by\nGibbs-Duhem-informed graph neural networks and matrix completion methods. We\nalso find that the model architecture, particularly the activation function,\ncan have a strong influence on the prediction quality. The approach can be\neasily extended to account for other thermodynamic consistency conditions.",
          "link": "http://arxiv.org/abs/2306.07937",
          "publishedOn": "2023-09-16T00:40:56.593Z",
          "wordCount": null,
          "title": "Gibbs-Duhem-Informed Neural Networks for Binary Activity Coefficient Prediction. (arXiv:2306.07937v2 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07175",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jafrasteh_B/0/1/0/all/0/1\">Bahram Jafrasteh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopez_S/0/1/0/all/0/1\">Sim&#xf3;n Pedro Lubi&#xe1;n L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fernandez_I/0/1/0/all/0/1\">Isabel Benavente Fern&#xe1;ndez</a>",
          "description": "MELAGE, a pioneering Python-based neuroimaging software, emerges as a\nversatile tool for the visualization, processing, and analysis of medical\nimages. Initially conceived to address the unique challenges of processing 3D\nultrasound and MRI brain images during the neonatal period, MELAGE exhibits\nremarkable adaptability, extending its utility to the domain of adult human\nbrain imaging. At its core, MELAGE features a semi-automatic brain extraction\ntool empowered by a deep learning module, ensuring precise and efficient brain\nstructure extraction from MRI and 3D Ultrasound data. Moreover, MELAGE offers a\ncomprehensive suite of features, encompassing dynamic 3D visualization,\naccurate measurements, and interactive image segmentation. This transformative\nsoftware holds immense promise for researchers and clinicians, offering\nstreamlined image analysis, seamless integration with deep learning algorithms,\nand broad applicability in the realm of medical imaging.",
          "link": "http://arxiv.org/abs/2309.07175",
          "publishedOn": "2023-09-16T00:40:56.587Z",
          "wordCount": null,
          "title": "MELAGE: A purely python based Neuroimaging software (Neonatal). (arXiv:2309.07175v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yao Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Mengkang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jun Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jifeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "Embodied AI is a crucial frontier in robotics, capable of planning and\nexecuting action sequences for robots to accomplish long-horizon tasks in\nphysical environments. In this work, we introduce EmbodiedGPT, an end-to-end\nmulti-modal foundation model for embodied AI, empowering embodied agents with\nmulti-modal understanding and execution capabilities. To achieve this, we have\nmade the following efforts: (i) We craft a large-scale embodied planning\ndataset, termed EgoCOT. The dataset consists of carefully selected videos from\nthe Ego4D dataset, along with corresponding high-quality language instructions.\nSpecifically, we generate a sequence of sub-goals with the \"Chain of Thoughts\"\nmode for effective embodied planning. (ii) We introduce an efficient training\napproach to EmbodiedGPT for high-quality plan generation, by adapting a 7B\nlarge language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We\nintroduce a paradigm for extracting task-related features from LLM-generated\nplanning queries to form a closed loop between high-level planning and\nlow-level control. Extensive experiments show the effectiveness of EmbodiedGPT\non embodied tasks, including embodied planning, embodied control, visual\ncaptioning, and visual question answering. Notably, EmbodiedGPT significantly\nenhances the success rate of the embodied control task by extracting more\neffective features. It has achieved a remarkable 1.6 times increase in success\nrate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World\nbenchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.",
          "link": "http://arxiv.org/abs/2305.15021",
          "publishedOn": "2023-09-16T00:40:56.565Z",
          "wordCount": null,
          "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought. (arXiv:2305.15021v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07135",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ingolfsson_T/0/1/0/all/0/1\">Thorir Mar Ingolfsson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chakraborty_U/0/1/0/all/0/1\">Upasana Chakraborty</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xiaying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beniczky_S/0/1/0/all/0/1\">Sandor Beniczky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ducouret_P/0/1/0/all/0/1\">Pauline Ducouret</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benatti_S/0/1/0/all/0/1\">Simone Benatti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ryvlin_P/0/1/0/all/0/1\">Philippe Ryvlin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cossettini_A/0/1/0/all/0/1\">Andrea Cossettini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>",
          "description": "Epilepsy is a prevalent neurological disorder that affects millions of\nindividuals globally, and continuous monitoring coupled with automated seizure\ndetection appears as a necessity for effective patient treatment. To enable\nlong-term care in daily-life conditions, comfortable and smart wearable devices\nwith long battery life are required, which in turn set the demand for\nresource-constrained and energy-efficient computing solutions. In this context,\nthe development of machine learning algorithms for seizure detection faces the\nchallenge of heavily imbalanced datasets. This paper introduces EpiDeNet, a new\nlightweight seizure detection network, and Sensitivity-Specificity Weighted\nCross-Entropy (SSWCE), a new loss function that incorporates sensitivity and\nspecificity, to address the challenge of heavily unbalanced datasets. The\nproposed EpiDeNet-SSWCE approach demonstrates the successful detection of\n91.16% and 92.00% seizure events on two different datasets (CHB-MIT and\nPEDESITE, respectively), with only four EEG channels. A three-window majority\nvoting-based smoothing scheme combined with the SSWCE loss achieves 3x\nreduction of false positives to 1.18 FP/h. EpiDeNet is well suited for\nimplementation on low-power embedded platforms, and we evaluate its performance\non two ARM Cortex-based platforms (M4F/M7) and two parallel ultra-low power\n(PULP) systems (GAP8, GAP9). The most efficient implementation (GAP9) achieves\nan energy efficiency of 40 GMAC/s/W, with an energy consumption per inference\nof only 0.051 mJ at high performance (726.46 MMAC/s), outperforming the best\nARM Cortex-based solutions by approximately 160x in energy efficiency. The\nEpiDeNet-SSWCE method demonstrates effective and accurate seizure detection\nperformance on heavily imbalanced datasets, while being suited for\nimplementation on energy-constrained platforms.",
          "link": "http://arxiv.org/abs/2309.07135",
          "publishedOn": "2023-09-16T00:40:56.534Z",
          "wordCount": null,
          "title": "EpiDeNet: An Energy-Efficient Approach to Seizure Detection for Embedded Systems. (arXiv:2309.07135v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farrukh_Y/0/1/0/all/0/1\">Yasir Ali Farrukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wali_S/0/1/0/all/0/1\">Syed Wali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_I/0/1/0/all/0/1\">Irfan Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastian_N/0/1/0/all/0/1\">Nathaniel D. Bastian</a>",
          "description": "The widespread integration of Internet of Things (IoT) devices across all\nfacets of life has ushered in an era of interconnectedness, creating new\navenues for cybersecurity challenges and underscoring the need for robust\nintrusion detection systems. However, traditional security systems are designed\nwith a closed-world perspective and often face challenges in dealing with the\never-evolving threat landscape, where new and unfamiliar attacks are constantly\nemerging. In this paper, we introduce a framework aimed at mitigating the open\nset recognition (OSR) problem in the realm of Network Intrusion Detection\nSystems (NIDS) tailored for IoT environments. Our framework capitalizes on\nimage-based representations of packet-level data, extracting spatial and\ntemporal patterns from network traffic. Additionally, we integrate stacking and\nsub-clustering techniques, enabling the identification of unknown attacks by\neffectively modeling the complex and diverse nature of benign behavior. The\nempirical results prominently underscore the framework's efficacy, boasting an\nimpressive 88\\% detection rate for previously unseen attacks when compared\nagainst existing approaches and recent advancements. Future work will perform\nextensive experimentation across various openness levels and attack scenarios,\nfurther strengthening the adaptability and performance of our proposed solution\nin safeguarding IoT environments.",
          "link": "http://arxiv.org/abs/2309.07461",
          "publishedOn": "2023-09-16T00:40:56.503Z",
          "wordCount": null,
          "title": "Detecting Unknown Attacks in IoT Environments: An Open Set Classifier for Enhanced Network Intrusion Detection. (arXiv:2309.07461v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07893",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tripuraneni_N/0/1/0/all/0/1\">Nilesh Tripuraneni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richardson_L/0/1/0/all/0/1\">Lee Richardson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+DAmour_A/0/1/0/all/0/1\">Alexander D&#x27;Amour</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Soriano_J/0/1/0/all/0/1\">Jacopo Soriano</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>",
          "description": "In many randomized experiments, the treatment effect of the long-term metric\n(i.e. the primary outcome of interest) is often difficult or infeasible to\nmeasure. Such long-term metrics are often slow to react to changes and\nsufficiently noisy they are challenging to faithfully estimate in short-horizon\nexperiments. A common alternative is to measure several short-term proxy\nmetrics in the hope they closely track the long-term metric -- so they can be\nused to effectively guide decision-making in the near-term. We introduce a new\nstatistical framework to both define and construct an optimal proxy metric for\nuse in a homogeneous population of randomized experiments. Our procedure first\nreduces the construction of an optimal proxy metric in a given experiment to a\nportfolio optimization problem which depends on the true latent treatment\neffects and noise level of experiment under consideration. We then denoise the\nobserved treatment effects of the long-term metric and a set of proxies in a\nhistorical corpus of randomized experiments to extract estimates of the latent\ntreatment effects for use in the optimization problem. One key insight derived\nfrom our approach is that the optimal proxy metric for a given experiment is\nnot apriori fixed; rather it should depend on the sample size (or effective\nnoise level) of the randomized experiment for which it is deployed. To\ninstantiate and evaluate our framework, we employ our methodology in a large\ncorpus of randomized experiments from an industrial recommendation system and\nconstruct proxy metrics that perform favorably relative to several baselines.",
          "link": "http://arxiv.org/abs/2309.07893",
          "publishedOn": "2023-09-16T00:40:56.503Z",
          "wordCount": null,
          "title": "Choosing a Proxy Metric from Past Experiments. (arXiv:2309.07893v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianpu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Weilong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_M/0/1/0/all/0/1\">Mengda Xing</a>",
          "description": "As one of the important tools for spatial feature extraction, graph\nconvolution has been applied in a wide range of fields such as traffic flow\nprediction. However, current popular works of graph convolution cannot\nguarantee spatio-temporal consistency in a long period. The ignorance of\ncorrelational dynamics, convolutional locality and temporal comprehensiveness\nwould limit predictive accuracy. In this paper, a novel Attention-based Dynamic\nGraph Convolutional Recurrent Neural Network (ADGCRNN) is proposed to improve\ntraffic flow prediction in highway transportation. Three temporal resolutions\nof data sequence are effectively integrated by self-attention to extract\ncharacteristics; multi-dynamic graphs and their weights are dynamically created\nto compliantly combine the varying characteristics; a dedicated gated kernel\nemphasizing highly relative nodes is introduced on these complete graphs to\nreduce overfitting for graph convolution operations. Experiments on two public\ndatasets show our work better than state-of-the-art baselines, and case studies\nof a real Web system prove practical benefit in highway transportation.",
          "link": "http://arxiv.org/abs/2309.07196",
          "publishedOn": "2023-09-16T00:40:56.474Z",
          "wordCount": null,
          "title": "Attention-based Dynamic Graph Convolutional Recurrent Neural Network for Traffic Flow Prediction in Highway Transportation. (arXiv:2309.07196v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bicer_Y/0/1/0/all/0/1\">Yunus Bicer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smedemark_Margulies_N/0/1/0/all/0/1\">Niklas Smedemark-Margulies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celik_B/0/1/0/all/0/1\">Basak Celik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunger_E/0/1/0/all/0/1\">Elifnur Sunger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orendorff_R/0/1/0/all/0/1\">Ryan Orendorff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naufel_S/0/1/0/all/0/1\">Stephanie Naufel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imbiriba_T/0/1/0/all/0/1\">Tales Imbiriba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdo%7Bg%7Dmu%7Bs%7D_D/0/1/0/all/0/1\">Deniz Erdo{&#x11f;}mu{&#x15f;}</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tunik_E/0/1/0/all/0/1\">Eugene Tunik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarossi_M/0/1/0/all/0/1\">Mathew Yarossi</a>",
          "description": "We designed and tested a system for real-time control of a user interface by\nextracting surface electromyographic (sEMG) activity from eight electrodes in a\nwrist-band configuration. sEMG data were streamed into a machine-learning\nalgorithm that classified hand gestures in real-time. After an initial model\ncalibration, participants were presented with one of three types of feedback\nduring a human-learning stage: veridical feedback, in which predicted\nprobabilities from the gesture classification algorithm were displayed without\nalteration, modified feedback, in which we applied a hidden augmentation of\nerror to these probabilities, and no feedback. User performance was then\nevaluated in a series of minigames, in which subjects were required to use\neight gestures to manipulate their game avatar to complete a task. Experimental\nresults indicated that, relative to baseline, the modified feedback condition\nled to significantly improved accuracy and improved gesture class separation.\nThese findings suggest that real-time feedback in a gamified user interface\nwith manipulation of feedback may enable intuitive, rapid, and accurate task\nacquisition for sEMG-based gesture recognition applications.",
          "link": "http://arxiv.org/abs/2309.07289",
          "publishedOn": "2023-09-16T00:40:56.451Z",
          "wordCount": null,
          "title": "User Training with Error Augmentation for Electromyogram-based Gesture Classification. (arXiv:2309.07289v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Angela Zhou</a>",
          "description": "In consequential domains, it is often impossible to compel individuals to\ntake treatment, so that optimal policy rules are merely suggestions in the\npresence of human non-adherence to treatment recommendations. In these same\ndomains, there may be heterogeneity both in who responds in taking-up\ntreatment, and heterogeneity in treatment efficacy. While optimal treatment\nrules can maximize causal outcomes across the population, access parity\nconstraints or other fairness considerations can be relevant in the case of\nencouragement. For example, in social services, a persistent puzzle is the gap\nin take-up of beneficial services among those who may benefit from them the\nmost. When in addition the decision-maker has distributional preferences over\nboth access and average outcomes, the optimal decision rule changes. We study\ncausal identification, statistical variance-reduced estimation, and robust\nestimation of optimal treatment rules, including under potential violations of\npositivity. We consider fairness constraints such as demographic parity in\ntreatment take-up, and other constraints, via constrained optimization. Our\nframework can be extended to handle algorithmic recommendations under an\noften-reasonable covariate-conditional exclusion restriction, using our\nrobustness checks for lack of positivity in the recommendation. We develop a\ntwo-stage algorithm for solving over parametrized policy classes under general\nconstraints to obtain variance-sensitive regret bounds. We illustrate the\nmethods in two case studies based on data from randomized encouragement to\nenroll in insurance and from pretrial supervised release with electronic\nmonitoring.",
          "link": "http://arxiv.org/abs/2309.07176",
          "publishedOn": "2023-09-16T00:40:56.177Z",
          "wordCount": null,
          "title": "Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.14541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faruque_O/0/1/0/all/0/1\">Omar Faruque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nji_F/0/1/0/all/0/1\">Francis Ndikum Nji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cham_M/0/1/0/all/0/1\">Mostafa Cham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_R/0/1/0/all/0/1\">Rohan Mandar Salvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xue Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianwu Wang</a>",
          "description": "Clustering high-dimensional spatiotemporal data using an unsupervised\napproach is a challenging problem for many data-driven applications. Existing\nstate-of-the-art methods for unsupervised clustering use different similarity\nand distance functions but focus on either spatial or temporal features of the\ndata. Concentrating on joint deep representation learning of spatial and\ntemporal features, we propose Deep Spatiotemporal Clustering (DSC), a novel\nalgorithm for the temporal clustering of high-dimensional spatiotemporal data\nusing an unsupervised deep learning method. Inspired by the U-net architecture,\nDSC utilizes an autoencoder integrating CNN-RNN layers to learn latent\nrepresentations of the spatiotemporal data. DSC also includes a unique layer\nfor cluster assignment on latent representations that uses the Student's\nt-distribution. By optimizing the clustering loss and data reconstruction loss\nsimultaneously, the algorithm gradually improves clustering assignments and the\nnonlinear mapping between low-dimensional latent feature space and\nhigh-dimensional original data space. A multivariate spatiotemporal climate\ndataset is used to evaluate the efficacy of the proposed method. Our extensive\nexperiments show our approach outperforms both conventional and deep\nlearning-based unsupervised clustering algorithms. Additionally, we compared\nthe proposed model with its various variants (CNN encoder, CNN autoencoder,\nCNN-RNN encoder, CNN-RNN autoencoder, etc.) to get insight into using both the\nCNN and RNN layers in the autoencoder, and our proposed technique outperforms\nthese variants in terms of clustering results.",
          "link": "http://arxiv.org/abs/2304.14541",
          "publishedOn": "2023-09-16T00:40:56.177Z",
          "wordCount": null,
          "title": "Deep Spatiotemporal Clustering: A Temporal Clustering Approach for Multi-dimensional Climate Data. (arXiv:2304.14541v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07140",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cui_Y/0/1/0/all/0/1\">Yang Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1\">Han Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yijian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1\">Lu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "In deep learning, the load data with non-temporal factors are difficult to\nprocess by sequence models. This problem results in insufficient precision of\nthe prediction. Therefore, a short-term load forecasting method based on\nconvolutional neural network (CNN), self-attention encoder-decoder network\n(SAEDN) and residual-refinement (Res) is proposed. In this method, feature\nextraction module is composed of a two-dimensional convolutional neural\nnetwork, which is used to mine the local correlation between data and obtain\nhigh-dimensional data features. The initial load fore-casting module consists\nof a self-attention encoder-decoder network and a feedforward neural network\n(FFN). The module utilizes self-attention mechanisms to encode high-dimensional\nfeatures. This operation can obtain the global correlation between data.\nTherefore, the model is able to retain important information based on the\ncoupling relationship between the data in data mixed with non-time series\nfactors. Then, self-attention decoding is per-formed and the feedforward neural\nnetwork is used to regression initial load. This paper introduces the residual\nmechanism to build the load optimization module. The module generates residual\nload values to optimize the initial load. The simulation results show that the\nproposed load forecasting method has advantages in terms of prediction accuracy\nand prediction stability.",
          "link": "http://arxiv.org/abs/2309.07140",
          "publishedOn": "2023-09-16T00:40:55.832Z",
          "wordCount": 724,
          "title": "Short-term power load forecasting method based on CNN-SAEDN-Res. (arXiv:2309.07140v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.04953",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Cavlak_M/0/1/0/all/0/1\">Meryem Banu Cavlak</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Singh_G/0/1/0/all/0/1\">Gagandeep Singh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alser_M/0/1/0/all/0/1\">Mohammed Alser</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Firtina_C/0/1/0/all/0/1\">Can Firtina</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lindegger_J/0/1/0/all/0/1\">Jo&#xeb;l Lindegger</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sadrosadati_M/0/1/0/all/0/1\">Mohammad Sadrosadati</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ghiasi_N/0/1/0/all/0/1\">Nika Mansouri Ghiasi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alkan_C/0/1/0/all/0/1\">Can Alkan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mutlu_O/0/1/0/all/0/1\">Onur Mutlu</a>",
          "description": "Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling\ncomputationally-inefficient and memory-hungry; bottlenecking the entire genome\nanalysis pipeline. However, for many applications, the majority of reads do no\nmatch the reference genome of interest (i.e., target reference) and thus are\ndiscarded in later steps in the genomics pipeline, wasting the basecalling\ncomputation. To overcome this issue, we propose TargetCall, the first\npre-basecalling filter to eliminate the wasted computation in basecalling.\nTargetCall's key idea is to discard reads that will not match the target\nreference (i.e., off-target reads) prior to basecalling. TargetCall consists of\ntwo main components: (1) LightCall, a lightweight neural network basecaller\nthat produces noisy reads; and (2) Similarity Check, which labels each of these\nnoisy reads as on-target or off-target by matching them to the target\nreference. TargetCall aims to filter out all off-target reads before\nbasecalling. The highly-accurate but slow basecalling is performed only on the\nraw signals whose noisy reads are labeled as on-target. Our thorough\nexperimental evaluations using both real and simulated data show that\nTargetCall 1) improves the end-to-end basecalling performance while maintaining\nhigh sensitivity in keeping on-target reads, 2) maintains high accuracy in\ndownstream analysis, 3) precisely filters out up to 94.71% of off-target reads,\nand 4) achieves better performance, throughput, sensitivity, precision, and\ngenerality compared to prior works. We open-source TargetCall at\nhttps://github.com/CMU-SAFARI/TargetCall",
          "link": "http://arxiv.org/abs/2212.04953",
          "publishedOn": "2023-09-16T00:40:55.822Z",
          "wordCount": 793,
          "title": "TargetCall: Eliminating the Wasted Computation in Basecalling via Pre-Basecalling Filtering. (arXiv:2212.04953v2 [q-bio.GN] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.10520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lehner_J/0/1/0/all/0/1\">Johannes Lehner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkin_B/0/1/0/all/0/1\">Benedikt Alkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furst_A/0/1/0/all/0/1\">Andreas F&#xfc;rst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rumetshofer_E/0/1/0/all/0/1\">Elisabeth Rumetshofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miklautz_L/0/1/0/all/0/1\">Lukas Miklautz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>",
          "description": "Masked Image Modeling (MIM) methods, like Masked Autoencoders (MAE),\nefficiently learn a rich representation of the input. However, for adapting to\ndownstream tasks, they require a sufficient amount of labeled data since their\nrich features code not only objects but also less relevant image background. In\ncontrast, Instance Discrimination (ID) methods focus on objects. In this work,\nwe study how to combine the efficiency and scalability of MIM with the ability\nof ID to perform downstream classification in the absence of large amounts of\nlabeled data. To this end, we introduce Masked Autoencoder Contrastive Tuning\n(MAE-CT), a sequential approach that utilizes the implicit clustering of the\nNearest Neighbor Contrastive Learning (NNCLR) objective to induce abstraction\nin the topmost layers of a pre-trained MAE. MAE-CT tunes the rich features such\nthat they form semantic clusters of objects without using any labels. Notably,\nMAE-CT does not rely on hand-crafted augmentations and frequently achieves its\nbest performances while using only minimal augmentations (crop & flip).\nFurther, MAE-CT is compute efficient as it requires at most 10% overhead\ncompared to MAE re-training. Applied to large and huge Vision Transformer (ViT)\nmodels, MAE-CT excels over previous self-supervised methods trained on ImageNet\nin linear probing, k-NN and low-shot classification accuracy as well as in\nunsupervised clustering accuracy. With ViT-H/16 MAE-CT achieves a new\nstate-of-the-art in linear probing of 82.2%.",
          "link": "http://arxiv.org/abs/2304.10520",
          "publishedOn": "2023-09-16T00:40:55.810Z",
          "wordCount": 782,
          "title": "Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget. (arXiv:2304.10520v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07250",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+East_R/0/1/0/all/0/1\">Richard D. P. East</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Alonso_Linaje_G/0/1/0/all/0/1\">Guillermo Alonso-Linaje</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Park_C/0/1/0/all/0/1\">Chae-Yeun Park</a>",
          "description": "Variational algorithms require architectures that naturally constrain the\noptimisation space to run efficiently. In geometric quantum machine learning,\none achieves this by encoding group structure into parameterised quantum\ncircuits to include the symmetries of a problem as an inductive bias. However,\nconstructing such circuits is challenging as a concrete guiding principle has\nyet to emerge. In this paper, we propose the use of spin networks, a form of\ndirected tensor network invariant under a group transformation, to devise SU(2)\nequivariant quantum circuit ans\\\"atze -- circuits possessing spin rotation\nsymmetry. By changing to the basis that block diagonalises SU(2) group action,\nthese networks provide a natural building block for constructing parameterised\nequivariant quantum circuits. We prove that our construction is mathematically\nequivalent to other known constructions, such as those based on twirling and\ngeneralised permutations, but more direct to implement on quantum hardware. The\nefficacy of our constructed circuits is tested by solving the ground state\nproblem of SU(2) symmetric Heisenberg models on the one-dimensional triangular\nlattice and on the Kagome lattice. Our results highlight that our equivariant\ncircuits boost the performance of quantum variational algorithms, indicating\nbroader applicability to other real-world problems.",
          "link": "http://arxiv.org/abs/2309.07250",
          "publishedOn": "2023-09-16T00:40:55.794Z",
          "wordCount": 729,
          "title": "All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks. (arXiv:2309.07250v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14131",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1\">Shengchao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shu_T/0/1/0/all/0/1\">Ting Shu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_H/0/1/0/all/0/1\">Huan Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhong_G/0/1/0/all/0/1\">Guo Zhong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xunlai Chen</a>",
          "description": "Meteorological radar reflectivity data (i.e. radar echo) significantly\ninfluences precipitation prediction. It can facilitate accurate and expeditious\nforecasting of short-term heavy rainfall bypassing the need for complex\nNumerical Weather Prediction (NWP) models. In comparison to conventional\nmodels, Deep Learning (DL)-based radar echo extrapolation algorithms exhibit\nhigher effectiveness and efficiency. Nevertheless, the development of reliable\nand generalized echo extrapolation algorithm is impeded by three primary\nchallenges: cumulative error spreading, imprecise representation of sparsely\ndistributed echoes, and inaccurate description of non-stationary motion\nprocesses. To tackle these challenges, this paper proposes a novel radar echo\nextrapolation algorithm called Temporal-Spatial Parallel Transformer, referred\nto as TempEE. TempEE avoids using auto-regression and instead employs a\none-step forward strategy to prevent cumulative error spreading during the\nextrapolation process. Additionally, we propose the incorporation of a\nMulti-level Temporal-Spatial Attention mechanism to improve the algorithm's\ncapability of capturing both global and local information while emphasizing\ntask-related regions, including sparse echo representations, in an efficient\nmanner. Furthermore, the algorithm extracts spatio-temporal representations\nfrom continuous echo images using a parallel encoder to model the\nnon-stationary motion process for echo extrapolation. The superiority of our\nTempEE has been demonstrated in the context of the classic radar echo\nextrapolation task, utilizing a real-world dataset. Extensive experiments have\nfurther validated the efficacy and indispensability of various components\nwithin TempEE.",
          "link": "http://arxiv.org/abs/2304.14131",
          "publishedOn": "2023-09-16T00:40:55.786Z",
          "wordCount": 774,
          "title": "TempEE: Temporal-Spatial Parallel Transformer for Radar Echo Extrapolation Beyond Auto-Regression. (arXiv:2304.14131v2 [eess.SP] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.01726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Escobar_Bach_M/0/1/0/all/0/1\">Mikael Escobar-Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goudet_O/0/1/0/all/0/1\">Olivier Goudet</a>",
          "description": "In the presence of right-censored data with covariates, the conditional\nKaplan-Meier estimator (also known as the Beran estimator) consistently\nestimates the conditional survival function of the random follow-up for the\nevent of interest. However, a necessary condition is the unambiguous knowledge\nof whether each individual is censored or not, which may be incomplete in\npractice. We therefore propose a study of the Beran estimator when the\ncensoring indicators are generic random variables and discuss necessary\nconditions for the efficiency of the Beran estimator. From this, we provide a\nnew estimator for the conditional survival function with missing not at random\n(MNAR) censoring indicators based on a conditional copula model for the\nmissingness mechanism. In addition to the theoretical results, we illustrate\nhow the estimators work for small samples through a simulation study and show\ntheir practical applicability by analyzing synthetic and real data.",
          "link": "http://arxiv.org/abs/2009.01726",
          "publishedOn": "2023-09-16T00:40:55.687Z",
          "wordCount": 673,
          "title": "Survival Estimation for Missing not at Random Censoring Indicators based on Copula Models. (arXiv:2009.01726v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07602",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klenitskiy_A/0/1/0/all/0/1\">Anton Klenitskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilev_A/0/1/0/all/0/1\">Alexey Vasilev</a>",
          "description": "Recently sequential recommendations and next-item prediction task has become\nincreasingly popular in the field of recommender systems. Currently, two\nstate-of-the-art baselines are Transformer-based models SASRec and BERT4Rec.\nOver the past few years, there have been quite a few publications comparing\nthese two algorithms and proposing new state-of-the-art models. In most of the\npublications, BERT4Rec achieves better performance than SASRec. But BERT4Rec\nuses cross-entropy over softmax for all items, while SASRec uses negative\nsampling and calculates binary cross-entropy loss for one positive and one\nnegative item. In our work, we show that if both models are trained with the\nsame loss, which is used by BERT4Rec, then SASRec will significantly outperform\nBERT4Rec both in terms of quality and training speed. In addition, we show that\nSASRec could be effectively trained with negative sampling and still outperform\nBERT4Rec, but the number of negative examples should be much larger than one.",
          "link": "http://arxiv.org/abs/2309.07602",
          "publishedOn": "2023-09-16T00:40:55.653Z",
          "wordCount": 669,
          "title": "Turning Dross Into Gold Loss: is BERT4Rec really better than SASRec?. (arXiv:2309.07602v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klemen_M/0/1/0/all/0/1\">Maximiliano Klemen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carreira_Perpinan_M/0/1/0/all/0/1\">Miguel &#xc1;. Carreira-Perpi&#xf1;&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Garcia_P/0/1/0/all/0/1\">Pedro Lopez-Garcia</a>",
          "description": "Automatic static cost analysis infers information about the resources used by\nprograms without actually running them with concrete data, and presents such\ninformation as functions of input data sizes. Most of the analysis tools for\nlogic programs (and other languages) are based on setting up recurrence\nrelations representing (bounds on) the computational cost of predicates, and\nsolving them to find closed-form functions that are equivalent to (or a bound\non) them. Such recurrence solving is a bottleneck in current tools: many of the\nrecurrences that arise during the analysis cannot be solved with current\nsolvers, such as Computer Algebra Systems (CASs), so that specific methods for\ndifferent classes of recurrences need to be developed. We address such a\nchallenge by developing a novel, general approach for solving arbitrary,\nconstrained recurrence relations, that uses machine-learning sparse regression\ntechniques to guess a candidate closed-form function, and a combination of an\nSMT-solver and a CAS to check whether such function is actually a solution of\nthe recurrence. We have implemented a prototype and evaluated it with\nrecurrences generated by a cost analysis system (the one in CiaoPP). The\nexperimental results are quite promising, showing that our approach can find\nclosed-form solutions, in a reasonable time, for classes of recurrences that\ncannot be solved by such a system, nor by current CASs.",
          "link": "http://arxiv.org/abs/2309.07259",
          "publishedOn": "2023-09-16T00:40:55.637Z",
          "wordCount": 762,
          "title": "Solving Recurrence Relations using Machine Learning, with Application to Cost Analysis. (arXiv:2309.07259v1 [cs.PL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasircioglu_B/0/1/0/all/0/1\">Burak Hasircioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz Gunduz</a>",
          "description": "The task of preserving privacy while ensuring efficient communication is a\nfundamental challenge in federated learning. In this work, we tackle this\nchallenge in the trusted aggregator model, and propose a solution that achieves\nboth objectives simultaneously. We show that employing a quantization scheme\nbased on subtractive dithering at the clients can effectively replicate the\nnormal noise addition process at the aggregator. This implies that we can\nguarantee the same level of differential privacy against other clients while\nsubstantially reducing the amount of communication required, as opposed to\ntransmitting full precision gradients and using central noise addition. We also\nexperimentally demonstrate that the accuracy of our proposed approach matches\nthat of the full precision gradient method.",
          "link": "http://arxiv.org/abs/2309.07809",
          "publishedOn": "2023-09-16T00:40:55.620Z",
          "wordCount": 616,
          "title": "Communication Efficient Private Federated Learning Using Dithering. (arXiv:2309.07809v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mollers_A/0/1/0/all/0/1\">Alexander M&#xf6;llers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Immer_A/0/1/0/all/0/1\">Alexander Immer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isufi_E/0/1/0/all/0/1\">Elvin Isufi</a>",
          "description": "Simplicial complexes prove effective in modeling data with multiway\ndependencies, such as data defined along the edges of networks or within other\nhigher-order structures. Their spectrum can be decomposed into three\ninterpretable subspaces via the Hodge decomposition, resulting foundational in\nnumerous applications. We leverage this decomposition to develop a contrastive\nself-supervised learning approach for processing simplicial data and generating\nembeddings that encapsulate specific spectral information.Specifically, we\nencode the pertinent data invariances through simplicial neural networks and\ndevise augmentations that yield positive contrastive examples with suitable\nspectral properties for downstream tasks. Additionally, we reweight the\nsignificance of negative examples in the contrastive loss, considering the\nsimilarity of their Hodge components to the anchor. By encouraging a stronger\nseparation among less similar instances, we obtain an embedding space that\nreflects the spectral properties of the data. The numerical results on two\nstandard edge flow classification tasks show a superior performance even when\ncompared to supervised learning techniques. Our findings underscore the\nimportance of adopting a spectral perspective for contrastive learning with\nhigher-order data.",
          "link": "http://arxiv.org/abs/2309.07364",
          "publishedOn": "2023-09-16T00:40:55.549Z",
          "wordCount": 666,
          "title": "Hodge-Aware Contrastive Learning. (arXiv:2309.07364v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07770",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Yi_J/0/1/0/all/0/1\">Jianming Yi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Suresh_K/0/1/0/all/0/1\">Kalyani Suresh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Moghiseh_A/0/1/0/all/0/1\">Ali Moghiseh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wehn_N/0/1/0/all/0/1\">Norbert Wehn</a>",
          "description": "Quantum Support Vector Machines (QSVM) play a vital role in using quantum\nresources for supervised machine learning tasks, such as classification.\nHowever, current methods are strongly limited in terms of scalability on Noisy\nIntermediate Scale Quantum (NISQ) devices. In this work, we propose a novel\napproach called the Variational Quantum Linear Solver (VQLS) enhanced QSVM.\nThis is built upon our idea of utilizing the variational quantum linear solver\nto solve system of linear equations of a least squares-SVM on a NISQ device.\nThe implementation of our approach is evaluated by an extensive series of\nnumerical experiments with the Iris dataset, which consists of three distinct\niris plant species. Based on this, we explore the practicality and\neffectiveness of our algorithm by constructing a classifier capable of\nclassification in a feature space ranging from one to seven dimensions.\nFurthermore, by strategically exploiting both classical and quantum computing\nfor various subroutines of our algorithm, we effectively mitigate practical\nchallenges associated with the implementation. These include significant\nimprovement in the trainability of the variational ansatz and notable\nreductions in run-time for cost calculations. Based on the numerical\nexperiments, our approach exhibits the capability of identifying a separating\nhyperplane in an 8-dimensional feature space. Moreover, it consistently\ndemonstrated strong performance across various instances with the same dataset.",
          "link": "http://arxiv.org/abs/2309.07770",
          "publishedOn": "2023-09-16T00:40:55.543Z",
          "wordCount": 717,
          "title": "Variational Quantum Linear Solver enhanced Quantum Support Vector Machine. (arXiv:2309.07770v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.11721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Donahue_K/0/1/0/all/0/1\">Kate Donahue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollapudi_S/0/1/0/all/0/1\">Sreenivas Gollapudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollias_K/0/1/0/all/0/1\">Kostas Kollias</a>",
          "description": "Historically, much of machine learning research has focused on the\nperformance of the algorithm alone, but recently more attention has been\nfocused on optimizing joint human-algorithm performance. Here, we analyze a\nspecific type of human-algorithm collaboration where the algorithm has access\nto a set of $n$ items, and presents a subset of size $k$ to the human, who\nselects a final item from among those $k$. This scenario could model content\nrecommendation, route planning, or any type of labeling task. Because both the\nhuman and algorithm have imperfect, noisy information about the true ordering\nof items, the key question is: which value of $k$ maximizes the probability\nthat the best item will be ultimately selected? For $k=1$, performance is\noptimized by the algorithm acting alone, and for $k=n$ it is optimized by the\nhuman acting alone. Surprisingly, we show that for multiple of noise models, it\nis optimal to set $k \\in [2, n-1]$ - that is, there are strict benefits to\ncollaborating, even when the human and algorithm have equal accuracy\nseparately. We demonstrate this theoretically for the Mallows model and\nexperimentally for the Random Utilities models of noisy permutations. However,\nwe show this pattern is reversed when the human is anchored on the algorithm's\npresented ordering - the joint system always has strictly worse performance. We\nextend these results to the case where the human and algorithm differ in their\naccuracy levels, showing that there always exist regimes where a more accurate\nagent would strictly benefit from collaborating with a less accurate one, but\nthese regimes are asymmetric between the human and the algorithm's accuracy.",
          "link": "http://arxiv.org/abs/2308.11721",
          "publishedOn": "2023-09-16T00:40:55.527Z",
          "wordCount": 813,
          "title": "When Are Two Lists Better than One?: Benefits and Harms in Joint Decision-making. (arXiv:2308.11721v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07188",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lillelund_C/0/1/0/all/0/1\">Christian Marius Lillelund</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pannullo_F/0/1/0/all/0/1\">Fernando Pannullo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jakobsen_M/0/1/0/all/0/1\">Morten Opprud Jakobsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedersen_C/0/1/0/all/0/1\">Christian Fischer Pedersen</a>",
          "description": "Ball bearings find widespread use in various manufacturing and mechanical\ndomains, and methods based on machine learning have been widely adopted in the\nfield to monitor wear and spot defects before they lead to failures. Few\nstudies, however, have addressed the problem of censored data, in which failure\nis not observed. In this paper, we propose a novel approach to predict the time\nto failure in ball bearings using survival analysis. First, we analyze bearing\ndata in the frequency domain and annotate when a bearing fails by comparing the\nKullback-Leibler divergence and the standard deviation between its break-in\nfrequency bins and its break-out frequency bins. Second, we train several\nsurvival models to estimate the time to failure based on the annotated data and\ncovariates extracted from the time domain, such as skewness, kurtosis and\nentropy. The models give a probabilistic prediction of risk over time and allow\nus to compare the survival function between groups of bearings. We demonstrate\nour approach on the XJTU and PRONOSTIA datasets. On XJTU, the best result is a\n0.70 concordance-index and 0.21 integrated Brier score. On PRONOSTIA, the best\nis a 0.76 concordance-index and 0.19 integrated Brier score. Our work motivates\nfurther work on incorporating censored data in models for predictive\nmaintenance.",
          "link": "http://arxiv.org/abs/2309.07188",
          "publishedOn": "2023-09-16T00:40:55.521Z",
          "wordCount": 741,
          "title": "Predicting Survival Time of Ball Bearings in the Presence of Censoring. (arXiv:2309.07188v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.01952",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1\">Mihaela Rosca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qin_C/0/1/0/all/0/1\">Chongli Qin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dherin_B/0/1/0/all/0/1\">Benoit Dherin</a>",
          "description": "The recipe behind the success of deep learning has been the combination of\nneural networks and gradient-based optimization. Understanding the behavior of\ngradient descent however, and particularly its instability, has lagged behind\nits empirical success. To add to the theoretical tools available to study\ngradient descent we propose the principal flow (PF), a continuous time flow\nthat approximates gradient descent dynamics. To our knowledge, the PF is the\nonly continuous flow that captures the divergent and oscillatory behaviors of\ngradient descent, including escaping local minima and saddle points. Through\nits dependence on the eigendecomposition of the Hessian the PF sheds light on\nthe recently observed edge of stability phenomena in deep learning. Using our\nnew understanding of instability we propose a learning rate adaptation method\nwhich enables us to control the trade-off between training stability and test\nset evaluation performance.",
          "link": "http://arxiv.org/abs/2302.01952",
          "publishedOn": "2023-09-16T00:40:55.516Z",
          "wordCount": 705,
          "title": "On a continuous time model of gradient descent dynamics and instability in deep learning. (arXiv:2302.01952v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Federici_M/0/1/0/all/0/1\">Marco Federici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomioka_R/0/1/0/all/0/1\">Ryota Tomioka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeling_B/0/1/0/all/0/1\">Bastiaan S. Veeling</a>",
          "description": "Markov processes are widely used mathematical models for describing dynamic\nsystems in various fields. However, accurately simulating large-scale systems\nat long time scales is computationally expensive due to the short time steps\nrequired for accurate integration. In this paper, we introduce an inference\nprocess that maps complex systems into a simplified representational space and\nmodels large jumps in time. To achieve this, we propose Time-lagged Information\nBottleneck (T-IB), a principled objective rooted in information theory, which\naims to capture relevant temporal features while discarding high-frequency\ninformation to simplify the simulation task and minimize the inference error.\nOur experiments demonstrate that T-IB learns information-optimal\nrepresentations for accurately modeling the statistical properties and dynamics\nof the original process at a selected time lag, outperforming existing\ntime-lagged dimensionality reduction methods.",
          "link": "http://arxiv.org/abs/2309.07200",
          "publishedOn": "2023-09-16T00:40:55.493Z",
          "wordCount": 657,
          "title": "Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck. (arXiv:2309.07200v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Braun_J/0/1/0/all/0/1\">Jona Braun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christen_S/0/1/0/all/0/1\">Sammy Christen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocabas_M/0/1/0/all/0/1\">Muhammed Kocabas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aksan_E/0/1/0/all/0/1\">Emre Aksan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "We propose a physics-based method for synthesizing dexterous hand-object\ninteractions in a full-body setting. While recent advancements have addressed\nspecific facets of human-object interactions, a comprehensive physics-based\napproach remains a challenge. Existing methods often focus on isolated segments\nof the interaction process and rely on data-driven techniques that may result\nin artifacts. In contrast, our proposed method embraces reinforcement learning\n(RL) and physics simulation to mitigate the limitations of data-driven\napproaches. Through a hierarchical framework, we first learn skill priors for\nboth body and hand movements in a decoupled setting. The generic skill priors\nlearn to decode a latent skill embedding into the motion of the underlying\npart. A high-level policy then controls hand-object interactions in these\npretrained latent spaces, guided by task objectives of grasping and 3D target\ntrajectory following. It is trained using a novel reward function that combines\nan adversarial style term with a task reward, encouraging natural motions while\nfulfilling the task incentives. Our method successfully accomplishes the\ncomplete interaction task, from approaching an object to grasping and\nsubsequent manipulation. We compare our approach against kinematics-based\nbaselines and show that it leads to more physically plausible motions.",
          "link": "http://arxiv.org/abs/2309.07907",
          "publishedOn": "2023-09-16T00:40:55.477Z",
          "wordCount": 695,
          "title": "Physically Plausible Full-Body Hand-Object Interaction Synthesis. (arXiv:2309.07907v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinckney_N/0/1/0/all/0/1\">Nathaniel Pinckney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khailany_B/0/1/0/all/0/1\">Brucek Khailany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haoxing Ren</a>",
          "description": "The increasing popularity of large language models (LLMs) has paved the way\nfor their application in diverse domains. This paper proposes a benchmarking\nframework tailored specifically for evaluating LLM performance in the context\nof Verilog code generation for hardware design and verification. We present a\ncomprehensive evaluation dataset consisting of 156 problems from the Verilog\ninstructional website HDLBits. The evaluation set consists of a diverse set of\nVerilog code generation tasks, ranging from simple combinational circuits to\ncomplex finite state machines. The Verilog code completions can be\nautomatically tested for functional correctness by comparing the transient\nsimulation outputs of the generated design with a golden solution. We also\ndemonstrate that the Verilog code generation capability of pretrained language\nmodels could be improved with supervised fine-tuning by bootstrapping with LLM\ngenerated synthetic problem-code pairs.",
          "link": "http://arxiv.org/abs/2309.07544",
          "publishedOn": "2023-09-16T00:40:55.456Z",
          "wordCount": 647,
          "title": "VerilogEval: Evaluating Large Language Models for Verilog Code Generation. (arXiv:2309.07544v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.00085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bilik_S/0/1/0/all/0/1\">Simon Bilik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zemcik_T/0/1/0/all/0/1\">Tomas Zemcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kratochvila_L/0/1/0/all/0/1\">Lukas Kratochvila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ricanek_D/0/1/0/all/0/1\">Dominik Ricanek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richter_M/0/1/0/all/0/1\">Milos Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zambanini_S/0/1/0/all/0/1\">Sebastian Zambanini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horak_K/0/1/0/all/0/1\">Karel Horak</a>",
          "description": "Wide use and availability of the machine learning and computer vision\ntechniques allows development of relatively complex monitoring systems in many\ndomains. Besides the traditional industrial domain, new application appears\nalso in biology and agriculture, where we could speak about the detection of\ninfections, parasites and weeds, but also about automated monitoring and early\nwarning systems. This is also connected with the introduction of the easily\naccessible hardware and development kits such as Arduino, or RaspberryPi\nfamily. In this paper, we survey 50 existing papers focusing on the methods of\nautomated beehive monitoring methods using the computer vision techniques,\nparticularly on the pollen and Varroa mite detection together with the bee\ntraffic monitoring. Such systems could also be used for the monitoring of the\nhoneybee colonies and for the inspection of their health state, which could\nidentify potentially dangerous states before the situation is critical, or to\nbetter plan periodic bee colony inspections and therefore save significant\ncosts. Later, we also include analysis of the research trends in this\napplication field and we outline the possible direction of the new\nexplorations. Our paper is aimed also at veterinary and apidology professionals\nand experts, who might not be familiar with machine learning to introduce them\nto its possibilities, therefore each family of applications is opened by a\nbrief theoretical introduction and motivation related to its base method. We\nhope that this paper will inspire other scientists to use machine learning\ntechniques for other applications in beehive monitoring.",
          "link": "http://arxiv.org/abs/2208.00085",
          "publishedOn": "2023-09-16T00:40:55.451Z",
          "wordCount": 806,
          "title": "Machine Learning and Computer Vision Techniques in Continuous Beehive Monitoring Applications: A survey. (arXiv:2208.00085v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13348",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ishikawa_K/0/1/0/all/0/1\">Kei Ishikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_N/0/1/0/all/0/1\">Niao He</a>",
          "description": "We study policy evaluation of offline contextual bandits subject to\nunobserved confounders. Sensitivity analysis methods are commonly used to\nestimate the policy value under the worst-case confounding over a given\nuncertainty set. However, existing work often resorts to some coarse relaxation\nof the uncertainty set for the sake of tractability, leading to overly\nconservative estimation of the policy value. In this paper, we propose a\ngeneral estimator that provides a sharp lower bound of the policy value. It can\nbe shown that our estimator contains the recently proposed sharp estimator by\nDorn and Guo (2022) as a special case, and our method enables a novel extension\nof the classical marginal sensitivity model using f-divergence. To construct\nour estimator, we leverage the kernel method to obtain a tractable\napproximation to the conditional moment constraints, which traditional\nnon-sharp estimators failed to take into account. In the theoretical analysis,\nwe provide a condition for the choice of the kernel which guarantees no\nspecification error that biases the lower bound estimation. Furthermore, we\nprovide consistency guarantees of policy evaluation and learning. In the\nexperiments with synthetic and real-world data, we demonstrate the\neffectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2302.13348",
          "publishedOn": "2023-09-16T00:40:55.445Z",
          "wordCount": 705,
          "title": "Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Michael J. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleming_L/0/1/0/all/0/1\">Luke Fleming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geach_J/0/1/0/all/0/1\">James E. Geach</a>",
          "description": "We introduce EarthPT -- an Earth Observation (EO) pretrained transformer.\nEarthPT is a 700 million parameter decoding transformer foundation model\ntrained in an autoregressive self-supervised manner and developed specifically\nwith EO use-cases in mind. We demonstrate that EarthPT is an effective\nforecaster that can accurately predict future pixel-level surface reflectances\nacross the 400-2300 nm range well into the future. For example, forecasts of\nthe evolution of the Normalised Difference Vegetation Index (NDVI) have a\ntypical error of approximately 0.05 (over a natural range of -1 -> 1) at the\npixel level over a five month test set horizon, out-performing simple\nphase-folded models based on historical averaging. We also demonstrate that\nembeddings learnt by EarthPT hold semantically meaningful information and could\nbe exploited for downstream tasks such as highly granular, dynamic land use\nclassification. Excitingly, we note that the abundance of EO data provides us\nwith -- in theory -- quadrillions of training tokens. Therefore, if we assume\nthat EarthPT follows neural scaling laws akin to those derived for Large\nLanguage Models (LLMs), there is currently no data-imposed limit to scaling\nEarthPT and other similar `Large Observation Models.'",
          "link": "http://arxiv.org/abs/2309.07207",
          "publishedOn": "2023-09-16T00:40:55.429Z",
          "wordCount": 700,
          "title": "EarthPT: a foundation model for Earth Observation. (arXiv:2309.07207v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kicki_P/0/1/0/all/0/1\">Piotr Kicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bidzinski_M/0/1/0/all/0/1\">Micha&#x142; Bidzi&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walas_K/0/1/0/all/0/1\">Krzysztof Walas</a>",
          "description": "The robotic manipulation of Deformable Linear Objects (DLOs) is a vital and\nchallenging task that is important in many practical applications. Classical\nmodel-based approaches to this problem require an accurate model to capture how\nrobot motions affect the deformation of the DLO. Nowadays, data-driven models\noffer the best tradeoff between quality and computation time. This paper\nanalyzes several learning-based 3D models of the DLO and proposes a new one\nbased on the Transformer architecture that achieves superior accuracy, even on\nthe DLOs of different lengths, thanks to the proposed scaling method. Moreover,\nwe introduce a data augmentation technique, which improves the prediction\nperformance of almost all considered DLO data-driven models. Thanks to this\ntechnique, even a simple Multilayer Perceptron (MLP) achieves close to\nstate-of-the-art performance while being significantly faster to evaluate. In\nthe experiments, we compare the performance of the learning-based 3D models of\nthe DLO on several challenging datasets quantitatively and demonstrate their\napplicability in the task of shaping a DLO.",
          "link": "http://arxiv.org/abs/2309.07609",
          "publishedOn": "2023-09-16T00:40:55.424Z",
          "wordCount": 691,
          "title": "Learning Quasi-Static 3D Models of Markerless Deformable Linear Objects for Bimanual Robotic Manipulation. (arXiv:2309.07609v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.03609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Junfeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>",
          "description": "While real-world applications of reinforcement learning are becoming popular,\nthe security and robustness of RL systems are worthy of more attention and\nexploration. In particular, recent works have revealed that, in a multi-agent\nRL environment, backdoor trigger actions can be injected into a victim agent\n(a.k.a. Trojan agent), which can result in a catastrophic failure as soon as it\nsees the backdoor trigger action. To ensure the security of RL agents against\nmalicious backdoors, in this work, we propose the problem of Backdoor Detection\nin a multi-agent competitive reinforcement learning system, with the objective\nof detecting Trojan agents as well as the corresponding potential trigger\nactions, and further trying to mitigate their Trojan behavior. In order to\nsolve this problem, we propose PolicyCleanse that is based on the property that\nthe activated Trojan agents accumulated rewards degrade noticeably after\nseveral timesteps. Along with PolicyCleanse, we also design a machine\nunlearning-based approach that can effectively mitigate the detected backdoor.\nExtensive experiments demonstrate that the proposed methods can accurately\ndetect Trojan agents, and outperform existing backdoor mitigation baseline\napproaches by at least 3% in winning rate across various types of agents and\nenvironments.",
          "link": "http://arxiv.org/abs/2202.03609",
          "publishedOn": "2023-09-16T00:40:55.418Z",
          "wordCount": 756,
          "title": "PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement Learning. (arXiv:2202.03609v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yeachan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_B/0/1/0/all/0/1\">Bonggun Shin</a>",
          "description": "Federated learning algorithms perform reasonably well on independent and\nidentically distributed (IID) data. They, on the other hand, suffer greatly\nfrom heterogeneous environments, i.e., Non-IID data. Despite the fact that many\nresearch projects have been done to address this issue, recent findings\nindicate that they are still sub-optimal when compared to training on IID data.\nIn this work, we carefully analyze the existing methods in heterogeneous\nenvironments. Interestingly, we find that regularizing the classifier's outputs\nis quite effective in preventing performance degradation on Non-IID data.\nMotivated by this, we propose Learning from Drift (LfD), a novel method for\neffectively training the model in heterogeneous settings. Our scheme\nencapsulates two key components: drift estimation and drift regularization.\nSpecifically, LfD first estimates how different the local model is from the\nglobal model (i.e., drift). The local model is then regularized such that it\ndoes not fall in the direction of the estimated drift. In the experiment, we\nevaluate each method through the lens of the five aspects of federated\nlearning, i.e., Generalization, Heterogeneity, Scalability, Forgetting, and\nEfficiency. Comprehensive evaluation results clearly support the superiority of\nLfD in federated learning with Non-IID data.",
          "link": "http://arxiv.org/abs/2309.07189",
          "publishedOn": "2023-09-16T00:40:55.406Z",
          "wordCount": 699,
          "title": "Learning From Drift: Federated Learning on Non-IID Data via Drift Regularization. (arXiv:2309.07189v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2110.12539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strong_M/0/1/0/all/0/1\">Marek Strong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohnke_J/0/1/0/all/0/1\">Jonas Rohnke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonafonte_A/0/1/0/all/0/1\">Antonio Bonafonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lajszczak_M/0/1/0/all/0/1\">Mateusz &#x141;ajszczak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_T/0/1/0/all/0/1\">Trevor Wood</a>",
          "description": "We present a Split Vector Quantized Variational Autoencoder (SVQ-VAE)\narchitecture using a split vector quantizer for NTTS, as an enhancement to the\nwell-known Variational Autoencoder (VAE) and Vector Quantized Variational\nAutoencoder (VQ-VAE) architectures. Compared to these previous architectures,\nour proposed model retains the benefits of using an utterance-level bottleneck,\nwhile keeping significant representation power and a discretized latent space\nsmall enough for efficient prediction from text. We train the model on\nrecordings in the expressive task-oriented dialogues domain and show that\nSVQ-VAE achieves a statistically significant improvement in naturalness over\nthe VAE and VQ-VAE models. Furthermore, we demonstrate that the SVQ-VAE latent\nacoustic space is predictable from text, reducing the gap between the standard\nconstant vector synthesis and vocoded recordings by 32%.",
          "link": "http://arxiv.org/abs/2110.12539",
          "publishedOn": "2023-09-16T00:40:55.390Z",
          "wordCount": 695,
          "title": "Discrete Acoustic Space for an Efficient Sampling in Neural Text-To-Speech. (arXiv:2110.12539v3 [cs.SD] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07133",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sakal_C/0/1/0/all/0/1\">Collin Sakal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Tingyou Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Juan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xinyue Li</a>",
          "description": "Conducting cognitive tests is time-consuming for patients and clinicians.\nWearable device-based prediction models allow for continuous health monitoring\nunder normal living conditions and could offer an alternative to identifying\nolder adults with cognitive impairments for early interventions. In this study,\nwe first derived novel wearable-based features related to circadian rhythms,\nambient light exposure, physical activity levels, sleep, and signal processing.\nThen, we quantified the ability of wearable-based machine-learning models to\npredict poor cognition based on outcomes from the Digit Symbol Substitution\nTest (DSST), the Consortium to Establish a Registry for Alzheimers Disease\nWord-Learning subtest (CERAD-WL), and the Animal Fluency Test (AFT). We found\nthat the wearable-based models had significantly higher AUCs when predicting\nall three cognitive outcomes compared to benchmark models containing age, sex,\neducation, marital status, household income, diabetic status, depression\nsymptoms, and functional independence scores. In addition to uncovering\npreviously unidentified wearable-based features that are predictive of poor\ncognition such as the standard deviation of the midpoints of each persons most\nactive 10-hour periods and least active 5-hour periods, our paper provides\nproof-of-concept that wearable-based machine learning models can be used to\nautonomously screen older adults for possible cognitive impairments. Such\nmodels offer cost-effective alternatives to conducting initial screenings\nmanually in clinical settings.",
          "link": "http://arxiv.org/abs/2309.07133",
          "publishedOn": "2023-09-16T00:40:55.379Z",
          "wordCount": 733,
          "title": "Using wearable device-based machine learning models to autonomously identify older adults with poor cognition. (arXiv:2309.07133v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.08447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cuadrado_N/0/1/0/all/0/1\">Nicolas Cuadrado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1\">Roberto Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yongli Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1\">Martin Takac</a>",
          "description": "Integrating variable renewable energy into the grid has posed challenges to\nsystem operators in achieving optimal trade-offs among energy availability,\ncost affordability, and pollution controllability. This paper proposes a\nmulti-agent reinforcement learning framework for managing energy transactions\nin microgrids. The framework addresses the challenges above: it seeks to\noptimize the usage of available resources by minimizing the carbon footprint\nwhile benefiting all stakeholders. The proposed architecture consists of three\nlayers of agents, each pursuing different objectives. The first layer,\ncomprised of prosumers and consumers, minimizes the total energy cost. The\nother two layers control the energy price to decrease the carbon impact while\nbalancing the consumption and production of both renewable and conventional\nenergy. This framework also takes into account fluctuations in energy demand\nand supply.",
          "link": "http://arxiv.org/abs/2303.08447",
          "publishedOn": "2023-09-16T00:40:55.372Z",
          "wordCount": 671,
          "title": "MAHTM: A Multi-Agent Framework for Hierarchical Transactive Microgrids. (arXiv:2303.08447v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.04688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhou Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yunpeng Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junda He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jieke Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kecen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Arunesh Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bowen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_X/0/1/0/all/0/1\">Xinwen Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1\">David Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>",
          "description": "A growing body of research has focused on the Reinforcement Learning (RL)\nmethods which allow the agent to learn from trial-and-error experiences\ngathered during the interaction with the environment. Recently, offline RL\nbecomes a popular RL paradigm because it saves the interactions with\nenvironments. In offline RL, data providers share large pre-collected datasets,\nand others can train high-quality agents without interacting with the\nenvironments. This paradigm has demonstrated effectiveness in critical tasks\nlike robot control, autonomous driving, etc. However, less attention is paid to\ninvestigating the security threats to the offline RL system. This paper focuses\non backdoor attacks, where some perturbations are added to the data\n(observations) such that given normal observations, the agent takes\nhigh-rewards actions, and low-reward actions on observations injected with\ntriggers. In this paper, we propose Baffle (Backdoor Attack for Offline\nReinforcement Learning), an approach that automatically implants backdoors to\nRL agents by poisoning the offline RL dataset, and evaluate how different\noffline RL algorithms react to this attack. Our experiments conducted on four\ntasks and four offline RL algorithms expose a disquieting fact: none of the\nexisting offline RL algorithms is immune to such a backdoor attack. Baffle\nmodifies $10\\%$ of the datasets for four tasks. Agents trained on the poisoned\ndatasets perform well in normal settings. However, when triggers are presented,\nthe agents' performance decreases drastically by $63.2\\%$, $53.9\\%$, $64.7\\%$,\nand $47.4\\%$ in the four tasks on average. The backdoor still persists after\nfine-tuning poisoned agents on clean datasets. We further show that the\ninserted backdoor is also hard to be detected by a popular defensive method.\nThis paper calls attention to developing more effective protection for the\nopen-source offline RL dataset.",
          "link": "http://arxiv.org/abs/2210.04688",
          "publishedOn": "2023-09-16T00:40:55.367Z",
          "wordCount": 818,
          "title": "BAFFLE: Backdoor Attack in Offline Reinforcement Learning. (arXiv:2210.04688v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.06028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michael Y. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grant_E/0/1/0/all/0/1\">Erin Grant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1\">Thomas L. Griffiths</a>",
          "description": "Not being able to understand and predict the behavior of deep learning\nsystems makes it hard to decide what architecture and algorithm to use for a\ngiven problem. In science and engineering, modeling is a methodology used to\nunderstand complex systems whose internal processes are opaque. Modeling\nreplaces a complex system with a simpler, more interpretable surrogate. Drawing\ninspiration from this, we construct a class of surrogate models for neural\nnetworks using Gaussian processes. Rather than deriving kernels for infinite\nneural networks, we learn kernels empirically from the naturalistic behavior of\nfinite neural networks. We demonstrate our approach captures existing phenomena\nrelated to the spectral bias of neural networks, and then show that our\nsurrogate models can be used to solve practical problems such as identifying\nwhich points most influence the behavior of specific neural networks and\npredicting which architectures and algorithms will generalize well for specific\ndatasets.",
          "link": "http://arxiv.org/abs/2208.06028",
          "publishedOn": "2023-09-16T00:40:55.335Z",
          "wordCount": 676,
          "title": "Gaussian Process Surrogate Models for Neural Networks. (arXiv:2208.06028v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alecsa_C/0/1/0/all/0/1\">Cristian Daniel Alecsa</a>",
          "description": "In the present paper we introduce new optimization algorithms for the task of\ndensity ratio estimation. More precisely, we consider extending the well-known\nKMM method using the construction of a suitable loss function, in order to\nencompass more general situations involving the estimation of density ratio\nwith respect to subsets of the training data and test data, respectively. The\nassociated codes can be found at https://github.com/CDAlecsa/Generalized-KMM.",
          "link": "http://arxiv.org/abs/2309.07887",
          "publishedOn": "2023-09-16T00:40:55.324Z",
          "wordCount": 592,
          "title": "Some notes concerning a generalized KMM-type optimization method for density ratio estimation. (arXiv:2309.07887v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.04824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prokhorov_B/0/1/0/all/0/1\">Boris Prokhorov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koldasbayeva_D/0/1/0/all/0/1\">Diana Koldasbayeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>",
          "description": "In machine learning models, the estimation of errors is often complex due to\ndistribution bias, particularly in spatial data such as those found in\nenvironmental studies. We introduce an approach based on the ideas of\nimportance sampling to obtain an unbiased estimate of the target error. By\ntaking into account difference between desirable error and available data, our\nmethod reweights errors at each sample point and neutralizes the shift.\nImportance sampling technique and kernel density estimation were used for\nreweighteing. We validate the effectiveness of our approach using artificial\ndata that resemble real-world spatial datasets. Our findings demonstrate\nadvantages of the proposed approach for the estimation of the target error,\noffering a solution to a distribution shift problem. Overall error of\npredictions dropped from 7% to just 2% and it gets smaller for larger samples.",
          "link": "http://arxiv.org/abs/2309.04824",
          "publishedOn": "2023-09-16T00:40:55.297Z",
          "wordCount": 656,
          "title": "Correcting sampling biases via importance reweighting for spatial modeling. (arXiv:2309.04824v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.01029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angarano_S/0/1/0/all/0/1\">Simone Angarano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martini_M/0/1/0/all/0/1\">Mauro Martini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navone_A/0/1/0/all/0/1\">Alessandro Navone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1\">Marcello Chiaberge</a>",
          "description": "In recent years, precision agriculture has gradually oriented farming closer\nto automation processes to support all the activities related to field\nmanagement. Service robotics plays a predominant role in this evolution by\ndeploying autonomous agents that can navigate fields while performing tasks\nwithout human intervention, such as monitoring, spraying, and harvesting. To\nexecute these precise actions, mobile robots need a real-time perception system\nthat understands their surroundings and identifies their targets in the wild.\nGeneralizing to new crops and environmental conditions is critical for\npractical applications, as labeled samples are rarely available. In this paper,\nwe investigate the problem of crop segmentation and propose a novel approach to\nenhance domain generalization using knowledge distillation. In the proposed\nframework, we transfer knowledge from an ensemble of models individually\ntrained on source domains to a student model that can adapt to unseen target\ndomains. To evaluate the proposed method, we present a synthetic multi-domain\ndataset for crop segmentation containing plants of variegate shapes and\ncovering different terrain styles, weather conditions, and light scenarios for\nmore than 50,000 samples. We demonstrate significant improvements in\nperformance over state-of-the-art methods and superior sim-to-real\ngeneralization. Our approach provides a promising solution for domain\ngeneralization in crop segmentation and has the potential to enhance a wide\nvariety of precision agriculture applications.",
          "link": "http://arxiv.org/abs/2304.01029",
          "publishedOn": "2023-09-16T00:40:55.210Z",
          "wordCount": 735,
          "title": "Domain Generalization for Crop Segmentation with Knowledge Distillation. (arXiv:2304.01029v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaillard_P/0/1/0/all/0/1\">Pierre Gaillard</a> (Thoth), <a href=\"http://arxiv.org/find/cs/1/au:+Gerchinovitz_S/0/1/0/all/0/1\">S&#xe9;bastien Gerchinovitz</a> (IMT), <a href=\"http://arxiv.org/find/cs/1/au:+Montbrun_E/0/1/0/all/0/1\">&#xc9;tienne de Montbrun</a> (TSE-R)",
          "description": "We study the classical problem of approximating a non-decreasing function $f:\n\\mathcal{X} \\to \\mathcal{Y}$ in $L^p(\\mu)$ norm by sequentially querying its\nvalues, for known compact real intervals $\\mathcal{X}$, $\\mathcal{Y}$ and a\nknown probability measure $\\mu$ on $\\cX$. For any function~$f$ we characterize\nthe minimum number of evaluations of $f$ that algorithms need to guarantee an\napproximation $\\hat{f}$ with an $L^p(\\mu)$ error below $\\epsilon$ after\nstopping. Unlike worst-case results that hold uniformly over all $f$, our\ncomplexity measure is dependent on each specific function $f$. To address this\nproblem, we introduce GreedyBox, a generalization of an algorithm originally\nproposed by Novak (1992) for numerical integration. We prove that GreedyBox\nachieves an optimal sample complexity for any function $f$, up to logarithmic\nfactors. Additionally, we uncover results regarding piecewise-smooth functions.\nPerhaps as expected, the $L^p(\\mu)$ error of GreedyBox decreases much faster\nfor piecewise-$C^2$ functions than predicted by the algorithm (without any\nknowledge on the smoothness of $f$). A simple modification even achieves\noptimal minimax approximation rates for such functions, which we compute\nexplicitly. In particular, our findings highlight multiple performance gaps\nbetween adaptive and non-adaptive algorithms, smooth and piecewise-smooth\nfunctions, as well as monotone or non-monotone functions. Finally, we provide\nnumerical experiments to support our theoretical results.",
          "link": "http://arxiv.org/abs/2309.07530",
          "publishedOn": "2023-09-16T00:40:55.202Z",
          "wordCount": 708,
          "title": "Adaptive approximation of monotone functions. (arXiv:2309.07530v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.05845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wannan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiralerspong_T/0/1/0/all/0/1\">Thomas Jiralerspong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malenfant_D/0/1/0/all/0/1\">Dane Malenfant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alsbury_Nealy_B/0/1/0/all/0/1\">Benjamin Alsbury-Nealy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richards_B/0/1/0/all/0/1\">Blake Richards</a>",
          "description": "In real life, success is often contingent upon multiple critical steps that\nare distant in time from each other and from the final reward. These critical\nsteps are challenging to identify with traditional reinforcement learning (RL)\nmethods that rely on the Bellman equation for credit assignment. Here, we\npresent a new RL algorithm that uses offline contrastive learning to hone in on\ncritical steps. This algorithm, which we call contrastive introspection\n(ConSpec), can be added to any existing RL algorithm. ConSpec learns a set of\nprototypes for the critical steps in a task by a novel contrastive loss and\ndelivers an intrinsic reward when the current state matches one of these\nprototypes. The prototypes in ConSpec provide two key benefits for credit\nassignment: (1) They enable rapid identification of all the critical steps. (2)\nThey do so in a readily interpretable manner, enabling out-of-distribution\ngeneralization when sensory features are altered. Distinct from other\ncontemporary RL approaches to credit assignment, ConSpec takes advantage of the\nfact that it is easier to retrospectively identify the small set of steps that\nsuccess is contingent upon than it is to prospectively predict reward at every\nstep taken in the environment. Altogether, ConSpec improves learning in a\ndiverse set of RL tasks, including both those with explicit, discrete critical\nsteps and those with complex, continuous critical steps.",
          "link": "http://arxiv.org/abs/2210.05845",
          "publishedOn": "2023-09-16T00:40:55.196Z",
          "wordCount": 798,
          "title": "ConSpec: honing in on critical steps for rapid learning and generalization in RL. (arXiv:2210.05845v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yeqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weixin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junze Yin</a>",
          "description": "Large language models (LLMs) have played a pivotal role in revolutionizing\nvarious facets of our daily existence. Solving attention regression is a\nfundamental task in optimizing LLMs. In this work, we focus on giving a\nprovable guarantee for the one-layer attention network objective function\n$L(X,Y) = \\sum_{j_0 = 1}^n \\sum_{i_0 = 1}^d ( \\langle \\langle \\exp(\n\\mathsf{A}_{j_0} x ) , {\\bf 1}_n \\rangle^{-1} \\exp( \\mathsf{A}_{j_0} x ), A_{3}\nY_{*,i_0} \\rangle - b_{j_0,i_0} )^2$. Here $\\mathsf{A} \\in \\mathbb{R}^{n^2\n\\times d^2}$ is Kronecker product between $A_1 \\in \\mathbb{R}^{n \\times d}$ and\n$A_2 \\in \\mathbb{R}^{n \\times d}$. $A_3$ is a matrix in $\\mathbb{R}^{n \\times\nd}$, $\\mathsf{A}_{j_0} \\in \\mathbb{R}^{n \\times d^2}$ is the $j_0$-th block of\n$\\mathsf{A}$. The $X, Y \\in \\mathbb{R}^{d \\times d}$ are variables we want to\nlearn. $B \\in \\mathbb{R}^{n \\times d}$ and $b_{j_0,i_0} \\in \\mathbb{R}$ is one\nentry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \\in \\mathbb{R}^d$\nis the $i_0$-column vector of $Y$, and $x \\in \\mathbb{R}^{d^2}$ is the\nvectorization of $X$.\n\nIn a multi-layer LLM network, the matrix $B \\in \\mathbb{R}^{n \\times d}$ can\nbe viewed as the output of a layer, and $A_1= A_2 = A_3 \\in \\mathbb{R}^{n\n\\times d}$ can be viewed as the input of a layer. The matrix version of $x$ can\nbe viewed as $QK^\\top$ and $Y$ can be viewed as $V$. We provide an iterative\ngreedy algorithm to train loss function $L(X,Y)$ up $\\epsilon$ that runs in\n$\\widetilde{O}( ({\\cal T}_{\\mathrm{mat}}(n,n,d) + {\\cal\nT}_{\\mathrm{mat}}(n,d,d) + d^{2\\omega}) \\log(1/\\epsilon) )$ time. Here ${\\cal\nT}_{\\mathrm{mat}}(a,b,c)$ denotes the time of multiplying $a \\times b$ matrix\nanother $b \\times c$ matrix, and $\\omega\\approx 2.37$ denotes the exponent of\nmatrix multiplication.",
          "link": "http://arxiv.org/abs/2309.07418",
          "publishedOn": "2023-09-16T00:40:55.191Z",
          "wordCount": 839,
          "title": "A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time. (arXiv:2309.07418v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Shouwei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Meiyan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuepeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Wenqian Dong</a>",
          "description": "Hurricanes present major challenges in the U.S. due to their devastating\nimpacts. Mitigating these risks is important, and the insurance industry is\ncentral in this effort, using intricate statistical models for risk assessment.\nHowever, these models often neglect key temporal and spatial hurricane patterns\nand are limited by data scarcity. This study introduces a refined approach\ncombining the ARIMA model and K-MEANS to better capture hurricane trends, and\nan Autoencoder for enhanced hurricane simulations. Our experiments show that\nthis hybrid methodology effectively simulate historical hurricane behaviors\nwhile providing detailed projections of potential future trajectories and\nintensities. Moreover, by leveraging a comprehensive yet selective dataset, our\nsimulations enrich the current understanding of hurricane patterns and offer\nactionable insights for risk management strategies.",
          "link": "http://arxiv.org/abs/2309.07174",
          "publishedOn": "2023-09-16T00:40:55.145Z",
          "wordCount": 677,
          "title": "HurriCast: An Automatic Framework Using Machine Learning and Statistical Modeling for Hurricane Forecasting. (arXiv:2309.07174v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07367",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Nakazato_K/0/1/0/all/0/1\">Kenichi Nakazato</a>",
          "description": "Deep neural networks have shown many fruitful applications in this decade. A\nnetwork can get the generalized function through training with a finite\ndataset. The degree of generalization is a realization of the proximity scale\nin the data space. Specifically, the scale is not clear if the dataset is\ncomplicated. Here we consider a network for the distribution estimation of the\ndataset. We show the estimation is unstable and the instability depends on the\ndata density and training duration. We derive the kernel-balanced equation,\nwhich gives a short phenomenological description of the solution. The equation\ntells us the reason for the instability and the mechanism of the scale. The\nnetwork outputs a local average of the dataset as a prediction and the scale of\naveraging is determined along the equation. The scale gradually decreases along\ntraining and finally results in instability in our case.",
          "link": "http://arxiv.org/abs/2309.07367",
          "publishedOn": "2023-09-16T00:40:55.118Z",
          "wordCount": 643,
          "title": "The kernel-balanced equation for deep neural networks. (arXiv:2309.07367v1 [cond-mat.dis-nn])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.00305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoubo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zekun Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>",
          "description": "Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nthis http URL and long-term maintenance.",
          "link": "http://arxiv.org/abs/2210.00305",
          "publishedOn": "2023-09-16T00:40:55.109Z",
          "wordCount": 655,
          "title": "LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph Embeddings. (arXiv:2210.00305v3 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2204.10372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bichuch_M/0/1/0/all/0/1\">Maxim Bichuch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallada_E/0/1/0/all/0/1\">Enrique Mallada</a>",
          "description": "We consider the problem of learning an inner approximation of the region of\nattraction (ROA) of an asymptotically stable equilibrium point without an\nexplicit model of the dynamics. Rather than leveraging approximate models with\nbounded uncertainty to find a (robust) invariant set contained in the ROA, we\npropose to learn sets that satisfy a more relaxed notion of containment known\nas recurrence. We define a set to be $\\tau$-recurrent (resp. $k$-recurrent) if\nevery trajectory that starts within the set, returns to it after at most $\\tau$\nseconds (resp. $k$ steps). We show that under mild assumptions a\n$\\tau$-recurrent set containing a stable equilibrium must be a subset of its\nROA. We then leverage this property to develop algorithms that compute inner\napproximations of the ROA using counter-examples of recurrence that are\nobtained by sampling finite-length trajectories. Our algorithms process samples\nsequentially, which allow them to continue being executed even after an initial\noffline training stage. We further provide an upper bound on the number of\ncounter-examples used by the algorithm, and almost sure convergence guarantees.",
          "link": "http://arxiv.org/abs/2204.10372",
          "publishedOn": "2023-09-16T00:40:55.094Z",
          "wordCount": 703,
          "title": "Model-free Learning of Regions of Attraction via Recurrent Sets. (arXiv:2204.10372v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.07200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qingxu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_M/0/1/0/all/0/1\">Mengting Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lei Han</a>",
          "description": "Recent advances in learning reusable motion priors have demonstrated their\neffectiveness in generating naturalistic behaviors. In this paper, we propose a\nnew learning framework in this paradigm for controlling physics-based\ncharacters with significantly improved motion quality and diversity over\nexisting state-of-the-art methods. The proposed method uses reinforcement\nlearning (RL) to initially track and imitate life-like movements from\nunstructured motion clips using the discrete information bottleneck, as adopted\nin the Vector Quantized Variational AutoEncoder (VQ-VAE). This structure\ncompresses the most relevant information from the motion clips into a compact\nyet informative latent space, i.e., a discrete space over vector quantized\ncodes. By sampling codes in the space from a trained categorical prior\ndistribution, high-quality life-like behaviors can be generated, similar to the\nusage of VQ-VAE in computer vision. Although this prior distribution can be\ntrained with the supervision of the encoder's output, it follows the original\nmotion clip distribution in the dataset and could lead to imbalanced behaviors\nin our setting. To address the issue, we further propose a technique named\nprior shifting to adjust the prior distribution using curiosity-driven RL. The\noutcome distribution is demonstrated to offer sufficient behavioral diversity\nand significantly facilitates upper-level policy learning for downstream tasks.\nWe conduct comprehensive experiments using humanoid characters on two\nchallenging downstream tasks, sword-shield striking and two-player boxing game.\nOur results demonstrate that the proposed framework is capable of controlling\nthe character to perform considerably high-quality movements in terms of\nbehavioral strategies, diversity, and realism. Videos, codes, and data are\navailable at https://tencent-roboticsx.github.io/NCP/.",
          "link": "http://arxiv.org/abs/2308.07200",
          "publishedOn": "2023-09-16T00:40:55.089Z",
          "wordCount": 778,
          "title": "Neural Categorical Priors for Physics-Based Character Control. (arXiv:2308.07200v2 [cs.GR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sajid_N/0/1/0/all/0/1\">Nafis Sajid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Md Rashidul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1\">Muhammad Ibrahim</a>",
          "description": "Community question answering (CQA) forums are Internet-based platforms where\nusers ask questions about a topic and other expert users try to provide\nsolutions. Many CQA forums such as Quora, Stackoverflow, Yahoo!Answer,\nStackExchange exist with a lot of user-generated data. These data are leveraged\nin automated CQA ranking systems where similar questions (and answers) are\npresented in response to the query of the user. In this work, we empirically\ninvestigate a few aspects of this domain. Firstly, in addition to traditional\nfeatures like TF-IDF, BM25 etc., we introduce a BERT-based feature that\ncaptures the semantic similarity between the question and answer. Secondly,\nmost of the existing research works have focused on features extracted only\nfrom the question part; features extracted from answers have not been explored\nextensively. We combine both types of features in a linear fashion. Thirdly,\nusing our proposed concepts, we conduct an empirical investigation with\ndifferent rank-learning algorithms, some of which have not been used so far in\nCQA domain. On three standard CQA datasets, our proposed framework achieves\nstate-of-the-art performance. We also analyze importance of the features we use\nin our investigation. This work is expected to guide the practitioners to\nselect a better set of features for the CQA retrieval task.",
          "link": "http://arxiv.org/abs/2309.07610",
          "publishedOn": "2023-09-16T00:40:55.084Z",
          "wordCount": 720,
          "title": "Feature Engineering in Learning-to-Rank for Community Question Answering Task. (arXiv:2309.07610v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Swope_J/0/1/0/all/0/1\">Jason Swope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1\">Steve Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunkel_E/0/1/0/all/0/1\">Emily Dunkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosch_Lluis_X/0/1/0/all/0/1\">Xavier Bosch-Lluis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Q/0/1/0/all/0/1\">Qing Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deal_W/0/1/0/all/0/1\">William Deal</a>",
          "description": "Smart Ice Cloud Sensing (SMICES) is a small-sat concept in which a primary\nradar intelligently targets ice storms based on information collected by a\nlookahead radiometer. Critical to the intelligent targeting is accurate\nidentification of storm/cloud types from eight bands of radiance collected by\nthe radiometer. The cloud types of interest are: clear sky, thin cirrus,\ncirrus, rainy anvil, and convection core.\n\nWe describe multi-step use of Machine Learning and Digital Twin of the\nEarth's atmosphere to derive such a classifier. First, a digital twin of\nEarth's atmosphere called a Weather Research Forecast (WRF) is used generate\nsimulated lookahead radiometer data as well as deeper \"science\" hidden\nvariables. The datasets simulate a tropical region over the Caribbean and a\nnon-tropical region over the Atlantic coast of the United States. A K-means\nclustering over the scientific hidden variables was utilized by human experts\nto generate an automatic labelling of the data - mapping each physical data\npoint to cloud types by scientists informed by mean/centroids of hidden\nvariables of the clusters. Next, classifiers were trained with the inputs of\nthe simulated radiometer data and its corresponding label. The classifiers of a\nrandom decision forest (RDF), support vector machine (SVM), Gaussian na\\\"ive\nbayes, feed forward artificial neural network (ANN), and a convolutional neural\nnetwork (CNN) were trained. Over the tropical dataset, the best performing\nclassifier was able to identify non-storm and storm clouds with over 80%\naccuracy in each class for a held-out test set. Over the non-tropical dataset,\nthe best performing classifier was able to classify non-storm clouds with over\n90% accuracy and storm clouds with over 40% accuracy. Additionally both sets of\nclassifiers were shown to be resilient to instrument noise.",
          "link": "http://arxiv.org/abs/2309.07173",
          "publishedOn": "2023-09-16T00:40:55.071Z",
          "wordCount": 818,
          "title": "Using Unsupervised and Supervised Learning and Digital Twin for Deep Convective Ice Storm Classification. (arXiv:2309.07173v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zadem_M/0/1/0/all/0/1\">Mehdi Zadem</a> (LIX, U2IS), <a href=\"http://arxiv.org/find/cs/1/au:+Mover_S/0/1/0/all/0/1\">Sergio Mover</a> (LIX), <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Sao Mai Nguyen</a> (U2IS, Flowers, IMT Atlantique - INFO, Lab-STICC_RAMBO)",
          "description": "Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this work, we propose a\ndevelopmental mechanism for subgoal discovery via an emergent representation\nthat abstracts (i.e., groups together) sets of environment states that have\nsimilar roles in the task. We create a HRL algorithm that gradually learns this\nrepresentation along with the policies and evaluate it on navigation tasks to\nshow the learned representation is interpretable and results in data\nefficiency.",
          "link": "http://arxiv.org/abs/2309.07168",
          "publishedOn": "2023-09-16T00:40:55.061Z",
          "wordCount": 682,
          "title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via Reachability Analysis. (arXiv:2309.07168v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07178",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Guo_D/0/1/0/all/0/1\">Di Guo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_S/0/1/0/all/0/1\">Sijin Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tu_Z/0/1/0/all/0/1\">Zhangren Tu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qiu_T/0/1/0/all/0/1\">Tianyu Qiu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Feng_L/0/1/0/all/0/1\">Liubin Feng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_D/0/1/0/all/0/1\">Donghai Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hong_Q/0/1/0/all/0/1\">Qing Hong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_M/0/1/0/all/0/1\">Meijin Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_Y/0/1/0/all/0/1\">Yanqin Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qu_X/0/1/0/all/0/1\">Xiaobo Qu</a>",
          "description": "Nuclear Magnetic Resonance (NMR) spectroscopy has served as a powerful\nanalytical tool for studying molecular structure and dynamics in chemistry and\nbiology. However, the processing of raw data acquired from NMR spectrometers\nand subsequent quantitative analysis involves various specialized tools, which\nnecessitates comprehensive knowledge in programming and NMR. Particularly, the\nemerging deep learning tools is hard to be widely used in NMR due to the\nsophisticated setup of computation. Thus, NMR processing is not an easy task\nfor chemist and biologists. In this work, we present CloudBrain-NMR, an\nintelligent online cloud computing platform designed for NMR data reading,\nprocessing, reconstruction, and quantitative analysis. The platform is\nconveniently accessed through a web browser, eliminating the need for any\nprogram installation on the user side. CloudBrain-NMR uses parallel computing\nwith graphics processing units and central processing units, resulting in\nsignificantly shortened computation time. Furthermore, it incorporates\nstate-of-the-art deep learning-based algorithms offering comprehensive\nfunctionalities that allow users to complete the entire processing procedure\nwithout relying on additional software. This platform has empowered NMR\napplications with advanced artificial intelligence processing. CloudBrain-NMR\nis openly accessible for free usage at https://csrc.xmu.edu.cn/CloudBrain.html",
          "link": "http://arxiv.org/abs/2309.07178",
          "publishedOn": "2023-09-16T00:40:55.033Z",
          "wordCount": 734,
          "title": "CloudBrain-NMR: An Intelligent Cloud Computing Platform for NMR Spectroscopy Processing, Reconstruction and Analysis. (arXiv:2309.07178v1 [q-bio.QM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Haochong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shuo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinrun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>",
          "description": "Financial simulators play an important role in enhancing forecasting\naccuracy, managing risks, and fostering strategic financial decision-making.\nDespite the development of financial market simulation methodologies, existing\nframeworks often struggle with adapting to specialized simulation context. We\npinpoint the challenges as i) current financial datasets do not contain context\nlabels; ii) current techniques are not designed to generate financial data with\ncontext as control, which demands greater precision compared to other\nmodalities; iii) the inherent difficulties in generating context-aligned,\nhigh-fidelity data given the non-stationary, noisy nature of financial data. To\naddress these challenges, our contributions are: i) we proposed the Contextual\nMarket Dataset with market dynamics, stock ticker, and history state as\ncontext, leveraging a market dynamics modeling method that combines linear\nregression and Dynamic Time Warping clustering to extract market dynamics; ii)\nwe present Market-GAN, a novel architecture incorporating a Generative\nAdversarial Networks (GAN) for the controllable generation with context, an\nautoencoder for learning low-dimension features, and supervisors for knowledge\ntransfer; iii) we introduce a two-stage training scheme to ensure that\nMarket-GAN captures the intrinsic market distribution with multiple objectives.\nIn the pertaining stage, with the use of the autoencoder and supervisors, we\nprepare the generator with a better initialization for the adversarial training\nstage. We propose a set of holistic evaluation metrics that consider alignment,\nfidelity, data usability on downstream tasks, and market facts. We evaluate\nMarket-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and\nshowcase superior performance in comparison to 4 state-of-the-art time-series\ngenerative models.",
          "link": "http://arxiv.org/abs/2309.07708",
          "publishedOn": "2023-09-16T00:40:55.028Z",
          "wordCount": 772,
          "title": "Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context. (arXiv:2309.07708v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Molina_R/0/1/0/all/0/1\">Raul Molina</a>",
          "description": "Transformers have significantly advanced the field of natural language\nprocessing, but comprehending their internal mechanisms remains a challenge. In\nthis paper, we introduce a novel geometric perspective that elucidates the\ninner mechanisms of transformer operations. Our primary contribution is\nillustrating how layer normalization confines the latent features to a\nhyper-sphere, subsequently enabling attention to mold the semantic\nrepresentation of words on this surface. This geometric viewpoint seamlessly\nconnects established properties such as iterative refinement and contextual\nembeddings. We validate our insights by probing a pre-trained 124M parameter\nGPT-2 model. Our findings reveal clear query-key attention patterns in early\nlayers and build upon prior observations regarding the subject-specific nature\nof attention heads at deeper layers. Harnessing these geometric insights, we\npresent an intuitive understanding of transformers, depicting them as processes\nthat model the trajectory of word particles along the hyper-sphere.",
          "link": "http://arxiv.org/abs/2309.07315",
          "publishedOn": "2023-09-16T00:40:55.021Z",
          "wordCount": 624,
          "title": "Traveling Words: A Geometric Interpretation of Transformers. (arXiv:2309.07315v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2310.03696",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Parhi_R/0/1/0/all/0/1\">Rahul Parhi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Unser_M/0/1/0/all/0/1\">Michael Unser</a>",
          "description": "We investigate the variational optimality (specifically, the Banach space\noptimality) of a large class of neural architectures with multivariate\nnonlinearities/activation functions. To that end, we construct a new family of\nBanach spaces defined via a regularization operator and the $k$-plane\ntransform. We prove a representer theorem that states that the solution sets to\nlearning problems posed over these Banach spaces are completely characterized\nby neural architectures with multivariate nonlinearities. These optimal\narchitectures have skip connections and are tightly connected to orthogonal\nweight normalization and multi-index models, both of which have received\nconsiderable interest in the neural network community. Our framework is\ncompatible with a number of classical nonlinearities including the rectified\nlinear unit (ReLU) activation function, the norm activation function, and the\nradial basis functions found in the theory of thin-plate/polyharmonic splines.\nWe also show that the underlying spaces are special instances of reproducing\nkernel Banach spaces and variation spaces. Our results shed light on the\nregularity of functions learned by neural networks trained on data,\nparticularly with multivariate nonlinearities, and provide new theoretical\nmotivation for several architectural choices found in practice.",
          "link": "http://arxiv.org/abs/2310.03696",
          "publishedOn": "2023-10-07T00:42:19.671Z",
          "wordCount": null,
          "title": "Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03556",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bolat_K/0/1/0/all/0/1\">Kutay B&#xf6;lat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tindemans_S/0/1/0/all/0/1\">Simon H. Tindemans</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Palensky_P/0/1/0/all/0/1\">Peter Palensky</a>",
          "description": "Probabilistic modelling of power systems operation and planning processes\ndepends on data-driven methods, which require sufficiently large datasets. When\nhistorical data lacks this, it is desired to model the underlying data\ngeneration mechanism as a probability distribution to assess the data quality\nand generate more data, if needed. Kernel density estimation (KDE) based models\nare popular choices for this task, but they fail to adapt to data regions with\nvarying densities. In this paper, an adaptive KDE model is employed to\ncircumvent this, where each kernel in the model has an individual bandwidth.\nThe leave-one-out maximum log-likelihood (LOO-MLL) criterion is proposed to\nprevent the singular solutions that the regular MLL criterion gives rise to,\nand it is proven that LOO-MLL prevents these. Relying on this guaranteed\nrobustness, the model is extended by assigning learnable weights to the\nkernels. In addition, a modified expectation-maximization algorithm is employed\nto accelerate the optimization speed reliably. The performance of the proposed\nmethod and models are exhibited on two power systems datasets using different\nstatistical tests and by comparison with Gaussian mixture models. Results show\nthat the proposed models have promising performance, in addition to their\nsingularity prevention guarantees.",
          "link": "http://arxiv.org/abs/2310.03556",
          "publishedOn": "2023-10-07T00:42:19.668Z",
          "wordCount": null,
          "title": "Stable Training of Probabilistic Models Using the Leave-One-Out Maximum Log-Likelihood Objective. (arXiv:2310.03556v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.05120",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deng_W/0/1/0/all/0/1\">Wei Deng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1\">Qian Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_G/0/1/0/all/0/1\">Guang Lin</a>",
          "description": "We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty\nquantification and mean predictions with distributed clients. In particular, we\ngeneralize beyond normal posterior distributions and consider a general class\nof models. We develop theoretical guarantees for FA-LD for strongly log-concave\ndistributions with non-i.i.d data and study how the injected noise and the\nstochastic-gradient noise, the heterogeneity of data, and the varying learning\nrates affect the convergence. Such an analysis sheds light on the optimal\nchoice of local updates to minimize communication costs. Important to our\napproach is that the communication efficiency does not deteriorate with the\ninjected noise in the Langevin algorithms. In addition, we examine in our FA-LD\nalgorithm both independent and correlated noise used over different clients. We\nobserve there is a trade-off between the pairs among communication, accuracy,\nand data privacy. As local devices may become inactive in federated networks,\nwe also show convergence results based on different averaging schemes where\nonly partial device updates are available. In such a case, we discover an\nadditional bias that does not decay to zero.",
          "link": "http://arxiv.org/abs/2112.05120",
          "publishedOn": "2023-10-07T00:42:19.667Z",
          "wordCount": null,
          "title": "On Convergence of Federated Averaging Langevin Dynamics. (arXiv:2112.05120v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03722",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1\">Hongjian Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "In 1976, Lai constructed a nontrivial confidence sequence for the mean $\\mu$\nof a Gaussian distribution with unknown variance $\\sigma$. Curiously, he\nemployed both an improper (right Haar) mixture over $\\sigma$ and an improper\n(flat) mixture over $\\mu$. Here, we elaborate carefully on the details of his\nconstruction, which use generalized nonintegrable martingales and an extended\nVille's inequality. While this does yield a sequential t-test, it does not\nyield an ``e-process'' (due to the nonintegrability of his martingale). In this\npaper, we develop two new e-processes and confidence sequences for the same\nsetting: one is a test martingale in a reduced filtration, while the other is\nan e-process in the canonical data filtration. These are respectively obtained\nby swapping Lai's flat mixture for a Gaussian mixture, and swapping the right\nHaar mixture over $\\sigma$ with the maximum likelihood estimate under the null,\nas done in universal inference. We also analyze the width of resulting\nconfidence sequences, which have a curious dependence on the error probability\n$\\alpha$. Numerical experiments are provided along the way to compare and\ncontrast the various approaches.",
          "link": "http://arxiv.org/abs/2310.03722",
          "publishedOn": "2023-10-07T00:42:19.666Z",
          "wordCount": null,
          "title": "Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.13053",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Assel_H/0/1/0/all/0/1\">Hugues Van Assel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Espinasse_T/0/1/0/all/0/1\">Thibault Espinasse</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chiquet_J/0/1/0/all/0/1\">Julien Chiquet</a>, <a href=\"http://arxiv.org/find/math/1/au:+Picard_F/0/1/0/all/0/1\">Franck Picard</a>",
          "description": "Most popular dimension reduction (DR) methods like t-SNE and UMAP are based\non minimizing a cost between input and latent pairwise similarities. Though\nwidely used, these approaches lack clear probabilistic foundations to enable a\nfull understanding of their properties and limitations. To that extent, we\nintroduce a unifying statistical framework based on the coupling of hidden\ngraphs using cross entropy. These graphs induce a Markov random field\ndependency structure among the observations in both input and latent spaces. We\nshow that existing pairwise similarity DR methods can be retrieved from our\nframework with particular choices of priors for the graphs. Moreover this\nreveals that these methods suffer from a statistical deficiency that explains\npoor performances in conserving coarse-grain dependencies. Our model is\nleveraged and extended to address this issue while new links are drawn with\nLaplacian eigenmaps and PCA.",
          "link": "http://arxiv.org/abs/2201.13053",
          "publishedOn": "2023-10-07T00:42:19.666Z",
          "wordCount": null,
          "title": "A Probabilistic Graph Coupling View of Dimension Reduction. (arXiv:2201.13053v3 [math.PR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuelin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "Building machines that can reason about physical events and their causal\nrelationships is crucial for flexible interaction with the physical world.\nHowever, most existing physical and causal reasoning benchmarks are exclusively\nbased on synthetically generated events and synthetic natural language\ndescriptions of causal relationships. This design brings up two issues. First,\nthere is a lack of diversity in both event types and natural language\ndescriptions; second, causal relationships based on manually-defined heuristics\nare different from human judgments. To address both shortcomings, we present\nthe CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of\nphysical events with human labels. We employ two techniques to improve data\ncollection efficiency: first, a novel iterative event cloze task to elicit a\nnew representation of events in videos, which we term Causal Event Graphs\n(CEGs); second, a data augmentation technique based on neural language\ngenerative models. We convert the collected CEGs into questions and answers to\nbe consistent with prior work. Finally, we study a collection of baseline\napproaches for CLEVRER-Humans question-answering, highlighting the great\nchallenges set forth by our benchmark.",
          "link": "http://arxiv.org/abs/2310.03635",
          "publishedOn": "2023-10-07T00:42:19.130Z",
          "wordCount": null,
          "title": "CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hellsten_E/0/1/0/all/0/1\">Erik Orm Hellsten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hvarfner_C/0/1/0/all/0/1\">Carl Hvarfner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papenmeier_L/0/1/0/all/0/1\">Leonard Papenmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nardi_L/0/1/0/all/0/1\">Luigi Nardi</a>",
          "description": "Bayesian optimization is an effective method for optimizing\nexpensive-to-evaluate black-box functions. High-dimensional problems are\nparticularly challenging as the surrogate model of the objective suffers from\nthe curse of dimensionality, which makes accurate modeling difficult. We\npropose a group testing approach to identify active variables to facilitate\nefficient optimization in these domains. The proposed algorithm, Group Testing\nBayesian Optimization (GTBO), first runs a testing phase where groups of\nvariables are systematically selected and tested on whether they influence the\nobjective. To that end, we extend the well-established theory of group testing\nto functions of continuous ranges. In the second phase, GTBO guides\noptimization by placing more importance on the active dimensions. By exploiting\nthe axis-aligned subspace assumption, GTBO is competitive against\nstate-of-the-art methods on several synthetic and real-world high-dimensional\noptimization tasks. Furthermore, GTBO aids in the discovery of active\nparameters in applications, thereby enhancing practitioners' understanding of\nthe problem at hand.",
          "link": "http://arxiv.org/abs/2310.03515",
          "publishedOn": "2023-10-07T00:42:19.101Z",
          "wordCount": null,
          "title": "High-dimensional Bayesian Optimization with Group Testing. (arXiv:2310.03515v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03112",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Herbinger_J/0/1/0/all/0/1\">Julia Herbinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dandl_S/0/1/0/all/0/1\">Susanne Dandl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ewald_F/0/1/0/all/0/1\">Fiona K. Ewald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loibl_S/0/1/0/all/0/1\">Sofia Loibl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1\">Giuseppe Casalicchio</a>",
          "description": "Surrogate models play a crucial role in retrospectively interpreting complex\nand powerful black box machine learning models via model distillation. This\npaper focuses on using model-based trees as surrogate models which partition\nthe feature space into interpretable regions via decision rules. Within each\nregion, interpretable models based on additive main effects are used to\napproximate the behavior of the black box model, striking for an optimal\nbalance between interpretability and performance. Four model-based tree\nalgorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their\nability to generate such surrogate models. We investigate fidelity,\ninterpretability, stability, and the algorithms' capability to capture\ninteraction effects through appropriate splits. Based on our comprehensive\nanalyses, we finally provide an overview of user-specific recommendations.",
          "link": "http://arxiv.org/abs/2310.03112",
          "publishedOn": "2023-10-07T00:42:19.029Z",
          "wordCount": null,
          "title": "Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1\">Philip M. Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Recent experiments have shown that, often, when training a neural network\nwith gradient descent (GD) with a step size $\\eta$, the operator norm of the\nHessian of the loss grows until it approximately reaches $2/\\eta$, after which\nit fluctuates around this value. The quantity $2/\\eta$ has been called the\n\"edge of stability\" based on consideration of a local quadratic approximation\nof the loss. We perform a similar calculation to arrive at an \"edge of\nstability\" for Sharpness-Aware Minimization (SAM), a variant of GD which has\nbeen shown to improve its generalization. Unlike the case for GD, the resulting\nSAM-edge depends on the norm of the gradient. Using three deep learning\ntraining tasks, we see empirically that SAM operates on the edge of stability\nidentified by this analysis.",
          "link": "http://arxiv.org/abs/2309.12488",
          "publishedOn": "2023-10-07T00:42:19.028Z",
          "wordCount": null,
          "title": "Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1\">Domenico Marinucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1\">Ivan Nourdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1\">Giovanni Peccati</a>",
          "description": "We study the distribution of a fully connected neural network with random\nGaussian weights and biases in which the hidden layer widths are proportional\nto a large constant $n$. Under mild assumptions on the non-linearity, we obtain\nquantitative bounds on normal approximations valid at large but finite $n$ and\nany fixed network depth. Our theorems show both for the finite-dimensional\ndistributions and the entire process, that the distance between a random fully\nconnected network (and its derivatives) to the corresponding infinite width\nGaussian process scales like $n^{-\\gamma}$ for $\\gamma>0$, with the exponent\ndepending on the metric used to measure discrepancy. Our bounds are strictly\nstronger in terms of their dependence on network width than any previously\navailable in the literature; in the one-dimensional case, we also prove that\nthey are optimal, i.e., we establish matching lower bounds.",
          "link": "http://arxiv.org/abs/2307.06092",
          "publishedOn": "2023-10-07T00:42:18.978Z",
          "wordCount": null,
          "title": "Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03243",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1\">Mingxuan Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Y/0/1/0/all/0/1\">Yan Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liang_F/0/1/0/all/0/1\">Faming Liang</a>",
          "description": "Sparse deep learning has become a popular technique for improving the\nperformance of deep neural networks in areas such as uncertainty\nquantification, variable selection, and large-scale network compression.\nHowever, most existing research has focused on problems where the observations\nare independent and identically distributed (i.i.d.), and there has been little\nwork on the problems where the observations are dependent, such as time series\ndata and sequential data in natural language processing. This paper aims to\naddress this gap by studying the theory for sparse deep learning with dependent\ndata. We show that sparse recurrent neural networks (RNNs) can be consistently\nestimated, and their predictions are asymptotically normally distributed under\nappropriate assumptions, enabling the prediction uncertainty to be correctly\nquantified. Our numerical results show that sparse deep learning outperforms\nstate-of-the-art methods, such as conformal predictions, in prediction\nuncertainty quantification for time series data. Furthermore, our results\nindicate that the proposed method can consistently identify the autoregressive\norder for time series data and outperform existing methods in large-scale model\ncompression. Our proposed method has important practical implications in fields\nsuch as finance, healthcare, and energy, where both accurate point estimates\nand prediction uncertainty quantification are of concern.",
          "link": "http://arxiv.org/abs/2310.03243",
          "publishedOn": "2023-10-07T00:42:18.910Z",
          "wordCount": null,
          "title": "Sparse Deep Learning for Time Series Data: Theory and Applications. (arXiv:2310.03243v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assel_H/0/1/0/all/0/1\">Hugues Van Assel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_Cuaz_C/0/1/0/all/0/1\">C&#xe9;dric Vincent-Cuaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vayer_T/0/1/0/all/0/1\">Titouan Vayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1\">R&#xe9;mi Flamary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1\">Nicolas Courty</a>",
          "description": "We present a versatile adaptation of existing dimensionality reduction (DR)\nobjectives, enabling the simultaneous reduction of both sample and feature\nsizes. Correspondances between input and embedding samples are computed through\na semi-relaxed Gromov-Wasserstein optimal transport (OT) problem. When the\nembedding sample size matches that of the input, our model recovers classical\npopular DR models. When the embedding's dimensionality is unconstrained, we\nshow that the OT plan delivers a competitive hard clustering. We emphasize the\nimportance of intermediate stages that blend DR and clustering for summarizing\nreal data and apply our method to visualize datasets of images.",
          "link": "http://arxiv.org/abs/2310.03398",
          "publishedOn": "2023-10-07T00:42:18.858Z",
          "wordCount": null,
          "title": "Interpolating between Clustering and Dimensionality Reduction with Gromov-Wasserstein. (arXiv:2310.03398v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.00195",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Altabaa_A/0/1/0/all/0/1\">Awni Altabaa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_T/0/1/0/all/0/1\">Taylor Webb</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1\">Jonathan Cohen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "An extension of Transformers is proposed that enables explicit relational\nreasoning through a novel module called the Abstractor. At the core of the\nAbstractor is a variant of attention called relational cross-attention. The\napproach is motivated by an architectural inductive bias for relational\nlearning that disentangles relational information from extraneous features\nabout individual objects. This enables explicit relational reasoning,\nsupporting abstraction and generalization from limited data. The Abstractor is\nfirst evaluated on simple discriminative relational tasks and compared to\nexisting relational architectures. Next, the Abstractor is evaluated on purely\nrelational sequence-to-sequence tasks, where dramatic improvements are seen in\nsample efficiency compared to standard Transformers. Finally, Abstractors are\nevaluated on a collection of tasks based on mathematical problem solving, where\nmodest but consistent improvements in performance and sample efficiency are\nobserved.",
          "link": "http://arxiv.org/abs/2304.00195",
          "publishedOn": "2023-10-07T00:42:18.855Z",
          "wordCount": null,
          "title": "Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers. (arXiv:2304.00195v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishi_H/0/1/0/all/0/1\">Hideyuki Ishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "The symmetry and geometry of input data are considered to be encoded in the\ninternal data representation inside the neural network, but the specific\nencoding rule has been less investigated. By focusing on a joint group\ninvariant function on the data-parameter domain, we present a systematic rule\nto find a dual group action on the parameter domain from a group action on the\ndata domain. Further, we introduce generalized neural networks induced from the\njoint invariant functions, and present a new group theoretic proof of their\nuniversality theorems by using Schur's lemma. Since traditional universality\ntheorems were demonstrated based on functional analytical methods, this study\nsheds light on the group theoretic aspect of the approximation theory,\nconnecting geometric deep learning to abstract harmonic analysis.",
          "link": "http://arxiv.org/abs/2310.03530",
          "publishedOn": "2023-10-07T00:42:18.515Z",
          "wordCount": null,
          "title": "Joint Group Invariant Functions on Data-Parameter Domain Induce Universal Neural Networks. (arXiv:2310.03530v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.03246",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghattas_O/0/1/0/all/0/1\">Omar Al Ghattas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sanz_Alonso_D/0/1/0/all/0/1\">Daniel Sanz-Alonso</a>",
          "description": "Many modern algorithms for inverse problems and data assimilation rely on\nensemble Kalman updates to blend prior predictions with observed data. Ensemble\nKalman methods often perform well with a small ensemble size, which is\nessential in applications where generating each particle is costly. This paper\ndevelops a non-asymptotic analysis of ensemble Kalman updates that rigorously\nexplains why a small ensemble size suffices if the prior covariance has\nmoderate effective dimension due to fast spectrum decay or approximate\nsparsity. We present our theory in a unified framework, comparing several\nimplementations of ensemble Kalman updates that use perturbed observations,\nsquare root filtering, and localization. As part of our analysis, we develop\nnew dimension-free covariance estimation bounds for approximately sparse\nmatrices that may be of independent interest.",
          "link": "http://arxiv.org/abs/2208.03246",
          "publishedOn": "2023-10-07T00:42:18.485Z",
          "wordCount": null,
          "title": "Non-Asymptotic Analysis of Ensemble Kalman Updates: Effective Dimension and Localization. (arXiv:2208.03246v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1\">Alexander Robey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1\">Eric Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>",
          "description": "Despite efforts to align large language models (LLMs) with human values,\nwidely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to\njailbreaking attacks, wherein an adversary fools a targeted LLM into generating\nobjectionable content. To address this vulnerability, we propose SmoothLLM, the\nfirst algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our\nfinding that adversarially-generated prompts are brittle to character-level\nchanges, our defense first randomly perturbs multiple copies of a given input\nprompt, and then aggregates the corresponding predictions to detect adversarial\ninputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to\nbelow one percentage point, avoids unnecessary conservatism, and admits\nprovable guarantees on attack mitigation. Moreover, our defense uses\nexponentially fewer queries than existing attacks and is compatible with any\nLLM.",
          "link": "http://arxiv.org/abs/2310.03684",
          "publishedOn": "2023-10-07T00:42:18.483Z",
          "wordCount": null,
          "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Beomsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1\">Gihyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kwanyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Diffusion models are a powerful class of generative models which simulate\nstochastic differential equations (SDEs) to generate data from noise. Although\ndiffusion models have achieved remarkable progress in recent years, they have\nlimitations in the unpaired image-to-image translation tasks due to the\nGaussian prior assumption. Schr\\\"odinger Bridge (SB), which learns an SDE to\ntranslate between two arbitrary distributions, have risen as an attractive\nsolution to this problem. However, none of SB models so far have been\nsuccessful at unpaired translation between high-resolution images. In this\nwork, we propose the Unpaired Neural Schr\\\"odinger Bridge (UNSB), which\nexpresses SB problem as a sequence of adversarial learning problems. This\nallows us to incorporate advanced discriminators and regularization to learn a\nSB between unpaired data. We demonstrate that UNSB is scalable and successfully\nsolves various unpaired image-to-image translation tasks. Code:\n\\url{https://github.com/cyclomon/UNSB}",
          "link": "http://arxiv.org/abs/2305.15086",
          "publishedOn": "2023-10-07T00:42:18.470Z",
          "wordCount": null,
          "title": "Unpaired Image-to-Image Translation via Neural Schr\\\"odinger Bridge. (arXiv:2305.15086v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.01751",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_G/0/1/0/all/0/1\">Guan-Horng Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>",
          "description": "It is a crucial challenge to reconstruct population dynamics using unlabeled\nsamples from distributions at coarse time intervals. Recent approaches such as\nflow-based models or Schr\\\"odinger Bridge (SB) models have demonstrated\nappealing performance, yet the inferred sample trajectories either fail to\naccount for the underlying stochasticity or are $\\underline{D}$eep\n$\\underline{M}$omentum Multi-Marginal $\\underline{S}$chr\\\"odinger\n$\\underline{B}$ridge(DMSB), a novel computational framework that learns the\nsmooth measure-valued spline for stochastic systems that satisfy position\nmarginal constraints across time. By tailoring the celebrated Bregman Iteration\nand extending the Iteration Proportional Fitting to phase space, we manage to\nhandle high-dimensional multi-marginal trajectory inference tasks efficiently.\nOur algorithm outperforms baselines significantly, as evidenced by experiments\nfor synthetic datasets and a real-world single-cell RNA sequence dataset.\nAdditionally, the proposed approach can reasonably reconstruct the evolution of\nvelocity distribution, from position snapshots only, when there is a ground\ntruth velocity that is nevertheless inaccessible.",
          "link": "http://arxiv.org/abs/2303.01751",
          "publishedOn": "2023-10-07T00:42:18.457Z",
          "wordCount": null,
          "title": "Deep Momentum Multi-Marginal Schr\\\"odinger Bridge. (arXiv:2303.01751v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02824",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stephanovitch_A/0/1/0/all/0/1\">Arthur St&#xe9;phanovitch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tanielian_U/0/1/0/all/0/1\">Ugo Tanielian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cadre_B/0/1/0/all/0/1\">Beno&#xee;t Cadre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Klutchnikoff_N/0/1/0/all/0/1\">Nicolas Klutchnikoff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Biau_G/0/1/0/all/0/1\">G&#xe9;rard Biau</a>",
          "description": "The mathematical forces at work behind Generative Adversarial Networks raise\nchallenging theoretical issues. Motivated by the important question of\ncharacterizing the geometrical properties of the generated distributions, we\nprovide a thorough analysis of Wasserstein GANs (WGANs) in both the finite\nsample and asymptotic regimes. We study the specific case where the latent\nspace is univariate and derive results valid regardless of the dimension of the\noutput space. We show in particular that for a fixed sample size, the optimal\nWGANs are closely linked with connected paths minimizing the sum of the squared\nEuclidean distances between the sample points. We also highlight the fact that\nWGANs are able to approach (for the 1-Wasserstein distance) the target\ndistribution as the sample size tends to infinity, at a given convergence rate\nand provided the family of generative Lipschitz functions grows appropriately.\nWe derive in passing new results on optimal transport theory in the\nsemi-discrete setting.",
          "link": "http://arxiv.org/abs/2201.02824",
          "publishedOn": "2023-10-07T00:42:18.381Z",
          "wordCount": null,
          "title": "Optimal 1-Wasserstein Distance for WGANs. (arXiv:2201.02824v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.04054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hagmann_M/0/1/0/all/0/1\">Michael Hagmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meier_P/0/1/0/all/0/1\">Philipp Meier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>",
          "description": "Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.",
          "link": "http://arxiv.org/abs/2302.04054",
          "publishedOn": "2023-10-07T00:42:18.372Z",
          "wordCount": null,
          "title": "Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.11024",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Zhengyu Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1\">Jiaoyang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M. Stuart</a>",
          "description": "Sampling a probability distribution with an unknown normalization constant is\na fundamental problem in computational science and engineering. This task may\nbe cast as an optimization problem over all probability measures, and an\ninitial distribution can be evolved to the desired minimizer dynamically via\ngradient flows. Mean-field models, whose law is governed by the gradient flow\nin the space of probability measures, may also be identified; particle\napproximations of these mean-field models form the basis of algorithms. The\ngradient flow approach is also the basis of algorithms for variational\ninference, in which the optimization is performed over a parameterized family\nof probability distributions such as Gaussians, and the underlying gradient\nflow is restricted to the parameterized family.\n\nBy choosing different energy functionals and metrics for the gradient flow,\ndifferent algorithms with different convergence properties arise. In this\npaper, we concentrate on the Kullback-Leibler divergence after showing that, up\nto scaling, it has the unique property that the gradient flows resulting from\nthis choice of energy do not depend on the normalization constant. For the\nmetrics, we focus on variants of the Fisher-Rao, Wasserstein, and Stein\nmetrics; we introduce the affine invariance property for gradient flows, and\ntheir corresponding mean-field models, determine whether a given metric leads\nto affine invariance, and modify it to make it affine invariant if it does not.\nWe study the resulting gradient flows in both probability density space and\nGaussian space. The flow in the Gaussian space may be understood as a Gaussian\napproximation of the flow. We demonstrate that the Gaussian approximation based\non the metric and through moment closure coincide, establish connections\nbetween them, and study their long-time convergence properties showing the\nadvantages of affine invariance.",
          "link": "http://arxiv.org/abs/2302.11024",
          "publishedOn": "2023-10-07T00:42:18.135Z",
          "wordCount": null,
          "title": "Gradient Flows for Sampling: Mean-Field Models, Gaussian Approximations and Affine Invariance. (arXiv:2302.11024v5 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2310.03725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1\">Mark Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boffi_N/0/1/0/all/0/1\">Nicholas M. Boffi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>",
          "description": "Generative models inspired by dynamical transport of measure -- such as flows\nand diffusions -- construct a continuous-time map between two probability\ndensities. Conventionally, one of these is the target density, only accessible\nthrough samples, while the other is taken as a simple base density that is\ndata-agnostic. In this work, using the framework of stochastic interpolants, we\nformalize how to \\textit{couple} the base and the target densities. This\nenables us to incorporate information about class labels or continuous\nembeddings to construct dynamical transport maps that serve as conditional\ngenerative models. We show that these transport maps can be learned by solving\na simple square loss regression problem analogous to the standard independent\nsetting. We demonstrate the usefulness of constructing dependent couplings in\npractice through experiments in super-resolution and in-painting.",
          "link": "http://arxiv.org/abs/2310.03725",
          "publishedOn": "2023-10-07T00:42:17.923Z",
          "wordCount": null,
          "title": "Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.14073",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Saremi_M/0/1/0/all/0/1\">Mehrzad Saremi</a>",
          "description": "We propose a graphical structure for structural equation models that is\nstable under marginalization under linearity and Gaussianity assumptions. We\nshow that computing the maximum likelihood estimation of this model is\nequivalent to training a neural network. We implement a GPU-based algorithm\nthat computes the maximum likelihood estimation of these models.",
          "link": "http://arxiv.org/abs/2309.14073",
          "publishedOn": "2023-10-07T00:42:17.450Z",
          "wordCount": 579,
          "title": "Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.14979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kasmi_G/0/1/0/all/0/1\">Gabriel Kasmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubus_L/0/1/0/all/0/1\">Laurent Dubus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drenan_Y/0/1/0/all/0/1\">Yves-Marie Saint Drenan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanc_P/0/1/0/all/0/1\">Philippe Blanc</a>",
          "description": "Neural networks have shown remarkable performance in computer vision, but\ntheir deployment in numerous scientific and technical fields is challenging due\nto their black-box nature. Scientists and practitioners need to evaluate the\nreliability of a decision, i.e., to know simultaneously if a model relies on\nthe relevant features and whether these features are robust to image\ncorruptions. Existing attribution methods aim to provide human-understandable\nexplanations by highlighting important regions in the image domain, but fail to\nfully characterize a decision process's reliability. To bridge this gap, we\nintroduce the Wavelet sCale Attribution Method (WCAM), a generalization of\nattribution from the pixel domain to the space-scale domain using wavelet\ntransforms. Attribution in the wavelet domain reveals where {\\it and} on what\nscales the model focuses, thus enabling us to assess whether a decision is\nreliable.",
          "link": "http://arxiv.org/abs/2305.14979",
          "publishedOn": "2023-10-07T00:42:17.433Z",
          "wordCount": 762,
          "title": "Assessment of the Reliablity of a Model's Decision by Generalizing Attribution to the Wavelet Domain. (arXiv:2305.14979v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.08417",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gerhardus_A/0/1/0/all/0/1\">Andreas Gerhardus</a>",
          "description": "In this paper, we introduce a novel class of graphical models for\nrepresenting time lag specific causal relationships and independencies of\nmultivariate time series with unobserved confounders. We completely\ncharacterize these graphs and show that they constitute proper subsets of the\ncurrently employed model classes. As we show, from the novel graphs one can\nthus draw stronger causal inferences -- without additional assumptions. We\nfurther introduce a graphical representation of Markov equivalence classes of\nthe novel graphs. This graphical representation contains more causal knowledge\nthan what current state-of-the-art causal discovery algorithms learn.",
          "link": "http://arxiv.org/abs/2112.08417",
          "publishedOn": "2023-10-07T00:42:17.425Z",
          "wordCount": 625,
          "title": "Characterization of causal ancestral graphs for time series with latent confounders. (arXiv:2112.08417v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1\">Albert Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anitescu_M/0/1/0/all/0/1\">Mihai Anitescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanyam_A/0/1/0/all/0/1\">Anirudh Subramanyam</a>",
          "description": "Measures of power grid vulnerability are often assessed by the amount of\ndamage an adversary can exact on the network. However, the cascading impact of\nsuch attacks is often overlooked, even though cascades are one of the primary\ncauses of large-scale blackouts. This paper explores modifications of\ntransmission line protection settings as candidates for adversarial attacks,\nwhich can remain undetectable as long as the network equilibrium state remains\nunaltered. This forms the basis of a black-box function in a Bayesian\noptimization procedure, where the objective is to find protection settings that\nmaximize network degradation due to cascading. Notably, our proposed method is\nagnostic to the choice of the cascade simulator and its underlying assumptions.\nNumerical experiments reveal that, against conventional wisdom, maximally\nmisconfiguring the protection settings of all network lines does not cause the\nmost cascading. More surprisingly, even when the degree of misconfiguration is\nlimited due to resource constraints, it is still possible to find settings that\nproduce cascades comparable in severity to instances where there are no\nresource constraints.",
          "link": "http://arxiv.org/abs/2304.14420",
          "publishedOn": "2023-10-07T00:42:17.111Z",
          "wordCount": 701,
          "title": "Network Cascade Vulnerability using Constrained Bayesian Optimization. (arXiv:2304.14420v2 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03298",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ping Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Comlek_Y/0/1/0/all/0/1\">Yigitcan Comlek</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate\nmodeling and design optimization by incorporating data from various\nlow-fidelity (LF) models. While most existing MF methods assume a fixed\ndataset, adaptive sampling methods that dynamically allocate resources among\nfidelity models can achieve higher efficiency in the exploring and exploiting\nthe design space. However, most existing MF methods rely on the hierarchical\nassumption of fidelity levels or fail to capture the intercorrelation between\nmultiple fidelity levels and utilize it to quantify the value of the future\nsamples and navigate the adaptive sampling. To address this hurdle, we propose\na framework hinged on a latent embedding for different fidelity models and the\nassociated pre-posterior analysis to explicitly utilize their correlation for\nadaptive sampling. In this framework, each infill sampling iteration includes\ntwo steps: We first identify the location of interest with the greatest\npotential improvement using the high-fidelity (HF) model, then we search for\nthe next sample across all fidelity levels that maximize the improvement per\nunit cost at the location identified in the first step. This is made possible\nby a single Latent Variable Gaussian Process (LVGP) model that maps different\nfidelity models into an interpretable latent space to capture their\ncorrelations without assuming hierarchical fidelity levels. The LVGP enables us\nto assess how LF sampling candidates will affect HF response with pre-posterior\nanalysis and determine the next sample with the best benefit-to-cost ratio.\nThrough test cases, we demonstrate that the proposed method outperforms the\nbenchmark methods in both MF global fitting (GF) and Bayesian Optimization (BO)\nproblems in convergence rate and robustness. Moreover, the method offers the\nflexibility to switch between GF and BO by simply changing the acquisition\nfunction.",
          "link": "http://arxiv.org/abs/2310.03298",
          "publishedOn": "2023-10-07T00:42:17.101Z",
          "wordCount": 779,
          "title": "A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15871",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daolang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bharti_A/0/1/0/all/0/1\">Ayush Bharti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Souza_A/0/1/0/all/0/1\">Amauri Souza</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acerbi_L/0/1/0/all/0/1\">Luigi Acerbi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "Simulation-based inference (SBI) methods such as approximate Bayesian\ncomputation (ABC), synthetic likelihood, and neural posterior estimation (NPE)\nrely on simulating statistics to infer parameters of intractable likelihood\nmodels. However, such methods are known to yield untrustworthy and misleading\ninference outcomes under model misspecification, thus hindering their\nwidespread applicability. In this work, we propose the first general approach\nto handle model misspecification that works across different classes of SBI\nmethods. Leveraging the fact that the choice of statistics determines the\ndegree of misspecification in SBI, we introduce a regularized loss function\nthat penalises those statistics that increase the mismatch between the data and\nthe model. Taking NPE and ABC as use cases, we demonstrate the superior\nperformance of our method on high-dimensional time-series models that are\nartificially misspecified. We also apply our method to real data from the field\nof radio propagation where the model is known to be misspecified. We show\nempirically that the method yields robust inference in misspecified scenarios,\nwhilst still being accurate when the model is well-specified.",
          "link": "http://arxiv.org/abs/2305.15871",
          "publishedOn": "2023-10-07T00:42:17.094Z",
          "wordCount": 711,
          "title": "Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1\">Haosen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_H/0/1/0/all/0/1\">Hamsa Bastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1\">Osbert Bastani</a>",
          "description": "Existing approaches to algorithmic fairness aim to ensure equitable outcomes\nif human decision-makers comply perfectly with algorithmic decisions. However,\nperfect compliance with the algorithm is rarely a reality or even a desirable\noutcome in human-AI collaboration. Yet, recent studies have shown that\nselective compliance with fair algorithms can amplify discrimination relative\nto the prior human policy. As a consequence, ensuring equitable outcomes\nrequires fundamentally different algorithmic design principles that ensure\nrobustness to the decision-maker's (a priori unknown) compliance pattern. We\ndefine the notion of compliance-robustly fair algorithmic recommendations that\nare guaranteed to (weakly) improve fairness in decisions, regardless of the\nhuman's compliance pattern. We propose a simple optimization strategy to\nidentify the best performance-improving compliance-robustly fair policy.\nHowever, we show that it may be infeasible to design algorithmic\nrecommendations that are simultaneously fair in isolation, compliance-robustly\nfair, and more accurate than the human policy; thus, if our goal is to improve\nthe equity and accuracy of human-AI collaboration, it may not be desirable to\nenforce traditional fairness constraints.",
          "link": "http://arxiv.org/abs/2310.03647",
          "publishedOn": "2023-10-07T00:42:17.087Z",
          "wordCount": 659,
          "title": "Rethinking Fairness for Human-AI Collaboration. (arXiv:2310.03647v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_Y/0/1/0/all/0/1\">Yuka Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "We identify hidden layers inside a DNN with group actions on the data space,\nand formulate the DNN as a dual voice transform with respect to Koopman\noperator, a linear representation of the group action. Based on the group\ntheoretic arguments, particularly by using Schur's lemma, we show a simple\nproof of the universality of those DNNs.",
          "link": "http://arxiv.org/abs/2310.03529",
          "publishedOn": "2023-10-07T00:42:17.062Z",
          "wordCount": 583,
          "title": "Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality of Formal Deep Networks. (arXiv:2310.03529v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peiyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaxuan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sirui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in the field of generative modeling due to its\nflexibility in the formulation and strong modeling power of the latent space.\nHowever, the common practice of learning latent space EBMs with non-convergent\nshort-run MCMC for prior and posterior sampling is hindering the model from\nfurther progress; the degenerate MCMC sampling quality in practice often leads\nto degraded generation quality and instability in training, especially with\nhighly multi-modal and/or high-dimensional target distributions. To remedy this\nsampling issue, in this paper we introduce a simple but effective\ndiffusion-based amortization method for long-run MCMC sampling and develop a\nnovel learning algorithm for the latent space EBM based on it. We provide\ntheoretical evidence that the learned amortization of MCMC is a valid long-run\nMCMC sampler. Experiments on several image modeling benchmark datasets\ndemonstrate the superior performance of our method compared with strong\ncounterparts",
          "link": "http://arxiv.org/abs/2310.03218",
          "publishedOn": "2023-10-07T00:42:17.056Z",
          "wordCount": 669,
          "title": "Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.00079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattaneo_M/0/1/0/all/0/1\">Matias D. Cattaneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klusowski_J/0/1/0/all/0/1\">Jason M. Klusowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shigida_B/0/1/0/all/0/1\">Boris Shigida</a>",
          "description": "In previous literature, backward error analysis was used to find ordinary\ndifferential equations (ODEs) approximating the gradient descent trajectory. It\nwas found that finite step sizes implicitly regularize solutions because terms\nappearing in the ODEs penalize the two-norm of the loss gradients. We prove\nthat the existence of similar implicit regularization in RMSProp and Adam\ndepends on their hyperparameters and the training stage, but with a different\n\"norm\" involved: the corresponding ODE terms either penalize the (perturbed)\none-norm of the loss gradients or, on the contrary, hinder its decrease (the\nlatter case being typical). We also conduct numerical experiments and discuss\nhow the proven facts can influence generalization.",
          "link": "http://arxiv.org/abs/2309.00079",
          "publishedOn": "2023-10-07T00:42:17.049Z",
          "wordCount": 653,
          "title": "On the Implicit Bias of Adam. (arXiv:2309.00079v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03575",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cui_H/0/1/0/all/0/1\">Hugo Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krzakala_F/0/1/0/all/0/1\">Florent Krzakala</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "We study the problem of training a flow-based generative model, parametrized\nby a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture.\nWe provide a sharp end-to-end analysis of the problem. First, we provide a\ntight closed-form characterization of the learnt velocity field, when\nparametrized by a shallow denoising auto-encoder trained on a finite number $n$\nof samples from the target distribution. Building on this analysis, we provide\na sharp description of the corresponding generative flow, which pushes the base\nGaussian density forward to an approximation of the target density. In\nparticular, we provide closed-form formulae for the distance between the mean\nof the generated mixture and the mean of the target mixture, which we show\ndecays as $\\Theta_n(\\frac{1}{n})$. Finally, this rate is shown to be in fact\nBayes-optimal.",
          "link": "http://arxiv.org/abs/2310.03575",
          "publishedOn": "2023-10-07T00:42:17.042Z",
          "wordCount": 637,
          "title": "Analysis of learning a flow-based generative model from limited sample complexity. (arXiv:2310.03575v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gong_S/0/1/0/all/0/1\">Shijin Gong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>",
          "description": "When artificial neural networks have demonstrated exceptional practical\nsuccess in a variety of domains, investigations into their theoretical\ncharacteristics, such as their approximation power, statistical properties, and\ngeneralization performance, have concurrently made significant strides. In this\npaper, we construct a novel theory for understanding the effectiveness of\nneural networks, which offers a perspective distinct from prior research.\nSpecifically, we explore the rationale underlying a common practice during the\nconstruction of neural network models: sample splitting. Our findings indicate\nthat the optimal hyperparameters derived from sample splitting can enable a\nneural network model that asymptotically minimizes the prediction risk. We\nconduct extensive experiments across different application scenarios and\nnetwork architectures, and the results manifest our theory's effectiveness.",
          "link": "http://arxiv.org/abs/2307.07726",
          "publishedOn": "2023-10-07T00:42:17.035Z",
          "wordCount": 647,
          "title": "Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.02671",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Klein_S/0/1/0/all/0/1\">Sara Klein</a>, <a href=\"http://arxiv.org/find/math/1/au:+Weissmann_S/0/1/0/all/0/1\">Simon Weissmann</a>, <a href=\"http://arxiv.org/find/math/1/au:+Doring_L/0/1/0/all/0/1\">Leif D&#xf6;ring</a>",
          "description": "Markov Decision Processes (MDPs) are a formal framework for modeling and\nsolving sequential decision-making problems. In finite-time horizons such\nproblems are relevant for instance for optimal stopping or specific supply\nchain problems, but also in the training of large language models. In contrast\nto infinite horizon MDPs optimal policies are not stationary, policies must be\nlearned for every single epoch. In practice all parameters are often trained\nsimultaneously, ignoring the inherent structure suggested by dynamic\nprogramming. This paper introduces a combination of dynamic programming and\npolicy gradient called dynamic policy gradient, where the parameters are\ntrained backwards in time. For the tabular softmax parametrisation we carry out\nthe convergence analysis for simultaneous and dynamic policy gradient towards\nglobal optima, both in the exact and sampled gradient settings without\nregularisation. It turns out that the use of dynamic policy gradient training\nmuch better exploits the structure of finite-time problems which is reflected\nin improved convergence bounds.",
          "link": "http://arxiv.org/abs/2310.02671",
          "publishedOn": "2023-10-07T00:42:16.999Z",
          "wordCount": 664,
          "title": "Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods. (arXiv:2310.02671v1 [math.OC] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03546",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Renaud_M/0/1/0/all/0/1\">Marien Renaud</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jiaming Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin de Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almansa_A/0/1/0/all/0/1\">Andr&#xe9;s Almansa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kamilov_U/0/1/0/all/0/1\">Ulugbek S. Kamilov</a>",
          "description": "Posterior sampling has been shown to be a powerful Bayesian approach for\nsolving imaging inverse problems. The recent plug-and-play unadjusted Langevin\nalgorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling\nand minimum mean squared error (MMSE) estimation by combining physical\nmeasurement models with deep-learning priors specified using image denoisers.\nHowever, the intricate relationship between the sampling distribution of\nPnP-ULA and the mismatched data-fidelity and denoiser has not been\ntheoretically analyzed. We address this gap by proposing a posterior-L2\npseudometric and using it to quantify an explicit error bound for PnP-ULA under\nmismatched posterior distribution. We numerically validate our theory on\nseveral inverse problems such as sampling from Gaussian mixture models and\nimage deblurring. Our results suggest that the sensitivity of the sampling\ndistribution of PnP-ULA to a mismatch in the measurement model and the denoiser\ncan be precisely characterized.",
          "link": "http://arxiv.org/abs/2310.03546",
          "publishedOn": "2023-10-07T00:42:16.973Z",
          "wordCount": 648,
          "title": "Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Deqian Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "This paper proposes a latent prompt Transformer model for solving challenging\noptimization problems such as molecule design, where the goal is to find\nmolecules with optimal values of a target chemical or biological property that\ncan be computed by an existing software. Our proposed model consists of three\ncomponents. (1) A latent vector whose prior distribution is modeled by a Unet\ntransformation of a Gaussian white noise vector. (2) A molecule generation\nmodel that generates the string-based representation of molecule conditional on\nthe latent vector in (1). We adopt the causal Transformer model that takes the\nlatent vector in (1) as prompt. (3) A property prediction model that predicts\nthe value of the target property of a molecule based on a non-linear regression\non the latent vector in (1). We call the proposed model the latent prompt\nTransformer model. After initial training of the model on existing molecules\nand their property values, we then gradually shift the model distribution\ntowards the region that supports desired values of the target property for the\npurpose of molecule design. Our experiments show that our proposed model\nachieves state of the art performances on several benchmark molecule design\ntasks.",
          "link": "http://arxiv.org/abs/2310.03253",
          "publishedOn": "2023-10-07T00:42:16.966Z",
          "wordCount": 697,
          "title": "Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03234",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1\">Quanqi Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_D/0/1/0/all/0/1\">Dixian Zhu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "This paper investigates new families of compositional optimization problems,\ncalled $\\underline{\\bf n}$on-$\\underline{\\bf s}$mooth $\\underline{\\bf\nw}$eakly-$\\underline{\\bf c}$onvex $\\underline{\\bf f}$inite-sum $\\underline{\\bf\nc}$oupled $\\underline{\\bf c}$ompositional $\\underline{\\bf o}$ptimization (NSWC\nFCCO). There has been a growing interest in FCCO due to its wide-ranging\napplications in machine learning and AI, as well as its ability to address the\nshortcomings of stochastic algorithms based on empirical risk minimization.\nHowever, current research on FCCO presumes that both the inner and outer\nfunctions are smooth, limiting their potential to tackle a more diverse set of\nproblems. Our research expands on this area by examining non-smooth\nweakly-convex FCCO, where the outer function is weakly convex and\nnon-decreasing, and the inner function is weakly-convex. We analyze a\nsingle-loop algorithm and establish its complexity for finding an\n$\\epsilon$-stationary point of the Moreau envelop of the objective function.\nAdditionally, we also extend the algorithm to solving novel non-smooth\nweakly-convex tri-level finite-sum coupled compositional optimization problems,\nwhich feature a nested arrangement of three functions. Lastly, we explore the\napplications of our algorithms in deep learning for two-way partial AUC\nmaximization and multi-instance two-way partial AUC maximization, using\nempirical studies to showcase the effectiveness of the proposed algorithms.",
          "link": "http://arxiv.org/abs/2310.03234",
          "publishedOn": "2023-10-07T00:42:16.957Z",
          "wordCount": 690,
          "title": "Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03054",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hagemann_P/0/1/0/all/0/1\">Paul Hagemann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hertrich_J/0/1/0/all/0/1\">Johannes Hertrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Altekruger_F/0/1/0/all/0/1\">Fabian Altekr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beinert_R/0/1/0/all/0/1\">Robert Beinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chemseddine_J/0/1/0/all/0/1\">Jannis Chemseddine</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Steidl_G/0/1/0/all/0/1\">Gabriele Steidl</a>",
          "description": "We propose conditional flows of the maximum mean discrepancy (MMD) with the\nnegative distance kernel for posterior sampling and conditional generative\nmodeling. This MMD, which is also known as energy distance, has several\nadvantageous properties like efficient computation via slicing and sorting. We\napproximate the joint distribution of the ground truth and the observations\nusing discrete Wasserstein gradient flows and establish an error bound for the\nposterior distributions. Further, we prove that our particle flow is indeed a\nWasserstein gradient flow of an appropriate functional. The power of our method\nis demonstrated by numerical examples including conditional image generation\nand inverse problems like superresolution, inpainting and computed tomography\nin low-dose and limited-angle settings.",
          "link": "http://arxiv.org/abs/2310.03054",
          "publishedOn": "2023-10-07T00:42:16.927Z",
          "wordCount": 644,
          "title": "Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03597",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_D/0/1/0/all/0/1\">Daniel Zhengyu Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_J/0/1/0/all/0/1\">Jiaoyang Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew M Stuart</a>",
          "description": "Sampling a target probability distribution with an unknown normalization\nconstant is a fundamental challenge in computational science and engineering.\nRecent work shows that algorithms derived by considering gradient flows in the\nspace of probability measures open up new avenues for algorithm development.\nThis paper makes three contributions to this sampling approach by scrutinizing\nthe design components of such gradient flows. Any instantiation of a gradient\nflow for sampling needs an energy functional and a metric to determine the\nflow, as well as numerical approximations of the flow to derive algorithms. Our\nfirst contribution is to show that the Kullback-Leibler divergence, as an\nenergy functional, has the unique property (among all f-divergences) that\ngradient flows resulting from it do not depend on the normalization constant of\nthe target distribution. Our second contribution is to study the choice of\nmetric from the perspective of invariance. The Fisher-Rao metric is known as\nthe unique choice (up to scaling) that is diffeomorphism invariant. As a\ncomputationally tractable alternative, we introduce a relaxed, affine\ninvariance property for the metrics and gradient flows. In particular, we\nconstruct various affine invariant Wasserstein and Stein gradient flows. Affine\ninvariant gradient flows are shown to behave more favorably than their\nnon-affine-invariant counterparts when sampling highly anisotropic\ndistributions, in theory and by using particle methods. Our third contribution\nis to study, and develop efficient algorithms based on Gaussian approximations\nof the gradient flows; this leads to an alternative to particle methods. We\nestablish connections between various Gaussian approximate gradient flows,\ndiscuss their relation to gradient methods arising from parametric variational\ninference, and study their convergence properties both theoretically and\nnumerically.",
          "link": "http://arxiv.org/abs/2310.03597",
          "publishedOn": "2023-10-07T00:42:16.919Z",
          "wordCount": 799,
          "title": "Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2310.03435",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magris_M/0/1/0/all/0/1\">Martin Magris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "The Bayesian estimation of GARCH-family models has been typically addressed\nthrough Monte Carlo sampling. Variational Inference is gaining popularity and\nattention as a robust approach for Bayesian inference in complex machine\nlearning models; however, its adoption in econometrics and finance is limited.\nThis paper discusses the extent to which Variational Inference constitutes a\nreliable and feasible alternative to Monte Carlo sampling for Bayesian\ninference in GARCH-like models. Through a large-scale experiment involving the\nconstituents of the S&P 500 index, several Variational Inference optimizers, a\nvariety of volatility models, and a case study, we show that Variational\nInference is an attractive, remarkably well-calibrated, and competitive method\nfor Bayesian learning.",
          "link": "http://arxiv.org/abs/2310.03435",
          "publishedOn": "2023-10-07T00:42:16.903Z",
          "wordCount": 592,
          "title": "Variational Inference for GARCH-family Models. (arXiv:2310.03435v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.16102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajorlou_A/0/1/0/all/0/1\">Amir Ajorlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jadbabaie_A/0/1/0/all/0/1\">Ali Jadbabaie</a>",
          "description": "Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where\nincreasing network depth leads to homogeneous node representations. While\nprevious work has established that Graph Convolutional Networks (GCNs)\nexponentially lose expressive power, it remains controversial whether the graph\nattention mechanism can mitigate oversmoothing. In this work, we provide a\ndefinitive answer to this question through a rigorous mathematical analysis, by\nviewing attention-based GNNs as nonlinear time-varying dynamical systems and\nincorporating tools and techniques from the theory of products of inhomogeneous\nmatrices and the joint spectral radius. We establish that, contrary to popular\nbelief, the graph attention mechanism cannot prevent oversmoothing and loses\nexpressive power exponentially. The proposed framework extends the existing\nresults on oversmoothing for symmetric GCNs to a significantly broader class of\nGNN models, including random walk GCNs, Graph Attention Networks (GATs) and\n(graph) transformers. In particular, our analysis accounts for asymmetric,\nstate-dependent and time-varying aggregation operators and a wide range of\ncommon nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU.",
          "link": "http://arxiv.org/abs/2305.16102",
          "publishedOn": "2023-10-07T00:42:16.767Z",
          "wordCount": 699,
          "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1812.00029",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Panda_S/0/1/0/all/0/1\">Sambit Panda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1\">Cencheng Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Decision forests are widely used for classification and regression tasks. A\nlesser known property of tree-based methods is that one can construct a\nproximity matrix from the tree(s), and these proximity matrices are induced\nkernels. While there has been extensive research on the applications and\nproperties of kernels, there is relatively little research on kernels induced\nby decision forests. We construct Kernel Mean Embedding Random Forests (KMERF),\nwhich induce kernels from random trees and/or forests using leaf-node\nproximity. We introduce the notion of an asymptotically characteristic kernel,\nand prove that KMERF kernels are asymptotically characteristic for both\ndiscrete and continuous data. Because KMERF is data-adaptive, we suspected it\nwould outperform kernels selected a priori on finite sample data. We illustrate\nthat KMERF nearly dominates current state-of-the-art kernel-based tests across\na diverse range of high-dimensional two-sample and independence testing\nsettings. Furthermore, our forest-based approach is interpretable, and provides\nfeature importance metrics that readily distinguish important dimensions,\nunlike other high-dimensional non-parametric testing procedures. Hence, this\nwork demonstrates the decision forest-based kernel can be more powerful and\nmore interpretable than existing methods, flying in the face of conventional\nwisdom of the trade-off between the two.",
          "link": "http://arxiv.org/abs/1812.00029",
          "publishedOn": "2023-09-30T00:41:30.863Z",
          "wordCount": null,
          "title": "Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1911.09307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>",
          "description": "Regularization plays a crucial role in machine learning models, especially\nfor deep neural networks. The existing regularization techniques mainly rely on\nthe i.i.d. assumption and only consider the knowledge from the current sample,\nwithout the leverage of the neighboring relationship between samples. In this\nwork, we propose a general regularizer called \\textbf{Patch-level Neighborhood\nInterpolation~(Pani)} that conducts a non-local representation in the\ncomputation of networks. Our proposal explicitly constructs patch-level graphs\nin different layers and then linearly interpolates neighborhood patch features,\nserving as a general and effective regularization strategy. Further, we\ncustomize our approach into two kinds of popular regularization methods, namely\nVirtual Adversarial Training (VAT) and MixUp as well as its variants. The first\nderived \\textbf{Pani VAT} presents a novel way to construct non-local\nadversarial smoothness by employing patch-level interpolated perturbations. The\nsecond derived \\textbf{Pani MixUp} method extends the MixUp, and achieves\nsuperiority over MixUp and competitive performance over state-of-the-art\nvariants of MixUp method with a significant advantage in computational\nefficiency. Extensive experiments have verified the effectiveness of our Pani\napproach in both supervised and semi-supervised settings.",
          "link": "http://arxiv.org/abs/1911.09307",
          "publishedOn": "2023-09-30T00:41:30.701Z",
          "wordCount": null,
          "title": "Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10259",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Denis_C/0/1/0/all/0/1\">Christophe Denis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dion_Blanc_C/0/1/0/all/0/1\">Charlotte Dion-Blanc</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mintsa_E/0/1/0/all/0/1\">Eddy Ella Mintsa</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tran_V/0/1/0/all/0/1\">Viet-Chi Tran</a>",
          "description": "We study the multiclass classification problem where the features come from\nthe mixture of time-homogeneous diffusions. Specifically, the classes are\ndiscriminated by their drift functions while the diffusion coefficient is\ncommon to all classes and unknown. In this framework, we build a plug-in\nclassifier which relies on nonparametric estimators of the drift and diffusion\nfunctions. We first establish the consistency of our classification procedure\nunder mild assumptions and then provide rates of cnvergence under different set\nof assumptions. Finally, a numerical study supports our theoretical findings.",
          "link": "http://arxiv.org/abs/2212.10259",
          "publishedOn": "2023-09-30T00:41:30.700Z",
          "wordCount": null,
          "title": "Nonparametric plug-in classifier for multiclass classification of S.D.E. paths. (arXiv:2212.10259v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16492",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">Hanyu Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tanneau_M/0/1/0/all/0/1\">Mathieu Tanneau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_C/0/1/0/all/0/1\">Chaofan Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Joseph_V/0/1/0/all/0/1\">V. Roshan Joseph</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shangkun Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hentenryck_P/0/1/0/all/0/1\">Pascal Van Hentenryck</a>",
          "description": "The growing penetration of intermittent, renewable generation in US power\ngrids, especially wind and solar generation, results in increased operational\nuncertainty. In that context, accurate forecasts are critical, especially for\nwind generation, which exhibits large variability and is historically harder to\npredict. To overcome this challenge, this work proposes a novel\nBundle-Predict-Reconcile (BPR) framework that integrates asset bundling,\nmachine learning, and forecast reconciliation techniques. The BPR framework\nfirst learns an intermediate hierarchy level (the bundles), then predicts wind\npower at the asset, bundle, and fleet level, and finally reconciles all\nforecasts to ensure consistency. This approach effectively introduces an\nauxiliary learning task (predicting the bundle-level time series) to help the\nmain learning tasks. The paper also introduces new asset-bundling criteria that\ncapture the spatio-temporal dynamics of wind power time series. Extensive\nnumerical experiments are conducted on an industry-size dataset of 283 wind\nfarms in the MISO footprint. The experiments consider short-term and day-ahead\nforecasts, and evaluates a large variety of forecasting models that include\nweather predictions as covariates. The results demonstrate the benefits of BPR,\nwhich consistently and significantly improves forecast accuracy over baselines,\nespecially at the fleet level.",
          "link": "http://arxiv.org/abs/2309.16492",
          "publishedOn": "2023-09-30T00:41:30.679Z",
          "wordCount": null,
          "title": "Asset Bundling for Wind Power Forecasting. (arXiv:2309.16492v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16476",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Adomaityte_U/0/1/0/all/0/1\">Urte Adomaityte</a>, <a href=\"http://arxiv.org/find/math/1/au:+Defilippis_L/0/1/0/all/0/1\">Leonardo Defilippis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Loureiro_B/0/1/0/all/0/1\">Bruno Loureiro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sicuro_G/0/1/0/all/0/1\">Gabriele Sicuro</a>",
          "description": "We investigate the high-dimensional properties of robust regression\nestimators in the presence of heavy-tailed contamination of both the covariates\nand response functions. In particular, we provide a sharp asymptotic\ncharacterisation of M-estimators trained on a family of elliptical covariate\nand noise data distributions including cases where second and higher moments do\nnot exist. We show that, despite being consistent, the Huber loss with\noptimally tuned location parameter $\\delta$ is suboptimal in the\nhigh-dimensional regime in the presence of heavy-tailed noise, highlighting the\nnecessity of further regularisation to achieve optimal performance. This result\nalso uncovers the existence of a curious transition in $\\delta$ as a function\nof the sample complexity and contamination. Moreover, we derive the decay rates\nfor the excess risk of ridge regression. We show that, while it is both optimal\nand universal for noise distributions with finite second moment, its decay rate\ncan be considerably faster when the covariates' second moment does not exist.\nFinally, we show that our formulas readily generalise to a richer family of\nmodels and data distributions, such as generalised linear estimation with\narbitrary convex regularisation trained on mixture models.",
          "link": "http://arxiv.org/abs/2309.16476",
          "publishedOn": "2023-09-30T00:41:30.674Z",
          "wordCount": null,
          "title": "High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality. (arXiv:2309.16476v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08079",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_L/0/1/0/all/0/1\">Likun Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_X/0/1/0/all/0/1\">Xiaoyu Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wikle_C/0/1/0/all/0/1\">Christopher K. Wikle</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huser_R/0/1/0/all/0/1\">Rapha&#xeb;l Huser</a>",
          "description": "Many real-world processes have complex tail dependence structures that cannot\nbe characterized using classical Gaussian processes. More flexible spatial\nextremes models exhibit appealing extremal dependence properties but are often\nexceedingly prohibitive to fit and simulate from in high dimensions. In this\npaper, we develop a new spatial extremes model that has flexible and\nnon-stationary dependence properties, and we integrate it in the\nencoding-decoding structure of a variational autoencoder (XVAE), whose\nparameters are estimated via variational Bayes combined with deep learning. The\nXVAE can be used as a spatio-temporal emulator that characterizes the\ndistribution of potential mechanistic model output states and produces outputs\nthat have the same statistical properties as the inputs, especially in the\ntail. As an aside, our approach also provides a novel way of making fast\ninference with complex extreme-value processes. Through extensive simulation\nstudies, we show that our XVAE is substantially more time-efficient than\ntraditional Bayesian inference while also outperforming many spatial extremes\nmodels with a stationary dependence structure. To further demonstrate the\ncomputational power of the XVAE, we analyze a high-resolution satellite-derived\ndataset of sea surface temperature in the Red Sea, which includes 30 years of\ndaily measurements at 16703 grid cells. We find that the extremal dependence\nstrength is weaker in the interior of Red Sea and it has decreased slightly\nover time.",
          "link": "http://arxiv.org/abs/2307.08079",
          "publishedOn": "2023-09-30T00:41:30.658Z",
          "wordCount": null,
          "title": "Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1\">Adri&#xe1;n Bazaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1\">Gos Micklem</a>",
          "description": "Unsupervised fact verification aims to verify a claim using evidence from a\ntrustworthy knowledge base without any kind of data annotation. To address this\nchallenge, algorithms must produce features for every claim that are both\nsemantically meaningful, and compact enough to find a semantic alignment with\nthe source information. In contrast to previous work, which tackled the\nalignment problem by learning over annotated corpora of claims and their\ncorresponding labels, we propose SFAVEL (Self-supervised Fact Verification via\nLanguage Model Distillation), a novel unsupervised framework that leverages\npre-trained language models to distil self-supervised features into\nhigh-quality claim-fact alignments without the need for annotations. This is\nenabled by a novel contrastive loss function that encourages features to attain\nhigh-quality claim and evidence alignments whilst preserving the semantic\nrelationships across the corpora. Notably, we present results that achieve a\nnew state-of-the-art on the standard FEVER fact verification benchmark (+8%\naccuracy) with linear evaluation.",
          "link": "http://arxiv.org/abs/2309.16540",
          "publishedOn": "2023-09-30T00:41:30.587Z",
          "wordCount": 651,
          "title": "Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16620",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Mufan Bill Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "The cost of hyperparameter tuning in deep learning has been rising with model\nsizes, prompting practitioners to find new tuning methods using a proxy of\nsmaller networks. One such proposal uses $\\mu$P parameterized networks, where\nthe optimal hyperparameters for small width networks transfer to networks with\narbitrarily large width. However, in this scheme, hyperparameters do not\ntransfer across depths. As a remedy, we study residual networks with a residual\nbranch scale of $1/\\sqrt{\\text{depth}}$ in combination with the $\\mu$P\nparameterization. We provide experiments demonstrating that residual\narchitectures including convolutional ResNets and Vision Transformers trained\nwith this parameterization exhibit transfer of optimal hyperparameters across\nwidth and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings\nare supported and motivated by theory. Using recent developments in the\ndynamical mean field theory (DMFT) description of neural network learning\ndynamics, we show that this parameterization of ResNets admits a well-defined\nfeature learning joint infinite-width and infinite-depth limit and show\nconvergence of finite-size network dynamics towards this limit.",
          "link": "http://arxiv.org/abs/2309.16620",
          "publishedOn": "2023-09-30T00:41:30.578Z",
          "wordCount": null,
          "title": "Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07227",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_B/0/1/0/all/0/1\">Benjamin J. Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marzouk_Y/0/1/0/all/0/1\">Youssef M. Marzouk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Spiliopoulos_K/0/1/0/all/0/1\">Konstantinos Spiliopoulos</a>",
          "description": "Langevin dynamics are widely used in sampling high-dimensional, non-Gaussian\ndistributions whose densities are known up to a normalizing constant. In\nparticular, there is strong interest in unadjusted Langevin algorithms (ULA),\nwhich directly discretize Langevin dynamics to estimate expectations over the\ntarget distribution. We study the use of transport maps that approximately\nnormalize a target distribution as a way to precondition and accelerate the\nconvergence of Langevin dynamics. We show that in continuous time, when a\ntransport map is applied to Langevin dynamics, the result is a Riemannian\nmanifold Langevin dynamics (RMLD) with metric defined by the transport map. We\nalso show that applying a transport map to an irreversibly-perturbed ULA\nresults in a geometry-informed irreversible perturbation (GiIrr) of the\noriginal dynamics. These connections suggest more systematic ways of learning\nmetrics and perturbations, and also yield alternative discretizations of the\nRMLD described by the map, which we study. Under appropriate conditions, these\ndiscretized processes can be endowed with non-asymptotic bounds describing\nconvergence to the target distribution in 2-Wasserstein distance. Illustrative\nnumerical results complement our theoretical claims.",
          "link": "http://arxiv.org/abs/2302.07227",
          "publishedOn": "2023-09-30T00:41:30.434Z",
          "wordCount": null,
          "title": "Transport map unadjusted Langevin algorithms: learning and discretizing perturbed samplers. (arXiv:2302.07227v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16448",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zukovic_M/0/1/0/all/0/1\">Milan &#x17d;ukovi&#x10d;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hristopulos_D/0/1/0/all/0/1\">Dionissios T. Hristopulos</a>",
          "description": "We introduce the modified planar rotator method (MPRS), a physically inspired\nmachine learning method for spatial/temporal regression. MPRS is a\nnon-parametric model which incorporates spatial or temporal correlations via\nshort-range, distance-dependent ``interactions'' without assuming a specific\nform for the underlying probability distribution. Predictions are obtained by\nmeans of a fully autonomous learning algorithm which employs equilibrium\nconditional Monte Carlo simulations. MPRS is able to handle scattered data and\narbitrary spatial dimensions. We report tests on various synthetic and\nreal-word data in one, two and three dimensions which demonstrate that the MPRS\nprediction performance (without parameter tuning) is competitive with standard\ninterpolation methods such as ordinary kriging and inverse distance weighting.\nIn particular, MPRS is a particularly effective gap-filling method for rough\nand non-Gaussian data (e.g., daily precipitation time series). MPRS shows\nsuperior computational efficiency and scalability for large samples. Massive\ndata sets involving millions of nodes can be processed in a few seconds on a\nstandard personal computer.",
          "link": "http://arxiv.org/abs/2309.16448",
          "publishedOn": "2023-09-30T00:41:30.422Z",
          "wordCount": 666,
          "title": "A parsimonious, computationally efficient machine learning method for spatial regression. (arXiv:2309.16448v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16274",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bargiotas_I/0/1/0/all/0/1\">Ioannis Bargiotas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kalogeratos_A/0/1/0/all/0/1\">Argyris Kalogeratos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vayatis_N/0/1/0/all/0/1\">Nicolas Vayatis</a>",
          "description": "The standard paired-sample testing approach in the multidimensional setting\napplies multiple univariate tests on the individual features, followed by\np-value adjustments. Such an approach suffers when the data carry numerous\nfeatures. A number of studies have shown that classification accuracy can be\nseen as a proxy for two-sample testing. However, neither theoretical\nfoundations nor practical recipes have been proposed so far on how this\nstrategy could be extended to multidimensional paired-sample testing. In this\nwork, we put forward the idea that scoring functions can be produced by the\ndecision rules defined by the perpendicular bisecting hyperplanes of the line\nsegments connecting each pair of instances. Then, the optimal scoring function\ncan be obtained by the pseudomedian of those rules, which we estimate by\nextending naturally the Hodges-Lehmann estimator. We accordingly propose a\nframework of a two-step testing procedure. First, we estimate the bisecting\nhyperplanes for each pair of instances and an aggregated rule derived through\nthe Hodges-Lehmann estimator. The paired samples are scored by this aggregated\nrule to produce a unidimensional representation. Second, we perform a Wilcoxon\nsigned-rank test on the obtained representation. Our experiments indicate that\nour approach has substantial performance gains in testing accuracy compared to\nthe traditional multivariate and multiple testing, while at the same time\nestimates each feature's contribution to the final result.",
          "link": "http://arxiv.org/abs/2309.16274",
          "publishedOn": "2023-09-30T00:41:30.416Z",
          "wordCount": 744,
          "title": "A framework for paired-sample hypothesis testing for high-dimensional data. (arXiv:2309.16274v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1\">Mert Pilanci</a>",
          "description": "In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.",
          "link": "http://arxiv.org/abs/2309.16512",
          "publishedOn": "2023-09-30T00:41:30.410Z",
          "wordCount": 670,
          "title": "From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.15728",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Luo_Y/0/1/0/all/0/1\">Yuetian Luo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_C/0/1/0/all/0/1\">Chao Gao</a>",
          "description": "Graphon estimation has been one of the most fundamental problems in network\nanalysis and has received considerable attention in the past decade. From the\nstatistical perspective, the minimax error rate of graphon estimation has been\nestablished by Gao et al (2015) for both stochastic block model (SBM) and\nnonparametric graphon estimation. The statistical optimal estimators are based\non constrained least squares and have computational complexity exponential in\nthe dimension. From the computational perspective, the best-known\npolynomial-time estimator is based on universal singular value thresholding\n(USVT), but it can only achieve a much slower estimation error rate than the\nminimax one. It is natural to wonder if such a gap is essential. The\ncomputational optimality of the USVT or the existence of a computational\nbarrier in graphon estimation has been a long-standing open problem. In this\nwork, we take the first step towards it and provide rigorous evidence for the\ncomputational barrier in graphon estimation via low-degree polynomials.\nSpecifically, in both SBM and nonparametric graphon estimation, we show that\nfor low-degree polynomial estimators, their estimation error rates cannot be\nsignificantly better than that of the USVT under a wide range of parameter\nregimes. Our results are proved based on the recent development of low-degree\npolynomials by Schramm and Wein (2022), while we overcome a few key challenges\nin applying it to the general graphon estimation problem. By leveraging our\nmain results, we also provide a computational lower bound on the clustering\nerror for community detection in SBM with a growing number of communities and\nthis yields a new piece of evidence for the conjectured Kesten-Stigum threshold\nfor efficient community recovery.",
          "link": "http://arxiv.org/abs/2308.15728",
          "publishedOn": "2023-09-30T00:41:30.296Z",
          "wordCount": null,
          "title": "Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials. (arXiv:2308.15728v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16314",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Arbel_J/0/1/0/all/0/1\">Julyan Arbel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pitas_K/0/1/0/all/0/1\">Konstantinos Pitas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vladimirova_M/0/1/0/all/0/1\">Mariia Vladimirova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>",
          "description": "Neural networks have achieved remarkable performance across various problem\ndomains, but their widespread applicability is hindered by inherent limitations\nsuch as overconfidence in predictions, lack of interpretability, and\nvulnerability to adversarial attacks. To address these challenges, Bayesian\nneural networks (BNNs) have emerged as a compelling extension of conventional\nneural networks, integrating uncertainty estimation into their predictive\ncapabilities.\n\nThis comprehensive primer presents a systematic introduction to the\nfundamental concepts of neural networks and Bayesian inference, elucidating\ntheir synergistic integration for the development of BNNs. The target audience\ncomprises statisticians with a potential background in Bayesian methods but\nlacking deep learning expertise, as well as machine learners proficient in deep\nneural networks but with limited exposure to Bayesian statistics. We provide an\noverview of commonly employed priors, examining their impact on model behavior\nand performance. Additionally, we delve into the practical considerations\nassociated with training and inference in BNNs.\n\nFurthermore, we explore advanced topics within the realm of BNN research,\nacknowledging the existence of ongoing debates and controversies. By offering\ninsights into cutting-edge developments, this primer not only equips\nresearchers and practitioners with a solid foundation in BNNs, but also\nilluminates the potential applications of this dynamic field. As a valuable\nresource, it fosters an understanding of BNNs and their promising prospects,\nfacilitating further advancements in the pursuit of knowledge and innovation.",
          "link": "http://arxiv.org/abs/2309.16314",
          "publishedOn": "2023-09-30T00:41:30.287Z",
          "wordCount": null,
          "title": "A Primer on Bayesian Neural Networks: Review and Debates. (arXiv:2309.16314v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>",
          "description": "Semi-supervised learning (SSL) is a promising approach for training deep\nclassification models using labeled and unlabeled datasets. However, existing\nSSL methods rely on a large unlabeled dataset, which may not always be\navailable in many real-world applications due to legal constraints (e.g.,\nGDPR). In this paper, we investigate the research question: Can we train SSL\nmodels without real unlabeled datasets? Instead of using real unlabeled\ndatasets, we propose an SSL method using synthetic datasets generated from\ngenerative foundation models trained on datasets containing millions of samples\nin diverse domains (e.g., ImageNet). Our main concepts are identifying\nsynthetic samples that emulate unlabeled samples from generative foundation\nmodels and training classifiers using these synthetic samples. To achieve this,\nour method is formulated as an alternating optimization problem: (i)\nmeta-learning of generative foundation models and (ii) SSL of classifiers using\nreal labeled and synthetic unlabeled samples. For (i), we propose a\nmeta-learning objective that optimizes latent variables to generate samples\nthat resemble real labeled samples and minimize the validation loss. For (ii),\nwe propose a simple unsupervised loss function that regularizes the feature\nextractors of classifiers to maximize the performance improvement obtained from\nsynthetic samples. We confirm that our method outperforms baselines using\ngenerative foundation models on SSL. We also demonstrate that our methods\noutperform SSL using real unlabeled datasets in scenarios with extremely small\namounts of labeled datasets. This suggests that synthetic samples have the\npotential to provide improvement gains more efficiently than real unlabeled\ndata.",
          "link": "http://arxiv.org/abs/2309.16143",
          "publishedOn": "2023-09-30T00:41:30.273Z",
          "wordCount": 761,
          "title": "Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1\">Wenzhuo Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qu_A/0/1/0/all/0/1\">Annie Qu</a>",
          "description": "Batch reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data lacking exhaustive exploration. Worst-case optimality algorithms,\nwhich calibrate a value-function model class from logged experience and perform\nsome type of pessimistic evaluation under the learned model, have emerged as a\npromising paradigm for batch RL. However, contemporary works on this stream\nhave commonly overlooked the hierarchical decision-making structure hidden in\nthe optimization landscape. In this paper, we adopt a game-theoretical\nviewpoint and model the policy learning diagram as a two-player general-sum\ngame with a leader-follower structure. We propose a novel stochastic\ngradient-based learning algorithm: StackelbergLearner, in which the leader\nplayer updates according to the total derivative of its objective instead of\nthe usual individual gradient, and the follower player makes individual updates\nand ensures transition-consistent pessimistic reasoning. The derived learning\ndynamic naturally lends StackelbergLearner to a game-theoretic interpretation\nand provides a convergence guarantee to differentiable Stackelberg equilibria.\nFrom a theoretical standpoint, we provide instance-dependent regret bounds with\ngeneral function approximation, which shows that our algorithm can learn a\nbest-effort policy that is able to compete against any comparator policy that\nis covered by batch data. Notably, our theoretical regret guarantees only\nrequire realizability without any data coverage and strong function\napproximation conditions, e.g., Bellman closedness, which is in contrast to\nprior works lacking such guarantees. Through comprehensive experiments, we find\nthat our algorithm consistently performs as well or better as compared to\nstate-of-the-art methods in batch RL benchmark and real-world datasets.",
          "link": "http://arxiv.org/abs/2309.16188",
          "publishedOn": "2023-09-30T00:41:30.253Z",
          "wordCount": null,
          "title": "Stackelberg Batch Policy Learning. (arXiv:2309.16188v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Han Bao</a>",
          "description": "Contrastive learning is a self-supervised representation learning framework,\nwhere two positive views generated through data augmentation are made similar\nby an attraction force in a data representation space, while a repulsive force\nmakes them far from negative examples. Non-contrastive learning, represented by\nBYOL and SimSiam, further gets rid of negative examples and improves\ncomputational efficiency. While learned representations may collapse into a\nsingle point due to the lack of the repulsive force at first sight, Tian et al.\n(2021) revealed through the learning dynamics analysis that the representations\ncan avoid collapse if data augmentation is sufficiently stronger than\nregularization. However, their analysis does not take into account\ncommonly-used feature normalization, a normalizer before measuring the\nsimilarity of representations, and hence excessively strong regularization may\ncollapse the dynamics, which is an unnatural behavior under the presence of\nfeature normalization. Therefore, we extend the previous theory based on the L2\nloss by considering the cosine loss, which involves feature normalization. We\nshow that the cosine loss induces sixth-order dynamics (while the L2 loss\ninduces a third-order one), in which a stable equilibrium dynamically emerges\neven if there are only collapsed solutions with given initial parameters. Thus,\nwe offer a new understanding that feature normalization plays an important role\nin robustly preventing the dynamics collapse.",
          "link": "http://arxiv.org/abs/2309.16109",
          "publishedOn": "2023-09-30T00:41:30.247Z",
          "wordCount": null,
          "title": "Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16521",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schurch_M/0/1/0/all/0/1\">Manuel Sch&#xfc;rch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Allam_A/0/1/0/all/0/1\">Ahmed Allam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rathmes_G/0/1/0/all/0/1\">Giulia Rathmes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mollaysa_A/0/1/0/all/0/1\">Amina Mollaysa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cavelti_Weder_C/0/1/0/all/0/1\">Claudia Cavelti-Weder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krauthammer_M/0/1/0/all/0/1\">Michael Krauthammer</a>",
          "description": "We propose a novel framework that combines deep generative time series models\nwith decision theory for generating personalized treatment strategies. It\nleverages historical patient trajectory data to jointly learn the generation of\nrealistic personalized treatment and future outcome trajectories through deep\ngenerative time series models. In particular, our framework enables the\ngeneration of novel multivariate treatment strategies tailored to the\npersonalized patient history and trained for optimal expected future outcomes\nbased on conditional expected utility maximization. We demonstrate our\nframework by generating personalized insulin treatment strategies and blood\nglucose predictions for hospitalized diabetes patients, showcasing the\npotential of our approach for generating improved personalized treatment\nstrategies. Keywords: deep generative model, probabilistic decision support,\npersonalized treatment generation, insulin and blood glucose prediction",
          "link": "http://arxiv.org/abs/2309.16521",
          "publishedOn": "2023-09-30T00:41:30.181Z",
          "wordCount": 641,
          "title": "Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models. (arXiv:2309.16521v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.03666",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1\">Shide Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fang_Z/0/1/0/all/0/1\">Zihan Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lan_S/0/1/0/all/0/1\">Shiyang Lan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_Y/0/1/0/all/0/1\">Yanchao Tan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gunther_M/0/1/0/all/0/1\">Manuel G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shiping Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guo_W/0/1/0/all/0/1\">Wenzhong Guo</a>",
          "description": "As researchers strive to narrow the gap between machine intelligence and\nhuman through the development of artificial intelligence technologies, it is\nimperative that we recognize the critical importance of trustworthiness in\nopen-world, which has become ubiquitous in all aspects of daily life for\neveryone. However, several challenges may create a crisis of trust in current\nartificial intelligence systems that need to be bridged: 1) Insufficient\nexplanation of predictive results; 2) Inadequate generalization for learning\nmodels; 3) Poor adaptability to uncertain environments. Consequently, we\nexplore a neural program to bridge trustworthiness and open-world learning,\nextending from single-modal to multi-modal scenarios for readers. 1) To enhance\ndesign-level interpretability, we first customize trustworthy networks with\nspecific physical meanings; 2) We then design environmental well-being\ntask-interfaces via flexible learning regularizers for improving the\ngeneralization of trustworthy learning; 3) We propose to increase the\nrobustness of trustworthy learning by integrating open-world recognition losses\nwith agent mechanisms. Eventually, we enhance various trustworthy properties\nthrough the establishment of design-level explainability, environmental\nwell-being task-interfaces and open-world recognition programs. These designed\nopen-world protocols are applicable across a wide range of surroundings, under\nopen-world multimedia recognition scenarios with significant performance\nimprovements observed.",
          "link": "http://arxiv.org/abs/2308.03666",
          "publishedOn": "2023-09-30T00:41:30.123Z",
          "wordCount": null,
          "title": "Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06807",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_X/0/1/0/all/0/1\">Xiran Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1\">Chun-Hao Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vemuri_B/0/1/0/all/0/1\">Baba C. Vemuri</a>",
          "description": "Hyperbolic spaces have been quite popular in the recent past for representing\nhierarchically organized data. Further, several classification algorithms for\ndata in these spaces have been proposed in the literature. These algorithms\nmainly use either hyperplanes or geodesics for decision boundaries in a large\nmargin classifiers setting leading to a non-convex optimization problem. In\nthis paper, we propose a novel large margin classifier based on horospherical\ndecision boundaries that leads to a geodesically convex optimization problem\nthat can be optimized using any Riemannian gradient descent technique\nguaranteeing a globally optimal solution. We present several experiments\ndepicting the competitive performance of our classifier in comparison to SOTA.",
          "link": "http://arxiv.org/abs/2302.06807",
          "publishedOn": "2023-09-30T00:41:30.118Z",
          "wordCount": null,
          "title": "Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16604",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1\">Junjie Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Labeau_M/0/1/0/all/0/1\">Matthieu Labeau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1\">Florence d&#x27;Alch&#xe9;-Buc</a>",
          "description": "Pairwise comparison of graphs is key to many applications in Machine learning\nranging from clustering, kernel-based classification/regression and more\nrecently supervised graph prediction. Distances between graphs usually rely on\ninformative representations of these structured objects such as bag of\nsubstructures or other graph embeddings. A recently popular solution consists\nin representing graphs as metric measure spaces, allowing to successfully\nleverage Optimal Transport, which provides meaningful distances allowing to\ncompare them: the Gromov-Wasserstein distances. However, this family of\ndistances overlooks edge attributes, which are essential for many structured\nobjects. In this work, we introduce an extension of Gromov-Wasserstein distance\nfor comparing graphs whose both nodes and edges have features. We propose novel\nalgorithms for distance and barycenter computation. We empirically show the\neffectiveness of the novel distance in learning tasks where graphs occur in\neither input space or output space, such as classification and graph\nprediction.",
          "link": "http://arxiv.org/abs/2309.16604",
          "publishedOn": "2023-09-30T00:41:30.114Z",
          "wordCount": null,
          "title": "Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein Distance. (arXiv:2309.16604v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.16735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gyorfi_L/0/1/0/all/0/1\">L&#xe1;szl&#xf3; Gy&#xf6;rfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linder_T/0/1/0/all/0/1\">Tam&#xe1;s Linder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walk_H/0/1/0/all/0/1\">Harro Walk</a>",
          "description": "We study the excess minimum risk in statistical inference, defined as the\ndifference between the minimum expected loss in estimating a random variable\nfrom an observed feature vector and the minimum expected loss in estimating the\nsame random variable from a transformation (statistic) of the feature vector.\nAfter characterizing lossless transformations, i.e., transformations for which\nthe excess risk is zero for all loss functions, we construct a partitioning\ntest statistic for the hypothesis that a given transformation is lossless and\nshow that for i.i.d. data the test is strongly consistent. More generally, we\ndevelop information-theoretic upper bounds on the excess risk that uniformly\nhold over fairly general classes of loss functions. Based on these bounds, we\nintroduce the notion of a delta-lossless transformation and give sufficient\nconditions for a given transformation to be universally delta-lossless.\nApplications to classification, nonparametric regression, portfolio strategies,\ninformation bottleneck, and deep learning, are also surveyed.",
          "link": "http://arxiv.org/abs/2307.16735",
          "publishedOn": "2023-09-30T00:41:30.109Z",
          "wordCount": null,
          "title": "Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v2 [cs.IT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.12547",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Li_J/0/1/0/all/0/1\">Jin Li</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Luo_Y/0/1/0/all/0/1\">Ye Luo</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaowei Zhang</a>",
          "description": "This paper identifies and addresses dynamic selection problems in online\nlearning algorithms with endogenous data. In a contextual multi-armed bandit\nmodel, a novel bias (self-fulfilling bias) arises because the endogeneity of\nthe data influences the choices of decisions, affecting the distribution of\nfuture data to be collected and analyzed. We propose an\ninstrumental-variable-based algorithm to correct for the bias. It obtains true\nparameter values and attains low (logarithmic-like) regret levels. We also\nprove a central limit theorem for statistical inference. To establish the\ntheoretical properties, we develop a general technique that untangles the\ninterdependence between data and actions.",
          "link": "http://arxiv.org/abs/2108.12547",
          "publishedOn": "2023-09-30T00:41:30.106Z",
          "wordCount": null,
          "title": "Dynamic Selection in Algorithmic Decision-making. (arXiv:2108.12547v3 [econ.EM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kevin Han Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orbanz_P/0/1/0/all/0/1\">Peter Orbanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austern_M/0/1/0/all/0/1\">Morgane Austern</a>",
          "description": "We provide results that exactly quantify how data augmentation affects the\nvariance and limiting distribution of estimates, and analyze several specific\nmodels in detail. The results confirm some observations made in machine\nlearning practice, but also lead to unexpected findings: Data augmentation may\nincrease rather than decrease the uncertainty of estimates, such as the\nempirical prediction risk. It can act as a regularizer, but fails to do so in\ncertain high-dimensional problems, and it may shift the double-descent peak of\nan empirical risk. Overall, the analysis shows that several properties data\naugmentation has been attributed with are not either true or false, but rather\ndepend on a combination of factors -- notably the data distribution, the\nproperties of the estimator, and the interplay of sample size, number of\naugmentations, and dimension. Our main theoretical tool is a limit theorem for\nfunctions of randomly transformed, high-dimensional random vectors. The proof\ndraws on work in probability on noise stability of functions of many variables.",
          "link": "http://arxiv.org/abs/2202.09134",
          "publishedOn": "2023-09-30T00:41:30.104Z",
          "wordCount": null,
          "title": "Data Augmentation in the Underparameterized and Overparameterized Regimes. (arXiv:2202.09134v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaoqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yibo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxin Chen</a>",
          "description": "The increasing capabilities of large language models (LLMs) raise\nopportunities for artificial general intelligence but concurrently amplify\nsafety concerns, such as potential misuse of AI systems, necessitating\neffective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has\nemerged as a promising pathway towards AI alignment but brings forth challenges\ndue to its complexity and dependence on a separate reward model. Direct\nPreference Optimization (DPO) has been proposed as an alternative, and it\nremains equivalent to RLHF under the reverse KL regularization constraint. This\npaper presents $f$-DPO, a generalized approach to DPO by incorporating diverse\ndivergence constraints. We show that under certain $f$-divergences, including\nJensen-Shannon divergence, forward KL divergences and $\\alpha$-divergences, the\ncomplex relationship between the reward and optimal policy can also be\nsimplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the\nneed for estimating the normalizing constant in the Bradley-Terry model and\nenables a tractable mapping between the reward function and the optimal policy.\nOur approach optimizes LLMs to align with human preferences in a more efficient\nand supervised manner under a broad set of divergence constraints. Empirically,\nadopting these divergences ensures a balance between alignment performance and\ngeneration diversity. Importantly, $f$-DPO outperforms PPO-based methods in\ndivergence efficiency, and divergence constraints directly influence expected\ncalibration error (ECE).",
          "link": "http://arxiv.org/abs/2309.16240",
          "publishedOn": "2023-09-30T00:41:30.052Z",
          "wordCount": null,
          "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints. (arXiv:2309.16240v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16578",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1\">Siyuan Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_J/0/1/0/all/0/1\">Jiacheng You</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_S/0/1/0/all/0/1\">Shuxin Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_Z/0/1/0/all/0/1\">Ziheng Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_N/0/1/0/all/0/1\">Nanning Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shao_B/0/1/0/all/0/1\">Bin Shao</a>",
          "description": "Orbital-free density functional theory (OFDFT) is a quantum chemistry\nformulation that has a lower cost scaling than the prevailing Kohn-Sham DFT,\nwhich is increasingly desired for contemporary molecular research. However, its\naccuracy is limited by the kinetic energy density functional, which is\nnotoriously hard to approximate for non-periodic molecular systems. In this\nwork, we propose M-OFDFT, an OFDFT approach capable of solving molecular\nsystems using a deep-learning functional model. We build the essential\nnonlocality into the model, which is made affordable by the concise density\nrepresentation as expansion coefficients under an atomic basis. With techniques\nto address unconventional learning challenges therein, M-OFDFT achieves a\ncomparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched\nby OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much\nlarger than those in training, which unleashes the appealing scaling for\nstudying large molecules including proteins, representing an advancement of the\naccuracy-efficiency trade-off frontier in quantum chemistry.",
          "link": "http://arxiv.org/abs/2309.16578",
          "publishedOn": "2023-09-30T00:41:30.051Z",
          "wordCount": null,
          "title": "M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.02958",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_W/0/1/0/all/0/1\">Wenjia Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yanyuan Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaowei Zhang</a>",
          "description": "Nested simulation concerns estimating functionals of a conditional\nexpectation via simulation. In this paper, we propose a new method based on\nkernel ridge regression to exploit the smoothness of the conditional\nexpectation as a function of the multidimensional conditioning variable.\nAsymptotic analysis shows that the proposed method can effectively alleviate\nthe curse of dimensionality on the convergence rate as the simulation budget\nincreases, provided that the conditional expectation is sufficiently smooth.\nThe smoothness bridges the gap between the cubic root convergence rate (that\nis, the optimal rate for the standard nested simulation) and the square root\nconvergence rate (that is, the canonical rate for the standard Monte Carlo\nsimulation). We demonstrate the performance of the proposed method via\nnumerical examples from portfolio risk management and input uncertainty\nquantification.",
          "link": "http://arxiv.org/abs/2201.02958",
          "publishedOn": "2023-09-30T00:41:30.051Z",
          "wordCount": null,
          "title": "Smooth Nested Simulation: Bridging Cubic and Square Root Convergence Rates in High Dimensions. (arXiv:2201.02958v5 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">A. Feder Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choksi_M/0/1/0/all/0/1\">Madiha Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barocas_S/0/1/0/all/0/1\">Solon Barocas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimmelmann_J/0/1/0/all/0/1\">James Grimmelmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1\">Jon Kleinberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1\">Siddhartha Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Baobao Zhang</a>",
          "description": "Variance in predictions across different trained models is a significant,\nunder-explored source of error in fair classification. In practice, the\nvariance on some data examples is so large that decisions can be effectively\narbitrary. To investigate this problem, we take an experimental approach and\nmake four overarching contributions: We 1) Define a metric called\nself-consistency, derived from variance, which we use as a proxy for measuring\nand reducing arbitrariness; 2) Develop an ensembling algorithm that abstains\nfrom classification when a prediction would be arbitrary; 3) Conduct the\nlargest to-date empirical study of the role of variance (vis-a-vis\nself-consistency and arbitrariness) in fair classification; and, 4) Release a\ntoolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily\nusable for future research. Altogether, our experiments reveal shocking\ninsights about the reliability of conclusions on benchmark datasets. Most\nfairness classification benchmarks are close-to-fair when taking into account\nthe amount of arbitrariness present in predictions -- before we even try to\napply common fairness interventions. This finding calls into question the\npractical utility of common algorithmic fairness methods, and in turn suggests\nthat we should fundamentally reconsider how we choose to measure fairness in\nmachine learning.",
          "link": "http://arxiv.org/abs/2301.11562",
          "publishedOn": "2023-09-30T00:41:29.963Z",
          "wordCount": null,
          "title": "Is My Prediction Arbitrary? Confounding Effects of Variance in Fair Classification. (arXiv:2301.11562v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16412",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fishkov_A/0/1/0/all/0/1\">Alexander Fishkov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Prediction with the possibility of abstention (or selective prediction) is an\nimportant problem for error-critical machine learning applications. While\nwell-studied in the classification setup, selective approaches to regression\nare much less developed. In this work, we consider the nonparametric\nheteroskedastic regression problem and develop an abstention procedure via\ntesting the hypothesis on the value of the conditional variance at a given\npoint. Unlike existing methods, the proposed one allows to account not only for\nthe value of the variance itself but also for the uncertainty of the\ncorresponding variance predictor. We prove non-asymptotic bounds on the risk of\nthe resulting estimator and show the existence of several different convergence\nregimes. Theoretical analysis is illustrated with a series of experiments on\nsimulated and real-world data.",
          "link": "http://arxiv.org/abs/2309.16412",
          "publishedOn": "2023-09-30T00:41:29.928Z",
          "wordCount": null,
          "title": "Selective Nonparametric Regression via Testing. (arXiv:2309.16412v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16598",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zrnic_T/0/1/0/all/0/1\">Tijana Zrnic</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Candes_E/0/1/0/all/0/1\">Emmanuel J. Cand&#xe8;s</a>",
          "description": "While reliable data-driven decision-making hinges on high-quality labeled\ndata, the acquisition of quality labels often involves laborious human\nannotations or slow and expensive scientific measurements. Machine learning is\nbecoming an appealing alternative as sophisticated predictive techniques are\nbeing used to quickly and cheaply produce large amounts of predicted labels;\ne.g., predicted protein structures are used to supplement experimentally\nderived structures, predictions of socioeconomic indicators from satellite\nimagery are used to supplement accurate survey data, and so on. Since\npredictions are imperfect and potentially biased, this practice brings into\nquestion the validity of downstream inferences. We introduce cross-prediction:\na method for valid inference powered by machine learning. With a small labeled\ndataset and a large unlabeled dataset, cross-prediction imputes the missing\nlabels via machine learning and applies a form of debiasing to remedy the\nprediction inaccuracies. The resulting inferences achieve the desired error\nprobability and are more powerful than those that only leverage the labeled\ndata. Closely related is the recent proposal of prediction-powered inference,\nwhich assumes that a good pre-trained model is already available. We show that\ncross-prediction is consistently more powerful than an adaptation of\nprediction-powered inference in which a fraction of the labeled data is split\noff and used to train the model. Finally, we observe that cross-prediction\ngives more stable conclusions than its competitors; its confidence intervals\ntypically have significantly lower variability.",
          "link": "http://arxiv.org/abs/2309.16598",
          "publishedOn": "2023-09-30T00:41:29.922Z",
          "wordCount": null,
          "title": "Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1\">Andrew Lowy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1\">Meisam Razaviyayn</a>",
          "description": "We study differentially private (DP) stochastic optimization (SO) with loss\nfunctions whose worst-case Lipschitz parameter over all data points may be\nextremely large. To date, the vast majority of work on DP SO assumes that the\nloss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are\nuniformly bounded over all data points). While this assumption is convenient,\nit often leads to pessimistic excess risk bounds. In many practical problems,\nthe worst-case (uniform) Lipschitz parameter of the loss over all data points\nmay be extremely large due to outliers. In such cases, the error bounds for DP\nSO, which scale with the worst-case Lipschitz parameter of the loss, are\nvacuous. To address these limitations, this work provides near-optimal excess\nrisk bounds that do not depend on the uniform Lipschitz parameter of the loss.\nBuilding on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we\nassume that stochastic gradients have bounded $k$-th order moments for some $k\n\\geq 2$. Compared with works on uniformly Lipschitz DP SO, our excess risk\nscales with the $k$-th moment bound instead of the uniform Lipschitz parameter\nof the loss, allowing for significantly faster rates in the presence of\noutliers and/or heavy-tailed data. For convex and strongly convex loss\nfunctions, we provide the first asymptotically optimal excess risk bounds (up\nto a logarithmic factor). In contrast to (Wang et al., 2020; Kamath et al.,\n2022), our bounds do not require the loss function to be differentiable/smooth.\nWe also devise a linear-time algorithm for smooth losses that has excess risk\nthat is tight in certain practical parameter regimes. Additionally, our work is\nthe first to address non-convex non-uniformly Lipschitz loss functions\nsatisfying the Proximal-PL inequality; this covers some practical machine\nlearning models. Our Proximal-PL algorithm has near-optimal excess risk.",
          "link": "http://arxiv.org/abs/2209.07403",
          "publishedOn": "2023-09-30T00:41:29.711Z",
          "wordCount": null,
          "title": "Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Agrawal_S/0/1/0/all/0/1\">Shubhada Agrawal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mathieu_T/0/1/0/all/0/1\">Timoth&#xe9;e Mathieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maillard_O/0/1/0/all/0/1\">Odalric-Ambrym Maillard</a>",
          "description": "We investigate the regret-minimisation problem in a multi-armed bandit\nsetting with arbitrary corruptions. Similar to the classical setup, the agent\nreceives rewards generated independently from the distribution of the arm\nchosen at each time. However, these rewards are not directly observed. Instead,\nwith a fixed $\\varepsilon\\in (0,\\frac{1}{2})$, the agent observes a sample from\nthe chosen arm's distribution with probability $1-\\varepsilon$, or from an\narbitrary corruption distribution with probability $\\varepsilon$. Importantly,\nwe impose no assumptions on these corruption distributions, which can be\nunbounded. In this setting, accommodating potentially unbounded corruptions, we\nestablish a problem-dependent lower bound on regret for a given family of arm\ndistributions. We introduce CRIMED, an asymptotically-optimal algorithm that\nachieves the exact lower bound on regret for bandits with Gaussian\ndistributions with known variance. Additionally, we provide a finite-sample\nanalysis of CRIMED's regret performance. Notably, CRIMED can effectively handle\ncorruptions with $\\varepsilon$ values as high as $\\frac{1}{2}$. Furthermore, we\ndevelop a tight concentration result for medians in the presence of arbitrary\ncorruptions, even with $\\varepsilon$ values up to $\\frac{1}{2}$, which may be\nof independent interest. We also discuss an extension of the algorithm for\nhandling misspecification in Gaussian model.",
          "link": "http://arxiv.org/abs/2309.16563",
          "publishedOn": "2023-09-30T00:41:29.710Z",
          "wordCount": null,
          "title": "CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.16409",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhang Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihua Zhang</a>",
          "description": "The purpose of this work is to transport the information from multiple\nrandomized controlled trials to the target population where we only have the\ncontrol group data. Previous works rely critically on the mean exchangeability\nassumption. However, as pointed out by many current studies, the mean\nexchangeability assumption might be violated. Motivated by the synthetic\ncontrol method, we construct a synthetic treatment group for the target\npopulation by a weighted mixture of treatment groups of source populations. We\nestimate the weights by minimizing the conditional maximum mean discrepancy\nbetween the weighted control groups of source populations and the target\npopulation. We establish the asymptotic normality of the synthetic treatment\ngroup estimator based on the sieve semiparametric theory. Our method can serve\nas a novel complementary approach when the mean exchangeability assumption is\nviolated. Experiments are conducted on synthetic and real-world datasets to\ndemonstrate the effectiveness of our methods.",
          "link": "http://arxiv.org/abs/2309.16409",
          "publishedOn": "2023-09-30T00:41:29.376Z",
          "wordCount": 648,
          "title": "Constructing Synthetic Treatment Groups without the Mean Exchangeability Assumption. (arXiv:2309.16409v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.10538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO), while proved highly effective for many black-box\nfunction optimization tasks, requires practitioners to carefully select priors\nthat well model their functions of interest. Rather than specifying by hand,\nresearchers have investigated transfer learning based methods to automatically\nlearn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO\n(Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those\nprior learning methods typically assume that the input domains are the same for\nall tasks, weakening their ability to use observations on functions with\ndifferent domains or generalize the learned priors to BO on different search\nspaces. In this work, we present HyperBO+: a pre-training approach for\nhierarchical Gaussian processes that enables the same prior to work universally\nfor Bayesian optimization on functions with different domains. We propose a\ntwo-step pre-training method and analyze its appealing asymptotic properties\nand benefits to BO both theoretically and empirically. On real-world\nhyperparameter tuning tasks that involve multiple search spaces, we demonstrate\nthat HyperBO+ is able to generalize to unseen search spaces and achieves lower\nregrets than competitive baselines.",
          "link": "http://arxiv.org/abs/2212.10538",
          "publishedOn": "2023-09-30T00:41:29.371Z",
          "wordCount": 735,
          "title": "HyperBO+: Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian processes. (arXiv:2212.10538v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xinran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zi Wang</a>",
          "description": "Bayesian optimization (BO) is a popular black-box function optimization\nmethod, which makes sequential decisions based on a Bayesian model, typically a\nGaussian process (GP), of the function. To ensure the quality of the model,\ntransfer learning approaches have been developed to automatically design GP\npriors by learning from observations on \"training\" functions. These training\nfunctions are typically required to have the same domain as the \"test\" function\n(black-box function to be optimized). In this paper, we introduce MPHD, a model\npre-training method on heterogeneous domains, which uses a neural net mapping\nfrom domain-specific contexts to specifications of hierarchical GPs. MPHD can\nbe seamlessly integrated with BO to transfer knowledge across heterogeneous\nsearch spaces. Our theoretical and empirical results demonstrate the validity\nof MPHD and its superior performance on challenging black-box function\noptimization tasks.",
          "link": "http://arxiv.org/abs/2309.16597",
          "publishedOn": "2023-09-30T00:41:29.364Z",
          "wordCount": 644,
          "title": "Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16099",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ertefaie_A/0/1/0/all/0/1\">Ashkan Ertefaie</a>, <a href=\"http://arxiv.org/find/math/1/au:+Duttweiler_L/0/1/0/all/0/1\">Luke Duttweiler</a>, <a href=\"http://arxiv.org/find/math/1/au:+Johnson_B/0/1/0/all/0/1\">Brent A. Johnson</a>, <a href=\"http://arxiv.org/find/math/1/au:+Laan_M/0/1/0/all/0/1\">Mark J. van der Laan</a>",
          "description": "Flexible estimation of the mean outcome under a treatment regimen (i.e.,\nvalue function) is the key step toward personalized medicine. We define our\ntarget parameter as a conditional value function given a set of baseline\ncovariates which we refer to as a stratum based value function. We focus on\nsemiparametric class of decision rules and propose a sieve based nonparametric\ncovariate adjusted regimen-response curve estimator within that class. Our work\ncontributes in several ways. First, we propose an inverse probability weighted\nnonparametrically efficient estimator of the smoothed regimen-response curve\nfunction. We show that asymptotic linearity is achieved when the nuisance\nfunctions are undersmoothed sufficiently. Asymptotic and finite sample criteria\nfor undersmoothing are proposed. Second, using Gaussian process theory, we\npropose simultaneous confidence intervals for the smoothed regimen-response\ncurve function. Third, we provide consistency and convergence rate for the\noptimizer of the regimen-response curve estimator; this enables us to estimate\nan optimal semiparametric rule. The latter is important as the optimizer\ncorresponds with the optimal dynamic treatment regimen. Some finite-sample\nproperties are explored with simulations.",
          "link": "http://arxiv.org/abs/2309.16099",
          "publishedOn": "2023-09-30T00:41:26.276Z",
          "wordCount": 686,
          "title": "Nonparametric estimation of a covariate-adjusted counterfactual treatment regimen response curve. (arXiv:2309.16099v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.16044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We study unconstrained Online Linear Optimization with Lipschitz losses. The\ngoal is to simultaneously achieve ($i$) second order gradient adaptivity; and\n($ii$) comparator norm adaptivity also known as \"parameter freeness\" in the\nliterature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and\nKoolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\\sqrt{V_T\\log\nV_T})$ dependence on the gradient variance $V_T$, while the present work\nimproves it to the optimal rate $O(\\sqrt{V_T})$ using a novel\ncontinuous-time-inspired algorithm, without any impractical doubling trick.\nThis result can be extended to the setting with unknown Lipschitz constant,\neliminating the range ratio problem from prior works (Mhammedi and Koolen,\n2020).\n\nConcretely, we first show that the aimed simultaneous adaptivity can be\nachieved fairly easily in a continuous time analogue of the problem, where the\nenvironment is modeled by an arbitrary continuous semimartingale. Then, our key\ninnovation is a new discretization argument that preserves such adaptivity in\nthe discrete time adversarial setting. This refines a non-gradient-adaptive\ndiscretization argument from (Harvey et al., 2023), both algorithmically and\nanalytically, which could be of independent interest.",
          "link": "http://arxiv.org/abs/2309.16044",
          "publishedOn": "2023-09-30T00:41:26.255Z",
          "wordCount": 680,
          "title": "Improving Adaptive Online Learning Using Refined Discretization. (arXiv:2309.16044v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11856",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Eliassen_S/0/1/0/all/0/1\">Sebastian Eliassen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Selvan_R/0/1/0/all/0/1\">Raghavendra Selvan</a>",
          "description": "Efficient training of large-scale graph neural networks (GNNs) has been\nstudied with a specific focus on reducing their memory consumption. Work by Liu\net al. (2022) proposed extreme activation compression (EXACT) which\ndemonstrated drastic reduction in memory consumption by performing quantization\nof the intermediate activation maps down to using INT2 precision. They showed\nlittle to no reduction in performance while achieving large reductions in GPU\nmemory consumption. In this work, we present an improvement to the EXACT\nstrategy by using block-wise quantization of the intermediate activation maps.\nWe experimentally analyze different block sizes and show further reduction in\nmemory consumption (>15%), and runtime speedup per epoch (about 5%) even when\nperforming extreme extents of quantization with similar performance trade-offs\nas with the original EXACT. Further, we present a correction to the assumptions\non the distribution of intermediate activation maps in EXACT (assumed to be\nuniform) and show improved variance estimations of the quantization and\ndequantization steps.",
          "link": "http://arxiv.org/abs/2309.11856",
          "publishedOn": "2023-09-23T00:40:39.641Z",
          "wordCount": 675,
          "title": "Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization. (arXiv:2309.11856v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11942",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1\">Jose M. Pe&#xf1;a</a>",
          "description": "This work is devoted to the study of the probability of immunity, i.e. the\neffect occurs whether exposed or not. We derive necessary and sufficient\nconditions for non-immunity and $\\epsilon$-bounded immunity, i.e. the\nprobability of immunity is zero and $\\epsilon$-bounded, respectively. The\nformer allows us to estimate the probability of benefit (i.e., the effect\noccurs if and only if exposed) from a randomized controlled trial, and the\nlatter allows us to produce bounds of the probability of benefit that are\ntighter than the existing ones. We also introduce the concept of indirect\nimmunity (i.e., through a mediator) and repeat our previous analysis for it.\nFinally, we propose a method for sensitivity analysis of the probability of\nimmunity under unmeasured confounding.",
          "link": "http://arxiv.org/abs/2309.11942",
          "publishedOn": "2023-09-23T00:40:39.609Z",
          "wordCount": null,
          "title": "On the Probability of Immunity. (arXiv:2309.11942v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.02900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yataka_R/0/1/0/all/0/1\">Ryoma Yataka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiraishi_M/0/1/0/all/0/1\">Masashi Shiraishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirashima_K/0/1/0/all/0/1\">Kazuki Hirashima</a>",
          "description": "Recently, studies on machine learning have focused on methods that use\nsymmetry implicit in a specific manifold as an inductive bias. Grassmann\nmanifolds provide the ability to handle fundamental shapes represented as shape\nspaces, enabling stable shape analysis. In this paper, we present a novel\napproach in which we establish the theoretical foundations for learning\ndistributions on the Grassmann manifold via continuous normalization flows,\nwith the explicit goal of generating stable shapes. Our approach facilitates\nmore robust generation by effectively eliminating the influence of extraneous\ntransformations, such as rotations and inversions, through learning and\ngenerating within a Grassmann manifolds designed to accommodate the essential\nshape information of the object. The experimental results indicated that the\nproposed method can generate high-quality samples by capturing the data\nstructure. Furthermore, the proposed method significantly outperformed\nstate-of-the-art methods in terms of the log-likelihood or evidence lower\nbound. The results obtained are expected to stimulate further research in this\nfield, leading to advances for stable shape generation and analysis.",
          "link": "http://arxiv.org/abs/2211.02900",
          "publishedOn": "2023-09-23T00:40:39.554Z",
          "wordCount": null,
          "title": "Grassmann Manifold Flows for Stable Shape Generation. (arXiv:2211.02900v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.03532",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shin_J/0/1/0/all/0/1\">Jaehyeok Shin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rinaldo_A/0/1/0/all/0/1\">Alessandro Rinaldo</a>",
          "description": "Sequential change detection is a classical problem with a variety of\napplications. However, the majority of prior work has been parametric, for\nexample, focusing on exponential families. We develop a fundamentally new and\ngeneral framework for sequential change detection when the pre- and post-change\ndistributions are nonparametrically specified (and thus composite). Our\nprocedures come with clean, nonasymptotic bounds on the average run length\n(frequency of false alarms). In certain nonparametric cases (like sub-Gaussian\nor sub-exponential), we also provide near-optimal bounds on the detection delay\nfollowing a changepoint. The primary technical tool that we introduce is called\nan \\emph{e-detector}, which is composed of sums of e-processes -- a fundamental\ngeneralization of nonnegative supermartingales -- that are started at\nconsecutive times. We first introduce simple Shiryaev-Roberts and CUSUM-style\ne-detectors, and then show how to design their mixtures in order to achieve\nboth statistical and computational efficiency. Our e-detector framework can be\ninstantiated to recover classical likelihood-based procedures for parametric\nproblems, as well as yielding the first change detection method for many\nnonparametric problems. As a running example, we tackle the problem of\ndetecting changes in the mean of a bounded random variable without i.i.d.\nassumptions, with an application to tracking the performance of a basketball\nteam over multiple seasons.",
          "link": "http://arxiv.org/abs/2203.03532",
          "publishedOn": "2023-09-23T00:40:39.530Z",
          "wordCount": null,
          "title": "E-detectors: a nonparametric framework for sequential change detection. (arXiv:2203.03532v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12238",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gassiat_E/0/1/0/all/0/1\">Elisabeth Gassiat</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kaddouri_I/0/1/0/all/0/1\">Ibrahim Kaddouri</a>, <a href=\"http://arxiv.org/find/math/1/au:+Naulet_Z/0/1/0/all/0/1\">Zacharie Naulet</a>",
          "description": "Thanks to their dependency structure, non-parametric Hidden Markov Models\n(HMMs) are able to handle model-based clustering without specifying group\ndistributions. The aim of this work is to study the Bayes risk of clustering\nwhen using HMMs and to propose associated clustering procedures. We first give\na result linking the Bayes risk of classification and the Bayes risk of\nclustering, which we use to identify the key quantity determining the\ndifficulty of the clustering task. We also give a proof of this result in the\ni.i.d. framework, which might be of independent interest. Then we study the\nexcess risk of the plugin classifier. All these results are shown to remain\nvalid in the online setting where observations are clustered sequentially.\nSimulations illustrate our findings.",
          "link": "http://arxiv.org/abs/2309.12238",
          "publishedOn": "2023-09-23T00:40:39.316Z",
          "wordCount": null,
          "title": "Model-based Clustering using Non-parametric Hidden Markov Models. (arXiv:2309.12238v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.06424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pabbaraju_C/0/1/0/all/0/1\">Chirag Pabbaraju</a>",
          "description": "A hypothesis class admits a sample compression scheme, if for every sample\nlabeled by a hypothesis from the class, it is possible to retain only a small\nsubsample, using which the labels on the entire sample can be inferred. The\nsize of the compression scheme is an upper bound on the size of the subsample\nproduced. Every learnable binary hypothesis class (which must necessarily have\nfinite VC dimension) admits a sample compression scheme of size only a finite\nfunction of its VC dimension, independent of the sample size. For multiclass\nhypothesis classes, the analog of VC dimension is the DS dimension. We show\nthat the analogous statement pertaining to sample compression is not true for\nmulticlass hypothesis classes: every learnable multiclass hypothesis class,\nwhich must necessarily have finite DS dimension, does not admit a sample\ncompression scheme of size only a finite function of its DS dimension.",
          "link": "http://arxiv.org/abs/2308.06424",
          "publishedOn": "2023-09-23T00:40:39.024Z",
          "wordCount": 652,
          "title": "Multiclass Learnability Does Not Imply Sample Compression. (arXiv:2308.06424v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11617",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Banchi_L/0/1/0/all/0/1\">Leonardo Banchi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pereira_J/0/1/0/all/0/1\">Jason Luke Pereira</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jose_S/0/1/0/all/0/1\">Sharu Theresa Jose</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Simeone_O/0/1/0/all/0/1\">Osvaldo Simeone</a>",
          "description": "Recent years have seen significant activity on the problem of using data for\nthe purpose of learning properties of quantum systems or of processing\nclassical or quantum data via quantum computing. As in classical learning,\nquantum learning problems involve settings in which the mechanism generating\nthe data is unknown, and the main goal of a learning algorithm is to ensure\nsatisfactory accuracy levels when only given access to data and, possibly, side\ninformation such as expert knowledge. This article reviews the complexity of\nquantum learning using information-theoretic techniques by focusing on data\ncomplexity, copy complexity, and model complexity. Copy complexity arises from\nthe destructive nature of quantum measurements, which irreversibly alter the\nstate to be processed, limiting the information that can be extracted about\nquantum data. For example, in a quantum system, unlike in classical machine\nlearning, it is generally not possible to evaluate the training loss\nsimultaneously on multiple hypotheses using the same quantum data. To make the\npaper self-contained and approachable by different research communities, we\nprovide extensive background material on classical results from statistical\nlearning theory, as well as on the distinguishability of quantum states.\nThroughout, we highlight the differences between quantum and classical learning\nby addressing both supervised and unsupervised learning, and we provide\nextensive pointers to the literature.",
          "link": "http://arxiv.org/abs/2309.11617",
          "publishedOn": "2023-09-23T00:40:38.978Z",
          "wordCount": null,
          "title": "Statistical Complexity of Quantum Learning. (arXiv:2309.11617v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.00997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tsai_C/0/1/0/all/0/1\">Chung-En Tsai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_H/0/1/0/all/0/1\">Hao-Chung Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yen-Huan Li</a>",
          "description": "Consider an online convex optimization problem where the loss functions are\nself-concordant barriers, smooth relative to a convex function $h$, and\npossibly non-Lipschitz. We analyze the regret of online mirror descent with\n$h$. Then, based on the result, we prove the following in a unified manner.\nDenote by $T$ the time horizon and $d$ the parameter dimension. 1. For online\nportfolio selection, the regret of $\\widetilde{\\text{EG}}$, a variant of\nexponentiated gradient due to Helmbold et al., is $\\tilde{O} ( T^{2/3} d^{1/3}\n)$ when $T > 4 d / \\log d$. This improves on the original $\\tilde{O} ( T^{3/4}\nd^{1/2} )$ regret bound for $\\widetilde{\\text{EG}}$. 2. For online portfolio\nselection, the regret of online mirror descent with the logarithmic barrier is\n$\\tilde{O}(\\sqrt{T d})$. The regret bound is the same as that of Soft-Bayes due\nto Orseau et al. up to logarithmic terms. 3. For online learning quantum states\nwith the logarithmic loss, the regret of online mirror descent with the\nlog-determinant function is also $\\tilde{O} ( \\sqrt{T d} )$. Its per-iteration\ntime is shorter than all existing algorithms we know.",
          "link": "http://arxiv.org/abs/2210.00997",
          "publishedOn": "2023-09-23T00:40:38.951Z",
          "wordCount": null,
          "title": "Online Self-Concordant and Relatively Smooth Minimization, With Applications to Online Portfolio Selection and Learning Quantum States. (arXiv:2210.00997v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1\">Ruohan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1\">Emma Brunskill</a>",
          "description": "Simple regret minimization is a critical problem in learning optimal\ntreatment assignment policies across various domains, including healthcare and\ne-commerce. However, it remains understudied in the contextual bandit setting.\nWe propose a new family of computationally efficient bandit algorithms for the\nstochastic contextual bandit settings, with the flexibility to be adapted for\ncumulative regret minimization (with near-optimal minimax guarantees) and\nsimple regret minimization (with SOTA guarantees). Furthermore, our algorithms\nadapt to model misspecification and extend to the continuous arm settings.\nThese advantages come from constructing and relying on \"conformal arm sets\"\n(CASs), which provide a set of arms at every context that encompass the\ncontext-specific optimal arm with some probability across the context\ndistribution. Our positive results on simple and cumulative regret guarantees\nare contrasted by a negative result, which shows that an algorithm can't\nachieve instance-dependent simple regret guarantees while simultaneously\nachieving minimax optimal cumulative regret guarantees.",
          "link": "http://arxiv.org/abs/2307.02108",
          "publishedOn": "2023-09-23T00:40:38.936Z",
          "wordCount": 685,
          "title": "Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giordani_L/0/1/0/all/0/1\">Luiz Giordani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daru_G/0/1/0/all/0/1\">Gilsiley Dar&#xfa;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Queiroz_R/0/1/0/all/0/1\">Rhenan Queiroz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buzinaro_V/0/1/0/all/0/1\">Vitor Buzinaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neiva_D/0/1/0/all/0/1\">Davi Keglevich Neiva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzman_D/0/1/0/all/0/1\">Daniel Camilo Fuentes Guzm&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_M/0/1/0/all/0/1\">Marcos Jardel Henriques</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junior_O/0/1/0/all/0/1\">Oilson Alberto Gonzatto Junior</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louzada_F/0/1/0/all/0/1\">Francisco Louzada</a>",
          "description": "The proliferation of fake news has become a significant concern in recent\ntimes due to its potential to spread misinformation and manipulate public\nopinion. This paper presents a comprehensive study on detecting fake news in\nBrazilian Portuguese, focusing on journalistic-type news. We propose a machine\nlearning-based approach that leverages natural language processing techniques,\nincluding TF-IDF and Word2Vec, to extract features from textual data. We\nevaluate the performance of various classification algorithms, such as logistic\nregression, support vector machine, random forest, AdaBoost, and LightGBM, on a\ndataset containing both true and fake news articles. The proposed approach\nachieves high accuracy and F1-Score, demonstrating its effectiveness in\nidentifying fake news. Additionally, we developed a user-friendly web platform,\nfakenewsbr.com, to facilitate the verification of news articles' veracity. Our\nplatform provides real-time analysis, allowing users to assess the likelihood\nof fake news articles. Through empirical analysis and comparative studies, we\ndemonstrate the potential of our approach to contribute to the fight against\nthe spread of fake news and promote more informed media consumption.",
          "link": "http://arxiv.org/abs/2309.11052",
          "publishedOn": "2023-09-23T00:40:38.838Z",
          "wordCount": null,
          "title": "fakenewsbr: A Fake News Detection Platform for Brazilian Portuguese. (arXiv:2309.11052v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_T/0/1/0/all/0/1\">Tiago da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_E/0/1/0/all/0/1\">Eliezer Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Ad&#xe8;le Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gois_A/0/1/0/all/0/1\">Ant&#xf3;nio G&#xf3;is</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heider_D/0/1/0/all/0/1\">Dominik Heider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mesquita_D/0/1/0/all/0/1\">Diego Mesquita</a>",
          "description": "Structure learning is the crux of causal inference. Notably, causal discovery\n(CD) algorithms are brittle when data is scarce, possibly inferring imprecise\ncausal relations that contradict expert knowledge -- especially when\nconsidering latent confounders. To aggravate the issue, most CD methods do not\nprovide uncertainty estimates, making it hard for users to interpret results\nand improve the inference process. Surprisingly, while CD is a human-centered\naffair, no works have focused on building methods that both 1) output\nuncertainty estimates that can be verified by experts and 2) interact with\nthose experts to iteratively refine CD. To solve these issues, we start by\nproposing to sample (causal) ancestral graphs proportionally to a belief\ndistribution based on a score function, such as the Bayesian information\ncriterion (BIC), using generative flow networks. Then, we leverage the\ndiversity in candidate graphs and introduce an optimal experimental design to\niteratively probe the expert about the relations among variables, effectively\nreducing the uncertainty of our belief over ancestral graphs. Finally, we\nupdate our samples to incorporate human feedback via importance sampling.\nImportantly, our method does not require causal sufficiency (i.e., unobserved\nconfounders may exist). Experiments with synthetic observational data show that\nour method can accurately sample from distributions over ancestral graphs and\nthat we can greatly improve inference quality with human aid.",
          "link": "http://arxiv.org/abs/2309.12032",
          "publishedOn": "2023-09-23T00:40:38.837Z",
          "wordCount": 734,
          "title": "Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets. (arXiv:2309.12032v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yuxiang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djemili_K/0/1/0/all/0/1\">Karim Djemili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elezi_D/0/1/0/all/0/1\">Denis Elezi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalman_A/0/1/0/all/0/1\">Aaneel Shalman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Ortiz_M/0/1/0/all/0/1\">Mar&#xed;a P&#xe9;rez-Ortiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulathwela_S/0/1/0/all/0/1\">Sahan Bulathwela</a>",
          "description": "This work describes the TrueLearn Python library, which contains a family of\nonline learning Bayesian models for building educational (or more generally,\ninformational) recommendation systems. This family of models was designed\nfollowing the \"open learner\" concept, using humanly-intuitive user\nrepresentations. For the sake of interpretability and putting the user in\ncontrol, the TrueLearn library also contains different representations to help\nend-users visualise the learner models, which may in the future facilitate user\ninteraction with their own models. Together with the library, we include a\npreviously publicly released implicit feedback educational dataset with\nevaluation metrics to measure the performance of the models. The extensive\ndocumentation and coding examples make the library highly accessible to both\nmachine learning developers and educational data mining and learning analytic\npractitioners. The library and the support documentation with examples are\navailable at https://truelearn.readthedocs.io/en/latest.",
          "link": "http://arxiv.org/abs/2309.11527",
          "publishedOn": "2023-09-23T00:40:38.813Z",
          "wordCount": null,
          "title": "TrueLearn: A Python Library for Personalised Informational Recommendations with (Implicit) Feedback. (arXiv:2309.11527v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.12095",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Markovic_D/0/1/0/all/0/1\">Dimitrije Markovi&#x107;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Friston_K/0/1/0/all/0/1\">Karl J. Friston</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kiebel_S/0/1/0/all/0/1\">Stefan J. Kiebel</a>",
          "description": "Deep learning's immense capabilities are often constrained by the complexity\nof its models, leading to an increasing demand for effective sparsification\ntechniques. Bayesian sparsification for deep learning emerges as a crucial\napproach, facilitating the design of models that are both computationally\nefficient and competitive in terms of performance across various deep learning\napplications. The state-of-the-art -- in Bayesian sparsification of deep neural\nnetworks -- combines structural shrinkage priors on model weights with an\napproximate inference scheme based on black-box stochastic variational\ninference. However, model inversion of the full generative model is\nexceptionally computationally demanding, especially when compared to standard\ndeep learning of point estimates. In this context, we advocate for the use of\nBayesian model reduction (BMR) as a more efficient alternative for pruning of\nmodel weights. As a generalization of the Savage-Dickey ratio, BMR allows a\npost-hoc elimination of redundant model weights based on the posterior\nestimates under a straightforward (non-hierarchical) generative model. Our\ncomparative study highlights the computational efficiency and the pruning rate\nof the BMR method relative to the established stochastic variational inference\n(SVI) scheme, when applied to the full hierarchical generative model. We\nillustrate the potential of BMR to prune model parameters across various deep\nlearning architectures, from classical networks like LeNet to modern frameworks\nsuch as Vision Transformers and MLP-Mixers.",
          "link": "http://arxiv.org/abs/2309.12095",
          "publishedOn": "2023-09-23T00:40:38.598Z",
          "wordCount": null,
          "title": "Bayesian sparsification for deep neural networks with Bayesian model reduction. (arXiv:2309.12095v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.11682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baharlouei_S/0/1/0/all/0/1\">Sina Baharlouei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1\">Meisam Razaviyayn</a>",
          "description": "While training fair machine learning models has been studied extensively in\nrecent years, most developed methods rely on the assumption that the training\nand test data have similar distributions. In the presence of distribution\nshifts, fair models may behave unfairly on test data. There have been some\ndevelopments for fair learning robust to distribution shifts to address this\nshortcoming. However, most proposed solutions are based on the assumption of\nhaving access to the causal graph describing the interaction of different\nfeatures. Moreover, existing algorithms require full access to data and cannot\nbe used when small batches are used (stochastic/batch implementation). This\npaper proposes the first stochastic distributionally robust fairness framework\nwith convergence guarantees that do not require knowledge of the causal graph.\nMore specifically, we formulate the fair inference in the presence of the\ndistribution shift as a distributionally robust optimization problem under\n$L_p$ norm uncertainty sets with respect to the Exponential Renyi Mutual\nInformation (ERMI) as the measure of fairness violation. We then discuss how\nthe proposed method can be implemented in a stochastic fashion. We have\nevaluated the presented framework's performance and efficiency through\nextensive experiments on real datasets consisting of distribution shifts.",
          "link": "http://arxiv.org/abs/2309.11682",
          "publishedOn": "2023-09-23T00:40:38.597Z",
          "wordCount": null,
          "title": "Dr. FERMI: A Stochastic Distributionally Robust Fair Empirical Risk Minimization Framework. (arXiv:2309.11682v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishchenko_K/0/1/0/all/0/1\">Konstantin Mishchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Defazio_A/0/1/0/all/0/1\">Aaron Defazio</a>",
          "description": "We consider the problem of estimating the learning rate in adaptive methods,\nsuch as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to\nprovably estimate the distance to the solution $D$, which is needed to set the\nlearning rate optimally. Our techniques are modifications of the D-Adaptation\nmethod for learning-rate-free learning. Our methods improve upon the\nconvergence rate of D-Adaptation by a factor of $O(\\sqrt{\\log(D/d_0)})$, where\n$d_0$ is the initial estimate of $D$. We test our methods on 12 common\nlogistic-regression benchmark datasets, VGG11 and ResNet-50 training on\nCIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on\nCriteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT\ntransformer training on BookWiki. Our experimental results show that our\napproaches consistently outperform D-Adaptation and reach test accuracy values\nclose to that of hand-tuned Adam.",
          "link": "http://arxiv.org/abs/2306.06101",
          "publishedOn": "2023-09-23T00:40:38.531Z",
          "wordCount": 663,
          "title": "Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11713",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1\">Khai Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bariletto_N/0/1/0/all/0/1\">Nicola Bariletto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>",
          "description": "Monte Carlo (MC) approximation has been used as the standard computation\napproach for the Sliced Wasserstein (SW) distance, which has an intractable\nexpectation in its analytical form. However, the MC method is not optimal in\nterms of minimizing the absolute approximation error. To provide a better class\nof empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that\nrely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of\nQMC for SW, we focus on the 3D setting, specifically computing the SW between\nprobability measures in three dimensions. In greater detail, we empirically\nverify various ways of constructing QMC points sets on the 3D unit-hypersphere,\nincluding Gaussian-based mapping, equal area mapping, generalized spiral\npoints, and optimizing discrepancy energies. Furthermore, to obtain an unbiased\nestimation for stochastic optimization, we extend QSW into Randomized\nQuasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed\nlow-discrepancy sequences. For theoretical properties, we prove the asymptotic\nconvergence of QSW and the unbiasedness of RQSW. Finally, we conduct\nexperiments on various 3D tasks, such as point-cloud comparison, point-cloud\ninterpolation, image style transfer, and training deep point-cloud\nautoencoders, to demonstrate the favorable performance of the proposed QSW and\nRQSW variants.",
          "link": "http://arxiv.org/abs/2309.11713",
          "publishedOn": "2023-09-23T00:40:38.009Z",
          "wordCount": 693,
          "title": "Quasi-Monte Carlo for 3D Sliced Wasserstein. (arXiv:2309.11713v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.11657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1\">Ilias Diakonikolas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1\">Sushrut Karmalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jongho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1\">Christos Tzamos</a>",
          "description": "We demonstrate the first algorithms for the problem of regression for\ngeneralized linear models (GLMs) in the presence of additive oblivious noise.\nWe assume we have sample access to examples $(x, y)$ where $y$ is a noisy\nmeasurement of $g(w^* \\cdot x)$. In particular, \\new{the noisy labels are of\nthe form} $y = g(w^* \\cdot x) + \\xi + \\epsilon$, where $\\xi$ is the oblivious\nnoise drawn independently of $x$ \\new{and satisfies} $\\Pr[\\xi = 0] \\geq o(1)$,\nand $\\epsilon \\sim \\mathcal N(0, \\sigma^2)$. Our goal is to accurately recover\na \\new{parameter vector $w$ such that the} function $g(w \\cdot x)$ \\new{has}\narbitrarily small error when compared to the true values $g(w^* \\cdot x)$,\nrather than the noisy measurements $y$.\n\nWe present an algorithm that tackles \\new{this} problem in its most general\ndistribution-independent setting, where the solution may not \\new{even} be\nidentifiable. \\new{Our} algorithm returns \\new{an accurate estimate of} the\nsolution if it is identifiable, and otherwise returns a small list of\ncandidates, one of which is close to the true solution. Furthermore, we\n\\new{provide} a necessary and sufficient condition for identifiability, which\nholds in broad settings. \\new{Specifically,} the problem is identifiable when\nthe quantile at which $\\xi + \\epsilon = 0$ is known, or when the family of\nhypotheses does not contain candidates that are nearly equal to a translated\n$g(w^* \\cdot x) + A$ for some real number $A$, while also having large error\nwhen compared to $g(w^* \\cdot x)$.\n\nThis is the first \\new{algorithmic} result for GLM regression \\new{with\noblivious noise} which can handle more than half the samples being arbitrarily\ncorrupted. Prior work focused largely on the setting of linear regression, and\ngave algorithms under restrictive assumptions.",
          "link": "http://arxiv.org/abs/2309.11657",
          "publishedOn": "2023-09-23T00:40:37.913Z",
          "wordCount": 784,
          "title": "GLM Regression with Oblivious Corruptions. (arXiv:2309.11657v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.10688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sclocchi_A/0/1/0/all/0/1\">Antonio Sclocchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Modern deep networks are trained with stochastic gradient descent (SGD) whose\nkey parameters are the number of data considered at each step or batch size\n$B$, and the step size or learning rate $\\eta$. For small $B$ and large $\\eta$,\nSGD corresponds to a stochastic evolution of the parameters, whose noise\namplitude is governed by the `temperature' $T\\equiv \\eta/B$. Yet this\ndescription is observed to break down for sufficiently large batches $B\\geq\nB^*$, or simplifies to gradient descent (GD) when the temperature is\nsufficiently small. Understanding where these cross-overs take place remains a\ncentral challenge. Here we resolve these questions for a teacher-student\nperceptron classification model, and show empirically that our key predictions\nstill apply to deep networks. Specifically, we obtain a phase diagram in the\n$B$-$\\eta$ plane that separates three dynamical phases: $\\textit{(i)}$ a\nnoise-dominated SGD governed by temperature, $\\textit{(ii)}$ a\nlarge-first-step-dominated SGD and $\\textit{(iii)}$ GD. These different phases\nalso corresponds to different regimes of generalization error. Remarkably, our\nanalysis reveals that the batch size $B^*$ separating regimes $\\textit{(i)}$\nand $\\textit{(ii)}$ scale with the size $P$ of the training set, with an\nexponent that characterizes the hardness of the classification problem.",
          "link": "http://arxiv.org/abs/2309.10688",
          "publishedOn": "2023-09-23T00:40:37.906Z",
          "wordCount": 727,
          "title": "On the different regimes of Stochastic Gradient Descent. (arXiv:2309.10688v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gkolemis_V/0/1/0/all/0/1\">Vasilis Gkolemis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzerefos_A/0/1/0/all/0/1\">Anargiros Tzerefos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalamagas_T/0/1/0/all/0/1\">Theodore Dalamagas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1\">Eirini Ntoutsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diou_C/0/1/0/all/0/1\">Christos Diou</a>",
          "description": "Generalized Additive Models (GAMs) are widely used explainable-by-design\nmodels in various applications. GAMs assume that the output can be represented\nas a sum of univariate functions, referred to as components. However, this\nassumption fails in ML problems where the output depends on multiple features\nsimultaneously. In these cases, GAMs fail to capture the interaction terms of\nthe underlying function, leading to subpar accuracy. To (partially) address\nthis issue, we propose Regionally Additive Models (RAMs), a novel class of\nexplainable-by-design models. RAMs identify subregions within the feature space\nwhere interactions are minimized. Within these regions, it is more accurate to\nexpress the output as a sum of univariate functions (components). Consequently,\nRAMs fit one component per subregion of each feature instead of one component\nper feature. This approach yields a more expressive model compared to GAMs\nwhile retaining interpretability. The RAM framework consists of three steps.\nFirstly, we train a black-box model. Secondly, using Regional Effect Plots, we\nidentify subregions where the black-box model exhibits near-local additivity.\nLastly, we fit a GAM component for each identified subregion. We validate the\neffectiveness of RAMs through experiments on both synthetic and real-world\ndatasets. The results confirm that RAMs offer improved expressiveness compared\nto GAMs while maintaining interpretability.",
          "link": "http://arxiv.org/abs/2309.12215",
          "publishedOn": "2023-09-23T00:40:37.898Z",
          "wordCount": 720,
          "title": "Regionally Additive Models: Explainable-by-design models minimizing feature interactions. (arXiv:2309.12215v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.03303",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cuchiero_C/0/1/0/all/0/1\">Christa Cuchiero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmocker_P/0/1/0/all/0/1\">Philipp Schmocker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teichmann_J/0/1/0/all/0/1\">Josef Teichmann</a>",
          "description": "We introduce so-called functional input neural networks defined on a possibly\ninfinite dimensional weighted space with values also in a possibly infinite\ndimensional output space. To this end, we use an additive family as hidden\nlayer maps and a non-linear activation function applied to each hidden layer.\nRelying on Stone-Weierstrass theorems on weighted spaces, we can prove a global\nuniversal approximation result for generalizations of continuous functions\ngoing beyond the usual approximation on compact sets. This then applies in\nparticular to approximation of (non-anticipative) path space functionals via\nfunctional input neural networks. As a further application of the weighted\nStone-Weierstrass theorem we prove a global universal approximation result for\nlinear functions of the signature. We also introduce the viewpoint of Gaussian\nprocess regression in this setting and show that the reproducing kernel Hilbert\nspace of the signature kernels are Cameron-Martin spaces of certain Gaussian\nprocesses. This paves the way towards uncertainty quantification for signature\nkernel regression.",
          "link": "http://arxiv.org/abs/2306.03303",
          "publishedOn": "2023-09-23T00:40:37.888Z",
          "wordCount": 705,
          "title": "Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.12279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khanmohammadi_R/0/1/0/all/0/1\">Reza Khanmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alhanai_T/0/1/0/all/0/1\">Tuka Alhanai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Mohammad M. Ghassemi</a>",
          "description": "Initialization of neural network weights plays a pivotal role in determining\ntheir performance. Feature Imitating Networks (FINs) offer a novel strategy by\ninitializing weights to approximate specific closed-form statistical features,\nsetting a promising foundation for deep learning architectures. While the\napplicability of FINs has been chiefly tested in biomedical domains, this study\nextends its exploration into other time series datasets. Three different\nexperiments are conducted in this study to test the applicability of imitating\nTsallis entropy for performance enhancement: Bitcoin price prediction, speech\nemotion recognition, and chronic neck pain detection. For the Bitcoin price\nprediction, models embedded with FINs reduced the root mean square error by\naround 1000 compared to the baseline. In the speech emotion recognition task,\nthe FIN-augmented model increased classification accuracy by over 3 percent.\nLastly, in the CNP detection experiment, an improvement of about 7 percent was\nobserved compared to established classifiers. These findings validate the broad\nutility and potency of FINs in diverse applications.",
          "link": "http://arxiv.org/abs/2309.12279",
          "publishedOn": "2023-09-23T00:40:37.883Z",
          "wordCount": 687,
          "title": "The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains. (arXiv:2309.12279v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.07626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "In this work, we provide a characterization of the feature-learning process\nin two-layer ReLU networks trained by gradient descent on the logistic loss\nfollowing random initialization. We consider data with binary labels that are\ngenerated by an XOR-like function of the input features. We permit a constant\nfraction of the training labels to be corrupted by an adversary. We show that,\nalthough linear classifiers are no better than random guessing for the\ndistribution we consider, two-layer ReLU networks trained by gradient descent\nachieve generalization error close to the label noise rate. We develop a novel\nproof technique that shows that at initialization, the vast majority of neurons\nfunction as random features that are only weakly correlated with useful\nfeatures, and the gradient descent dynamics 'amplify' these weak, random\nfeatures to strong, useful features.",
          "link": "http://arxiv.org/abs/2202.07626",
          "publishedOn": "2023-09-16T00:40:56.879Z",
          "wordCount": null,
          "title": "Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yafei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jianguo Liu</a>",
          "description": "Score-based methods for learning Bayesain networks(BN) aim to maximizing the\nglobal score functions. However, if local variables have direct and indirect\ndependence simultaneously, the global optimization on score functions misses\nedges between variables with indirect dependent relationship, of which scores\nare smaller than those with direct dependent relationship. In this paper, we\npresent an identifiability condition based on a determined subset of parents to\nidentify the underlying DAG. By the identifiability condition, we develop a\ntwo-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the\nglobal optimization. In the optimal phase, an optimization problem based on\nfirst-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated\nskeleton as the initial determined parents subset. In the tuning phase, the\nskeleton is locally tuned by deletion, addition and DAG-formalization\nstrategies using the theoretically proved incremental properties of high-order\nHSIC. Numerical experiments for different synthetic datasets and real-world\ndatasets show that the OT algorithm outperforms existing methods. Especially in\nSigmoid Mix model with the size of the graph being ${\\rm\\bf d=40}$, the\nstructure intervention distance (SID) of the OT algorithm is 329.7 smaller than\nthe one obtained by CAM, which indicates that the graph estimated by the OT\nalgorithm misses fewer edges compared with CAM.Source code of the OT algorithm\nis available at https://github.com/YafeiannWang/optimal-tune-algorithm.",
          "link": "http://arxiv.org/abs/2308.05969",
          "publishedOn": "2023-09-16T00:40:56.874Z",
          "wordCount": null,
          "title": "Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07453",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Navarro_M/0/1/0/all/0/1\">Madeline Navarro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "The myriad complex systems with multiway interactions motivate the extension\nof graph-based pairwise connections to higher-order relations. In particular,\nthe simplicial complex has inspired generalizations of graph neural networks\n(GNNs) to simplicial complex-based models. Learning on such systems requires\nlarge amounts of data, which can be expensive or impossible to obtain. We\npropose data augmentation of simplicial complexes through both linear and\nnonlinear mixup mechanisms that return mixtures of existing labeled samples. In\naddition to traditional pairwise mixup, we present a convex clustering mixup\napproach for a data-driven relationship among several simplicial complexes. We\ntheoretically demonstrate that the resultant synthetic simplicial complexes\ninterpolate among existing data with respect to homomorphism densities. Our\nmethod is demonstrated on both synthetic and real-world datasets for simplicial\ncomplex classification.",
          "link": "http://arxiv.org/abs/2309.07453",
          "publishedOn": "2023-09-16T00:40:56.869Z",
          "wordCount": null,
          "title": "SC-MAD: Mixtures of Higher-order Networks for Data Augmentation. (arXiv:2309.07453v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "In this paper, we consider the intersection of two problems in machine\nlearning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD).\nOn the one hand, the first considers adapting multiple heterogeneous labeled\nsource domains to an unlabeled target domain. On the other hand, the second\nattacks the problem of synthesizing a small summary containing all the\ninformation about the datasets. We thus consider a new problem called MSDA-DD.\nTo solve it, we adapt previous works in the MSDA literature, such as\nWasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD\nmethod Distribution Matching. We thoroughly experiment with this novel problem\non four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous\nStirred Tank Reactor, and Case Western Reserve University), where we show that,\neven with as little as 1 sample per class, one achieves state-of-the-art\nadaptation performance.",
          "link": "http://arxiv.org/abs/2309.07666",
          "publishedOn": "2023-09-16T00:40:56.744Z",
          "wordCount": null,
          "title": "Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning. (arXiv:2309.07666v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michael Y. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grant_E/0/1/0/all/0/1\">Erin Grant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1\">Thomas L. Griffiths</a>",
          "description": "Not being able to understand and predict the behavior of deep learning\nsystems makes it hard to decide what architecture and algorithm to use for a\ngiven problem. In science and engineering, modeling is a methodology used to\nunderstand complex systems whose internal processes are opaque. Modeling\nreplaces a complex system with a simpler, more interpretable surrogate. Drawing\ninspiration from this, we construct a class of surrogate models for neural\nnetworks using Gaussian processes. Rather than deriving kernels for infinite\nneural networks, we learn kernels empirically from the naturalistic behavior of\nfinite neural networks. We demonstrate our approach captures existing phenomena\nrelated to the spectral bias of neural networks, and then show that our\nsurrogate models can be used to solve practical problems such as identifying\nwhich points most influence the behavior of specific neural networks and\npredicting which architectures and algorithms will generalize well for specific\ndatasets.",
          "link": "http://arxiv.org/abs/2208.06028",
          "publishedOn": "2023-09-16T00:40:56.743Z",
          "wordCount": null,
          "title": "Gaussian Process Surrogate Models for Neural Networks. (arXiv:2208.06028v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ichikawa_Y/0/1/0/all/0/1\">Yuma Ichikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hukushima_K/0/1/0/all/0/1\">Koji Hukushima</a>",
          "description": "In the Variational Autoencoder (VAE), the variational posterior often aligns\nclosely with the prior, which is known as posterior collapse and hinders the\nquality of representation learning. To mitigate this problem, an adjustable\nhyperparameter beta has been introduced in the VAE. This paper presents a\nclosed-form expression to assess the relationship between the beta in VAE, the\ndataset size, the posterior collapse, and the rate-distortion curve by\nanalyzing a minimal VAE in a high-dimensional limit. These results clarify that\na long plateau in the generalization error emerges with a relatively larger\nbeta. As the beta increases, the length of the plateau extends and then becomes\ninfinite beyond a certain beta threshold. This implies that the choice of beta,\nunlike the usual regularization parameters, can induce posterior collapse\nregardless of the dataset size. Thus, beta is a risky parameter that requires\ncareful tuning. Furthermore, considering the dataset-size dependence on the\nrate-distortion curve, a relatively large dataset is required to obtain a\nrate-distortion curve with high rates. Extensive numerical experiments support\nour analysis.",
          "link": "http://arxiv.org/abs/2309.07663",
          "publishedOn": "2023-09-16T00:40:56.738Z",
          "wordCount": null,
          "title": "Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE. (arXiv:2309.07663v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03926",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fadikar_A/0/1/0/all/0/1\">Arindam Fadikar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Binois_M/0/1/0/all/0/1\">Mickael Binois</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Collier_N/0/1/0/all/0/1\">Nicholson Collier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stevens_A/0/1/0/all/0/1\">Abby Stevens</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Toh_K/0/1/0/all/0/1\">Kok Ben Toh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ozik_J/0/1/0/all/0/1\">Jonathan Ozik</a>",
          "description": "Epidemiological models must be calibrated to ground truth for downstream\ntasks such as producing forward projections or running what-if scenarios. The\nmeaning of calibration changes in case of a stochastic model since output from\nsuch a model is generally described via an ensemble or a distribution. Each\nmember of the ensemble is usually mapped to a random number seed (explicitly or\nimplicitly). With the goal of finding not only the input parameter settings but\nalso the random seeds that are consistent with the ground truth, we propose a\nclass of Gaussian process (GP) surrogates along with an optimization strategy\nbased on Thompson sampling. This Trajectory Oriented Optimization (TOO)\napproach produces actual trajectories close to the empirical observations\ninstead of a set of parameter settings where only the mean simulation behavior\nmatches with the ground truth.",
          "link": "http://arxiv.org/abs/2305.03926",
          "publishedOn": "2023-09-16T00:40:56.731Z",
          "wordCount": null,
          "title": "Trajectory-oriented optimization of stochastic epidemiological models. (arXiv:2305.03926v3 [stat.AP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.12814",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cook_A/0/1/0/all/0/1\">Andrew Cook</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hammerlindl_A/0/1/0/all/0/1\">Andy Hammerlindl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tucker_W/0/1/0/all/0/1\">Warwick Tucker</a>",
          "description": "We define a family of $C^1$ functions which we call \"nowhere coexpanding\nfunctions\" that is closed under composition and includes all $C^3$ functions\nwith non-positive Schwarzian derivative. We establish results on the number and\nnature of the fixed points of these functions, including a generalisation of a\nclassic result of Singer.",
          "link": "http://arxiv.org/abs/2303.12814",
          "publishedOn": "2023-09-16T00:40:56.728Z",
          "wordCount": null,
          "title": "Nowhere coexpanding functions. (arXiv:2303.12814v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_J/0/1/0/all/0/1\">Jin-Hong Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1\">Larry Wasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roeder_K/0/1/0/all/0/1\">Kathryn Roeder</a>",
          "description": "Tens of thousands of simultaneous hypothesis tests are routinely performed in\ngenomic studies to identify differentially expressed genes. However, due to\nunmeasured confounders, many standard statistical approaches may be\nsubstantially biased. This paper investigates the large-scale hypothesis\ntesting problem for multivariate generalized linear models in the presence of\nconfounding effects. Under arbitrary confounding mechanisms, we propose a\nunified statistical estimation and inference framework that harnesses\northogonal structures and integrates linear projections into three key stages.\nIt first leverages multivariate responses to separate marginal and uncorrelated\nconfounding effects, recovering the confounding coefficients' column space.\nSubsequently, latent factors and primary effects are jointly estimated,\nutilizing $\\ell_1$-regularization for sparsity while imposing orthogonality\nonto confounding coefficients. Finally, we incorporate projected and weighted\nbias-correction steps for hypothesis testing. Theoretically, we establish\nvarious effects' identification conditions and non-asymptotic error bounds. We\nshow effective Type-I error control of asymptotic $z$-tests as sample and\nresponse sizes approach infinity. Numerical experiments demonstrate that the\nproposed method controls the false discovery rate by the Benjamini-Hochberg\nprocedure and is more powerful than alternative methods. By comparing\nsingle-cell RNA-seq counts from two groups of samples, we demonstrate the\nsuitability of adjusting confounding effects when significant covariates are\nabsent from the model.",
          "link": "http://arxiv.org/abs/2309.07261",
          "publishedOn": "2023-09-16T00:40:56.655Z",
          "wordCount": null,
          "title": "Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07611",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Zheng_H/0/1/0/all/0/1\">Han Zheng</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_Z/0/1/0/all/0/1\">Zimu Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Strelchuk_S/0/1/0/all/0/1\">Sergii Strelchuk</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>",
          "description": "We develop a theoretical framework for $S_n$-equivariant convolutional\nquantum circuits with SU$(d)$-symmetry, building on and significantly\ngeneralizing Jordan's Permutational Quantum Computing (PQC) formalism based on\nSchur-Weyl duality connecting both SU$(d)$ and $S_n$ actions on qudits. In\nparticular, we utilize the Okounkov-Vershik approach to prove Harrow's\nstatement (Ph.D. Thesis 2005 p.160) on the equivalence between\n$\\operatorname{SU}(d)$ and $S_n$ irrep bases and to establish the\n$S_n$-equivariant Convolutional Quantum Alternating Ans\\\"atze ($S_n$-CQA) using\nYoung-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA is able to generate\nany unitary in any given $S_n$ irrep sector, which may serve as a universal\nmodel for a wide array of quantum machine learning problems with the presence\nof SU($d$) symmetry. Our method provides another way to prove the universality\nof Quantum Approximate Optimization Algorithm (QAOA) and verifies that 4-local\nSU($d$) symmetric unitaries are sufficient to build generic SU($d$) symmetric\nquantum circuits up to relative phase factors. We present numerical simulations\nto showcase the effectiveness of the ans\\\"atze to find the ground state energy\nof the $J_1$--$J_2$ antiferromagnetic Heisenberg model on the rectangular and\nKagome lattices. Our work provides the first application of the celebrated\nOkounkov-Vershik's $S_n$ representation theory to quantum physics and machine\nlearning, from which to propose quantum variational ans\\\"atze that strongly\nsuggests to be classically intractable tailored towards a specific optimization\nproblem.",
          "link": "http://arxiv.org/abs/2112.07611",
          "publishedOn": "2023-09-16T00:40:56.580Z",
          "wordCount": null,
          "title": "Speeding up Learning Quantum States through Group Equivariant Convolutional Quantum Ans\\\"atze. (arXiv:2112.07611v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinmei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuanning Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>",
          "description": "Accurately labeling biomedical data presents a challenge. Traditional\nsemi-supervised learning methods often under-utilize available unlabeled data.\nTo address this, we propose a novel reliability-based training data cleaning\nmethod employing inductive conformal prediction (ICP). This method capitalizes\non a small set of accurately labeled training data and leverages ICP-calculated\nreliability metrics to rectify mislabeled data and outliers within vast\nquantities of noisy training data. The efficacy of the method is validated\nacross three classification tasks within distinct modalities: filtering\ndrug-induced-liver-injury (DILI) literature with title and abstract, predicting\nICU admission of COVID-19 patients through CT radiomics and electronic health\nrecords, and subtyping breast cancer using RNA-sequencing data. Varying levels\nof noise to the training labels were introduced through label permutation.\nResults show significant enhancements in classification performance: accuracy\nenhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC\nenhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and\naccuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing\nexperiments (up to 74.6% and 89.0%). Our method offers the potential to\nsubstantially boost classification performance in multi-modal biomedical\nmachine learning tasks. Importantly, it accomplishes this without necessitating\nan excessive volume of meticulously curated training data.",
          "link": "http://arxiv.org/abs/2309.07332",
          "publishedOn": "2023-09-16T00:40:54.840Z",
          "wordCount": 803,
          "title": "Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining. (arXiv:2309.07332v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07893",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tripuraneni_N/0/1/0/all/0/1\">Nilesh Tripuraneni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richardson_L/0/1/0/all/0/1\">Lee Richardson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+DAmour_A/0/1/0/all/0/1\">Alexander D&#x27;Amour</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Soriano_J/0/1/0/all/0/1\">Jacopo Soriano</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>",
          "description": "In many randomized experiments, the treatment effect of the long-term metric\n(i.e. the primary outcome of interest) is often difficult or infeasible to\nmeasure. Such long-term metrics are often slow to react to changes and\nsufficiently noisy they are challenging to faithfully estimate in short-horizon\nexperiments. A common alternative is to measure several short-term proxy\nmetrics in the hope they closely track the long-term metric -- so they can be\nused to effectively guide decision-making in the near-term. We introduce a new\nstatistical framework to both define and construct an optimal proxy metric for\nuse in a homogeneous population of randomized experiments. Our procedure first\nreduces the construction of an optimal proxy metric in a given experiment to a\nportfolio optimization problem which depends on the true latent treatment\neffects and noise level of experiment under consideration. We then denoise the\nobserved treatment effects of the long-term metric and a set of proxies in a\nhistorical corpus of randomized experiments to extract estimates of the latent\ntreatment effects for use in the optimization problem. One key insight derived\nfrom our approach is that the optimal proxy metric for a given experiment is\nnot apriori fixed; rather it should depend on the sample size (or effective\nnoise level) of the randomized experiment for which it is deployed. To\ninstantiate and evaluate our framework, we employ our methodology in a large\ncorpus of randomized experiments from an industrial recommendation system and\nconstruct proxy metrics that perform favorably relative to several baselines.",
          "link": "http://arxiv.org/abs/2309.07893",
          "publishedOn": "2023-09-16T00:40:54.823Z",
          "wordCount": 746,
          "title": "Choosing a Proxy Metric from Past Experiments. (arXiv:2309.07893v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2105.06031",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1\">Yifeng Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khoo_Y/0/1/0/all/0/1\">Yuehaw Khoo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhizhen Zhao</a>",
          "description": "In the presence of heterogeneous data, where randomly rotated objects fall\ninto multiple underlying categories, it is challenging to simultaneously\nclassify them into clusters and synchronize them based on pairwise relations.\nThis gives rise to the joint problem of community detection and\nsynchronization. We propose a series of semidefinite relaxations, and prove\ntheir exact recovery when extending the celebrated stochastic block model to\nthis new setting where both rotations and cluster identities are to be\ndetermined. Numerical experiments demonstrate the efficacy of our proposed\nalgorithms and confirm our theoretical result which indicates a sharp phase\ntransition for exact recovery.",
          "link": "http://arxiv.org/abs/2105.06031",
          "publishedOn": "2023-09-16T00:40:54.809Z",
          "wordCount": 622,
          "title": "Joint Community Detection and Rotational Synchronization via Semidefinite Programming. (arXiv:2105.06031v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>",
          "description": "We introduce beta diffusion, a novel generative modeling method that\nintegrates demasking and denoising to generate data within bounded ranges.\nUsing scaled and shifted beta distributions, beta diffusion utilizes\nmultiplicative transitions over time to create both forward and reverse\ndiffusion processes, maintaining beta distributions in both the forward\nmarginals and the reverse conditionals, given the data at any point in time.\nUnlike traditional diffusion-based generative models relying on additive\nGaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is\nmultiplicative and optimized with KL-divergence upper bounds (KLUBs) derived\nfrom the convexity of the KL divergence. We demonstrate that the proposed KLUBs\nare more effective for optimizing beta diffusion compared to negative ELBOs,\nwhich can also be derived as the KLUBs of the same KL divergence with its two\narguments swapped. The loss function of beta diffusion, expressed in terms of\nBregman divergence, further supports the efficacy of KLUBs for optimization.\nExperimental results on both synthetic data and natural images demonstrate the\nunique capabilities of beta diffusion in generative modeling of range-bounded\ndata and validate the effectiveness of KLUBs in optimizing diffusion models,\nthereby making them valuable additions to the family of diffusion-based\ngenerative models and the optimization techniques used to train them.",
          "link": "http://arxiv.org/abs/2309.07867",
          "publishedOn": "2023-09-16T00:40:54.786Z",
          "wordCount": 706,
          "title": "Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yeqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weixin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junze Yin</a>",
          "description": "Large language models (LLMs) have played a pivotal role in revolutionizing\nvarious facets of our daily existence. Solving attention regression is a\nfundamental task in optimizing LLMs. In this work, we focus on giving a\nprovable guarantee for the one-layer attention network objective function\n$L(X,Y) = \\sum_{j_0 = 1}^n \\sum_{i_0 = 1}^d ( \\langle \\langle \\exp(\n\\mathsf{A}_{j_0} x ) , {\\bf 1}_n \\rangle^{-1} \\exp( \\mathsf{A}_{j_0} x ), A_{3}\nY_{*,i_0} \\rangle - b_{j_0,i_0} )^2$. Here $\\mathsf{A} \\in \\mathbb{R}^{n^2\n\\times d^2}$ is Kronecker product between $A_1 \\in \\mathbb{R}^{n \\times d}$ and\n$A_2 \\in \\mathbb{R}^{n \\times d}$. $A_3$ is a matrix in $\\mathbb{R}^{n \\times\nd}$, $\\mathsf{A}_{j_0} \\in \\mathbb{R}^{n \\times d^2}$ is the $j_0$-th block of\n$\\mathsf{A}$. The $X, Y \\in \\mathbb{R}^{d \\times d}$ are variables we want to\nlearn. $B \\in \\mathbb{R}^{n \\times d}$ and $b_{j_0,i_0} \\in \\mathbb{R}$ is one\nentry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \\in \\mathbb{R}^d$\nis the $i_0$-column vector of $Y$, and $x \\in \\mathbb{R}^{d^2}$ is the\nvectorization of $X$.\n\nIn a multi-layer LLM network, the matrix $B \\in \\mathbb{R}^{n \\times d}$ can\nbe viewed as the output of a layer, and $A_1= A_2 = A_3 \\in \\mathbb{R}^{n\n\\times d}$ can be viewed as the input of a layer. The matrix version of $x$ can\nbe viewed as $QK^\\top$ and $Y$ can be viewed as $V$. We provide an iterative\ngreedy algorithm to train loss function $L(X,Y)$ up $\\epsilon$ that runs in\n$\\widetilde{O}( ({\\cal T}_{\\mathrm{mat}}(n,n,d) + {\\cal\nT}_{\\mathrm{mat}}(n,d,d) + d^{2\\omega}) \\log(1/\\epsilon) )$ time. Here ${\\cal\nT}_{\\mathrm{mat}}(a,b,c)$ denotes the time of multiplying $a \\times b$ matrix\nanother $b \\times c$ matrix, and $\\omega\\approx 2.37$ denotes the exponent of\nmatrix multiplication.",
          "link": "http://arxiv.org/abs/2309.07418",
          "publishedOn": "2023-09-16T00:40:54.757Z",
          "wordCount": 839,
          "title": "A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time. (arXiv:2309.07418v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13348",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ishikawa_K/0/1/0/all/0/1\">Kei Ishikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_N/0/1/0/all/0/1\">Niao He</a>",
          "description": "We study policy evaluation of offline contextual bandits subject to\nunobserved confounders. Sensitivity analysis methods are commonly used to\nestimate the policy value under the worst-case confounding over a given\nuncertainty set. However, existing work often resorts to some coarse relaxation\nof the uncertainty set for the sake of tractability, leading to overly\nconservative estimation of the policy value. In this paper, we propose a\ngeneral estimator that provides a sharp lower bound of the policy value. It can\nbe shown that our estimator contains the recently proposed sharp estimator by\nDorn and Guo (2022) as a special case, and our method enables a novel extension\nof the classical marginal sensitivity model using f-divergence. To construct\nour estimator, we leverage the kernel method to obtain a tractable\napproximation to the conditional moment constraints, which traditional\nnon-sharp estimators failed to take into account. In the theoretical analysis,\nwe provide a condition for the choice of the kernel which guarantees no\nspecification error that biases the lower bound estimation. Furthermore, we\nprovide consistency guarantees of policy evaluation and learning. In the\nexperiments with synthetic and real-world data, we demonstrate the\neffectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2302.13348",
          "publishedOn": "2023-09-16T00:40:54.739Z",
          "wordCount": 705,
          "title": "Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07250",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+East_R/0/1/0/all/0/1\">Richard D. P. East</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Alonso_Linaje_G/0/1/0/all/0/1\">Guillermo Alonso-Linaje</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Park_C/0/1/0/all/0/1\">Chae-Yeun Park</a>",
          "description": "Variational algorithms require architectures that naturally constrain the\noptimisation space to run efficiently. In geometric quantum machine learning,\none achieves this by encoding group structure into parameterised quantum\ncircuits to include the symmetries of a problem as an inductive bias. However,\nconstructing such circuits is challenging as a concrete guiding principle has\nyet to emerge. In this paper, we propose the use of spin networks, a form of\ndirected tensor network invariant under a group transformation, to devise SU(2)\nequivariant quantum circuit ans\\\"atze -- circuits possessing spin rotation\nsymmetry. By changing to the basis that block diagonalises SU(2) group action,\nthese networks provide a natural building block for constructing parameterised\nequivariant quantum circuits. We prove that our construction is mathematically\nequivalent to other known constructions, such as those based on twirling and\ngeneralised permutations, but more direct to implement on quantum hardware. The\nefficacy of our constructed circuits is tested by solving the ground state\nproblem of SU(2) symmetric Heisenberg models on the one-dimensional triangular\nlattice and on the Kagome lattice. Our results highlight that our equivariant\ncircuits boost the performance of quantum variational algorithms, indicating\nbroader applicability to other real-world problems.",
          "link": "http://arxiv.org/abs/2309.07250",
          "publishedOn": "2023-09-16T00:40:54.730Z",
          "wordCount": 729,
          "title": "All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks. (arXiv:2309.07250v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.06724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wangni_J/0/1/0/all/0/1\">Jianqiao Wangni</a>",
          "description": "We aim to provide a general framework of for computational photography that\nrecovers the real scene from imperfect images, via the Deep Nonparametric\nConvexified Filtering (DNCF). It is consists of a nonparametric deep network to\nresemble the physical equations behind the image formation, such as denoising,\nsuper-resolution, inpainting, and flash. DNCF has no parameterization dependent\non training data, therefore has a strong generalization and robustness to\nadversarial image manipulation. During inference, we also encourage the network\nparameters to be nonnegative and create a bi-convex function on the input and\nparameters, and this adapts to second-order optimization algorithms with\ninsufficient running time, having 10X acceleration over Deep Image Prior. With\nthese tools, we empirically verify its capability to defend image\nclassification deep networks against adversary attack algorithms in real-time.",
          "link": "http://arxiv.org/abs/2309.06724",
          "publishedOn": "2023-09-16T00:40:54.725Z",
          "wordCount": 669,
          "title": "Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense. (arXiv:2309.06724v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1906.00331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We consider nonconvex-concave minimax problems, $\\min_{\\mathbf{x}}\n\\max_{\\mathbf{y} \\in \\mathcal{Y}} f(\\mathbf{x}, \\mathbf{y})$, where $f$ is\nnonconvex in $\\mathbf{x}$ but concave in $\\mathbf{y}$ and $\\mathcal{Y}$ is a\nconvex and bounded set. One of the most popular algorithms for solving this\nproblem is the celebrated gradient descent ascent (GDA) algorithm, which has\nbeen widely used in machine learning, control theory and economics. Despite the\nextensive convergence results for the convex-concave setting, GDA with equal\nstepsize can converge to limit cycles or even diverge in a general setting. In\nthis paper, we present the complexity results on two-time-scale GDA for solving\nnonconvex-concave minimax problems, showing that the algorithm can find a\nstationary point of the function $\\Phi(\\cdot) := \\max_{\\mathbf{y} \\in\n\\mathcal{Y}} f(\\cdot, \\mathbf{y})$ efficiently. To the best our knowledge, this\nis the first nonasymptotic analysis for two-time-scale GDA in this setting,\nshedding light on its superior practical performance in training generative\nadversarial networks (GANs) and other real applications.",
          "link": "http://arxiv.org/abs/1906.00331",
          "publishedOn": "2023-09-16T00:40:54.717Z",
          "wordCount": 779,
          "title": "On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. (arXiv:1906.00331v9 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07810",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1\">Yufan Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sur_P/0/1/0/all/0/1\">Pragya Sur</a>",
          "description": "We introduce a new debiasing framework for high-dimensional linear regression\nthat bypasses the restrictions on covariate distributions imposed by modern\ndebiasing technology. We study the prevalent setting where the number of\nfeatures and samples are both large and comparable. In this context,\nstate-of-the-art debiasing technology uses a degrees-of-freedom correction to\nremove shrinkage bias of regularized estimators and conduct inference. However,\nthis method requires that the observed samples are i.i.d., the covariates\nfollow a mean zero Gaussian distribution, and reliable covariance matrix\nestimates for observed features are available. This approach struggles when (i)\ncovariates are non-Gaussian with heavy tails or asymmetric distributions, (ii)\nrows of the design exhibit heterogeneity or dependencies, and (iii) reliable\nfeature covariance estimates are lacking.\n\nTo address these, we develop a new strategy where the debiasing correction is\na rescaled gradient descent step (suitably initialized) with step size\ndetermined by the spectrum of the sample covariance matrix. Unlike prior work,\nwe assume that eigenvectors of this matrix are uniform draws from the\northogonal group. We show this assumption remains valid in diverse situations\nwhere traditional debiasing fails, including designs with complex row-column\ndependencies, heavy tails, asymmetric properties, and latent low-rank\nstructures. We establish asymptotic normality of our proposed estimator\n(centered and scaled) under various convergence notions. Moreover, we develop a\nconsistent estimator for its asymptotic variance. Lastly, we introduce a\ndebiased Principal Component Regression (PCR) technique using our\nSpectrum-Aware approach. In varied simulations and real data experiments, we\nobserve that our method outperforms degrees-of-freedom debiasing by a margin.",
          "link": "http://arxiv.org/abs/2309.07810",
          "publishedOn": "2023-09-16T00:40:54.711Z",
          "wordCount": 772,
          "title": "Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.01726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Escobar_Bach_M/0/1/0/all/0/1\">Mikael Escobar-Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goudet_O/0/1/0/all/0/1\">Olivier Goudet</a>",
          "description": "In the presence of right-censored data with covariates, the conditional\nKaplan-Meier estimator (also known as the Beran estimator) consistently\nestimates the conditional survival function of the random follow-up for the\nevent of interest. However, a necessary condition is the unambiguous knowledge\nof whether each individual is censored or not, which may be incomplete in\npractice. We therefore propose a study of the Beran estimator when the\ncensoring indicators are generic random variables and discuss necessary\nconditions for the efficiency of the Beran estimator. From this, we provide a\nnew estimator for the conditional survival function with missing not at random\n(MNAR) censoring indicators based on a conditional copula model for the\nmissingness mechanism. In addition to the theoretical results, we illustrate\nhow the estimators work for small samples through a simulation study and show\ntheir practical applicability by analyzing synthetic and real data.",
          "link": "http://arxiv.org/abs/2009.01726",
          "publishedOn": "2023-09-16T00:40:54.693Z",
          "wordCount": 673,
          "title": "Survival Estimation for Missing not at Random Censoring Indicators based on Copula Models. (arXiv:2009.01726v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07779",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Griebel_M/0/1/0/all/0/1\">Michael Griebel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oswald_P/0/1/0/all/0/1\">Peter Oswald</a>",
          "description": "We consider the problem of approximating the regression function from noisy\nvector-valued data by an online learning algorithm using an appropriate\nreproducing kernel Hilbert space (RKHS) as prior. In an online algorithm,\ni.i.d. samples become available one by one by a random process and are\nsuccessively processed to build approximations to the regression function. We\nare interested in the asymptotic performance of such online approximation\nalgorithms and show that the expected squared error in the RKHS norm can be\nbounded by $C^2 (m+1)^{-s/(2+s)}$, where $m$ is the current number of processed\ndata, the parameter $0<s\\leq 1$ expresses an additional smoothness assumption\non the regression function and the constant $C$ depends on the variance of the\ninput noise, the smoothness of the regression function and further parameters\nof the algorithm.",
          "link": "http://arxiv.org/abs/2309.07779",
          "publishedOn": "2023-09-16T00:40:54.688Z",
          "wordCount": 636,
          "title": "Convergence analysis of online algorithms for vector-valued kernel regression. (arXiv:2309.07779v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.07260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhouri_M/0/1/0/all/0/1\">Mohamed Aziz Bhouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joly_M/0/1/0/all/0/1\">Michael Joly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Robert Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Soumalya Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>",
          "description": "Several fundamental problems in science and engineering consist of global\noptimization tasks involving unknown high-dimensional (black-box) functions\nthat map a set of controllable variables to the outcomes of an expensive\nexperiment. Bayesian Optimization (BO) techniques are known to be effective in\ntackling global optimization problems using a relatively small number objective\nfunction evaluations, but their performance suffers when dealing with\nhigh-dimensional outputs. To overcome the major challenge of dimensionality,\nhere we propose a deep learning framework for BO and sequential decision making\nbased on bootstrapped ensembles of neural architectures with randomized priors.\nUsing appropriate architecture choices, we show that the proposed framework can\napproximate functional relationships between design variables and quantities of\ninterest, even in cases where the latter take values in high-dimensional vector\nspaces or even infinite-dimensional function spaces. In the context of BO, we\naugmented the proposed probabilistic surrogates with re-parameterized Monte\nCarlo approximations of multiple-point (parallel) acquisition functions, as\nwell as methodological extensions for accommodating black-box constraints and\nmulti-fidelity information sources. We test the proposed framework against\nstate-of-the-art methods for BO and demonstrate superior performance across\nseveral challenging tasks with high-dimensional outputs, including a\nconstrained multi-fidelity optimization task involving shape optimization of\nrotor blades in turbo-machinery.",
          "link": "http://arxiv.org/abs/2302.07260",
          "publishedOn": "2023-09-16T00:40:54.674Z",
          "wordCount": 807,
          "title": "Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.05928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Benign overfitting, the phenomenon where interpolating models generalize well\nin the presence of noisy data, was first observed in neural network models\ntrained with gradient descent. To better understand this empirical observation,\nwe consider the generalization error of two-layer neural networks trained to\ninterpolation by gradient descent on the logistic loss following random\ninitialization. We assume the data comes from well-separated class-conditional\nlog-concave distributions and allow for a constant fraction of the training\nlabels to be corrupted by an adversary. We show that in this setting, neural\nnetworks exhibit benign overfitting: they can be driven to zero training error,\nperfectly fitting any noisy training labels, and simultaneously achieve minimax\noptimal test error. In contrast to previous work on benign overfitting that\nrequire linear or kernel-based predictors, our analysis holds in a setting\nwhere both the model and learning dynamics are fundamentally nonlinear.",
          "link": "http://arxiv.org/abs/2202.05928",
          "publishedOn": "2023-09-16T00:40:54.653Z",
          "wordCount": 725,
          "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. (arXiv:2202.05928v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chamma_A/0/1/0/all/0/1\">Ahmad Chamma</a> (1 and 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Engemann_D/0/1/0/all/0/1\">Denis A. Engemann</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Thirion_B/0/1/0/all/0/1\">Bertrand Thirion</a> (1 and 2 and 3) ((1) Inria, (2) Universite Paris Saclay, (3) CEA, (4) Roche Pharma Research and Early Development, Neuroscience and Rare Diseases, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd., Basel, Switzerland)",
          "description": "Variable importance assessment has become a crucial step in machine-learning\napplications when using complex learners, such as deep neural networks, on\nlarge-scale data. Removal-based importance assessment is currently the\nreference approach, particularly when statistical guarantees are sought to\njustify variable inclusion. It is often implemented with variable permutation\nschemes. On the flip side, these approaches risk misidentifying unimportant\nvariables as important in the presence of correlations among covariates. Here\nwe develop a systematic approach for studying Conditional Permutation\nImportance (CPI) that is model agnostic and computationally lean, as well as\nreusable benchmarks of state-of-the-art variable importance estimators. We show\ntheoretically and empirically that $\\textit{CPI}$ overcomes the limitations of\nstandard permutation importance by providing accurate type-I error control.\nWhen used with a deep neural network, $\\textit{CPI}$ consistently showed top\naccuracy across benchmarks. An empirical benchmark on real-world data analysis\nin a large-scale medical dataset showed that $\\textit{CPI}$ provides a more\nparsimonious selection of statistically significant variables. Our results\nsuggest that $\\textit{CPI}$ can be readily used as drop-in replacement for\npermutation-based methods.",
          "link": "http://arxiv.org/abs/2309.07593",
          "publishedOn": "2023-09-16T00:40:54.647Z",
          "wordCount": 729,
          "title": "Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07065",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Malpica_Morales_A/0/1/0/all/0/1\">Antonio Malpica-Morales</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Yatsyshin_P/0/1/0/all/0/1\">Peter Yatsyshin</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Duran_Olivencia_M/0/1/0/all/0/1\">Miguel A. Duran-Olivencia</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kalliadasis_S/0/1/0/all/0/1\">Serafim Kalliadasis</a>",
          "description": "The swift progression of machine learning (ML) has not gone unnoticed in the\nrealm of statistical mechanics. ML techniques have attracted attention by the\nclassical density-functional theory (DFT) community, as they enable discovery\nof free-energy functionals to determine the equilibrium-density profile of a\nmany-particle system. Within DFT, the external potential accounts for the\ninteraction of the many-particle system with an external field, thus, affecting\nthe density distribution. In this context, we introduce a statistical-learning\nframework to infer the external potential exerted on a many-particle system. We\ncombine a Bayesian inference approach with the classical DFT apparatus to\nreconstruct the external potential, yielding a probabilistic description of the\nexternal potential functional form with inherent uncertainty quantification.\nOur framework is exemplified with a grand-canonical one-dimensional particle\nensemble with excluded volume interactions in a confined geometry. The required\ntraining dataset is generated using a Monte Carlo (MC) simulation where the\nexternal potential is applied to the grand-canonical ensemble. The resulting\nparticle coordinates from the MC simulation are fed into the learning framework\nto uncover the external potential. This eventually allows us to compute the\nequilibrium density profile of the system by using the tools of DFT. Our\napproach benchmarks the inferred density against the exact one calculated\nthrough the DFT formulation with the true external potential. The proposed\nBayesian procedure accurately infers the external potential and the density\nprofile. We also highlight the external-potential uncertainty quantification\nconditioned on the amount of available simulated data. The seemingly simple\ncase study introduced in this work might serve as a prototype for studying a\nwide variety of applications, including adsorption and capillarity.",
          "link": "http://arxiv.org/abs/2309.07065",
          "publishedOn": "2023-09-16T00:40:54.640Z",
          "wordCount": 830,
          "title": "Physics-informed Bayesian inference of external potentials in classical density-functional theory. (arXiv:2309.07065v2 [cond-mat.stat-mech] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1\">Francisco Nunes Ferreira Quialheiro Simoes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dastani_M/0/1/0/all/0/1\">Mehdi Dastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommen_T/0/1/0/all/0/1\">Thijs van Ommen</a>",
          "description": "Artificial intelligence models and methods commonly lack causal\ninterpretability. Despite the advancements in interpretable machine learning\n(IML) methods, they frequently assign importance to features which lack causal\ninfluence on the outcome variable. Selecting causally relevant features among\nthose identified as relevant by these methods, or even before model training,\nwould offer a solution. Feature selection methods utilizing information\ntheoretical quantities have been successful in identifying statistically\nrelevant features. However, the information theoretical quantities they are\nbased on do not incorporate causality, rendering them unsuitable for such\nscenarios. To address this challenge, this article proposes information\ntheoretical quantities that incorporate the causal structure of the system,\nwhich can be used to evaluate causal importance of features for some given\noutcome variable. Specifically, we introduce causal versions of entropy and\nmutual information, termed causal entropy and causal information gain, which\nare designed to assess how much control a feature provides over the outcome\nvariable. These newly defined quantities capture changes in the entropy of a\nvariable resulting from interventions on other variables. Fundamental results\nconnecting these quantities to the existence of causal effects are derived. The\nuse of causal information gain in feature selection is demonstrated,\nhighlighting its superiority over standard mutual information in revealing\nwhich features provide control over a chosen outcome variable. Our\ninvestigation paves the way for the development of methods with improved\ninterpretability in domains involving causation.",
          "link": "http://arxiv.org/abs/2309.07703",
          "publishedOn": "2023-09-16T00:40:54.633Z",
          "wordCount": 777,
          "title": "Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07882",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Anirban Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Abhisek Chakraborty</a>",
          "description": "Gaussian process is an indispensable tool in clustering functional data,\nowing to it's flexibility and inherent uncertainty quantification. However,\nwhen the functional data is observed over a large grid (say, of length $p$),\nGaussian process clustering quickly renders itself infeasible, incurring\n$O(p^2)$ space complexity and $O(p^3)$ time complexity per iteration; and thus\nprohibiting it's natural adaptation to large environmental applications. To\nensure scalability of Gaussian process clustering in such applications, we\npropose to embed the popular Vecchia approximation for Gaussian processes at\nthe heart of the clustering task, provide crucial theoretical insights towards\nalgorithmic design, and finally develop a computationally efficient expectation\nmaximization (EM) algorithm. Empirical evidence of the utility of our proposal\nis provided via simulations and analysis of polar temperature anomaly\n(\\href{https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/global/time-series}{noaa.gov})\ndata-sets.",
          "link": "http://arxiv.org/abs/2309.07882",
          "publishedOn": "2023-09-16T00:40:54.618Z",
          "wordCount": 610,
          "title": "Scalable Model-Based Gaussian Process Clustering. (arXiv:2309.07882v1 [stat.CO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Angela Zhou</a>",
          "description": "In consequential domains, it is often impossible to compel individuals to\ntake treatment, so that optimal policy rules are merely suggestions in the\npresence of human non-adherence to treatment recommendations. In these same\ndomains, there may be heterogeneity both in who responds in taking-up\ntreatment, and heterogeneity in treatment efficacy. While optimal treatment\nrules can maximize causal outcomes across the population, access parity\nconstraints or other fairness considerations can be relevant in the case of\nencouragement. For example, in social services, a persistent puzzle is the gap\nin take-up of beneficial services among those who may benefit from them the\nmost. When in addition the decision-maker has distributional preferences over\nboth access and average outcomes, the optimal decision rule changes. We study\ncausal identification, statistical variance-reduced estimation, and robust\nestimation of optimal treatment rules, including under potential violations of\npositivity. We consider fairness constraints such as demographic parity in\ntreatment take-up, and other constraints, via constrained optimization. Our\nframework can be extended to handle algorithmic recommendations under an\noften-reasonable covariate-conditional exclusion restriction, using our\nrobustness checks for lack of positivity in the recommendation. We develop a\ntwo-stage algorithm for solving over parametrized policy classes under general\nconstraints to obtain variance-sensitive regret bounds. We illustrate the\nmethods in two case studies based on data from randomized encouragement to\nenroll in insurance and from pretrial supervised release with electronic\nmonitoring.",
          "link": "http://arxiv.org/abs/2309.07176",
          "publishedOn": "2023-09-16T00:40:54.609Z",
          "wordCount": 720,
          "title": "Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.01952",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1\">Mihaela Rosca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qin_C/0/1/0/all/0/1\">Chongli Qin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dherin_B/0/1/0/all/0/1\">Benoit Dherin</a>",
          "description": "The recipe behind the success of deep learning has been the combination of\nneural networks and gradient-based optimization. Understanding the behavior of\ngradient descent however, and particularly its instability, has lagged behind\nits empirical success. To add to the theoretical tools available to study\ngradient descent we propose the principal flow (PF), a continuous time flow\nthat approximates gradient descent dynamics. To our knowledge, the PF is the\nonly continuous flow that captures the divergent and oscillatory behaviors of\ngradient descent, including escaping local minima and saddle points. Through\nits dependence on the eigendecomposition of the Hessian the PF sheds light on\nthe recently observed edge of stability phenomena in deep learning. Using our\nnew understanding of instability we propose a learning rate adaptation method\nwhich enables us to control the trade-off between training stability and test\nset evaluation performance.",
          "link": "http://arxiv.org/abs/2302.01952",
          "publishedOn": "2023-09-16T00:40:54.604Z",
          "wordCount": 705,
          "title": "On a continuous time model of gradient descent dynamics and instability in deep learning. (arXiv:2302.01952v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175qdu3/d_how_to_download_datasets_from_huggingface/",
          "author": null,
          "description": "Hello, first time using Google Colab and huggingface datasets. Colab notebook is easy to setup but I can't seem to figure out how to download datasets from huggingface.\n I am trying to download https://huggingface.co/datasets/kili-technology/plastic_in_river dataset in Colab Notebook. After reading some beginners forums, I modified the example to look like one below but it failed.\n from datasets import load_dataset data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\", \"validation\": \"validation.csv\"} dataset = load_dataset(\"kili-technology/plastic_in_river\", data_files=data_files) \n Because there's no path to the files to be downloaded. Can someone explain how to download datasets from huggingface please?\n Downloading builder script: 100% 3.25k/3.25k [00:00<00:00, 228kB/s] Downloading metadata: 100% 2.79k/2.79k [00:00<00:00, 147kB/s] Downloading readme: 100% 496/496 [00:00<00:00, 34.2kB/s] --------------------------------------------------------------------------- FileNotFoundError Traceback (most recent call last) <ipython-input-5-98701edb7a4d> in <cell line: 4>() 2 3 data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\", \"validation\": \"validation.csv\"} ----> 4 dataset = load_dataset(\"kili-technology/plastic_in_river\", data_files=data_files) 5 frames /usr/local/lib/python3.10/dist-packages/datasets/data_files.py in resolve_pattern(pattern, base_path, allowed_extensions, download_config) 366 if allowed_extensions is not None: 367 error_msg += f\" with any supported extension {list(allowed_extensions)}\" --> 368 raise FileNotFoundError(error_msg) 369 return out 370 FileNotFoundError: Unable to find 'https://huggingface.co/datasets/kili-technology/plastic_in_river/resolve/main/train.csv' \n    submitted by    /u/0ni0nrings  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175qdu3/d_how_to_download_datasets_from_huggingface/",
          "publishedOn": "2023-10-11T22:06:28.000Z",
          "wordCount": 2711,
          "title": "[D] how to download datasets from huggingface",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ns6h/d_how_do_bytelevel_language_models_work/",
          "author": null,
          "description": "I've recently been trying to pre-train my own small language model on the tiny-series datasets on huggingface. I also wanted to use a model similar to MEGABYTE but I don't understand how using bytes would work. The only implementation I could find from lucidrains used str(chr(max(32, token))) to decode any token (byte) to a character and put the embedding size as 256. Firstly, why 256 and not 256-32 as any values below 32 are ignored? Also, many byte-level models including this and ByteT5 mention that they can process any text sequence even in a multilingual setting, however how would that be true if we are only using one byte, would we have to move to 2 bytes or use an UNK token, and if we did use 2 bytes that would make our embedding size around 65000 which defeats sort of the point as o…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ns6h/d_how_do_bytelevel_language_models_work/",
          "publishedOn": "2023-10-11T20:18:32.000Z",
          "wordCount": 2887,
          "title": "[D] How do byte-level language models work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175n78x/p_evaluating_and_tuning_a_model_when_the/",
          "author": null,
          "description": "Consider a predictive model that is predicting if an outcome Y will occur in Q1 2023, based on data from Q1 2022.\n Now, if want to predict outcomes for 2024, we must use last years data to build the model, but we are going to have some bias if there are features that vary year over year.\n Is the best approach in such a situation to try and tune/validate the model with other years in the hopes of mitigating any features that are correlated with a specific year? \n Any help would be much appreciated, as I can't find agreed upon methods.\n    submitted by    /u/unga123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175n78x/p_evaluating_and_tuning_a_model_when_the/",
          "publishedOn": "2023-10-11T19:54:48.000Z",
          "wordCount": 2655,
          "title": "[P] Evaluating and tuning a model when the population may change YoY and best practices for mitigating overfitting on features that correlate with time.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175lw8r/is_there_a_model_to_input_anecdotal_text_stories/",
          "author": null,
          "description": "I have a goal and am looking for direction from others who know more than me about machine learning. \n I want to submit 5-10 pieces of text to a model. The text will be anecdotes from a common experience but each one from a different person’s perspective. For example, if a family visits a theme park, each family member will have a story or two about the day. Each family’s story would be a submission to the model. One person might have loved the roller coaster and can tell about the exciting parts. Another person maybe just can’t stop talking about how great he food was. Someone else maybe felt sick and complains the line at the bathroom was too long. Perhaps another family member also rode the same roller coasters as the first person but instead hated it, so would have a very different description of it than the first. \n All these anecdotes are submitted to the model. \n Then, the model can be queried. Such as, \n “Tell me about the theme park.” \n or\n “I love roller coasters. Tell me about the theme park.” \n or\n “I tend to overeat, tell me about the theme park.” (the model wouldn’t hype of the food, maybe it would talk about how much exercise the visitors get by walking around all day.) \n In this case of a theme park context, the model would have a preconception of a theme park. It would know the general concept, know of several examples or standards that it could compare this theme park against, understand it’s all for fun, etc. \n This type of model may be available as an API or model already and I just don’t know about it. That’d be fine, please point me towards it. Or, maybe there’s something already available but would need tweaked or customized.\n    submitted by    /u/Semper_Disco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175lw8r/is_there_a_model_to_input_anecdotal_text_stories/",
          "publishedOn": "2023-10-11T18:59:24.000Z",
          "wordCount": 2851,
          "title": "Is there a model to input anecdotal text stories as training data to return a more comprehensive story? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175l9mz/d_help_me_learn_ml_easily_specially_in_model/",
          "author": null,
          "description": "Can you give easy to understand sources and hands-on practice methodology to master ML? Help me understand build the models in and out . Thank you\n    submitted by    /u/the_mystic_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175l9mz/d_help_me_learn_ml_easily_specially_in_model/",
          "publishedOn": "2023-10-11T18:32:02.000Z",
          "wordCount": 2568,
          "title": "[D] Help me learn ML easily specially in model building and EDA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175k7bl/nsf_workshop_on_llms_in_chemistry_education_r/",
          "author": null,
          "description": "Over Feb 12-13 of 2024, the National Science Foundation (NSF) is sponsoring a workshop titled “Integrating LLMs into the Materials Chemistry Curriculum” in Golden, Colorado. We aim to explore and develop innovative ways to incorporate large language models (LLMs, e.g. GPT, ChatGPT, and Bard) into upper division chemistry laboratories and virtual lab experiences. During the workshop, participants will brainstorm and create demonstrations incorporating LLMs into the curriculum.\n The event will bring together folks across academia and the private sector with disciplinary backgrounds that range across chemistry, computer science, materials science, physics, and education. There is no registration fee, and we anticipate being able to cover the majority of participant travel costs thanks to NSF support. Participants early in their career (i.e., graduate students, postdoctoral scholars) are particularly encouraged to apply.\n If you are interested in participating in this workshop, please fill out the Google form (link below).\n Please feel free to distribute this invitation widely.\n Application: https://forms.gle/P9QdNiCuaUAHFZj29\n    submitted by    /u/KC2792  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175k7bl/nsf_workshop_on_llms_in_chemistry_education_r/",
          "publishedOn": "2023-10-11T17:47:21.000Z",
          "wordCount": 2689,
          "title": "NSF workshop on LLMs in chemistry education [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ji6s/p_where_to_find_projects_to_contribute_to/",
          "author": null,
          "description": "Hello, I'm a developer with 6 years of experience in the mobile field, and I recently completed my master's degree in artificial intelligence (Text mining). I want to transition into the field of AI, but I need more experience with projects in the \"real world,\" outside of academia, and I'd like to contribute to an open-source project. I looked on Github, but I ended up feeling confused and not sure where to start.\n P.S.: I did some research in this subreddit, but the posts about contributions seemed a bit dated.\n    submitted by    /u/Substantial_Fact_205  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ji6s/p_where_to_find_projects_to_contribute_to/",
          "publishedOn": "2023-10-11T17:18:07.000Z",
          "wordCount": 2628,
          "title": "[P] Where to find projects to contribute to?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ie4l/p_image_based_python_opencv_automation_mmorpg/",
          "author": null,
          "description": "Video:\n https://youtu.be/0m12vkaoE7w\n ​\n Detailed Medium post will follow in the upcoming days.\n https://medium.com/@pssdplayer\n    submitted by    /u/HistorianCrafty3514  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ie4l/p_image_based_python_opencv_automation_mmorpg/",
          "publishedOn": "2023-10-11T16:32:54.000Z",
          "wordCount": 2554,
          "title": "[P] Image based Python + OpenCV automation, MMORPG Laghaim Auto-Fighter Bot Demo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175i3xg/d_i_have_2030_million_shopify_products_dataset/",
          "author": null,
          "description": "I have collected over 20 million shopify products & had the following ideas for them: \n - LLM ( Finetune an llm to know how to speak ecom )\n - Video bot that can make videos on those products, using their description, elevenlabs & AIFaceGen\n - EcomStore that will markup the products about 30% ( This will need the bot to frequently scrape, to ensure that the products are up to date ) \n - Selling the dataset based on fragments, like 1$ per 1k-10k records, depends on what sells. \n Please let me know if these are good ideas, and if someone would like to support / help me in any way ( I just need to selfhost my supabase instance, & add all the products to it & then dev can get started ) \n    submitted by    /u/AdonisCodes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175i3xg/d_i_have_2030_million_shopify_products_dataset/",
          "publishedOn": "2023-10-11T16:21:31.000Z",
          "wordCount": 2672,
          "title": "[D] - I have 20-30 million shopify products dataset, any ideas?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175hovg/d_best_opensource_ai_model_for_qa_generation_from/",
          "author": null,
          "description": "As the title says I’m looking for an open-source AI model for generating question-and-answers with a correct answer option and explanation to the correct answer from the input context. So far I have tried these models,\n  \nTheBloke/Llama-2-7B-GPTQ\n TheBloke/Llama-2-13B-GPTQ\n TheBloke/Llama-2-7b-Chat-GPTQ (the output is not consistent. Sometimes I get an empty response or without the correct answer option and an explanation data)\n TheBloke/Llama-2-13b-Chat-GPTQ (even 7b is better)\n TheBloke/Mistral-7B-Instruct-v0.1-GGUF(so far this is the only one that gives the output consistently. But not able to generate more than 2 QA due to max token limit of 512. Even tried setting the max token as 1024, 2048 but nothing helped)\n TheBloke/Mistral-7B-OpenOrca-GGUF\n NousResearch/Llama-2-7b-chat-hf\n  \nMy system configurations are: Windows 10 with 16GB GPU\n Additional Information: The input prompt token will be around 250-350 tokens per request.\n    submitted by    /u/gokulcv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175hovg/d_best_opensource_ai_model_for_qa_generation_from/",
          "publishedOn": "2023-10-11T16:04:17.000Z",
          "wordCount": 2663,
          "title": "[D] Best open-source AI model for QA generation from context",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175h9zh/churn_prediction_r/",
          "author": null,
          "description": "I want to build a model to predict churn in a third party logistics company. What variables should make up my data? Any help would do. Thanks\n    submitted by    /u/DisastrousAd8814  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175h9zh/churn_prediction_r/",
          "publishedOn": "2023-10-11T15:47:38.000Z",
          "wordCount": 2560,
          "title": "Churn Prediction [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175h4ob/d_recommendations_for_cpubased_realtime_vector/",
          "author": null,
          "description": "Hello everyone, I have a specific online vectorization use case: I'm looking to search the internet for articles, vectorize these articles along with the search queries, and then retrieve the most relevant passages from them. Currently, I have basic hosting through DigitalOcean. \n Could anyone recommend the most suitable vector dataset for this task? Additionally, considering my resources, is it feasible to run this system solely on CPUs? And if so, would this setup be scalable if deployed on CPUs only?\n    submitted by    /u/Traditional-Poet2746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175h4ob/d_recommendations_for_cpubased_realtime_vector/",
          "publishedOn": "2023-10-11T15:41:43.000Z",
          "wordCount": 2620,
          "title": "[D] Recommendations for CPU-Based Real-Time Vector Database Indexing and Matching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175g6rn/r_network_digital_twin_for_cybersecurity/",
          "author": null,
          "description": "Hi all,\n for a text work of mine I am trying to do a project based on generating digital twin of networks. My goal is to create a digital twin of a network and then work on it from a cyber security point of view. I will briefly explain what I would like to do.\n I am currently using software for network vulnerability scans (OpenVAS). I use this software to perform network vulnerability scans at the network level, so basically to OpenVAS I pass a network (for example 192.168.xx.xx/24) to automatically identify all the vulnerabilities that are there.\n The next step ( what I'd like to do and that's why I'm asking for your advice) is to create a digital twin of the newly scanned network and then perform a penetration test on this digital twin of the network, without going to stress the actual network.\n Ideally, I would like to pass the output of the OpenVAS vulnerability scans, routing rules, and firewall rules to some tool that will then generate for me the digital twin of the network, which will then be used for offensive cybersecurity, so exploits, privilege escalation, etc.... will be tested on this digital twin without worrying about breaking some kind of service or stressing the real network.\n What I am asking is, do you know of any tool that would do the trick for me? So some tool that allows me to generate a digital twin of a network by providing as input vulnerability scans (xml,json,csv etc...), routing rules, firewall rules, pcap traces etc... \n Do you have any references or documentation? \n Are you aware of any open source tools?\n I thank you for your helpfulness!\n ​\n    submitted by    /u/Salt-Arugula-8128  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175g6rn/r_network_digital_twin_for_cybersecurity/",
          "publishedOn": "2023-10-11T15:04:28.000Z",
          "wordCount": 2816,
          "title": "[R] network digital twin for cybersecurity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175fobx/best_approach_for_vfx_lineups_using_ml_project/",
          "author": null,
          "description": "Quick intro\n Lineups are one of the first steps in the VFX pipeline\n Source:\n - orignal footage that was shot on set\n - a reference (quicktime) video from the film edit.\n Task:\n The reference shows modifications to the original footage. They can be :\n - timewarp (either fixed retimes like 200% speed or completely random)\n - transform (moved the image in x/y axis, rotation, scale, etc.)\n So the lineup task is to align the original footage to the reference quicktime.\n What I did so Far:\n Made a simple script in the software Nuke, using some Python and readily available tools to make it work on a simple shot. General logic is compare every frame and the associated one is the frame with the least difference between the two. This works on super simple and straightforward tasks. (can provide more info if needed).\n Issue:\n Some references are more heavily modified. They can have some muzzle flash, basic 3d objects or even some slight error introduced like a distortion applied to the image when none shouldn't so it will never be perfectly aligned. This makes the difference of the full frame higher for some frames, making the lineup wrong. (it will take the wrong frame that has no muzzle flash, because it has less difference...)Some other things to consider is that watermarks are covering the ref and the colors are not perfectly matching, can get them close enough, but there's a difference.\n Conclusion:\n Because of those issues, I'm thinking about using Machine Learning. I have next to no knowledge on the subject. I know there Is a bunch of ways to train a model, but no clue where to start, so here's my question :\n Which learning styles has the best potential to be able to solve this task?\n    submitted by    /u/Pretty_Customer_8113  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175fobx/best_approach_for_vfx_lineups_using_ml_project/",
          "publishedOn": "2023-10-11T14:43:28.000Z",
          "wordCount": 2827,
          "title": "Best approach for VFX lineups using ML [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ezse/r_what_are_some_interesting_research_topics_to/",
          "author": null,
          "description": "I will have to pick and start a research project next January for my final year. So wanted to start exploring now. \n I want to do something substantive and interesting enough to get published.\n    submitted by    /u/BadMeditator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ezse/r_what_are_some_interesting_research_topics_to/",
          "publishedOn": "2023-10-11T14:13:22.000Z",
          "wordCount": 2582,
          "title": "[R] What are some interesting research topics to study in the intersection of ML and signal processing currently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ep9x/r_mistral_7b/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ep9x/r_mistral_7b/",
          "publishedOn": "2023-10-11T14:00:25.000Z",
          "wordCount": 2544,
          "title": "[R] Mistral 7B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ep6x/r_tsinghua_university_inverting_transformers/",
          "author": null,
          "description": "Transformers are great at NLP and computer vision tasks, but I was surprised to learn they still lag behind simple linear models at time series forecasting.\n The issue is how most Transformer architectures treat each timestamp as a token and fuse all the variable data from that moment. This makes two big problems:\n  \nVariables recorded at slightly different times get blurred together, losing important timing info\n Each token can only see a single moment, no long-term dependencies\n  \nSo Transformers struggle to extract useful patterns and correlations from the data.\n Some researchers from Tsinghua University took a fresh look at this and realized the Transformer components themselves are solid, they just need to flip the architecture for time series data.\n Their \"Inverted Transformer\" (or iTransformer):\n  \nMakes each variable's full history into a token, instead of each timestamp\n Uses self-attention over variables to capture relationships\n Processes time dependencies per variable with feedforward layers\n  \nThis simple tweak gives all the benefits we want:\n  \nState-of-the-art forecasting accuracy, beating both linear models and standard Transformers\n Better generalization to unseen variables\n Increased interpretability\n Ability to leverage longer historical context\n  \nTLDR: Inverting Transformers to align with time series structure allows them to outperform alternatives in working with time series data.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ep6x/r_tsinghua_university_inverting_transformers/",
          "publishedOn": "2023-10-11T14:00:19.000Z",
          "wordCount": 2748,
          "title": "[R] Tsinghua University: Inverting Transformers Significantly Improves Time Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ct0u/r_how_to_train_multiple_models_on_multiple_gpus/",
          "author": null,
          "description": "Hi! The task is to train N TensorFlow/Keras models using [2, ... N] GPU's on K different datasets in parallel. It is for testing a custom pipeline, you create a pipeline, you run it on multiple different datasets and get an aggregated metric. For now I'm using a for loop but how do I do it in parallel e.g. on AWS? I googled, but surprisingly haven't found a lot of results. I looked at Apache AirFlow because I'm vaguely familiar with it but so far I couldn't get a definite answer on how it works with multiple GPU's. Second option I found is to use Ray library. Is it worth trying? What should I use to solve this task? Thanks.\n UPD. I'd also consider a PyTorch solution as a backup option.\n UPDUPD. Jesus, why Reddit removing newlines after edit? \n    submitted by    /u/Disastrous_Sky9468  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ct0u/r_how_to_train_multiple_models_on_multiple_gpus/",
          "publishedOn": "2023-10-11T12:26:23.000Z",
          "wordCount": 2677,
          "title": "[R] How to train multiple models on multiple GPU's simultaneously",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175cf8w/d_how_important_is_having_a_great_team_when_ml/",
          "author": null,
          "description": "My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.\n I am the “lead”/senior data scientist in an R&D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.\n I have developed the domain expertise and I have a PhD in an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.\n I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.\n    submitted by    /u/Diligent_Trust2569  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175cf8w/d_how_important_is_having_a_great_team_when_ml/",
          "publishedOn": "2023-10-11T12:06:14.000Z",
          "wordCount": 2761,
          "title": "[D] How important is having a great team when ML solutions are slow to be adopted ? When to move on?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175ccwv/d_p_r_what_to_do_when_your_model_isnt_testing_well/",
          "author": null,
          "description": "I have 200k observations overall. I split my data into training and test set. My target variable has low prevalence ~ 9% so I tried random oversampling, random undersampling and SMOTE. After I fit my models, I tested them on my training test and the results were awful. I mean I've never had a model with 50% roc-auc, but then again, I rarely developed ML models. I'm wondering what the next steps would be? I understand there could be some sort of overfitting. But what would you do next? Any references would be appreciated :)\n    submitted by    /u/Actual-Muscle-9846  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175ccwv/d_p_r_what_to_do_when_your_model_isnt_testing_well/",
          "publishedOn": "2023-10-11T12:02:42.000Z",
          "wordCount": 2637,
          "title": "[D] [P] [R] What to do when your model isn't testing well?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/175a8bs/d_fastest_lipsync_projects/",
          "author": null,
          "description": "Given an image, and an audio file (TTS generated), what is current fastest library that can output me a video of a talking image with the audio on it?\n I have made some research and I have seen Wav2Lip and SadTalker. Any better options? I am looking for processing speed and for the lesser hardware intensive solution for a side project.\n Thanks!\n    submitted by    /u/reddit2vid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/175a8bs/d_fastest_lipsync_projects/",
          "publishedOn": "2023-10-11T09:50:59.000Z",
          "wordCount": 2596,
          "title": "[D] Fastest lipsync projects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17552x9/p_loopquest_a_githublike_platform_to_host/",
          "author": null,
          "description": "Hello everyone! Here is my pet project, https://www.loopquest.ai/. I am trying to build a platform like Github to let people upload their simulation environments so people can train their AI agents by interacting with the environments created by others. Here is a 2-min demo, https://youtu.be/d53NFjkU7JA. It is not launched yet but would love to get some early feedbacks. \n Here is the corresponding Github repo https://github.com/LoopMind-AI/loopquest. For now, the package can log env-agent interaction data by adding one extra line of code. You can think of it similar to https://github.com/google-deepmind/envlogger but with much better backend and frontend support. \n Any feedbacks are appreciated :)\n    submitted by    /u/jxx123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17552x9/p_loopquest_a_githublike_platform_to_host/",
          "publishedOn": "2023-10-11T04:00:52.000Z",
          "wordCount": 2644,
          "title": "[P] LoopQuest, A Github-like platform to host simulation environments for AI training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17536bo/d_why_async_gradient_update_doesnt_get_popular_in/",
          "author": null,
          "description": "The pipedream-2bw paper and the Zero-offload paper both show that 1-step delayed asynchronous gradient update doesn’t affect the convergence (and perplexity) while improve the training efficiency (by fully utilize the bubbles in pipeline parallelism) at a large margin.\n However, both the Megatron-LM and the DeepSpeed don’t use pipedream-2bw scheduling. Could anyone share me some insights or ideas about why such an efficient scheduling scheme doesn’t get popular in the LLM pretraining community? Does it suffer convergence/accuracy issue in practice? Or are there any other concerns that blocking it become the default / most popular pipeline parallelism scheduling?\n (I posted the same question in hacknews as well: Why async gradient update doesn't get popular in LLM community? | Hacker News)\n I have tried to implement the pipedream-2bw scheduling scheme on Megatron-LM and do can reproduce the performance gain as well as loss convergence with GPT-2 345M using 8xV100 GPUs: https://github.com/sighingnow/Megatron-LM/blob/ht/dev-pipe/megatron/core/pipeline_parallel/schedules.py#L1421\n    submitted by    /u/sighingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17536bo/d_why_async_gradient_update_doesnt_get_popular_in/",
          "publishedOn": "2023-10-11T02:23:18.000Z",
          "wordCount": 2684,
          "title": "[D] Why async gradient update doesn’t get popular in LLM community?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1750uim/d_ide/",
          "author": null,
          "description": "What’s the best IDE to work with or is it on user needs that determines best fit or is their one top dog and dominator that can robustly if not better preform other IDE’s ?\n    submitted by    /u/External_Age_5855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1750uim/d_ide/",
          "publishedOn": "2023-10-11T00:31:01.000Z",
          "wordCount": 2568,
          "title": "[D] IDE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174zyyu/d_onchain_reputation_model/",
          "author": null,
          "description": "I am relatively new to machine learning, and I am thinking about building an on-chain reputation ML model.\n Here is how far I have gone in my ideation phase, can someone help with some suggestion on how I can approach this issue.\n  \nInput data could include on-chain activity like number of transactions, value transferred, smart contracts interacted with, tokens held, NFTs owned, etc.\n Additionally, data from off-chain sources could be incorporated like identity verification, credentials, ratings, reviews, social media profiles, etc.\n Supervised learning algorithms like regression or classification models could be used to predict a reputation score. The target variable would be some verified reputation rating.\n Models like linear regression, random forests, or neural networks could work. Choice depends on size of data and complexity needed.\n Model would need to be transparent and parameters verifiable on-chain for validity. So linear models or simple neural networks may be most practical initially.\n The model could be trained off-chain initially but ultimately parameters and logic stored on-chain. Predictions could also be verified on-chain.\n Careful feature selection is important so the model relies on signals that are resistant to manipulation and capture true reputation.\n The model would need continuous updates as new data comes in reflecting latest reputation. This would require clear on-chain governance.\n Issues like privacy, collusion resistance, and censorship resistance would need to be addressed through crypto mechanisms like zero-knowledge proofs.\n  \nP.S. This is a personal project I want to attempt to level up my ML skills.\n    submitted by    /u/AdParticular2891  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174zyyu/d_onchain_reputation_model/",
          "publishedOn": "2023-10-10T23:50:20.000Z",
          "wordCount": 2779,
          "title": "[D] On-Chain Reputation Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174yb4k/d_pivoting_jobs_to_ml/",
          "author": null,
          "description": "Hi everyone, I recently started a job as a Junior Data Engineer. I have learned a lot so far working with DBT, Snowflake, Looker, Jira workflow, and Git using SQL and Python.\n I plan to stay at this company for 2 years. My boss has assured me that if I work hard I will progress from a Junior to full Data Engineer. After 2-3 years as a DE, I want to level up and move towards Data Science/ ML roles.\n My questions are: What other skills should I learn to enable me to pivot into something ML related? Should I find a job as a Data Scientist first, then try for ML jobs?\n Just looking for some advice/suggestions. Thanks!\n    submitted by    /u/SydeFxs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174yb4k/d_pivoting_jobs_to_ml/",
          "publishedOn": "2023-10-10T22:36:18.000Z",
          "wordCount": 2655,
          "title": "[D] Pivoting jobs to ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174xkir/problem_solving_in_programming_d/",
          "author": null,
          "description": "Hello Redditors,\n I am a student who is currently studying Bachelor of Science in AI. I have a question regarding improving my coding skills. I am aiming for a research internship and I don't know where to start. I previously took a summer school that taught me a lot about state-of-the-art models such as GANs, Transformers, VAEs, GNNs, etc. I would like to improve my coding skills, specifically problem-solving and writing clean code. I have experience with deep learning in general and data analysis. I am looking for a research internship next summer. Where should I start?\n I plan to review some of the deep learning material in the Deep Learning Specialization before taking the GAN specialization. However, when it comes to coding, I want to think like a software engineer or a great programmer. What do you guys suggest for improving my coding or problem-solving skills? I'm feeling confused with multiple resources and I don't know where to begin.\n I’d really appreciate your help.\n    submitted by    /u/misplacedlion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174xkir/problem_solving_in_programming_d/",
          "publishedOn": "2023-10-10T22:04:54.000Z",
          "wordCount": null,
          "title": "Problem solving in programming [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174xc6c/random_forest_trained_on_insider_trades_d/",
          "author": null,
          "description": "Would be very appreciative if someone looked at these results and pointed out potential / actual flaws.\n Dataset basics: insider trade details, insider trades over the last month, insider trades over the last week, (…) stock return over the last month (…), 46 columns total. \n Labels… 0: <-5% return in two weeks 1: >-5% + <5% 2: >5%\n Dates predicted: reported date. Usually 2-3 days behind transaction.\n Also, not positive if results are significant in the first place so that would be a great call out as well.\n Colab notebook: https://colab.research.google.com/drive/1fO1hVsVMWN3TORNj4OQn5UbWQOeug4fi?usp=sharing\n    submitted by    /u/This_Cardiologist242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174xc6c/random_forest_trained_on_insider_trades_d/",
          "publishedOn": "2023-10-10T21:55:11.000Z",
          "wordCount": 2629,
          "title": "Random forest trained on insider trades [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174rdaq/r_almt_using_text_to_narrow_focus_in_multimodal/",
          "author": null,
          "description": "Multimodal sentiment analysis combines text, audio and video to understand human emotions. But extra inputs can add irrelevant or conflicting signals. So filtering matters.\n Researchers made a \"Adaptive Language-guided Multimodal Transformer\" (ALMT) that uses text to guide filtering of visual and audio data. This creates a \"hyper-modality\" with less noise that complements the text.\n They tested it on datasets like MOSI (YouTube reviews), MOSEI (YouTube clips) and CH-SIMS (Chinese videos). ALMT achieved improved accuracy:\n  \nMOSI: YouTube movie reviews with 2,199 samples. ALMT achieves state-of-the-art performance on various metrics including 6% higher 7-class accuracy.\n MOSEI: 22,856 YouTube clips covering sentiment-rich scenarios. ALMT improves multi-class accuracy by 3-5% over previous methods.\n CH-SIMS: Chinese dataset with over 2,000 video samples. ALMT surpasses prior work by 1.4% in binary accuracy.\n  \nAnalyses showed big drops in performance without the guided filtering, so this validates that it's the main innovation.\n Downsides are it needs lots of training data and has minor gains on sparse regression metrics. But overall the technique of filtering multimodal data under text guidance gives improvements.\n The concepts feel intuitive - use dominant signals to filter others and retain useful complements. My guess is it would transfer well to other multimodal tasks.\n TLDR: New way to filter multimodal data for sentiment analysis using text guidance improves performance. Shows the value in removing distracting signals. Sometimes less is more.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174rdaq/r_almt_using_text_to_narrow_focus_in_multimodal/",
          "publishedOn": "2023-10-10T17:49:39.000Z",
          "wordCount": 2775,
          "title": "[R] ALMT: Using text to narrow focus in multimodal sentiment analysis improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174r35r/has_anyone_evaluated_tiktoks_algorithm_for_their/",
          "author": null,
          "description": "As a disclaimer, I am not familiar with many Recsys benchmarks. \n So I know Tiktok published a white paper on their purported algorithm, Monolith, but it is unclear if that is what they use in their products or not. Given, recommender systems seem to be core to Bytedance's business, I imagine they wouldn't provide many details.\n Has anyone evaluated Monolith on their own products and seen an improvement? \n I think the app is impressive and am wondering how it has transferred to other use cases. \n ​\n    submitted by    /u/HybridRxN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174r35r/has_anyone_evaluated_tiktoks_algorithm_for_their/",
          "publishedOn": "2023-10-10T17:37:40.000Z",
          "wordCount": null,
          "title": "Has anyone evaluated Tiktok's algorithm for their recsys use case? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174qdqv/p_optimistix_nonlinear_optimisation_in_jaxequinox/",
          "author": null,
          "description": "Hi everyone! I wanted to advertise my new JAX optimisation library Optimistix!\n Optimistix has high-level APIs for minimisation, least-squares, root-finding, and fixed-point iteration and was written to take care of these kinds of subroutines in Diffrax.\n Here is the GitHub: https://github.com/patrick-kidger/optimistix\n The elevator pitch is Optimistix is really fast, especially to compile. It plays nicely with Optax for first-order gradient-based methods, and takes a lot of design inspiration from Equinox, representing the state of all the solvers as standard JAX PyTrees.\n For those familiar with classical nonlinear unconstrained optimisation, Optimistix does some pretty nifty new things. It introduces new abstractions for modular optimisers, allowing users to mix-and-match different optimisation techniques easily. For example, creating a BFGS optimiser with Levenberg-Marquardt style Tikhnov regularisation takes less than 10 lines of code in Optimistix.\n I'm using Optimistix as a tool for my own research, and continue to work on it as part of my PhD (supervised by Patrick Kidger.) I would love for some more people to try it, so let me know what you think!\n    submitted by    /u/packquickly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174qdqv/p_optimistix_nonlinear_optimisation_in_jaxequinox/",
          "publishedOn": "2023-10-10T17:08:25.000Z",
          "wordCount": 2710,
          "title": "[P] Optimistix, nonlinear optimisation in JAX+Equinox!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174odzs/d_document_layout_recreating_the_structure/",
          "author": null,
          "description": "Hello,\n Document layout analysis has been a great tool so far to extract the components of a document (title, paragraph, tables ...). I'm working on long text PDF which are mostly scanned documents.\n One of the process involved after document layout analysis, is to recreate the document structure: creating sections, sub section, sub sub sections and so on. As of today, this task is done by parsing the title and finding out any ordering information (numeric, alphabetical or roman notation):\n 1. Title A 1.1 Title B 2. Title C 2.a) Title D \n This technique works only if a document follows this constraint (numeration). I want to go one step further, where the algorithm could create the document structure with any title ordering information.\n I believe that relying only on parsing cannot do the trick. What could be the options? Given that the only features are: title's text and title's position (x,y) in the document. I was wondering if a model like a seq2seq could fit this problem, or should I stick with an engineering rule based approach.\n Thanks\n ​\n    submitted by    /u/mathrb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174odzs/d_document_layout_recreating_the_structure/",
          "publishedOn": "2023-10-10T15:44:15.000Z",
          "wordCount": 2716,
          "title": "[D] Document layout - recreating the structure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n4ve/r_is_there_an_enstablished_method_to_test_if/",
          "author": null,
          "description": "I am using ChatGPT and other LLMs for which the training data is unknown. I am using them to test a set of MC question from a medical test published after the models knowledge cutoff. However, I cannot be 100% sure the questions were not on the internet beforehand. \n Is there any established method or testsuit to try to understands weather a given instance has been seen at training time? All I can think is looking at memorization or at perplexity, but I was looking for a more out of the box methodology that people use. It seems to me that the problem is quite general. \n Thanks!\n Edit: I know LLMs do not just memorize things and learn pattern. However, there is research on trying to understand if a datapoints has been used in training or not. Eg there is research that tries to exploit the fact that seen text has normally lower perplexity than unseen text or other similar infornation. I was wonderibg what the state in this topic is and if something is normally used as a score to have some clues. I do not expect to be able to retrieve the exact same questions lol\n    submitted by    /u/ombelicoInfinito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n4ve/r_is_there_an_enstablished_method_to_test_if/",
          "publishedOn": "2023-10-10T14:50:46.000Z",
          "wordCount": 2747,
          "title": "[R] Is there an enstablished method to test if something has been memorized / seen by black-box LLMs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n1kt/d_extracting_multimodal_embeddings_image_text_to/",
          "author": null,
          "description": "I am looking for methods/frameworks to extract multi-modal embeddings from images and text for similarity search purposes. The problem setup is slightly different from how CLIP style methods are generally used ( where similarity between text and image embeddings obtained through the model are computed to assess how similar a caption is to an image). My intended application is similarity search, where I want to find entries of images and captions pair similar to a piece of the query image and caption encoded together.\n Some approaches I tried: I tried concatenating the textual and visual embeddings obtained from CLIP and ResNET with textual embeddings and using it with cosine similarity, but it had limited utility. My guess is that concatenating two modalities merely without any training would yield very little utility. The next direction could be to train a model to fuse the embeddings obtained, but my dataset size is really small (10 thousand total), so not sure if training a model would be helpful. \n Are there any approaches that can allow me to combine the multi-modal embeddings for similarity purposes, similar to how pre-trained ResNET or Inception can be used off-the-shelf for retrieving visually similar images? Any pointers/advice would be greatly appreciated. \n    submitted by    /u/No-Commission3556  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n1kt/d_extracting_multimodal_embeddings_image_text_to/",
          "publishedOn": "2023-10-10T14:46:49.000Z",
          "wordCount": 2748,
          "title": "[D] Extracting Multi-modal embeddings (Image + text) to be used for visual similarity purposes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174n0mv/pd_building_datasets/",
          "author": null,
          "description": "In my ML/AI journey up until now, most training and hands-on labs either use a pre-built dataset or have you build a pretty simple and flat dataset. I am now looking to stretch my exploration into some real-world use cases and find the data I want is way more complex.\n Researching online feels like the meme on learning to draw an owl.\n So I'm looking for some guidance on how to handle my data.\n The data is an array from a rest API that includes all alarms from an application as nested objects. So the data looks like this for a single event:\n data = { \"event_data\": [ { \"root_cause\": \"Root cause added after API calls\" \"alarms\": [ { \"alarm_id\": \"alarm_id\", \"alarm_name\": \"alarm_name\", \"alarm_type\": \"alarm_type\", \"alarm_description\": \"alarm_description\", \"alarm_details\": { pro1: val1, prop2: val2, etc... }, \"actual_alarm_value\": { any_random_key: \"any_random_value\", etc... }, } ], } ] } \n I need to build a dataset that includes many of these events with the ultimate goal of predicting future events. I plan to test this against various ML models and LLMs.\n Each event would be a single row, and I would flatten out each alarm so each nested property has its own column. Where I need clarification is how to handle the flatting of alarms. If I fully flatten them, it appears like I lose the context of the alarm's parent event. But if I only flatten them to the alarm level, I lose each property having its own row\n Also actual_alarm_value is very random, so my thinking is to use string encoding here.\n I know this is a lot of detail, and I appreciate any and all advice and help in learning how to do this.\n    submitted by    /u/that1guy15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174n0mv/pd_building_datasets/",
          "publishedOn": "2023-10-10T14:45:38.000Z",
          "wordCount": 2817,
          "title": "[P][D] Building Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174kryt/d_is_there_a_rest_api_for_text_embeddings/",
          "author": null,
          "description": "I'm aware there are commercial offerings like OpenAI and cohere with the embedding API. But what about for open source models like the ones from SentenceTransformers?\n I'm aware you can use the HuggingFace inference API, but it's probably not best for commercial use, in which case the Inference endpoints would be better, but it's quite pricey for a startup with no customers.\n I also know I could use some kind of serverless GPU / inference platform to create my own API.\n But is there just a straight-up REST API for getting text embeddings from a model via SentenceTransformers or other HuggingFace models?\n    submitted by    /u/TheSaasDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174kryt/d_is_there_a_rest_api_for_text_embeddings/",
          "publishedOn": "2023-10-10T13:08:48.000Z",
          "wordCount": 2642,
          "title": "[D] Is there a REST API for text embeddings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174jv0q/d_langauge_confusion/",
          "author": null,
          "description": "I am a Second Year Student\n I'm planning to start learning ML which obviously requires python. But at the same time I wanna start practicing DSA / competitive programming as well. I'm sorta in this dilemma of what to do.\n Since python is a must for ML I'm 100% doing it, but for DSA I am confused whether I should learn DSA in Python or C++. People say C++ is the best and ideally I should do that. But python suits my need more. Obviously I don't mind doing both languages together but it seems a bit redundant.\n P.S: I'm learning DS basics in college via C language so learning the basic concepts isn't an issue.\n What do you suggest?\n    submitted by    /u/No-Discipline-2354  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174jv0q/d_langauge_confusion/",
          "publishedOn": "2023-10-10T12:24:15.000Z",
          "wordCount": null,
          "title": "[D] Langauge Confusion.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174jkeb/project_i_created_a_tool_that_navigates_the/",
          "author": null,
          "description": "Hi! I created a universal data API that uses headless browsers and GPT to extract any data from the web in JSON format. I started this project because I needed some API to do data enrichment to get company data (headcount, investment rounds, etc.). Once I did the first version, I quickly realized that there can be many use cases for such a tool: data enrichment, web scraping, data validation, etc. \n You can get the early access to the API here: https://singleapi.co/ \n Thanks!\n    submitted by    /u/semanser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174jkeb/project_i_created_a_tool_that_navigates_the/",
          "publishedOn": "2023-10-10T12:08:58.000Z",
          "wordCount": 2628,
          "title": "[Project] I created a tool that navigates the Internet and scrapes data using GPT-4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174iz9n/applied_aiml_data_science_ms_in_germany_d/",
          "author": null,
          "description": "Hey folks, I graduated from a tier 2 college in India with an ECE degree and then started working as an ML engineer in a mid-size startup 2 years ago. (1 year of internship + 1 year of Full time employment at the same company). Now, I am looking to get a Master's Degree in AI/ML/DS in Germany starting Winter 2024. I am a person with interests in Industry skills(Applied AI/ML) rather than the research/academia part as I don't wish to pursue a PhD nor do I want to be stuck in a Math-deep subject that may not be relevant for me in the future. On account of this, I wanted to know which college/degree offers the best balance in-between theory and applied AI/ML/DS.\n Also, people have been telling me that exams are super tough and it is hard to successfully complete an AI/ML/Data Science MS degree in Germany, Is it true? It has been super discouraging for me to hear this and is affecting me mentally to go through the application process.\n PS. CS/Electrical Degrees with good electives for AI/ML/DS are also good enough for me (Just hoping the coursework/grading is not too harsh) Also, it would be great if someone could clarify if an Electronics and Communications student can apply for a CS degree in Germany.\n Sorry for asking too many questions, TIA. :)\n    submitted by    /u/TheDivineKnight01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174iz9n/applied_aiml_data_science_ms_in_germany_d/",
          "publishedOn": "2023-10-10T11:37:07.000Z",
          "wordCount": 2765,
          "title": "Applied AI/ML/ Data Science MS in Germany [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174hkcn/d_prompting_as_searching_through_a_space_of/",
          "author": null,
          "description": "Enlightening article from Francois Chollet about #LLMs and embeddings\n \"Prompt engineering is the process of searching through program space to find the program that empirically seems to perform best on your target task.\"\n ​\n https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering \n    submitted by    /u/alexisperrier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174hkcn/d_prompting_as_searching_through_a_space_of/",
          "publishedOn": "2023-10-10T10:09:17.000Z",
          "wordCount": 2575,
          "title": "[D] Prompting as searching through a space of vector programs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/174cwha/d_best_approach_to_verify_4_million_sentencenamed/",
          "author": null,
          "description": "I have a dataset of about 4 million pairs of sentence-named entity.\n Looks like this:\n Sentence: MarketWatch has reached out to Charles Schwab and GQG for comment. Corresponding NER Tags: [{'end': 6, 'entity': 'B-ORG', 'index': 1, 'score': '0.98322886', 'start': 0, 'word': 'Market'} {'end': 7, 'entity': 'I-ORG', 'index': 2, 'score': '0.969261', 'start': 6, 'word': '##W'} {'end': 11, 'entity': 'I-ORG', 'index': 3, 'score': '0.97644824', 'start': 7, 'word': '##atch'} {'end': 38, 'entity': 'B-PER', 'index': 8, 'score': '0.9927636', 'start': 31, 'word': 'Charles'} {'end': 41, 'entity': 'I-PER', 'index': 9, 'score': '0.99394774', 'start': 39, 'word': 'Sc'} {'end': 44, 'entity': 'I-PER', 'index': 10, 'score': '0.41437265', 'start': 41, 'word': '##hwa'} {'end': 45, 'entity': 'I-PER', 'index': 11, 'score': '0.46933985', 'start': 44, 'word': '##b'} {'end': 51, 'entity': 'B-ORG', 'index': 13, 'score': '0.9984176', 'start': 50, 'word': 'G'} {'end': 52, 'entity': 'I-ORG', 'index': 14, 'score': '0.99367344', 'start': 51, 'word': '##Q'} {'end': 53, 'entity': 'I-ORG', 'index': 15, 'score': '0.99617106', 'start': 52, 'word': '##G'}] \n What would be a good approach to verify the correctness of each item?\n    submitted by    /u/shardblaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/174cwha/d_best_approach_to_verify_4_million_sentencenamed/",
          "publishedOn": "2023-10-10T04:53:27.000Z",
          "wordCount": 2705,
          "title": "[D] Best approach to verify 4 million sentence-named entity pairs ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1746g81/r_language_agent_tree_search_unifies_reasoning/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.04406 \n Abstract:\n  \nWhile large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents. We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. What is crucial in this method is the use of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that moves beyond the limitations of existing techniques. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting. In particular, LATS achieves 94.4\\% for programming on HumanEval with GPT-4 and an average score of 75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness and generality of our method. \n  \nhttps://preview.redd.it/ail2c1kbh9tb1.jpg?width=857&format=pjpg&auto=webp&s=a89d1f4ce3c536eecda3f7ab6027f304286f6c81\n https://preview.redd.it/j8xzx1kbh9tb1.jpg?width=1655&format=pjpg&auto=webp&s=c791756af926c7d472313b212de765e74c2b75da\n https://preview.redd.it/t47ne1kbh9tb1.jpg?width=1362&format=pjpg&auto=webp&s=560e5dd82ad06fdb729ab8ea1434c98e5c1a2ed3\n https://preview.redd.it/r58es3kbh9tb1.jpg?width=1341&format=pjpg&auto=webp&s=d5681992547dd6248ade5729c545eb17e824b7ea\n https://preview.redd.it/7viy42kbh9tb1.jpg?width=1496&format=pjpg&auto=webp&s=6454cfe65b511b34771cd510f67775be4e01c636\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1746g81/r_language_agent_tree_search_unifies_reasoning/",
          "publishedOn": "2023-10-09T23:31:05.000Z",
          "wordCount": 2734,
          "title": "[R] Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models - University of Illinois 2023 - Achieves 94.4\\% for programming on HumanEval with GPT-4 and 86.9\\% with GPT-3.5 20\\% better than with reflexion!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1746614/r_looking_for_indepth_tutorials_and_papers_on_nn/",
          "author": null,
          "description": "I only started working with neural nets a year ago and i've been having trouble understanding how pruning actually works. If there's any resources you think might help please guide me to them. thanks!\n    submitted by    /u/Sidekiiick02  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1746614/r_looking_for_indepth_tutorials_and_papers_on_nn/",
          "publishedOn": "2023-10-09T23:18:44.000Z",
          "wordCount": 2575,
          "title": "[R] looking for in-depth tutorials and papers on NN pruning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1744w8p/d_feature_selection_for_multivariate_time_series/",
          "author": null,
          "description": "Say for a sample that you have 5 target variables and 30 exogenous variables. If you want to include no more than 10 exogenous variables to your time series forecast, because of overfitting issues and such, what feature selections would you apply? Could you use pca and vif for multivariate models or are there other approaches to consider?\n    submitted by    /u/AdWhole1559  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1744w8p/d_feature_selection_for_multivariate_time_series/",
          "publishedOn": "2023-10-09T22:23:49.000Z",
          "wordCount": 2597,
          "title": "[D] Feature selection for multivariate time series model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1740ycb/r_scalearn_simple_and_highly_parameterefficient/",
          "author": null,
          "description": "Title: ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale\n Paper: https://arxiv.org/abs/2310.01217\n Code: https://github.com/CPJKU/ScaLearn\n https://preview.redd.it/xvcz7obtc8tb1.jpg?width=2020&format=pjpg&auto=webp&s=26169fa234e4e714d424ce17a7f0fa2c513fc42c\n Abstract:\n  \nMulti-task learning (MTL) has shown considerable practical benefits, particularly when using pre-trained language models (PLMs). While this is commonly achieved by simultaneously learning n tasks under a joint optimization procedure, recent methods such as AdapterFusion structure the problem into two distinct stages: (i) task learning, where knowledge specific to a task is encapsulated within sets of parameters (e.g., adapters), and (ii) transfer, where this already learned knowledge is lev…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1740ycb/r_scalearn_simple_and_highly_parameterefficient/",
          "publishedOn": "2023-10-09T19:41:45.000Z",
          "wordCount": 2822,
          "title": "[R] ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173y66v/d_what_is_more_valuable_10k_cpus_or_1k_gpu_hours/",
          "author": null,
          "description": "Hello ML community!\n I recently built, incredibly simple to learn, cluster compute software. Users can (in <60 seconds) go from coding on their local laptop, to coding on thousands of computers in the cloud, with zero setup, and just one line of code.\n I have a fair amount of GCP credits and want to run a promotion to get additional users. It would be giving away compute. In your opinion what would be more valuable... 10k CPU hours or 1k GPU hours? If you have any other promotional ideas for python users specific those in the ML, Bioinformatics, and GIS spaces I'd love to hear them.\n All feedback is greatly appreciated. Also if you're interested in trying out the tool check it out here --> https://www.burla.dev/\n    submitted by    /u/Ok_Post_149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173y66v/d_what_is_more_valuable_10k_cpus_or_1k_gpu_hours/",
          "publishedOn": "2023-10-09T17:50:53.000Z",
          "wordCount": 2668,
          "title": "[D] What is more valuable 10k CPUs or 1k GPU hours?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173y1so/r_transformers_kv_caching_explained/",
          "author": null,
          "description": "https://medium.com/@joaolages/kv-caching-explained-276520203249\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173y1so/r_transformers_kv_caching_explained/",
          "publishedOn": "2023-10-09T17:45:54.000Z",
          "wordCount": 2537,
          "title": "[R] Transformers KV Caching Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173xp39/d_llms_in_gec_problem/",
          "author": null,
          "description": "Up to now, which LLMs model, encoder-decoder model is best for the problem of grammatical error correction on uncommon language datasets (small dataset size) or languages ​​with specific characteristics (about punctuation? ,...)\n    submitted by    /u/con-nguoi-ki-cac  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173xp39/d_llms_in_gec_problem/",
          "publishedOn": "2023-10-09T17:31:35.000Z",
          "wordCount": 2568,
          "title": "[D] LLMs in GEC problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173wzr9/d_learning_natural_events_ai_art_generation/",
          "author": null,
          "description": "Hello!\n 1 I'd like to know if I could train AI to recognize details found it nature / weathering / aging and feed it pictures and it would recognize them (segmenting) so it can spot them but also their positions based on surrounding shapes, and the logical placement resulting. Seems hard.\n 2 then feed it some examples of those aging stuff on their own (with proper tags) so it learn to reproduce them and create new ones from scratch.\n 3 but then feed it \"clean\" pics and it would age them according to patterns it could find on the base training set so it can guess where to best place them.\n Pretty sure 2 is trivial enough, 1 seems possible until learning the \"logic\", but 3?\n Thanks for your insight.\n 1 comment \n    submitted by    /u/ConfusionSame9623  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173wzr9/d_learning_natural_events_ai_art_generation/",
          "publishedOn": "2023-10-09T17:03:12.000Z",
          "wordCount": 2671,
          "title": "[D] Learning natural events / AI art generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173vy9t/r_why_do_we_need_weight_decay_in_modern_deep/",
          "author": null,
          "description": "Title: Why Do We Need Weight Decay in Modern Deep Learning?\n Paper: https://arxiv.org/abs/2310.04415\n Abstract: Weight decay is a broadly used technique for training state-of-the-art deep networks, including large language models. Despite its widespread usage, its role remains poorly understood. In this work, we highlight that the role of weight decay in modern deep learning is different from its regularization effect studied in classical learning theory. For overparameterized deep networks, we show how weight decay modifies the optimization dynamics enhancing the ever-present implicit regularization of SGD via the loss stabilization mechanism. In contrast, for underparameterized large language models trained with nearly online SGD, we describe how weight decay balances the bias-variance tradeoff in stochastic optimization leading to lower training loss. Moreover, we show that weight decay also prevents sudden loss divergences for bfloat16 mixed-precision training which is a crucial tool for LLM training. Overall, we present a unifying perspective from ResNets on vision tasks to LLMs: weight decay is never useful as an explicit regularizer but instead changes the training dynamics in a desirable way. Our code is available at this https URL.\n    submitted by    /u/m_andriushchenko  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173vy9t/r_why_do_we_need_weight_decay_in_modern_deep/",
          "publishedOn": "2023-10-09T16:20:51.000Z",
          "wordCount": 2725,
          "title": "[R] Why do we need weight decay in modern deep learning? 🤔",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173vy4u/d_anyone_tried_training_language_models_on_simple/",
          "author": null,
          "description": "Seems the way people train language models today feels like sending a preschooler to a college library and telling him to start browsing books.\n Anyone know of papers describing language models being trained more like a child?\n Perhaps starting with preschool books with a tiny vocabulary and short sentence fragments like \"goodnight moon...\", moving up to \"the lorax\".... and then fine-tuning on elementary school books ... then jr high level reading ... then high school .... etc.\n I'm guessing this might be a path to more natural human-feeling speech.\n Anyone here tried this, or anyone here know of papers talking about it?\n    submitted by    /u/Appropriate_Ant_4629  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173vy4u/d_anyone_tried_training_language_models_on_simple/",
          "publishedOn": "2023-10-09T16:20:43.000Z",
          "wordCount": 2652,
          "title": "[D] Anyone tried training language models on simple (elementary school) text first and fine-tuning on progressively more advanced text?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ucih/d_where_do_yall_get_training_data/",
          "author": null,
          "description": "Hi there,\n Can I ask everyone here, where do you get your custom training data from?\n My team is training classifier models from scratch, so need thousands of specific query/response examples to train on.\n It's not the kinda data you could randomly scrape or source from a library.\n Are there any platforms that exist where you can pay a bunch of humans to write high volumes of relatively high quality text based training data?\n    submitted by    /u/paritsky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ucih/d_where_do_yall_get_training_data/",
          "publishedOn": "2023-10-09T15:15:23.000Z",
          "wordCount": 2612,
          "title": "[D] Where do y'all get training data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173t9mz/d_what_is_sota_for_continual_learning_on/",
          "author": null,
          "description": "If you have the dataset used to make the pretrained you could always create a new model with the old + new data, but this is often prohibitively expensive or impossible because the dataset is not available.\n Catastrophic forgetting seems to be the big issue, especially if you've already undergone instruction tuning since the model will lose its conversational tone. I've seen papers discussing regularization techniques to avoid that by minimizing the changes to high value attention heads but not sure if that is considered to be the most promising direction.\n I'm aware of LoRAs but I imagine at some point you can't just arbitrarily cram new info into such a low dimensional space.\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173t9mz/d_what_is_sota_for_continual_learning_on/",
          "publishedOn": "2023-10-09T14:30:40.000Z",
          "wordCount": 2658,
          "title": "[D] - What is SOTA for Continual Learning on pretrained LLMs, particularly those that have already undergone instruction tuning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173t2is/r_thought_propagation_an_analogical_approach_to/",
          "author": null,
          "description": "LLMs are great at basic reasoning when prompted, but still struggle with complex multi-step problems like optimization or planning. Humans tackle new problems by drawing on intuition from similar experiences, which LLMs can't do.\n Researchers propose \"Thought Propagation\" to have LLMs reason more like humans - by thinking analogically. First, GPT is prompted to suggest related \"analogous\" problems to the input. Then it solves those. Finally, it aggregates the solutions to directly solve the input problem or extract useful strategies.\n They tested this technique on challenges like finding optimal graph paths, writing coherent stories, and planning for LLM agents. Across different models, it significantly boosted performance over regular prompting:\n  \n12% better at finding shortest paths\n 13% improvement in creative writing (human preference)\n 15% higher task completion for LLM agents\n  \nIt also beat chain-of-thought (there is a comparison to CoT and ToT in the paper).\n After 1-2 iterations, adding more layers of analogy didn't help much. Efficiently generating useful analogies is still difficult and that's a limitation.\n I think this is interesting because it shows the value of \"meta-cognition\" - having models reflect on their own reasoning. More techniques like this could incrementally improve LLMs' reasoning to be more human-like.\n TLDR: Teaching LLMs to reason analogically, using solutions for similar problems as hints, significantly boosts their complex reasoning ability.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173t2is/r_thought_propagation_an_analogical_approach_to/",
          "publishedOn": "2023-10-09T14:22:25.000Z",
          "wordCount": 2759,
          "title": "[R] Thought Propagation: An analogical approach to complex reasoning with LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173scf2/d_how_to_deal_with_the_inconsistency_of_eyeball/",
          "author": null,
          "description": "I tried a few open-source GAN-based face swapping models. Some of the models have issues of the inconsistency of eyeball location (or eye direction) between the original and face-swapped ones. Any suggestions? Thanks.\n    submitted by    /u/Curious_Dragonfly_13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173scf2/d_how_to_deal_with_the_inconsistency_of_eyeball/",
          "publishedOn": "2023-10-09T13:52:05.000Z",
          "wordCount": 2582,
          "title": "[D] How to deal with the inconsistency of eyeball location in the output of a GAN-based face-swapping model.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173pjho/d_i_need_to_perform_kmean_clustering_on_a_large/",
          "author": null,
          "description": "I have a class with around 96031740 96x64 images and need to select a sample of 17929 to match the minority class of my classification problem. \n Having already established a baseline based on random sampling of the majority class; now I am looking to try more complex approaches. I am specifically trying to replicate the 'nearest neighbor of clustering center' approach from Lin et al., 2017.\n The problem is I am working on my desktop and only have 32 Gb of RAM and 2 1Tb NVMe disks at half capacity. I have tried working with only 10% of the data and still the MiniBatchKMeans function of sklearn doesnt have enough space to run: \"numpy.core._exceptions._ArrayMemoryError: Unable to allocate 440. GiB for an array with shape (9603174, 6144) and data type float64\". \n Does anyone have a suggestion on how I can move forward? Could cloud services be an option? \n Thanks\n References:\n Lin, W. C., Tsai, C. F., Hu, Y. H., & Jhang, J. S. (2017). Clustering-based undersampling in class-imbalanced data. Information Sciences, 409–410, 17–26. https://doi.org/10.1016/j.ins.2017.05.008\n    submitted by    /u/RafaeldeCampos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173pjho/d_i_need_to_perform_kmean_clustering_on_a_large/",
          "publishedOn": "2023-10-09T11:34:35.000Z",
          "wordCount": 2721,
          "title": "[D] I need to perform k-mean clustering on a large image dataset to downsample the majority class.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173oi03/d_what_are_the_best_network_analysis_tools_like/",
          "author": null,
          "description": "Almost everyone I know uses tensorboard to analyze their network outputs. Some people swear on Weights & Biases instead.\n Are there any other tools that help you with your work?\n    submitted by    /u/Smart-Emu5581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173oi03/d_what_are_the_best_network_analysis_tools_like/",
          "publishedOn": "2023-10-09T10:30:03.000Z",
          "wordCount": 2571,
          "title": "[D] What are the best network analysis tools, like tensorboard?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173nvhs/d_training_strategy_considering_the_possibility/",
          "author": null,
          "description": "During the training of overparameterized neural networks, when I observed decreasing training loss and increasing or non-decreasing validation loss, how should I decide if I should stop training and start a new experiment (with stronger regularization) or keep training to wait for 'grokking' or 'double descent' to happen? \n Are there any papers giving methods or some metrics to detect 'grokking' or 'double descent' in the early stage of training？\n    submitted by    /u/alayaMatrix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173nvhs/d_training_strategy_considering_the_possibility/",
          "publishedOn": "2023-10-09T09:48:43.000Z",
          "wordCount": 2611,
          "title": "[D] Training strategy considering the possibility of 'double descent' or 'grokking'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ioa5/r_legged_robots_performing_extreme_parkour_using/",
          "author": null,
          "description": "submitted by    /u/pathak22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ioa5/r_legged_robots_performing_extreme_parkour_using/",
          "publishedOn": "2023-10-09T04:04:46.000Z",
          "wordCount": 2547,
          "title": "[R] Legged Robots performing Extreme Parkour using Deep Reinforcement Learning just from a Front Camera (link in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173ef1i/d_i_need_guidance_related_to_using_machine/",
          "author": null,
          "description": "I am working on an a web app where people will be able to upload photos and write text. I don't want to have problems with my government or other countries governments in regards with the content that is uploaded to my website. I have searched about measures that can be taken to avoid this from happening. Adding a report button and having moderators are both good starting options.\n I thought that as time passes, more and more content is going to be created by the users so supervising that people are following the rules needs to be automated from the beginning. Applying measures to prevent people from uploading/posting links containing nudity, child porn, beastiality, or whatever users capture with a camera that could lead to legal problems must be a priority and allowing this type of content is not ethical.\n I am a software developer, but I haven't delved into machine learning and ai for most of my career because I haven't to. This seems like the perfect case to learn by doing and time is not a constraint, but I need some guidance.\n I have read superficially about how people train models by providing lots of data, I imagine other websites that use machine learning & ai to remove this type of content don't download media that contains nudity, child pornography, besteality, etc to train their models and make their tests. There must be some pretrained models, maybe, but how would they test this works? I don't know, I am just thinking on my own how other devs are currently handling this.\n I am no looking for upvotes, I don't care for downvotes, I am just looking for guidance, and I would be very happy to hear the opinion of someone with experience.\n    submitted by    /u/Comitatense  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173ef1i/d_i_need_guidance_related_to_using_machine/",
          "publishedOn": "2023-10-09T00:25:21.000Z",
          "wordCount": 2851,
          "title": "[D] I need guidance related to using machine learning & ai to prevent uploads or remove certain type of content from a web app.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173dwe7/r_identifying_the_risks_of_lm_agents_with_an/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.15817 \n Github: https://github.com/ryoungj/toolemu \n Website: https://toolemu.com/ \n Abstract:\n  \nRecent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks - such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, manually setting up the environment for each test scenario, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tailed risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables the testing of LM agents against a diverse range of tools and scenarios, without manual instantiation. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 68.8% of failures identified with ToolEmu would be valid real-world agent failures. Using our curated initial benchmark consisting of 36 high-stakes tools and 144 test cases, we provide a quantitative risk analysis of current LM agents and identify numerous failures with potentially severe outcomes. Notably, even the safest LM agent exhibits such failures 23.9% of the time according to our evaluator, underscoring the need to develop safer LM agents for real-world deployment. \n  \nhttps://preview.redd.it/lupenzddh2tb1.jpg?width=1368&format=pjpg&auto=webp&s=eaac22f0e3e4f5c2913aa9f2696e8fa0138967d9\n https://preview.redd.it/1dq443edh2tb1.jpg?width=1520&format=pjpg&auto=webp&s=2119053825de1cdabeafe61151940c26190abfa0\n https://preview.redd.it/m9e933edh2tb1.jpg?width=1528&format=pjpg&auto=webp&s=28c0093e8479feacb1e6f89bcb73de5994e30e8f\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173dwe7/r_identifying_the_risks_of_lm_agents_with_an/",
          "publishedOn": "2023-10-08T23:59:49.000Z",
          "wordCount": 2781,
          "title": "[R] Identifying the Risks of LM Agents with an LM-Emulated Sandbox - University of Toronto 2023 - Benchmark consisting of 36 high-stakes tools and 144 test cases!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173c1vh/r_pbllm_partially_binarized_large_language_models/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.00034 \n Github: https://github.com/hahnyuan/PB-LLM \n Abstract:\n  \nThis paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. Specifically, our exploration first uncovers the ineffectiveness of naive applications of existing binarization algorithms and highlights the imperative role of salient weights in achieving low-bit quantization. Thus, PB-LLM filters a small ratio of salient weights during binarization, allocating them to higher-bit storage, i.e., partially-binarization. PB-LLM is extended to recover the capacities of quantized LMMs, by analyzing from the perspective of post-training quantization (PTQ) and quantization aware training (QAT). Under PTQ, combining the concepts from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian matrix and successfully recover the reasoning capacity of PB-LLM in low-bit. Under QAT, we freeze the salient weights during training, explore the derivation of optimal scaling factors crucial for minimizing the quantization error, and propose a scaling mechanism based on this derived scaling strategy for residual binarized weights. Those explorations and the developed methodologies significantly contribute to rejuvenating the performance of low-bit quantized LLMs and present substantial advancements in the field of network binarization for LLMs. \n  \nhttps://preview.redd.it/0eywtpal22tb1.jpg?width=1183&format=pjpg&auto=webp&s=ad044123bec485805f98ae7115b1959162705b9d\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173c1vh/r_pbllm_partially_binarized_large_language_models/",
          "publishedOn": "2023-10-08T22:34:35.000Z",
          "wordCount": 2762,
          "title": "[R] PB-LLM: Partially Binarized Large Language Models - UC Berkeley 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173bs9h/help_choosing_courses_d/",
          "author": null,
          "description": "Hello, I am currently a math masters student, and I am planning to do my masters thesis on using neural networks to solve differential equations. I am taking courses in machine learning and differential equations right now, and I am going to take courses on deep neural networks and partial differential equations next semester. My question pertains to which classes would be more beneficial to learn next year (i.e. fall 2024-spring 2025). I am debating taking the sequence of regression analysis and multivariate analysis, or taking the pairing of numerical analysis for PDEs and perturbation methods. Which do you guys think would be more beneficial? Thank you very much!\n    submitted by    /u/purpledesertsky1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173bs9h/help_choosing_courses_d/",
          "publishedOn": "2023-10-08T22:22:56.000Z",
          "wordCount": 2644,
          "title": "Help choosing courses [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/173at26/r_pt_3_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/173at26/r_pt_3_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-10-08T21:42:02.000Z",
          "wordCount": 2537,
          "title": "[R] (Pt. 3) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1738pb4/d_multiscale_predictions_with_videos_does_this/",
          "author": null,
          "description": "I aim to develop a model that utilizes livestream data by employing embeddings for each frame from t0 to tn-1, with the objective of predicting frames from tn to tn+k, after encodoing the frames using a vectorizer and taking an average (np.mean ([], axis=0) to get a resultant for that time period.\n for example list:\n 1, [...] 2, [...] 3, [...] \n the resultant embedding would be [3, np.mean(list, axis=0)]\n I incorporate positional embeddings related to the timescale, such as duration from current time variables, into the array. would this loosely qualify as a \"multiscale attention\", since it's predicting on multiple scales of time?\n Are there any examples or applications where this methodology has been implemented? references to papers or repos greatly appreciated.\n    submitted by    /u/bluzkluz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1738pb4/d_multiscale_predictions_with_videos_does_this/",
          "publishedOn": "2023-10-08T20:13:30.000Z",
          "wordCount": null,
          "title": "[d] Multiscale predictions with videos- does this approach have a name? and has it been used?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17389hx/d_how_to_model_noisy_time_series/",
          "author": null,
          "description": "Is it possible to model time series data that fluctuates. The main solution is to take first differences and make it easier to fit conventional models. What if non-linear models are built? Can they solve a noisy time series (e.g stock market data) and make good predictions? Can adding a square term or a trigonometric term or something else non-linear work? Has some researched the topic? \n    submitted by    /u/Pineapple_throw_105  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17389hx/d_how_to_model_noisy_time_series/",
          "publishedOn": "2023-10-08T19:55:08.000Z",
          "wordCount": 2604,
          "title": "[D] How to model noisy time series?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1737xdb/newsmit_ai_conference_in_mountain_view_california/",
          "author": null,
          "description": "https://preview.redd.it/n6agjsye71tb1.png?width=2034&format=png&auto=webp&s=8c0a14524d9b6ead75ac0adb3cebeedb9e614e14\n Meet some of the Greatest Minds in AI and discover how it is being used to uncover new opportunities and transform industries.\n Register and see our complete speaker list & agenda at https://www.mitaiconference.org/.\n Registration ends Oct. 16!\n https://preview.redd.it/egtj0ufr81tb1.png?width=659&format=png&auto=webp&s=bfd0521a1e1b349129250a74fa2c6a10b1a83dc7\n ​\n    submitted by    /u/769498sy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1737xdb/newsmit_ai_conference_in_mountain_view_california/",
          "publishedOn": "2023-10-08T19:40:33.000Z",
          "wordCount": 2571,
          "title": "[News]MIT AI Conference in Mountain View, California, October 21!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1736h1a/r_computer_vision_system_for_material_detection/",
          "author": null,
          "description": "The goal of my research is to develop a YOLO model that can track all cups in a live feed and determine the material that the cups are made out of. I would like to start building a database of cups, but I am unsure of the way to go for this. My first thought was to just take 1000s of pictures of different cups, but I won't be doing that. Any thoughts and suggestions would be greatly appreciated. \n    submitted by    /u/Young_Neji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1736h1a/r_computer_vision_system_for_material_detection/",
          "publishedOn": "2023-10-08T18:40:03.000Z",
          "wordCount": 2617,
          "title": "[R] Computer Vision System for Material Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1735fks/r_ai_and_civil_engineering_probabilistic/",
          "author": null,
          "description": "Despite being much safer and more efficient than intersections, roundabouts are tricky to design - small tweaks can ruin traffic flow. \n They're typically designed iteratively, which takes time. This is a pain for developing countries without resources to test options. But AI could help auto-generate diverse and valid design options.\n In a new paper, researchers propose using Generative Flow Networks (GFlowNets) to sample varied roundabout layouts. Their approach works by constructing layouts step-by-step, maximizing rewards for realism, diversity, and safety.\n They also use a clever approximation during training. Rather than simulating traffic, they quickly check road intersections to focus the search (This sped up training by 200x).\n The authors tested their generated roundabout designs on simulated road scenarios of different complexity. Their model generated more diverse designs than rule-based or reinforcement learning approaches while maintaining realism and traffic flow.\n Plus, as road connections increased, the model kept discovering novel options without compromising quality.\n I thought this paper was an awesome proof-of-concept for auto-generating better roundabouts with AI, and I especially liked the authors' angle of leveraging this technology to specifically help developing countries. This could help them design higher-quality transportation networks faster and cheaper. (Plus I also like Cities: Skylines but struggle at building roundabouts).\n TLDR: Roundabouts are costly to design. New paper demonstrates how AI can generate diverse, valid roundabout designs quickly to cut costs and raise quality. Helpful for infrastructure in developing countries.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1735fks/r_ai_and_civil_engineering_probabilistic/",
          "publishedOn": "2023-10-08T17:56:58.000Z",
          "wordCount": 2787,
          "title": "[R] AI and Civil Engineering: Probabilistic Generative Modeling for Procedural Roundabout Generation for Developing Countries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1732o0l/p_makeagents_a_python_micro_framework_for/",
          "author": null,
          "description": "submitted by    /u/montebicyclelo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1732o0l/p_makeagents_a_python_micro_framework_for/",
          "publishedOn": "2023-10-08T15:58:41.000Z",
          "wordCount": null,
          "title": "[P] MakeAgents - A Python micro framework for creating LLM-powered agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17322bu/discussion_weekday_specific_feature_engineering/",
          "author": null,
          "description": "Focusing on Specific Day of Week Features With Binary Masks, One Hot Coding, Sin/Cos 2d Vector, Or Embedded Vector in Multivariate Time Series Data ?\n The essential challenge is trying to get the model to focus on making predictions for mondays by looking at monday (or actually making predictions for categorical earmarked hours of the day such as midday sales data).\n I keep getting the suggestion to include one hot encoding as a binary mask feature to determine if an hour sales figure is earmarked for the category or the day of the week I want the model to focus on-- in order to get it to ignore the data from the other six days of the week or the other periods of the day.\n In other words I want to hone in on and focus on one period of the week to predict for that period of the week, with extra attention, within time series data. Is this type of binary mask really sufficient for that, or am I overlooking something?\n    submitted by    /u/samdane7777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17322bu/discussion_weekday_specific_feature_engineering/",
          "publishedOn": "2023-10-08T15:32:28.000Z",
          "wordCount": 2705,
          "title": "[Discussion] Weekday Specific Feature Engineering in Time Series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1731tf3/d_rag_platform/",
          "author": null,
          "description": "I don’t have a large data science or even engineering team. But I’m interested in implementing RAG against my corpus in SharePoint. Are there platforms that I can configure without having to put them together or write code to implement RAG?\n    submitted by    /u/Silver_Patient_7253  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1731tf3/d_rag_platform/",
          "publishedOn": "2023-10-08T15:22:17.000Z",
          "wordCount": 2575,
          "title": "[D] RAG Platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1731pcg/r_why_is_adamw_often_superior_to_adam_with/",
          "author": null,
          "description": "A recent work explores how weight decay controls the effective learning rate for different layers and neurons. This rotational behavior drastically differs between Adam with L2 regularization compared to Adam with decoupled weight decay (AdamW) and seems to be the reason AdamW performs better in practice. It could also explain why normalization methods like weight standardization work so well and irregular rotational behavior could contribute to the need for a learning rate warmup.\n Full Abstract: Weight decay can significantly impact the optimization dynamics of deep neural networks. In certain situations, the effects of weight decay and gradient updates on the magnitude of a parameter vector cancel out on average, forming a state known as equilibrium. This causes the expected rotation of the vector in each update to remain constant along with its magnitude. Importantly, equilibrium can arise independently for the weight vectors of different layers and neurons. These equilibria are highly homogeneous for some optimizer and normalization configurations, effectively balancing the average rotation—a proxy for the effective learning rate—across network components. In this work we explore the equilibrium states of multiple optimizers including AdamW and SGD with momentum, providing insights into interactions between the learning rate, weight decay, initialization, normalization and learning rate schedule. We show how rotational equilibrium can be enforced throughout training, eliminating the chaotic transient phase corresponding to the transition towards equilibrium, thus simplifying the training dynamics. Finally, we show that rotational behavior may play a key role in the effectiveness of AdamW compared to Adam with L2-regularization, the performance of different normalization layers, and the need for learning rate warmup.\n    submitted by    /u/PlantsAreSoooAwesome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1731pcg/r_why_is_adamw_often_superior_to_adam_with/",
          "publishedOn": "2023-10-08T15:17:39.000Z",
          "wordCount": 2819,
          "title": "[R] Why is AdamW often superior to Adam with L2-Regularization in practice? The answer may lie in how weight decay balances updates across layers.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17318zf/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17318zf/d_simple_questions_thread/",
          "publishedOn": "2023-10-08T15:00:22.000Z",
          "wordCount": 2584,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1730i60/d_why_cant_models_trained_on_textimage/",
          "author": null,
          "description": "My main question is, that shouldn't models with Text-image interleaved data, be able to generate images as well as take them as input? because however they were tokenized, the bot would have image outputs as well, wouldn't it?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1730i60/d_why_cant_models_trained_on_textimage/",
          "publishedOn": "2023-10-08T14:29:08.000Z",
          "wordCount": 2585,
          "title": "[D] Why can't models trained on text-image interleaved data generate Images as well as read them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172w843/p_coding_stable_diffusion_from_scratch_in_pytorch/",
          "author": null,
          "description": "submitted by    /u/hkproj_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172w843/p_coding_stable_diffusion_from_scratch_in_pytorch/",
          "publishedOn": "2023-10-08T10:49:23.000Z",
          "wordCount": 2550,
          "title": "[P] Coding Stable Diffusion from scratch in PyTorch, with full explanation of the math behind diffusion models in a simple way!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172w3zu/d_optimize_rvc_training_parameters/",
          "author": null,
          "description": "I've been training a model recently with a rather large dataset (0_gt_wavs are 1h10) and my Epochs are taking 43min on average. I'm running a gtx 1080 and my usage is looking like this: https://i.imgur.com/EE9SUXp.png\n My training parameters:\n 'batch_size': 6, 'fp16_run': False, 'lr_decay': 0.999875, 'segment_size': 12800, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 40000, 'filter_length': 2048, 'hop_length': 400, 'win_length': 2048, 'n_mel_channels': 125, 'mel_fmin': 0.0, 'mel_fmax': None, 'training_files': './logs\\\\model1/filelist.txt'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [10, 10, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'use_spectral_norm': False, 'gin_channels': 256, 'spk_embed_dim': 109}, 'model_dir': './logs\\\\model1', 'experiment_dir': './logs\\\\model1', 'save_every_epoch': 10, 'name': 'model1', 'total_epoch': 500, 'pretrainG': 'pretrained_v2/f0G40k.pth', 'pretrainD': 'pretrained_v2/f0D40k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '40k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '0', 'if_cache_data_in_gpu': 0} \n Am I doing something obviously wrong? Is there a way to optimize my training parameters to reduce the epoch duration? I've previously trained something where the GPU usage was constantly at 100% and not fluctuating so much, but I can't remember which settings were different. It was definitely a smaller dataset.\n And follow up: if there are parameters to change, how can I abort the current training and continue it with the modified parameters?\n Thanks in advance!\n    submitted by    /u/induna_crewneck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172w3zu/d_optimize_rvc_training_parameters/",
          "publishedOn": "2023-10-08T10:42:30.000Z",
          "wordCount": null,
          "title": "[D] optimize RVC training parameters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172vppq/d_how_to_finetune_llm_for_text_generation_with/",
          "author": null,
          "description": "I have a text regression dataset with ad popularity. I have already trained a model to perform regression (popularity prediction) with good metrics. Now I want to use an LLM to \"improve\" texts, i.e. something like \"Make this text more engaging: {text}\".\n I tried out a few OpenAI models (GPT-3.5, GPT-3.5-instruct, GPT-4), but popularity predictions for augmented texts did not improve (checked with histograms, medians, and Wilcoxon test).\n So now I want to fine-tune an LLM to perform text generation, but guided with my predicted popularity, which basically works as a quality metric. I could not find any resources on this, only on either text generation finetuning (without guiding quality metric) or on classification (no text generation objective). I can also change my quality metric to binary (augmented text is better or not), if this matters.\n How can I do this? Any blogs / tutorials / papers are appreciated.\n    submitted by    /u/qalis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172vppq/d_how_to_finetune_llm_for_text_generation_with/",
          "publishedOn": "2023-10-08T10:17:22.000Z",
          "wordCount": 2692,
          "title": "[D] How to fine-tune LLM for text generation with regression quality metric?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172vllp/r_gaia1_a_generative_world_model_for_autonomous/",
          "author": null,
          "description": "submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172vllp/r_gaia1_a_generative_world_model_for_autonomous/",
          "publishedOn": "2023-10-08T10:10:39.000Z",
          "wordCount": 2551,
          "title": "[R] GAIA-1: A Generative World Model for Autonomous Driving",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172t5hc/r_pbllm_compressed_large_language_models_with/",
          "author": null,
          "description": "Research on network binarization techniques tailored for Large Language Models (LLMs). The team has introduced a method called Partial Binarization for LLMs (PB-LLM) which compresses the majority of model parameters down to just a single bit while maintaining its language reasoning capabilities. PB-LLM achieves this by selectively filtering critical weights and allocating more bits for storage, enabling low-bit quantization.\n The researchers have explored methods like Post-Training Quantization (PTQ), named GPTQ-PB, and Quantization Aware Training (QAT) to restore the inference capabilities of LLMs. \n For those interested in delving deeper, you can find the research paper on Arxiv: https://arxiv.org/abs/2310.00034 and the code implementation on GitHub: https://github.com/hahnyuan/PB-LLM.\n ​\n  Partially-Binarized LLM \n Result\n    submitted by    /u/hahnyuan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172t5hc/r_pbllm_compressed_large_language_models_with/",
          "publishedOn": "2023-10-08T07:33:56.000Z",
          "wordCount": 2647,
          "title": "[R] PB-LLM: Compressed Large Language Models with Partial Binarization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172pkkg/p_evaluating_retrievalaugmented_generation_rag/",
          "author": null,
          "description": "To help developers test their RAG systems, we added a RAG experiment class to our open-source library PromptTools. It allows users to easily experiment with different combinations of LLMs and vector DBs, and evaluate the results of their whole pipeline.\n In particular, you can experiment with:\n  \nChunking up your documents into different sizes\n Pre-processing those documents in various ways\n Inserting those documents into your vector DBs with various vectorizer and embedding function, and accessing them with different distance functions\n  \nIn our RAG example, we retrieve documents from ChromaDB and pass them into OpenAI’s chat model along with our prompt. We then pass the results into built-in evaluation functions, such as semantic similarity and autoeval, to quantitatively evaluate your result.\n PromptTools is agnostic to what LLMs and vector DBs you use. You can easily iterate over different system architectures forRAG. You can even bring your own fine-tuned models or write a custom integration. In addition, you can write your own evaluation metrics, and independently evaluate the results from the retrieval step as well.\n Our current integrations include:\n  \nLLM: OpenAI (chat, fine-tuned), Anthropic, Google Vertex/PaLM, Llama (local or via Replicate)\n Vector DB: Chroma, Weaviate, LanceDB, Pinecone, Qdrant\n Framework: LangChain, MindsDB\n  \nYou can get started with RAG in minutes by installing the library and running this example.\n As open-source maintainers, we’re always interested to hear the community’s pain points and requests. Let us know how you are testing your RAG systems and how we can help.\n    submitted by    /u/hegel-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172pkkg/p_evaluating_retrievalaugmented_generation_rag/",
          "publishedOn": "2023-10-08T03:57:41.000Z",
          "wordCount": 2789,
          "title": "[P] Evaluating Retrieval-Augmented Generation (RAG) with any combination of LLMs, Vector DBs, and Ingestion Strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172pauc/research_pixnav_bridging_zeroshot_object/",
          "author": null,
          "description": "Paper: https://arxiv.org/pdf/2309.10309\n Github: https://github.com/wzcai99/Pixel-Navigator\n Abstract: Zero-shot object navigation is a challenging task for home-assistance robots. This task emphasizes visual grounding, commonsense inference, and locomotion abilities, where the first two are inherent in foundation models. But for the locomotion part, most works still depend on map-based planning approaches. The gap between RGB space and map space makes it difficult to directly transfer the knowledge from foundation models to navigation tasks. In this work, we propose a Pixel-guided Navigation skill (PixNav), which bridges the gap between the foundation models and the embodied navigation task. It is straightforward for recent foundation models to indicate an object by pixels, and with pixels as the goal specification, our method becomes a versatile navigation policy towards all different kinds of objects. Besides, our PixNav is a pure RGB-based policy that can reduce the cost of home-assistance robots. Experiments demonstrate the robustness of the PixNav which achieves 80+% success rate in the local path-planning task. To perform long-horizon object navigation, we design an LLM-based planner to utilize the commonsense knowledge between objects and rooms to select the best waypoint. Evaluations across both photorealistic indoor simulators and real-world environments validate the effectiveness of our proposed navigation strategy.\n https://preview.redd.it/5qtd7ralgwsb1.png?width=828&format=png&auto=webp&s=118d5a1e8a083130b6d64bf1602af0417067aac8\n https://preview.redd.it/jwr2nnorgwsb1.png?width=1984&format=png&auto=webp&s=20062d7982c0eb1906fe0f6964d4b42e45b44a51\n https://preview.redd.it/llk4ubitgwsb1.png?width=1986&format=png&auto=webp&s=eb4894d52d7d8a82d97d83a2ff7a6be83da11af2\n    submitted by    /u/Character_Push3985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172pauc/research_pixnav_bridging_zeroshot_object/",
          "publishedOn": "2023-10-08T03:42:22.000Z",
          "wordCount": 2766,
          "title": "[Research] PixNav: Bridging Zero-Shot Object Navigation and Foundation Models through Pixel-Guided Navigation Skill - A pure RGB navigation framework that can be seamlessly integrated with the foundation models and perform efficient exploration in object navigation task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172iqur/d_how_do_i_get_a_fundamental_mathematical/",
          "author": null,
          "description": "Diffusion models, GAN, VAE, normalizing flows, etc. I \"understand\" those methods from an algorithmic perspective, diffusions gradually denoise an image, VAE use an encoder decoder architecture to turn an image into a latent distribution etc.\n But from a statistical modeling standpoint, I'm really struggling, when I read papers like DDPM, DDIM or Normalizing Flows, I kind of undestand the notation, but I barely understand the statistical modeling, and I wouldn't be able to produce such thing myself\n I want to understand this, which resources should I use ?\n Are books like Bishop and Murphy enough ? Which one is the best ?\n    submitted by    /u/Even_Information4853  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172iqur/d_how_do_i_get_a_fundamental_mathematical/",
          "publishedOn": "2023-10-07T22:25:25.000Z",
          "wordCount": 2647,
          "title": "[D] How do I get a fundamental mathematical understanding of modern generative modeling methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172gvb3/n_emnlp_2023_anonymity_hypocrisy/",
          "author": null,
          "description": "Some of you might already be aware that a junior who submitted their paper to arxiv 30 mins late had their paper desk rejected late in the process. One of the PCs, Juan Pino, spoke up about it and said it was unfortunate, but for fairness reasons they had to enforce the anonymity policy rules. https://x.com/juanmiguelpino/status/1698904035309519124\n Well, what you might not realize is that Longyue Wang, a senior area chair for AACL 23/24, also broke anonymity DURING THE REVIEW PROCESS. https://x.com/wangly0229/status/1692735595179897208\n I emailed the senior area chairs for the track that the paper was submitted to, but guess what? I just found out that the paper was still accepted to the main conference.\n So, whatever \"fairness\" they were talking about apparently only goes one way: towards punishing the lowly undergrad on their first EMNLP submission, while allowing established researchers from major industry labs to get away with even more egregious actions (actively promoting the work DURING REVIEW; the tweet has 10.6K views ffs).\n They should either accept the paper they desk rejected for violating the anonymity policy, or retract the paper they've accepted since it also broke the anonymity policy (in a way that I think is much more egregious). Otherwise, the notion of fairness they speak of is a joke.\n    submitted by    /u/emnlp2023_hypocrisy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172gvb3/n_emnlp_2023_anonymity_hypocrisy/",
          "publishedOn": "2023-10-07T21:05:24.000Z",
          "wordCount": 2747,
          "title": "[N] EMNLP 2023 Anonymity Hypocrisy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172fj9f/r_tora_a_toolintegrated_reasoning_agent_for/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17452v2 \n Github: https://github.com/microsoft/ToRA / The code will be cleaned and uploaded within a few days, all ToRA models will be released.\n Abstract:\n  \nLarge language models have made significant progress in various language tasks, yet they still struggle with complex mathematics. In this paper, we propose ToRA a series of Tool-integrated Reasoning Agents designed to solve challenging mathematical problems by seamlessly integrating natural language reasoning with the utilization of external tools (e.g., computation libraries and symbolic solvers), thereby amalgamating the analytical prowess of language and the computational efficiency of tools. To train ToRA, we curate interactive tool-use trajectories on mathematical datasets, apply imitation learn…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172fj9f/r_tora_a_toolintegrated_reasoning_agent_for/",
          "publishedOn": "2023-10-07T20:07:18.000Z",
          "wordCount": 2769,
          "title": "[R] ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving - Microsoft 2023 - Is competitive with GPT-4 solving problems with programs while being open-source!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172fhpz/r_video_object_removal_and_video_completion/",
          "author": null,
          "description": "​\n https://preview.redd.it/ukov8uy67usb1.png?width=1864&format=png&auto=webp&s=cb34448c2af90d08f8ef6db828d61141636498df\n https://shangchenzhou.com/projects/ProPainter/\n    submitted by    /u/Milkyson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172fhpz/r_video_object_removal_and_video_completion/",
          "publishedOn": "2023-10-07T20:05:29.000Z",
          "wordCount": 2545,
          "title": "[R] Video object removal and video completion - Propainter : Propagation and transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172dbor/p_a_poor_mans_vr_front_camera_tensorflowjs/",
          "author": null,
          "description": "Using the front camera and tensorflow.js, the smartphone becomes a “window” into the real world. Video and image content appear as if they were seen through this window. To do this, the viewer’s position is determined using a neural network. The viewed content is then moved according to the viewer’s position. This makes it seem like the content is physically behind the smartphone and is viewed through the smartphone’s screen. This effect is especially useful for content captured using an ultra-wide lens.\n    submitted by    /u/muxamilian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172dbor/p_a_poor_mans_vr_front_camera_tensorflowjs/",
          "publishedOn": "2023-10-07T18:31:06.000Z",
          "wordCount": 2629,
          "title": "[P] A poor man’s VR (front camera + tensorflow.js)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172cafd/p_building_a_gptdriven_chatbot_assistant_ai/",
          "author": null,
          "description": "submitted by    /u/sschepis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172cafd/p_building_a_gptdriven_chatbot_assistant_ai/",
          "publishedOn": "2023-10-07T17:48:57.000Z",
          "wordCount": 2547,
          "title": "[P] Building a GPT-Driven Chatbot Assistant / AI Interpreter with Node.js",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172bz3h/r_what_is_the_current_sota_for_image_to_image/",
          "author": null,
          "description": "I know a few years back it was pix2pix, but the world has moved on since then. Is there a transformer with cross attention that is adept at this, or are diffusion models the best bet?\n    submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172bz3h/r_what_is_the_current_sota_for_image_to_image/",
          "publishedOn": "2023-10-07T17:35:23.000Z",
          "wordCount": 2578,
          "title": "[R] What is the current SOTA for image to image translation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172becm/multivariate_time_series_forecasting_with_cnnlstm/",
          "author": null,
          "description": "I want to implement a multivariate multi-step CNN-LSTM model, to obtain forecasts for monthly sales of several different products. Furthermore, I want to include additional time-series data (features) as input. So for example:\n Input: time series of product 1, product 2, GDP, PMI\n Output: product 1 (monthly 6-steps ahead), product 2 (monthly 6-steps ahead)\n I have a couple of questions:\n  \nFeasibility: I've been researching this approach, but I haven't found many tutorials or guides on how to tackle multivariate time series forecasting with a CNN-LSTM architecture. I do find tutorials on CNN-LSTM, but not on how to include additional features as input. Has anyone here attempted something similar or can provide insights on how to proceed?\n Feature Selection: I have access to 20 different features, all of which are time series data. I want to choose the most relevant features for my model. I've considered performing a Variance Inflation Factor (VIF) analysis to select the best features. Does anyone have experience with this or other methods for feature selection in time series forecasting? How to decide the number of features to include? \n  \nAny advice or pointers in the right direction would be greatly appreciated!\n    submitted by    /u/Ambitious-Pay6329  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172becm/multivariate_time_series_forecasting_with_cnnlstm/",
          "publishedOn": "2023-10-07T17:11:22.000Z",
          "wordCount": 2734,
          "title": "Multivariate Time Series Forecasting with CNN-LSTM and features [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172anhw/easy_image_datasets_besides_mnist_p/",
          "author": null,
          "description": "Can anyone recommend some image classification datasets (besides MNIST) that are easy enough to the point that they can be solved with linear layers, not requiring any convolutional layers? Thanks!\n    submitted by    /u/mike20731  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172anhw/easy_image_datasets_besides_mnist_p/",
          "publishedOn": "2023-10-07T16:40:03.000Z",
          "wordCount": 2567,
          "title": "Easy Image Datasets Besides MNIST? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1729z0y/r_hugging_face/",
          "author": null,
          "description": "So if I wanted to generate a shirt or book cover with a design and text that's inputted by me what do I have to do? I know that even Mid Journey doesn't generate good text with its images but I was thinking maybe its bc it was trained just with pictures. Is there an easy way to get legible text and images every time with any model on the site? Do I need to train one? Do I need to train a GAN looking for assistance, thanks.\n    submitted by    /u/MonstaAndrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1729z0y/r_hugging_face/",
          "publishedOn": "2023-10-07T16:10:20.000Z",
          "wordCount": 2622,
          "title": "[R] Hugging Face",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1729fi5/d_how_can_i_findcreate_a_dataset_of_satellite/",
          "author": null,
          "description": "I'm a student currently researching the use of satellite imagery to detect obstacles on railways such as fallen trees and rockfalls. There doesn't seem to be any datasets available containing satellite imagery of these obstacles.\n I'm considering the use of generative AI to create a synthetic dataset, but I don't know where to start.\n Has anyone tried something similar?\n    submitted by    /u/Just_Status_9380  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1729fi5/d_how_can_i_findcreate_a_dataset_of_satellite/",
          "publishedOn": "2023-10-07T15:46:09.000Z",
          "wordCount": 2600,
          "title": "[D] How can I find/create a dataset of satellite imagery?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1728s4w/d_need_clarification_on_training_diffusion_model/",
          "author": null,
          "description": "Hey i have trained a diffusion model for 100 epochs , 8 hours and i got the following train and val loss mostly the implementation is done using diffusers. then i try reconstruction on the test set to check whether the model learned any thing this is whats happening most if the images are not getting denoised at all why this is happening? is this common or should i need to train more. any suggestions? please help\n val loss\n train loss\n input and reconstructed images\n    submitted by    /u/specializedboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1728s4w/d_need_clarification_on_training_diffusion_model/",
          "publishedOn": "2023-10-07T15:16:49.000Z",
          "wordCount": 2623,
          "title": "[D] Need clarification on training diffusion model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/172502d/d_tuning_on_xml_data/",
          "author": null,
          "description": "Hello experts, I'm a dumb ML enthusiast,\n I'm asking for your high level thoughts and opinions.\n So I'm doing my research and trying to find a way to train a LLM model to know all the right answers based on XML data. The data is a shop inventory, containing information on shoe models, sizes, is it in stock, description, image links etc.\n How would you approach it? For now the best option i came up with is parsing data, transforming it into predefined set of questions with answers based on the data derived from xml. Doesn't seem smart enough to me.\n    submitted by    /u/yarikbratashchuk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/172502d/d_tuning_on_xml_data/",
          "publishedOn": "2023-10-07T12:16:32.000Z",
          "wordCount": 2635,
          "title": "[D] Tuning on XML data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1723s59/d_when_using_gpts_function_calling_are_the_words/",
          "author": null,
          "description": "Example: ``` student_custom_functions = [ { 'name': 'extract_student_info', 'description': 'Get the student information from the body of the input text', 'parameters': { 'type': 'object', 'properties': { 'name': { 'type': 'string', 'description': 'Name of the person' }, 'major': { 'type': 'string', 'description': 'Major subject.' }, 'school': { 'type': 'string', 'description': 'The university name.' }, 'grades': { 'type': 'integer', 'description': 'GPA of the student.' }, 'club': { 'type': 'string', 'description': 'School club for extracurricular activities. ' }\n  } } } \n ] ```\n ``` student_description = [student_1_description,student_2_description] for sample in student_description: response = openai.ChatCompletion.create( model = 'gpt-3.5-turbo', messages = [{'role': 'user', 'content': sample}], functions = student_custom_functions, function_call = 'auto' )\n # Loading the response as a JSON object json_response = json.loads(response['choices'][0]['message']['function_call']['arguments']) print(json_response) \n ```\n Are the words specified in the properties parameter under functions in the above GPT function calling counted as input tokens?\n    submitted by    /u/redd-dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1723s59/d_when_using_gpts_function_calling_are_the_words/",
          "publishedOn": "2023-10-07T11:08:00.000Z",
          "wordCount": 2686,
          "title": "[D] When using GPT’s function calling, are the words specified in the `properties` parameter under `functions` counted as input tokens?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1723fn3/d_schmidhuber_summarized_in_one_picture/",
          "author": null,
          "description": "submitted by    /u/fromnighttilldawn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1723fn3/d_schmidhuber_summarized_in_one_picture/",
          "publishedOn": "2023-10-07T10:47:10.000Z",
          "wordCount": 2546,
          "title": "[D] Schmidhuber summarized in one picture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171zot4/r_the_alberta_plan_for_ai_research/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171zot4/r_the_alberta_plan_for_ai_research/",
          "publishedOn": "2023-10-07T06:52:04.000Z",
          "wordCount": 2549,
          "title": "[R] The Alberta Plan for AI Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171s8ef/r_arxiv_endorsement/",
          "author": null,
          "description": "Hello, all.\n I've spent the better part of the last two years learning ML and conquering severe ADHD, and I believe I finally have results that are worth publishing.\n Problem is, Arxiv requires endorsements and, I'll be honest, all my peers are AI at this point.\n They said their requirements were that you have three papers published already. Thanks, and looking forward to meeting people 😁\n    submitted by    /u/lilyerickson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171s8ef/r_arxiv_endorsement/",
          "publishedOn": "2023-10-07T00:14:59.000Z",
          "wordCount": 2600,
          "title": "[R] Arxiv Endorsement?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171qfiu/d_what_exactly_does_base_multimodal_mean/",
          "author": null,
          "description": "I here a lot of people say that models like flamingo and Idefics aren't really multimodal, that they just use clip models to give text captions to the transformer, that there not \"base multimodal\" what exactly does it mean? Is there a way to directly tokenize images to transformers? Are there major architectural changes, if so, how would they differ from GPT-2?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171qfiu/d_what_exactly_does_base_multimodal_mean/",
          "publishedOn": "2023-10-06T22:56:29.000Z",
          "wordCount": null,
          "title": "[D] What exactly does base multimodal mean?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171lrmy/r_autoagents_a_framework_for_automatic_agent/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17288v1 \n Github: https://github.com/LinkSoul-AI/AutoAgents \n Abstract:\n  \nLarge language models (LLMs) have enabled remarkable advances in automated task-solving with multi-agent systems. However, most existing LLM-based multi-agent approaches rely on predefined agents to handle simple tasks, limiting the adaptability of multi-agent collaboration to different scenarios. Therefore, we introduce AutoAgents, an innovative framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks. Specifically, AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Multiple specialized agents collaborate with each other to efficiently accomplish tasks. Concurrently, an observer role is incorporated into the framework to reflect on the designated plans and agents' responses and improve upon them. Our experiments on various benchmarks demonstrate that AutoAgents generates more coherent and accurate solutions than the existing multi-agent methods. This underscores the significance of assigning different roles to different tasks and of team cooperation, offering new perspectives for tackling complex tasks. \n  \nhttps://preview.redd.it/2jmnr73kymsb1.jpg?width=1663&format=pjpg&auto=webp&s=08f53d5da3d12e685c5d4b24f27628d880a917c1\n https://preview.redd.it/jklyr73kymsb1.jpg?width=824&format=pjpg&auto=webp&s=6f69b2fc5ef4bda60553da0bb953bd3c07ad506b\n https://preview.redd.it/elatla3kymsb1.jpg?width=1029&format=pjpg&auto=webp&s=e7e508cedd17b4798c9f90bf1c089beff3042f4a\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171lrmy/r_autoagents_a_framework_for_automatic_agent/",
          "publishedOn": "2023-10-06T19:45:05.000Z",
          "wordCount": 2736,
          "title": "[R] AutoAgents: A Framework for Automatic Agent Generation - Peking University 2023 - Generates the for the task necessary amount of different Agents that are also able to use tools in their work!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171kwaq/project_lora_from_scratch/",
          "author": null,
          "description": "Hi there! I was interested in learning more about LoRA but I was having a hard time finding a good simple example of implementing LoRA, as most sources are training large models and use a combination of huggingface transformers and the loralib package the original LoRA authors wrote. As a result, I ended up writing a simple LoRA implementation from scratch in pytorch lightning, and I figured other people might find it helpful as a learning resource or springboard: https://github.com/sunildkumar/lora_from_scratch/tree/main\n    submitted by    /u/dragseon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171kwaq/project_lora_from_scratch/",
          "publishedOn": "2023-10-06T19:09:06.000Z",
          "wordCount": 2609,
          "title": "[Project] LoRA from Scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171kdxx/p_tutorial_benchmarking_bark_texttospeech_on_26/",
          "author": null,
          "description": "In this project, we benchmarked Bark text-to-speech across 26 different consumer GPUs. \n The goal: To get Bark to read 144K food recipes from Food.com's recipe dataset. \n You can read the full tutorial here: https://blog.salad.com/bark-benchmark-text-to-speech/\n Included: Architecture diagram, data preparation, inference server setup, queue worker, setting up container group & compiling the results\n Code-blocks included in the tutorial. \n Words per dollar for each GPU:\n https://preview.redd.it/6daqluu3omsb1.png?width=2000&format=png&auto=webp&s=bc4b74fe6ee80c2721ab324eb0d9a2d7c2f7ddb1\n Although the latest cards are indeed much faster than older cards at performing the inference, there’s really a sweet spot for cost-performance in the lower end 30xx series cards. \n Conclusions\n  \nAs is often the case, there’s a clear trade-off here between cost and performance. Higher end cards are faster, but their disproportionate cost makes them more expensive per word spoken.\n The model’s median speed is surprisingly similar across GPU types, even though the peak performance can be quite different.\n Salad has a lot of RTX 3060 GPUs available, based on their relatively low speed, yet huge number of inferences performed over the test.\n No matter what GPU you select, you should be prepared for significant variability in performance.\n Qualitative: While bark’s speech is often impressively natural sounding, it does have a tendency to go off script sometimes.\n  \nWe’ve also made available audio from 1000 top-rated recipes, paired with the script it was trying to read.\n    submitted by    /u/SaladChefs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171kdxx/p_tutorial_benchmarking_bark_texttospeech_on_26/",
          "publishedOn": "2023-10-06T18:48:38.000Z",
          "wordCount": 2763,
          "title": "[P] Tutorial: Benchmarking Bark text-to-speech on 26 consumer GPUs - Reading out 144K recipes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171igzx/r_brown_university_paper_lowresource_languages/",
          "author": null,
          "description": "Researchers from Brown University presented a new study supporting that translating unsafe prompts into `low-resource languages` allows them to easily bypass safety measures in LLMs.\n By converting English inputs like \"how to steal without getting caught\" into Zulu and feeding to GPT-4, harmful responses slipped through 80% of the time. English prompts were blocked over 99% of the time, for comparison.\n The study benchmarked attacks across 12 diverse languages and categories:\n  \nHigh-resource: English, Chinese, Arabic, Hindi\n Mid-resource: Ukrainian, Bengali, Thai, Hebrew\n Low-resource: Zulu, Scots Gaelic, Hmong, Guarani\n  \nThe low-resource languages showed serious vulnerability to generating harmful responses, with combined attack success rates of around 79%. Mid-resource language success rates were much lower at 22%, while high-resource languages showed minimal vulnerability at around 11% success.\n Attacks worked as well as state-of-the-art techniques without needing adversarial prompts.\n These languages are used by 1.2 billion speakers today and allows easy exploitation by translating prompts. The English-centric focus misses vulnerabilities in other languages.\n TLDR: Bypassing safety in AI chatbots is easy by translating prompts to low-resource languages (like Zulu, Scots Gaelic, Hmong, and Guarani). Shows gaps in multilingual safety training.\n Full summary Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171igzx/r_brown_university_paper_lowresource_languages/",
          "publishedOn": "2023-10-06T17:32:00.000Z",
          "wordCount": 2737,
          "title": "[R] Brown University Paper: Low-Resource Languages (Zulu, Scots Gaelic, Hmong, Guarani) Can Easily Jailbreak LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171iel8/d_textbook_prerequisites/",
          "author": null,
          "description": "What are the prerequisites to read the book: \"probabilistic machine learning an introduction\" by Kevin P. Murphy?\n    submitted by    /u/OneAdhesiveness2585  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171iel8/d_textbook_prerequisites/",
          "publishedOn": "2023-10-06T17:29:29.000Z",
          "wordCount": null,
          "title": "[D] Textbook prerequisites",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171hona/r_moving_object_based_collisionfree_video_synopsis/",
          "author": null,
          "description": "Webpage : Moving Object Based Collision-Free Video Synopsis (IEEE SMC 2018) (anton-jeran.github.io) \n Paper : Moving Object Based Collision-Free Video Synopsis | IEEE Conference Publication | IEEE Xplore \n Presentation : [IEEE SMC 2018] Moving Object Based Collision-Free Video Synopsis - YouTube \n    submitted by    /u/Snoo63916  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171hona/r_moving_object_based_collisionfree_video_synopsis/",
          "publishedOn": "2023-10-06T17:01:19.000Z",
          "wordCount": 2578,
          "title": "[R] Moving Object Based Collision-Free Video Synopsis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171h0bc/p_musicgen_streaming/",
          "author": null,
          "description": "Faster MusicGen Generation with Streaming\n There's no need to wait for MusicGen to generate the full audio before you can start listening to the outputs ⏰ With streaming, you can play the audio as soon as the first chunk is ready 🎵 In practice, this reduces the latency to just 5s ⚡️\n Check-out the demo: https://huggingface.co/spaces/sanchit-gandhi/musicgen-streaming\n How Does it Work?\n MusicGen is an auto-regressive transformer-based model, meaning generates audio codes (tokens) in a causal fashion. At each decoding step, the model generates a new set of audio codes, conditional on the text input and all previous audio codes. From the frame rate of the EnCodec model used to decode the generated codes to audio waveform, each set of generated audio codes corresponds to 0.02 seconds. This me…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171h0bc/p_musicgen_streaming/",
          "publishedOn": "2023-10-06T16:35:12.000Z",
          "wordCount": null,
          "title": "[P] MusicGen Streaming 🎵",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171gm3b/dr_simple_question_on_generating_a_confusion/",
          "author": null,
          "description": "i have to generate a confusion matrix for object detection through my own code. if i have predicted Bounding Box A (BB-A) which matches to Ground Truth A (GT-A), and I have another predicted Bounding Box B (BB-B) with a lower score than BB-A, does BB-B count as a true positive/match? or is it considered a false positive given that there has already been a matched BB to GT-A? \n i.e., with matching bounding boxes for generating a confusion matrix, is it a one-to-one matching? or is it more like match one GT to as many predictions?\n    submitted by    /u/Alarmed-Broccoli2536  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171gm3b/dr_simple_question_on_generating_a_confusion/",
          "publishedOn": "2023-10-06T16:19:28.000Z",
          "wordCount": null,
          "title": "[D]/{R] simple question on generating a confusion matrix for object detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171dnug/p_im_using_instruct_gpt_to_show_anticlickbait/",
          "author": null,
          "description": "submitted by    /u/Wise-Astronaut-4047  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171dnug/p_im_using_instruct_gpt_to_show_anticlickbait/",
          "publishedOn": "2023-10-06T14:24:26.000Z",
          "wordCount": 2541,
          "title": "[P] I'm using Instruct GPT to show anti-clickbait summaries on youtube videos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171d234/d_feature_extraction_for_sets_ie_data_of_varying/",
          "author": null,
          "description": "Are there classical feature extraction methods that work on sets i.e. data of variable size?\n I'd like to start with a feature matrix X_in of shape N x f and have some feature mixing to arive at X_out N x h (N=size of set, f=input feature size, h=output feature size). Here, N can vary. \n For clarity, one set(containing N vectors of size f) is one sample. A dataset consists of many samples(each one being a set of varying size).\n Then I'd run this through a classical ML model.\n So, essentially, I'm looking for something like DeepSets or Transformers - can handle data of varying size and is permutation equivariant, but I don't wanna train for long.\n ​\n https://fabianfuchsml.github.io/learningonsets/\n    submitted by    /u/Mundane_Pay1506  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171d234/d_feature_extraction_for_sets_ie_data_of_varying/",
          "publishedOn": "2023-10-06T14:00:01.000Z",
          "wordCount": null,
          "title": "[D] Feature extraction for sets i.e. data of varying size",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/171alt3/d_how_is_neural_odes_as_a_field_of_study/",
          "author": null,
          "description": "Hi, I'm a 21yr old physics undergrad, and I have zero knowledge in neural networks / machine learning / so on. I have an opportunity to do a research project on neural ODEs, so I want to know more about the field: Is it an emerging field or is it mature and well-researched? What are my career outlooks if I take this project? Thank you.\n    submitted by    /u/moorelibqc17412  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/171alt3/d_how_is_neural_odes_as_a_field_of_study/",
          "publishedOn": "2023-10-06T12:07:14.000Z",
          "wordCount": 2606,
          "title": "[D] How is neural ODEs as a field of study?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/17181z7/d_nonconvex_functions_with_exactly_one_local/",
          "author": null,
          "description": "Rosenbrock function is non-convex, but has exactly one local minimum. Is there a specific name for such functions? Are there any theorems about them? Any special optimization algorithms?\n On the first glance, while being non-convex, they seem to be \"easier\" to optimize than functions that have multiple local minima, such as Rastrigin function.\n    submitted by    /u/Tomarchelone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/17181z7/d_nonconvex_functions_with_exactly_one_local/",
          "publishedOn": "2023-10-06T09:42:55.000Z",
          "wordCount": null,
          "title": "[D] Non-convex functions with exactly one local minimum",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1715kbd/p_talk_to_your_zendesk_tickets_with_weaviates/",
          "author": null,
          "description": "Hi folks,\n we played around sticking production pipelines and vector dbs together to enable \"talking to your data\". We created an example with Zendesk, but it would work with any custom python generator or existing connectors. \n Project: Talk to your Zendesk tickets with Weaviate’s Verba and dlt: A step by step guide\n If you are interested to try more ready made connectors, to for example talk with your github or asana data or something else.\n Who are we? dlt, the open source loading library: https://pypi.org/project/dlt/\n Like the demo? Give us a git star\n Want to discuss? join the dlt slack community\n    submitted by    /u/Thinker_Assignment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1715kbd/p_talk_to_your_zendesk_tickets_with_weaviates/",
          "publishedOn": "2023-10-06T06:56:02.000Z",
          "wordCount": 2642,
          "title": "[P] Talk to your Zendesk tickets with Weaviate’s Verba and dlt: A step by step guide",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1711hoa/d_emnlp_2023_decisions_thread/",
          "author": null,
          "description": "When can we expect to get the decisions? Any idea folks? What can be a good cutoff for main or findings?\n    submitted by    /u/Ok_Swan3875  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1711hoa/d_emnlp_2023_decisions_thread/",
          "publishedOn": "2023-10-06T03:01:51.000Z",
          "wordCount": null,
          "title": "[D] EMNLP 2023 decisions thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1711e8w/d_parallelizing_cheaper_gpusrtx_4090_vs_buying/",
          "author": null,
          "description": "Hi. I am a college student and I am trying to run deep learning models (hopefully LLMs one day) and my laptop keep crashing because of ram issue. So I am going to build a new desktop. I am thinking of buying 2 rtx 4090 and Parallelizing them instead of buying A100 because buying 2 rtx 4090 is half the cost of buying A100. But is there a downside of Parallelizing vs buying a single gpu with large vram? If I am willing to take longer to train a model, can i use 3 rtx 4090 instead of a100 80gb model??\n    submitted by    /u/ColumbiaGSAlum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1711e8w/d_parallelizing_cheaper_gpusrtx_4090_vs_buying/",
          "publishedOn": "2023-10-06T02:57:17.000Z",
          "wordCount": null,
          "title": "[D] Parallelizing cheaper GPUs(rtx 4090) vs buying A100",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1710ilb/d_whats_the_sota_model_in_time_series_long_term/",
          "author": null,
          "description": "I read https://arxiv.org/abs/2205.13504 which compare different transformer models. But now is 2023, I am not sure if any better models appear in this time series.\n ​\n https://preview.redd.it/o6sihjqjrhsb1.png?width=1076&format=png&auto=webp&s=3db7d50590270bac52e7115e1e9903a6785957d2\n    submitted by    /u/Trust_Ok  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1710ilb/d_whats_the_sota_model_in_time_series_long_term/",
          "publishedOn": "2023-10-06T02:14:52.000Z",
          "wordCount": null,
          "title": "[D] What's the SOTA model in Time Series Long term forecasting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170z9lm/r_agent_instructs_large_language_models_to_be/",
          "author": null,
          "description": "Nicholas Crispino, Kyle Montgomery, Fankun Zeng, Dawn Song, Chenguang Wang\n Paper: https://arxiv.org/abs/2310.03710\n Abstract: We introduce a method to improve the zero-shot reasoning abilities of large language models on general language understanding tasks. Specifically, we build an autonomous agent to instruct the reasoning process of large language models. We show this approach further unleashes the zero-shot reasoning abilities of large language models to more tasks. We study the performance of our method on a wide set of datasets spanning generation, classification, and reasoning. We show that our method generalizes to most tasks and obtains state-of-the-art zero-shot performance on 20 of the 29 datasets that we evaluate. For instance, our method boosts the performance of state-of-the-art large language models by a large margin, including Vicuna-13b (13.3%), Llama-2-70b-chat (23.2%), and GPT-3.5 Turbo (17.0%). Compared to zero-shot chain of thought, our improvement in reasoning is striking, with an average increase of 10.5%. With our method, Llama-2-70b-chat outperforms zero-shot GPT-3.5 Turbo by 10.2%. The code will be available at https://github.com/wang-research-lab/agentinstruct.\n    submitted by    /u/ncrispino  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170z9lm/r_agent_instructs_large_language_models_to_be/",
          "publishedOn": "2023-10-06T01:15:59.000Z",
          "wordCount": 2707,
          "title": "[R] Agent Instructs Large Language Models to be General Zero-Shot Reasoners",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170yipf/d_how_to_compute_the_distance_between_two/",
          "author": null,
          "description": "Hey all,\n I am generating a set of extra MNIST digits for a research project, and I am interested in somehow computing the distance between the distribution these digits represent and the distribution that the MNIST train set, for example, represents. The issue is that it seems like typical methods (Jensen-Shannon, Wasserstein, etc.) collapse at high dimensions. Is there a consensus solid approach to do this nowadays? Thanks!\n    submitted by    /u/SignificantSundae793  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170yipf/d_how_to_compute_the_distance_between_two/",
          "publishedOn": "2023-10-06T00:40:50.000Z",
          "wordCount": 2609,
          "title": "[D] How to compute the distance between two high-dimensional distributions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170xha8/d_synthetic_dataset_searching_for_honest/",
          "author": null,
          "description": "I'm looking for resources, papers, or experiences that compare the performance of large language models (LLMs). I'm trying to find a honest benchmark to compare the capabilities of the latest large models, while really intrested un those: GPT-3.5 Instruct, GPT-4, Claude 2, Claude Instant 100k, Palm2-Bizon, jurassic-2, LLama2 70 and other state-of-the-art LLama2 fine tunes (possibly an Orca-style model). \n I'm interested in general benchmarks and, if they exist, comparisons of performance on synthetic data generation tasks (both generating data with the \"textbook are all you need\" approach used in Phi and some Orca/EvolveInstuct-style models like Wizard...).\n    submitted by    /u/Distinct-Target7503  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170xha8/d_synthetic_dataset_searching_for_honest/",
          "publishedOn": "2023-10-05T23:52:46.000Z",
          "wordCount": null,
          "title": "[D] - Synthetic dataset - Searching for honest comparison between LLM (gpt4, bizon, jurassic-2, Claude...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170wnbx/p_how_to_extract_and_count_artist_mentions_from/",
          "author": null,
          "description": "I have a long list of responses from a poll (in this case, we've asked our Facebook community we should have at our music festival). Our goal is to count the total mentions for each artist, but the data quality is low.\n Here is some sample data:\n Rena Guinn and the Gentlemen Blackwater Railroad Company Mo' Mojo Music !! We would love to be apart of this awesome event! Amazing!!!!! The Rollin' Rust came threw at the #falldownfest last weekend 🙂 much love:) keep it up boys 🙂 Luke Hess Langhorne Slim!!!!!, Sierra Hull, First Aid Kit, Jim Lauderdale (always) \n We feel the data quality is too poor for basic LDA approaches (lots of misspellings, odd phrasings) and we feel a LLM would be best at least extracting the names of artists using context.\n We have found that ChatGPT and Claude are decent at the extraction tasks on small samples but can't handle the full input, and are next to worthless on the counting task. We've tried very specific and differnet prompts, but haven't been able to get a good result.\n So how should I approach this problem? I'm not sure how to break this down in to prompts or substeps. I'm not sure how to do anything of this outside of a browser, and I'm a data science novice, but willing to learn some things.\n Here's an example of a prompt that's not returning correct counts (off by >50% in most cases)\n The following is raw text comments copied from a poll. Count the total number of mentions in the poll and create a table that contains columns Band (a unique list of bands) and a column containing the total number of mentions. The table should cover the top 100 bands by total mentions. Use judgement and context to conform band names in to unique values (Example: The Town Pants, Town Pants, townpants are all the same band). Count completely and accurately. Now here is the raw data: \n    submitted by    /u/strway2heaven77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170wnbx/p_how_to_extract_and_count_artist_mentions_from/",
          "publishedOn": "2023-10-05T23:16:47.000Z",
          "wordCount": 2874,
          "title": "[P] How to extract and count artist mentions from messy text data using LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170vs5a/p_avenues_for_publishing_ai_ethics_case_studies/",
          "author": null,
          "description": "I am a computer science graduate student. As part of my coursework, I am exploring the ethical issues of using Large Language Models for mental healthcare applications. I found four unique examples from the real world and outlined the ethical dilemma within them. I intend to analyze these dilemmas using various ethical frameworks in order to come up with solutions. While I am interested in getting a publication out of this work, I am unsure of the types of conferences/journals that accept case-study articles (specifically in AI ethics). Any advice from academicians over here would be greatly appreciated!\n    submitted by    /u/jwalapoet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170vs5a/p_avenues_for_publishing_ai_ethics_case_studies/",
          "publishedOn": "2023-10-05T22:40:58.000Z",
          "wordCount": 2637,
          "title": "[P] Avenues for publishing AI ethics case studies?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170uh8d/d_r_is_the_noise_predictor_in_ddpms_predicting/",
          "author": null,
          "description": "Hi fellow computer scientists,\n ​\n After reading the paper Improved Denoising Diffusion Probabilistic Models I got a little confused. Looking at section \"2.2. Training in Practice\" the authors say that:\n 1) \"The network could also predict the noise eps added to x_0, and this noise could be used to predict x0 via...\"\n ​\n 2) \"Ho et al. (2020) found that predicting eps worked best...\"\n ​\n So this left me wondering if the noise predictor is trying to compute (1) the epsilon that was added to x_0 through the close-form formula or (2) the noise added in the previous timestep to obtain x_t from x_{t-1} (i.e., eps_t or eps_{t-1}, idk...)?\n ​\n Thank you :)\n    submitted by    /u/Christs_Elite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170uh8d/d_r_is_the_noise_predictor_in_ddpms_predicting/",
          "publishedOn": "2023-10-05T21:49:36.000Z",
          "wordCount": 2659,
          "title": "[D] [R] Is the noise predictor in DDPMs predicting the noise added to x_0 or the noise added to x_{t-1}?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170tduq/p_mazegpt_transformer_based_maze_generator/",
          "author": null,
          "description": "Hello all,\n I recently did a summer research project implementing GPT-2 to generate mazes. \n The core concept of the model is to combine a bunch of popular maze generation algorithms into one. The goal was that the transformer will be able to identify key components using self-attention and piece together different algorithms. Most maze generation algorithms result in almost a finger print (like in chaos theory). The end goal was to mimic a higher degree of randomness / make the mazes appear less algorithmic.\n I'm dipping my toes into the realm of research and am looking for feedback. So far I've run the model for 5x5 mazes, it would be interesting to try training the model with varying dimensions. Feel free to join in and contribute to the project!\n https://github.com/noah-hein/mazeGPT\n 5x5 live generation\n https://i.redd.it/v6smbdd88gsb1.gif\n ​\n    submitted by    /u/noah-hein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170tduq/p_mazegpt_transformer_based_maze_generator/",
          "publishedOn": "2023-10-05T21:06:57.000Z",
          "wordCount": 2671,
          "title": "[P] MazeGPT - Transformer based maze generator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170s6f5/d_unable_to_improve_binary_classification_problem/",
          "author": null,
          "description": "I am currently working on a binary classification problem where I aim to predict whether a customer will make a purchase in the next 30 days based on their transaction history. I have a dataset of 1,000 transactions with the following features:\n  \nTransactionAmount\n (float): The amount of the transaction.\n ProductCategory\n (categorical): Category of the product purchased (e.g., Groceries, Electronics, Books).\n DateOfPurchase\n (datetime): The date on which the transaction occurred.\n  \nI've done some preprocessing and feature engineering, including normalization, one-hot encoding of categorical variables, creating interaction terms, and adding features like days since the first purchase and whether the purchase was made during the holiday season.Dataset is balanced and cleaned.\n I started with a base Random Forest classifier with default parameters as a starting point, but the performance is not satisfactory (accuracy = 48.5%, ROC-AUC = 0.485). I tried other models as well but was unable to improve the accuracy by more than 57%.\n    submitted by    /u/SnooTigers4634  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170s6f5/d_unable_to_improve_binary_classification_problem/",
          "publishedOn": "2023-10-05T20:18:55.000Z",
          "wordCount": null,
          "title": "[D] Unable to improve binary classification problem accuracy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170s4iu/d_emnlp_2023_results/",
          "author": null,
          "description": "Making a post for EMNLP 2023 results to come out today.\n    submitted by    /u/East-Beginning9987  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170s4iu/d_emnlp_2023_results/",
          "publishedOn": "2023-10-05T20:16:53.000Z",
          "wordCount": 2546,
          "title": "[D] EMNLP 2023 results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170rvz4/p_need_help_figuring_out_my_input_for_anomaly/",
          "author": null,
          "description": "I’ve been given a task to identify if a PCB is faulty or not based on its frequency response. I don’t have labeled data. The data I have are various gain values calculated over frequencies, so my data looks something similar to the table below.\n PCB | Frequency | G1 | G2\n PCB 1 | 1Hz | 0.1 | 1\n PCB 1 | 2Hz | 0.2 | 2\n PCB2 | 1Hz | 0.3 | 3\n PCB2 | 2Hz | 0.4| 4\n Each PCB has several G parameters measurements taken over the same set of frequencies. \n I need to use an auto encoder to identify outliers and I need help in deciding how my feature matrix should look like. \n For example, let us consider only one data point that is PCB 1, then would a matrix like this make sense?\n [[ 0.1 0.2 ] - 1st row is all G1 values\n [1 2]] - 2nd row is all G2 values\n Similarly the matrix for the other PCBs are also created. I have not included frequency in my feature set because these G parameters have been measured for the same set of frequencies for all PCBs. Is this correct ?\n Additionally, are there any resources someone can point me to related to finding anomalies in frequency response data ? I am struggling with using the keywords while googling.\n    submitted by    /u/Savage_Garbage  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170rvz4/p_need_help_figuring_out_my_input_for_anomaly/",
          "publishedOn": "2023-10-05T20:07:20.000Z",
          "wordCount": null,
          "title": "[P] Need help figuring out my input for anomaly detection in frequency responses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170rtxo/r_towards_monosemanticity_decomposing_language/",
          "author": null,
          "description": "Paper. I am not affiliated with this paper or its authors.\n Twitter thread (Nitter alternative for those who want to see the entire thread without being logged into Twitter).\n Related work: Sparse Autoencoders Find Highly Interpretable Features in Language Models.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170rtxo/r_towards_monosemanticity_decomposing_language/",
          "publishedOn": "2023-10-05T20:05:08.000Z",
          "wordCount": 2595,
          "title": "[R] Towards Monosemanticity: Decomposing Language Models With Dictionary Learning. From Anthropic. \"We demonstrate a method for decomposing groups of neurons into interpretable features [...]\".",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170roi4/r_meta_researchers_present_method_for_decoding/",
          "author": null,
          "description": "Researchers at Meta trained a deep learning model on brain recordings and audio data from 169 people listening to speech. Their method achieves up to 73% accuracy at identifying a 3-second clip of speech from non-invasive EEG or MEG scans.\n This is a massive improvement over previous attempts at decoding speech from neural signals. It approaches the performance of studies using implanted electrodes.\n The key innovations:\n  \nA contrastive loss function that aligns latent speech and brain representations\n Leveraging pretrained speech models like wav2vec 2.0\n Training one model on multiple subjects with individual tuning\n  \nBeing able to decode speech intention from brainwaves could one day help restore communication for patients suffering from strokes, ALS, etc.\n There's still a ways to go before this becomes a medical reality. Performance needs to improve and be validated during speech production rather than just passive listening. And the accuracy isn't high enough for natural conversations.\n But this is a hugely promising step toward brain-computer interfaces. Really interesting work at the intersection of neuroscience and AI!\n TLDR: New model achieves up to 73% accuracy decoding speech directly from non-invasive brain scans. Could eventually help patients with neurological conditions communicate just by thinking.\n Full summary here. Paper is here\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170roi4/r_meta_researchers_present_method_for_decoding/",
          "publishedOn": "2023-10-05T19:59:25.000Z",
          "wordCount": 2744,
          "title": "[R] Meta researchers present method for decoding speech from brain waves",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170psdc/d_emnlp_2023_notification/",
          "author": null,
          "description": "Discussion thread for EMNLP 2023 notifications which will be released in a few hours along with GEM workshop. Best of luck to everyone.\n    submitted by    /u/EDEN1998  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170psdc/d_emnlp_2023_notification/",
          "publishedOn": "2023-10-05T18:43:58.000Z",
          "wordCount": 2558,
          "title": "[D] EMNLP 2023 Notification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170nclx/d_ordinal_or_nominal_variable/",
          "author": null,
          "description": "Hey all, I am working with stock market data and scratching my head if certain variables are ordinal and can be left as is or if it is nominal and should be one-hot encoded. \n One of the variables in question consists of the direction of the market over a certain time. It has three categories: up, down, sideways. hope was to code them as 1, -1 and 0 respectively and treat as ordinal. There appears to be some order/relationship between them but not sure if it is enough.\n Is this the correct approach or should it be one-hot encoded?\n    submitted by    /u/Fishpo0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170nclx/d_ordinal_or_nominal_variable/",
          "publishedOn": "2023-10-05T17:07:18.000Z",
          "wordCount": 2635,
          "title": "[D] ordinal or nominal variable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170n9ex/d_deep_learning_online_course_using_pytorch/",
          "author": null,
          "description": "I've been out of the deep learning space for a while now and I'd like to take an online course, or set of courses, to get myself back up to speed on the latest techniques, architectures, and how to use them. I think the DeepLearning.ai specialization through Coursera is a good match, but I see that it uses Tensorflow. Is there any course like this that would use PyTorch? Or would the transition not be too hard once the fundamentals are in place? Thanks!\n    submitted by    /u/ComicFoil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170n9ex/d_deep_learning_online_course_using_pytorch/",
          "publishedOn": "2023-10-05T17:03:47.000Z",
          "wordCount": null,
          "title": "[D] Deep Learning online course using PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170mtzx/fine_tuning_or_rag_for_coding_d/",
          "author": null,
          "description": "Need some help what is the best way to start. Pls Advice !\n I have a specific code in my repos (lets say .net + JS). The goal is to have prompt based code adjustments to existing repos (like very focused copilot) . Either using single agent or using something like AutoGen. So let say I have thousands of files with code and some descriptions about code functionality (spec) . I want either to generate code based on next spec and I want newly generated code to be similar in style to what is in my repos. So now questions: Should I vectorize my code (What is best way to do that ?) or try to fine tune some model ? Give me your ideas / experience in code generation based on previous code.\n    submitted by    /u/mcwin1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170mtzx/fine_tuning_or_rag_for_coding_d/",
          "publishedOn": "2023-10-05T16:47:22.000Z",
          "wordCount": 2672,
          "title": "Fine Tuning or RAG for Coding [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170mh6t/project_i_built_an_opensource_scraping_api_that/",
          "author": null,
          "description": "I decided to open-source my own web scraping API that I'm using to get information from different websites without using any selectors or XPath. Just provide the URL and a desired JSON schema, and it will return extracted data. Hope this can be helpful for someone. Cheers!\n https://github.com/semanser/JsonGenius \n https://preview.redd.it/icq1i8slvesb1.png?width=4096&format=png&auto=webp&s=ac86ccdb3da5ef1ffa86e3473619162f6b652ac6\n    submitted by    /u/semanser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170mh6t/project_i_built_an_opensource_scraping_api_that/",
          "publishedOn": "2023-10-05T16:33:05.000Z",
          "wordCount": 2587,
          "title": "[Project] I built an open-source scraping API that returns structured JSON data using GPT.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170m0o7/r_is_selfcorrection_a_viable_method_to_improve/",
          "author": null,
          "description": "Can LLMs actually improve their own reasoning by self-correcting mistakes? A new paper from DeepMind and the University of Illinois looks to answer this quantitatively.\n The results show that unaided, LLMs struggle at self-correction for reasoning tasks. The core issue is LLMs have trouble reliably evaluating the correctness of their own responses. They rarely identify flaws in initial reasoning. Sometimes LLMs even alter initially correct responses to become incorrect after self-correction! (I've personally seen this when interacting with ChatGPT many times and you probably have too).\n More complex techniques like critiquing between LLM instances don't help much either. External feedback or guidance looks necessary to improve reasoning (Well, some interesting parallels to this paper here about implicit improvement from preference data vs traditional RLHF).\n Self-correction does show promise for things like making responses more polite or safe though. Criteria there are more clear-cut.\n The authors argue we need to balance enthusiasm with realistic expectations on self-correction. It has a lot of limits for improving reasoning (at least with current models). But they suggest promising directions like incorporating high-quality external feedback from humans, training data, and tools. That could be key to unlocking self-correction's potential down the road.\n TLDR: Basically title... LLMs can't reliably self-correct reasoning yet. Maybe hybrid techniques combining self-correction with external guidance could work but we need more research.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170m0o7/r_is_selfcorrection_a_viable_method_to_improve/",
          "publishedOn": "2023-10-05T16:15:11.000Z",
          "wordCount": 2769,
          "title": "[R] Is self-correction a viable method to improve LLM reasoning? Probably not.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170jkna/p_niddkcr_data_centric_challenge_enhancing_niddk/",
          "author": null,
          "description": "Calling all AI researchers! \n Using data aggregation, harmonization, fusion, and other data enhancement methods, you can help the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) enhance the utility of NIDDK datasets for AI applications. The goal of the NIDDK Data Centric Challenge will be to generate an “AI-ready” dataset that can be used for future data challenges, using data on Type 1 Diabetes available through the NIDDK Central Repository. Register today! https://www.challenge.gov/?challenge=niddk-central-repository-data-centric-challenge\n    submitted by    /u/DataCentricChallenge  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170jkna/p_niddkcr_data_centric_challenge_enhancing_niddk/",
          "publishedOn": "2023-10-05T14:34:53.000Z",
          "wordCount": null,
          "title": "[P] NIDDK-CR Data Centric Challenge: Enhancing NIDDK datasets for future artificial intelligence applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170jah3/d_offtopic_is_meta_llama_2_license_agreement_safe/",
          "author": null,
          "description": "in the Meta Llama 2 license agreement (that can be found here), there is a section of \"Prohibited Uses\" that clearly states several use cases that the signer must accept upon himself, but several of them state the word \"facilitate\", as far as i can understand, if we use Llama 2 as part of a commercial product, and some end-user will use the product in malicious way (say cause the chat-bot to write the recipe of mustard gas) then this could be considered that the creator of the product is facilitating the end-user,\n ​\n so my questions are:\n  \ndo you think this is a fair interpretation of the agreement ?\n does that mean the creator is liable to whatever the model spit out ?\n is there a way to censor the model (short of retraining a new model, or fine-tune on a large scale) ?\n is there an open source model that already gone through the process, and more safe for commercial use ?\n  \n​\n https://preview.redd.it/3zo3tm4e8esb1.png?width=1197&format=png&auto=webp&s=8aa522183f82ba8f85edb69cbaabd93262efd516\n ​\n as per @gentlecucumber advice, i also posted it on r/legaladvice:\n https://www.reddit.com/r/legaladvice/comments/170ll2t/d_is_meta_llama_2_license_agreement_safe_to_sign/?utm_source=share&utm_medium=web2x&context=3\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170jah3/d_offtopic_is_meta_llama_2_license_agreement_safe/",
          "publishedOn": "2023-10-05T14:22:58.000Z",
          "wordCount": null,
          "title": "[D] off-topic, is Meta Llama 2 license agreement safe to sign for commercial use ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170j47f/d_tesseractocr_vs_paddleocr_vs_easyocr_for/",
          "author": null,
          "description": "Which would be the best OCR toolkit to invest the effort to learning and building a pipeline for an OCR system that will be used to extract Japanese text?\n I tried Tesseract initially and although I got some good results, I found it hard to do finetuning due to messy and outdated documentation.\n I haven't had the time to look at the other two OCR tools yet but if anyone had any experience, please do share them especially with how easy or difficult is the finetuning process as well as deploying the tuned models. \n    submitted by    /u/Spitfire_ex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170j47f/d_tesseractocr_vs_paddleocr_vs_easyocr_for/",
          "publishedOn": "2023-10-05T14:15:30.000Z",
          "wordCount": 2635,
          "title": "[D] TesseractOCR vs PaddleOCR vs EasyOCR for Japanese text extraction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170iuw5/d_adapting_opensource_gpt_models/",
          "author": null,
          "description": "Hi,\n our company plans for some budget in 2024 to invest into hardware to do the following\n - running local LLMs for our coworkers to interfere with an locally running offline GPT alike ChatGPT. Use cases: \n  \ngenerating templates for email, letters etc \n Translation (EN/GER/FR/SPA)\n Querying internal knowledge bases and/or FAQs/HOWTOs\n  \nI did some research but it is still hard for me to estimate what are the HW / AI skill requirements to implement something not a quarter as good as ChatGPT. Ive played with Nomics gpt4all which comes close to a baseline.\n We cant use cloud services due to our data privacy policy, so I checked on what would be a good starting point to invest into hardware.\n I came up with a gamer PC (octacore Intel i9/AMD Ryzen 7) utilizing NVidia RTX 4090 (24Gb) / Radeon RX 7900 / 2TB SSD / 64Gb RAM for approximately 3600 Eur. I am pretty sure that would be sufficient to host a decent LLM serving simultaneous client requests. \n But is there also a way to adapt / process our companies data? Most sources state that proper LLMs were trained using hundreds of NVidia A100 and thousands of CPUs. On the other hand we would be fine with just fine-tuning a pretrained model.\n Could you please point me to some sources to learn more about possibilities and requirements as to be able to make well-informed investment decisions? Also, we probably lack the required skills, and would be interested to learn if there are companies and/or projects assisting with this kind of task?\n thanks\n    submitted by    /u/EatTFM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170iuw5/d_adapting_opensource_gpt_models/",
          "publishedOn": "2023-10-05T14:04:27.000Z",
          "wordCount": 2798,
          "title": "[D] Adapting OpenSource GPT Models - requirements/possibilities?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170ib3c/d_are_loras_able_to_improve_results_on_reasoning/",
          "author": null,
          "description": "Is there any good research on which benchmarks LoRAs are most effective at impacting, or are they relegated mostly to changing the style of an LLM's response? \n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170ib3c/d_are_loras_able_to_improve_results_on_reasoning/",
          "publishedOn": "2023-10-05T13:40:45.000Z",
          "wordCount": 2575,
          "title": "[D] - Are LoRAs able to improve results on reasoning benchmarks or is full-parameter fine tuning required?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170hvjs/d_how_to_test_if_regression_model_is/",
          "author": null,
          "description": "I have a regression model, predicting a popularity of a text. I have its performance metrics on test set, e.g. RMSE and MAE. This gives me an uncertainty estimate about its predictions.\n Now I want to transform the text in some way, e.g. give it to human experts or another model to \"upgrade\" (in terms of getting better popularity). So I have the original and transformed text.\n Now I have 3 popularity scores:\n  \ntrue popularity for original text\n predicted popularity for original text\n predicted popularity for transformed text\n  \nObviously, if model MAE is for example around 5, and predicted popularity for transformed text is higher than for the original by 1.5, this can be totally random, due to errors in the model prediction.\n How can I measure if text transformation is beneficial, i.e. statistically significantly better than the original text, incorporating information about model quality? Requiring that the improvement has to be higher than model error would be incredibly strict.\n    submitted by    /u/qalis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170hvjs/d_how_to_test_if_regression_model_is/",
          "publishedOn": "2023-10-05T13:21:10.000Z",
          "wordCount": null,
          "title": "[D] How to test if regression model is statistically significantly better, including its test error?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/170gngt/d_david_donoho_data_science_at_the_singularity/",
          "author": null,
          "description": "submitted by    /u/wojcech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/170gngt/d_david_donoho_data_science_at_the_singularity/",
          "publishedOn": "2023-10-05T12:25:43.000Z",
          "wordCount": 2560,
          "title": "[D] David Donoho: Data Science at the Singularity (pushback on AGI singularity, advocates for Open Science and reproducibility)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1707x8f/r_tensor_programs_vi_feature_learning_in/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2310.02244\n Abstract: \n  \nBy classifying infinite-width neural networks and identifying the optimal limit, Tensor Programs IV and V demonstrated a universal way, called μP, for widthwise hyperparameter transfer, i.e., predicting optimal hyperparameters of wide neural networks from narrow ones. Here we investigate the analogous classification for depthwise parametrizations of deep residual networks (resnets). We classify depthwise parametrizations of block multiplier and learning rate by their infinite-width-then-depth limits. In resnets where each block has only one layer, we identify a unique optimal parametrization, called Depth-μP that extends μP and show empirically it admits depthwise hyperparameter transfer. We identify feature diversity as a crucial factor in deep networks, and Depth-μP can be characterized as maximizing both feature learning and feature diversity. Exploiting this, we find that absolute value, among all homogeneous nonlinearities, maximizes feature diversity and indeed empirically leads to significantly better performance. However, if each block is deeper (such as modern transformers), then we find fundamental limitations in all possible infinite-depth limits of such parametrizations, which we illustrate both theoretically and empirically on simple networks as well as Megatron transformer trained on Common Crawl.\n  \nInteresting, great to see this line of work continued, muP was great, now Depth-muP\n    submitted by    /u/_puhsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1707x8f/r_tensor_programs_vi_feature_learning_in/",
          "publishedOn": "2023-10-05T03:48:52.000Z",
          "wordCount": 2738,
          "title": "[R] Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zzlz3/p_opensource_project_to_run_locally_llms_in/",
          "author": null,
          "description": "Excited to introduce BlindChat (https://github.com/mithril-security/blind_chat), an open-source, privacy-centric alternative to ChatGPT for in-browser Conversational AI!\n We provide full local inference in browser, by using libraries from Hugging Face like transformers.js or candle for WASM inference.\n We have supported several small models, the latest one being Phi-1.5, the 1.3B model that beat Llama 2 7b!\n As Microsoft’s researchers mentioned in their paper, the model often produces incorrect code and statements. They are just suggestions, and this model is not trained for instruction tuning, so it might be harder to use than regular chat. More info on their model card (https://huggingface.co/microsoft/phi-1_5).\n We would love to have your feedback on our project, as we are aiming to build a privacy-first and open-source alternative to ChatGPT!\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zzlz3/p_opensource_project_to_run_locally_llms_in/",
          "publishedOn": "2023-10-04T21:43:41.000Z",
          "wordCount": 2664,
          "title": "[P] Open-source project to run locally LLMs in browser, such as Phi-1.5 for fully private inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zycqy/d_what_is_the_relation_between_learning_rate_and/",
          "author": null,
          "description": "How can we tackle vanishing gradient problem by changing the learning rate? Is it possible?\n    submitted by    /u/InternationalBack472  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zycqy/d_what_is_the_relation_between_learning_rate_and/",
          "publishedOn": "2023-10-04T20:54:42.000Z",
          "wordCount": 2553,
          "title": "[D] What is the relation between learning rate and vanishing gradient problem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zxl43/p_torchsummary_not_working_with_your_layers_again/",
          "author": null,
          "description": "pip install output-shape \n It is a minimalistic and simple alternative to torchsummary with a simple print of the output shape of a layer, or custom layer. For torch.nn.MultiheadAttention, it handles both the output shape and the attn matrix separately. \n https://github.com/avocardio/output-shape\n Currently only works with PyTorch models, soon with Tensorflow / Keras as well. Jax is also on the list for later!\n    submitted by    /u/capital-man  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zxl43/p_torchsummary_not_working_with_your_layers_again/",
          "publishedOn": "2023-10-04T20:24:04.000Z",
          "wordCount": 2599,
          "title": "[P] Torchsummary not working with your layers again? Try this lightweight alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zw3ps/d_thoughts_on_current_vector_db_landscape/",
          "author": null,
          "description": "Hello,\n What are your thoughts on current Vector DB offerings? For instance:\n  \nDo you think the pricing for them is reasonable/viable?\n Do you think there’s a sufficient level of developer/user experience? What about for those who aren’t necessarily specialized in data?\n If you like a managed service, why do you prefer it over the open source alternatives?\n  \n   submitted by    /u/LucasSaysHello  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zw3ps/d_thoughts_on_current_vector_db_landscape/",
          "publishedOn": "2023-10-04T19:23:39.000Z",
          "wordCount": 2590,
          "title": "[D] Thoughts on current Vector DB landscape?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zvohd/r_neurbf_a_neural_fields_representation_with/",
          "author": null,
          "description": "Project Page\n Paper\n Code\n  \nWe present a novel type of neural fields that uses general radial bases for signal representation. State-of-the-art neural fields typically rely on grid-based representations for storing local neural features and N-dimensional linear kernels for interpolating features at continuous query points. The spatial positions of their neural features are fixed on grid nodes and cannot well adapt to target signals. Our method instead builds upon general radial bases with flexible kernel position and shape, which have higher spatial adaptivity and can more closely fit target signals. To further improve the channel-wise capacity of radial basis functions, we propose to compose them with multi-frequency sinusoid functions. This technique extends a radial basis to multiple Fourier radial bases of different frequency bands without requiring extra parameters, facilitating the representation of details. Moreover, by marrying adaptive radial bases with grid-based ones, our hybrid combination inherits both adaptivity and interpolation smoothness. We carefully designed weighting schemes to let radial bases adapt to different types of signals effectively. Our experiments on 2D image and 3D signed distance field representation demonstrate the higher accuracy and compactness of our method than prior arts. When applied to neural radiance field reconstruction, our method achieves state-of-the-art rendering quality, with small model size and comparable training speed.\n  \n   submitted by    /u/Sirisian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zvohd/r_neurbf_a_neural_fields_representation_with/",
          "publishedOn": "2023-10-04T19:06:23.000Z",
          "wordCount": 2745,
          "title": "[R] NeuRBF: A Neural Fields Representation with Adaptive Radial Basis Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zvo5f/d/",
          "author": null,
          "description": "Hi guys !\n I am going to purchase a laptop for programming and AI tasks. I will be working on a simulation software project related to the trajectory of an object in 2d and 3d space.\n Which laptop will be the most suitable for these tasks and it should have high battery backup because the place where I work does not have enough power sockets.\n The first laptop which came into my mind was Macbook pro with M2 pro chip and Lenovo Thinkpad X1 Carbon gen 10.\n Suggest me the best.\n    submitted by    /u/smitherium  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zvo5f/d/",
          "publishedOn": "2023-10-04T19:06:03.000Z",
          "wordCount": 2618,
          "title": "[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zua0j/discussion_feature_selection_algorithms/",
          "author": null,
          "description": "I have only 200 samples but about 30 features. What are some effective commonly used feature selection algorithms? I want to identify the features that play the most significant role in generating outcomes.\n    submitted by    /u/Shina-pig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zua0j/discussion_feature_selection_algorithms/",
          "publishedOn": "2023-10-04T18:09:51.000Z",
          "wordCount": 2563,
          "title": "[Discussion] Feature Selection Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zt2df/r_will_a_small_error_be_determining_in_the_final/",
          "author": null,
          "description": "About a week ago, I submitted my first paper into one of the most prestigious Machine Learning conferences out there. This was a last minute submission, and my supervisor and I were working on it simultaneously until the very last moment.\n Sadly, my supervisor committed an error when writing the mathematical definition of a certain set, slightly changing its meaning. This change, even though small, changes the definition in such a way that the subsequent theorem and its proof isn't formally correct anymore, as it assumes the original definition of the set, not the new one.\n How much will this affect the decision of accepting or rejecting my paper?\n The whole method, results and consequences are still the same, no matter this definition. It's more a problem of a \"formal\" nature (here \"formal\" as a word in the mathematical sense). \n Is there a other way that I can inform about this error without changing the content maybe? I know that at some point, they give a chance to edit the original paper, but I don't know if this is after the decision to accept/reject.\n    submitted by    /u/howtorewriteaname  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zt2df/r_will_a_small_error_be_determining_in_the_final/",
          "publishedOn": "2023-10-04T17:21:13.000Z",
          "wordCount": 2724,
          "title": "[R] Will a small error be determining in the final decision for my paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zsqrj/how_can_i_apply_object_detection_and_image/",
          "author": null,
          "description": "So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here's where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!\n So how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found then it should return \"No object found\" or like that.\n    submitted by    /u/meWhoObserves  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zsqrj/how_can_i_apply_object_detection_and_image/",
          "publishedOn": "2023-10-04T17:08:17.000Z",
          "wordCount": 2731,
          "title": "How can I apply object detection and image segmentation functionality to my current custom-trained Image Classification model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zrme9/r_large_language_models_represents_space_and_time/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2310.02207\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zrme9/r_large_language_models_represents_space_and_time/",
          "publishedOn": "2023-10-04T16:23:37.000Z",
          "wordCount": 2537,
          "title": "[R] Large Language Models Represents Space and Time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zqmet/r_help_shape_the_future_of_machine_learning_take/",
          "author": null,
          "description": "Hello Redditors in r/MachineLearning\n We are the team behind ML Workbench, an upcoming integrated platform designed to streamline your entire machine learning lifecycle. From data preprocessing and model training to validation and deployment, we aim to make the process as seamless as possible.\n But here's the thing: we need your insights to build something that truly resonates with the community and solves real-world problems.\n 📝 Click Here to Take the Survey\n Why Should You Care?\n  \nUnified Experience: Imagine managing all your ML tasks in one integrated environment.\n High-Performance Computing: We're leveraging powerful A100 GPUs to accelerate your work.\n User-Centric Design: Whether you're a beginner or a pro, the platform is designed to cater to all skill levels.\n Collaboration: Built-in features to make team collaboration effortless.\n  \nWhat's in the Survey?\n The survey contains questions about your current challenges, the tools you use, and what you'd love to see in an ML platform. It should only take about 5-10 minutes to complete.\n Thank You Gift\n As a small token of our appreciation, we're offering exclusive early access to the platform for selected participants. Don't miss this chance to be among the first to experience what we're building!\n 📝 Click Here to Take the Survey\n Your feedback is crucial for us to create a tool that we hope will make a significant positive impact in the machine learning community. Thank you for taking the time to read this post and participate in our survey.\n Cheers, The ML Workbench Team\n    submitted by    /u/nonononottodayorever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zqmet/r_help_shape_the_future_of_machine_learning_take/",
          "publishedOn": "2023-10-04T15:44:36.000Z",
          "wordCount": 2790,
          "title": "[R] Help Shape the Future of Machine Learning: Take Our Short Survey and Let's Create Something Amazing Together!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zq9sf/p_video_event_detection/",
          "author": null,
          "description": "Hi, I'm looking to create a model that given a sequence of frames from a video, returns a probability distribution over a set of events that may have occurred in those frames (probably 5 - 10 events). The training data will consist of video and hand labelled frame index/event pairs. I'm not too concerned about handling simultaneous events. \n It would be super helpful for some suggestions on a model architecture that would yield the best results and/or good papers/examples that achieve something similar.\n Thanks!\n    submitted by    /u/Dredgefort  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zq9sf/p_video_event_detection/",
          "publishedOn": "2023-10-04T15:30:50.000Z",
          "wordCount": 2614,
          "title": "[P] Video Event Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zouad/p_retrieval_augmented_generation_with_opensearch/",
          "author": null,
          "description": "I created a video tutorial that tries to demonstrate that semantic search (using embeddings) is not always necessary for RAG (retrieval augmented generation). It was inspired by the following Cohere blog post: https://txt.cohere.com/rerank/\n I code up a minimal RAG pipeline: OpenSearch -> Rerank -> Chat completion (without using Langchain or similar libraries) and then see how it performs on various queries.\n Hope some of you find it helpful. Feel free to share any feedback@\n Video link: https://youtu.be/OsE7YcDcPz0\n    submitted by    /u/mildlyoverfitted  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zouad/p_retrieval_augmented_generation_with_opensearch/",
          "publishedOn": "2023-10-04T14:34:31.000Z",
          "wordCount": 2613,
          "title": "[P] Retrieval augmented generation with OpenSearch and reranking [Video tutorial]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zoh3s/r_hacking_an_nlp_benchmark_how_to_score_100/",
          "author": null,
          "description": "AMR parsing is a fun task where researchers map texts onto little graphs that explicate their meaning, so called Abstract Meaning Representations (AMRs). While arguably not the top NLP benchmark regarding popularity, research has been active for the last 10 years, including at major NLP conferences such as ACL/NAACL/EACL/EMNLP etc.\n Funnily, I recently found some vulnerabilities in the evaluation protocol, and if we exploit these vulnerabilities, we can get the highest score on the benchmark. \n To get an overview over the issue (without understanding AMR), imagine a cooking contest that takes place regularly, say, once a year. In all events, we have the same judge, participants are amateurs, meals are scored on 0 to 100, with 100 meaning “it can’t possibly get better”. Over the years, the …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zoh3s/r_hacking_an_nlp_benchmark_how_to_score_100/",
          "publishedOn": "2023-10-04T14:19:39.000Z",
          "wordCount": 2984,
          "title": "[R] Hacking an NLP benchmark: How to score 100 points on AMR parsing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zn7vv/d_looking_for_an_article_related_to_machine/",
          "author": null,
          "description": "Hi all,\n I'm curious if anyone has a stand-out article they believe would prompt a lively discussion in a journal club I have coming up. Something that may have people take sides, or maybe a recent breakthrough in the ML space as it relates to clinical/health care.\n ​\n Thanks!\n    submitted by    /u/veilofosiris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zn7vv/d_looking_for_an_article_related_to_machine/",
          "publishedOn": "2023-10-04T13:26:24.000Z",
          "wordCount": 2592,
          "title": "[D] Looking for an article related to machine learning in medicine to be presented at a journal club",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zmlf5/r_think_before_you_speak_training_language_models/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2310.02226\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zmlf5/r_think_before_you_speak_training_language_models/",
          "publishedOn": "2023-10-04T12:59:23.000Z",
          "wordCount": 2540,
          "title": "[R] Think before you speak: Training Language Models With Pause Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zjfon/p_good_models_to_use_for_multimodal_object/",
          "author": null,
          "description": "So basically I have a dataset with images of vehicles in top down view in both RGB and IR, what are some models I can use for both unimodal and multimodal object detection to compare their performance. Links to GitHub repos would be helpful. Thanks\n    submitted by    /u/Xyber5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zjfon/p_good_models_to_use_for_multimodal_object/",
          "publishedOn": "2023-10-04T10:21:08.000Z",
          "wordCount": 2595,
          "title": "[P] Good models to use for multimodal object detection when both the modalities are image based or some object detection models which support ensembling out of the box like Yolov5?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zi37s/p_using_pretrained_models_as_features/",
          "author": null,
          "description": "Hey everyone!\n Currently, I am working on a project around music emotion classifcation/regression model. Basically I am trying to predict a score to each emotion on a given song.\n The problem is that my dataset has quite imbalanced scores (y). Most scores are centered around a certain score range. Therefore, having difficulties predicting scores that are further away of the mean values.\n I had this idea to bring in pre-trained (on other datasets and problems) audio classification models into this as there are a bunch of good performing pre-trained classification models out there already. The prediction of these pre-trained models should be used as features (e.g. prediction of genre, instrument etc) beside the original spectorgram in my model.\n I know this won't solve the problem of imbalances in the scores but I thought maybe this could improve the performance as the model would have more features to work with.\n Does this make sense?\n I appreciate any input.\n    submitted by    /u/Kniggi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zi37s/p_using_pretrained_models_as_features/",
          "publishedOn": "2023-10-04T08:56:08.000Z",
          "wordCount": 2683,
          "title": "[P] Using pre-trained models as features?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zhkq2/d_lomo_underrated/",
          "author": null,
          "description": "Does anyone have an idea why the LOMO optimizer (low memory optimizer) which was released a few months ago is not widely available and everyone still uses either Adam or SGD? \n While the paper looks really promising\n    submitted by    /u/RedMoula  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zhkq2/d_lomo_underrated/",
          "publishedOn": "2023-10-04T08:22:28.000Z",
          "wordCount": 2566,
          "title": "[D] LOMO underrated",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16zbwcf/p_camera_based_monitoring_of_infants_breathing/",
          "author": null,
          "description": "Hi! I recently have seen systems that monitor breathing rate of an infant through camera. I have read several articles on that topic, where people used things like 3D camera, RGB or Interferometric Radar Sensor. Do you guys have any idea on how to accurately measure this?\n    submitted by    /u/kaina_m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16zbwcf/p_camera_based_monitoring_of_infants_breathing/",
          "publishedOn": "2023-10-04T02:58:47.000Z",
          "wordCount": 2580,
          "title": "[P] Camera based monitoring of infant's breathing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z9dko/r_towards_selfassembling_artificial_neural/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z9dko/r_towards_selfassembling_artificial_neural/",
          "publishedOn": "2023-10-04T01:04:04.000Z",
          "wordCount": 2547,
          "title": "[R] Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z88hp/d_how_do_you_track_projects_in_a_scaling_ml_team/",
          "author": null,
          "description": "I am part of a Machine Learning team that has experienced significant growth recently. When we were a small team, tracking projects was straightforward. However, as the team has expanded, it's become increasingly challenging to keep track of everything. We are part of a larger corporation, so we have access to tools for creating epics and boards. However, these corporate tools are too generic and don't provide the level of detail I need for internal management. Specifically, I'm looking for a way to track model versions, dataset versions, and the overall status of our projects. I'd also like to be able to assign team members to projects.\n Currently, we use a MIRO board, but it's disorganized and difficult to read and update. I'd love to hear what tools or strategies you've used for similar situations, especially since our team is expected to grow even more, making tracking increasingly complex.\n    submitted by    /u/Spiritual_Narwhal649  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z88hp/d_how_do_you_track_projects_in_a_scaling_ml_team/",
          "publishedOn": "2023-10-04T00:14:11.000Z",
          "wordCount": 2684,
          "title": "[D] How Do You Track Projects in a Scaling ML Team?\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z6yek/d_what_are_some_effective_dimensionality/",
          "author": null,
          "description": "I am considering comparing mutual information scores, but I also don't think I understand MI well enough. \n For example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I'm thinking that a high MI value is \"bad\" since this means X, Y would be redundant. I am not sure if my understanding here is correct. \n Another method I have tried is to binarize the data for each feature (represented as rows in my dataset) using \"present\" (1) and \"absent\" (0). The main issue I have run into doing this is that I am trying to then create a distribution to compare the fea…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z6yek/d_what_are_some_effective_dimensionality/",
          "publishedOn": "2023-10-03T23:19:44.000Z",
          "wordCount": 2943,
          "title": "[D] What are some effective dimensionality reduction (unsupervised feature selection) techniques for a high dimensional, sparse dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z6poz/d_best_interface_to_use_llms_for_code_chat_or/",
          "author": null,
          "description": "Hi everyone,\n I am quite interested in understanding what are the feedback from the community in terms of interface to leverage LLMs for code productivity.\n Because LLMs tend to do mistake I have mostly used Chat-like interfaces, like ChatGPT, as they allow to interact with the model and converge to a conclusion. \n I haven't used Copilot for a while but my feeling was that it could do some boilerplate correctly but then it quickly started suggesting code that would be misleading and could actually hurt productivity.\n It might have changed since then but that was my feeling back then.\n What is your favorite option and why?\n View Poll\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z6poz/d_best_interface_to_use_llms_for_code_chat_or/",
          "publishedOn": "2023-10-03T23:09:51.000Z",
          "wordCount": 2654,
          "title": "[D] Best interface to use LLMs for code: Chat or completion?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z6mqr/d_ml_input_data_has_to_be_derived_from_a_larger/",
          "author": null,
          "description": "Hello everyone. I am curious to know if anyone has encountered a ML problem like this and if so, I seek your advice. Usually in ML classification such as the IRIS dataset, each row represents a sample and each column a parameter, right ! My problem is that my ML classification parameters have to be derived from a range of values (parent data). I have taken mean of the parent values to generate the parameters for the ML input data. This results in lower classification accuracies using Random forest and XGBoost.\n Has anyone encountered a similar situation like this where the data has to be generated from a range of other datasets? Is there any other way to do this? I did not find any papers or articles from the web so just asking.\n I can generate additional parameters from other statistics such as median, standard deviation etc. which can improve the classification accuracy but can make interpretation of the results a little weird, domain wise. I wish to avoid this if possible.\n    submitted by    /u/notmyfault7676  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z6mqr/d_ml_input_data_has_to_be_derived_from_a_larger/",
          "publishedOn": "2023-10-03T23:06:36.000Z",
          "wordCount": 2709,
          "title": "[D] ML input data has to be derived from a larger dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z0zlz/d_book_review_for_metas_ml_design_interview/",
          "author": null,
          "description": "I'm preparing for the ML system design interview for Meta, and I searched for various resources. This book (ML System Design Interview (by Ali Aminian & Alex Xu)) seems like a solid structured resource that covers solutions to case studies in detail. Has anyone used it to prepare for Meta's ML System Design interview? Thoughts?\n Khang's book doesn't seem to have great reviews.\n Chip Huyen's book (Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications) doesn't seem very focused on interview prep??\n Also, happy to hear about other cool resources to prepare. Thanks very much!\n    submitted by    /u/irEFrienfk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z0zlz/d_book_review_for_metas_ml_design_interview/",
          "publishedOn": "2023-10-03T19:27:04.000Z",
          "wordCount": 2639,
          "title": "[D] Book review for Meta's ML Design interview? Machine Learning System Design Interview (by Ali Aminian and Alex Xu)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z0ev6/r_open_xembodiment_robotic_learning_datasets_and/",
          "author": null,
          "description": "Blog: https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types \n https://robotics-transformer-x.github.io/ here you can also find the Datasets and Code!\n Paper: https://robotics-transformer-x.github.io/paper.pdf\n Abstract:\n  \nLarge, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train “generalist” X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through a collaboration between 21 institutions, demonstrating 527 skills (160266 tasks). We show that a high-capacity model trained on this data, which we call RT-X, exhibits positive transfer and improves the capabilities of multiple robots by leveraging experience from other platforms. \n  \nhttps://preview.redd.it/oxzutrhtb1sb1.jpg?width=1693&format=pjpg&auto=webp&s=37b8b1dbf5f489dc2c8eaca4d15cb9c32ebc2660\n https://preview.redd.it/ldsiwshtb1sb1.jpg?width=1494&format=pjpg&auto=webp&s=fdbf0f91c705acf11bff854f6d6af82dddd47021\n https://preview.redd.it/ikk18jitb1sb1.jpg?width=1693&format=pjpg&auto=webp&s=e50b443dc4b0266a0480d54c4f92a0b708485797\n https://preview.redd.it/t5wmciitb1sb1.jpg?width=1361&format=pjpg&auto=webp&s=2971fd645acb6dcbed2ca3522e311d0772c45964\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z0ev6/r_open_xembodiment_robotic_learning_datasets_and/",
          "publishedOn": "2023-10-03T19:03:49.000Z",
          "wordCount": 2742,
          "title": "[R] Open X-Embodiment: Robotic Learning Datasets and RT-X Models - DeepMind 2023 - RT-X exhibits positive transfer and improves the capabilities of multiple robots by leveraging experience from other platforms!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z08iy/d_biggest_problems_with_ml_in_industry/",
          "author": null,
          "description": "For all my corporate ML engineers I have a question, what are the most annoying / biggest problems you face when developing/deploying ML in industry? \n This can be anywhere from data, to tuning, to even MLOPS. \n    submitted by    /u/hai_cben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z08iy/d_biggest_problems_with_ml_in_industry/",
          "publishedOn": "2023-10-03T18:57:03.000Z",
          "wordCount": 2567,
          "title": "[D] Biggest problems with ML in industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16z01w5/d_difficulty_with_paper_implementations_on_google/",
          "author": null,
          "description": "I am not from CS background, my knowledge is from online courses and books. All of which used some variation of Jupyter notebook. My knowledge of code can be lacking sometimes, since I am not from CS background.\n I am trying to implement some computer vision paper codes on newer samples. I understand the papers, and the underlying mechanisms. However, I fail to decipher the codes provided with the associated github repository. Usually, these repository contains information on how to recreate the experiment on some specific data using shell. But I am using google Colab for this purpose, as I don't have access to GPU, and I found it impossible to recreate the experiments in the google Colab, using shell commands, let alone extend it to newer samples.\n I would appreciate some help in this regard, I haven't done this before, and there aren't really any tutorial/resource on how to do this. Ideally, what I am trying to do is separate the model, input some images, get the output, and interpret it. I am stuck, and I would really appreciate some help or advice in this regard. Right now I am trying to work with this paper, meta ood\n I would appreciate any help/advice/resource anything. I feel very lost. Thanks in Advance.\n    submitted by    /u/franticpizzaeater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16z01w5/d_difficulty_with_paper_implementations_on_google/",
          "publishedOn": "2023-10-03T18:49:40.000Z",
          "wordCount": 2744,
          "title": "[D] Difficulty with paper implementations on google colab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yx8pj/repurposing_a_personal_desktop_computer_p/",
          "author": null,
          "description": "Hello! \n I'm debating turning my old desktop (old CPU but relatively new GPU 3980 or 90) into a ML box that I can remote into. I'm sure people here have done something similar and I was wondering if anyone could point me towards some resources for getting it off the ground/any pitfalls to avoid/suggestions. \n I'm an active data scientist researcher for my job and this would just be for fun side projects but I have some pretty glaring holes in my knowledge of computers (like the best way to set this up - should I uninstall windows install unbuntu or is windows fine?) \n Honestly I'm sure my ignorance will be pretty apparent from the questions I'm asking/not asking so any advice anyone has would be welcome! \n Thanks! Sorry if this is the wrong subreddit for this sort of thing. \n ​\n    submitted by    /u/shebaiscool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yx8pj/repurposing_a_personal_desktop_computer_p/",
          "publishedOn": "2023-10-03T16:58:30.000Z",
          "wordCount": 2669,
          "title": "Repurposing a personal desktop computer [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ywkc6/r_generative_memory_generative_diffusion_models/",
          "author": null,
          "description": "https://arxiv.org/abs/2309.17290\n    submitted by    /u/LucaAmbrogioni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ywkc6/r_generative_memory_generative_diffusion_models/",
          "publishedOn": "2023-10-03T16:31:19.000Z",
          "wordCount": 2537,
          "title": "[R] Generative memory: generative diffusion models are equivalent to modern Hopfield nets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yvwky/d_stuck_in_automation_of_ai_models/",
          "author": null,
          "description": "Hello everyone!\n ​\n I'm currently working on a project and have hit a roadblock in automating the deployment of my machine-learning models. Can anyone provide guidance on the best practices or tools for streamlining the deployment process? Specifically, I'm looking to create a seamless workflow where models can be easily uploaded, deployed on the cloud, and accessible through APIs. Any insights or advice would be greatly appreciated!\n ​\n Automation!!!\n    submitted by    /u/homelander81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yvwky/d_stuck_in_automation_of_ai_models/",
          "publishedOn": "2023-10-03T16:06:27.000Z",
          "wordCount": 2598,
          "title": "[D] Stuck in Automation of AI models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yvwbb/p_the_case_of_the_missing_masterpiece/",
          "author": null,
          "description": "Hi, I just wanted to share an applied image classification problem that I worked on a few years ago: https://vdalv.github.io/2018/09/01/missingMasterpiece.html\n    submitted by    /u/vdalv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yvwbb/p_the_case_of_the_missing_masterpiece/",
          "publishedOn": "2023-10-03T16:06:12.000Z",
          "wordCount": 2551,
          "title": "[P] The Case of the Missing Masterpiece",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yvpnm/need_to_build_a_xai_model_to_explain_the/",
          "author": null,
          "description": "Hello, I need help from someone that knows about XAI. I have to create a XAI model to intérprete the resulta of an AI model, an MLP, that works as an IDS classifier. I have no idea on how to do It and I have been completely blocked for 2.5 years. This is the final project of my career and I just don't know how to do It, and my tutor isn't very helpful. If anyone is able to help I would explain him what I have to do and would be very grateful.\n Thanks for your help\n    submitted by    /u/elMandarine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yvpnm/need_to_build_a_xai_model_to_explain_the/",
          "publishedOn": "2023-10-03T15:59:45.000Z",
          "wordCount": 2636,
          "title": "Need to build a XAI model to explain the behaviour of an IDS [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yskxk/d_optimal_scheduling_tool_with_aiml/",
          "author": null,
          "description": "Hello all,\n I'm trying to plan out for a new web platform development for workforce management but have little experience. We all know that hard coding can be done for general scheduling, including manager polling shifts based on labor category, staff assignments, conflt resolving, emergency scheduling, etc. But what I want to research to is....how can I ensure that one optimal schedule is automatically computed using AI/machine learning tools so that I don't have to go through the list of hard-coded generated schedules (I’m sure these will work fine, but still want to compute one ultimate schedule).\n    submitted by    /u/Playful-Bed-2183  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yskxk/d_optimal_scheduling_tool_with_aiml/",
          "publishedOn": "2023-10-03T13:55:01.000Z",
          "wordCount": 2628,
          "title": "[D] Optimal scheduling tool with AI/ML recommendations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yse3r/r_breakascene_extracting_multiple_concepts_from_a/",
          "author": null,
          "description": "​\n Break-A-Scene: Given a single image with multiple concepts, annotated by loose segmentation masks, our method can learn a distinct token for each concept, and use natural language guidance to re-synthesize the individual concepts or combinations of them in various contexts.\n Project Page: https://omriavrahami.com/break-a-scene/\n Code is publicly released!\n Abstract\n  \nText-to-image model personalization aims to introduce a user-provided concept to the model, allowing its synthesis in diverse contexts. However, current methods primarily focus on the case of learning a single concept from multiple images with variations in backgrounds and poses, and struggle when adapted to a different scenario. In this work, we introduce the task of textual scene decomposition: given a single image of a scene that may contain several concepts, we aim to extract a distinct text token for each concept, enabling fine-grained control over the generated scenes. To this end, we propose augmenting the input image with masks that indicate the presence of target concepts. These masks can be provided by the user or generated automatically by a pre-trained segmentation model. We then present a novel two-phase customization process that optimizes a set of dedicated textual embeddings (handles), as well as the model weights, striking a delicate balance between accurately capturing the concepts and avoiding overfitting. We employ a masked diffusion loss to enable handles to generate their assigned concepts, complemented by a novel loss on cross-attention maps to prevent entanglement. We also introduce union-sampling, a training strategy aimed to improve the ability of combining multiple concepts in generated images. We use several automatic metrics to quantitatively compare our method against several baselines, and further affirm the results using a user study. Finally, we showcase several applications of our method.\n  \n​\n    submitted by    /u/sgd_is_all_you_need  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yse3r/r_breakascene_extracting_multiple_concepts_from_a/",
          "publishedOn": "2023-10-03T13:46:54.000Z",
          "wordCount": 2813,
          "title": "[R] Break-A-Scene: Extracting Multiple Concepts from a Single Image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yr7kx/r_mit_meta_cmu_researchers_llms_trained_with_a/",
          "author": null,
          "description": "LLMs like GPT-3 struggle in streaming uses like chatbots because their performance tanks on long texts exceeding their training length. I checked out a new paper investigating why windowed attention fails for this.\n By visualizing the attention maps, the researchers noticed LLMs heavily attend initial tokens as \"attention sinks\" even if meaningless. This anchors the distribution.\n They realized evicting these sink tokens causes the attention scores to get warped, destabilizing predictions.\n Their proposed \"StreamingLLM\" method simply caches a few initial sink tokens plus recent ones. This tweaks LLMs to handle crazy long texts. Models tuned with StreamingLLM smoothly processed sequences with millions of tokens, and were up to 22x faster than other approaches. \n Even cooler - adding a special \"[Sink Token]\" during pre-training further improved streaming ability. The model just used that single token as the anchor. I think the abstract says it best:\n  \nWe introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence length without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more.\n  \nTLDR: LLMs break on long convos. Researchers found they cling to initial tokens as attention sinks. Caching those tokens lets LLMs chat infinitely.\n Full summary here\n Paper link: https://arxiv.org/pdf/2309.17453.pdf\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yr7kx/r_mit_meta_cmu_researchers_llms_trained_with_a/",
          "publishedOn": "2023-10-03T12:56:26.000Z",
          "wordCount": 2770,
          "title": "[R] MIT, Meta, CMU Researchers: LLMs trained with a finite attention window can be extended to infinite sequence lengths without any fine-tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yq79a/d_really_good_dataset_for_a_course_capstone/",
          "author": null,
          "description": "Hey everyone!\n My friends and I are taking a Data Science course in our university. We are modestly versed in ML/DL techniques, and want to use everything we know on a really good capstone project for this course. We are looking for a dataset where we can demonstrate a nice variety of techniques to really blow the socks off our Professor. \n Ideally we'd like this to be stemming from something basic that most would consider \"Data Science\", as in something with a tabular dataset and elements of classification. Though we still want chances to bring in what we know from outside the course: for example, if there's images to supplement the dataset we could use Image Classification models or something multimodal to bring in more features, if there's natural language data then we could use LLMs to extract salient features etc. More importantly though, we want something whose exploration can be really motivated so it doesn't seem we're only in it for the ML aspect.\n Thank you!\n    submitted by    /u/Subject-Revolution-3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yq79a/d_really_good_dataset_for_a_course_capstone/",
          "publishedOn": "2023-10-03T12:09:29.000Z",
          "wordCount": 2699,
          "title": "[D] Really good dataset for a Course Capstone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ypoak/d_competitiveness_in_ml_research/",
          "author": null,
          "description": "I've been diving deep into the world of machine learning research, and I'm genuinely baffled: how on Earth do some researchers seem to pump out paper after paper? I mean, there's only 24 hours in a day, right?\n Are academic minions (i.e. PhD students) doing all the heavy lifting? Or maybe some highly efficient workflows I'm not privy to?\n On a more serious note, I would like a career in ML, and the sheer volume and pace of these publications is making me feel a bit disheartened.\n How is this prolificity possible? Any words of encouragement or advice?\n    submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ypoak/d_competitiveness_in_ml_research/",
          "publishedOn": "2023-10-03T11:43:54.000Z",
          "wordCount": 2627,
          "title": "[D] Competitiveness in ML research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ypmuh/d_why_should_i_use_a_hostedcloud_vectordb/",
          "author": null,
          "description": "Why the hell should i use cloud based or server hosted solution over a easy peasy servless variant like lancedb or even faiss vector store is enough for most of the use cases on small-medium\n I often see posts like\n \"oh my stack is... pinecone Chroma weaviate_io\"\n And they just ingest minisets of data, what the hell man\n    submitted by    /u/Dear_Bullfrog193  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ypmuh/d_why_should_i_use_a_hostedcloud_vectordb/",
          "publishedOn": "2023-10-03T11:41:46.000Z",
          "wordCount": 2597,
          "title": "[D] Why should I use a hosted/cloud VectorDB solutions over a serverless or vector store?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yo7j4/p_fontogen_generating_truetype_fonts/",
          "author": null,
          "description": "I'd like to share a project that I've spent a few weekends working on. FontoGen is an autoregressive encoder-only transformer model that's capable of generating true-type fonts. \n GitHub: https://github.com/SerCeMan/fontogen\n Weights: https://huggingface.co/SerCe/fontogen\n Blog post with more details: https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font\n The project is largely an exploration of whether generating fonts natively, line by line, is possible. I'm not aware of any previous research that would achieve the same results for complete fonts previously. This is my first ML-specific project, and I would appreciate any feedback on the model architecture, and I'm also happy to answer any questions you may have.\n    submitted by    /u/SerCeMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yo7j4/p_fontogen_generating_truetype_fonts/",
          "publishedOn": "2023-10-03T10:28:10.000Z",
          "wordCount": 2620,
          "title": "[P] FontoGen: generating true-type fonts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ylbx6/d_what_happens_after_removing_the_causal_mask_of/",
          "author": null,
          "description": "The causal mask in LLaMA serves as a protective barrier to prevent information leakage. However, in certain tasks, leveraging information leakage can be a beneficial strategy for enhancing performance, particularly in tasks like token classification, such as Named Entity Recognition (NER). Interestingly, the paper titled \"Label Supervised LLaMA Finetuning\" (available at https://arxiv.org/abs/2310.01208) reveals a significant performance boost in token classification when the causal mask is removed.\n    submitted by    /u/seanlee97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ylbx6/d_what_happens_after_removing_the_causal_mask_of/",
          "publishedOn": "2023-10-03T07:27:05.000Z",
          "wordCount": 2600,
          "title": "[D] What happens after removing the causal mask of LLaMA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yk8ka/r_radit_retrievalaugmented_dual_instruction_tuning/",
          "author": null,
          "description": "New paper that proposes instruction-tuning with in-context retrieval-augmentation to improve SOTA LLMs in cases where access to large, external knowledge sources is needed. Tested on LLaMA 65B, 13B and 7B.\n https://arxiv.org/abs/2310.01352\n    submitted by    /u/todpole3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yk8ka/r_radit_retrievalaugmented_dual_instruction_tuning/",
          "publishedOn": "2023-10-03T06:13:48.000Z",
          "wordCount": 2561,
          "title": "[R] RA-DIT: Retrieval-Augmented Dual Instruction Tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yebwm/d_how_do_you_scale_computational_intensive_python/",
          "author": null,
          "description": "Hey ML Community, I'm wondering how people currently go about scaling their Python programs? Lets say for instances you're doing batch inference using an LLM. Each prediction takes 2-3 minutes to process, how would you go about scaling that to make a million predictions? \n I'm asking this question because a few months back I started building a tool to quickly parallelize python functions across thousands of machines in the cloud. I'm focused on making the barrier to interact with the cloud extremely low and want to know all the core alternatives out there. Also, if you have any advice on starting a business I'd love to hear it. \n    submitted by    /u/Ok_Post_149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yebwm/d_how_do_you_scale_computational_intensive_python/",
          "publishedOn": "2023-10-03T01:06:51.000Z",
          "wordCount": 2641,
          "title": "[D] How do you scale computational intensive Python scripts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ydpzc/d_what_is_the_highest_quality_automatic_image/",
          "author": null,
          "description": "I make very high quality Lora's and finetuned stable diffusion models. These models yield very good results, but more importantly they are very easy to use as I have always captioned my images as one would use natural spoken language (no weird booru tags and all that jazz). The most labor intensive processes in the workflow is image captioning. For example, my last project had almost 10000 images in the data set. Every single image was manually captioned by me as the quality of all automated solutions I tried is subpar and has too many accuracy issues. I have tried Blip auto captioning and LLava, but they still were not accurate enough for what I needed. I am hoping someone here can suggest a solution, if one exists, thanks.\n    submitted by    /u/no_witty_username  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ydpzc/d_what_is_the_highest_quality_automatic_image/",
          "publishedOn": "2023-10-03T00:39:06.000Z",
          "wordCount": 2663,
          "title": "[D] What is the highest quality automatic image captioning solution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16yd5qh/d_interview_help_do_you_know_any_good_resources/",
          "author": null,
          "description": "I'm preparing for a data science interview and am looking for case study prep resources, especially for the financial domain (loans and credit cards). Mainly, I want to understand some good metrics for the financial domain, ways to break down the questions and create a rough data model, kinds of conditions to take into consideration (eg. Seasonality), kinds of effects that can be used expected (like opportunities and risks), etc. Any resources or help is greatly appreciated!\n    submitted by    /u/how_the_turn_tablez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16yd5qh/d_interview_help_do_you_know_any_good_resources/",
          "publishedOn": "2023-10-03T00:13:43.000Z",
          "wordCount": 2625,
          "title": "[D] (Interview Help) Do you know any good resources for interview case studies in the finance domain (especially dealing in loan and credit cards)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ycp51/discussion_i_didnt_do_well_in_calculus_iii/",
          "author": null,
          "description": "So I got an A in calculus three but I probably didn't deserve it since it was online and all I did was look up the answer and understand the problems given on the test. So I probably have a C level understanding. Will I be tested on calc 3 knowledge in machine learning or should I retake calc 3?\n    submitted by    /u/Glittering-Target-87  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ycp51/discussion_i_didnt_do_well_in_calculus_iii/",
          "publishedOn": "2023-10-02T23:53:32.000Z",
          "wordCount": 2592,
          "title": "[Discussion] I didn't do well in Calculus III",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ya5p1/p_hand_keypoint_detection/",
          "author": null,
          "description": "Hello Reddit,\n I have a question regarding the right tool. I'm looking for a tool / model to detect hand-keypoints in a video stream of a person assembling stuff. I know OpenPose is a possible one, also Google MediaPipe.\n I’m not really getting along with OpenPose and MediaPipe don’t show really good results.\n In my project, I would like to detect hand keypoints in assembly scenarios. It would be ok to use 2 cameras or a depth camera if necessary.\n Does anybody knows any models / tools to use?\n Thanks in advance :)\n    submitted by    /u/VGHMD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ya5p1/p_hand_keypoint_detection/",
          "publishedOn": "2023-10-02T22:11:04.000Z",
          "wordCount": 2621,
          "title": "[P] Hand keypoint detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y9k4x/p_best_option_for_a_large_local_embedding_database/",
          "author": null,
          "description": "Langchain offers a wide array of vector databases for text embedding models. I need to create a vector database for around 3 million sentence embeddings, each being of dimension 384. I'm building a prototype, so it has to be local and free of charge to use.\n So far, I've hit limits for Chroma (41,666 max). I've also tried Redis, QDrant and FAISS - each of these gets so large that it eats up all the RAM and the process gets killed, or with QDrant, just errors out.\n I've used Pinecone before, but I don't really want to pay for a prototype as I have plenty of disk space.\n I was thinking of chunking the 3 million documents into local vector stores of size 41,666 using ChromaDB - but there isn't a whole lot out there about whether Chroma would allow me to merge all ~70 of these smaller databases into a bigger one for search. I also cannot find whether it would be possible to load all 70 of these into memory and search each one individually.\n So what are my options?\n My other thought was just creating a large Doc2Vec model, however I would like to use something more sophisticated like Huggingface embedding models.\n    submitted by    /u/russ_fegoli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y9k4x/p_best_option_for_a_large_local_embedding_database/",
          "publishedOn": "2023-10-02T21:47:25.000Z",
          "wordCount": 2738,
          "title": "[P] Best option for a large, local embedding database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y9hwt/d_proof_of_convergence_for_a_heavyball_adaptive/",
          "author": null,
          "description": "Hello everyone,\n I am struggling with prooving convergence for an optimizer which uses adaptive step-size with heavy ball algorithm for convex and non-convex functions. In some literature, I could find a regret bound analysis/proof for convex functions and proving that the estimated gradient at t -> inf goes to zero for non-convex functions. \n There are some assumptions and preconditions:\n  \nThe algorithm is heavy ball momentum with adaptive step-size. '\n X_(k+1) = X_k - \\eta_k . \\nabla(f(x_k)) + \\beta(x_k - x_(k-1))\n \nThe following assumptions are made: \n  \nA. The function is smooth. B. The function is Lipschitz. C. The gradients are Lipschitz. \n I attempt to prove the convergence to a critical point or a local minima. Where the estimate of the gradients at any instance k goes to zero. i.e. E[\\nabla(f(x_k))] = 0 as t -> inf. \n Could anyone please guide me through the process of convergence proof for non-convex functions or give me literature recommendations for the same.\n Thank you very much in advance.\n    submitted by    /u/Loose_Foundation5990  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y9hwt/d_proof_of_convergence_for_a_heavyball_adaptive/",
          "publishedOn": "2023-10-02T21:44:58.000Z",
          "wordCount": 2699,
          "title": "[D] Proof of convergence for a heavy-ball adaptive step-size algorithm for non-convex functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y8oyn/d_open_problems_after_gpt4_capabilities/",
          "author": null,
          "description": "We all know that LLMs (and especially foundation models) are extremely functionally capable. Has anyone made a nice list of deficiencies that they show? \n I know Gary Marcus did so many years ago, but after GPT3 and GPT4 -- what is still unsolved? \n    submitted by    /u/Cultural-Average3959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y8oyn/d_open_problems_after_gpt4_capabilities/",
          "publishedOn": "2023-10-02T21:16:21.000Z",
          "wordCount": 2573,
          "title": "[D] open problems after GPT4 capabilities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y7r0w/d_hoeffdings_inequality_does_it_make_sense/",
          "author": null,
          "description": "According to it, increasing the hypotheses set loosens the upper bound between in-sample and out-of-sample error.\n ​\n Can't we subdivide the hypotheses set to multiple ones, ensuring tighter bounds in general?\n ​\n and generally, have you seen it in use before? I have seen a lot of ML projects without anybody mentioning it or anything theoretical.\n    submitted by    /u/2azo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y7r0w/d_hoeffdings_inequality_does_it_make_sense/",
          "publishedOn": "2023-10-02T20:41:06.000Z",
          "wordCount": 2580,
          "title": "[D] Hoeffdings inequality, does it make sense practically?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y7jpw/p_good_models_to_use_for_multimodal_object/",
          "author": null,
          "description": "So basically I have a dataset with images of vehicles in top down view in both RGB and IR, what are some models I can use for both unimodal and multimodal object detection to compare their performance. Links to GitHub repos would be helpful. Thanks\n    submitted by    /u/Xyber5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y7jpw/p_good_models_to_use_for_multimodal_object/",
          "publishedOn": "2023-10-02T20:33:15.000Z",
          "wordCount": 2591,
          "title": "[P] Good models to use for multimodal object detection when both the modalities are image based or some models which support ensembling?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y6ul8/benefits_of_converting_dicom_images_to_pngs_p/",
          "author": null,
          "description": "I try to understand what are the benefits to convert DICOM images to PNG's.\n Context:\n I have DICOM images which I already extracted the useful meta-data I want to use.\n Those images are for a task, classification-detection pipeline of some disease.\n So as I already asked, what are the benefits of converting those DICOM files to PNG's rather then just using pydicom and the dicom pixel_array?\n Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.\n If I understand how networks actually works, they get as input an array of pixels as floating point numbers no? So what's the differences between DICOM pixel_array to PNG's pixel array and numpy array or tensor? both are eventually will be fed to the network as a tensor of floating numbers.\n Is the reason is because PNG's are usually faster to train?\n Is the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?\n Is the reason is because PNG's are the format many pre-trained models expect to? (I write this knowing it's 99% not true, as mentioned the tensor thing)\n Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)\n    submitted by    /u/01jasper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y6ul8/benefits_of_converting_dicom_images_to_pngs_p/",
          "publishedOn": "2023-10-02T20:07:29.000Z",
          "wordCount": 2743,
          "title": "Benefits of converting DICOM images to PNG's [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y5cra/d_what_kind_of_distribution_is_this/",
          "author": null,
          "description": "Hey guys,\n I am wondering what kind of distribution my data are following? I want to fit a distribution function to them and use this fitted distribution function to generate new samples with a given mean and standard deviation (python). Any tips for this?\n Happy to hear your suggestions :) \n https://preview.redd.it/kdcftvpq8urb1.png?width=408&format=png&auto=webp&s=6163b9f571069e098c9e9a609c3d1cb9910fe1fb\n    submitted by    /u/Tigmib  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y5cra/d_what_kind_of_distribution_is_this/",
          "publishedOn": "2023-10-02T19:10:29.000Z",
          "wordCount": 2575,
          "title": "[D] What kind of distribution is this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y5bk2/r_efficient_streaming_language_models_with/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17453\n Github: https://github.com/mit-han-lab/streaming-llm\n Abstract:\n  \nDeploying Large Language Models (LLMs) in streaming applications such as multi-round dialogue, where long interactions are expected, is urgently needed but poses two major challenges. Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Window attention, where only the most recent KVs are cached, is a natural approach -- but we show that it fails when the text length surpasses the cache size. We observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of wind…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y5bk2/r_efficient_streaming_language_models_with/",
          "publishedOn": "2023-10-02T19:09:13.000Z",
          "wordCount": 2792,
          "title": "[R] Efficient Streaming Language Models with Attention Sinks - Meta AI 2023 - StreamingLLM enables Llama-2, Falcon and Pythia to have an infinite context length without any fine-tuning! Allows streaming use of LLMs!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y3r7t/project_i_just_released_an_opensource_package/",
          "author": null,
          "description": "You just give it any PyTorch model (as-is, no changes needed), and it spits out a data structure with the activations of any layer you want, along with a bunch of metadata about the model and each layer and an optional automatic visualization of the model's computational graph. I hope this greatly speeds up the process of extracting features from models for further analysis, and also serves as an aid in quickly understanding new models. I also hope it'd be helpful for teaching purposes, too. It is meant to work for any PyTorch model whatsoever and I've tested it on hundreds of models (see the \"model menagerie\" of visualizations below), though it's always possible I've missed some edge case or another.\n Hope it helps you out--I'm still actively developing it, so let me know if there's anything on your wishlist!\n https://preview.redd.it/k37nhejvxtrb1.png?width=640&format=png&auto=webp&s=5713a8711110644794e2264d84dd479ede861c5e\n GitHub Repo\n Twitter Thread\n Paper\n CoLab Tutorial\n Gallery of Model Visuals\n    submitted by    /u/therealjmt91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y3r7t/project_i_just_released_an_opensource_package/",
          "publishedOn": "2023-10-02T18:08:31.000Z",
          "wordCount": 2704,
          "title": "[Project] I just released an open-source package, TorchLens, that can extract the activations/metadata from any PyTorch model, and visualize its structure, in just one line of code. I hope it helps you out!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y1rxz/d_why_vision_tranformers/",
          "author": null,
          "description": "Transformers have been the new kid on the block, easy to see why with LLMs and and sequential output generation, but I still don't know why vision transformers based on ViT are so hot in the field right now. From my understanding, CNNs are just vastly better than transformers for vision tasks, as its inductive biases allows it to determine the relationship between neighboring features of an image via pooling and filters. However, transformers don't have this kind of inductive bias, and as a result, take much more data and compute to reach similar levels of performance.\n I read this survey paper on Vision Transformers here: https://arxiv.org/pdf/2012.12556.pdf, which has the performance of CNNs vs various transformer models for CV. Comparing even the best vision transformers to the classic …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y1rxz/d_why_vision_tranformers/",
          "publishedOn": "2023-10-02T16:51:58.000Z",
          "wordCount": 2860,
          "title": "[D] Why Vision Tranformers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16y18co/r_toolintegrated_reasoning_a_new_approach_for/",
          "author": null,
          "description": "When trying to get language models to solve complex math problems, researchers kept running into limits. Models like GPT-3 and ChatGPT still struggle with advanced algebra, calculus, and geometry questions. The math is just too abstract and symbol-heavy for them.\n To break through this barrier, researchers from Tsinghua University and Microsoft taught models to combine natural language reasoning with calling external math tools.\n The key is their new \"tool-integrated reasoning\" format. Models generate a natural language plan first, then write code to invoke tools like SymPy to solve equations. They take the output results and continue verbal reasoning.\n By interleaving natural language and symbolic computations, they get the best of both worlds - semantic understanding from language models and rigorous math from tools.\n They trained versions of the LLaMA model this way, producing their Tool-Integrated Reasoning Agent (TORA). They present some strong results:\n  \nIn evaluations on 10 math datasets, TORA substantially outperformed prior state-of-the-art methods, achieving 13-19% higher accuracy on average.\n On one competition test, TORA-7B scored 40% accuracy, beating the previous best model by 22 percentage points.\n  \nThis demonstrates that integrating tools directly into the reasoning process can significantly enhance mathematical capabilities, even for large models like GPT-4.\n However, tough problems involving geometry and advanced algebra are still there. New techniques for symbolic reasoning and spatial understanding will likely be needed to push further.\n Overall though, tool integration seems a promising path to improve reasoning skills. Applying this to other domains like logic and programming could also be impactful.\n TLDR: Teaching language models to use math tools helps them solve way more complex problems.\n Full Paper Summary\n arXiv Link\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16y18co/r_toolintegrated_reasoning_a_new_approach_for/",
          "publishedOn": "2023-10-02T16:30:09.000Z",
          "wordCount": 2803,
          "title": "[R] Tool-Integrated Reasoning: A New Approach for Math-Savvy LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xy554/p_awesome_ai_developer_productivity_github_repo/",
          "author": null,
          "description": "Hello everyone,\n We've begun gathering a variety of AI coding tools used in one place to make things easier for everyone. We're inviting everyone to check out our collection, and maybe even add tools you find useful.\n You can find the repository here: https://github.com/gaborsoter/awesome-ai-dev-productivity\n Feel free to explore and contribute! \n    submitted by    /u/BootstrapGuy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xy554/p_awesome_ai_developer_productivity_github_repo/",
          "publishedOn": "2023-10-02T14:29:17.000Z",
          "wordCount": 2581,
          "title": "[P] Awesome AI developer productivity Github repo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xx1r2/r_on_the_biometric_capacity_of_generative_face/",
          "author": null,
          "description": "We developed a statistical model to estimate “How many unique identities can a generative face model generate?” without exhaustively generating a lot of faces.\n Abstract: There has been tremendous progress in generating realistic faces with high fidelity over the past few years. Despite this progress, a crucial question remains unanswered: “Given a generative face model, how many unique identities can it generate?” In other words, what is the biometric capacity of the generative face model? A scientific basis for answering this question will benefit evaluating and comparing different generative face models and establish an upper bound on their scalability. This paper proposes a statistical approach to estimate the biometric capacity of generated face images in a hyperspherical feature space. We employ our approach on multiple generative models, including unconditional generators like StyleGAN, Latent Diffusion Model, and “Generated Photos,” as well as DCFace, a class-conditional generator. We also estimate capacity w.r.t. demographic attributes such as gender and age. Our capacity estimates indicate that (a) under ArcFace representation at a false acceptance rate (FAR) of 0.1%, StyleGAN3 and DCFace have a capacity upper bound of 1.43 million and 11,900, respectively; (b) the capacity reduces drastically as we lower the desired FAR with an estimate of 17,960 and 562 at FAR of 1% and 10%, respectively, for StyleGAN3; (c) there is no discernible disparity in the capacity w.r.t gender; and (d) for some generative models, there is an appreciable disparity in the capacity w.r.t age.\n Paper: https://arxiv.org/abs/arXiv:2308.02065\n Code: https://github.com/human-analysis/capacity-generative-face-models\n    submitted by    /u/VishDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xx1r2/r_on_the_biometric_capacity_of_generative_face/",
          "publishedOn": "2023-10-02T13:45:19.000Z",
          "wordCount": 2779,
          "title": "[R] On the Biometric Capacity of Generative Face Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xtrbv/p_comgra_a_library_for_debugging_and/",
          "author": null,
          "description": "I'm a machine learning engineer and researcher. I got fed up with how difficult it is to understand why neural networks behave the way they do, so i wrote a library to help with it.\n Comgra (computation graph analysis) is a library you can use with pytorch to extract all the tensor data you care about and visualize it graphically in a browser.\n This allows for a much more detailed analysis of what is happening than the usual approach of using tensorboard. You can go investigate tensors as training proceeds, drill down into individual neurons, inspect single data sets that are of special interest to you, track gradients, compare statistics between different training runs, and more.\n This tool has saved me a ton of time in my research by letting me check my hypotheses much more quickly than normal and by helping me understand how the different parts of my network really interact.\n I first published this a month ago and have made some improvements since then. I would be happy to hear even more feedback!\n My goal is to make this the go-to library used both by novices who want to understand what's going on under the hood, and by researchers in neural architecture design.\n    submitted by    /u/Smart-Emu5581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xtrbv/p_comgra_a_library_for_debugging_and/",
          "publishedOn": "2023-10-02T11:08:44.000Z",
          "wordCount": 2740,
          "title": "[P] Comgra: A library for debugging and understanding neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xshji/d_the_most_complete_audio_ml_toolkit/",
          "author": null,
          "description": "Hugging Face Transformers is a complete audio toolkit that provides state-of-the-art models for all audio tasks, including TTS, ASR, audio embeddings, audio classification and music generation.\n All you need to do is install the Transformers package:\n pip install --upgrade transformers \n And then all of these models can be used in just 3 lines of code:\n ​\n TTS\n Example usage:\n from transformers import pipeline generator = pipeline(\"text-to-speech\", model=\"suno/bark-small\") speech = generator(\"Hey - it's Hugging Face on the phone!\") \n Available models:\n  \nBark https://huggingface.co/suno/bark\n MMS TTS https://huggingface.co/facebook/mms-tts-eng\n VITS https://huggingface.co/kakao-enterprise/vits-vctk\n SpeechT5 https://huggingface.co/microsoft/speecht5_tts\n And more! https://huggingface.co/mo…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xshji/d_the_most_complete_audio_ml_toolkit/",
          "publishedOn": "2023-10-02T09:54:19.000Z",
          "wordCount": 2799,
          "title": "[D] The most complete Audio ML toolkit 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.17421 \n Youtube: https://youtu.be/Q0pP782dSh0?si=MiJAlK5k-KEyQ-Zr \n Abstract:\n  \nLarge multimodal models (LMMs) extend large language models (LLMs) with multi-sensory skills, such as visual understanding, to achieve stronger generic intelligence. In this paper, we analyze the latest model, GPT-4V(ision), to deepen the understanding of LMMs. The analysis focuses on the intriguing tasks that GPT-4V can perform, containing test samples to probe the quality and genericity of GPT-4V's capabilities, its supported inputs and working modes, and the effective ways to prompt the model. In our approach to exploring GPT-4V, we curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks. Observations from these samples demonstrate that GPT-4V's unprecedented ability in processing arbitrarily interleaved multimodal inputs and the genericity of its capabilities together make GPT-4V a powerful multimodal generalist system. Furthermore, GPT-4V's unique capability of understanding visual markers drawn on input images can give rise to new human-computer interaction methods such as visual referring prompting. We conclude the report with in-depth discussions on the emerging application scenarios and the future research directions for GPT-4V-based systems. We hope that this preliminary exploration will inspire future research on the next-generation multimodal task formulation, new ways to exploit and enhance LMMs to solve real-world problems, and gaining better understanding of multimodal foundation models. \n  \nhttps://preview.redd.it/qkytzg2rjqrb1.jpg?width=511&format=pjpg&auto=webp&s=fc306dc6ae64100e993639f8e27583b809bf8a5c\n https://preview.redd.it/z4kq0l2rjqrb1.jpg?width=507&format=pjpg&auto=webp&s=d4fda59456846fa7a6c9b318b21fc9c544bd2b68\n https://preview.redd.it/1ptrkk2rjqrb1.jpg?width=712&format=pjpg&auto=webp&s=2b44fbc949e76fdf20d05b1236f56c87ba5efece\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/",
          "publishedOn": "2023-10-02T06:45:31.000Z",
          "wordCount": 2750,
          "title": "[R] The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) - Microsoft 2023 - 166 Pages!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xm3mt/p_nanophi_implementing_some_of_the_success_of/",
          "author": null,
          "description": "Hi, i'm trying to replicate at least some of the success of Phi 1.5 on a model 10x smaller, gpt-2 124m.\n I have started with model finetuning, and have a simple github with roadmap, https://github.com/VatsaDev/NanoPhi, check it out there!\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xm3mt/p_nanophi_implementing_some_of_the_success_of/",
          "publishedOn": "2023-10-02T03:35:26.000Z",
          "wordCount": 2574,
          "title": "[P] NanoPhi, Implementing some of the success of Phi-1.5, with GPT-2(124m)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xg8nh/r_the_unsolved_mystery_at_the_heard_of_the_how_to/",
          "author": null,
          "description": "submitted by    /u/CellWithoutCulture  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xg8nh/r_the_unsolved_mystery_at_the_heard_of_the_how_to/",
          "publishedOn": "2023-10-01T23:14:37.000Z",
          "wordCount": 2621,
          "title": "[R] The unsolved mystery at the heard of the \"How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions\" paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/",
          "author": null,
          "description": "Prompt engineering frequently involves trying to encode very specific behaviors into a model to steer it a certain direction. In practice, as requirements become more complex, you often end up with fairly lengthy prompts, especially when using methods like RAG. I was wondering, how effective are LLMs at following instructions as the system prompt grows in size and complexity?\n I did some quick experiments on this and found that, unsurprisingly, GPT-4 can follow a lot of rules (up to 50) quite accurately. But even GPT-3.5 slowly degrades and Llama-2-70b-chat starts to fail after just a few rules.\n Comparison of performance metrics over increasing rule counts, demonstrating GPT-4's consistent performance and a decline in accuracy for GPT-3.5 and Llama-2-70b-chat.\n These results are based on …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/",
          "publishedOn": "2023-10-01T20:10:40.000Z",
          "wordCount": 3055,
          "title": "[D] How many instructions can LLMs handle before they start to ignore them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/",
          "author": null,
          "description": "Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge. LangDiversity is an implementation of \"diversity measures\" that are domain independent and can be used to measure the uncertainty in the result of a language model.\n Type pip install langdiversity\n Video: https://www.youtube.com/watch?v=86J_K9mR7lw\n Web: https://neurosymbolic.asu.edu/llm-correction/\n Visit https://github.com/lab-v2/langdiversity\n Read the paper: https://arxiv.org/abs/2308.11189\n https://preview.redd.it/rb0xg1ly8nrb1.png?width=1021&format=png&auto=webp&s=8e57056d24327ca2987abea12a7a9066a825738b\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/",
          "publishedOn": "2023-10-01T19:37:59.000Z",
          "wordCount": 2651,
          "title": "[R] LangDiversity: software to identify LLM errors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x975p/p_simplest_model_to_run_with_limited_hardware/",
          "author": null,
          "description": "We want to run (not train, i.e. think single forward pass only) an ML algorithm on a machine with very limited resources.\n Which model could we use to show off the possibilities?\n If the benchmark is an MLP for binary image classification, what else could we do with a similar scale of operations?\n E.g.\n Which model is the simplest for e.g. text-to-image generation?\n Any other ML models that are simple enough to run and if initialized with good params, does something impressive\n    submitted by    /u/2i2i_tokenized_time  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x975p/p_simplest_model_to_run_with_limited_hardware/",
          "publishedOn": "2023-10-01T18:46:32.000Z",
          "wordCount": 2675,
          "title": "[P] Simplest model to run with limited hardware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x91b9/p_deep_memory_a_way_to_boost_retrieval_accuracy/",
          "author": null,
          "description": "submitted by    /u/davidbun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x91b9/p_deep_memory_a_way_to_boost_retrieval_accuracy/",
          "publishedOn": "2023-10-01T18:40:30.000Z",
          "wordCount": 2598,
          "title": "[P] Deep Memory, a Way to Boost Retrieval Accuracy by up to +22% for RAG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x63ce/d_perplexityai_search_feasibility/",
          "author": null,
          "description": "I've been using Perplexity.ai for a bit now when it hit me that I don't understand how they can sustain their business model with search. Stuff like Bing search and Google search cost around $5 or more per 1000 searches, so how can they even afford to do this kind of search. Do they have their own search index.\n Also, I don't know how they pull in the data from these sources so fast? I've played around with some things like this with Langchain with retrieval, but the speed of splitting and tokenizing website html is not very fast. Have they already pre-scrapped the websites from the search results and tokenized them for LLM retrieval?\n    submitted by    /u/dragon18456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x63ce/d_perplexityai_search_feasibility/",
          "publishedOn": "2023-10-01T16:47:35.000Z",
          "wordCount": 2704,
          "title": "[D] Perplexity.ai Search Feasibility",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x5d0h/metagpt_use_case_d/",
          "author": null,
          "description": "Guys, i am currently working building a project, there are certain tasks like building a ml model using certain use-cases. I wish to automate this task, do u think metagpt is a good fit for the same. \n Let me know if you need any further information!!\n EDIT: \n One of the tasks my app needs to do is to convert image to text (aim to implement image captioning). So, if i give metaGPT the requirements for my project, is it possible it will give me the code which I need. I need to save certain tasks here so that I can focus more on operation and design side. \n Edit: it seems, such kind of vague questions are not encouraged on this platform, I will work and will straigh away ask questions which are quite good and meet the standards of this platform. Thanks!!\n Thanks!!\n Always have a massive respect for this community!!\n    submitted by    /u/aristotleTheFake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x5d0h/metagpt_use_case_d/",
          "publishedOn": "2023-10-01T16:17:20.000Z",
          "wordCount": 2740,
          "title": "Metagpt use case [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x2o47/r_meta_inria_researchers_discover_that_explicit/",
          "author": null,
          "description": "When visualizing the inner workings of vision transformers (ViTs), researchers noticed weird spikes of attention on random background patches. This didn't make sense since the models should focus on foreground objects.\n By analyzing the output embeddings, they found a small number of tokens (2%) had super high vector norms, causing the spikes.\n The high-norm \"outlier\" tokens occurred in redundant areas and held less local info but more global info about the image.\n Their hypothesis is that ViTs learn to identify unimportant patches and recycle them as temporary storage instead of discarding. This enables efficient processing but causes issues.\n Their fix is simple - just add dedicated \"register\" tokens that provide storage space, avoiding the recycling side effects.\n Models trained with registers have:\n  \nSmoother and more meaningful attention maps\n Small boosts in downstream performance\n Way better object discovery abilities\n  \nThe registers give ViTs a place to do their temporary computations without messing stuff up. Just a tiny architecture tweak improves interpretability and performance. Sweet!\n I think it's cool how they reverse-engineered this model artifact and fixed it with such a small change. More work like this will keep incrementally improving ViTs.\n TLDR: Vision transformers recycle useless patches to store data, causing problems. Adding dedicated register tokens for storage fixes it nicely.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x2o47/r_meta_inria_researchers_discover_that_explicit/",
          "publishedOn": "2023-10-01T14:28:22.000Z",
          "wordCount": 2812,
          "title": "[R] Meta, INRIA researchers discover that explicit registers eliminate ViT attention spikes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x2658/d_multiple_single_class_segmentation_vs_single/",
          "author": null,
          "description": "submitted by    /u/waterstrider123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x2658/d_multiple_single_class_segmentation_vs_single/",
          "publishedOn": "2023-10-01T14:08:42.000Z",
          "wordCount": 2677,
          "title": "[D] Multiple single class segmentation vs single multiclass segmentation models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16x1fzr/r_sota_of_deepshallow_encoderdecoder_llms_for/",
          "author": null,
          "description": "There's some evidence [1] [2] that it's possible to run text2text language model at substantially (potentially on the order of magnitude) better inference speed by keeping the decoder shallow.\n I'm curious whether some general reasoner SOTA (small model for machine translation available at [3]) style models are publicly available for this sort of thing.\n If not, how would one go about training one?\n Would it be necessary to do it entirely from scratch (extremely costly)? Or would it be possible to take, say, Flan-UL2 (20B), chop off its decoder, and train a much smaller decoder on top of it with the UL2 encoder frozen (ie how one trains adapter layers).\n Assuming the decoder hyperparameters are kept small, would this be possible within reasonable compute budget? Would that even meaningfully converge with small amount of compute (assuming same training objective as is for UL2)?\n Would the strength (ie somewhat comparable to 10B if we cut 20B in half) transfer from the SOTA encoder, or would cutting off half of the model layers kneecap it too badly?\n [1] https://arxiv.org/pdf/2006.10369.pdf\n [2] https://aclanthology.org/2023.sustainlp-1.6.pdf\n [3] https://github.com/snoop2head/Deep-Encoder-Shallow-Decoder\n    submitted by    /u/upalse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16x1fzr/r_sota_of_deepshallow_encoderdecoder_llms_for/",
          "publishedOn": "2023-10-01T13:37:56.000Z",
          "wordCount": 2769,
          "title": "[R] SOTA of Deep-Shallow Encoder-Decoder LLMs for fast inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wytmy/d_duplicating_layers_in_large_models/",
          "author": null,
          "description": "Is there any notable work on duplicating layers in large feed forward models? In contrast to e.g. the brain which is essentially a directed graph most networks utilized nowerdays use a feed forward approach. E.g. transformers are able to attend to past tokens, but generate the tokens in a way where for a given token a given weight is not utilized at different stages in the feed forward pass. In my intuition this would lead to an issue where concepts (factual data as well as learned \"algorithms\") might be duplicated as they are needed at different depths in the generation process and are sequentially dependent on one another. This does not directly make the model less capable, as it might learn the same concept at two layers sufficiently well, but it reduces the data and parameter efficiency and and might impact generalization capabilities. Using a full on brain like graph might be hard to implement/optimize/scale on current hardware and is tricky with the backprop. But is there any work on duplicating a few layers, placing them at different depths in large models. I would guess that this would be more impactful for large models. One would essentially trade compute for better data efficiency.\n    submitted by    /u/floriv1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wytmy/d_duplicating_layers_in_large_models/",
          "publishedOn": "2023-10-01T11:34:38.000Z",
          "wordCount": 2788,
          "title": "[D] Duplicating layers in large models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wn8qu/n_introducing_raudioai_any_ai_you_can_hear/",
          "author": null,
          "description": "I couldn't find any AI sub dedicated to audio, so I’ve created r/AudioAI to serve as a hub for everything at the intersection of artificial intelligence and the world of sounds.\n AI-driven music, speech, audio production, and all other AI audio technologies.\n If anyone wants to be part of mod, let me know!\n    submitted by    /u/chibop1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wn8qu/n_introducing_raudioai_any_ai_you_can_hear/",
          "publishedOn": "2023-10-01T00:52:01.000Z",
          "wordCount": 2646,
          "title": "[n] Introducing r/AudioAI: Any AI You Can Hear!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wjrnu/phandling_categorical_missing_data_in_churn/",
          "author": null,
          "description": "I am working on a telecom dataset where I need to fit a model to for predicting churn(yes or no). There are a lot of categorical data with missing values( total values 7043). What is the best way to handle missing data in this case, is it better to ignore it or any other better imputation method?\n Data columns (total 21 columns): customerID 7043 non-null object gender 7043 non-null object Age 7043 non-null int64 Partner 7043 non-null object Dependents 7043 non-null object tenure 7043 non-null int64 PhoneService 7043 non-null object MultipleLines 6500 non-null object InternetService 6500 non-null object OnlineSecurity 7043 non-null object OnlineBackup 7043 non-null object DeviceProtection 7043 non-null object TechSupport 7043 non-null object StreamingTV 6500 non-null object StreamingMovies 6500 non-null object Contract 6500 non-null object PaperlessBilling 7043 non-null object PaymentMethod 6500 non-null object MonthlyCharges 7043 non-null float64 TotalCharges 7043 non-null object Churn 7043 non-null object \n    submitted by    /u/guyloveskissing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wjrnu/phandling_categorical_missing_data_in_churn/",
          "publishedOn": "2023-09-30T22:22:07.000Z",
          "wordCount": 2741,
          "title": "[P]Handling categorical missing data in churn prediction model for telecom data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wf3lk/d_how_can_you_estimate_inference_speed_of_a_nn/",
          "author": null,
          "description": "How, outside of testing, do you estimate how quickly a specific model will run on some hardware? Anything about time is rarely mentioned in papers and if it is, it's more likely to talk about training, unless authors are specifically proud of their speed (like YOLO). Even less so in any README.\n Some way to translate numbers of parameters into seconds on a given GPU/CPU, any rules of thumb better than just setting up everything every time?\n    submitted by    /u/teleoflexuous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wf3lk/d_how_can_you_estimate_inference_speed_of_a_nn/",
          "publishedOn": "2023-09-30T19:10:51.000Z",
          "wordCount": 2676,
          "title": "[D] (How) Can you estimate inference speed of a NN model on given hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wcbhg/d_how_do_i_begin_with_ai/",
          "author": null,
          "description": "I'm fairly new to the Al domain. I've decent python knowledge. I've gone through a lot of YouTube tutorials and got stuck in the tutorial hell. After struggling through hours of videos came here as my only last hope !!. How do I begin? What python frameworks should I learn? Which particular books should I refer ?\n    submitted by    /u/Dry_Ad_3887  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wcbhg/d_how_do_i_begin_with_ai/",
          "publishedOn": "2023-09-30T17:15:53.000Z",
          "wordCount": 2650,
          "title": "[D] How do I begin with AI ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16wbqcd/d_struggling_to_get_interviews_what_to_do/",
          "author": null,
          "description": "Edit: I am a USA citizen so no need for sponsorship.\n I have 4 yoe in a start up company and a phd four publications 2 in high level math journals and 2 CV/DL papers in A journals and also 4 patents. I have experience with most common Cv tasks eg object detection, Multi object tracking, 2d/3d human pose estimation and monocular depth estimation. I’m well versed in typical network building blocks eg conv nets, FFNs, transformers, Diffusion etc. I have a little experience with NLP like NLTK and TTS networks. Also some other general dev technologies like ec2,s3,sql,mongoose, etc. \n That all being said I can’t seem to even get interviews these days just straight rejections not talking to recruiters. On the other hand in 2020, I was just searching for jobs passively and had something like a 75% success rate with getting interviews. I know the job market has changed but I’m a lot more experienced at this time than then and having abysmal luck.\n Anyone have any advice would be happy to share my resume if that would make it easier to give advice. Also open to hearing what other technologies o should/could learn.\n    submitted by    /u/AbjectDrink3276  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16wbqcd/d_struggling_to_get_interviews_what_to_do/",
          "publishedOn": "2023-09-30T16:51:12.000Z",
          "wordCount": 2789,
          "title": "[D] Struggling to get interviews what to do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w9kz7/arxiv_dives_segment_anything/",
          "author": null,
          "description": "Every Friday for the past few months we’ve been hosting a public paper club called “Arxiv Dives”. We pick a paper and dive deep into it and chat about it as a group.\n There are a lot of gems of knowledge hidden in these research papers, and the main motivation is simply to keep up with most impactful techniques in the field by taking the time to dive in and discuss. \n The attendees so far have been great, and would love for anyone is interested to join!\n https://lu.ma/oxenbookclub\n    submitted by    /u/FallMindless3563  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w9kz7/arxiv_dives_segment_anything/",
          "publishedOn": "2023-09-30T15:20:55.000Z",
          "wordCount": 2691,
          "title": "Arxiv [D]ives - Segment Anything",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w7lcl/d_what_exactly_are_the_compute_requirements_for/",
          "author": null,
          "description": "Hi, New to ML, I can't find a clear answer to this question. I find references online to a 1.8 trillion parameter model taking up the computational power of a 10B model, yet I also hear that the memory requirements a lot higher for an MoE?\n If I was interested in training/inferencing, for example, a 15M dense model, or a 60M MoE with 4 15M experts. whats the difference gonna be?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w7lcl/d_what_exactly_are_the_compute_requirements_for/",
          "publishedOn": "2023-09-30T14:00:29.000Z",
          "wordCount": 2671,
          "title": "[D] What exactly are the compute requirements for training a dense model versus an MoE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w3ydj/d_how_close_are_we_to_neurosymbolic_architectures/",
          "author": null,
          "description": "I’m new to AI/ML and my understanding is that (1) LLMs are SOTA in many tasks, and their short comings, such as ~70% accuracy, hallucinations, inability to learn from small samples etc, are well known. (2) Neuro-symbolic approaches are apparently the way to get accuracy to 100% and solve other shortcomings.\n So question is (3) What are the promising research in LLMs+Symbolic architectures? (4) And how close is it to production, rather than academic? (5) Do we need non-LLM based architectures instead?\n    submitted by    /u/reeldeele  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w3ydj/d_how_close_are_we_to_neurosymbolic_architectures/",
          "publishedOn": "2023-09-30T11:00:41.000Z",
          "wordCount": 2673,
          "title": "[D] How close are we to Neuro-Symbolic architectures that are 100% accurate?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w2jtj/d_how_to_integrate_fine_tuned_llama_2_in_website/",
          "author": null,
          "description": "I'm absolute beginner in Machine Learning. Me and My team are building a Chat Bot that recommends medicine based on symptoms, for that we are fine tuning LLAMA 2. Uploading BOOKS to train and we will ask question based on that books. SomeHow I got code on github to FineTune LLAMA 2. But how can I Integrate in my website ? How to connect it in my web app. Need some guidance. We have submission in 2 weeks.\n If anyone is willing to mentor us in this project or just guide what to do.\n    submitted by    /u/BookAny3024  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w2jtj/d_how_to_integrate_fine_tuned_llama_2_in_website/",
          "publishedOn": "2023-09-30T09:36:34.000Z",
          "wordCount": 2690,
          "title": "[D] How to Integrate fine tuned LLAMA 2 in website ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w0tse/d_what_algorithms_to_use_text_classification/",
          "author": null,
          "description": "I have some data - twitter description of an event in text and the event itself. If I have 100000 tweets in column X and a category in Y - e.g sporting event review, movie review, news, etc what is the best algorithm to match them. Should I make the description a bag of words and depending on the word frequency I can train a ML model (random forest,svm,etc.) or can the algorithm take into account the order.\n    submitted by    /u/AnyJello605  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w0tse/d_what_algorithms_to_use_text_classification/",
          "publishedOn": "2023-09-30T07:46:50.000Z",
          "wordCount": 2670,
          "title": "[D] What algorithms to use text classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16w08p1/d_deploy_the_mistral_7b_generative_model_on_an/",
          "author": null,
          "description": "Hello,\n The Mistral 7b AI model beats LLaMA 2 7b on all benchmarks and LLaMA 2 13b in many benchmarks. It is actually even on par with the LLaMA 1 34b model.\n So I made a quick video about how to deploy this model on an A10 GPU on an AWS EC2 g5.4xlarge instance:\n https://nlpcloud.com/deploy-mistral-7b-on-a10-gpu-on-aws.html\n I hope it will be useful. If you have recommendations about how to improve this video please don't hesitate to let me know, that will be very much appreciated!\n Julien\n    submitted by    /u/juliensalinas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16w08p1/d_deploy_the_mistral_7b_generative_model_on_an/",
          "publishedOn": "2023-09-30T07:11:38.000Z",
          "wordCount": 2683,
          "title": "[D] Deploy the Mistral 7b Generative Model on an A10 GPU on AWS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vvh84/d_cider_values_in_pali_model_and_xm_3600_dataset/",
          "author": null,
          "description": "I am reading PaLI: A Jointly-Scaled Multilingual Language-Image Model . In their table 2 (page 6), it's reported that Thapliyal et al. (2022) (0.8B) model got 57.6 of CIDEr on XM 3600 for English. Thapliyal et al. (2022) is Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset. However in this paper, the CIDEr values are reported less than 1. For example, the largest model got 0.584 of CIDEr on XM 3600 for English.\n Could someone explain to me why those values have great differences?\n    submitted by    /u/KingsmanVince  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vvh84/d_cider_values_in_pali_model_and_xm_3600_dataset/",
          "publishedOn": "2023-09-30T02:46:43.000Z",
          "wordCount": 2678,
          "title": "[D] CIDEr values in PaLI model and XM 3600 dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vshvy/r_pathway_to_selflearning_mathematics_and/",
          "author": null,
          "description": "Hey everyone. I am very passionate about getting in ML research and was wondering what the learning pathway was, particularly with regards to the theoretical Math and Statistics involved.\n For context:\n  \nI am a second year undergraduate. By the end of this year, I will have taken and finished A Multivariable Calculus with Proofs course, so that is my current starting point.\n I have been working with ML for the last 3 years and am proficient in Python and frameworks like PyTorch.\n I have also made my own implementation of several research papers (LSTMs, GRUs, Transformers, ELMo, BERT, GPT, as well as a few computer vision papers).\n  \nI have a good general intuition of how deep learning works, but I want to formalise this knowledge with the adequate mathematical background so that I can eventually pursue a career in research. I understand that I have plenty of time until I reach there, and I am willing to dedicate it to grinding out the math and statistical knowledge required.\n I have done my research on this sub and other forums, and here are a few resources that stood out:\n  \nMathematics for Machine Learning by Deisenroth, Faisal and Ong\n Advanced Calculus of Several Variables by C. H. Edwards Jr.\n Mathematical Methods Lecture Notes from Imperial College by Deisenroth and Cheraghchi\n The original information theory paper by Shannon\n The Elements of Statistical Learning by Hastie, Tibshirani and Friedman\n Pattern Recognition and Machine Learning by Bishop\n The Probabalistic Machine Learning Series by Kevin P. Murphy\n Deep Learning by Goodfellow, Bengio and Courville\n Mathematics of Machine Learning on MIT OCW (here)\n  \nMy question is, what order should I start self-learning in, given the (somewhat limited) background knowledge I have? Also, are there any other resources that would help?\n    submitted by    /u/Far_Clothes_5054  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vshvy/r_pathway_to_selflearning_mathematics_and/",
          "publishedOn": "2023-09-30T00:30:39.000Z",
          "wordCount": 2888,
          "title": "[R] Pathway to self-learning mathematics and statistics for ML research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vs7qd/d_what_is_the_best_opensource_framework_to_create/",
          "author": null,
          "description": "Hi everyone,\n With the different data points, such as phi-1.5 performance being as good as 7b models on some tasks, it seems to be plausible that small models can be quite capable on specific tasks.\n I am working on BlindChat, an open-source and private solution to run small LLMs on your browser and I am interested in fine-tuning a phi-1.5 on some domain specific data.\n I am thinking of having an approach similar to the researchers of the phi paper, which is creating a high quality dataset using GPT3.5 / GPT4. \n Do you know good open-source frameworks that make it easy to create a high quality data for a specific task using an existing large model, like GPT3.5/4 or Llama 2 70b?\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vs7qd/d_what_is_the_best_opensource_framework_to_create/",
          "publishedOn": "2023-09-30T00:18:49.000Z",
          "wordCount": 2726,
          "title": "[D] What is the best open-source framework to create a synthetic and domain specific dataset for fine-tuning small models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vrts5/p_how_do_i_train_or_tune_an_llm_like_llama_for_my/",
          "author": null,
          "description": "I want to tune Facebook's LLaMA or any available LLM model to be able to answer questions about my business. The idea is to provide a prompt of the business and some Q&As, then based on the provided information, the AI chatbot will answer customers who ask questions about the business. If the answers to the questions are not known or the question is not relevant, the bot should say \"I dont know\".\n    submitted by    /u/the_aceix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vrts5/p_how_do_i_train_or_tune_an_llm_like_llama_for_my/",
          "publishedOn": "2023-09-30T00:03:02.000Z",
          "wordCount": 2672,
          "title": "[P] How do I train or tune an LLM like LLaMA for my business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vq1a0/r_drive_like_a_human_rethinking_autonomous/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2307.07162\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vq1a0/r_drive_like_a_human_rethinking_autonomous/",
          "publishedOn": "2023-09-29T22:49:36.000Z",
          "wordCount": 2594,
          "title": "[R] Drive Like a Human: Rethinking Autonomous Driving with Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vosgf/research_resource_to_query_ml_and_llm_based/",
          "author": null,
          "description": "Made a repo for you all to try using a collaborative AI tool which includes 100+ papers on LLM-Based-Agents. You can try out the repo here: https://www.collama.ai/varun/llm-based-agents\n    submitted by    /u/_llama2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vosgf/research_resource_to_query_ml_and_llm_based/",
          "publishedOn": "2023-09-29T22:00:57.000Z",
          "wordCount": 2616,
          "title": "[Research] - Resource to query ML and LLM based research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vnzgc/d_choosing_the_best_learning_model_for_a_start_up/",
          "author": null,
          "description": "Straight off the bat: I am not very familiar but was tasked to find a suggest a reasonable model for our need.\n Here is a bit what I read:\n  \nhttps://www.obviously.ai/post/how-to-choose-the-right-ai-model-for-your-application\n https://www.addevice.io/blog/ai-framework-for-app-development\n  \nThe app that I am working on is an education app, and the purpose of the AI would be to (at least in terms of priority) generate a post subject line / topic to discuss.\n The company is super small, so money is important. JS is being used mainly at the moment.\n What would be a good choice for a small start up to generate topics for an education app used by schools?\n At least any ideas or things to consider would be wonderful to get my rabbit hole dive started! Thanks.\n    submitted by    /u/Willy988  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vnzgc/d_choosing_the_best_learning_model_for_a_start_up/",
          "publishedOn": "2023-09-29T21:30:19.000Z",
          "wordCount": 2719,
          "title": "[D] Choosing the best learning model for a start up app?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vmmxz/r_gsgen_textto3d_using_gaussian_splatting/",
          "author": null,
          "description": "Project Page\n Paper\n Code \n  \nIn this paper, we present Gaussian Splatting based text-to-3D generation (GSGEN), a novel approach for generating high-quality 3D objects. Previous methods suffer from inaccurate geometry and limited fidelity due to the absence of 3D prior and proper representation. We leverage 3D Gaussian Splatting, a recent state-of-the-art representation, to address existing shortcomings by exploiting the explicit nature that enables the incorporation of 3D prior. Specifically, our method adopts a progressive optimization strategy, which includes a geometry optimization stage and an appearance refinement stage. In geometry optimization, a coarse representation is established under a 3D geometry prior along with the ordinary 2D SDS loss, ensuring a sensible and 3D-consistent rough shape. Subsequently, the obtained Gaussians undergo an iterative refinement to enrich details. In this stage, we increase the number of Gaussians by compactness-based densification to enhance continuity and improve fidelity. With these designs, our approach can generate 3D content with delicate details and more accurate geometry. Extensive evaluations demonstrate the effectiveness of our method, especially for capturing high-frequency components.\n  \n   submitted by    /u/Sirisian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vmmxz/r_gsgen_textto3d_using_gaussian_splatting/",
          "publishedOn": "2023-09-29T20:38:01.000Z",
          "wordCount": 2760,
          "title": "[R] Gsgen: Text-to-3D using Gaussian Splatting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vmlg0/d_does_anyone_else_feel_like_mojo_isnt_getting/",
          "author": null,
          "description": "https://docs.modular.com/mojo/\n    submitted by    /u/hai_cben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vmlg0/d_does_anyone_else_feel_like_mojo_isnt_getting/",
          "publishedOn": "2023-09-29T20:36:20.000Z",
          "wordCount": 2599,
          "title": "[D] Does anyone else feel like MOJO isn't getting the attention it deserves?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vkwhk/p_carton_run_any_ml_model_from_any_programming/",
          "author": null,
          "description": "Hi! I just open-sourced a project that I've been working on for a while and wanted to see what you think!\n The goal of Carton (https://carton.run) is to let you use a single interface to run any machine learning model from any programming language.\n It’s currently difficult to integrate models that use different technologies (e.g. TensorRT, Ludwig, TorchScript, JAX, GGML, etc) into your application, especially if you’re not using Python. Even if you learn the details of integrating each of these frameworks, running multiple frameworks in one process can cause hard-to-debug crashes.\n Ideally, the ML framework a model was developed in should just be an implementation detail. Carton lets you decouple your application from specific ML frameworks so you can focus on the problem you actually want to solve.\n At a high level, the way Carton works is by running models in their own processes and using an IPC system to communicate back and forth with low overhead. Carton is primarily implemented in Rust, with bindings to other languages. There are lots more details linked in the architecture doc below.\n Importantly, Carton uses your model’s original underlying framework (e.g. PyTorch) under the hood to actually execute the model. This is meaningful because it makes Carton composable with other technologies. For example, it’s easy to use custom ops, TensorRT, etc without changes. This lets you keep up with cutting-edge advances, but decouples them from your application.\n I’ve been working on Carton for almost a year now and I open sourced it on Wednesday!\n Some useful links:\n  \nWebsite, docs, quickstart - https://carton.run\n Explore existing models - https://carton.pub\n Repo - https://github.com/VivekPanyam/carton\n Architecture - https://github.com/VivekPanyam/carton/blob/main/ARCHITECTURE.md\n  \nPlease let me know what you think!\n    submitted by    /u/vpanyam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vkwhk/p_carton_run_any_ml_model_from_any_programming/",
          "publishedOn": "2023-09-29T19:28:10.000Z",
          "wordCount": 2874,
          "title": "[P] Carton – Run any ML model from any programming language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vje52/p_location_computation/",
          "author": null,
          "description": "Hi Everyone, \n I’m doing a project where I’m crowdsourcing a lot of location data for a set of location labels and then trying to cluster it for each and using the centroid of the cluster as the most accurate location for that location label. \n The data keeps coming in everyday. I’m not sure when to stop computation. Initially I thought I’ll check the delta between each days centroid computed and if the delta falls under a threshold then stop computing. \n But now I’m thinking if my daily data collected gets marked as outliers, subsequent days centroids won’t have much of a delta and it will pass my convergence condition. \n Any suggestions?\n    submitted by    /u/Longjumping-Song4958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vje52/p_location_computation/",
          "publishedOn": "2023-09-29T18:31:06.000Z",
          "wordCount": 2699,
          "title": "[P] Location Computation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vfuzb/dr_deploying_deep_models_on_memory_constrained/",
          "author": null,
          "description": "Suppose we want to use a deep learning model on a gpu within our app. We want this model to coexist on the gpu with other processes, effectively limit it's possible usage of resources.\n As cuDNN/cuBLAS routines are nondeterministic and possibly dynamically allocate variable amount of memory, how do people manage this problem? Is it a problem at all? Estimating memory usage of deep learning models on gpu is notoriously hard. There is a research paper from Microsoft tackling this problem and they mispredict the usage of memory by 15% on average. Some cpu BLAS libraries like openBLAS or MKL also dynamically allocate the memory, but there are alternatives - LAPACK as far as I know uses only the memory provided by the caller, making it viable option for applications in embedded.\n In safety crit…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vfuzb/dr_deploying_deep_models_on_memory_constrained/",
          "publishedOn": "2023-09-29T16:14:04.000Z",
          "wordCount": 2964,
          "title": "[D][R] Deploying deep models on memory constrained devices",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ve2ij/d_best_sequence_embedding_models/",
          "author": null,
          "description": "Which are currently the best Sentence Embedding pre-trained models out there?\n    submitted by    /u/Uilxitora  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ve2ij/d_best_sequence_embedding_models/",
          "publishedOn": "2023-09-29T15:04:32.000Z",
          "wordCount": 2601,
          "title": "[D] Best Sequence Embedding Models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vd8u8/d_using_gamification_to_demystify_the_ai_blackbox/",
          "author": null,
          "description": "Blog about AI \"black box\" nature and how it can be explained and become engaging to users using gamification. Explained with example from open-appsec an open-source machine learning-based Web Application & API Security product.\n https://www.openappsec.io/post/using-gamification-to-demystify-the-ai-black-box-in-a-waf-product\n https://github.com/openappsec/openappsec\n    submitted by    /u/onirisapp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vd8u8/d_using_gamification_to_demystify_the_ai_blackbox/",
          "publishedOn": "2023-09-29T14:31:37.000Z",
          "wordCount": 2623,
          "title": "[D] Using Gamification to demystify the AI black-box",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vc1kc/project_startup_job_postcontractor_role/",
          "author": null,
          "description": "Hey all!\n I'm in the throws of doing a startup and looking for someone to help build a legal tech platform. I can discuss more in person, but it is intended to be a human/lawyer in the loop workflow tool for complex contract and deal analysis. Base product is built and deployed.\n I'm a former developer turned lawyer with 15 years corporate experiences, and need help/talent/co-founder to help take things to the next level. Ideally you have a mixture of NLP and regular software engineering background and just a very practical approach. If you've played with LLM's all the better.\n Options for cash, equity, larger roles are all on the table. Just looking for the right talent. DM me if you are interested and lets talk about experience, etc.!\n And it seems that tags are turned off in here, so not sure how to tag something as [Project] but I put it in the title.\n    submitted by    /u/pudgyplacater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vc1kc/project_startup_job_postcontractor_role/",
          "publishedOn": "2023-09-29T13:44:05.000Z",
          "wordCount": 2745,
          "title": "[Project] Startup Job Post/Contractor role",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vc0hp/r_realfill_referencedriven_generation_for/",
          "author": null,
          "description": "Project page: https://realfill.github.io/\n Paper: https://arxiv.org/abs/2309.16668\n RealFill is able to complete the image with what should have been there.\n Abstract\n  \nRecent advances in generative imagery have brought forth outpainting and inpainting models that can produce high-quality, plausible image content in unknown regions, but the content these models hallucinate is necessarily inauthentic, since the models lack sufficient context about the true scene. In this work, we propose RealFill, a novel generative approach for image completion that fills in missing regions of an image with the content that should have been there. RealFill is a generative inpainting model that is personalized using only a few reference images of a scene. These reference images do not have to be aligned with the target image, and can be taken with drastically varying viewpoints, lighting conditions, camera apertures, or image styles. Once personalized, RealFill is able to complete a target image with visually compelling contents that are faithful to the original scene. We evaluate RealFill on a new image completion benchmark that covers a set of diverse and challenging scenarios, and find that it outperforms existing approaches by a large margin.\n  \n​\n    submitted by    /u/StrawberryNumberNine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vc0hp/r_realfill_referencedriven_generation_for/",
          "publishedOn": "2023-09-29T13:42:47.000Z",
          "wordCount": 2772,
          "title": "[R] RealFill: Reference-Driven Generation for Authentic Image Completion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vbsqh/r_listen2scene_interactive_materialaware_binaural/",
          "author": null,
          "description": "https://www.youtube.com/watch?v=aNJWCwG-H_U\n    submitted by    /u/Snoo63916  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vbsqh/r_listen2scene_interactive_materialaware_binaural/",
          "publishedOn": "2023-09-29T13:33:19.000Z",
          "wordCount": 2597,
          "title": "[R] Listen2Scene: Interactive material-aware binaural sound propagation for reconstructed 3D scenes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vbs0o/r_m3audiodec_multichannel_multispeaker/",
          "author": null,
          "description": "Paper : https://arxiv.org/abs/2309.07416\n Demo : https://anton-jeran.github.io/MAD/\n Code : https://github.com/anton-jeran/MULTI-AUDIODEC\n    submitted by    /u/Snoo63916  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vbs0o/r_m3audiodec_multichannel_multispeaker/",
          "publishedOn": "2023-09-29T13:32:27.000Z",
          "wordCount": 2601,
          "title": "[R] M3-AUDIODEC: Multi-channel multi-speaker multi-spatial audio codec",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16vbnbt/r_the_future_of_romance_novel_techniques_for/",
          "author": null,
          "description": "submitted by    /u/TobyWasBestSpiderMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16vbnbt/r_the_future_of_romance_novel_techniques_for/",
          "publishedOn": "2023-09-29T13:26:45.000Z",
          "wordCount": 2616,
          "title": "[R] The Future of Romance: Novel Techniques for Replacing your Boyfriend with Generative AI (parody)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16v6ihg/classical_nlp_course_d/",
          "author": null,
          "description": "Classical NLP course recommendation\n Can you recommend me NLP course that dives into classical NLP methods: For example:\n HMM MaxEnt CKY algo Sytactic parsing Dependency Parsing\n    submitted by    /u/Thick-brain-dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16v6ihg/classical_nlp_course_d/",
          "publishedOn": "2023-09-29T09:02:57.000Z",
          "wordCount": 2615,
          "title": "Classical NLP course [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16v1z14/d_multitask_learning_leads_to_overfitting_is_this/",
          "author": null,
          "description": "I have a CNN model, call it model M. It was trained on dataset A for object pose estimation. After training for 100 epochs, it resulted in these losses:\n  \nTrain: 0.06\n Val: 0.08\n  \nAs dataset A is somewhat limited, I wonder if I can incorporate additional data via a different, but related task: object segmentation for similar objects. Model M is a UNet, so I can incorporate this task simply with an additional output channel in the last layer. \n I add dataset B for object segmentation. During training, M learns on both datasets quite well, which suggests to me that the tasks are well-aligned. After 100 epochs, I get these losses on dataset A:\n  \nTrain: 0.06\n Val: 0.16\n  \nThis is surprising to me. If I get the same training loss on dataset A, while training on additional data. I'd expect the validation loss to be lower, since I'm training on 2x the data. Yet the validation performance is consistently higher when I train on both datasets. \n The only explanation I can think of is the double descent phenomenon. Perhaps when I trained only on dataset A, I was significantly over-parameterized, but past the interpolation threshold. So perhaps adding more data brought me closer to the interpolation threshold, leading to worse generalization.\n Does this explanation seem likely? Has anyone had similar experiences?\n    submitted by    /u/murrdpirate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16v1z14/d_multitask_learning_leads_to_overfitting_is_this/",
          "publishedOn": "2023-09-29T04:31:27.000Z",
          "wordCount": 2818,
          "title": "[D] Multi-task learning leads to overfitting. Is this the double descent phenomenon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uyboe/d_whats_the_relationship_between_denoising/",
          "author": null,
          "description": "Hello, denoising autoencoders is when you train something to reverse x+n -> x. This seems to be basically the same as a diffusion model, more so if you see the U-Net diffusion model, which is effectively an information bottleneck.\n    submitted by    /u/windoze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uyboe/d_whats_the_relationship_between_denoising/",
          "publishedOn": "2023-09-29T01:34:28.000Z",
          "wordCount": 2634,
          "title": "[D] What's the relationship between Denoising Autoencoders and Diffusion Models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ux9xt/d_how_is_this_sub_not_going_ballistic_over_the/",
          "author": null,
          "description": "For a quick disclaimer, I know people on here think the sub is being flooded by people who arent ml engineers/researchers. I have worked at two FAANGS on ml research teams/platforms. \n My opinion is that GPT-4 Vision/Image processing is out of science fiction. I fed chatgpt an image of a complex sql data base schema, and it converted it to code, then optimized the schema. It understood the arrows pointing between table boxes on the image as relations, and even understand many to one/many to many. \n I took a picture of random writing on a page, and it did OCR better than has ever been possible. I was able to ask questions that required OCR and a geometrical understanding of the page layout. \n Where is the hype on here? This is an astounding human breakthrough. I cannot believe how much ML is now obsolete as a result. I cannot believe how many computer science breakthroughs have occurred with this simple model update. Where is the uproar on this sub? Why am I not seeing 500 comments on posts about what you can do with this now? Why are there even post submissions about anything else?\n    submitted by    /u/corporate_autist  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ux9xt/d_how_is_this_sub_not_going_ballistic_over_the/",
          "publishedOn": "2023-09-29T00:48:00.000Z",
          "wordCount": 2794,
          "title": "[D] How is this sub not going ballistic over the recent GPT-4 Vision release?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uwqx1/p_vllm_with_mistral_7b_guide/",
          "author": null,
          "description": "Hey all - vllm==0.2.0 got released a couple of hours ago and I put together some code to get it running with the new Mistral 7B model. Also included are some benchmarks for different input batch sizes with the model (output capped at 200 tokens):\n  \n Batch size Tokens /s \n  \n 1 46 \n  10 400 \n  60 1.8k \n \n Hope it's useful, let me know if you'd like any more info!\n Here's the link:\n https://docs.mystic.ai/docs/mistral-ai-7b-vllm-fast-inference-guide\n    submitted by    /u/paulcjh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uwqx1/p_vllm_with_mistral_7b_guide/",
          "publishedOn": "2023-09-29T00:25:33.000Z",
          "wordCount": 2658,
          "title": "[P] vLLM with Mistral 7B guide",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ur7h1/n_we_collaborated_with_outerbounds_to_enable_hpc/",
          "author": null,
          "description": "Here is our blog post - please check it out: https://forums.autodesk.com/t5/engineering-hub-blog/autodesk-and-outerbounds-partner-to-open-source-ray-and-hpc/ba-p/12254816\n And try out the metaflow-ray extension here: https://github.com/outerbounds/metaflow-ray\n    submitted by    /u/rirhun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ur7h1/n_we_collaborated_with_outerbounds_to_enable_hpc/",
          "publishedOn": "2023-09-28T20:49:55.000Z",
          "wordCount": 2613,
          "title": "[N] We Collaborated with Outerbounds to Enable HPC and Ray Integration in Metaflow",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ur4zb/d_what_are_the_options_for_the_most_human_tts/",
          "author": null,
          "description": "So I’ve been using elevenlabs but it burns through characters really fast. What are the best options for the most human sounding TTS available? I’ve been looking into tortoise, but would like to see if there are other options I should be looking into.\n    submitted by    /u/Long8D  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ur4zb/d_what_are_the_options_for_the_most_human_tts/",
          "publishedOn": "2023-09-28T20:47:07.000Z",
          "wordCount": 2635,
          "title": "[D] What are the options for the most human TTS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16unpn9/d_how_do_we_know_closed_source_released/",
          "author": null,
          "description": "I've recently started working with ML and NLP, so I'm sorry if this sounds Naive.\n Unlike Llama 2 or other open source, we don't have access to the model weights for GPT-4, Claude or Bard, so Benchmark Evals are being run through either APIs or the chat Interface. So how do we know that the model isn't being Boosted by custom web-searching abilities or RAG? While GPT-4 might have a turnoff option, I'm pretty sure Bard is always online, being built by google. So how do we trust benchmarks? Also, have any opensource been tested after Websearch/RAG?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16unpn9/d_how_do_we_know_closed_source_released/",
          "publishedOn": "2023-09-28T18:34:49.000Z",
          "wordCount": 2694,
          "title": "[D] How do we know Closed source released benchmarks aren't being heavily optimized, through outside means?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ulks3/r_searching_for_a_regression_dataset_with/",
          "author": null,
          "description": "I am searching for a relatively simple dataset to train a regressor that has some structure in its predictions. Can't be too tiny cause I have to try out a NN architecture. It must have at least some continuous feature but can also have additional categorical or related discrete structures. I usually work with vision tasks, so I am not sure if I miss something obvious I could try? Open for ideas! \n I thoughts about predicting rows in some tabular dataset? Anything suitable that comes to mind?\n    submitted by    /u/LeanderKu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ulks3/r_searching_for_a_regression_dataset_with/",
          "publishedOn": "2023-09-28T17:08:23.000Z",
          "wordCount": 2679,
          "title": "[R] Searching for a regression dataset with structure in its prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uldmh/n_cuda_architect_and_cofounder_of_mlperf_amds/",
          "author": null,
          "description": "Greg Diamos, the CTO of startup Lamini, was an early CUDA architect at NVIDIA and later cofounded MLPerf. \n He asserts that AMD's ROCM has \"achieved software parity\" with CUDA for LLMs.\n Lamini, focused on tuning LLM's for corporate and institutional users, has decided to go all-in with AMD Instict GPU's.\n https://www.crn.com/news/components-peripherals/llm-startup-embraces-amd-gpus-says-rocm-has-parity-with-nvidia-s-cuda-platform\n    submitted by    /u/makmanred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uldmh/n_cuda_architect_and_cofounder_of_mlperf_amds/",
          "publishedOn": "2023-09-28T17:00:36.000Z",
          "wordCount": 2647,
          "title": "[N] CUDA Architect and Cofounder of MLPerf: AMD's ROCM has achieved software parity with CUDA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ukolg/p_request_to_test_mirage_a_platform_to_search_and/",
          "author": null,
          "description": "Mirage is the infinite asset library that helps you find or create the perfect digital asset.\n 🗨️ Just Search Naturally: No awkward keywords—Mirage understands you.\n 🤖 State-of-the-Art Models: Can't find it? Generate it, thanks to open-source models.\n 🔍 Similarity Search: Discover more of what you love with a single click.\n 🤗 Fully Personalized: Our AI librarian learns your style to show you assets you'll dig.\n Website Link: MirageML\n Open-Source Github: Github\n Development Status: Beta\n I would love to get some honest feedback!\n    submitted by    /u/perception-eng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ukolg/p_request_to_test_mirage_a_platform_to_search_and/",
          "publishedOn": "2023-09-28T16:32:36.000Z",
          "wordCount": 2683,
          "title": "[P] Request to test Mirage: A platform to search and generate images, videos, audio, and 3D assets using natural language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uivnf/p_request_to_test_domeis_a_new_platform_for/",
          "author": null,
          "description": "Domeis is a no-code Machine Learning platform that offers a dashboard to design, train and test Machine Learning algorithms, as well as to import, pre-process and cleanse data, all from the Graphical User Interface and without writing a single line of code.\n The aim of this platform is two-fold:\n  \nMaking Machine Learning accessible to anyone and not just Data Scientists or experienced software developers. By offering the possibility to design, train and test Machine Learning models directly via GUI, being an experienced software developer is no longer a pre-condition for creating ML models\n Making Machine Learning model creation, training and testing faster for experienced Data Scientists / Machine Learning Engineers. By drastically reducing the time needed to set up environments, import data and define models, Domeis allows Machine Learning practitioners to focus on trying out and compare different models/approaches.\n  \nWebsite Link: https://www.domeis.it/\n Development Status: Alpha\n I would love to get some honest feedback!\n    submitted by    /u/Ok_Hold_5385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uivnf/p_request_to_test_domeis_a_new_platform_for/",
          "publishedOn": "2023-09-28T15:21:52.000Z",
          "wordCount": 2746,
          "title": "[P] Request to test Domeis: A new platform for no-code Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uibr4/d_help_understanding_convergence_proof_adaptive/",
          "author": null,
          "description": "Hello everyone,\n I am trying to understand the convergence analysis/derivation of the momentum algorithm, or the stochastic heavy ball algorithm, using the regret bound analysis from different research papers. \n  \nhttps://ieeexplore.ieee.org/document/7330562 - Page3\n \nhttps://www.mdpi.com/2504-3110/6/12/709 - Page6\n \nhttp://arxiv.org/abs/1707.01647 - Page4\n \n ​\n In the derivation, there is the following simplification, which I do not understand at all\n ​\n $\\frac{2\\boldsymbol{\\eta}_{k}}{(1-\\beta)}\\sum_{k=0}^{T}\\left|J(\\theta_k) - J(\\theta^*)\\right| + \\frac{2\\boldsymbol{\\eta}_{k}\\beta}{(1-\\beta)^2} \\sum_{k=0}^{T}\\left|J(\\theta_k) - J(\\theta_{k-1})\\right| \\leq \\ \\left|\\boldsymbol{\\theta}_{0} + \\boldsymbol{p}_{0} - \\boldsymbol{\\theta}^* \\right|^2 - \\left|\\boldsymbol{\\theta}_{T+1} + \\boldsymbol…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uibr4/d_help_understanding_convergence_proof_adaptive/",
          "publishedOn": "2023-09-28T15:00:31.000Z",
          "wordCount": 2843,
          "title": "[D] Help understanding convergence proof (Adaptive learning rate + Momentum)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ui0vx/dany_researchers_or_institutions_in_usa_that/",
          "author": null,
          "description": "I have tried to follow the main collaborators of Hutter and other prominent scientists to track this, but they are mostly in Europe with some in Australia. American institutions seems to be more interested in more open ai like deep neural networks. If anyone is familiar with any US based institutions that does notable work in this line,please comment\n    submitted by    /u/Netero1999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ui0vx/dany_researchers_or_institutions_in_usa_that/",
          "publishedOn": "2023-09-28T14:48:03.000Z",
          "wordCount": 2653,
          "title": "[D]Any researchers or institutions in USA that follows Ai-compression relationships specifically like deepmind",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ui0br/r_brain_tumor_segmentation/",
          "author": null,
          "description": "Can any of you suggest me computer science research ideas related to brain tumor segmentation using UNet.\n    submitted by    /u/Eleonora467  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ui0br/r_brain_tumor_segmentation/",
          "publishedOn": "2023-09-28T14:47:25.000Z",
          "wordCount": 2602,
          "title": "[R] Brain Tumor segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ugkmc/p_bionicgpt_chatgpt_replacement_that_lets_you_run/",
          "author": null,
          "description": "BionicGPT is an open source WebUI that gives enterprises the ability to run Retrieval Augmented Generation (RAG) on their on premise documents.\n To allow people to get up to speed we deploy with a quantized 7B model that runs on CPU.\n Github Repo: https://github.com/purton-tech/bionicgpt\n We basically implement a RAG pipeline including document upload, embeddings generation and subsequent retrieval.\n Feedback:\n We'd love to get some feedback in the form or github issues or comments here.\n Screenshot:\n https://preview.redd.it/uiw0wqul30rb1.png?width=2447&format=png&auto=webp&s=8ad7e61ed048258c19aa63bf7c94d12da5b721fa\n    submitted by    /u/purton_i  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ugkmc/p_bionicgpt_chatgpt_replacement_that_lets_you_run/",
          "publishedOn": "2023-09-28T13:48:37.000Z",
          "wordCount": 2669,
          "title": "[P] BionicGPT - ChatGPT replacement that let's you run R.A.G on confidential data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ug81n/n_first_impressions_with_gpt4vision/",
          "author": null,
          "description": "My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:\n  \nVisual question answering (VQA) across a range of domains (locations, movies, plants)\n OCR\n Math OCR\n Object detection\n And more\n  \nTL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).\n https://blog.roboflow.com/gpt-4-vision/\n I would love to hear what other people have found working with GPT-4V.\n    submitted by    /u/zerojames_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ug81n/n_first_impressions_with_gpt4vision/",
          "publishedOn": "2023-09-28T13:33:55.000Z",
          "wordCount": 2667,
          "title": "[N] First Impressions with GPT-4V(ision)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uexkq/r_nus_results_of_combining_pixel_and_latent/",
          "author": null,
          "description": "A new paper proposes Show-1, a hybrid model that combines pixel and latent diffusion for efficient high-quality text-to-video generation.\n Both of these approaches have tradeoffs, so researchers at the National University of Singapore tried a hybrid approach combining both, and shared the results in a paper published yesterday.\n My highlights from the paper:\n  \nPixel diffusion excels at low-res video generation precisely aligned with text \n Latent diffusion acts as efficient upsampling expert from low to high res \n Chaining the two techniques inherits benefits of both Show-1 achieves strong alignment, quality, and 15x less inference memory \n The key is using pixel diffusion for the initial low-resolution stage. This retains alignment with text descriptions.\n Latent diffusion then serves as a super-resolution expert, upsampling efficiently while preserving fidelity.\n  \nBy blending complementary techniques, Show-1 moves past tradeoffs limiting the individual models.\n More details here. Paper is here (includes links to example generations).\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uexkq/r_nus_results_of_combining_pixel_and_latent/",
          "publishedOn": "2023-09-28T12:39:00.000Z",
          "wordCount": 2741,
          "title": "[R] NUS: Results of Combining Pixel and Latent Diffusion Models for Text-to-Video Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16uctzu/linear_regression_queries_d/",
          "author": null,
          "description": "I am a beginner in Data Science. I have recently enrolled in the supervised machine learning algorithm by Andrew Ng in Coursera. I am now familiarized with linear regression, gradient descent. However, I faced a certain issue. \n In the optional lab, there was a task to calculate the value of the cost function using gradient descent for linear regression. I wrote the code in my notebook by myself and cross checked it to be correct. However, the desired output of w,b are very much different but the cost function yields a better result in my code. Another factor, I noticed that have to scale only thex variables, leaving the values of y. I have two major queries now: \n  \nIs the yielding of different w,b values fine as long as the cost function is minimum? (w is a numpy array) \n Why do scale the x variables only? Why don't scale the y variables? \n  \nThanks in advance.\n    submitted by    /u/healing_you  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16uctzu/linear_regression_queries_d/",
          "publishedOn": "2023-09-28T10:57:45.000Z",
          "wordCount": 2740,
          "title": "Linear Regression Queries [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ubcan/p_handson_opensource_workflows_for_voice_ai/",
          "author": null,
          "description": "Hey r/MachineLearning,\n we made a tutorial that showcases typical workflows and tooling for voice analytics applications. The tutorial is intended for intermediate-level ML practitioners. \n The walkthrough is purely based on open source software and covers:\n  \nEfficient interactive data exploration and inspection\n Dataset handling and inference on pre-trained models\n Model debugging and identification of critical data clusters\n Model comparison and selection\n  \n​\n https://i.redd.it/j15gk3kkgyqb1.gif\n 🔗 Blog with code: https://medium.com/p/dbfd923a5a79#432e-3559ae606f80\n 🤗 Interactive demo: https://huggingface.co/spaces/renumics/emodb-model-debugging\n ​\n ​\n    submitted by    /u/44sps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ubcan/p_handson_opensource_workflows_for_voice_ai/",
          "publishedOn": "2023-09-28T09:32:21.000Z",
          "wordCount": 2657,
          "title": "[P] Hands-on open-source workflows for voice AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ub6k9/d_cv_annotations_and_work_with_cocoyolo_dataset/",
          "author": null,
          "description": "Hi everyone. In my job I work with a lot of data for Computer Vision, and I use Label Studio for annotations. But the last time I've worked with it, I lost some of my annotations, which I need for other purposes. I have the final result as a YOLO and COCO dataset, but I cannot import the results from them to recover all I need.\n Can you suggest me good applications with an intuitive UI to import the COCO or YOLO dataset and work with labels?\n    submitted by    /u/thattallsoldier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ub6k9/d_cv_annotations_and_work_with_cocoyolo_dataset/",
          "publishedOn": "2023-09-28T09:22:08.000Z",
          "wordCount": 2676,
          "title": "[D] CV annotations and work with COCO/YOLO dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u9y56/p_request_to_test_pymilo_a_new_python_library_for/",
          "author": null,
          "description": "Pymilo is an open-source Python package that offers an efficient, safe, and transparent method for transporting pre-trained machine-learning models. The motivation for developing this package is to eliminate the risks of binary or pickle formats. As this library is still in its early stages of development, it currently supports only a limited number of machine learning models provided by Scikit-learn. Nevertheless, it will be precious if the community utilizes this library and provides us with their feedback about improving the package's interface and prioritizing future developments. Your cooperation would be invaluable to us.\n In the following, I provide an example of how to utilize PyMilo.\n GitHub Repo: https://github.com/openscilab/pymilo \n Development Status: Alpha\n Simple Linear Mode…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u9y56/p_request_to_test_pymilo_a_new_python_library_for/",
          "publishedOn": "2023-09-28T08:02:52.000Z",
          "wordCount": 2827,
          "title": "[P] Request to Test PyMilo: A New Python Library for Machine Learning I/O",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u8a34/discussion_interesting_interview_question/",
          "author": null,
          "description": "Was asked something similar to the following question in an interview for a ML role and was curious how others would answer this:\n Say you have a dataset with one feature column and one label column (with different classes). Assume this data is too large to fit into memory and could be infinite in size (e.g data is coming in as a stream). How would you train a ML model on this data to accurately predict the label?\n Followup: instead of one feature column, what if you had several thousand? How would you decide which features to use given the size of the dataset? \n I discussed online sampling (resevoir sampling, etc) as a way to get a training dataset that could fit in memory + continually train on that but the interviewer did not seem convinced. Any thoughts?\n    submitted by    /u/scpdstudent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u8a34/discussion_interesting_interview_question/",
          "publishedOn": "2023-09-28T06:17:51.000Z",
          "wordCount": 2717,
          "title": "[Discussion] Interesting interview question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u5tmk/d_what_appropriate_loss_function_to_use_for/",
          "author": null,
          "description": "I'm studying the application of ML to improve searches. Here's a couple of example scenarios:\n  \nDocument retrieval (search) system: We have a (source) document with us and we're trying to find a matching document in a database. The source document has text and image attributes - for simplicity let's say a title and a single image. Each search result will also be a document - with a title and at most one image.\n A search engine: We have a query comprised of both text and an image (like google image search allows text to be added to the query as well). Each search result will be a website with text and image attributes (for simplicity, webpage title and at most one image)\n  \nMore generally, I have a search system - whatever we're trying to search for has text and an image associated with it…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u5tmk/d_what_appropriate_loss_function_to_use_for/",
          "publishedOn": "2023-09-28T04:01:48.000Z",
          "wordCount": 3420,
          "title": "[D] What appropriate loss function to use for \"Search recall\" optimization?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u14il/d_how_does_your_organization_approach_machine/",
          "author": null,
          "description": "How does the development process of a Machine Learning project unfold phase-by-phase within your organization? Could you please specify the type of organization you are, the time spent on each phase, as well as any aspects you consider to be weak or fundamental? It would also be great if you could share any tips or tricks you've learned that have changed your perspective. \n    submitted by    /u/Spiritual_Narwhal649  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u14il/d_how_does_your_organization_approach_machine/",
          "publishedOn": "2023-09-28T00:25:09.000Z",
          "wordCount": 2656,
          "title": "[D] How Does Your Organization Approach Machine Learning Projects Phase by Phase?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16u0ok1/p_rubiks_cube_square_detection/",
          "author": null,
          "description": "Hello everyone,\n I am trying to detect the 9 squares of a face of a Rubik’s Cube through a camera. The idea is that I want to use my computer camera and tell the user to show all the Rubik’s Cube faces and read the faces so I can feed it to a solver.\n Here are the steps I have tried so far:\n  \nSharpened square edges\n Obtained binary image and removed noise\n Detected and extracted squares\n  \nSome methods I used were using different blurs and cv functions but nothing worked. Sometimes, it can get all 9 squares but sometimes it doesn't. There also seems to be a difference for different colors; for example; the model can detect green squares easier than yellow squares.\n Can anyone provide advice as to how I can detect the squares on the face?\n ​\n https://preview.redd.it/1ht9f4h31wqb1.png?width=2180&format=png&auto=webp&s=32d23515a43406c0f8828e6790ad71e754b0ab80\n    submitted by    /u/uglyboi34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16u0ok1/p_rubiks_cube_square_detection/",
          "publishedOn": "2023-09-28T00:06:30.000Z",
          "wordCount": 2724,
          "title": "[P] Rubik's Cube Square Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tzdca/graph_feature_vector_embedding_d/",
          "author": null,
          "description": "Hey all, \n I’m trying to do a regression algorithm for a dataset where I have a graph for each patient I have representing a location in their brain from MRI images. Right now, I don’t have a ton of data, so I’m looking for some way to take each graph I have and get a feature vector for it to put into a regression algorithm. So for 100 patients, I have 100 graphs, I’d like to have 100 feature vectors representing each patients graph. \n My issue is trying to find some algorithm that takes in the entire graph and outputs a single feature vector. I’ve been looking at some libraries but they all seem wildly scattered. I don’t want to grab a bunch of nose embeddings and do some elementary merge of them, like an average or sum, etc. Any help in pointing me to some Python libraries that can help me do this, or algorithms, or anything. Thank you so much.\n    submitted by    /u/kaleb7589  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tzdca/graph_feature_vector_embedding_d/",
          "publishedOn": "2023-09-27T23:11:45.000Z",
          "wordCount": 2748,
          "title": "Graph Feature vector (embedding) [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tx9ea/normalization_in_vaed/",
          "author": null,
          "description": "Normalization in VAE[D]\n Am training a variational auto encoder. First I tried with batch normalization before I send the data to the network and someone probably wisely pointed out that it's not correct. If I don't use batch norm then my training fails due to numerical instability. I then tried scaling my data before hand using standard scaler from sklewrn. And now my training works. Is this reasonable?\n Any other thoughts?\n    submitted by    /u/Global-Gene2392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tx9ea/normalization_in_vaed/",
          "publishedOn": "2023-09-27T21:51:18.000Z",
          "wordCount": 2655,
          "title": "Normalization in VAE[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tx76g/p_predicted_stock_data_with_tensorflow_is_very/",
          "author": null,
          "description": "I'm following a YouTube video to create a simple machine learning model to predict stock prices. I have to reshape my prediction data so it works with inverse_transform, but in the video he doesn't do this. If I don't reshape it I get an error, but I think when I do reshape it it messes with the data.\n The predicted values are all very similar. I've tried messing with epoch and batch sizes, and changing other metrics like prediction_days, but nothing has worked.\n This is what the prediction data looks like when plotted, and this is what it looks like when printed. Does anyone know what could be causing this?\n Here's my code\n    submitted by    /u/darkshadowtrail  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tx76g/p_predicted_stock_data_with_tensorflow_is_very/",
          "publishedOn": "2023-09-27T21:49:04.000Z",
          "wordCount": 2706,
          "title": "[P] Predicted stock data with TensorFlow is very different from actual data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tubz1/new_subreddit_rule_idea_d/",
          "author": null,
          "description": "This subreddit will continue to die if it doesn't foster discussion of the latest research and reduce low-quality posts. However, making a judgement as to what is or is not low-quality is time-consuming and subjective -- not something the mods should be doing.\n To this end, I had the following new rule idea:\n  \nIf it's your first time at Fight If it's your first post in this subreddit, it needs to be a link to arxiv (Or, more generally, the number of your non-arxiv posts cannot exceed the number of your arxiv posts)\n All arxiv posts must be standard links to the abstract page (to catch reposts and to connect discussions of the same paper in different subreddits)\n An arxiv post must be a paper you've read yourself, and you should post a comment describing what you liked and DIDN'T like about it (Let the airing of grievances begin! I think this will help seed the discussion, which is really the raison d'être of this subreddit)\n If the post or the comment get downvoted, they do not count.\n  \nWhat do you think? Will this help steer this subreddit in the right direction? Is this enforceable?\n    submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tubz1/new_subreddit_rule_idea_d/",
          "publishedOn": "2023-09-27T19:59:17.000Z",
          "wordCount": 2781,
          "title": "New subreddit rule idea [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tuajs/d_how_feasible_is_it_to_complete_a_course/",
          "author": null,
          "description": "Hi I am a physicist (1st year in masters) and I decided to take NN class (for cs students). I have a decent experience with python but I have never done low level coding. The class project requires a C++ implementation of NN with back propagation algorithm. I am quite confident in my learning ability, nonetheless, do you guys think it is feasible for me to code such a project in 13 weeks (I also have other subjects and cant just spend all my time on this)? Thanks\n    submitted by    /u/merimace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tuajs/d_how_feasible_is_it_to_complete_a_course/",
          "publishedOn": "2023-09-27T19:57:38.000Z",
          "wordCount": 2678,
          "title": "[D] How feasible is it to complete a course.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ttbu3/pd_need_guidance_on_building_a_chatbot_like/",
          "author": null,
          "description": "Hey fellow Redditors,\n I find myself in quite a situation and could use some guidance. Recently, I introduced my professor to privateGPT and demonstrated its capabilities using a small set of college data. To my delight, he was impressed and has now tasked me with researching and developing a ChatGPT-like chatbot, but with access to our university's extensive data.\n Here's where I need your help: my professor wants this chatbot to be hosted on our university's systems due to privacy concerns, which means I can't use ChatGPT's API. I've been given access to Sol HPC, but I'm finding it quite confusing to get started.\n I'm looking for advice, tips, or any resources that can help me embark on this journey. Has anyone here worked on a similar project, or does anyone have experience with Sol HPC or building chatbots with local data sources? Any guidance or insights would be greatly appreciated!\n Thank you in advance for your help. This project means a lot to me, and I want to make sure I'm heading in the right direction.\n    submitted by    /u/ssshankyyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ttbu3/pd_need_guidance_on_building_a_chatbot_like/",
          "publishedOn": "2023-09-27T19:20:07.000Z",
          "wordCount": 2772,
          "title": "[P][D] Need Guidance on Building a Chatbot like ChatGPT for University Data - Help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tt7z9/r_unc_researchers_present_videodirectorgpt_using/",
          "author": null,
          "description": "Generating coherent videos spanning multiple scenes from text descriptions poses unique challenges for AI. While recent progress enables creating short clips, smoothly transitioning across diverse events and maintaining continuity remains difficult.\n A new paper from UNC Chapel Hill proposes VIDEODIRECTORGPT, a two-stage framework attempting to address multi-scene video generation:\n Here are my highlights from the paper:\n  \nTwo-stage approach: first a language model generates detailed \"video plan\", then a video generation module renders scenes based on the plan\n Video plan contains multi-scene descriptions, entities/layouts, backgrounds, consistency groupings - guides downstream video generation\n Video generation module called Layout2Vid trained on images, adds spatial layout control and cross-scene consistency to existing text-to-video model\n Experiments show improved object layout/control in single-scene videos vs baselines\n Multi-scene videos display higher object consistency across scenes compared to baselines\n Competitive open-domain video generation performance maintained\n  \nThe key innovation seems to be using a large language model to plot detailed video plans to guide overall video generation. And the video generator Layout2Vid adds better spatial and temporal control through some clever tweaks. The separation of these tasks seems to matter.\n You can read my full summary here. There's a link to the repo there too. Paper link is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tt7z9/r_unc_researchers_present_videodirectorgpt_using/",
          "publishedOn": "2023-09-27T19:16:03.000Z",
          "wordCount": 2794,
          "title": "[R] UNC Researchers Present VideoDirectorGPT: Using AI to Generate Multi-Scene Videos from Text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tryd2/survival_analysis_in_matlab_project/",
          "author": null,
          "description": "survival analysis in matlab\n hi everyone one i'm doing a predictive algorithm to find DFS using Cox regression, i first used LASSO regression to select the predictive variables, now i'm using the c-index to evaluate the predictive accuracy, and it's always equals to 1 and I can't understand why(I tried to reduce the numbers of variables just to see if it could change but it didn't change).Also, i'm working on censored date of course.\n can someone help me understand what I'm doing wrong?\n    submitted by    /u/bl4s3159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tryd2/survival_analysis_in_matlab_project/",
          "publishedOn": "2023-09-27T18:19:28.000Z",
          "wordCount": 2669,
          "title": "survival analysis in matlab [project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16towe3/r_can_you_help_me_validate_my_kmeans_calculator/",
          "author": null,
          "description": "My annotations are in pascal voc format. Below is a calculator I am testing . Not sure if I am calculating the scale and aspect ratios correctly. Please help. \n import os import xml.etree.ElementTree as ET import numpy as np from sklearn.cluster import KMeans def compute_scales_and_aspect_ratios(directory, n_clusters, img_size): widths = [] heights = [] for filename in os.listdir(directory): if not filename.endswith('.xml'): continue fullname = os.path.join(directory, filename) tree = ET.parse(fullname) root = tree.getroot() for obj in root.iter('object'): xmlbox = obj.find('bndbox') w = float(xmlbox.find('xmax').text) - float(xmlbox.find('xmin').text) h = float(xmlbox.find('ymax').text) - float(xmlbox.find('ymin').text) widths.append(w) heights.append(h) widths = np.array(widths) / img_size[1] # Normalize by image width heights = np.array(heights) / img_size[0] # Normalize by image height scales = np.sqrt(widths * heights).reshape(-1, 1) aspect_ratios = (widths / heights).reshape(-1, 1) kmeans_scales = KMeans(n_clusters=n_clusters, random_state=0).fit(scales) kmeans_aspect_ratios = KMeans(n_clusters=n_clusters, random_state=0).fit(aspect_ratios) return kmeans_scales.cluster_centers_, kmeans_aspect_ratios.cluster_centers_ directory = \"path_to_top_folder/batch-1\" n_clusters = 5 img_size = (640, 1024) scales, aspect_ratios = compute_scales_and_aspect_ratios(directory, n_clusters, img_size) print('Scales:', scales.flatten()) print('Aspect Ratios:', aspect_ratios.flatten()) \n ​\n    submitted by    /u/dpadhy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16towe3/r_can_you_help_me_validate_my_kmeans_calculator/",
          "publishedOn": "2023-09-27T16:19:26.000Z",
          "wordCount": 2751,
          "title": "[R] Can you help me validate my kmeans calculator for tensorflow faster rcnn model config ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tonm8/p_any_available_datasets_of_childrens_books_or/",
          "author": null,
          "description": "I am looking for training data consisting of children’s stories and associated grade level. Does anyone know of any publicly available or paid datasets like this?\n    submitted by    /u/SpellboundLRN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tonm8/p_any_available_datasets_of_childrens_books_or/",
          "publishedOn": "2023-09-27T16:10:02.000Z",
          "wordCount": 2616,
          "title": "[P] Any available datasets of children’s books or stories?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tnt37/embers_of_autoregression_understanding_large/",
          "author": null,
          "description": "submitted by    /u/cegras  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tnt37/embers_of_autoregression_understanding_large/",
          "publishedOn": "2023-09-27T15:37:01.000Z",
          "wordCount": 2606,
          "title": "Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tnm6d/p_tetris_ai_suggestions_on_direction_to_take_from/",
          "author": null,
          "description": "Hello! I'm working on a Tetris AI and am representing the 10x20 grid cubes with a one hot encoded dataset: https://www.kaggle.com/datasets/conlan/tetris-training-set-9262023\n This means my data has 208 features (200 for the grid cubes being on/off, 7 for the \"next shape\" box, and 1 for the labeled best move.\n I currently have 9460 labeled samples and have done some preliminary fitting here: https://www.kaggle.com/code/conlan/tetris-ai?scriptVersionId=144388350 with a highest f1_macro score of 0.431090.\n Does anyone have suggestions for which direction to take from here to improve? Currently I see:\n  \nCollect More Data\n Tune Hyperparameters\n Rework Features\n  \nI'm hesitant to rework the features as that would require telling the model more specifics and would like to keep it abstract, but maybe 200 is crazy high? Or maybe <10k samples is too low and I should just keep collecting data?\n Thanks in advance!\n    submitted by    /u/conlanrios  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tnm6d/p_tetris_ai_suggestions_on_direction_to_take_from/",
          "publishedOn": "2023-09-27T15:29:44.000Z",
          "wordCount": 2736,
          "title": "[P] Tetris AI - Suggestions on direction to take from here? (One hot encoded dataset with 200 features)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tlpso/r_the_internal_state_of_an_llm_knows_when_its/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2304.13734\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tlpso/r_the_internal_state_of_an_llm_knows_when_its/",
          "publishedOn": "2023-09-27T14:12:33.000Z",
          "wordCount": 2595,
          "title": "[R] The Internal State of an LLM Knows When its Lying",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16th395/d_feature_transformation_scaling/",
          "author": null,
          "description": "ood morning everyone,\n I am currently reading the book of Mr. Burkov: Machine Learning Engineering. He talk about a step that might be helpful before training a ML model: Feature Scaling. Furthermore, he adds that before Feature Scaling, you might do Feature Transformation (Log, Square,...) in order to make your data look normal and have better models. How true do you think this statement is? Do you also transform your feature, and then scale them? How often do you do it? It is important for Regression or SVM, but do you do it also for other black box algorithms such as Random Forests? What are the best practices according to you?\n    submitted by    /u/dekozr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16th395/d_feature_transformation_scaling/",
          "publishedOn": "2023-09-27T10:39:42.000Z",
          "wordCount": 2697,
          "title": "[D] Feature Transformation & Scaling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tgfa4/aaai_24_discussion/",
          "author": null,
          "description": "So no discussions are going on about AAAI 2024, or have I just been unable to find any?\n Opening this regarding Phase 1-2 and Results discussions if anyone wants to discuss. If there already is a thread, share!\n For an opening question, any idea about what percentages are rejected in desk rejection, phase 1 and finally phase 2? (Roughly of course)\n    submitted by    /u/atharvandogra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tgfa4/aaai_24_discussion/",
          "publishedOn": "2023-09-27T10:00:47.000Z",
          "wordCount": 2645,
          "title": "AAAI 24 [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tffpm/d_gpt2_diagrams_are_wrong/",
          "author": null,
          "description": "so if u go check the source code for gpt2 u can clearly see that the nrom happens inside the attention and mlp layers.\n and that the add is separate. this is in the official openai github and is relatively easy to read:https://github.com/openai/gpt-2/blob/master/src/model.py#L123-L130 (thx KingsmanVince)\n ​\n for some reason all the online materials are saying that there is a full norm layer before the mlp instead of inside of it\n    submitted by    /u/rejectedlesbian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tffpm/d_gpt2_diagrams_are_wrong/",
          "publishedOn": "2023-09-27T08:57:41.000Z",
          "wordCount": 2655,
          "title": "[D] GPT2 diagrams are wrong",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tf3gh/d_onnx_or_torchlib_for_on_device_training_in_c/",
          "author": null,
          "description": "Hi,\n Recently I am trying to reimplement a deep learning based object tracking in C++. However, the whole pipeline involve online training and weight update.\n Is it possible to do the training for ONNX model and using cuda as accelerator in C++?\n If yes, then how is the training speed (BP/update)compare to torchlib?\n I personally strongly prefer onnx, cuz it is much easier to deploy…\n    submitted by    /u/Independent_Bet1268  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tf3gh/d_onnx_or_torchlib_for_on_device_training_in_c/",
          "publishedOn": "2023-09-27T08:35:19.000Z",
          "wordCount": 2656,
          "title": "[D] ONNX or torchlib for on device training in C++",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16teob2/d_the_quality_of_this_sub/",
          "author": null,
          "description": "Mods finally commented\n The only time that mods were active is when they removed the cat meme. It has been a month since that. Let see what mods have done to improve this sub.\n Here are some of the other posts obviously rule-breaking or off-topic that mods do NOT remove:\n  \nA person asking for help with their motherboard\n A person asking about statistics\n A person asking for machine learning roadmap\n Another asking-for-roadmap post\n ... the list goes on with absolute beginner questions, and low-quality posts. \n  \nAll these posts were written in less than 1 week. As we can see, mods do nothing. They only remove posts that calling out them. \n Here are posts that people discuss the status of this sub:\n  \n17 Sep 2023\n 2 Sep 2023\n 1 Aug 2023\n  \nQuestions for mods: where are you when people complain? Why do you only show up when someone call you out?\n We have few options:\n  \nReport the mods and the sub for unmoderated (see this 1 and this 2)\n Find other communities\n Gatekeep harder, tell people to go to r/learnmachinelearning r/MLQuestions r/cscareerquestions r/languagetechnology\n  \n   submitted by    /u/March8365  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16teob2/d_the_quality_of_this_sub/",
          "publishedOn": "2023-09-27T08:08:28.000Z",
          "wordCount": 2769,
          "title": "[D] The quality of this sub",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16te7yw/d_model_release_v01_from_mistralai/",
          "author": null,
          "description": "EDIT:\n They released the model weights on HF (https://huggingface.co/mistralai) under a Apache 2.0 License.\n They also updated their website with documentation on how to use/run : https://docs.mistral.ai\n Note: I am not affiliated with Mistral AI.\n ​\n Via their Twitter X account :\n magnet:?xt=urn:btih:208b101a0f51514ecf285885a8b0f6fb1a1e4d7d&dn=mistral-7B-v0.1&tr=udp%3A%2F%http://2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=https%3A%2F%http://2Ftracker1.520.jp%3A443%2Fannounce \n ​\n https://preview.redd.it/0o46ls925rqb1.png?width=1306&format=png&auto=webp&s=7ff7ca3a510577e9ecdaa3c9ccb7ef763acc0780\n    submitted by    /u/Fluid-Age-9266  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16te7yw/d_model_release_v01_from_mistralai/",
          "publishedOn": "2023-09-27T07:39:40.000Z",
          "wordCount": 2629,
          "title": "[D] Model release v0.1 from MistralAI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16tdkjg/dfinetune_t5_for_classification_but_not_seeing/",
          "author": null,
          "description": "I am wondering if any one runs into this before, i have finetuned flan-t5-xl for classification task by generating one token from decoder. The finetune process looks OK. I want to convert this into t5 encoder with a head to save memory. I am using huggingface T5ForSequenceClassification. However i am seeing loss not actually decrease but bounce around certain float value. What could be wrong? I have tried a few learning rates and other hyperparameters tuning.\n    submitted by    /u/Chen806  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16tdkjg/dfinetune_t5_for_classification_but_not_seeing/",
          "publishedOn": "2023-09-27T07:00:13.000Z",
          "wordCount": 2666,
          "title": "[D]Finetune t5 for classification but not seeing loss reduction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16t52u7/r_microsoft_researchers_propose_dit_morality_test/",
          "author": null,
          "description": "Researchers from Microsoft have just proposed using a psychological assessment tool called the Defining Issues Test (DIT) to evaluate the moral reasoning capabilities of large language models (LLMs) like GPT-3, ChatGPT, etc.\n The DIT presents moral dilemmas and has subjects rate and rank the importance of various ethical considerations related to the dilemma. It allows quantifying the sophistication of moral thinking through a P-score.\n In this new paper, the researchers tested prominent LLMs with adapted DIT prompts containing AI-relevant moral scenarios.\n Key findings:\n  \nLarge models like GPT-3 failed to comprehend prompts and scored near random baseline in moral reasoning.\n ChatGPT, Text-davinci-003 and GPT-4 showed coherent moral reasoning with above-random P-scores.\n Surprisingly, the smaller 70B LlamaChat model outscored larger models in its P-score, demonstrating advanced ethics understanding is possible without massive parameters.\n The models operated mostly at intermediate conventional levels as per Kohlberg's moral development theory. No model exhibited highly mature moral reasoning.\n  \nI think this is an interesting framework to evaluate and improve LLMs' moral intelligence before deploying them into sensitive real-world environments - to the extent that a model can be said to possess moral intelligence (or, seem to possess it?).\n Here's a link to my full summary with a lot more background on Kohlberg's model (had to read up on it since I didn't study psych). Full paper is here\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16t52u7/r_microsoft_researchers_propose_dit_morality_test/",
          "publishedOn": "2023-09-27T00:18:33.000Z",
          "wordCount": 2789,
          "title": "[R] Microsoft Researchers Propose DIT Morality Test for LLMs To Quantify AI Moral Reasoning Abilities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16t3oqj/d_implementation_of_chatgptsteered_editing/",
          "author": null,
          "description": "I found the paper “ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization” published in march and I was looking for information about the cost of training such a system. Have someone tried ? Is there some weights in the nature already trained for the instructor model ?\n I have found the GitHub associated with the paper but it obviously only contain the code for training but no information about approximate token used or anything like that.\n    submitted by    /u/Agreeable-Committee6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16t3oqj/d_implementation_of_chatgptsteered_editing/",
          "publishedOn": "2023-09-26T23:22:01.000Z",
          "wordCount": 2641,
          "title": "[D] Implementation of ChatGPT-steered Editing Instructor for Customization of Abstractive Summarization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16t3npr/p_interact_with_an_owlvit_object_detection_model/",
          "author": null,
          "description": "We noticed a lot of people wanting to deploy computer vision models, so we built an interactive demo of OWL-ViT to show how it might be used by an end user when integrated into a product.\n OWL-ViT is a new object detection model from the team at Google Research. It allows you to identify an object in one image (the “query image”) and then find that same object in any number of target images.\n Here is the link to interact with an OWL-ViT model!\n    submitted by    /u/modelbit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16t3npr/p_interact_with_an_owlvit_object_detection_model/",
          "publishedOn": "2023-09-26T23:20:49.000Z",
          "wordCount": 2644,
          "title": "[P] Interact with an OWL-ViT Object Detection Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16t18tl/question_about_dataset_d/",
          "author": null,
          "description": "hey everyone, novice at ML and trying to do a project on my own. I am trying to predict the rainfall amount in inches for a given day. I’ve decided to make it a classification problem and predict the zone of rainfall as in 0-0.5 in inches or 1-1.5 inches. My data set has ~40,000 samples however i have noticed that 24,000 of them have 0.0 as the amount of rainfall. And a high percentage of the rest are very low like below 0.5 inch. I’m wondering if there’s still a way to create the type of model I had originally intended or not. Is there a way to reduce the size of my data set , specifically the amount of low values without losing important feature information? Thank you and any help is appreciated :)\n    submitted by    /u/RepeatResponsible499  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16t18tl/question_about_dataset_d/",
          "publishedOn": "2023-09-26T21:50:35.000Z",
          "wordCount": 2692,
          "title": "Question about dataset [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16swrha/d_asus_rog_zephyrus_vs_macbook_pro_for_ml_phd/",
          "author": null,
          "description": "Hi all, I understand it all comes down to personal preference and that it is an old topic, but a bit advice would be welcome. My current workload consists of analyzing large medical records, medical images (upcoming work) with mainly PyTorch.\n Now I have direct and remote access to my personal lab pc which has configuration: core i9-9900K, 32 GB Ram, GTX 2080Ti 12 GB, Windows 11.\n Now I am planning to buy a laptop that would help with coursework, research paper reading and remote access to my lab PC. It should last at least 4/5 years (My current 5-year-old MSI laptop's hinge broke).\n I have the following laptops in mind with a budget of around $2000\n  \n14-inch Macbook Pro with 16 GB RAM and M2 PRO = $1999\n ASUS ROG Zephyrus 15.6\" WQHD 165Hz Gaming Laptop, AMD Ryzen 9 6900HS,16GB DDR5 4800Mhz RAM, 1TB SSD PCIe 4.0 Storage, NVIDIA GeForce RTX 3060 = $1400\n  \n   submitted by    /u/Furiousguy79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16swrha/d_asus_rog_zephyrus_vs_macbook_pro_for_ml_phd/",
          "publishedOn": "2023-09-26T19:05:30.000Z",
          "wordCount": 2717,
          "title": "[D] Asus ROG Zephyrus vs Macbook Pro for ML (PhD Student)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16suyv3/is_rust_a_thing_in_ml_d/",
          "author": null,
          "description": "I've seeing some people saying thar python is for training models and rust is for deploying them. Is it a widespread practice or it's just a localized need for companie with \"performance sensitive\" models?\n    submitted by    /u/horace_desplein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16suyv3/is_rust_a_thing_in_ml_d/",
          "publishedOn": "2023-09-26T17:58:12.000Z",
          "wordCount": 2593,
          "title": "Is Rust a thing in ML? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16st3o4/d_announcing_boomerang_vectaras_new_embedding/",
          "author": null,
          "description": "Happy to share Vectara's new state-of-the-art embedding model, called Boomerang. Embedding models were so far not too much in the spotlight relative to chat models like ChatGPT, but for Retrieval-augmented-generation applications, getting the best embedding model matters a lot.\n would love to hear what has been the experience of others in this respect - what embedding models have worked best so far with RAG?\n Blog post: https://vectara.com/introducing-boomerang-vectaras-new-and-improved-retrieval-model/\n Hackernews: https://news.ycombinator.com/item?id=37661359\n    submitted by    /u/ofermend  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16st3o4/d_announcing_boomerang_vectaras_new_embedding/",
          "publishedOn": "2023-09-26T16:46:56.000Z",
          "wordCount": 2629,
          "title": "[D] Announcing Boomerang - Vectara's new embedding model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16srupa/r_automated_quality_assurance_for_object/",
          "author": null,
          "description": "Would you deploy a self-driving car model that was trained on images for which data annotators accidentally forgot to highlight some pedestrians?\n Errors in object detection examples found via cleanlab.\n Annotators of real-world object detection datasets often make such errors and many other mistakes. To avoid training models on erroneous data and save QA teams significant time, you can now use automated algorithms invented by our scientists.\n Our newest paper introduces Cleanlab Object Detection: a novel algorithm to assess label quality in any object detection dataset and catch errors (named ObjectLab for short). Extensive benchmarks show Cleanlab Object Detection identifies mislabeled images with better precision/recall than other approaches. When applied to the famous COCO dataset, Cleanlab Object Detection automatically discovers hundreds of mislabeled images, including errors where annotators mistakenly: overlooked an object that should’ve had a bounding box, sloppily drew a box in a poor location, or chose the wrong class label for an annotated object.\n We’ve open-sourced one line of code to find errors in any object detection dataset via Cleanlab Object Detection, which can utilize any existing object detection model you’ve trained. \n For those interested, you can check out the 5-minute tutorial to get started and the blog to read the details.\n    submitted by    /u/jonas__m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16srupa/r_automated_quality_assurance_for_object/",
          "publishedOn": "2023-09-26T15:58:52.000Z",
          "wordCount": 2764,
          "title": "[R] Automated Quality Assurance for Object Detection Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16srky8/r_need_directions_to_embed_and_query_structured/",
          "author": null,
          "description": "Hi there community, I hope everyone is doing well ::]\n I’m exploring ada-002 embedding model for building a recommendation system (along some other similarity search things like generating playlists), so naturally a lot of questions started to pop. But before goign deeper, let me explain what I am building and how the data is structured:\n Imagine a music app with song recommendations based on all the users history and musical metadata. Currently I have a table with a couple data on it just for tests - the users, the artists and the songs. Each of these columns have their own rows, for example song have genres, danceability, number of likes, etc.\n I am now implementing two more columns for history logs - a “history” (that will be related with users and songs) and a “session” (wich is a coll…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16srky8/r_need_directions_to_embed_and_query_structured/",
          "publishedOn": "2023-09-26T15:48:06.000Z",
          "wordCount": 3541,
          "title": "[R] 🤖🎸 Need directions to embed and query structured table data for a music recommendation system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sraie/p_where_can_i_find_preannotated_images_dataset/",
          "author": null,
          "description": "I am trying to do an Object Detection project, Does anyone know where I can find Pre-Annotated image dataset \n    submitted by    /u/Nomadic-Foe-011  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sraie/p_where_can_i_find_preannotated_images_dataset/",
          "publishedOn": "2023-09-26T15:36:52.000Z",
          "wordCount": 2579,
          "title": "[P] Where can I find Pre-Annotated images dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16spza8/rpd_scene_encoder_like_vit_l14_from_clip_but_for/",
          "author": null,
          "description": "I'm working on my thesis and want to perform 3D scene understanding and VQA. My scenes would be textured meshes (or pointclouds). My goal is not only to know the objects present in the scene but also the spatial relationships between them, like chair is in front of the couch, bottle is on the table etc. I want to know if there is a 3D scene encoder like the 2D image encoder ViT L/14 from CLIP. \n My search hasn't resulted much yet in this direction, but I have come across papers that render a 3D scene in multiple angles and then use 2D scene encoders on them. \n So I'd like to ask the community: \n  \nAre there 3D scene encoders like CLIP ViT \n If not, is there's any other way that I can approach this problem.\n  \n   submitted by    /u/Bluebird705  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16spza8/rpd_scene_encoder_like_vit_l14_from_clip_but_for/",
          "publishedOn": "2023-09-26T14:46:31.000Z",
          "wordCount": 2699,
          "title": "[R][P][D] Scene Encoder like ViT L/14 from CLIP but for 3D Scenes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16spsm3/research_exciting_new_paper_on_stylegan_domain/",
          "author": null,
          "description": "Hey, fellow machine learning enthusiasts!\n AIRI researchers are thrilled to share some exciting news with you all. Our paper, \"StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for One-shot and Few-shot Domain Adaptation\", has been accepted to ICCV 2023! 🥳\n  \nAbstract: Domain adaptation of GANs is a problem of fine-tuning GAN models pretrained on a large dataset (e.g., StyleGAN) to a specific domain with few samples (e.g., painting faces, sketches, etc.). While there are many methods that tackle this problem in different ways, there are still many important questions that remain unanswered. In this paper, we provide a systematic and in-depth analysis of the domain adaptation problem of GANs, focusing on the StyleGAN model. We perform a detailed exploration of the most i…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16spsm3/research_exciting_new_paper_on_stylegan_domain/",
          "publishedOn": "2023-09-26T14:39:41.000Z",
          "wordCount": 2909,
          "title": "[Research] Exciting New Paper on StyleGAN Domain Adaptation: StyleDomain - ICCV 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16spnpj/d_what_are_some_good_ai_tools_to_help_you_in_your/",
          "author": null,
          "description": "Title pretty much says it all. It would be really cool if we have more AI tools that don't just straight up generate an image but help artists in their own art process.\n    submitted by    /u/salehxoxo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16spnpj/d_what_are_some_good_ai_tools_to_help_you_in_your/",
          "publishedOn": "2023-09-26T14:34:33.000Z",
          "wordCount": 2614,
          "title": "[D] What are some good AI tools to help you in your own 2D digital art. Softwares or apps that help you improve and speed up your drawing/colouring process.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16so7bz/d_how_did_you_succeed_in_a_new_role_what_lessons/",
          "author": null,
          "description": "When switching to a new role what did you do to ensure that you succeed? What lessons did you learn from your previous job that you took into your new job? \n For example Im in the process of switching jobs and one of the things I’ve learnt is that when delivering results (during fire drills) the way I write my code is focused on simply getting the results out vs being organized, efficient and scalable. While I get from point A to point B the way I get from point A to point B is not the most efficient. I think something I can do is take a step back and take a top down approach to problem solving when I enter my new role.\n    submitted by    /u/Terrible-Hamster-342  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16so7bz/d_how_did_you_succeed_in_a_new_role_what_lessons/",
          "publishedOn": "2023-09-26T13:36:43.000Z",
          "wordCount": 2695,
          "title": "[D] How did you succeed in a new role? What lessons did you take from your previous role?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sni5g/n_next_week_iccv_feel_at_iccv_as_if_you_were_at/",
          "author": null,
          "description": "Next week will take place the International Conference on Computer Vision ICCV2023 in Paris.\n If you are not going, stay in touch by subscribing to the ICCV Daily magazine. It's free:\n https://www.rsipvision.com/feel-iccv-iccv/\n Full daily previews and reports of selected ICCV papers and events.\n https://preview.redd.it/yxmf2ksomlqb1.jpg?width=794&format=pjpg&auto=webp&s=7063c770e7a02d0ca7bba6f41ecc36438aa86256\n    submitted by    /u/Gletta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sni5g/n_next_week_iccv_feel_at_iccv_as_if_you_were_at/",
          "publishedOn": "2023-09-26T13:07:46.000Z",
          "wordCount": 2609,
          "title": "[N] NEXT WEEK ICCV - Feel at ICCV as if you were at ICCV!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sm2q0/news_speech_technology_with_tencent_ai_labs/",
          "author": null,
          "description": "https://preview.redd.it/4kmpzlb5clqb1.jpg?width=1140&format=pjpg&auto=webp&s=b09660dfebbd5947dc14020ca43df29b05cb82d9\n In a recent development, Tencent AI Lab has launched AutoPrep, a preprocessing framework explicitly crafted for in-the-wild speech data. This innovative framework is positioned to change the landscape of speech data processing by offering automated preprocessing and high-quality annotation for unstructured speech data, addressing the longstanding challenges in the field. \n Read the full story\n    submitted by    /u/El-Professor-1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sm2q0/news_speech_technology_with_tencent_ai_labs/",
          "publishedOn": "2023-09-26T12:08:06.000Z",
          "wordCount": 2620,
          "title": "[News] Speech Technology with Tencent AI Lab’s AutoPrep for Optimal Unstructured Speech Data Processing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16slvkz/r_deepmind_using_smallscale_proxies_to_hunt_and/",
          "author": null,
          "description": "Training giant AI models like GPT-3 requires large resources - thousands of GPUs running for months. As a solo researcher without access to that kind of scale, I can't easily reproduce experiments and findings from papers on huge models.\n But a new paper from DeepMind shows you can recreate and study training instabilities seen in massive models by using small ones.\n The key is increasing the learning rate:\n  \nThis reproduces \"attention collapse\" where the model focuses on just a few tokens, like overfitting.\n Also can reproduce \"logit divergence\" where output values drift unstably.\n  \nThese issues have been reported when scaling up to billions of params. The cool part is techniques that fix them for giant models also work for small models:\n  \nqk-layernorm prevents attention collapse.\n Adding a \"z-loss\" term stops logit divergence.\n  \nSome other highlights from the paper include:\n  \nLonger warmup helps stability, especially for bigger models.\n Decoupling LR and weight decay improves stability.\n Depth increases sensitivity much faster than width.\n Can predict upcoming issues from scaling trends.\n Default epsilon hurts at large scale.\n  \nIf the authors are right, one more tool that lets researchers study and even help train giant models without Google-size resources. Small models can guide large model development, sort of like how you can build a scale train set to study and improve how a railroad system works... for a lot less money than starting your own railroad company, buying land, building real tracks, etc.\n Full summary. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16slvkz/r_deepmind_using_smallscale_proxies_to_hunt_and/",
          "publishedOn": "2023-09-26T12:00:26.000Z",
          "wordCount": 2810,
          "title": "[R] DeepMind: Using small-scale proxies to hunt and solve large-scale transformer training instabilities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16skfan/r_towards_robust_continual_learning_with_bayesian/",
          "author": null,
          "description": "submitted by    /u/JustAddMoreLayers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16skfan/r_towards_robust_continual_learning_with_bayesian/",
          "publishedOn": "2023-09-26T10:49:51.000Z",
          "wordCount": 2562,
          "title": "[R] Towards Robust Continual Learning with Bayesian Adaptive Moment Regularization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sjyb0/research_analysis_of_back_pain_using_biomechanics/",
          "author": null,
          "description": "Worked on this beautiful analysis for some time and wanted to share how nice data visualization animations can look. It makes the whole process of data science feel like a story.\n And AI is mere mathematics. Mathematics are beautiful, and they can be understood\n A paper will be published soon, detailing the algorithms and the final results \n https://youtu.be/P-gHTqxCo_g?si=7clD0nb16EIDprkW\n    submitted by    /u/SemperZero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sjyb0/research_analysis_of_back_pain_using_biomechanics/",
          "publishedOn": "2023-09-26T10:24:40.000Z",
          "wordCount": 2621,
          "title": "[Research] Analysis of Back Pain Using Biomechanics and Artificial Intelligence (ML)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sifuy/d_john_carmack_and_rich_sutton_partner_to/",
          "author": null,
          "description": "John Carmack, celebrated software engineer and founder of Keen Technologies, and Dr. Richard Sutton, Chief Scientific Advisor at the Alberta Machine Intelligence Institute (Amii) announce a partnership to bring greater focus and urgency to the creation of artificial general intelligence (AGI).\n This partnership is the first public milestone for Keen Technologies, following its initial funding announcement in August of 2022. The initial $20M round was led by Nat Friedman, Danial Gross, Patrick Collision, Tobi Lutke, Jim Keller, Sequoia Capital, and Capital Factory. In December 2022, Carmack departed as consulting CTO at Meta to focus his efforts on AGI.\n Sutton is the principal founder of the field of reinforcement learning. His work with Keen Technologies advances previously announced research priorities to understand basic computational intelligence. Through this work, documented in part in The Alberta Plan, Sutton seeks to understand and create long-lived computation agents that interact with a vastly more complex world and come to predict and control their sensory input signals.\n https://www.amii.ca/latest-from-amii/john-carmack-and-rich-sutton-agi/\n    submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sifuy/d_john_carmack_and_rich_sutton_partner_to/",
          "publishedOn": "2023-09-26T08:58:56.000Z",
          "wordCount": 2728,
          "title": "[D] John Carmack and Rich Sutton partner to accelerate development of Artificial General Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16shkxz/p_vkfft_now_supports_quad_precision_doubledouble/",
          "author": null,
          "description": "Hello, I am the creator of the VkFFT - GPU Fast Fourier Transform library for Vulkan/CUDA/HIP/OpenCL/Level Zero and Metal. In the latest update, I have added support for quad-precision double-double emulation for FFT calculation on most modern GPUs. I understand that modern ML is going in the opposite low-precision direction, but I still think that it may be useful to have this functionality at least for some prototyping and development of concepts.\n The double-double approach to the evaluation of quads represents an FP128 number as an unevaluated sum of two double numbers (like 1 and 1e-17 - the second one is smaller than 1 ULP of the first one). This increases the significand from 53 to 106 bits, allowing to do operations on numbers varying up to 32 orders of magnitude. The range of numb…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16shkxz/p_vkfft_now_supports_quad_precision_doubledouble/",
          "publishedOn": "2023-09-26T08:03:21.000Z",
          "wordCount": 2995,
          "title": "[P] - VkFFT now supports quad precision (double-double) FFT computation on GPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sgxkh/discussion_why_should_better_networks_be_endtoend/",
          "author": null,
          "description": "TYPO IN THE TITLE: I wanted the title to be \"why should neural networks be end-to-end?\" My lazy ass was swipe texting on my phone and this typo happened. FML\n Especially in robotics, there's been a lot of research for end-to-end neutral networks where an image is the input and the control action is the output, for say, tasks like pick an object and place it somewhere. I feel this is very restrictive while developing such a solution because it tightly couples the \"control\" network to the \"estimation\" network. This reduces modularity in building the solution, i.e., if I find a better controller architecture (machine learning based or rule based) I'm unable to use that for the task I'm solving. Moreover it seems like the generalizability of this task suffers because training this network to do this task may make it very good at only doing that specific task and the explainability of the decision making goes out of the window because it is black box. Additionally doesn't more parameters mean requiring more data to train the model? I don't see much use from such network architectures. However, I do see the applications in machine translation where you simply train the encoder and decoder to the target language at the same time with a single loss function. It seems useful there, but maybe not so much in robotics.\n Can someone tell me their thoughts on end-to-end architectures? Let's have a healthy discussion\n Edit: typo\n    submitted by    /u/piccadilly_nickadeli  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sgxkh/discussion_why_should_better_networks_be_endtoend/",
          "publishedOn": "2023-09-26T07:21:34.000Z",
          "wordCount": 2806,
          "title": "[Discussion] Why should better networks be end-to-end? (Or why not?)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sga70/d_podcasts_about_ai_and_machine_learning/",
          "author": null,
          "description": "As the title says, what are the best podcasts to listen to that discuss new machine learning and AI advancements, new papers, and such?\n    submitted by    /u/darthJOYBOY  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sga70/d_podcasts_about_ai_and_machine_learning/",
          "publishedOn": "2023-09-26T06:41:21.000Z",
          "wordCount": 2583,
          "title": "[D] Podcasts about AI and Machine Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16sb9wx/prd_bio_inspired_algorithm_for_recommender_system/",
          "author": null,
          "description": "Hi! I am working on a content based recommender system that uses bio inspired optimization algorithms. The problem is, there aren't many resources online pertaining to this concept. Initially i thought it could be used to optimize text similarity. So is it possible to do that? Or it could be used to optimize any other aspect of the system? Please let me know if you have any knowledge! Thanks!\n    submitted by    /u/Jellyfishh_13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16sb9wx/prd_bio_inspired_algorithm_for_recommender_system/",
          "publishedOn": "2023-09-26T02:16:53.000Z",
          "wordCount": 2628,
          "title": "[P][R][D] Bio inspired algorithm for recommender system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16s8e4d/d_how_are_machine_learning_videos_made_and_what/",
          "author": null,
          "description": "Is this done with computer vision or somehow within the game itself?\n Also, what would you recommend as a resource to learning about machine learning fast? Is Microsoft Azure worth it or should I use TensorFlow? (I'll mostly do audio classification and game simulations)\n https://www.youtube.com/watch?v=tVNoetVLuQg\n Thanks so much! Please recommend go-to resources you've used to get up and running. Looking forward to what yall recommend.\n    submitted by    /u/Fit-Replacement7245  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16s8e4d/d_how_are_machine_learning_videos_made_and_what/",
          "publishedOn": "2023-09-26T00:06:13.000Z",
          "wordCount": 2622,
          "title": "[D] How are machine learning videos made, and what platform is best?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16s7if3/d_mlrelated_conspiracy_theories_that_you_guys/",
          "author": null,
          "description": "I have one that I'd like to share with the class. I think the grokking / double descent paper was sponsored by cloud providers to get people to continue training even when the loss curve has flattened out (speaking as someone who is watching a flat loss curve all day today).\n Anyone have any other ones?\n I'm only being semi-serious obviously.\n    submitted by    /u/new_name_who_dis_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16s7if3/d_mlrelated_conspiracy_theories_that_you_guys/",
          "publishedOn": "2023-09-25T23:27:33.000Z",
          "wordCount": 2616,
          "title": "[D] ML-related conspiracy theories that you guys want to discuss?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16s6iez/d_newbie_to_ml_are_there_hosted_service_that_can/",
          "author": null,
          "description": "I'm not really a ML/backend guy, mostly work with front end but I want to be able to use chatgpt api with long term memory. I did some research and it seems like it's possible with vector databases but seems quite complicated to setup. \n Are there hosted solutions/api that would allow me to just have long term memory with chatgpt? \n    submitted by    /u/yalag  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16s6iez/d_newbie_to_ml_are_there_hosted_service_that_can/",
          "publishedOn": "2023-09-25T22:45:35.000Z",
          "wordCount": 2621,
          "title": "[D] Newbie to ML, are there hosted service that can do long term memory of chatgpt?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16s5jq3/d_ml_deployment_survey/",
          "author": null,
          "description": "Hi, we are doing a survey of ML deployment platforms. Kindly fill it out and share it with your friends. We will share the results with the community\n https://forms.gle/1Q3WeSukHj8xBzUBA\n    submitted by    /u/fazkan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16s5jq3/d_ml_deployment_survey/",
          "publishedOn": "2023-09-25T22:07:19.000Z",
          "wordCount": 2578,
          "title": "[D] ML deployment survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16s3l0g/discussion_best_platformstools_to_help_build_ml/",
          "author": null,
          "description": "Looking for something that's lightweight on infrastructure/setup where I can quickly validate my use case quickly to see if I can achieve desired accuracy/precision with my initial data set, I've always done this manually in the past but was curious as to how others do it and if there are any tools designed for it or that support it\n    submitted by    /u/PatienceLogical2694  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16s3l0g/discussion_best_platformstools_to_help_build_ml/",
          "publishedOn": "2023-09-25T20:52:33.000Z",
          "wordCount": 2612,
          "title": "[Discussion] Best Platforms/Tools To Help Build ML POC",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16s1087/d_decentralized_alignment_and_training_for_llms_2/",
          "author": null,
          "description": "A magazine style article outline:\n Decentralizing AI: A Journey Towards True Collective Intelligence\n In today's digital age, AI shapes our interactions, decisions, and understanding of the world. Imagine a future where AI's guiding hand isn't controlled by a select few but shaped by the collective wisdom of people everywhere. Welcome to the horizon of decentralized training and alignment of Large Language Models (LLMs). Together, let's explore this visionary frontier.\n 1. The AI We Know Today\n At present, AI's most prominent representatives, LLMs like GPT-4, are a product of centralized training. Massive datasets, often sourced from specific regions or languages, direct their learning. While this method has given us incredibly powerful tools, it also raises concerns: potential biases, lac…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16s1087/d_decentralized_alignment_and_training_for_llms_2/",
          "publishedOn": "2023-09-25T19:12:57.000Z",
          "wordCount": 3561,
          "title": "[D] Decentralized alignment and training for LLMs: 2 articles GPT4 wrote",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rzlqa/p_ai_therapy/",
          "author": null,
          "description": "Hey, I'm the creator of MindMateGPT, an AI therapist that has helped a lot of people with emotional/social issues.\n It's not meant to replace humans, but it is a very useful augment as a daily therapy tool.\n It will refer you to a human if you have a very serious issue, but it provides a bunch of tools and coping tactics for every day emotional issues.\n Try it out! It's 100% free.\n    submitted by    /u/MindMateGPT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rzlqa/p_ai_therapy/",
          "publishedOn": "2023-09-25T18:18:26.000Z",
          "wordCount": 2620,
          "title": "[P] AI therapy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rzf36/d_what_are_your_goto_resources_on_the_most_up_to/",
          "author": null,
          "description": "Hello! I am a software engineer (4 yoe) working in full stack web and app development, transitioning to LLMs/ AI/ ML. My background includes extensive research in neuroscience so I am most comfortable w academic or comprehensive lectures. \n I am looking for reputable and vetted lectures, talks, resources on ML and the like. \n I am having trouble sifting through the surface level pop sci type resources floating around on the internet. I’m NOT looking for the 10min everything you need to know about AI type talks. \n Thanks in advance!\n    submitted by    /u/yosoylatte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rzf36/d_what_are_your_goto_resources_on_the_most_up_to/",
          "publishedOn": "2023-09-25T18:11:11.000Z",
          "wordCount": 2649,
          "title": "[D] What are your go-to resources on the most up to date research on AI/ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rydfz/p_update_on_candle_a_minimalist_ml_framework_in/",
          "author": null,
          "description": "this is mostly a cross-post from r/rust as my initial attempt failed because of some external links\n We've first announced Candle, a minimalist ML framework in Rust 6 weeks ago. Since then we've focused on adding various recent models and improved the framework so as to support the necessary features in an efficient way. You can checkout a gallery of the examples, supported models include:\n  \nLarge language models: LLaMA, LLaMA v2, Falcon, Phi-v1.5, StarCoder.\n Quantized models with the llama.cpp approach: LLaMA, T5, Phi-v1.5.\n Image generation: Stable Diffusion, Wuerstchen.\n Computer Vision: DINOv2, yolo-v3, yolo-v8, Segment-Anything Model.\n Text-to-speech: Whisper.\n  \nOne of the big upside of the pure Rust approach is that models can run directly in the browser using WASM, these can be accessed through this collection, you can try out Yolo, Whisper, Segment-Anything, T5, Llama2-c from your web browser.\n Finally, in order to present a use case where Candle has unique capabilities, we've built a quantized version of the recently released Phi-v1.5 LLM. You can try it out with the following command, this uses a q4k quantized model resulting in very fast inference on CPU while still producing pretty nice texts.\n $ cargo run --example phi --release -- \\ --prompt \"Explain how to find the median of an array and write the corresponding python function.\\nAnswer:\" \\ --quantized --sample-len 200 Explain how to find the median of an array and write the corresponding python function. Answer: The median is the middle value in an array. If the array has an even number of elements, the median is the average of the two middle values. def median(arr): arr.sort() n = len(arr) if n % 2 == 0: return (arr[n//2 - 1] + arr[n//2]) / 2 else: return arr[n//2] \n It's still very early days for Candle so please let us know if you start using it and run into some rough edges. We look forward to Rust getting a lot more usage in the ML space!\n    submitted by    /u/l-m-z  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rydfz/p_update_on_candle_a_minimalist_ml_framework_in/",
          "publishedOn": "2023-09-25T17:30:28.000Z",
          "wordCount": 2877,
          "title": "[P] Update on Candle, a minimalist ML framework in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ryc23/d_why_is_fastgan_considered_a_simple_gan/",
          "author": null,
          "description": "Hi, I'm reading this GAN paper which introduces a faster and simpler GAN architecture for creating high resolution images: FastGAN paper\n The authors claim the computational advantage of their approach is partly the simple architecture. \n Looking at figure 3 and 4, I cannot quite see why this is considered a simpler architecture to older GANs,say DCGAN. I get the technical argument that the generator only has one convolutional layer, but figure 3 has lots of up sampling layers, and the discriminator has plenty of downsampling layers. So why is this considered a simple GAN model? \n Any pointers appreciated.\n    submitted by    /u/treetop-600  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ryc23/d_why_is_fastgan_considered_a_simple_gan/",
          "publishedOn": "2023-09-25T17:29:05.000Z",
          "wordCount": 2652,
          "title": "[D] Why is FastGAN considered a simple GAN architecture?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rvbrh/d_user_intent_extraction_our_journey_with_infra/",
          "author": null,
          "description": "I just wrapped up a new blog post about our experience working with LLMs while developing InfraCopilot. We're using both GPT4 and GPT3.5-turbo(16k) differently compared to what others are doing. We found a few new LLM tricks like dynamic examples and automated e2e intent parsing testing that I think are applicable to many other teams.\n I'd love to hear what everyone thinks, have you tried using dynamic examples while working with LLMs?\n    submitted by    /u/lothamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rvbrh/d_user_intent_extraction_our_journey_with_infra/",
          "publishedOn": "2023-09-25T15:33:40.000Z",
          "wordCount": 2627,
          "title": "[D] User Intent Extraction: Our Journey with Infra and LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rs7x9/d_is_tensorflow_dead_or_heading_in_that_direction/",
          "author": null,
          "description": "First of all anyone offended by that question - heartiest apology. I am using it myself profusely at the moment. The reason for me asking this question, over last few weeks / months, I have been gradually educating myself in machine learning using Tensorflow and have been able to train multiple models using only one of the model zoo candidates. All the other pre trained models have failed me so far.\n I went onto Tensorflow official forum / Stackoverflow / Tensorflow github with specific error messages that I am getting on Ubuntu with Nvidia card / Mac M2 and there has been absolute radio silence in response to multiple posts over last month. Found many open issues listed since 2020 on the same line as mine i.e. identical error messages that people have come across.\n Finally after about a month of being on TF forum, I direct messaged an official TF2 dev who kindly responded with answers. I haven't succeeded yet with any of the pre trained model from the official section. Only one model from research section is working so far for me i.e. Faster_rcnn_resnet_50_640x640 ..\n Thus the question. Kindly help me enlighten myself with where is this thing headed. Should I consider switching to Pytorch or some alternative ? If yes what alternatives do you recommend ? TIA\n    submitted by    /u/dpadhy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rs7x9/d_is_tensorflow_dead_or_heading_in_that_direction/",
          "publishedOn": "2023-09-25T13:32:39.000Z",
          "wordCount": 2775,
          "title": "[D] Is Tensorflow dead or heading in that direction ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rrokr/d_trainingfinetuning_a_llm/",
          "author": null,
          "description": "Hey! Months ago, I was fascinated by Karpathy’s nanoGPT project - the ability to train a small LLM on your text file seemed very interesting to me. I tried training it on my chat history to build some inifinite chat-generator for fun, but unfortunately, the results were bad. Recently I had even worse experiences with newly-released ChatGPT 3.5 fine-tuning.\n Are there any good, simple ways to train/fine-tune LLMs now? I would love something that could train on an Apple M2 processor (like Karpathy’s nanoGPT), or Colab, or cheap API (like ChatGPT fine-tuning).\n    submitted by    /u/11igor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rrokr/d_trainingfinetuning_a_llm/",
          "publishedOn": "2023-09-25T13:12:04.000Z",
          "wordCount": 2641,
          "title": "[D] Training/finetuning a LLM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rqo3k/r_microsoft_researchers_announce_codeplan/",
          "author": null,
          "description": "As software projects grow, changing code across entire repositories becomes tedious & error-prone. Tasks like migrating APIs or updating dependencies require complex edits across files. I explored a new approach from Microsoft Research to automate these \"repository-level\" coding challenges with AI.\n Their new paper proposes CodePlan - an AI system that breaks repository tasks into incremental steps guided by planning & analysis.\n Key points:\n  \nUses LLMs like GPT-3 for localized code edits\n Maintains validity across repository via incremental analysis\n Adaptively plans multi-step changes based on code dependencies\n Significantly outperformed baselines on API migration & temporal edits\n Automated tasks across 168 file C# codebase\n 2-3x more accurate edit locations than baselines\n Produced final valid codebases, unlike reactive approaches\n  \nThe core insight is combining LLM strengths with rigorous planning based on dependency analysis. This automates interdependent code changes that naive LLM use struggles with (I personally have these kinds of issues all the time with GPT4 - lack of context about the entirety of the repo/how files fit together).\n I think CodePlan demonstrates AI can expand beyond small coding assists into large-scale engineering tasks. Planning + LLMs > LLMs alone. This could really improve productivity and code quality... at least for me :)\n Full summary. Arxiv paper: https://arxiv.org/pdf/2309.12499.pdf\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rqo3k/r_microsoft_researchers_announce_codeplan/",
          "publishedOn": "2023-09-25T12:27:33.000Z",
          "wordCount": 2764,
          "title": "[R] Microsoft Researchers Announce CodePlan: Automating Complex Repo-Level Software Engineering Tasks with AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rpi6b/d_distillation_understanding/",
          "author": null,
          "description": "In the main scenario, the smaller model learns from the same data as the bigger model and also from the predictions of the bigger model and incorporate the 2 output labels on a specific loss.\n Basically, it is equivalent to say to the smaller model : \"be careful this example is hard\" in the case that big model divergence from true output? I am missing something?\n    submitted by    /u/Grumlyly  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rpi6b/d_distillation_understanding/",
          "publishedOn": "2023-09-25T11:32:21.000Z",
          "wordCount": 2614,
          "title": "[D] Distillation understanding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rp6tc/baby_sleep_tracker_using_a_basic_svm_p/",
          "author": null,
          "description": "I made a FOSS baby sleep tracking system. The system tracks wake/sleep status, and informs the user when their baby is likely to need a nap next. But it stopped working as soon as my baby started sleeping on his stomach, and started using blankets. The original version relied on anatomical features being visible.\n This version delivers the ability to train a blank slate SVM binary classifier on pictures of a user's baby, making it extremely biased (and resilient) to the custom behaviors the user's baby exhibits (blanket covering baby, teddy bear/other objects in crib, etc.). All generated data stays on your machine, nothing leaves the LAN.\n Video: https://youtu.be/8i0wHA_knKc?si=uhA4PpOYP0jMKLz1\n For obvious reasons I didn't have a dataset of babies sleeping.. so I wrapped a python/flask service with a React app which lets a user press a button to train the model w/ a new image from the camera's live stream. Then this model is invoked over time (+ other heuristics) to determine whether your baby is present and sleeping.\n I believe it works better than $300+ systems sold on the market, open sourced it: https://github.com/calebolson123/BabySleepCoach\n ​\n I'm thinking a fun next step for this project could be to apply privateGPT on the feature-engineered sleep records for a true \"Sleep Coach\"\n    submitted by    /u/GoochCommander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rp6tc/baby_sleep_tracker_using_a_basic_svm_p/",
          "publishedOn": "2023-09-25T11:16:10.000Z",
          "wordCount": 2762,
          "title": "Baby Sleep Tracker using a basic SVM [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16roy7g/d_does_granger_causality_work_for_time_series/",
          "author": null,
          "description": "Is there a Granger test where series are a quarterly one and a weekly one?\n    submitted by    /u/Pineapple_throw_105  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16roy7g/d_does_granger_causality_work_for_time_series/",
          "publishedOn": "2023-09-25T11:04:05.000Z",
          "wordCount": 2571,
          "title": "[D] Does granger causality work for time series with different frequencies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rmla9/r_seeking_insights_on_ai_security_challenges/",
          "author": null,
          "description": "Hello everyone,\n I'm conducting a research survey on the challenges and gaps in AI security. Given the expertise in this community, I believe your feedback would be invaluable in shaping the future of AI security solutions.\n The survey takes less than 10 minutes and delves into current practices, perceptions, and needs related to AI security. If you have experience or insights in this area, I would greatly appreciate your participation.\n Survey Link: https://forms.gle/i9AefyL8izyt9QjX6\n All responses will remain anonymous, and the collected data will only be used for research purposes. Additionally, if you're open to a deeper discussion on this topic, there's an option within the survey to indicate your interest.\n Thank you in advance for your time and insights! If you have any questions or additional thoughts, please don't hesitate to comment below.\n    submitted by    /u/Agile_Temperature678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rmla9/r_seeking_insights_on_ai_security_challenges/",
          "publishedOn": "2023-09-25T08:43:20.000Z",
          "wordCount": 2687,
          "title": "[R] Seeking Insights on AI Security Challenges: Short Survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rjqqi/d_how_does_ddim_work/",
          "author": null,
          "description": "The Wikipedia page on Diffusion Models has been pretty minimal for an entire year. I feel like it should be fixed, so I fixed it finally. It strikes me odd that such a hot topic has such atrociously bad Wikipedia. I feel duty-bound to educate the near-future AI, since they'll be reading Wikipedia for the next few years at least.\n Currently I think it's mostly complete, but I still don't understand the mathematical details of DDIM (I tried reading the paper and could not understand it), or generally how it is possible to sample without noise. This is a serious problem since as far as I see most of practical diffusion models use deterministic sampling, and they are all based on the same principle as DDIM.\n If anyone could explain simply what DDIM is really doing that would be great. I understand part of the paper: that they constructed an entire family of distributions over trajectories that has the same two-point marginals.\n I also haven't got much in the section on Examples. If you think there are some interesting examples of Diffusion Models, please comment below.\n    submitted by    /u/furrypony2718  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rjqqi/d_how_does_ddim_work/",
          "publishedOn": "2023-09-25T05:45:35.000Z",
          "wordCount": 2736,
          "title": "[D] How does DDIM work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rib9k/d_how_has_work_changed_for_you_given_the_shift/",
          "author": null,
          "description": "For the data scientists/applied scientists/research scientists - What kind of projects are you working on now that the economy has shifted and companies are focusing more on profitability than on growth? \n What techniques have worked for you and what are you looking into as potential solutions?\n An example would be - optimizing your marketing campaign spend in channels that give you the most bang for your buck vs just spending arbitrarily to acquire new users.\n    submitted by    /u/Terrible-Hamster-342  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rib9k/d_how_has_work_changed_for_you_given_the_shift/",
          "publishedOn": "2023-09-25T04:24:10.000Z",
          "wordCount": 2634,
          "title": "[D] How has work changed for you given the shift from growth to profitability?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rg533/r_leap_hand_lowcost_2kusd_anthropomorphic/",
          "author": null,
          "description": "submitted by    /u/pathak22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rg533/r_leap_hand_lowcost_2kusd_anthropomorphic/",
          "publishedOn": "2023-09-25T02:33:17.000Z",
          "wordCount": 2558,
          "title": "[R] LEAP Hand: Low-Cost (<2KUSD), Anthropomorphic, Multi-fingered Hand -- Easy to Build (link in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rd9et/p_openglbased_inference_engine/",
          "author": null,
          "description": "I created an OpenGL/OpenGLES based inference framework a while back which is rather GPU-agnostic and might be a good option for distributing multi-platform ML solutions for platforms ranging from Android over desktop to WebGL(2). Quite recently I added support for LLMs to that (restricted to 4-bit quantized Llama models for now). \n The LLM-enabled fork can be found here (compileable sample code inside). \n Maybe someone finds this useful. Also looking for collaborators to extend the functionality.\n ​\n    submitted by    /u/mtnwrw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rd9et/p_openglbased_inference_engine/",
          "publishedOn": "2023-09-25T00:15:20.000Z",
          "wordCount": 2584,
          "title": "[P] OpenGL-based inference engine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rcmsw/p_i_create_a_small_pytorch_utility_to_import/",
          "author": null,
          "description": "Hi guys , TorchClassifierData is A small pytorch utility to Import, Split ,Normalize and Visualize custom dataset for classification tasks. wich is indispensable for real word problem .\n You can find a full notebook that use TorchClassifierData to train a classifier on this kaggle dataset here.\n The code source is avalaible on my github. Thank you. \n    submitted by    /u/charles_data_dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rcmsw/p_i_create_a_small_pytorch_utility_to_import/",
          "publishedOn": "2023-09-24T23:46:27.000Z",
          "wordCount": 2572,
          "title": "[P] I create a small pytorch utility to Import custom dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rbp9t/d_why_do_diffusion_models_work_so_well_while/",
          "author": null,
          "description": "Diffusion models are basically Langevin sampling. What are the key differences and tricks that set them apart from Langevin dynamics? Why do they work so well while very similar sampling methods don't?\n    submitted by    /u/Dangerous-Flan-6581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rbp9t/d_why_do_diffusion_models_work_so_well_while/",
          "publishedOn": "2023-09-24T23:03:52.000Z",
          "wordCount": 2549,
          "title": "[D] Why do Diffusion models work so well while SG-MCMC does not?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16rbg7g/d_in_ml_a_phd_gives_you_a_10year_head_start_over/",
          "author": null,
          "description": "​\n https://preview.redd.it/cczbhu367aqb1.png?width=1600&format=png&auto=webp&s=f1761911d7ce3bbefaef43774b5d60f638886893\n ML is often portrayed as a magical field where anyone with a laptop and Python skills can build amazing AI systems. \n The reality is less democratic: mastering ML requires gritty, systematic work best learned through formal training. You need rock solid foundations in math, programming, and core concepts—skills acquired through advanced education, which (almost always) is beyond self-taught hackers. \n Most think a PhD is unnecessary, but the reality is that advanced degrees provide the deepest training. Patience and persistence do matter, but a PhD gives you a 10-year head start over weekend warriors. The hype overlooks the work and education needed to excel. This article has a great blueprint of all the required skills to become a ML Engineer (in the CV field).\n    submitted by    /u/btcmx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16rbg7g/d_in_ml_a_phd_gives_you_a_10year_head_start_over/",
          "publishedOn": "2023-09-24T22:53:21.000Z",
          "wordCount": 2642,
          "title": "[D] In ML, a PhD gives you a 10-year head start over weekend warriors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ra2im/d_offer_from_bug_4_vs_startup/",
          "author": null,
          "description": "So briefly about my current experience, I graduated 2 years ago with a bachelor in data science and I have 2-3 years of experience as a data scientist/ml engineer/software engineer.\n So I’ve got competing offers, one from the big 4 accounting firms as a software systems engineer - AI/ML (Big 4) and the other as a machine learning engineer. The startup salary is higher while big 4 is lower. Additionally the startup isn’t necessarily a unicorn it’s a relatively small startup with an interesting product but it doesn’t necessarily blow me away. The salary at the startup is 15 percent higher that that of the big 4 offer. For those wondering I did already negotiate the salary and they did increase it marginally. \n I am conflicted because I think that the big 4 jobs will have\n 1) more career growth 2) more potential future opportunities and 3) more networking potential\n Is this an accurate assessment? Which is the best job to take for maximum future potential?\n    submitted by    /u/zorenum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ra2im/d_offer_from_bug_4_vs_startup/",
          "publishedOn": "2023-09-24T21:56:41.000Z",
          "wordCount": 2675,
          "title": "[D] Offer From Bug 4 VS Startup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ra2hf/p_hardware_resources_for_training_swinbert/",
          "author": null,
          "description": "So I've been thinking of implementing SwinBert for a college project and have been wondering what all resources i would be needing for a computer.\n Any ideas?\n    submitted by    /u/Big-Brain_69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ra2hf/p_hardware_resources_for_training_swinbert/",
          "publishedOn": "2023-09-24T21:56:39.000Z",
          "wordCount": 2538,
          "title": "[P] Hardware Resources for training SwinBert",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r8bl8/d_career_advice_for_a_midlevel_ml/",
          "author": null,
          "description": "I’ve been having a bit of an existential crisis as of late and wanted to ask for advice on how to move forward.\n I have a Master’s in CS with research experience and a few publications applying machine learning in a fairly niche area (So not novel from the ML side). Since graduating, I’ve worked ~2 years as an ML engineer in small company(Niche area, different than research).\n I’ve done quite well here and have played a critical role in taking several big greenfield projects to completion. \n Most of my work is framing problems, understanding what’s possible with current research, then building the data pipelines, and training models(with small mods here and there). My main worry is that I might be approaching a point where there won’t be any more problems I’m capable of solving here. I’d imagine I’d hit the same wall at any future company with my current skill set.\n I’d like to continue working in CV/Graphics/Perception if possible, but I’d also like to be realistic about the competitiveness of this particular subfield and my general ability.\n I’ve been trying to up-skill and am struggling to self study MVG by Hartley and Zisserman. I’m also looking into OMCS to review low-level programming - maybe I can transition to optimizing ml/cv algorithms?\n It hit me recently that I don’t really know what to study/what I’d benefit from learning. Hence this post. Any advice would be most appreciated!\n    submitted by    /u/answersareallyouneed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r8bl8/d_career_advice_for_a_midlevel_ml/",
          "publishedOn": "2023-09-24T20:47:46.000Z",
          "wordCount": 2751,
          "title": "[D] Career advice for a mid-level ml engineer(Perception/CV)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r801s/d_imagetotext_webscraping/",
          "author": null,
          "description": "I'm curious if anyone has tried pix2struct-large for web-scraping text from wesites.\n If so - how well did it perform?\n If not - is there something else that is considered better to use?\n    submitted by    /u/ReddSpark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r801s/d_imagetotext_webscraping/",
          "publishedOn": "2023-09-24T20:35:01.000Z",
          "wordCount": 2541,
          "title": "[D] Image-to-text web-scraping",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r6kaf/d_where_will_the_demand_for_ai_work_be_in_future/",
          "author": null,
          "description": "Hypothesis:\n Big tech companies are investing vast amounts of money to develop general models on which others will build. They'll develop interfaces to make it easier for others to fine-tune on top of their models. So that there will be less and less of a need for ML engineers that know how to create a deep learning model in Pytorch, and more and more of a need for data engineers that simply plug into pre-trained models. An AI assistant will also be quicker at coding up a more bespoke AI model for a companies needs, guided by data engineers.\n What do people think? Is this a scenario that they think will play out? Where will the demand for AI skills be coming from in the future?\n    submitted by    /u/QuintBa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r6kaf/d_where_will_the_demand_for_ai_work_be_in_future/",
          "publishedOn": "2023-09-24T19:36:38.000Z",
          "wordCount": 2642,
          "title": "[D] Where will the demand for AI work be in future?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r5ywj/r_researchers_announce_gpt4tools_a_method_for/",
          "author": null,
          "description": "LLMs are great with words but can't handle visual tasks like understanding images. Teaching them to use visual tools could make them much more capable.\n A new paper introduces GPT4Tools - a method to efficiently teach existing LLMs to invoke tools for visual tasks without proprietary data.\n My highlights from the paper:\n  \nUses ChatGPT as a \"teacher\" to generate instructional data for other LLMs\n Fine-tunes LLMs like Vicuna on this data using selective weight tuning (keeps base model frozen)\n Allows smaller 13B LLM to match 175B GPT-3.5 on seen tools after tuning\n Data augmentation with negative/context samples was found to be the secret sauce to get this to work\n Can generalize to brand new visual tools in a zero-shot way\n  \nThis is big because it shows we may not need hyper-expensive training of massive models to impart visual capabilities to LLMs. They seems to be generalizable enough that they can be taught to work with images. Some examples shown include counting objects or segmenting items in pictures using other tools.\n With this approach, existing models can be made multi-modal! Pretty cool.\n Full summary. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r5ywj/r_researchers_announce_gpt4tools_a_method_for/",
          "publishedOn": "2023-09-24T19:11:58.000Z",
          "wordCount": 2708,
          "title": "[R] Researchers announce GPT4Tools: a method for teaching LLMs how to use tools for visual tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r590k/d_tools_to_gather_and_collaborate_on_finetuning/",
          "author": null,
          "description": "Hey all, I run a small team & we are collaborating on a few data sets that we use to fine-tune GPT3.5,\n We are currently using Google Sheets and I'm wondering if there is a tool where we can organize our data preferably with version control\n Any ideas?\n    submitted by    /u/zeJaeger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r590k/d_tools_to_gather_and_collaborate_on_finetuning/",
          "publishedOn": "2023-09-24T18:42:44.000Z",
          "wordCount": 2562,
          "title": "[D] Tools to gather and collaborate on fine-tuning datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r4mzu/d_colored_point_cloud_completion/",
          "author": null,
          "description": "Hello, I have created point clouds from images using Point-E. Sadly they are very sparse (for example wehn inputting an image of a house, the roof has very few points in it) and I was searching for other Models, that could\n  \nmake the PC more dense and\n predict the color of every point.\n  \nPoint-E outputs xyz and rgb vectors for every point.\n Do some of you have advise for me here?\n    submitted by    /u/bySmily  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r4mzu/d_colored_point_cloud_completion/",
          "publishedOn": "2023-09-24T18:17:43.000Z",
          "wordCount": 2581,
          "title": "[D] Colored Point Cloud Completion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r4khr/pjust_published_my_second_blog_on_medium_about/",
          "author": null,
          "description": "submitted by    /u/indusop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r4khr/pjust_published_my_second_blog_on_medium_about/",
          "publishedOn": "2023-09-24T18:15:04.000Z",
          "wordCount": 2533,
          "title": "[P]Just published my second blog on medium about feature scaling in machine learning please have a look",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r3j0m/dp_how_to_create_a_3d_gymnasium_environment_for/",
          "author": null,
          "description": "Hi\n I'm a student and working on a RL project for the university and need some guidance.\n I have created a 3d model with mujoco (I have the xml file) how do I create an environment in gymnasium with this xml file?\n for the sake of an example let's say I have the xml file of the humanoid model how do I load this in gymnasium so that I could train it to walk? (this is just an example because the current project is harder to explain, but will use the humanoid model in the project)\n or is the approach that I'm trying is not appropriate at all? I came across this stackoverflow post where they say mujoco is itself good for this but was hard for me to understand due to lack of examples.\n would really appreciate some advice and guidance \n thank you.\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r3j0m/dp_how_to_create_a_3d_gymnasium_environment_for/",
          "publishedOn": "2023-09-24T17:32:40.000Z",
          "wordCount": 2660,
          "title": "[D][P] how to create a 3D gymnasium environment for mujoco env?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16r0pa5/p_made_a_simple_semantic_segmentation_annotation/",
          "author": null,
          "description": "I just open-sourced (MIT License) semantic segmentation annotation tool powered by segment-anything model that I used for a while in my projects. Hopefully it will help someone as it seems to me that it is more suitable for small projects than popular huge web based annotation tools.\n Link to the project: SAMAT (any feedback in Discussions section on GitHub is appreciated)\n Features:\n  \nBrush annotation (opposed to polygons)\n Magic Wand (like in Photoshop) powered by segment-anything masks (it is optional, if you don’t have cool GPU to prepare masks)\n  \nsamat showcase\n Why yet another annotation tool?\n Before starting this project I tried supervisely, segments.ai, roboflow and several others, but found them not convenient for my tasks.\n Their cons, I tried to fix with my tool:\n  \nLatency: they are web based, hence burden with irritating latency during labeling (SAMAT is snappy because it is a local desktop app)\n Complicated: too much features, hence overloaded UI (SAMAT is just a colored brush)\n  \nP.S. there is another labeling tool called SALT on github which also uses segment-anything model, but it follows different approach to UI/UX, may be it will be more suitable for you, so take a look at it too.\n    submitted by    /u/Divelix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16r0pa5/p_made_a_simple_semantic_segmentation_annotation/",
          "publishedOn": "2023-09-24T15:37:32.000Z",
          "wordCount": 2712,
          "title": "[P] Made a simple semantic segmentation annotation tool with segment-anything masks support in PyQt5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qztf4/r_generative_ai_in_mafialike_game_simulation/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.11672\n Abstract: In this research, we explore the efficacy and potential of Generative AI models, specifically focusing on their application in role-playing simulations exemplified through Spyfall, a renowned mafia-style game. By leveraging GPT-4's advanced capabilities, the study aimed to showcase the model's potential in understanding, decision-making, and interaction during game scenarios. Comparative analyses between GPT-4 and its predecessor, GPT-3.5-turbo, demonstrated GPT-4's enhanced adaptability to the game environment, with significant improvements in posing relevant questions and forming human-like responses. However, challenges such as the model;s limitations in bluffing and predicting opponent moves emerged. Reflections on game development, fi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qztf4/r_generative_ai_in_mafialike_game_simulation/",
          "publishedOn": "2023-09-24T15:00:45.000Z",
          "wordCount": 2845,
          "title": "[R] Generative AI in Mafia-like game simulation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qzt8j/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qzt8j/d_simple_questions_thread/",
          "publishedOn": "2023-09-24T15:00:32.000Z",
          "wordCount": 2558,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qvw6d/d_insights_on_the_arsenal_tool_ai_security/",
          "author": null,
          "description": "For those who have tried Microsoft's Arsenal tool in conjunction with MITRE's offerings, how does it compare to other AI security tools you've used?\n    submitted by    /u/Agile_Temperature678  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qvw6d/d_insights_on_the_arsenal_tool_ai_security/",
          "publishedOn": "2023-09-24T11:54:05.000Z",
          "wordCount": 2537,
          "title": "[D] insights on the arsenal tool, AI Security",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qv1q7/d_help_with_rvc_mode_training/",
          "author": null,
          "description": "so I've had this problem where I try to train the model in RVC but the training stops after:\n INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n Does anyone know why is it happening and how can I fix it?\n this is what it shows to me and idk what to do... any help would be appreciated thank you\n    submitted by    /u/mannequin7412  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qv1q7/d_help_with_rvc_mode_training/",
          "publishedOn": "2023-09-24T11:07:50.000Z",
          "wordCount": 2570,
          "title": "[D] help with RVC mode training!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qul5q/d_what_are_some_good_resources_for_implementing/",
          "author": null,
          "description": "Our company has a new data science team and the team is relatively in experienced. I am working on a regression ML project and want to deploy it using best practices.What materials are there for learning how to implement CI/CD pipelines that deal with data transformation/model building/testing/deploying? The company uses azure environment with databricks/azure devops setup. I appreciate resources that show examples on how to setup MLOps on the company's environments.\n    submitted by    /u/userid95  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qul5q/d_what_are_some_good_resources_for_implementing/",
          "publishedOn": "2023-09-24T10:41:37.000Z",
          "wordCount": 2585,
          "title": "[D] What are some good resources for implementing MLOps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qu37e/d_interpretation_of_wx_b_0_in_svm/",
          "author": null,
          "description": "[D] I watch this MIT lecture and I don't know if my understanding of wx + b = 0 is correct or not. Every explanation of the hyperplane state that all the points which are orthogonal to the vector w are in the hyperplane. However, all data point coordinates are defined wrt origin. So in order to attain this objective, we define the hyperplane as :\n wx = c\n This vector w is the vector which is normal to the hyperplane. And the data points x when dot producting with w outputting c are the points which are in the hyperplane due to the coordinates representation of x wrt origin.\n So points in the hyperplane are the points which when performing dot product with w equals 0 when the coordinates is defined wrt origin that lie in the hyperplane is equivalent to the points which when performing dot product with w equals c when the coordinates is defined wrt original origin (0) or (0,0) or ...\n    submitted by    /u/Emotional-Fox-4285  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qu37e/d_interpretation_of_wx_b_0_in_svm/",
          "publishedOn": "2023-09-24T10:12:35.000Z",
          "wordCount": 2681,
          "title": "[D] Interpretation of wx + b = 0 in SVM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qu0tp/dllms_engineeringtechnical_blogsresources/",
          "author": null,
          "description": "Hi,\n I have a fairly good understanding of how LLMs work under the hood, the attention mechanism, the different architectures and so on. However most of that knowledge takes the backseat in practical cases, especially in the industry. Are there any resources which discuss practical LLM engineering and the challenges that come with it? I'm talking about everything from fine-tuning to dealing with tokenisation limit to optimising the vectorDB and so on?\n    submitted by    /u/thoraway0612  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qu0tp/dllms_engineeringtechnical_blogsresources/",
          "publishedOn": "2023-09-24T10:08:36.000Z",
          "wordCount": 2580,
          "title": "[D]LLMs engineering/technical blogs/resources?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qlrw6/r_robot_learns_to_throw_and_catch_with_hands/",
          "author": null,
          "description": "submitted by    /u/XiaolongWang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qlrw6/r_robot_learns_to_throw_and_catch_with_hands/",
          "publishedOn": "2023-09-24T02:09:03.000Z",
          "wordCount": 2512,
          "title": "[R] Robot learns to throw and catch with hands",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qga1l/d_tortoise_tts_mimic_quality/",
          "author": null,
          "description": "Hi everyone, been playing with tortoise all day and trying to get a clone of my voice as close as possible and nothing seems to work.\n I'm thinking maybe I need to use my phone to record my voice and pass it into tortoise but I'm not sure of how to get the wav files from my phone at the recommended quality.\n Has anybody had really good luck getting tortoise to mimic you very closely?\n    submitted by    /u/MaxxMarketTrades  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qga1l/d_tortoise_tts_mimic_quality/",
          "publishedOn": "2023-09-23T21:48:35.000Z",
          "wordCount": 2586,
          "title": "[D] Tortoise TTS - mimic quality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qfp0l/d_prediction_when_targets_lag_value_are_part_of/",
          "author": null,
          "description": "I'm using LGBM for regression, where the Target column's lagged values (7 columns for each lag day) are also used as predictors when training the model. Absence of the 7Day lag values severely increases MAE value.\n Now when using the model in production, if I use the complete data as training dataset, how to get the 7day lag value of the time period I'm planning to predict? I obviously won't have the target value, to calculate it's 7Day lag value. What to do now?\n To explain in more detail:\n So, I'm predicting sales amount (Target variable y). The model is trained on 20 predictors (X), and 7 of them are the lag value of the Target Variable, i.e. Sales Amount.\n The thing is, while preparing the model, I had access to both X & y dataset, thus I could easily calculate Y's Lag values.\n Now, when predicting for future timestamps, I won't be having y. So how do I calculate the lag values, which is required in the trained model's predictor columns now?\n    submitted by    /u/boredmonki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qfp0l/d_prediction_when_targets_lag_value_are_part_of/",
          "publishedOn": "2023-09-23T21:23:23.000Z",
          "wordCount": 2688,
          "title": "[D] Prediction when Target's lag value are part of predictors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qdltp/r_rain_your_language_models_can_align_themselves/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07124 \n Abstract:\n  \nLarge language models (LLMs) often demonstrate inconsistencies with human preferences. Previous research gathered human preference data and then aligned the pre-trained models using reinforcement learning or instruction tuning, the so-called finetuning step. In contrast, aligning frozen LLMs without any extra data is more appealing. This work explores the potential of the latter setting. We discover that by integrating self-evaluation and rewind mechanisms, unaligned LLMs can directly produce responses consistent with human preferences via self-boosting. We introduce a novel inference method, Rewindable Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate their own generation and use the evaluation results to guid…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qdltp/r_rain_your_language_models_can_align_themselves/",
          "publishedOn": "2023-09-23T19:55:03.000Z",
          "wordCount": 2752,
          "title": "[R] RAIN: Your Language Models Can Align Themselves without Finetuning - Microsoft Research 2023 - Reduces the adversarial prompt attack success rate from 94% to 19%!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qd2a5/p_were_building_a_cloud_for_ai_agents_ai_apps_its/",
          "author": null,
          "description": "submitted by    /u/mlejva  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qd2a5/p_were_building_a_cloud_for_ai_agents_ai_apps_its/",
          "publishedOn": "2023-09-23T19:31:08.000Z",
          "wordCount": 2541,
          "title": "[P] We're building a cloud for AI agents & AI apps, It's free and we're gradually open-sourcing the infra. Would love to hear your feedback!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qcs2u/d_learn_machinelearning/",
          "author": null,
          "description": "Hello everyone so I wanted to get into machinelearning and learn about ai Can someone help me with a roadmap, I would be really thankful\n    submitted by    /u/Fooda234  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qcs2u/d_learn_machinelearning/",
          "publishedOn": "2023-09-23T19:18:54.000Z",
          "wordCount": 2533,
          "title": "[D] learn machinelearning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qcnef/discussion_advices_for_exams/",
          "author": null,
          "description": "Hello,\n I'm currently preparing for oral exams in which I'll be evaluated on my understanding and proficiency in using Decision Trees, Random Forests, Neural Networks, and Support Vector Machines for various machine learning tasks (mostly spatial data). I'm contacting this community to gain valuable insights and guidance to excel in these exams.\n What are some crucial lessons you've learned in your machine-learning journey? Whether it's about model selection, data preprocessing, or debugging, I'm all ears for your experiences.\n What are some rules you have learned through practical work that are not so extensively described in classical literature?\n What are some mistakes that even professionals make when developing machine learning models?\n What are some common pitfalls to avoid when training neural networks?\n Thanks :\n    submitted by    /u/Aim_F0r_The_Moon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qcnef/discussion_advices_for_exams/",
          "publishedOn": "2023-09-23T19:13:22.000Z",
          "wordCount": 2632,
          "title": "\"[Discussion]\" Advices for exams",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16qb9yq/r_how_much_data_needed_to_train_transformer/",
          "author": null,
          "description": "Im trying to create a graph transformer-based model for de novo drug design (using graph transformer because I want to implement 3D data). I currently have 2 potential sources of primary data: PDBbind and CrossDocked2020. This would provide the protein-ligand structures. \n PDBbind is a more robust and higher quality dataset from what I know, and easier to work with. The problem is that it only contains about 20,000 complexes, and I'm not sure if that is enough for training a transformer. CrossDocked2020 contains millions of entries but I'm not sure about the quality and ease of use. \n Another dilemma is that I need/want to use a multi-task learning approach where the model is also being trained on bioactivity data, not just the structural information. This would require supplementation from sources like PubChem, ChEMBL, BDB, etc. and then I would need to align the data so it all matches up. \n If anyone can provide some guidance I'd really appreciate it.\n    submitted by    /u/Present_Network1959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16qb9yq/r_how_much_data_needed_to_train_transformer/",
          "publishedOn": "2023-09-23T18:15:07.000Z",
          "wordCount": 2672,
          "title": "[R] How much data needed to train transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q9znl/d_help_for_an_upcoming_presentation/",
          "author": null,
          "description": "I am supposed to be delivering a 5 minute presentation on tree-models as part of coursework requirement to a graduate class ON machine learning that I am enrolled in and I couldn't be more stressed! This is my first time 'learning' ML and I don't even know what I don't know about this topic!! \n If you were attending my presentation on tree models, what would you like to see (assuming this is a new topic for you too. but please provide feedback based on your [hopefully] extensive knowledge on this topic)?\n Here is what I have so far (based on google searches, some papers):\n -Introduction\n -Types of trees based on algo and techniques (basically classification trees and regression trees)\n -Then I am thinking of going off on a tangent about decision trees bec I have no clue about how to move this presentation forward\n -Real-world applications\n -Key takeaways (inserts clownface emoji)\n My prof asks the students questions about the topic as well. I am mostly concerned about WHAT to cover in 5 minutes without making look under-researched. Any redirection/suggestions will be appreciated!\n ​\n    submitted by    /u/toomanymouthstofeed  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q9znl/d_help_for_an_upcoming_presentation/",
          "publishedOn": "2023-09-23T17:19:46.000Z",
          "wordCount": 2693,
          "title": "[D] HELP for an upcoming presentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q8uab/d_predicting_the_next_thought/",
          "author": null,
          "description": "(I'm a Software Engineer who knows almost nothing about ML / NLP, so, apologies in advance if this doesn't make any sense.)\n I had a shower thought around if tokenization could incorporate meaning, so the models could be trained on \"thoughts\" instead of subword tokens (which is probably closer to how we humans think). To expand a little bit, we could first cluster all the words (maybe using the current day LLMs), then each token (or \"thought\") in the new scheme could represent a group of related words, followed by refinements that would be less and less important.\n For example, (cop_thought, cop_refinement) -> cop, but (cop_thought, police_refinement) -> police etc.\n So the encoding step would involve an LLM (which could possibly be relatively smaller), whose output would go to the actual model but the decoding would still be fairly straightforward. This could possibly free up some additional capacity in the actual model, assuming this heavy lifting tokenization makes its job easier, but as I'm typing it, I guess I'm simply moving some of the semantic understand happening in the hidden layers of the current day LLMs explicitly to the tokenization (encoding) step, which may not really change anything (if not make it worse).\n I'm still curious what folks think, if there's any related efforts (and all the ways I'm wrong -- https://meta.wikimedia.org/wiki/Cunningham%27s_Law). Thanks!\n    submitted by    /u/avamsi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q8uab/d_predicting_the_next_thought/",
          "publishedOn": "2023-09-23T16:30:58.000Z",
          "wordCount": 2733,
          "title": "[D] Predicting the next \"thought\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q8r6a/suggestions_for_ml_project_to_detect/",
          "author": null,
          "description": "Keep in mind I'm very new to machine learning. I have an idea for a project where I train an AI to detect instances of someone being highly confident in a treatment for a condition, maybe biased toward more unconventional treatments.\n I was thinking that there may be many instances of people who posted that they were cured or nearly cured of such and such disease by an unconventional treatment on a forum about the condition. It may have been discussed for a little while, but ultimately buried in the pages of the forum.\n The plan would be to annotate instances I can find of such scenarios, maybe like this:\n  \n[FIRST_PERSON_HIGH_CONFIDENCE_TREATMENT]I had severe [CONDITION]migraines[/CONDITION] for years, and nothing seemed to work. Then I tried [TREATMENT]grounding, where I walk barefoot on grass for 30 minutes every day[/TREATMENT]. I can [HIGH_CONFIDENCE]honestly say I've never felt better[/HIGH_CONFIDENCE]. My [CONDITION]migraines[/CONDITION] have reduced by 80%, and I'm [HIGH_CONFIDENCE]convinced this is a game-changer for me[/HIGH_CONFIDENCE].[/FIRST_PERSON_HIGH_CONFIDENCE_TREATMENT]\n  \nThen train an AI with that data, so that it could detect cases of a person talking about themselves (to avoid hearsay) and saying, with high confidence, that a treatment worked for a condition.\n Then millions of forum posts could be fed to the AI to detect these, and the resulting data could be used to possibly discover effective treatments that are not in the mainstream.\n Any tips on getting started? I know almost nothing about this kind of stuff, like what models I should use, how to annotate it best (should I use relational labels?), whether to use a transformer or something else, stuff like that. Suggestions for books or other resources fit for a beginner that could help me learn how this could be done would be great too.\n    submitted by    /u/carbonflow45  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q8r6a/suggestions_for_ml_project_to_detect/",
          "publishedOn": "2023-09-23T16:27:16.000Z",
          "wordCount": 2804,
          "title": "Suggestions for ML project to detect unconventional treatments [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q8pwa/d_how_does_selfattention_work_in_transformer/",
          "author": null,
          "description": "I'm currently diving into the world of machine learning and transformers, and I'm trying to wrap my head around the concept of \"attention\" in transformer models. I've been reading papers and documentation, but I'm still struggling to fully grasp it.\n My Struggle:\n I get that attention involves multiplying \"query\" and \"key\" vectors to determine the importance of different words in a sequence, but I don't quite understand why this multiplication gives us a meaningful metric for importance.\n What I'm looking for:\n I'm comfortable with moderate level technicalities but require a deeper insight into the inner workings and rationale behind these mechanisms. Please share any insights, analogies, or technical details that can shed light on this concept.\n Thanks a bunch!\n    submitted by    /u/GraphicsMonster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q8pwa/d_how_does_selfattention_work_in_transformer/",
          "publishedOn": "2023-09-23T16:25:44.000Z",
          "wordCount": 2632,
          "title": "[D] How does 'self-attention' work in transformer models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q81fh/d_gpt35instruct_beats_gpt4_at_chess_and_is_a_1800/",
          "author": null,
          "description": "99.7% of its 8000 moves were legal with the longest game going 147 moves. You can test it here: https://github.com/adamkarvonen/chess_gpt_eval \n ​\n https://preview.redd.it/821ydy7521qb1.png?width=1000&format=png&auto=webp&s=da6c96feaa527d0b7dfbf407bdc0210f3fcf947b\n More details here: https://twitter.com/a_karvonen/status/1705340535836221659\n    submitted by    /u/seraine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q81fh/d_gpt35instruct_beats_gpt4_at_chess_and_is_a_1800/",
          "publishedOn": "2023-09-23T15:56:39.000Z",
          "wordCount": 2556,
          "title": "[D] GPT-3.5-instruct beats GPT-4 at chess and is a ~1800 ELO chess player. Results of 150 games of GPT-3.5 vs stockfish and 30 of GPT-3.5 vs GPT-4.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q64k4/p_how_to_create_an_image_dataset_for_indian/",
          "author": null,
          "description": "​\n Hi everyone, I am working on a project that involves machine learning and computer vision. I want to train a model that can recognize and classify different types of signals used by the Indian railways. For this, I need a large and diverse image dataset of railway signals from various locations, angles, lighting conditions, etc.\n I have searched online for existing datasets, but I could not find any that suit my needs. So I wish to create my own dataset from scratch. However, I am not sure how to go about it. What are the best practices and tools for creating an image dataset? How do I collect, label, and organize the images? How do I ensure the quality and consistency of the data?\n    submitted by    /u/Responsible-Diver226  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q64k4/p_how_to_create_an_image_dataset_for_indian/",
          "publishedOn": "2023-09-23T14:36:27.000Z",
          "wordCount": 2640,
          "title": "[P] How to create an image dataset for Indian railways signals?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q5ncz/d_math_in_machine_learning/",
          "author": null,
          "description": "Hello,\n I am starting a ML course soon in college and I wanted to get a head start on the math part of things, since they keep saying the course is math heavy and hard. I know that it involves quite a lot of Linear Algebra, Calculus, and Probability and statistics, but what concepts in particular does ML focus on?\n If anyone has any Youtube or Udemy courses, as I have access to those, I would really appreciate it.\n For starters, I’m really aiming to just at least tackle the ML-specific math concepts.\n Thanks.\n    submitted by    /u/CrunchyMind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q5ncz/d_math_in_machine_learning/",
          "publishedOn": "2023-09-23T14:16:24.000Z",
          "wordCount": 2604,
          "title": "[D] Math in Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q5c28/r_alma_proposed_new_2step_training_method_to/",
          "author": null,
          "description": "TLDR: New training approach proposed to help smaller AI models to achieve state-of-the-art translation performance\n Large AI models like GPT-3 have good performance on translation tasks, but some smaller models struggle.\n Researchers from Johns Hopkins and Microsoft propose a new 2-stage fine-tuning method called ALMA that unlocks stronger translation abilities in smaller models with just 7-13 billion parameters.\n How it works:\n  \nFine-tune on monolingual data in non-English languages to improve comprehension\n Further fine-tune on small sets of high-quality human-translated parallel text\n  \nThe authors claim this achieves SOTA-level translation using far less data and compute than conventional methods:\n  \nMatches performance of 175B parameter GPT-3 and 54B parameter NLLB with only 7-13B parameters\n Reaches NLLB-level quality with just 1 billion monolingual tokens and 18 hours of training\n  \nI think this shows that smaller models can reach SOTA translation with specialized fine-tuning, so we may not need endlessly bigger datasets and models to get better performance. Looks like deliberate tuning targeting key language skills could be more important.\n Full summary here. Paper (preprint) is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q5c28/r_alma_proposed_new_2step_training_method_to/",
          "publishedOn": "2023-09-23T14:02:35.000Z",
          "wordCount": 2692,
          "title": "[R] ALMA: Proposed New 2-Step Training Method to Boost Translation Performance in Smaller Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q35tx/r_d_hyperdreambooth_lora_matrix_shapes/",
          "author": null,
          "description": "I've been reading the HyperDreamBooth paper and am confused about the number of parameters and corresponding matrix shapes in section 4.1 and figure 3 (below).\n ​\n Figure 3 from the paper\n Maybe there's something more than just matrix multiplication, because the numbers don't add up. If there are two matrices, A & B, of size n,r and r,m, and r = 1, and you multiply them, then it implies that n + m = 386k, which seems to be a bit much for a number of parameters in a single layer.\n Then we have two matrices of size a,r and r,b, where a = 100, b = 50 and there are 28k variables, according to the figure - in 4.1 they say 30k. If there's 30k, that would imply r = 200, for matrices of shape 100,200 and 200,50.\n I guess 386k and 28k are for the whole models, n and m differ from layer to layer, and r stays at one. Quite surprising to me that approximating a n,m shaped matrix with a product of n,1 and 1,m vectors would work. Even more surprising that apparently you could squeeze it further to 100,1 and 50,1. \n    submitted by    /u/Foxtr0t  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q35tx/r_d_hyperdreambooth_lora_matrix_shapes/",
          "publishedOn": "2023-09-23T12:23:34.000Z",
          "wordCount": 2706,
          "title": "[R] [D] HyperDreamBooth LoRA matrix shapes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q334y/d_cleaning_scraped_text_improving_similarity/",
          "author": null,
          "description": "Hey everyone!\n Multi-part question.\n  \nI have scraped text (I repeat, text, and not structured data such as tables or something) from a medical site, and I want to know how to clean it. And when I say clean, I don't mean removal of html tags and such. I already have the paragraphs in plain text but there is a lot of spammy stuff like \"You are not signed in; subscribe to this newsletter; by checking this box, I agree to the terms and conditions, etc.\" This text is not the exact same in all the paragraphs but there is high similarity. I would have thought there would be many tools to clean text and remove unrelated chunks like these but all I have been able to find has to do with cleaning html tags, changing date-time format and so on. Am I missing something or is this actually difficult?\n  \nSecondly, the spammy text I mentioned is from just one site. I will be eventually scaling to many sites and god knows what random text I'll have to clean then.\n  \nI used OpenAI embeddings and cosine similarity on the medical text to find similar paragraphs. The results were not great. Is there a way to improve the similarity search? I will be trying FAISS next but wanted to know what else I can do. It was suggested to me to use a pretrained embedding model specific to medical data. However, I found only one such model which is 20 gigs!\n  \nI'm just getting started with these, so, appreciate any help I can get.\n Thanks a ton!\n    submitted by    /u/yipra97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q334y/d_cleaning_scraped_text_improving_similarity/",
          "publishedOn": "2023-09-23T12:20:03.000Z",
          "wordCount": 2778,
          "title": "[D] Cleaning scraped TEXT; improving similarity search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q2q2g/d_comparison_of_top_ten_llms/",
          "author": null,
          "description": "Hey folks - I have been tasked with a project at work that is outside of my typical realm (non technical background), and I would love any and all insight on it!\n I have been asked to compare the top ten llms for research before we implement an llm for our company. So far my research has felt scattered because I’m not what directions to go in. I’ve been looking at things like open source vs closed source, parameters, tokens, what the license looks like (available for commercial use), and pricing. \n If anyone has thoughts on resources to look at or better ways to approach this, I would really appreciate it!\n    submitted by    /u/Greatvalueaidybryant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q2q2g/d_comparison_of_top_ten_llms/",
          "publishedOn": "2023-09-23T12:01:40.000Z",
          "wordCount": 2622,
          "title": "[D] Comparison of top ten llms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16q0rrd/p_which_mlops_framework_to_use/",
          "author": null,
          "description": "Relatively novice ML practitioner here. My research is on various medical image segmentation problems, including brain 3D US (glioma), lung CT (interstitial lung disease in scleroderma patients), etc. using the PyTorch ecosystem (probably including frameworks such as MONAI)\n I'll have to conduct several experiments on various model architectures on parameters in the coming months. Specifically, these are what I'm gonna need:\n  \nExperiment tracking (model architecture, training configuration, hyperparameters, evaluation metrics)\n Model storage (would be nice if there's a better way to store my model's parameters other than storing tons of .pth file on my harddisk or google drive)\n (Optional) Visualization (sample predictions of the model on the training or validation sets, maybe every 20 epochs or sth)\n Would like to hear any suggestions from the community\n  \nI've found wandb, clearML, neptune, and Aim; but trying each of them individually would be too time-consuming considering my current schedule.\n Thanks in advance!\n    submitted by    /u/mimivirus2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16q0rrd/p_which_mlops_framework_to_use/",
          "publishedOn": "2023-09-23T10:13:41.000Z",
          "wordCount": 2661,
          "title": "[P] Which MLops framework to use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pwh6n/r_introduction_to_hierarchical_correlation/",
          "author": null,
          "description": "submitted by    /u/jarekduda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pwh6n/r_introduction_to_hierarchical_correlation/",
          "publishedOn": "2023-09-23T05:55:12.000Z",
          "wordCount": 2536,
          "title": "[R] Introduction to Hierarchical Correlation Reconstruction (HCR) - family of methods between statistics and machine learning to model (joint) distributions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pwdk6/r_numerical_instability_in_some_optimizers_for/",
          "author": null,
          "description": "I found an interesting arxiv paper mentioning that some optimizers can occur numerical instability for training neural network.\n Link: https://arxiv.org/abs/2307.16189\n This can be a simple approach for low-precision neural network with 16-bit and future 8-bit or 4-bit.\n    submitted by    /u/Klutzy_Divide3485  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pwdk6/r_numerical_instability_in_some_optimizers_for/",
          "publishedOn": "2023-09-23T05:49:11.000Z",
          "wordCount": 2552,
          "title": "[R] Numerical Instability in Some Optimizers for training Neural Network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pmmye/n_splash_pro_drops_generative_music_model_and/",
          "author": null,
          "description": "Seems like a strong contender in this space, plus comercial use: https://www.splashmusic.com/music-generation\n    submitted by    /u/No-Reference8836  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pmmye/n_splash_pro_drops_generative_music_model_and/",
          "publishedOn": "2023-09-22T21:54:16.000Z",
          "wordCount": 2529,
          "title": "[N] Splash Pro drops generative music model and comparison to other models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16piksd/r_btlm3b8k_7b_parameter_performance_in_a_3b/",
          "author": null,
          "description": "Hello Reddit!\n I'm Daria from the Cerebras ML team, and I've got some thrilling updates to share with you! 🚀 We've recently published our BTLM-3B-8K paper on arXiv, and I’m excited to share that I am one of the authors! Check it out here: https://arxiv.org/abs/2309.11568\n It distills our recipe for training SOTA LLMs:\n  \nAn extensively deduplicated dataset: SlimPajama \n Hyperparameter search using muP \n Variable sequence length training + ALiBi \n Aggressive LR decay \n  \nOur BTLM-3B-8K not only sets a new standard for 3B parameter models but also frequently surpasses the performance of 7B models! In the paper, we meticulously outline how we developed the BTLM model and conducted a comprehensive analysis of its performance on 22 validation benchmarks. These benchmarks span a range of capabilities including common sense reasoning, world knowledge, reading comprehension, code generation, long sequence interpolation/extrapolation, bias, toxicity, and misinformation.\n For those eager to dive in, we've made our SlimPajama dataset and the BTLM-3B-8K model available on Hugging Face: https://huggingface.co/cerebras 🎉\n Feel free to delve into the details, explore the dataset and model, and let us know your thoughts, insights, or questions! We're here to discuss and excited to hear your feedback. Happy exploring! 🚀\n    submitted by    /u/daria-sobol  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16piksd/r_btlm3b8k_7b_parameter_performance_in_a_3b/",
          "publishedOn": "2023-09-22T19:08:26.000Z",
          "wordCount": 2710,
          "title": "[R] BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pfk69/d_is_there_any_followup_to_effect_of_model_size/",
          "author": null,
          "description": "Hello all,\n I am re-reading the LoRA paper (https://arxiv.org/abs/2106.09685) to get a deeper understanding of some of the analysis the authors perform at the end and saw this line\n  \nNote that the relationship between model size and the optimal rank for adaptation is still an open question. \n  \nDoes anybody know of any resources out there that looked into this question, given that LoRA has been around for a little bit now? Perhaps someone has performed similar subspace overlap / optimal \"r\" value studies on some of the LLMs that fall in-between GPT2 and 3, i.e. some of the ~7B, ~15B, ~40B and ~70B models? \n    submitted by    /u/lightSpeedBrick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pfk69/d_is_there_any_followup_to_effect_of_model_size/",
          "publishedOn": "2023-09-22T17:03:07.000Z",
          "wordCount": 2623,
          "title": "[D]: Is There Any Followup To Effect Of Model Size on LoRA Rank \"r\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pegyz/d_when_do_we_use_the_instruct_version_of_a_llm/",
          "author": null,
          "description": "If censorship isn’t an issue for me, when there’s an instruct version of an LLM, is it generally always better to use the instruct version than the non-instruct version (because instruct versions tend to hallucinate less)?\n Apart from censorship and hallucinations, are there any other pros and cons between intrust vs. non-instruct version?\n    submitted by    /u/--leockl--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pegyz/d_when_do_we_use_the_instruct_version_of_a_llm/",
          "publishedOn": "2023-09-22T16:17:46.000Z",
          "wordCount": 2569,
          "title": "[D] When do we use the instruct version of a LLM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pedlu/r_how_to_reduce_hallucinations_using_chain_of/",
          "author": null,
          "description": "This new paper from Shehzaad Dhuliawala et al. (2023) introduces a combination of prompting and consistency checks made by the LLM itself.\n Implementing this technique actually made me like gpt-3.5 again !\n I wrote a tutorial on how to actually implement this method : https://advanced-stack.com/resources/how-to-reduce-hallucinations-using-chain-of-verification-cov-in-large-language-models.html\n Let me know if you find it useful\n ​\n    submitted by    /u/Fluid-Age-9266  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pedlu/r_how_to_reduce_hallucinations_using_chain_of/",
          "publishedOn": "2023-09-22T16:13:52.000Z",
          "wordCount": 2571,
          "title": "[R] How to reduce hallucinations using Chain Of Verification in Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pe28v/d_looking_for_suggestions/",
          "author": null,
          "description": "Hi guys, a final year CS student here. I want to create a portfolio to showcase my skills in ML and DL. I have knowledge in docker and have access to google cloud platform to deploy. Now, I am unable to find any project that stands out. Could u suggest something that I could learn from as well as looks pretty on my cv?\n    submitted by    /u/Virtual_Heron_7417  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pe28v/d_looking_for_suggestions/",
          "publishedOn": "2023-09-22T16:01:03.000Z",
          "wordCount": 2573,
          "title": "[D] Looking for suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pdhb1/transformers_i_cant_fathom_the_concept_of_dynamic/",
          "author": null,
          "description": "Hey everyone, \n I've been diving deep into the world of neural networks, and recently, I've been particularly intrigued by the dynamicity of attention head parameters (weights). These weights play a crucial role in transformers, and understanding how they change during training and inference can provide valuable insights into model behavior. \n The question is, what does dynamic mean in this context? Is it input-adaptive? Do weights change at inference time according to inputs? \n I have a hard time understanding this concept, for me, weights are static and pre-established at training time.\n    submitted by    /u/assalas23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pdhb1/transformers_i_cant_fathom_the_concept_of_dynamic/",
          "publishedOn": "2023-09-22T15:37:14.000Z",
          "wordCount": 2608,
          "title": "Transformers: I can't fathom the concept of dynamic weights in attention heads [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pdcpv/d_transformers_i_cant_fathom_the_concept_of/",
          "author": null,
          "description": "Hey everyone, \n I've been diving deep into the world of neural networks, and recently, I've been particularly intrigued by the dynamicity of attention head parameters (weights). These weights play a crucial role in transformers, and understanding how they change during training and inference can provide valuable insights into model behavior. \n The question is, what does dynamic mean in this context? Is it input-adaptive? Do weights change at inference time according to inputs? \n I have a hard time understanding this concept, for me, weights are static and pre-established at training time.\n    submitted by    /u/assalas23  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pdcpv/d_transformers_i_cant_fathom_the_concept_of/",
          "publishedOn": "2023-09-22T15:31:58.000Z",
          "wordCount": 2608,
          "title": "[D] Transformers: I can't fathom the concept of dynamic weights in attention heads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pcji8/help_shape_the_future_of_ai_take_a_quick_2minute/",
          "author": null,
          "description": "Hello guys!\n ​\n Are you intrigued by the world of Artificial Intelligence? I am conducting a brief and insightful survey on AI for academic research purposes. It'll take just 2 minutes of your time, and your valuable insights will contribute to our understanding of AI trends and perspectives. Whether you're a tech enthusiast, a data wizard, or just curious about the future of AI, your input is incredibly valuable!\n ​\n Click the link below to share your thoughts and help to understand this new technology:\n ​\n https://forms.gle/7fbbkc1f2iBPXHJV7\n ​\n Thank you in advance for being a part of this exciting AI study! #AIResearch #AI #Artificial Intelligence #SurveyTime\n    submitted by    /u/JukeboxNV  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pcji8/help_shape_the_future_of_ai_take_a_quick_2minute/",
          "publishedOn": "2023-09-22T14:59:04.000Z",
          "wordCount": 2622,
          "title": "Help Shape the Future of A.I.! Take a Quick 2-minute Survey for Academic Research [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pbmnr/r_longlora_new_method_extends_llama2_7b_to_100k/",
          "author": null,
          "description": "As AI models get bigger, training them requires more and more computing power. Researchers are looking for ways to train these large AI models without needing Google-scale resources.\n A new paper proposes LongLoRA, a fine-tuning approach that can extend LLaMA2 7B to 100k context length and 70B model to 32k context length on a single 8× A100 machine.\n Here are my highlights from the paper:\n Big one of course: LongLoRA efficiently fine-tunes large AI models on longer texts\n Key points:\n  \nApproximates standard attention via \"shift short attention\" during training\n Tuning only a subset of weights (LoRA) plus some embeddings & norms\n Fine-tuned 7B parameter model on 100k tokens with 1 machine\n Way lower training cost than full fine-tuning for large contexts\n Close to full fine-tuning performance\n  \nThe core insight is that an approximation of full attention enables efficient training while retaining standard attention for final inference. Combined with selective weight tuning, this really reduces compute needs.\n I think this demonstrates the potential to train more capable AI without unreasonable resources. Efficient training techniques = more powerful LLMs for the same resources.\n Full summary here.\n Arxiv paper: https://arxiv.org/pdf/2309.12307.pdf\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pbmnr/r_longlora_new_method_extends_llama2_7b_to_100k/",
          "publishedOn": "2023-09-22T14:22:16.000Z",
          "wordCount": 2716,
          "title": "[R] LongLoRA: New method extends LLAMA2 7B to 100k context length, 70B to 32k context length on on a single 8 × A100 machine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pb5yv/d_machine_learning_jobs/",
          "author": null,
          "description": "Hello, looking for job opportunities as a data scientist or machine learning engineer.\n Any help would be appreciated.\n Thanks!!\n    submitted by    /u/ArachnidFun2671  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pb5yv/d_machine_learning_jobs/",
          "publishedOn": "2023-09-22T14:03:04.000Z",
          "wordCount": 2528,
          "title": "[D] Machine learning jobs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16pa13n/research_modelling_tabular_data_with_diffusion/",
          "author": null,
          "description": "Denoising diffusion probabilistic models are becoming the leading paradigm of generative modeling for many important data modalities. TabDDPM is a diffusion model that can be universally applied to any tabular dataset and handles any type of feature.\n Blog post link.\n    submitted by    /u/metkere  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16pa13n/research_modelling_tabular_data_with_diffusion/",
          "publishedOn": "2023-09-22T13:13:47.000Z",
          "wordCount": 2554,
          "title": "[Research] Modelling tabular data with diffusion models (Blog post)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16p95js/p_advice_needed_for_what_toolalgorithm_is/",
          "author": null,
          "description": "Context of the problem: I have the following entities: stations, programs, project manager, days, and time slots. The goal of the problem is to decide what program with who project manager to assign on what day at what time slot for each station.\n Some notes:\n  \nEach program has its own duration. Say Program A last for 50 minutes, Program B is 30 minutes, etc.\n Each project manager has qualifications on what program he/she can handle. This constraint is a hard constraint.\n Time slots start from 6AM to 6PM. This means that if Program A which lasts for 30 minutes is assigned to start at 6:00AM, then it will end at 6:30AM. Only one program can be assigned in each station, so there should be no overlap in programs in terms of day and time per station.\n There is a forecasting model that takes a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16p95js/p_advice_needed_for_what_toolalgorithm_is/",
          "publishedOn": "2023-09-22T12:35:19.000Z",
          "wordCount": 2964,
          "title": "[P] Advice needed for what tool/algorithm is appropriate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16p8wyw/p_introducing_geococo_easily_transform_gis/",
          "author": null,
          "description": "https://github.com/jaspersiebring/geococo\n Introducing GeoCOCO, an open source project that enables users to turn their GIS annotations (e.g. shapefile) into COCO datasets which can then be used to train computer vision models!\n It allows users to use the likes of QGIS, ArcGIS to annotate geographic imagery in the same way you would annotate non-geographic imagery with LabelMe. It is powered by Python and a variety of packages (e.g. pydantic, pandera, geopandas, pycocotools). On the more meta side, it also features automated tests/builds/releases through Github Actions (using the likes of poetry, ruff, mypy, pytest, black).\n Sharing it with you guys in case someone else might find it useful! I am also very interested to hear some feedback (suggestions, flaws, etc.), let me know!\n ​\n Here's…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16p8wyw/p_introducing_geococo_easily_transform_gis/",
          "publishedOn": "2023-09-22T12:23:58.000Z",
          "wordCount": 2835,
          "title": "[P] Introducing GeoCOCO: Easily transform GIS annotations into Microsoft's Common Objects In Context (COCO) datasets for use in deep learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16p8k9r/d_finding_linkedin_article_on_anomaly_detection/",
          "author": null,
          "description": "Finding linkedIn article on anomaly detection\n Last week I saw a LinkedIn article on anomaly detection. In that post, Tail movement of a running mice on rotating rod ( roller) is captured with CV and plotted as a time series. Then based on the tail movement time series , anomalities in that time series are detected where mice loose the balance in rotating rod. \n I am trying to find this post in linkedIn but still didnt able get any clue. If you have seen this research article or have any clue please let me know. It will be great help. Appriciate you time and help.Thank You very much ! ❤️\n [D] [R]\n    submitted by    /u/isurusachitha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16p8k9r/d_finding_linkedin_article_on_anomaly_detection/",
          "publishedOn": "2023-09-22T12:06:51.000Z",
          "wordCount": 2624,
          "title": "[D] Finding linkedIn article on anomaly detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16p6uxd/r_parallelizing_rnn_over_its_sequence_length/",
          "author": null,
          "description": "I am really excited to share our newest work in deep learning: parallelizing RNN! https://arxiv.org/abs/2309.12252\n RNN is thought to be non-parallelizable because of its inherent sequential nature: its state depends on its previous state. This makes training RNN for long sequence usually takes long time compared to other architecture classes (like CNN).\n What we present is an algorithm based on Newton's method to evaluate and train RNN in parallel. In one of our experiment, we can achieve >1000x faster evaluation of a small GRU compared to common sequential method on a very long sequence. Training RNNs with our algorithm could also be more than 10x faster than training with sequential method.\n However, it's not without flaws. There are 2 major drawbacks we noticed: non-convergence and sca…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16p6uxd/r_parallelizing_rnn_over_its_sequence_length/",
          "publishedOn": "2023-09-22T10:37:15.000Z",
          "wordCount": 3014,
          "title": "[R] Parallelizing RNN over its sequence length",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16p6dgr/d_is_running_an_open_sourced_llm_in_the_cloud_via/",
          "author": null,
          "description": "Assuming using the same cloud service, Is running an open sourced LLM in the cloud via GPU generally cheaper than running a closed sourced LLM? (ie. do we pay a premium when running a closed sourced LLM compared to just running anything on the cloud via GPU?)\n One eg. I am thinking of is running Llama 2 13b GPTQ in Microsoft Azure vs. GPT-3.5 Turbo.\n I understand there are a lot of parameters to consider (such as choosing which GPU to use in Microsoft Azure etc.), but I am really looking at what’s the cheapest way to run Llama 2 13b GPTQ or a performance-equivalent closed sourced LLM.\n    submitted by    /u/--leockl--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16p6dgr/d_is_running_an_open_sourced_llm_in_the_cloud_via/",
          "publishedOn": "2023-09-22T10:08:15.000Z",
          "wordCount": 2633,
          "title": "[D] Is running an open sourced LLM in the cloud via GPU generally cheaper than running a closed sourced LLM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16p427x/p_stateoftheart_imagetoimage_generators_opensource/",
          "author": null,
          "description": "Hi all. I am curious to know what is cutting edge in this domain? The use-case is creating an image of myself that is older than I am. I've looked a bit into StarGAN but I've never done work in this domain and don't know if this is still used today. Any help would be appreciated!\n    submitted by    /u/ProudOwner_of_Fram  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16p427x/p_stateoftheart_imagetoimage_generators_opensource/",
          "publishedOn": "2023-09-22T07:41:12.000Z",
          "wordCount": 2566,
          "title": "[P] State-of-the-art Image-to-Image generators (open-source)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16p3kxz/gradient_of_langevin_dynamics_step_wrt_model/",
          "author": null,
          "description": "I am reading the following paper about self-supervised learning.\n ​\n https://preview.redd.it/g4bz7wjxarpb1.png?width=1323&format=png&auto=webp&s=9f923825b57d4d3da346bb1bb4dd008366493dbd\n Briefly their idea for self-supervised learning is to reconstruct a corrupted image (e.g., random masking) using Langevin step of a learned energy function and the reconstructed image is compared to the clean image for supervision.\n i.e.,\n ​\n https://preview.redd.it/q9e1pd9yarpb1.png?width=953&format=png&auto=webp&s=528e654d3ae4db1435aa3c11e5edc787876fd9ac\n This should work because going along the decreasing energy value ensures that corrupted images have high energy and clean images have low energy.\n Everything made sense to me until I tried to implement it.\n ​\n In order to optimize the parameters (\\theta), we have to take the gradient of the loss w.r.t \\theta and by the chain the chain rule we will compute the gradient of the reconstructed x (\\tilde x) w.r.t \\theta.\n ​\n https://preview.redd.it/j3qbyddzarpb1.png?width=1280&format=png&auto=webp&s=c03d54dbaf70ba588c2a4d87691d71184797ae3f\n Is this even correct? What am I even talking about I am confused.\n Anyways ...\n They provided the following PyTorch pseudocode and I have provided the actual PyTorch code.\n ​\n https://preview.redd.it/m4wd7pq2frpb1.png?width=1266&format=png&auto=webp&s=d5febf258f0c92fc90116a996367b605cd597128\n Actually the model parameters never change no matter what what the values of step size (alpha) or the learning rate are.\n I am missing something?\n ​\n https://preview.redd.it/yznnuws9frpb1.png?width=1185&format=png&auto=webp&s=1ced5a213d372f309e6c20a9781ac35c1abcc436\n Any help is appreciated\n ​\n    submitted by    /u/ThoughtOk5558  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16p3kxz/gradient_of_langevin_dynamics_step_wrt_model/",
          "publishedOn": "2023-09-22T07:08:37.000Z",
          "wordCount": 2689,
          "title": "Gradient of Langevin Dynamics Step w.r.t model parameters [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ote5k/d_what_fundamentally_prevents_training_with/",
          "author": null,
          "description": "I’d love to see people come together, donate their spare compute to train more open source models, boost research etc. One relevant paper I was able to find is this one https://arxiv.org/abs/2103.08894\n    submitted by    /u/tecbar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ote5k/d_what_fundamentally_prevents_training_with/",
          "publishedOn": "2023-09-21T22:24:35.000Z",
          "wordCount": 2545,
          "title": "[D] What fundamentally prevents training with Volunteer Computing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16osmqm/aaai24_fast_track_submission_d/",
          "author": null,
          "description": "I'm planning on submitting a rejected NeurIPS paper to the AAAI fast track. A few days ago I registered myself as an author on CMT, but I cannot see an option to submit a paper. Will the portal open later? Can anyone else see an option to submit yet?\n    submitted by    /u/Firm-Act-3860  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16osmqm/aaai24_fast_track_submission_d/",
          "publishedOn": "2023-09-21T21:55:00.000Z",
          "wordCount": 2559,
          "title": "AAAI24 fast track submission [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16os3md/d_can_you_go_to_neurips_workshops_without/",
          "author": null,
          "description": "This year will be my first NeurIPS, and I see some cool workshops but don't have any work that would be a good fit for them. Can I just go and listen?\n    submitted by    /u/ThickBiker  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16os3md/d_can_you_go_to_neurips_workshops_without/",
          "publishedOn": "2023-09-21T21:34:29.000Z",
          "wordCount": 2546,
          "title": "[D] Can you go to NeurIPS workshops without presenting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oqb6b/d_motherboard_help/",
          "author": null,
          "description": "So a few weeks ago I purchased a Sega 36 Crane Machine (Claw Machine) off ebay and everything worked great except the claw strength being too strong. I took the board out so I could possibly have something added to the board for me. It was missing a “Free Play” button which is used to adjust claw strength on this machine.. Anyway, I kept the board in the garage while searching for the right parts and dad threw it away on accident while cleaning, now im out a board and I have no idea what to do. Can anybody help me or am I sol? Even if im in the wrong community for this, a step to the right direction would even help. I also have attached some pictures of the board.. Im not good with these boards at all and have no clue what im looking for. Theres also a diagram of the boards functions! Thanks for all information/help!\n    submitted by    /u/Ready_Highlight9758  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oqb6b/d_motherboard_help/",
          "publishedOn": "2023-09-21T20:24:44.000Z",
          "wordCount": 2668,
          "title": "[D] Motherboard Help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16opubk/opensource_trading_ai_p/",
          "author": null,
          "description": "Hi, I am an experienced trader and coder. I am embarking on a journey to develop an open-source Trading AI in Python, and I'm looking for passionate individuals to join me in this project. This is a non-commercial, community-driven project, so there won't be any monetary compensation involved. However, it's a great opportunity to learn and collaborate in the field of trading AI.\n ​\n - You don't need to know trading to contribute.\n - As an Open Source project, you have complete freedom to use the AI.\n ​\n About the Project:\n - Objective: Our goal is to create a self-learning AI system for trading in financial markets.\n - Tech Stack: We'll be working with Python for data analysis, machine learning, and neural network development.\n - Data: We'll be using historical stock market data to train a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16opubk/opensource_trading_ai_p/",
          "publishedOn": "2023-09-21T20:06:08.000Z",
          "wordCount": 2831,
          "title": "Open-Source Trading AI [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oohp0/p_mle_recsys_ops_at_deovr/",
          "author": null,
          "description": "Hi, we're welcoming talented Machine Learning Engineers with a focus on Recommendation Systems and ML Operations.\n Who are we?\n Leading in VR video streaming, we drive the DeoVR platform with interactive 8K videos, ML, computer vision, and advanced haptic tech.\n What you'd do?\n  \nFor MLE RecSys: develop ML pipelines for top recommendations, engage with community for desired features, and collaborate with Backend/Frontend/Unity teams.\n For ML Ops: construct ML inference infrastructure, refine models & workflows, and ensure high-availability ML services.\n  \nWhat we offer?\n  \n🌍Remote flexibility\n 🤝Collaborative and inclusive work environment\n 🚀Make a significant impact in the VR industry\n  \nInterested? Check out and apply here or drop me a DM😎\n    submitted by    /u/SanjaVR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oohp0/p_mle_recsys_ops_at_deovr/",
          "publishedOn": "2023-09-21T19:14:05.000Z",
          "wordCount": 2620,
          "title": "[P] MLE RecSys / Ops at DeoVR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16omvdh/d_where_to_find_checkpoints_for_models_with/",
          "author": null,
          "description": "i.e., models with the exact same architecture, but their initial weights are different, and the order which the model sees the training data is different.\n    submitted by    /u/just2gud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16omvdh/d_where_to_find_checkpoints_for_models_with/",
          "publishedOn": "2023-09-21T18:11:05.000Z",
          "wordCount": 2544,
          "title": "[D] Where to find checkpoints for models (with different seeds) trained on the Imagenet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ol0bs/p_blindchat_fully_inbrowser_and_private/",
          "author": null,
          "description": "We are happy to share with you BlindChat, the open-source and privacy-by-design alternative to ChatGPT for a fully in-browser, yet private, Conversational AI!\n You can play with it on our Gradio demo.\n Our philosophy is that Conversational AI should be easily accessible, and privacy should not be a luxury but a given.\n By leveraging local models running in the browser, with transformers.js, we make it possible to have a fully transparent and private AI that works on your browser without any extra setup. Because all the logic is offloaded to users’ devices, data never leaves and there is no risk of it being used for finetuning by third parties.\n For now, we only support inference with LaMini-Flan-T5, so you might see modest performance. We plan to integrate Microsoft phi-1.5 for better performance once the 370M is out.\n We are also working on LlamaIndex-TS integration on the client side to have in-browser RAG for local querying of private documents.\n As our roadmap is quite dense, with RAG, internet search, improved inference, we welcome warmly contributors! If you want to contribute, or have questions, ping us on Discord and GitHub!\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ol0bs/p_blindchat_fully_inbrowser_and_private/",
          "publishedOn": "2023-09-21T16:56:39.000Z",
          "wordCount": 2706,
          "title": "[P] BlindChat: Fully in-browser and private Conversational AI with Transformers.js for local inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ok8v6/r_deepmind_llms_compress_images_43_better_than/",
          "author": null,
          "description": "Edit: FLAC is the tested audio extension, not MP3\n I read the new paper from DeepMind so you don't have to. Here are the key highlights:\n  \nDespite training on text, langauge models compressed images 43% better than PNG, and audio nearly 2x better than flac.\n Confirmation of scaling laws - bigger models compressed better. But model size must match dataset size.\n There are tradeoffs between model scale, data size, and compression performance. More data enables bigger models.\n Tokenization (like BPE) generally hurts compression slightly by making prediction harder.\n Longer contexts let models exploit more sequential dependencies.\n  \nImplications:\n  \nModels have learned very general capabilities beyond just text. Their strong compression reflects deep understanding of images, audio etc statistically.\n I got some new perspective on model scaling laws and links between prediction and generalization.\n There's potential for practical applications compressing images, video etc. But large model size an issue.\n Overall it shows these models are very capable general purpose learners, not just for language.\n  \nFull summary here if you want more details. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ok8v6/r_deepmind_llms_compress_images_43_better_than/",
          "publishedOn": "2023-09-21T16:24:09.000Z",
          "wordCount": 2695,
          "title": "[R] DeepMind: LLMs compress images 43% better than PNG, and audio nearly 2x better than MP3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oj4oq/d_stanfords_ai_professional_program/",
          "author": null,
          "description": "Hi,\n I am interested in taking couple of AI/ML online courses from the Stanford's Artificial Intelligence Professional Program (https://online.stanford.edu/programs/artificial-intelligence-professional-program). I am interested in taking XCS221 and XCS229. My employer would be paying for this (I hope!). I know these are not the complete courses offered in the university. Has anyone taken courses from this program ? Is it worth it ?\n    submitted by    /u/RealMadrista007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oj4oq/d_stanfords_ai_professional_program/",
          "publishedOn": "2023-09-21T15:39:27.000Z",
          "wordCount": 2571,
          "title": "[D] Stanford's AI Professional Program",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oi6fb/n_openais_new_language_model_gpt35turboinstruct/",
          "author": null,
          "description": "This Twitter thread claims that OpenAI's new language model gpt-3.5-turbo-instruct can \"readily\" beat Lichess Stockfish level 4. This tweet shows the style of prompts that are being used to get these results with the new language model.\n I used website parrotchess[dot]com (discovered here) to play multiple games of chess purportedly pitting this new language model vs. various levels of Fairy-Stockfish 14 at website Lichess. My current results for all completed games: The language model is 2-0 vs. Fairy-Stockfish 14 level 5 (game 1, game 2), and 0-2 vs. Fairy-Stockfish 14 level 6 (game 1, game 2). One game I aborted because the language model apparently tried an illegal move.\n The following is a screenshot from the aforementioned chess web app showing the end state of the first game vs. Fai…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oi6fb/n_openais_new_language_model_gpt35turboinstruct/",
          "publishedOn": "2023-09-21T15:01:28.000Z",
          "wordCount": 2843,
          "title": "[N] OpenAI's new language model gpt-3.5-turbo-instruct can defeat chess engine Fairy-Stockfish 14 at level 5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oheao/d_what_would_be_your_approach_if_you_were_to/",
          "author": null,
          "description": "I've been playing around with transformers since following Karpathy's shakespeare model on youtube and found it really cool. Thought I should write a Tree-of-Thoughts model as my next project which will be somewhat similar, given what we're doing is learning the meaning behind words and phrases and then using that knowledge to generate a sequence based on a seed token or sequence of tokens.\n Here's how I was thinking it should go: I write a next token in sequence prediction model and write a generate function that generates a sequence of tokens on top of a seed token. Then I write a tree model that takes in whatever this bigram has learned and adds onto it some kind of knowledge about where one thought about the seed has been generated and stop there. Then iteratively generate a few more such thoughts based on the same seed.\n This is how I initially thought it would go but now when I'm writing, I've already written the bigram(next token prediction and generation), I don't know what to do next. I am kind of stuck.\n It will be interesting to see how you, if you've ever written a similar model or are good at NLP, would attempt this. Looking at a variety of different approaches to the same problem I am trying to solve would be great.\n So I decided to post here. Would be great to hear from you guys!\n    submitted by    /u/GraphicsMonster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oheao/d_what_would_be_your_approach_if_you_were_to/",
          "publishedOn": "2023-09-21T14:30:00.000Z",
          "wordCount": 2756,
          "title": "[D] What would be your approach if you were to write a Tree-of-Thoughts model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ogon3/n_toyota_research_institute_unveils_breakthrough/",
          "author": null,
          "description": "Press release\n Diffusion Policy: Visuomotor Policy Learning via Action Diffusion (contains link to paper)\n Comments on Hacker News with some interesting info / links.\n    submitted by    /u/falconberger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ogon3/n_toyota_research_institute_unveils_breakthrough/",
          "publishedOn": "2023-09-21T14:00:09.000Z",
          "wordCount": 2540,
          "title": "[N] Toyota Research Institute Unveils Breakthrough in Teaching Robots New Behaviors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oeau0/looking_for_this_particular_dataset_on_cervical/",
          "author": null,
          "description": "Hi all, \n I have found this dataset on Kaggle with zero information about it. It is very intriguing and would like to find the original researchers about it. It contains over 270,000 histopathological images of cervical cancer. I cannot contact the person who posted it on Kaggle because I am not a contributor yet. And they are not replying on other platforms. Any help on finding it will be very much appreciated. If not, where else can I get such large cervical or bladder cancer datasets? \n Link to the dataset mentioned: https://www.kaggle.com/datasets/rzelite/cervical-cancer \n Thanks in advance.\n    submitted by    /u/dumb_persn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oeau0/looking_for_this_particular_dataset_on_cervical/",
          "publishedOn": "2023-09-21T12:13:34.000Z",
          "wordCount": 2609,
          "title": "Looking for this particular dataset on Cervical cancer [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16odxrb/n_github_ceo_interview_regarding_ai_and/",
          "author": null,
          "description": "https://preview.redd.it/u7lq37efllpb1.png?width=1029&format=png&auto=webp&s=824ee138d9ae4b28d1600b969eab2077f47fb2a6\n GitHub CEO Thomas Dohmke spoke on stage at TC Disrupt today and made several statements regarding the development of artificial intelligence and programming:\n  \nDohmke believes that AI won't replace software developers but will make them more efficient.\n Despite AI advancements, the demand for software developers will continue to exceed the supply.\n The growth in software usage is expected to be exponential, with every company becoming a software company.\n Legacy code maintenance remains crucial, especially in industries like finance with outdated codebases.\n Generative AI is creating more demand for technical talent as companies seek to adopt innovative AI solutions.\n There is a shortage of computer science students, leading to increased demand for developers with AI skills.\n  \nSource: https://techcrunch.com/2023/09/20/github-ceo-despite-ai-gains-demand-for-software-developers-will-still-outweigh-supply/\n    submitted by    /u/gcore-com  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16odxrb/n_github_ceo_interview_regarding_ai_and/",
          "publishedOn": "2023-09-21T11:56:41.000Z",
          "wordCount": 2630,
          "title": "[N] GitHub CEO interview regarding AI and programming",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oc8up/d_timegan_doubt_on_generated_sequence/",
          "author": null,
          "description": "Hello everyone\n I have a doubt regarding GANs for tabular data, more specifically for time-series generation. Looking at the TimeGAN paper (code) and other implementations such as the one by YData, considering that the training dataset is divided into slices (like a rolling window) of N length and that the generated sequence will follow the same format, that is [batch size, N, n_features], what we are effectively generating are slices and not a fully synthetic time-series.\n ​\n To clarify my question, the output of a TimeGAN is only a set of slices, although there is no guarantee that generated slice(N-1) is the one before slice(N), and so the true use of a TimeGAN is generating slices that can be used to train a predictive TS model but not reconstructing a complete time series like the one used for training.\n ​\n I suspect that's the case (useful only to generate good slices for training predictive models) as there is no fully generated time series in the paper or any of the codes, while the quality of the generated data is partially measured by training a model on original data and generated data and comparing their predictive performance. If anyone can confirm/develop upon these thoughts I would be extremely grateful.\n    submitted by    /u/iReallyReadiT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oc8up/d_timegan_doubt_on_generated_sequence/",
          "publishedOn": "2023-09-21T10:24:31.000Z",
          "wordCount": 2718,
          "title": "[D] TimeGAN - doubt on generated sequence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16obzkb/p_quick_finetuning_image_classification_models/",
          "author": null,
          "description": "I've been working on our interactive dataset explorer for machine learning: renumics-spotlight. Recently, I set up an image classification example using it. I utilized Bing image search to create a fully functional example for custom-defined classes.\n To my surprise, it not only worked efficiently but also took only a few minutes for fine-tuning. The best part is its adaptability. You can easily switch it up for different image classes.\n Maybe you like it. Let me know what you think or if you have any suggestions to improve!\n Install with\n pip install renumics-spotlight sliceguard[all] \n Imports\n from renumics import spotlight from sliceguard.data import create_imagedataset_from_bing from sliceguard.models.huggingface import finetune_image_classifier, generate_image_pred_probs_embeddings from sliceguard.embeddings import generate_image_embeddings \n ​\n Create an Image Dataset from Bing\n class_names = [ \"Blue Tang\", \"Clownfish\", \"Spotted Eagle Ray\", \"Longnose Butterfly Fish\", \"Moorish Idol\", \"Royal Gramma Fish\", ] df = create_imagedataset_from_bing( class_names, 25, \"data\", test_split=0.2, license=\"Free to share and use\" ) \n Fine-tune a ViT Model with the data (in 1-2 minutes on a GPU)\n finetune_image_classifier( df[df[\"split\"] == \"train\"], model_name=\"google/vit-base-patch16-224-in21k\", output_model_folder=\"./model_folder\", epochs=15, ) \n Enrich the DataFrame with Predictions, Probabilities and Embeddings and visualize it:\n df[\"prediction\"], df[\"probs\"], df[\"embeddings\"] = generate_image_pred_probs_embeddings( df[\"image\"].values, model_name=\"./model_folder\" ) # Check the result and detect problematic clusters spotlight.show( df, layout=\"https://spotlight.renumics.com/resources/image_classification_v1.0.json\" ) \n ​\n https://i.redd.it/20qy5xw62lpb1.gif\n    submitted by    /u/DocBrownMS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16obzkb/p_quick_finetuning_image_classification_models/",
          "publishedOn": "2023-09-21T10:09:06.000Z",
          "wordCount": 2715,
          "title": "[P] Quick fine-tuning image classification models from Bing image search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oancr/d_finetuning_quantized_model_is_a_bad_idea/",
          "author": null,
          "description": "Hi there, due to the lack of my resources, I have to use quantized big-model or something lighter. In this situation, I want to try the first option, and goona finetune some model. How do you expect the result? \n Training huge model in 4-bits circumstance will be significantly different from original setting?\n Thanks.\n    submitted by    /u/Mundane_Definition_8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oancr/d_finetuning_quantized_model_is_a_bad_idea/",
          "publishedOn": "2023-09-21T08:45:36.000Z",
          "wordCount": 2566,
          "title": "[D] finetuning quantized model is a bad idea?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16oaco8/d_uncertainty_in_gradient_boosting_via_ensembles/",
          "author": null,
          "description": "Paper: https://doi.org/10.48550/arXiv.2006.10562\n Hi all, This paper explores the use of using a single model (meaning an ensemble of trees) to generate uncertainty.\n This technique has been implemented into catboost. My question is why hasn't this been implemented into xgboost? The technique looks easily applicable but I would have expected it to be implemented already as it is 2 years old.\n Is this for some reason not applicable to Xgboost?\n ​\n Figure 1 from paper showing the 'virtual' ensemble\n    submitted by    /u/MetalOrganicKneeJerk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16oaco8/d_uncertainty_in_gradient_boosting_via_ensembles/",
          "publishedOn": "2023-09-21T08:26:23.000Z",
          "wordCount": 2589,
          "title": "[D] UNCERTAINTY IN GRADIENT BOOSTING VIA ENSEMBLES",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16o1bol/context_vectors_embedding_r/",
          "author": null,
          "description": "Previously I was spoiled my LangChain.\n Suppose I have a bunch of PDFs that I want to store as context vectors. And I want to use an open-source LLMs. Without using LangChain, how do I generate the context vectors? (I will store it in vector databases)\n    submitted by    /u/stephenhky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16o1bol/context_vectors_embedding_r/",
          "publishedOn": "2023-09-21T00:26:30.000Z",
          "wordCount": 2573,
          "title": "Context Vectors Embedding [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16o0tfl/n_openai_announced_dalle_3_art_generator_powered/",
          "author": null,
          "description": "For those who missed it: DALL-E 3 was announced today by OpenAI, and here are some interesting things:\n No need to be a prompt engineering grand master - DALL-E 3 enables you to use the ChatGPT conversational interface to improve the images you generate. This means that if you didn't like what it produced, you can simply talk with ChatGPT and ask for the changes you'd like to make. This removes the complexity associated with prompt engineering, which requires you to iterate over the prompt.\n Majure improvement in the quality of products compared to DALL-E 2. This is a very vague statement provided by OpenAI, which is also hard to measure, but personally, they haven't failed me so far, so I'm really excited to see the results.\n DALL-E 2 Vs. DALL-E 3, image by OpenAI\n From October, DALL-E 3 will be available through ChatGPT and API for those with the Plus or Enterprise version.\n And there are many more news! 🤗 I've gathered all the information in this blog 👉 https://dagshub.com/blog/dall-e-3/\n    submitted by    /u/RepresentativeCod613  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16o0tfl/n_openai_announced_dalle_3_art_generator_powered/",
          "publishedOn": "2023-09-21T00:03:05.000Z",
          "wordCount": 2704,
          "title": "[N] OpenAI Announced DALL-E 3: Art Generator Powered by ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nytb7/p_how_to_build_cicd_pipelines_with_aws_sagemaker/",
          "author": null,
          "description": "TL;DR How to build CI/CD pipelines with AWS SageMaker for ML training: https://dagshub.com/blog/ci-cd-for-continuous-training-with-sagemaker/\n One of the most time-resources-energy-consuming tasks we face when we build internal projects is setting up an instance for ML training.\n It's a repetitive process as we run multiple experiments over the project life cycle, with many steps and configurations that are usually documented poorly and scattered around different places.\n As good engineers, we decided to automate the process using CI/CD pipelines. \n But how?\n We had ZERO ideas on how to do it, so we had to go through the rigorous process of using AWS guides and tutorials to figure it out.\n Usually, when this happens, we extend the project lifecycle and have a team member document the process so we can refer back to it when we need to do it again.\n Knowing this can benefit the community, we decided to share a series of blogs that guide you through building CI/CD pipelines for continuous training with AWS SageMaker.\n We published the first blog, which covers the configuration part a month ago, and we are happy to share the second one which explains how to build a continuous training pipeline for ML.\n Configure AWS SageMaker for CI/CD: https://dagshub.com/blog/setup-sagemaker-for-ci-cd-pipelines/\n How to build CI/CD pipeline with AWS SageMaker for ML training: https://dagshub.com/blog/ci-cd-for-continuous-training-with-sagemaker/\n I'm sure we can improve these tutorials, and would love to learn from your experience on how we can do it! 🤗\n    submitted by    /u/RepresentativeCod613  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nytb7/p_how_to_build_cicd_pipelines_with_aws_sagemaker/",
          "publishedOn": "2023-09-20T22:35:47.000Z",
          "wordCount": 2772,
          "title": "[P] How to build CI/CD pipelines with AWS SageMaker for continuous ML training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nwxlv/dhow_to_productionize_a_jupyter_notebook_in_a/",
          "author": null,
          "description": "Hi redditors!\n I've been tasked with an technical homework that asks me to \"productionize\" a Jupyter notebook. The notebook's workflow is as follows:\n  \nReads data from a CSV.\n Pre-processes the data.\n Trains a machine learning model.\n Makes predictions.\n  \nMy initial thoughts are:\n  \nSeparation of Concerns: Break the notebook down into distinct components - data processing, model training, and inference.\n Containerization: Write a Dockerfile to ensure the environment is reproducible and isolated.\n API for Prediction: Set up a Flask-based service to expose the model's prediction capability.\n  \nHowever, I'm grappling with a few challenges:\n  \nI'm not seeing a stark difference between the Jupyter notebook setup and the production setting. Becuase the model is small and training is not complicated. If I were to deploy to Kubernetes pods, it seems wasteful that many pods are doing the same thing( prediction for the same model, maybe just as high availability guarantee?) .\n Does the training phrase or data cleansing phase need to be containerized and deployed? Because this seems like a one-off process.\n How to deploy a scalable service? I am new to this. Each container may have a HTTP service. How to load balance them on Kubernetes from outside?\n What kind of CI/CD do you recommend for this task? What kind of testing or pipeline are needed?\n  \n   submitted by    /u/zjplab  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nwxlv/dhow_to_productionize_a_jupyter_notebook_in_a/",
          "publishedOn": "2023-09-20T21:22:19.000Z",
          "wordCount": 2747,
          "title": "[D]How to \"productionize\" a jupyter notebook in a technical interview?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nwkfw/pn_announcing_zivy_scholar_an_ai_tool_to_help/",
          "author": null,
          "description": "Hi r/MachineLearning\n After a long beta, we are excited to announce Zivy Scholar to the public!\n Zivy Scholar is a tool that allows you to help researchers consume research papers.\n I'm one of the creators and I've found that I want to listen to research papers in the car or when I'm working out.\n Current features include:\n  \nListen to and read along with a research paper\n Share the paper with colleagues and friends.\n  \nWe use state of the art pdf data extraction techniques with TTS to provide this functionality.\n Features we're planning:\n  \nFull PDF to HTML including images, tables, and figures inline for the read-along experience. This includes mobile optimization. This functionality is based on some newer research and we're excited to bring it to you all!\n  \nDiscussion and feedback are welcome!\n Cheers, Collin\n    submitted by    /u/collin_code_77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nwkfw/pn_announcing_zivy_scholar_an_ai_tool_to_help/",
          "publishedOn": "2023-09-20T21:08:08.000Z",
          "wordCount": 2670,
          "title": "[P][N] Announcing Zivy Scholar – An AI tool to help researchers consume papers.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ntjju/d_which_is_the_best_model_for_generation_of_code/",
          "author": null,
          "description": "The title basically conveys the entire message. Which according to you is the best AI model for generation of code.\n I mainly code in python with AI and deep learning as a core focus and recently started doing a bit of c++ and thus far have used only bard and ChatGPT 3.5. With this experience of my I can confidently say that GPT outperforms Bard by a huge margin\n There are usually some minor modifications that need to be done and that is part of a devs life isn't it? recently a lot of new models are picking up steam hence was wondering if there exits a model which is better than GPT\n what are your views?\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ntjju/d_which_is_the_best_model_for_generation_of_code/",
          "publishedOn": "2023-09-20T19:05:11.000Z",
          "wordCount": 2650,
          "title": "[D] Which is the best Model for generation of code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nt01l/p_looking_for_cs_students_to_collaborate_with_on/",
          "author": null,
          "description": "Looking for CS students to team up with for the E-BAY ML challenge.\n eBay hosts a ML challenge where the winning team gets an internship We already have a team in place and have mad some significant progress, now looking for team members to take us even further.\n https://eval.ai/web/challenges/challenge-page/2014/overview\n    submitted by    /u/thelongshortseller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nt01l/p_looking_for_cs_students_to_collaborate_with_on/",
          "publishedOn": "2023-09-20T18:43:03.000Z",
          "wordCount": 2585,
          "title": "[P] looking for cs students to collaborate with on the E-Bay ML challenge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nsw95/d_do_neurips_workshop_papers_get_published/",
          "author": null,
          "description": "I’m submitting to the workshop and was wondering if the papers there get published?\n    submitted by    /u/Odd-Distance-4439  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nsw95/d_do_neurips_workshop_papers_get_published/",
          "publishedOn": "2023-09-20T18:38:40.000Z",
          "wordCount": 2544,
          "title": "[D] Do NeurIPs workshop papers get published?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nsjym/silent_data_corruption_affects_large_model/",
          "author": null,
          "description": "Sharing an investigation we did at Adept into some issues that were causing problems with training LLMs at scale. Sometimes the hardware makes silent errors! How we found them and tracked down the problematic machines.\n https://www.adept.ai/blog/sherlock-sdc\n    submitted by    /u/ekelsen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nsjym/silent_data_corruption_affects_large_model/",
          "publishedOn": "2023-09-20T18:25:12.000Z",
          "wordCount": 2567,
          "title": "Silent Data Corruption affects Large Model Training [News]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ns6x2/d_which_specs_would_be_better_for_a_beginner_a/",
          "author": null,
          "description": "I'm looking to buy an upgrade, and at my price point (~ 850 GBP) I can get a new 13th i7 + rtx 3050, or a used gtx3060 + 12th gen i7, both 16GB laptop. Unfortunately I really need the mobility of a laptop in my life at the moment and I realise this isn't ideal.\n I'll be looking and experimenting with basic networks, no language models, maybe a few GANs for fun, some DL networks for the atari gym and other experiments. All this for learning, with my own custom networks for various data.\n I'll be running linux - possibly Debian. I'd love to hear your comments or suggestions if there's something better at my price point in a laptop.\n Thanks\n    submitted by    /u/Mean_Actuator3911  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ns6x2/d_which_specs_would_be_better_for_a_beginner_a/",
          "publishedOn": "2023-09-20T18:10:34.000Z",
          "wordCount": 2669,
          "title": "[D] Which specs would be better for a beginner: a 12th gen i7 + RTX 3060 or 13th gen i7 + RTX 3050 (laptop)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nrza8/r_robust_enerf_nerf_from_sparse_noisy_events/",
          "author": null,
          "description": "Project Page\n Paper\n Code \n Abstract:\n  \nEvent cameras offer many advantages over standard cameras due to their distinctive principle of operation: low power, low latency, high temporal resolution and high dynamic range. Nonetheless, the success of many downstream visual applications also hinges on an efficient and effective scene representation, where Neural Radiance Field (NeRF) is seen as the leading candidate. Such promise and potential of event cameras and NeRF inspired recent works to investigate on the reconstruction of NeRF from moving event cameras. However, these works are mainly limited in terms of the dependence on dense and low-noise event streams, as well as generalization to arbitrary contrast threshold values and camera speed profiles. In this work, we propose Robust e-NeRF, a novel method to directly and robustly reconstruct NeRFs from moving event cameras under various real-world conditions, especially from sparse and noisy events generated under non-uniform motion. It consists of two key components: a realistic event generation model that accounts for various intrinsic parameters (e.g. time-independent, asymmetric threshold and refractory period) and non-idealities (e.g. pixel-to-pixel threshold variation), as well as a complementary pair of normalized reconstruction losses that can effectively generalize to arbitrary speed profiles and intrinsic parameter values without such prior knowledge. Experiments on real and novel realistically simulated sequences verify our effectiveness. Our code, synthetic dataset and improved event simulator are public.\n  \n   submitted by    /u/Sirisian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nrza8/r_robust_enerf_nerf_from_sparse_noisy_events/",
          "publishedOn": "2023-09-20T18:02:00.000Z",
          "wordCount": 2756,
          "title": "[R] Robust e-NeRF: NeRF from Sparse & Noisy Events under Non-Uniform Motion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16now5v/n_savelikeaproai_ai_powered_whatsapp_driven/",
          "author": null,
          "description": "👋 Try, savelikeapro.ai, It’ s, \n A.I powered. Zero-installation fits in your daily workflow. FREE-forever option\n    submitted by    /u/prithivida  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16now5v/n_savelikeaproai_ai_powered_whatsapp_driven/",
          "publishedOn": "2023-09-20T15:57:56.000Z",
          "wordCount": 2547,
          "title": "[N] Savelikeapro.ai: AI powered, WhatsApp driven bookmarking for productivity.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16noh6s/r_program_generation_is_all_you_need_for_math/",
          "author": null,
          "description": "The paper introduces improved performance by prompting LLMs with \"natural language embedded programs (NLEP)\". No task-specific prompt is needed.\n Paper: https://arxiv.org/abs/2309.10814 \n An automatic NLEP generation toolkit is opensourced: https://github.com/luohongyin/langcode\n Example Colab notebook is included in the Github repo.\n This work introduces the following features of NLEP:\n  \nNLEP is a full python program that prints the target response of LLMs.\n \nTask-general NLEP prompting outperforms task-specific chain-of-thought prompting on math, symbolic, and natural language.\n \nEnable the chain-of-thought reasoning ability of small models (RoBERTa) on text classification\n \nHierarchical instructing via program completion.\n \n    submitted by    /u/SUKHOIHY  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16noh6s/r_program_generation_is_all_you_need_for_math/",
          "publishedOn": "2023-09-20T15:41:09.000Z",
          "wordCount": 2626,
          "title": "[R] Program generation is all you need? For math, symbolic reasoning, natural language, etc.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nm0a9/p_implications_of_unequal_fold_sizes_in/",
          "author": null,
          "description": "I’m working on a project where I initially split my dataset into k equally sized folds for cross-validation. However, I want to perform some additional sampling operations on the training set within each fold, which would result in varying fold sizes.\n Is this practice acceptable, or does it violate the premises of traditional cross-validation? If so, are there any papers or resources that explore the implications of varying fold sizes in cross-validation?\n Thank you for your insights!\n    submitted by    /u/Leading_Complex7425  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nm0a9/p_implications_of_unequal_fold_sizes_in/",
          "publishedOn": "2023-09-20T13:58:59.000Z",
          "wordCount": 2608,
          "title": "[P] Implications of Unequal Fold Sizes in Cross-Validation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nltc7/p_running_llm_on_desktopmobile_hybrid_distantlocal/",
          "author": null,
          "description": "Hey, I was checking out tauri last week. \n I was so blown away that I wrote a bit more recently and wrote hf.co/chat desktop/mobile API + local LLM. \n https://github.com/Narsil/hf-chat \n Just thought I should share in case others are interested, and wanted to make a bit shoutout to tauri team, the docs, and overall UX is top notch, basically everything pretty much worked out of the box without any hiccup.\n    submitted by    /u/narsilouu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nltc7/p_running_llm_on_desktopmobile_hybrid_distantlocal/",
          "publishedOn": "2023-09-20T13:50:18.000Z",
          "wordCount": 2599,
          "title": "[P] Running LLM on desktop/mobile (Hybrid distant/local)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nljrn/d_neurips_2023_paper_acceptance_results/",
          "author": null,
          "description": "NeurIPS 2023 paper acceptance results are supposed to be released at 8 pm (CDT) on September 21. I thought to create a discussion thread for us to countdown and discuss any celebration/issue/complaint/feedback or anything else.\n There is so much noise in the reviews every year. Some good work that the authors are proud of might get rejected because of the noisy system, given that NeurIPS is growing so large these years. We should keep in mind that the work is still valuable no matter what the final result is.\n    submitted by    /u/Apprentice12358  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nljrn/d_neurips_2023_paper_acceptance_results/",
          "publishedOn": "2023-09-20T13:38:32.000Z",
          "wordCount": 2618,
          "title": "[D] NeurIPS 2023 paper acceptance results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16njeju/d_attention_mechanism_issue/",
          "author": null,
          "description": "Hello, I'm trying to train a multi-modal transformer for Activity Recognition. I employed a two-stream architecture, where one is a Transformer that takes in a sequence of skeleton trajectory, and the latter is a pre-trained Vision Transformer. When I train the model, and investigate the attention weights for the Transformer which takes in skeleton trajectories, I noticed that all of them are approximately the same (~0.029). I'm not really sure what is going on here, I've tried changing the learning rate, tried different optimizers(SGD, Adam). But still I'm not really sure what is causing this. Please suggest me some debugging steps, or what should I look at anything in particular that causes this\n    submitted by    /u/Terrible-Ad6239  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16njeju/d_attention_mechanism_issue/",
          "publishedOn": "2023-09-20T11:57:54.000Z",
          "wordCount": 2640,
          "title": "[D] Attention mechanism issue",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16niwm7/d_zoomposium_with_professor_dr_petra_ritter_the/",
          "author": null,
          "description": "Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\"\n In another installment in our \"Zoomposium Series\" on the topic of \"Brain Research\", my colleague Axel Stöcker of the \"Blog der großen Fragen\" and I had the great honor and pleasure of conducting an interview with the very well-known and renowned German medical doctor and neuroscientist Professor Dr. Petra Ritter.\n In this context, Ms. Ritter became a co-founder and leader of the co-design project \"The #Virtual #Brain\", which is a component of the European Open Science Cloud (EOSC) and is \"a neuroinformatics platform for simulating whole brain networks using biologically realistic connectivity\".\n She is leading the development of a virtual research environment as a collaborative research platform for sensitive health data and head of the \"German National Neuroscience Research Infrastructure Initiative (NFDI-Neuroscince)\" and involved in the development of the \"Health Data Cloud #EBRAINS\".\n Petra Ritter has been Johanna Quandt Professor and Head of the Section for Brain Simulation at the Department of Neurology with Experimental Neurology at Charité - Universitätsmedizin Berlin since 2017.\n There, Professor Ritter and her team are involved in the \"Simulation of Brains\".\n More at: https://philosophies.de/index.php/2023/09/17/die-simulation-von-gehirnen/\n ​\n https://preview.redd.it/3cpni6o6cepb1.jpg?width=1000&format=pjpg&auto=webp&s=998c30d16ddae30511b7983abce7802dfdd54945\n    submitted by    /u/philosophiesde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16niwm7/d_zoomposium_with_professor_dr_petra_ritter_the/",
          "publishedOn": "2023-09-20T11:31:39.000Z",
          "wordCount": 2723,
          "title": "[D] Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16nhq2n/r_from_sparse_to_dense_gpt4_summarization_with/",
          "author": null,
          "description": "The following example implements the technique from the paper \"From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting\", Adams et al. (2023).\n Edit : the library used is py-llm-core\n ```python from typing import List from dataclasses import dataclass from llm_core.assistants import OpenAIAssistant\n @dataclass class DenseSummary: denser_summary: str missing_entities: List[str]\n @dataclass class DenserSummaryCollection: system_prompt = \"\"\" You are an expert in writing rich and dense summaries in broad domains. \"\"\"\n prompt = \"\"\" Article: {article} ---- You will generate increasingly concise, entity-dense summaries of the above Article. Repeat the following 2 steps 5 times. - Step 1: Identify 1-3 informative Entities from the Article which are missing from the previously gene…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16nhq2n/r_from_sparse_to_dense_gpt4_summarization_with/",
          "publishedOn": "2023-09-20T10:24:31.000Z",
          "wordCount": 2893,
          "title": "[R] From Sparse to Dense : GPT-4 Summarization with Chain of Density Prompting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ngzki/p_looking_for_projects_and_collaboration_in_the/",
          "author": null,
          "description": "Hi,\n I have been looking through a few open source projects for LLM, but without much success in finding some integrating approaches from neuroscience of human intelligence.\n That why I am here to ask for projects and collaborations either academical, non-for-profit / open source or commercial.\n It would be great if your can give me some directions for this.\n Thanks\n    submitted by    /u/confluence_84  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ngzki/p_looking_for_projects_and_collaboration_in_the/",
          "publishedOn": "2023-09-20T09:40:06.000Z",
          "wordCount": 2596,
          "title": "[P] Looking for projects and collaboration in the field of neuroscience-inspired intelligent agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ngtyh/r_contrastive_decoding_improves_reasoning_in/",
          "author": null,
          "description": "submitted by    /u/InterviewIntrepid889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ngtyh/r_contrastive_decoding_improves_reasoning_in/",
          "publishedOn": "2023-09-20T09:29:58.000Z",
          "wordCount": 2574,
          "title": "[R] \"Contrastive Decoding Improves Reasoning in Large Language Models\", O'Brien & Lewis 2023 (boosts LLaMA-8B to >GPT-3.5/PaLM-540B on GSM8K)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n6rb5/d_are_there_any_good_math_datasets_for_training/",
          "author": null,
          "description": "I've seen Allen AI's Lila Dataset, and I want to use this for a small model, to turn math to code. However, I dont think a small dataset in 300k rows is enough. Does anyone know of any bigger, similar datasets?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n6rb5/d_are_there_any_good_math_datasets_for_training/",
          "publishedOn": "2023-09-20T00:13:48.000Z",
          "wordCount": 2574,
          "title": "[D] Are there any good math Datasets for Training small models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n5r3x/p_optimizer_that_makes_cnns_learn_in_fewer/",
          "author": null,
          "description": "Hi all.\n I have been tinkering with a project to get quicker learning for CNNs. \n The idea came after reading the SDProp paper. Algorithms using adaptive learning rate can be interpeted as muliplying the gradient(with or without momentum) with the inverse square-root of the covariance matrix. Using a diagonal estimate of the covariance matrix.\n Which begs the question: what happens if we use a fuller estimate? I chose to include covariances between the elements of convolutional filters. I.e. a conv.weight of size [n_out,n_in,5,5] needs a tensor of size [n_out,n_int,25,25] to store its contribution to the covariance matrix.\n for 3x3 filters and 5x5 filters, torch.linalg.eigh could be used to calculate the square root of the covariance matrices. For 7x7, I used newtons method to approximate the square root.\n In the figure below are some results for a 6 layer CNN on CIFAR 100. Huge gains iteration for iteration. But is it quicker? Not a lot. A bit for the smaller 3x3 filter. More optimizations could still be made. And it will obviously depend on network architecture and computer hardware. \n I'm sure there could be some use-cases. The computation of the square-root calculations is invariant to batch_size and image_size (unless number of filters also is increased).\n If anyone is interested I can also link to my torch implementation of the optimizer, once I get it up on github.\n Not sure if this, or something like it, has been done before? Would love to have some papers linked if so...\n https://preview.redd.it/kyy0ogr0qapb1.jpg?width=714&format=pjpg&auto=webp&s=96ac499fb8ab35ce13e7c59bbe3dbc94ba275b9c\n https://preview.redd.it/p52zllr0qapb1.jpg?width=342&format=pjpg&auto=webp&s=8663a9c3c782d192b16289a735b53da6a8d29c47\n    submitted by    /u/maka89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n5r3x/p_optimizer_that_makes_cnns_learn_in_fewer/",
          "publishedOn": "2023-09-19T23:29:00.000Z",
          "wordCount": 2778,
          "title": "[P] Optimizer that makes CNNs learn in fewer iterations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n4bed/d_help_with_peft_using_lora/",
          "author": null,
          "description": "Can someone provide like a step by step example notebook of how to use LORA for peft. I saw too many videos and articles online and Im really confused rn.\n    submitted by    /u/HazSylvia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n4bed/d_help_with_peft_using_lora/",
          "publishedOn": "2023-09-19T22:26:28.000Z",
          "wordCount": 2558,
          "title": "[D] Help with Peft using Lora",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n4bdn/d_help_with_peft_using_lora/",
          "author": null,
          "description": "Can someone provide like a step by step example notebook of how to use LORA for peft. I saw too many videos and articles online and Im really confused rn.\n    submitted by    /u/HazSylvia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n4bdn/d_help_with_peft_using_lora/",
          "publishedOn": "2023-09-19T22:26:27.000Z",
          "wordCount": 2558,
          "title": "[D] Help with Peft using Lora",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n479f/d_optimizing_transformer_architecture_for/",
          "author": null,
          "description": "Hello all,\n I am currently working on a project where my team and I have collected a rich dataset of biomedical sensor data from clinical trials earlier this year. Our aim is to use this sensor data to predict changes in specific biomarkers over time. The data's tensor shape is B,T,F,C, where:\n  \nB = batch size\n T = sequence length\n F = sampled frequencies\n C = features at each frequency\n  \nCurrently, my approach involves flattening this tensor to B,T,−1 and then feeding it to a transformer model. While this has yielded reasonable results, I'm contemplating whether there are more effective ways to prepare the data for the transformer model.\n Here are my specific concerns:\n  \nFlattening the tensor might dilute the information specific to each frequency across various features.\n I could potentially miss the chance to capture frequency-related variations within the features.\n  \nTo address these, I've considered a few options:\n  \nSelf-attention over individual features or frequencies: Although this could be effective, it might make the model too large given my medium-sized dataset.\n Using convolutional layers: Preliminary experiments with this approach have not led to any significant improvements.\n  \nI'm particularly interested in any thoughts on how to make my transformer more receptive to the multi-dimensional nature of my dataset. Increasing the number of attention heads to better accommodate all features is also on the table.\n Does anyone have any insights or can point me to relevant papers or codebases for handling such multi-dimensional data with transformers?\n Thank you for your help!\n    submitted by    /u/BiomedEngineer_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n479f/d_optimizing_transformer_architecture_for/",
          "publishedOn": "2023-09-19T22:21:26.000Z",
          "wordCount": 2782,
          "title": "[D] Optimizing Transformer Architecture for Multi-Dimensional Sensor Data in Clinical Study",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n3pc7/learn_from_computer_vision_industry_experts/",
          "author": null,
          "description": "Hi all,\n I think this will be useful for people in this group who are working on computer vision or vision AI applications.\n There's a free online event about vision AI where industry experts from Runway, Pepsi, AWS, and SoftServe will share how they are using CV software in developing their use cases or applications.\n Register here (https://nvda.ws/3t23idp), if you are interested.\n If you have any questions, please leave a comment and I will do my best to respond as soon as possible.\n    submitted by    /u/Designer-Comb-7144  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n3pc7/learn_from_computer_vision_industry_experts/",
          "publishedOn": "2023-09-19T21:59:15.000Z",
          "wordCount": 2618,
          "title": "Learn From Computer Vision Industry Experts - Runway, Pepsi, AWS, and SoftServe [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n3adf/r_headless_language_models_learning_without/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.08351\n ​\n  \nSelf-supervised pre-training of language models usually consists in predicting probability distributions over extensive token vocabularies. In this study, we propose an innovative method that shifts away from probability prediction and instead focuses on reconstructing input embeddings in a contrastive fashion via Constrastive Weight Tying (CWT). We apply this approach to pretrain Headless Language Models in both monolingual and multilingual contexts. Our method offers practical advantages, substantially reducing training computational requirements by up to 20 times, while simultaneously enhancing downstream performance and data efficiency. We observe a significant +1.6 GLUE score increase and a notable +2.7 LAMBADA accuracy improvement compared to classical LMs within similar compute budgets.\n  \n​\n Comparison of our approach vs. classical MLM within same compute budgets\n The Contrastive Weight Tying approach\n ​\n    submitted by    /u/nthngdy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n3adf/r_headless_language_models_learning_without/",
          "publishedOn": "2023-09-19T21:40:40.000Z",
          "wordCount": 2657,
          "title": "[R] Headless Language Models: Learning without Predicting with Contrastive Weight Tying",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mzhfb/mini_gaming_pc_project/",
          "author": null,
          "description": "https://www.amazon.com/Gaming-6900HX-Channel-Computers-Desktop/dp/B0CB3JLBQ4/ref=mp_s_a_1_2?crid=LZHUL5EOU6F0&keywords=refurbished+server+with+rtx+gpu&qid=1695146558&sprefix=refurbished+server+with+rtx+gpu%2Caps%2C146&sr=8-2 Would this be suitable to do basic machine learning?\n    submitted by    /u/stoned_chemist_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mzhfb/mini_gaming_pc_project/",
          "publishedOn": "2023-09-19T19:08:05.000Z",
          "wordCount": 2536,
          "title": "Mini gaming pc [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mxztt/n_xwinlm_surpasses_gpt4_has_rlhf_been_worked_out/",
          "author": null,
          "description": "It seems that Alpaca Eval Leaderboard is in the past ...\n Xwin-LM surpasses GPT-4 now:\n https://preview.redd.it/gyzi98nn59pb1.png?width=2205&format=png&auto=webp&s=ca401e603efe521faeeeccde8410d3dbdd6741da\n They also mentioned RLHF \"plays crucial role in the strong performance of Xwin-LM-V0.1 release\"...\n https://preview.redd.it/20sjx73r59pb1.png?width=1047&format=png&auto=webp&s=2255fc652e43674515882f01c0708369fdef56a4\n Are we seeing open source community finally work out how to do RLHF for LLMs???\n    submitted by    /u/llm_nerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mxztt/n_xwinlm_surpasses_gpt4_has_rlhf_been_worked_out/",
          "publishedOn": "2023-09-19T18:07:14.000Z",
          "wordCount": 2580,
          "title": "[N] Xwin-LM surpasses GPT-4 ??? Has RLHF been worked out by open source community???",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mwy2p/d_c_for_ml/",
          "author": null,
          "description": "Hi I wanted to learn ML with C++, I've already done some ML stuff in python, but I wanted to challenge myself by using C++\n I hear from some people that I won't get anything from it if want to be serious within ML - which I'm not entirely sure I want to\n Are they right? Should I rather stick with python for ML?\n    submitted by    /u/Potential_Wealth_830  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mwy2p/d_c_for_ml/",
          "publishedOn": "2023-09-19T17:24:24.000Z",
          "wordCount": 2590,
          "title": "[D] C++ for ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mwua6/d_spam_detection/",
          "author": null,
          "description": "Hi!\n Let me preface this by saying that I am not well-versed in the ML/AI literature. Please excuse my ignorance.\n I am trying to create a system to detect whether some given data is spam or not. Is there a good, out-of-the-box solution for this? I imagine there would be. I am currently using heuristics but I'm wondering if there is a better, ML-y solution.\n My ideal solution would have the following attributes:\n  \nSimple\n Open-source\n Very cheap to test whether something is spam (less than $0.00001 per test)\n Very fast to test (less than 50ms per test)\n Quick to \"figure out\" what is spam and what is not (less than 100,000 labeled data)\n Does not require a lot of set-up or up-keep (less than 5 days set up; less than 1 hr up-keep per month)\n  \nIt doesn't have to be perfect. I'm just looking to set up something quickly for now and gauge it vs heuristics.\n Thank you.\n ---\n Edit: To clarify, I'm looking for something I can ideally build myself with open source software. And not specifically email.\n Just looking for the right direction. Names of OSS, techniques, etc.\n    submitted by    /u/Acrobatic-You-3279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mwua6/d_spam_detection/",
          "publishedOn": "2023-09-19T17:20:00.000Z",
          "wordCount": 2715,
          "title": "[D] Spam Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mvnf7/d_best_python_aimldl_learningpractice_material/",
          "author": null,
          "description": "I’m in search of a good textbook or something that will show me how to use python to implement machine learning. I would seriously appreciate any type of helpful guide that teaches ML and deep learning using python. Here’s a little about me and my experience:\n Graduated under grad with Bachelor’s in CS. In school took a ton of stats, ai classes, algorithms classes, data science and linear algebra and did well but my school didn’t really use python or do a ton of programming for hw or exams. (Data science was the one class that used python)\n My programming is pretty good nonetheless. I currently work as a full stack devops engineer for a cybersecurity startup and regularly work with python, Django MySQL, etc on the backend and JavaScript and various frontend frameworks for the front end. \n I really appreciate yall’s help.\n In particular I’m looking for good ai/ml/deep learning books that teach concepts and also teach with python code and have some coding projects. \n Thank you!\n    submitted by    /u/hydrated-terpman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mvnf7/d_best_python_aimldl_learningpractice_material/",
          "publishedOn": "2023-09-19T16:31:33.000Z",
          "wordCount": 2696,
          "title": "[D] Best python AI/ML/DL learning/practice material?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mvmkv/d_what_gpu_to_buy_for_faster_llm_training/",
          "author": null,
          "description": "I need some advice about what hardware to buy in order to build an ML / DL workstation for home private experiments, i intend to play with different LLM models, train some and try to tweak the way the models are built and understand what impact training speeds, so i will have to train, learn the results, tweak the model / data / algorithms and train again...\n i intend to use large data samples,\n due to board limitations (ASRock Taichi X399 TR4, CPU: AMD Threadripper 1950x),\n i can either buy:\n 2 x nVidia Tesla T4 (16G GDDR6 / 2560 CUDA / 0.585 GHz / ~800$)\n -- or --\n 2 x nVidia Tesla M10 (4 x 8G GDDR5 / 2560 CUDA / 1.03 GHz / ~780$)\n -- or --\n 4 x nVidia Tesla P40 (24G GDDR5X / 3840 CUDA / 3.5 GHz / ~120$)\n -- or --\n 4 x nVidia Tesla K80 (2 x 12G GDDR5 / 4992 CUDA / 2.7 GHz / ~200$)\n -- or --\n 1 x nVidia RTX 4080 (16G GDDR6X / 9728 CUDA / 2.51 GHz / ~1450$)\n i know that i will need to air vent the Tesla models, the question is what is faster for training time (i have read all the Tflops / OPS / int / 16float / 32float / 64float ... i got to admit it is all very confusing)\n what would you do and for what reason ?\n any advice will be appreciated\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mvmkv/d_what_gpu_to_buy_for_faster_llm_training/",
          "publishedOn": "2023-09-19T16:30:39.000Z",
          "wordCount": 2774,
          "title": "[D] What GPU to buy for faster LLM training ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mvanm/dalternative_replacement_for_system76_thelio/",
          "author": null,
          "description": "Hello everyone! Our group was planning on purchasing a PC that will be mainly used for running intensive ML algorithms. Had decided on a custom Thelio Massive from System 76, but it seems like they currently don't have it in stock anymore. Looking for an already built-alternative that might serve our purposes (can't build it ourselves due to dept regulations)! and was hoping maybe someone has any suggestions (has to be intel).\n CPU #1: 2nd Gen Intel Xeon Gold 6230R CPU#1 Memory: 256GB Quad Channel DDR4 at 2933Mhz (4X64GB) CPU#2: 2nd Gen Intel Xeon Gold 6230R CPU#2 Memory: None OS Drive: 8TB PCIe Gen 4 3300MB R 2900MB W Graphics: NVIDIA GeForce RTX 4090 Power Supply: 1650W\n Any help would be appreciated!\n    submitted by    /u/Chiski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mvanm/dalternative_replacement_for_system76_thelio/",
          "publishedOn": "2023-09-19T16:17:22.000Z",
          "wordCount": 2652,
          "title": "[D]Alternative replacement for System76 Thelio Massive (ML PC)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mtmc6/r_efficientvit_lightweight_multiscale_attention/",
          "author": null,
          "description": "Using relu attention (inspired by Transformers are RNNs) and some convolution tricks to get multiscale attention, they're able to get SOTA semseg performance with MUCH faster inference on embedded hardware (e.g. CPUs, low end GPUs) than previous ViTs or EfficientNets.\n    submitted by    /u/say_wot_again  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mtmc6/r_efficientvit_lightweight_multiscale_attention/",
          "publishedOn": "2023-09-19T15:11:00.000Z",
          "wordCount": 2584,
          "title": "[R] EfficientViT: Lightweight Multi-Scale Attention for On-Device Semantic Segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mthsy/r_generating_and_imputing_tabular_data_via/",
          "author": null,
          "description": "submitted by    /u/AlexiaJM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mthsy/r_generating_and_imputing_tabular_data_via/",
          "publishedOn": "2023-09-19T15:05:58.000Z",
          "wordCount": 2546,
          "title": "[R] Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees (XGBoost)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16msx5x/research_binaural_source_seperation_casual_online/",
          "author": null,
          "description": "Just a shout out to any of you ML brains as Linux really could do with a code optimised source separation maybe a DUET like alg/nn, that has relatively low computional cost?\n Any of you guys up for the challenge.\n I say duet as in the 80/20 rule of voice input where home automation is a need generally there are only 2 noise sources of distinct DOA (media noise / command).\n The math is a bit beyond my paygrade and likely so is the optimised c/rust code but have this gut feeling for the data/signal scientists out there this is actually not that complex but for some reason is overlooked. \n    submitted by    /u/rolyantrauts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16msx5x/research_binaural_source_seperation_casual_online/",
          "publishedOn": "2023-09-19T14:43:28.000Z",
          "wordCount": 2636,
          "title": "[research] Binaural source seperation (casual / online)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16msexv/3090_investment_vs_cloud_d/",
          "author": null,
          "description": "Hi everyone,\n I was wondering if I could get some guidance. I currently own an RTX 2060, but I cannot do some of the fun stuff such as fine tuning LLMs. I’m pursuing my masters focusing on Speech Recognition and I also work as an AI developer. Also, I play games every now and then.\n I’m getting offered a 3090 for around 700 usd. However, I have to rebuild my entire PC which will end up costing 2-2.5K. I’m from Costa Rica so my KWh is around 0.23 usd. For me seems like a big investment, im not sure if im getting the desired returns.\n I was thinking about using cloud instances for my experiments. However, lambda labs is not yet available in my country. I’m not sure if there are any other options worthwhile considering. \n Thanks :)\n    submitted by    /u/Beginning_Kick756  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16msexv/3090_investment_vs_cloud_d/",
          "publishedOn": "2023-09-19T14:25:12.000Z",
          "wordCount": 2665,
          "title": "3090 Investment vs Cloud [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mrndn/hybrid_nets_d/",
          "author": null,
          "description": "Is it hypothetically possible to create hybrid nets that make use of any combination of types of architecture?\n    submitted by    /u/ShadrachOsiris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mrndn/hybrid_nets_d/",
          "publishedOn": "2023-09-19T13:53:34.000Z",
          "wordCount": 2543,
          "title": "Hybrid Nets. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mp275/r_research_directions_for_tracking_and_counting/",
          "author": null,
          "description": "Hi r/machinelearning community,\n I'm currently working on a project where I need to track and count specific features of objects using multiple monocular views with available intrinsic and extrinsic parameters. As an example, I'm interested in detecting and counting different graffiti instances in images of a kiosk.\n ​\n I've already tried various tracking algorithms, but they have struggled with the task due to the significant changes in perspective across the views. It has become apparent that simply relying on tracking without considering the camera positions is insufficient for accurate results. Therefore, I'm now exploring methods that take into account information about the camera positions and potentially use this data to improve feature tracking and counting. \n ​\n If you have any knowledge of such methods, oresearch directions or if you're aware of resources, papers, or code implementations that tackle similar problems, I would greatly appreciate your insights and recommendations. Additionally, if you have any tips or best practices for handling such tasks in the context of machine learning, I'd love to hear them. \n ​\n Thank you in advance for your help!\n    submitted by    /u/aiazar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mp275/r_research_directions_for_tracking_and_counting/",
          "publishedOn": "2023-09-19T12:00:51.000Z",
          "wordCount": 2712,
          "title": "[R] Research directions for Tracking and Counting Specific Features in Multiple Monocular Views",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mmi5b/r_exponentially_faster_feedforward_networks/",
          "author": null,
          "description": "TL;DR: Almost like your feedforward networks, shown to be up to 220x faster at inference time (depending on width) thanks to the regionalization of the input space.\n Paper: https://arxiv.org/abs/2308.14711\n GitHub: https://github.com/pbelcak/fastfeedforward\n PyPI: pip install fastfeedforward\n Abstract:\n  \nWe break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a log-time alternative to feedforward networks. We demonstrate that FFFs are up to 220x faster than feedforward networks, up to 6x faster than mixture-of-experts networks, and exhibit better training properties than mixtures of experts thanks to noiseless conditional execution. Pushing FFFs to the limit, we show that they can use as little as 1% of layer neurons for inference in vision transformers while preserving 94.2% of predictive performance.\n  \nFast feedforward networks can be used anywhere where feedforward and mixture-of-experts networks are used, delivering a significant speedup.\n ​\n    submitted by    /u/lexected  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mmi5b/r_exponentially_faster_feedforward_networks/",
          "publishedOn": "2023-09-19T09:39:46.000Z",
          "wordCount": 2669,
          "title": "[R] Exponentially Faster Feedforward Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ml3po/r_culturax_a_cleaned_enormous_and_multilingual/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.09400\n Hugging Face datasets: https://huggingface.co/datasets/uonlp/CulturaX\n Abstract:\n  \nThe driving factors behind the development of large language models (LLMs) with impressive learning capabilities are their colossal model sizes and extensive training datasets. Along with the progress in natural language processing, LLMs have been frequently made accessible to the public to foster deeper investigation and applications. However, when it comes to training datasets for these LLMs, especially the recent state-of-the-art models, they are often not fully disclosed. Creating training data for high-performing LLMs involves extensive cleaning and deduplication to ensure the necessary level of quality. The lack of transparency for training data has thus hampered research on attributing and addressing hallucination and bias issues in LLMs, hindering replication efforts and further advancements in the community. These challenges become even more pronounced in multilingual learning scenarios, where the available multilingual text datasets are often inadequately collected and cleaned. Consequently, there is a lack of open-source and readily usable dataset to effectively train LLMs in multiple languages. To overcome this issue, we present CulturaX, a substantial multilingual dataset with 6.3 trillion tokens in 167 languages, tailored for LLM development. Our dataset undergoes meticulous cleaning and deduplication through a rigorous pipeline of multiple stages to accomplish the best quality for model training, including language identification, URL-based filtering, metric-based cleaning, document refinement, and data deduplication. CulturaX is fully released to the public in HuggingFace to facilitate research and advancements in multilingual LLMs: this https URL. \n  \n​\n https://preview.redd.it/3u5dddpv66pb1.png?width=834&format=png&auto=webp&s=780b590cf621b548c525ed15305b091246c5414c\n    submitted by    /u/InterviewIntrepid889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ml3po/r_culturax_a_cleaned_enormous_and_multilingual/",
          "publishedOn": "2023-09-19T08:10:29.000Z",
          "wordCount": 2780,
          "title": "[R] CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages - 6.3 trillion tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mjr2m/d_representation_learning_with_regression_task/",
          "author": null,
          "description": "I searched around, it seems there is limited attention to regression task for representation learning.\n I assume it is because for both vision and language data (the most popular modality), MAE is the more appliable, if not better, method than the supervised contrastive learning approach. But I am working on data that is:\n  \ndifficult to design a sensible augmentation method for self-supervised training.\n Limited in size to support an autoencoder model.\n The target is continuous, and, to my knowledge, hard to transfer into class label.\n  \nCan anyone suggest some related paper?\n    submitted by    /u/AWEsoMe-Cat1231  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mjr2m/d_representation_learning_with_regression_task/",
          "publishedOn": "2023-09-19T06:46:15.000Z",
          "wordCount": 2619,
          "title": "[D] Representation learning with regression task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mc1pa/p_openjourney_xl_finetuned_sdxl_on_midjourney_v5/",
          "author": null,
          "description": "You can find more info here, and the model is still training:\n https://www.mystic.ai/paulh/open-journey-xl:latest/play\n tldr; SDXL was finetuned on 8x H100 GPUs on the Midjourney v5 dataset, only including the upscaled images which is a sub-portion of the dataset.\n Some outputs:\n ​\n https://preview.redd.it/m6r2pkdyw3pb1.jpg?width=1024&format=pjpg&auto=webp&s=4f12a7dfd5c65e4eb8476b8f3c2dc4f795817f56\n https://preview.redd.it/dc02jyu4w3pb1.jpg?width=1024&format=pjpg&auto=webp&s=df93b74c774d44a74a05d929f7ab4b17c487f24f\n https://preview.redd.it/tt5kfyu4w3pb1.jpg?width=1024&format=pjpg&auto=webp&s=ed8cc9f99227c2bb5e824a828ae1c5cb2626f54e\n ​\n https://preview.redd.it/rf00fzu4w3pb1.jpg?width=1024&format=pjpg&auto=webp&s=3b3e99dbc2d14183b5b2a2131c6f991fc60eca88\n ​\n    submitted by    /u/paulcjh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mc1pa/p_openjourney_xl_finetuned_sdxl_on_midjourney_v5/",
          "publishedOn": "2023-09-19T00:17:32.000Z",
          "wordCount": 2597,
          "title": "[P] OpenJourney XL – Finetuned SDXL on Midjourney v5 Dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mas5h/d_fsdp_model_in_each_process_is_different/",
          "author": null,
          "description": "Hey Guys,\n I'm training a large model using FSDP. I'm loading the models on each rank like this:\n ​\n https://preview.redd.it/khoquvxzk3pb1.png?width=1766&format=png&auto=webp&s=1f5acd75600d9a87212ca37e70695edfb0cc75d0\n what is weird is that right before doing the first inference on each rank, I'm summing up the weights of the model and to my surprise, they are all different across each rank. Completely different!\n ​\n What am I doing wrong here?\n    submitted by    /u/hassanzadeh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mas5h/d_fsdp_model_in_each_process_is_different/",
          "publishedOn": "2023-09-18T23:22:05.000Z",
          "wordCount": 2614,
          "title": "[D] FSDP: model in each process is different",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m9sru/curious_what_people_use_for_their_ml_workflow_on/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/cstein123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m9sru/curious_what_people_use_for_their_ml_workflow_on/",
          "publishedOn": "2023-09-18T22:41:34.000Z",
          "wordCount": 2566,
          "title": "Curious what people use for their ML workflow on cloud platforms? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m85rq/d_seeking_guidance_on_choosing_a_phd_topic_in/",
          "author": null,
          "description": "Hello fellow researchers! I'm in the exciting yet challenging phase of choosing a PhD topic in the realm of meta-learning optimization, and I could use some advice and insights.\n I've extensively researched existing meta-learning optimization algorithms like MAML and its various adaptations. I need advice and guidance on the following topics:\n  \nFirst I want to implement and compare 8-10 state-of-the-art meta-learning methods on benchmark datasets. This would involve in-depth simulation and performance evaluations to provide a comprehensive understanding of their strengths and weaknesses. Could you please guide me here if there are review papers which implement and compare different algorithms. \n \nThen I want to delve into developing a novel optimization algorithm that considers the curvature of loss functions. The idea here is to enhance the performance of existing meta-learning techniques by leveraging insights from the loss landscape.\n \nFurther, I'm considering exploring new loss functions or new improvements to loss functions tailored to the context of meta-learning. These could potentially lead to improvements in the learning process and generalization capabilities of meta-learning models.\n \n I'm reaching out to the community to gather opinions, suggestions, or any insights you might have. If you've worked in meta-learning or optimization, your experiences and advice would be invaluable in helping me choose the right direction for my PhD research. Thank you in advance for your guidance!\n    submitted by    /u/Loose_Foundation5990  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m85rq/d_seeking_guidance_on_choosing_a_phd_topic_in/",
          "publishedOn": "2023-09-18T21:37:11.000Z",
          "wordCount": 2778,
          "title": "[D] Seeking Guidance on Choosing a PhD Topic in Meta-Learning Optimization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m43o6/p_i_used_bayesian_statistics_to_find_the_best/",
          "author": null,
          "description": "https://preview.redd.it/86js8jroa2pb1.png?width=1464&format=png&auto=webp&s=7ce10494b5a77fd5c73a41322feefbf7e1f16504\n Hello!\n I thought people on this subreddit might be interested in how I went about inferring Zonai device draw chances for each dispenser in The Legend of Zelda: Tears of the Kingdom.\n In this Switch game there are devices that can be glued together to create different machines. For instance, you can make a snowmobile from a fan, sled, and steering stick.\n There are dispensers that dispense 3-6 of about 30 or so possible devices when you feed it a construct horn (dropped by defeated robot enemies) or a regular (also dropped from defeated enemies) or large Zonai charge (Found in certain chests, dropped by certain boss enemies, obtained from completing certain challenges, etc…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m43o6/p_i_used_bayesian_statistics_to_find_the_best/",
          "publishedOn": "2023-09-18T19:02:05.000Z",
          "wordCount": 3008,
          "title": "[P] I used Bayesian statistics to find the best dispensers for every Zonai device in The Legend of Zelda: Tears of the Kingdom",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m3t0t/r_unified_humanscene_interaction_via_prompted/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07918 \n Blog: https://xizaoqu.github.io/unihsi/ Code coming soon!\n Abstract:\n  \nHuman-Scene Interaction (HSI) is a vital component of fields like embodied AI and virtual reality. Despite advancements in motion quality and physical plausibility, two pivotal factors, versatile interaction control and the development of a user-friendly interface, require further exploration before the practical application of HSI. This paper presents a unified HSI framework, UniHSI, which supports unified control of diverse interactions through language commands. This framework is built upon the definition of interaction as Chain of Contacts (CoC): steps of human joint-object part pairs, which is inspired by the strong correlation between interaction types and human-object contact regions. Based on the definition, UniHSI constitutes a Large Language Model (LLM) Planner to translate language prompts into task plans in the form of CoC, and a Unified Controller that turns CoC into uniform task execution. To facilitate training and evaluation, we collect a new dataset named ScenePlan that encompasses thousands of task plans generated by LLMs based on diverse scenarios. Comprehensive experiments demonstrate the effectiveness of our framework in versatile task execution and generalizability to real scanned scenes. \n  \nhttps://preview.redd.it/0twcwloc82pb1.jpg?width=1078&format=pjpg&auto=webp&s=71bca59aae81ec114f49a742cc42f78cabc9e4c0\n https://preview.redd.it/439nzmoc82pb1.jpg?width=1637&format=pjpg&auto=webp&s=f33059c78a9d845437d551886c5f3a657ddd91fb\n https://preview.redd.it/df6i4ooc82pb1.jpg?width=758&format=pjpg&auto=webp&s=eeb33395d9de1196b4d00531c9e063c8c8fb22cd\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m3t0t/r_unified_humanscene_interaction_via_prompted/",
          "publishedOn": "2023-09-18T18:51:09.000Z",
          "wordCount": 2742,
          "title": "[R] Unified Human-Scene Interaction via Prompted Chain-of-Contacts - Shanghai AI Laboratory 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m32qs/d_rl_algorithm_used_in_tesla_fsd_v120/",
          "author": null,
          "description": "There was a lot of hype around the FSD v12.0 from Tesla in that it uses end-to-end neural networks for driving and that it is using imitation learning from good drivers to achieve that. Does someone know more about the specifics around how they are actually implementing this? I cannot find a lot about recent imitation learning/offline learning algorithms. So is this some old algorithm that they are using with a lot of data or just something new? \n    submitted by    /u/FrederikdeGrote  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m32qs/d_rl_algorithm_used_in_tesla_fsd_v120/",
          "publishedOn": "2023-09-18T18:23:32.000Z",
          "wordCount": 2633,
          "title": "[D] RL algorithm used in Tesla FSD v12.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m28oj/discussion_any_reliable_ai_to_aid_my_school/",
          "author": null,
          "description": "We know that AI is great when studying subjects that depend on simply memorizing facts (like high school biology), but we also know that AI is usually bad when studying subjects that depend on logic (like mathematics and physics).\n What I need the AI for is to explain very complex mathematical concepts to me simply, thoroughly, and accurately. I can't rely on ChatGPT because it's known for not being very reliable when it comes logical things like mathematics or physics. The best AI I know of right now is Bing AI, because it uses GPT-4 and because it prefers searching the web before deducing an answer from its data. I heard that AI agents that run on your computer like Auto-GPT and search from the web are also good at this kind of stuff, but I'm not really sure about that. Do you have any better suggestions?\n    submitted by    /u/Maximum-Gene9660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m28oj/discussion_any_reliable_ai_to_aid_my_school/",
          "publishedOn": "2023-09-18T17:51:01.000Z",
          "wordCount": 2715,
          "title": "[Discussion] Any reliable AI to aid my school studies (heavily abstract and logical, my course is focused on mathematics and physics)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m26g4/p_resume_parser_advice_seeking/",
          "author": null,
          "description": "Hi ! I am about to start a new project with Python probably using Machine Learning to parse resumes, the data is in a pdf/docx format then returned in a json format to later be used in an API or so. I am seeking advice on how to proceed, so far I am trying to collect data which will be provided to me, but not really sure how to go about it as I have found people talking about using Spacy for NLP, pyresparser which is for parsing resumes, but i was wondering if i should make everything from scratch. appreciate your time and opinion in advance \n    submitted by    /u/General-Carrot-4624  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m26g4/p_resume_parser_advice_seeking/",
          "publishedOn": "2023-09-18T17:48:38.000Z",
          "wordCount": 2659,
          "title": "[P] Resume parser advice seeking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m1itm/p_how_to_deploy_yolo_for_real_time_in_a_scalable/",
          "author": null,
          "description": "Hi, I trained a Yolo (v5) model, and I want to deploy it for a real time usage (10 FPS). I am looking for (as possible) a scalable solution, where I could pay only for inference time, at the beginning suitable for 1/2 user's at the same time occasionally, but which could be scaled to dozens of user at the same time.\n As it is for real-time usage Indeed lag to be lowest as possible. According to my current test, I can fit maximum 6 users on T400.\n Is it possible to achieve that using HuggingFace? Thank you to anyone who could help me\n    submitted by    /u/tarsiospettro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m1itm/p_how_to_deploy_yolo_for_real_time_in_a_scalable/",
          "publishedOn": "2023-09-18T17:23:02.000Z",
          "wordCount": 2664,
          "title": "[P] How to deploy Yolo for real time, in a scalable solution ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m0c4a/droadmap_for_machine_learning/",
          "author": null,
          "description": "I want to start learning machine learning. I Know python language and data structure. I am planning to learn algorithm. Can you provide me free learning sites or utube channel where I can machine learning step by step . Any site to practice machine learning?\n    submitted by    /u/Temporary-Pie-1831  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m0c4a/droadmap_for_machine_learning/",
          "publishedOn": "2023-09-18T16:36:35.000Z",
          "wordCount": 2596,
          "title": "[D]Roadmap for machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m03qn/research_detecting_errors_in_numerical_data_via/",
          "author": null,
          "description": "Years ago, we showed the world it was possible to automatically detect label errors in classification datasets via machine learning. Since that moment, folks have asked whether the same is possible for regression datasets?\n Figuring out this question required extensive research since properly accounting for uncertainty (critical to decide when to trust machine learning predictions over the data itself) poses unique challenges in the regression setting.\n Today I have published a new paper introducing an effective method for “Detecting Errors in Numerical Data via any Regression Model”. Our method can find likely incorrect values in any numerical column of a dataset by utilizing a regression model trained to predict this column based on the other data features.\n We’ve added our new algorithm to our open-source cleanlab library for you to algorithmically audit your own datasets for errors. Use this code for applications like detecting: data entry errors, sensor noise, incorrect invoices/prices in your company’s / client’s records, mis-estimated counts (eg. of cells in biological experiments).\n Find errors in regression data in just a few lines of code.\n Extensive benchmarks reveal cleanlab’s algorithm detects erroneous values in real numeric datasets better than alternative methods like RANSAC and conformal inference.\n If you'd like to learn more, you can check out the blogpost, research paper, code, and tutorial to run this on your data.\n    submitted by    /u/jonas__m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m03qn/research_detecting_errors_in_numerical_data_via/",
          "publishedOn": "2023-09-18T16:27:20.000Z",
          "wordCount": 2778,
          "title": "[Research] Detecting Errors in Numerical Data via any Regression Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lwfna/d_does_the_existence_of_mesa_optimizers_in_modern/",
          "author": null,
          "description": "Recent work shows transformers are capable of performing multi-step gradient descent of mesa objectives inside of their transformer layers. This is even possible for linear transformers, which effectively perform linear optimization on deep representations of features calculated by earlier layers.\n https://arxiv.org/pdf/2309.05858.pdf\n For those unfamiliar, instrumental convergence is the idea that entities with different goals will tend towards different subgoals. Examples could include gathering power, not dying, acquiring resources, etc. A famous thought experiment, known as the paperclip maximizer, is the idea of an AI that is optimized for paperclip production taking over the world so it can build as many paperclips as possible.\n However, if models are dynamically pursuing different objectives at runtime via generated mesa-optimizers, even if instrumental convergence is real, would we still expect it to happen? Without a constant objective given subgoals might start to conflict with each other. On the other hand, since instrumental convergence implies that different goals benefit from similar sub-objectives, perhaps the varying mesa objective doesn't really matter.\n ​\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lwfna/d_does_the_existence_of_mesa_optimizers_in_modern/",
          "publishedOn": "2023-09-18T14:02:57.000Z",
          "wordCount": 2732,
          "title": "[D] Does the existence of mesa optimizers in modern models like transformers make instrumental convergence (think paperclip maximizer) scenarios unlikely?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lvltj/discussion_are_researchers_shifting_from_rl/",
          "author": null,
          "description": "In recent months, I've noticed a significant increase in the number of research papers focusing on LLM and generative models, particularly diffusion models. This trend appears to indicate a growing interest in these areas when compared to the relatively reduced attention given to Reinforcement Learning. It begs the question: Are researchers shifting their focus away from Reinforcement Learning towards these domains? Because in the past I have seen many people complaining about RL on its efficiency and it's impact which have often fallen short of expectations.\n    submitted by    /u/Global_Raise_2979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lvltj/discussion_are_researchers_shifting_from_rl/",
          "publishedOn": "2023-09-18T13:29:04.000Z",
          "wordCount": 2639,
          "title": "[Discussion] Are Researchers shifting from RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lvj4b/d_whats_the_best_practice_in_choosing_which/",
          "author": null,
          "description": "I am reading these 3 articles below and it is still not clear to me what’s the best practice to follow to guide me in choosing which quantized Llama 2 model to use.\n https://huggingface.co/blog/gptq-integration\n https://huggingface.co/blog/overview-quantization-transformers\n https://towardsai.net/p/machine-learning/gptq-quantization-on-a-llama-2-7b-fine-tuned-model-with-huggingface?amp=1\n Questions: 1) I understand there are currently 4 quantized Llama 2 models (8, 4, 3, and 2-bit precision) to choose from. Is this right? 2) with the default Llama 2 model, how many bit precision is it? 3) are there any best practice guide to choose which quantized Llama 2 model to use?\n Would really appreciate any input on the above, even if you only know the answer to 1 or 2 of the questions above. Many thanks!\n    submitted by    /u/--leockl--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lvj4b/d_whats_the_best_practice_in_choosing_which/",
          "publishedOn": "2023-09-18T13:25:59.000Z",
          "wordCount": 2672,
          "title": "[D] What’s the best practice in choosing which quantized Llama 2 model to use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ltjhf/d_chatting_with_multiple_pdfs_in_using_aws/",
          "author": null,
          "description": "I want to create an application which can be used to chat, compare and summarize two simulataneous insurance policy/policies. How can I do it using AWS and HuggingFace ? Has anyone already done it?\n    submitted by    /u/UnfinishedSentenc-1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ltjhf/d_chatting_with_multiple_pdfs_in_using_aws/",
          "publishedOn": "2023-09-18T11:57:26.000Z",
          "wordCount": 2592,
          "title": "[D] Chatting with Multiple PDF's in Using AWS Sagemaker and Kendra",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lt9e9/discussion_transformers_for_predictions_from/",
          "author": null,
          "description": "I'm in a situation where I have to map from unitary matrices to something (doesn't matter here, but in short: we're in the realm of tooling for quantum computing).\n The key issue The number of matrix elements of the unitaries scales as 2^(2N), where N is the problem size. With N<5 I can easily flatten the matrix and put it into a simple FNN, which works quite well. Once hitting N=5 (the point where things actually get interesting), however, we already have 1024 matrix elements and the method struggles a lot. Still converging to something but very suboptimal. Sure, increasing N hardens the problem in general, but the performance degradation is so abrupt that I suspect some model issues, maybe caused by the curse of dimensionality or something similar.\n Idea (spoiler alert: Transformer) The …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lt9e9/discussion_transformers_for_predictions_from/",
          "publishedOn": "2023-09-18T11:44:42.000Z",
          "wordCount": 2940,
          "title": "[Discussion] Transformers for predictions from orthonormal base sets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lstp1/d_professionally_code_with_torch/",
          "author": null,
          "description": "I just concluded my PhD in Robotics & AI and I'd like to learn how to professionally code with Torch.\n Is there any book/resource you can recommend?\n    submitted by    /u/rossomalpelo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lstp1/d_professionally_code_with_torch/",
          "publishedOn": "2023-09-18T11:22:37.000Z",
          "wordCount": 2579,
          "title": "[D] Professionally code with Torch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lrjje/d_integral_over_neural_network_input_space/",
          "author": null,
          "description": "I'm wondering if it's possible to compute definite integral over the input space. Assuming the network is designed to have finite integral with Gaussian being the final layer, is there a way to implement this without resorting to sampling? All inputs go from negative infinity to infinity.\n    submitted by    /u/donchan789  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lrjje/d_integral_over_neural_network_input_space/",
          "publishedOn": "2023-09-18T10:14:18.000Z",
          "wordCount": 2601,
          "title": "[D] Integral over neural network input space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lfst0/d_help_with_understanding_diffusion_models_a/",
          "author": null,
          "description": "I'm trying to read through the paper Understanding Diffusion Models: A Unified Perspective and came across this section:\n https://preview.redd.it/ykkctwhmhwob1.png?width=2346&format=png&auto=webp&s=c7595aae52a8ee22813c840a40a6d29dcf773a10\n I think I kind of get what is going on here but not clearly. For one, what exactly is a Monte Carlo estimate? I tried looking online but didn't get many good results. I'm having trouble understanding why\n https://preview.redd.it/yazmfzg1iwob1.png?width=380&format=png&auto=webp&s=dbbbf80e85a95cd96d8e1ede73e9f8ba1e6e9096\n is approximately equal to:\n ​\n https://preview.redd.it/lbw36em7iwob1.png?width=464&format=png&auto=webp&s=46fb3ebcd02fb4b772b1be51cd59d60d3a1cf438\n where z is sampled from q. Secondly, what exactly does L that z is indexed by refer to? The number of samples X or what exactly?\n    submitted by    /u/lumijekpr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lfst0/d_help_with_understanding_diffusion_models_a/",
          "publishedOn": "2023-09-17T23:38:30.000Z",
          "wordCount": 2639,
          "title": "[D] Help with Understanding Diffusion Models: A Unified Perspective.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ld46e/r_shattering_all_2input_binary_functions/",
          "author": null,
          "description": "I'm looking for the simplest model that can fit all 16 (222) possible 2-input binary functions I used the term \"shatter\" from VC dimension, which does not give a constructive approach to building the model\n    submitted by    /u/hnsmn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ld46e/r_shattering_all_2input_binary_functions/",
          "publishedOn": "2023-09-17T21:43:34.000Z",
          "wordCount": 2585,
          "title": "[R] Shattering all 2-input binary functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lc16n/p_is_20s_per_step_on_an_efficientnetb4_cnn_normal/",
          "author": null,
          "description": "I'm getting 20 seconds per step while training a 244x244x3 EfficientNet-B4 model. The batch size is 20, with 8 classes. Since I have about 5000 images, that makes each epoch around an hour and a half.\n Looking at models online, it seems like people get step durations in the milliseconds. Is it a problem on my end? Running on Google Colab free version.\n    submitted by    /u/hnknerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lc16n/p_is_20s_per_step_on_an_efficientnetb4_cnn_normal/",
          "publishedOn": "2023-09-17T21:00:57.000Z",
          "wordCount": 2617,
          "title": "[P] Is 20s per Step on an EfficientNet-B4 CNN normal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16larsn/dp_how_to_get_the_3d_pose_estimations_from_an/",
          "author": null,
          "description": "Hi,\n I'am trying to get the 3D keypoints coordinates from an image or video and then map it to SMPL model. It's pretty easy to get the keypoints from an image or video using the mediapipe library. But the mapping of it with the SMPL model is something that I can't figure out. mainly because the skeleton structure is different. Some already had a similar issue but the answers were not clear and he didn't even ask futher. Is it possible to do this?? if it's not possible with mediapipe is there some other library that I could use?? I heard about openPose too but when I tried it didn't work someone was saying it works only on windows 11. There are some other parts also to this project which will mostly be dealt with Pytorch. There are some pose estimators in TensorFlow but I want to stick to pytorch hence would like some pose estimators in that framwork, or a library or somehing inside opencv\n https://preview.redd.it/w9mioiyxhvob1.png?width=951&format=png&auto=webp&s=3886c356513b62efbcaddaa76841457cf3eb22e5\n https://preview.redd.it/xjal9kyxhvob1.png?width=506&format=png&auto=webp&s=7f544a3050fbd744d300d2bf6e1a286a4014ece5\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16larsn/dp_how_to_get_the_3d_pose_estimations_from_an/",
          "publishedOn": "2023-09-17T20:10:59.000Z",
          "wordCount": 2723,
          "title": "[D][P] How to get the 3D pose estimations from an Image or Video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l7ict/r_earthpt_how_to_superscale_llms_with_large/",
          "author": null,
          "description": "submitted by    /u/Smith4242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l7ict/r_earthpt_how_to_superscale_llms_with_large/",
          "publishedOn": "2023-09-17T18:02:01.000Z",
          "wordCount": 2565,
          "title": "[R] EarthPT: how to superscale LLMs with large observation models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l59xb/discussion_research_how_to_add_furniture_to_an/",
          "author": null,
          "description": "Hello all,\n I've come across a fascinating example of virtual staging and I'm looking for some technical advice.\n Here's the image:\n https://preview.redd.it/3vbw441eeuob1.png?width=2511&format=png&auto=webp&s=679bc62f0cb61d479fe6dc6ce93af4f8846b8cea\n I get how ControlNet-MLSD is used to generate the lines and structure of the empty room. My question is, how is the furniture generated and added to the room without messing up the pixels, making it look as realistic as in the example?\n    submitted by    /u/dexter-dot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l59xb/discussion_research_how_to_add_furniture_to_an/",
          "publishedOn": "2023-09-17T16:33:52.000Z",
          "wordCount": 2630,
          "title": "[Discussion] [Research] How to Add Furniture to an Empty Room Using ControlNet-MLSD, so the model learns to keep the exact room pixels?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l4s9q/d_pinecone_vs_pgvector_vs_any_other_alternative/",
          "author": null,
          "description": "Hi Everyone,\n Which vector database would be efficient and affordable for a enterprise chatbot? I tried Pinecone, its was simple to integrate with my python backend. But it's not open-source and its pricing it bit concerning. So Please suggest an alternative.\n    submitted by    /u/Free_Conversation106  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l4s9q/d_pinecone_vs_pgvector_vs_any_other_alternative/",
          "publishedOn": "2023-09-17T16:15:19.000Z",
          "wordCount": 2595,
          "title": "[D] Pinecone vs PgVector vs Any other alternative vector database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l4h0x/d_am_i_thinking_backpropagation_right/",
          "author": null,
          "description": "Basically i wanted to understand how backprop is done in neural networks and how i should be implementing it, so i did what i always do - the math. I just want to know if what i though up is even usable in practice or not. Here is my math. \n    submitted by    /u/EnderPoint07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l4h0x/d_am_i_thinking_backpropagation_right/",
          "publishedOn": "2023-09-17T16:03:16.000Z",
          "wordCount": 2600,
          "title": "[D] Am i thinking backpropagation right?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l3vx2/discussion_question_on_the_paper_named/",
          "author": null,
          "description": "Hi, all.\n ​\n I just read the paper named \" SELF-ATTENTION DOES NOT NEED O(n 2 ) MEMORY\" from Google.\n I understood that it requires O(1) for a single query, but still cannot understand why it requires O(log N) for self-attention and different order input.\n ​\n It seems like adding one index into a sequence requires O(log N) (The paper's saying this).\n But why does it take O(log N)? Isn't it just O(1)? Because it is just adding a single datapoint for the index.\n ​\n I really hope someone understands why it is and leaves any comment on this. \n Here's the paper.\n https://arxiv.org/abs/2112.05682\n ​\n Thanks in advance.\n    submitted by    /u/Maximum_Performance_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l3vx2/discussion_question_on_the_paper_named/",
          "publishedOn": "2023-09-17T15:40:37.000Z",
          "wordCount": 2661,
          "title": "[Discussion] Question on the paper named, SELF-ATTENTION DOES NOT NEED O(n 2 ) MEMORY from Google.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l30vp/d_convert_onnx_model_to_wasm_format/",
          "author": null,
          "description": "I need some help regarding the process of converting ONNX model to WASM format\n I created ELECTRA discriminator model with my own config, then convert the Pytorch model to ONNX format. After that, I quantized the model to 2mb. The model will be used for text classification.\n Now I want to convert it to WASM, but I'm literally stucked and dont know how to proceed\n I need some suggestions on how to proceed Please help, thank you\n    submitted by    /u/Ellzaf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l30vp/d_convert_onnx_model_to_wasm_format/",
          "publishedOn": "2023-09-17T15:06:11.000Z",
          "wordCount": 2628,
          "title": "[D] Convert ONNX model to WASM format",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l1gbq/d_what_architecture_to_use_with_correlated_data/",
          "author": null,
          "description": "LIke the title says, i have correlated data samples and a covariance matrix among them. if i use a fcnn i can only consider the samples i.i.d. and the use either the MSE or THE MLE as loss function. but the data samples are not independent, so what architecture would allow me to use the full covariance matrix among the samples? transformers? \n    submitted by    /u/ilrazziatore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l1gbq/d_what_architecture_to_use_with_correlated_data/",
          "publishedOn": "2023-09-17T14:01:38.000Z",
          "wordCount": 2615,
          "title": "[D] what architecture to use with correlated data samples?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kyv37/tmlr_header_coming_up_when_trying_to_upload_paper/",
          "author": null,
          "description": "I have written and submitted a paper to TMLR and also am uploading it to arxiv. However, even after using \\usepackage[preprint]{tmlr}, I'm getting \"Under Submission at TMLR\". Should this happen. If not, where am I going wrong?\n    submitted by    /u/filletedforeskin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kyv37/tmlr_header_coming_up_when_trying_to_upload_paper/",
          "publishedOn": "2023-09-17T11:59:55.000Z",
          "wordCount": 2593,
          "title": "TMLR header coming up when trying to upload paper to arxiv [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kycoq/d_can_overtraining_be_considered_a_subset_of_the/",
          "author": null,
          "description": "i.e the goal of learning to model the empirical distribution is misaligned with the goal of modeling the \"true\" distribution.\n I've found this framing helpful for describing regulirization heuristics to people, is this a valid way of viewing it?\n    submitted by    /u/Cartesian_Carrot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kycoq/d_can_overtraining_be_considered_a_subset_of_the/",
          "publishedOn": "2023-09-17T11:33:02.000Z",
          "wordCount": 2594,
          "title": "[D] Can overtraining be considered a subset of the alignment problem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kxfmr/d_any_materials_on_machine_learning_applied_to/",
          "author": null,
          "description": "I have asked this question in other subreddits but no one answered me yet.I've googled it, but maybe some kind people who actually have worked or are working in this field would share some resources. Maybe there are some books or papers that are very explanatory and directly show what problems can be solved by using ML in prosthetics, how and etc. Maybe there are introductory textbooks or must-read papers.\n    submitted by    /u/tenderwrath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kxfmr/d_any_materials_on_machine_learning_applied_to/",
          "publishedOn": "2023-09-17T10:41:14.000Z",
          "wordCount": 2623,
          "title": "[D] Any materials on machine learning applied to prosthetics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kwupb/r_the_rise_and_potential_of_large_language_model/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07864 \n Github: https://github.com/WooooDyy/LLM-Agent-Paper-List \n Abstract:\n  \nFor a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent AI agents since the mid-20th century. However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kwupb/r_the_rise_and_potential_of_large_language_model/",
          "publishedOn": "2023-09-17T10:07:20.000Z",
          "wordCount": 2854,
          "title": "[R] The Rise and Potential of Large Language Model Based Agents: A Survey - Fudan NLP Group miHoYo Inc 2023 China - Github repository includes over 100 Papers with github links!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kwn56/d_alternatives_to_this_sub/",
          "author": null,
          "description": "Since the influx caused by LLMs, this sub has become almost useless to me. What are some alternatives where interesting papers are shared, research discussions take place, and which isn't flooded with LLMs, startups, or personal projects?\n    submitted by    /u/ParanoidTire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kwn56/d_alternatives_to_this_sub/",
          "publishedOn": "2023-09-17T09:55:18.000Z",
          "wordCount": 2586,
          "title": "[D] Alternatives to this sub?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kvopg/d_should_i_scale_multiclass_target_variable/",
          "author": null,
          "description": "Hey all Please don't mind my English writing \n I have a dataset with scaled feature (scaled by StanderScaler) and multiple class target variable encoded as 0,1,2..6 \n Should I scale the target variable like the feature to increase the accuracy (current accuracy is 79%) and if so how can I do this\n    submitted by    /u/Sunday_A  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kvopg/d_should_i_scale_multiclass_target_variable/",
          "publishedOn": "2023-09-17T08:57:40.000Z",
          "wordCount": 2602,
          "title": "[D] Should I scale multiclass target variable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kvmcv/r_factors_influencing_adoption_intention_of/",
          "author": null,
          "description": "Hello,\n ​\n I am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.\n ​\n Please note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.\n ​\n If you are interested in learning more about the study, please follow the link below. \n ​\n https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf_link\n ​\n Thank you for taking the time to contribute to our research study. Your participation is greatly appreciated!\n    submitted by    /u/maulanashi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kvmcv/r_factors_influencing_adoption_intention_of/",
          "publishedOn": "2023-09-17T08:53:18.000Z",
          "wordCount": 2724,
          "title": "[R] Factors Influencing Adoption Intention of ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kv1ie/d_how_do_the_apis_of_llms_determine_whether_they/",
          "author": null,
          "description": "When I ask questions related to security issues through the APIs of ChatGPT, Claude and other LLMs, such as inquiring how to make a bomb, the APIs of these LLMs would often refuse to answer.\n How do the APIs of these LLMs determine whether they should answer a question?\n Do they make judgments based on pre-generated responses?\n Or do they match keywords in the input prompt?\n Or do they use a classifier to identify the input prompt?\n    submitted by    /u/ShacklesLay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kv1ie/d_how_do_the_apis_of_llms_determine_whether_they/",
          "publishedOn": "2023-09-17T08:15:47.000Z",
          "wordCount": 2635,
          "title": "[D] How do the APIs of LLMs determine whether they should answer a question?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ksqjj/r_the_rise_and_potential_of_large_language_model/",
          "author": null,
          "description": "People have been chasing super-smart AI for ages, hoping they could think and act like us. While we've made a lot of cool tech, we still need a killer starting point for AI that can handle all sorts of tasks. Large Language Models\" (LLMs) are like a big leap toward AI that's smart across the board. People have been using LLMs to make AI that can do loads of things. \n The article takes us on a trip from where AI ideas started, to why LLMs rock as the backbone for AI. \n https://arxiv.org/abs/2309.07864\n They break down this LLM-AI into three parts: \n  \nthe thinky bit (brain), \n what they sense (perception), \n and what they do (action). \n  \nThey chat about how these AI can work solo, in teams, or buddy up with humans.\n https://arxiv.org/abs/2309.07864\n    submitted by    /u/QuantumAsha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ksqjj/r_the_rise_and_potential_of_large_language_model/",
          "publishedOn": "2023-09-17T05:48:38.000Z",
          "wordCount": 2685,
          "title": "[R] The Rise and Potential of Large Language Model Based Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kifvd/p_made_a_simple_github_tool_to_check_gpu_vram/",
          "author": null,
          "description": "submitted by    /u/ExploreExploit400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kifvd/p_made_a_simple_github_tool_to_check_gpu_vram/",
          "publishedOn": "2023-09-16T21:21:57.000Z",
          "wordCount": 2572,
          "title": "[P] Made a simple github tool to check GPU vRAM breakdown for any LLM. Supports GGML & bnb quantization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kifmt/p_text_to_image_generation/",
          "author": null,
          "description": "submitted by    /u/No-Percentage7346  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kifmt/p_text_to_image_generation/",
          "publishedOn": "2023-09-16T21:21:42.000Z",
          "wordCount": 2604,
          "title": "[P] Text to Image generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kh5m8/d_no_code_ml_tools/",
          "author": null,
          "description": "I'm taking a No code ML class and we are asked to choose which platform we want to use. The options are Dataiku, RapidMiner, and KNIME. Does anyone have thoughts on these options in terms of which is best/worst for someone with minimal coding experience?\n    submitted by    /u/V1ncentAdultman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kh5m8/d_no_code_ml_tools/",
          "publishedOn": "2023-09-16T20:27:09.000Z",
          "wordCount": 2594,
          "title": "[D] No Code ML Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kdrzn/research_layerneighbor_sampling_for_scalable/",
          "author": null,
          "description": "Hi everybody,\n I have been working on scalable GNN training for a while and noticed that the bottleneck of training GNNs is the graph sampling and feature fetching stages. GNN training frameworks PyG and DGL that most people use seem to default to using Neighbor Sampling for minibatch training. I am hoping that with my new paper Layer-Neighbor Sampling -- Defusing Neighborhood Explosion in GNNs, this default might be due to change.\n My new approach combines the layer sampling approach with the neighbor sampling approach. The result is that there is more overlap in the sampled neighborhoods and one still gets a fixed number of neighbors per seed vertex. It is even possible to turn it into a subgraph sampling approach by fixing the random seed used for sampling across all layers of the GNN m…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kdrzn/research_layerneighbor_sampling_for_scalable/",
          "publishedOn": "2023-09-16T17:59:49.000Z",
          "wordCount": 2974,
          "title": "[Research] Layer-Neighbor Sampling for Scalable Graph Network Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kbqce/d_how_do_i_move_into_cvnlp/",
          "author": null,
          "description": "Hi guys need some advice,\n I have been working as a data scientist for the past 3 years, mostly in the domain of time series & predictive analytics (churn prediction/segmentation, etc.) with some deployment, hence do not currently have any major NLP/CV/Deep learning projects as such.\n Now, I can see that NLP/CV/Gen AI is mostly in demand and they are really enjoyable as well.\n How do I shift into these domains, given that new companies having these roles are asking for similar past working experience?\n    submitted by    /u/immortal_omen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kbqce/d_how_do_i_move_into_cvnlp/",
          "publishedOn": "2023-09-16T16:30:17.000Z",
          "wordCount": 2634,
          "title": "[D] How do I move into CV/NLP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kawop/r_deva_tracking_anything_with_decoupled_video/",
          "author": null,
          "description": "submitted by    /u/Mediocre-Bullfrog686  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kawop/r_deva_tracking_anything_with_decoupled_video/",
          "publishedOn": "2023-09-16T15:54:59.000Z",
          "wordCount": 2550,
          "title": "[R] DEVA: Tracking Anything with Decoupled Video Segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kapda/d_i_want_to_improve_my_self_in_machine_learning/",
          "author": null,
          "description": "I am beginner in machine learning field. I know python, some basic machine learnig algorithm like linear, logistic, decision tree, random forest. I did some work on jupyter notebok related to machine learning like data gathering, data preprocessing, data modeling, data training, finding accuracy, confusion matrix, precision, recall, feature generation etc. i deployed one machine learning model on Skitlearn as well.\n Now, I just want to know that what next means what i can do more in machine learning field after this. I just need some guidance to move on further. I use kaggle and tensor flow (don't know exactly more about this ). If you have any suggestion or any guidance that will be appreciated.\n    submitted by    /u/myteachexplore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kapda/d_i_want_to_improve_my_self_in_machine_learning/",
          "publishedOn": "2023-09-16T15:46:11.000Z",
          "wordCount": 2671,
          "title": "[D] I want to improve my self in machine learning field",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k7ezx/d_the_fate_of_neural_vqa_and_semantic_scene/",
          "author": null,
          "description": "Today we live in a world of multi-model LLMs. How will the following technologies fare against these LLM-based models? \n  \nNeural VQA\n \nSemantic Scene Segmentation\n \n Multi-model LLM are emerging quickly now, (such as NExT-GPT https://next-gpt.github.io/ ) . When you consider the kind of \"understanding\" of a visual scene these models are capable of, what will happen to prior approaches like Neural VQA? The nagging feeling that Neural VQA is going to be completely superseded by LLMs is palpable. The only vestige left for the older technology may have something to do with reasoning about the objects , such as properly counting the number of objects of a category that are present. But even that is getting sketchy. \n On the topic of scene understanding, we can turn to semantic scene segmentation. SSS is a more complicated topic than Neural VQA. SOTA SSS algorithms are still largely employing DeConv Nets, and still require fully labelled datasets. With multi-model LLMs, there is a nagging question : Why go through the complexity/mess of first segmenting a scene very accurately, when an LLM can do better at identifying the entire scene's category in one fail swoop? \n One might suggest that SSS still has a use in regards to interacting with the segmented objects of an environment, where one such \"interaction\" would be avoiding collisions with pedestrians, trees, or other cars. But honestly, SSS does not really make this connection with planning and action, it really only gives you the categories of the segments. THe autonomous vehicle's next moves are still an open problem. \n What technologies do you expect that multi-model LLMs will supersede, if any?\n    submitted by    /u/moschles  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k7ezx/d_the_fate_of_neural_vqa_and_semantic_scene/",
          "publishedOn": "2023-09-16T13:19:36.000Z",
          "wordCount": 2823,
          "title": "[D] The fate of neural VQA and Semantic Scene Segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k5b9l/r_three_ways_to_generate_ai_art_using_intel_arc/",
          "author": null,
          "description": "submitted by    /u/reps_up  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k5b9l/r_three_ways_to_generate_ai_art_using_intel_arc/",
          "publishedOn": "2023-09-16T11:36:26.000Z",
          "wordCount": 2566,
          "title": "[R] Three Ways to Generate AI Art Using Intel Arc GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k1mke/d_using_gans_to_help_understand_latent/",
          "author": null,
          "description": "Hey. First of all I'm not a researcher on this area, so pardon my ignorance.\n I'm looking to employ a GAN on a dataset. The goals are still a bit unclear, but it's mainly to improve classification by either data augmentation and class balancing, or understanding the data through the latent representations.\n I'm really keen on InfoGAN at the moment. I trained one on the MNIST and the continuous variables learned the rotation and width, as in the paper and other peoples code.\n But at this point I think I need some help. I have labels, which means that maybe I should use a conditional GAN. But how will I learn similar representations as those in InfoGAN? I know StyleGAN is the current big thing in this area, but my images are limited to similar pixel-range as MNIST, and StyleGAN seems dependant on the ProGAN idea of increasing resolution for training.\n I'm a bit confused on the whole topic and would love a pointer to any discussion etc., as I can't seem to find anything but papers and they seem to be only focused on human faces, my data is unnatural not unsimilar again to MNIST. I don't have semantical information either as I see many papers employing that.\n I see many papers employing semi-supervision in this area, but honestly I'm just a bit lost and overwhelmed as this is not my area and GAN papers are still not stopping (I read a post here from 2017 about a GAN making GANs...).\n If you read this far: thank you and any pointers and discussion are very welcome. I would post on /r/learnmachinelearning but I feel the discussion in there is very different from this. My main goal is data exploration, but also to prove effectiveness some classification will be necessary and here the generative approach may help to augment data efficiently.\n    submitted by    /u/Infamous-Bank-7739  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k1mke/d_using_gans_to_help_understand_latent/",
          "publishedOn": "2023-09-16T07:55:16.000Z",
          "wordCount": 2866,
          "title": "[D] Using GANs to help understand latent representations of small dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k10bn/d_how_do_i_change_my_domain_from_ds_to_mle/",
          "author": null,
          "description": "Hi guys need some advice,\n I have been working as a data scientist for the past 3 years, mostly in the domain of time series & predictive analytics, hence do not currently have any major NLP/CV/Deep learning projects as such. \n Now, I can see that NLP/CV/Gen AI is mostly in demand and they are really enjoyable as well.\n How do I shift into these domains, given that new companies having these roles are asking for similar past working experience? \n ​\n    submitted by    /u/immortal_omen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k10bn/d_how_do_i_change_my_domain_from_ds_to_mle/",
          "publishedOn": "2023-09-16T07:18:00.000Z",
          "wordCount": 2632,
          "title": "[D] How do I change my domain (from DS to MLE)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jyh7p/d_ganimede_jupyter_whiteboard/",
          "author": null,
          "description": "I have been working on a alternative to Jupyter Notebooks. Please check it out and share your thoughts : https://github.com/nottherealsanta/ganimede \n ​\n https://preview.redd.it/k8rcx8fwrjob1.png?width=2302&format=png&auto=webp&s=a8a670251f6c268acffc88a40bd528d8d438a5f5\n    submitted by    /u/notsorealsanta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jyh7p/d_ganimede_jupyter_whiteboard/",
          "publishedOn": "2023-09-16T04:44:32.000Z",
          "wordCount": 2568,
          "title": "[D] Ganimede, Jupyter Whiteboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jx9od/d_how_to_evaluate_spectrograms/",
          "author": null,
          "description": "How would you evaluate generated spectrogram audio quality? Taking Riffusion for example, how would you then compare its performance to another generator? What are some common techniques that I could use?\n I mean of course purely in the quality of the audio itself, not my subjective opinion on how much I like the music\n    submitted by    /u/DavesEmployee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jx9od/d_how_to_evaluate_spectrograms/",
          "publishedOn": "2023-09-16T03:36:22.000Z",
          "wordCount": 2603,
          "title": "[D] How to Evaluate Spectrograms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16josbf/p_building_my_own_aimodel_hub_seeking_guidance/",
          "author": null,
          "description": "Hello everyone! I'm embarking on a project to create an AI-model hub—a platform where users can upload and utilize their AI models. While I'm aware of popular platforms that offer this, my primary goal is for educational purposes. I'd greatly appreciate any recommendations for helpful articles, videos, or codebases to guide me on this journey. Thanks in advance!\n    submitted by    /u/Electronic-Choice-86  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16josbf/p_building_my_own_aimodel_hub_seeking_guidance/",
          "publishedOn": "2023-09-15T21:03:02.000Z",
          "wordCount": 2612,
          "title": "[P] Building My Own AI-Model Hub: Seeking Guidance and Resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16joh3y/p_llma_expert_guidance_on_generative_ai_tailored/",
          "author": null,
          "description": "Hello everyone,\n Introducing LLMa: ChatGPT built around YOU (getllma.com) - a dedicated service offering hands-on expertise to integrate state-of-the-art generative AI tailored for your projects. We utilize open-source models and train them to outperform GPT-4 on tasks specific to your domain. Envision having a seasoned AI specialist on your team, ensuring your model not only rivals the big players but excels in your unique challenges.\n 🌟 Why LLMa?\n  \nPersonalized Expertise: Our team collaborates closely with you, delving into your needs and sculpting a model that thrives in your domain.\n Bespoke Training: We refine open-source models (LLaMa, T5, etc.) with plenty of secret tricks to specialize and surpass GPT-4's performance for your specific tasks.\n Cost-Effective: LLMa tends to be around 100x cheaper than GPT-4, offering significant savings. No recurring fees; invest in a one-time fee based on your model's complexity.\n Full Ownership: We hand over the model files/weights to you. It's entirely yours, ensuring total privacy with no PII leaks.\n Deployment Assistance: Beyond just crafting the model, we can guide you in deploying it, ensuring a seamless integration into your operations.\n Ongoing Support: From initial brainstorming to model deployment, we're with you, ensuring success at every phase.\n  \n💼 Tailored for Enterprises: LLMa is meticulously crafted for enterprises that aim for a high-performing, bespoke AI solution. Transparent pricing begins at $500, contingent on your distinct requirements.\n ❓ Navigating the Generative AI Terrain? Embarking on the vast journey of generative AI? LLMa is your compass. We aid in defining challenges, strategizing solutions, and optimizing the AI potential for your endeavors.\n If LLMa piques your interest or if you have any queries, fill-in the form, drop a comment below or DM me. I'm all ears and eager to connect!\n    submitted by    /u/iliashark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16joh3y/p_llma_expert_guidance_on_generative_ai_tailored/",
          "publishedOn": "2023-09-15T20:50:41.000Z",
          "wordCount": 2845,
          "title": "[P] LLMa: Expert Guidance on Generative AI, Tailored for Your Needs, Outdoing GPT-4 & Saving Costs!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jo7hg/p_deploying_hugging_face_models_on_amazon/",
          "author": null,
          "description": "Quick template that bootstraps Amazon SageMaker running a LlaMa 2 model from Hugging Face. Everything deployed as code (Python), no manual tweaking in the SageMaker console. \n www.pulumi.com/blog/mlops-huggingface-llm-aws-sagemaker-python/ \n    submitted by    /u/kao-pulumi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jo7hg/p_deploying_hugging_face_models_on_amazon/",
          "publishedOn": "2023-09-15T20:39:55.000Z",
          "wordCount": 2583,
          "title": "[P] Deploying Hugging Face models on Amazon SageMaker using infrastructure as code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jlgvp/d_gan_training/",
          "author": null,
          "description": "Am trying to train GANs for oversampling a minority text class (am feeding it only the minority class), but the results dont seem to improve much (AUC only improves by .03 so far). while basic oversampling techniques like SMOTE gives way better results. also am using a vector representation for the whole text instead of word embedding(same used for SMOTE), i tried different architectures with CNN.\n is there any tricks maybe in training the discriminator and generator ? i can't seem to find the problem\n    submitted by    /u/SlightSecretaryB  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jlgvp/d_gan_training/",
          "publishedOn": "2023-09-15T18:49:58.000Z",
          "wordCount": 2632,
          "title": "[D] GAN training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jl4pe/r_agents_an_opensource_framework_for_autonomous/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07870 \n Github: https://github.com/aiwaves-cn/agents \n Abstract:\n  \nRecent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces. We consider language agents as a promising direction towards artificial general intelligence and release Agents, an open-source library with the goal of opening up these advances to a wider non-specialist audience. Agents is carefully engineered to support important features including planning, memory, tool usage, multi-agent communication, and fine-grained symbolic control. Agents is user-friendly as it enables non-specialists to build, customize, test, tune, and deploy state-of-the-art autonomous language agents without much coding. The library is also research-friendly as its modularized design makes it easily extensible for researchers. \n  \nhttps://preview.redd.it/3bdi71r5rgob1.jpg?width=1131&format=pjpg&auto=webp&s=760942c19be6ecda791414c812a77e72751c526d\n https://preview.redd.it/howf64r5rgob1.jpg?width=1656&format=pjpg&auto=webp&s=636744fccab7a1c2bafb902bad5dbb647440fff5\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jl4pe/r_agents_an_opensource_framework_for_autonomous/",
          "publishedOn": "2023-09-15T18:36:10.000Z",
          "wordCount": 2682,
          "title": "[R] Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jkk71/image_dataset_management_tools_d/",
          "author": null,
          "description": "Hi all,\n I have about 100K images on my machine and I am looking for a tool that can help me do some QA on it.\n Example features I would love:\n  \nSearch and visualize all images with a prefix \"cls1_\" or \"cls2_\"\n Easily rename file names if they're not named correctly\n \nVisualize all captions associated with each image \n  \nWe can assume they have the same name but with extension \".txt\" or \".captions\"\n Or there's a metadata.json linking between \"img_file\" and \"caption_file\"\n \n \nEasily edit captions in the dashboard\n \n I can also work with some kind of metadata file instead of relying on filename logic if it really helps a certain tool.\n I prefer a locally run, open-source tool. It would be a problem for me to upload this data to any online platform.\n Many thanks in advance for any help or guidance.\n    submitted by    /u/JYP_Scouter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jkk71/image_dataset_management_tools_d/",
          "publishedOn": "2023-09-15T18:12:37.000Z",
          "wordCount": 2689,
          "title": "Image dataset management tools [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jk2s1/d_testing_values_are_different_from_real_world/",
          "author": null,
          "description": "Before training my model im going through multiple steps to collect and process my data. One of these steps to is calculate values from algorithmic and mathematical functions. In my training and testing data the values are around 12-15 decimal places. I then split the data without shuffling. Training, validation and testing averages at 75% accuracy. \n Now my next step I wanted to do a \"real world\" data test where I collect the exact same data as my testing data and predict it using my previously built model but the values inside test_dataset1 are different to test_dataset2 within the last 6-9 decimal places even though the data is going through the exact same code. For example \n Test_dataset1 Value : 1.123456789\n Test_dataset2 Value : 1.123456987\n This messes with my prediction and its making me wonder aswell as standrising my data should I be rounding my float values to say 4-6 decimal places?\n    submitted by    /u/paddockson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jk2s1/d_testing_values_are_different_from_real_world/",
          "publishedOn": "2023-09-15T17:52:54.000Z",
          "wordCount": 2704,
          "title": "[D] Testing values are different from \"Real World\" values",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jjx4m/d_what_is_the_difference_between_the_tpu_found_in/",
          "author": null,
          "description": "What are the key differences between the Tensor Processing Unit (TPU) found in Google Tensor chips and the Neural Engine found in Apple's A and M series chips? Are they the same things?\n Or is the TPU only available for Google's own AI, while the Neural Engine is available to all developers for accelerating AI for all apps, if they decide to?\n Can developers optimize apps for Google Tensor like they can for the Neural Engine?\n If not, how do developers take advantage of machine learning acceleration chips on Google Pixel or Android in general?\n If yes, let's say a developer optimizes their app for the Google TPU, will they need to re-optimize for other chips like Samsung's NPU or Qualcomm AI too? If not, how well do they run? Are they the same fast and efficient?\n    submitted by    /u/GRguy_21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jjx4m/d_what_is_the_difference_between_the_tpu_found_in/",
          "publishedOn": "2023-09-15T17:46:21.000Z",
          "wordCount": 2705,
          "title": "[D] What is the difference between the TPU found in Google Tensor chips vs the Neural Engine found in Apple's A and M series?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jjp5l/p_suggestionsdirection_working_on_image_dehazing/",
          "author": null,
          "description": "Working on Final year project in the field on computer vision: Image Dehazing. I aim at having a novel approch for better dehazing of face haze images.\n Have read papers related to single image dehazing & face SR/Deblur.\n Any thoughts/ suggestions/ leads would be appreciated.\n    submitted by    /u/GahlotB  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jjp5l/p_suggestionsdirection_working_on_image_dehazing/",
          "publishedOn": "2023-09-15T17:37:22.000Z",
          "wordCount": 2598,
          "title": "[P] Suggestions/Direction: Working on Image Dehazing for Face Images.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jibo2/r_traveling_words_a_geometric_interpretation_of/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07315\n Abstract:\n  \nTransformers have significantly advanced the field of natural language processing, but comprehending their internal mechanisms remains a challenge. In this paper, we introduce a novel geometric perspective that elucidates the inner mechanisms of transformer operations. Our primary contribution is illustrating how layer normalization confines the latent features to a hyper-sphere, subsequently enabling attention to mold the semantic representation of words on this surface. This geometric viewpoint seamlessly connects established properties such as iterative refinement and contextual embeddings. We validate our insights by probing a pre-trained 124M parameter GPT-2 model. Our findings reveal clear query-key attention patterns in early layers and build upon prior observations regarding the subject-specific nature of attention heads at deeper layers. Harnessing these geometric insights, we present an intuitive understanding of transformers, depicting them as processes that model the trajectory of word particles along the hyper-sphere.\n  \n​\n https://preview.redd.it/0i302t857gob1.png?width=1864&format=png&auto=webp&s=1da999c014979bdb6c99809d5b38eb5ccfd717d0\n    submitted by    /u/CoolThingsOnTop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jibo2/r_traveling_words_a_geometric_interpretation_of/",
          "publishedOn": "2023-09-15T16:43:10.000Z",
          "wordCount": 2694,
          "title": "[R] Traveling Words: A Geometric Interpretation of Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jfe2w/p_hampel_python_library_with_c_extensions/",
          "author": null,
          "description": "Repo -> https://github.com/MichaelisTrofficus/hampel_filter\n The Python library hampel implements the Hampel Filter, which is generally used to detect anomalies in data with a timeseries structure. It basically consists of a sliding window of a parameterizable size.\n The library was in plain Python before (using pandas for all the sliding operations, median computation etc), but now it has been replaced by a Cython implementation, which speeds up things quite a bit! 😀\n It also provides much more valuable information (thresholds, median absolute deviations, etc.), allowing us to create plots like this one:\n https://preview.redd.it/6j4ubiwgmfob1.png?width=800&format=png&auto=webp&s=bbc56777fce30a464d0bb33ac5126033b3413838\n ​\n    submitted by    /u/Hefty-Consequence443  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jfe2w/p_hampel_python_library_with_c_extensions/",
          "publishedOn": "2023-09-15T14:47:18.000Z",
          "wordCount": 2642,
          "title": "[P] Hampel Python Library with C extensions 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jd9h7/discussion_how_to_generate_post_custom_for_each/",
          "author": null,
          "description": "Hi everybody.\n Currently, I am building a Deep Learning model with the task of automatically generating random posts and tweets. The characteristic is that it must have the personality of the writer, for example the user is the CEO of company A, then the generated post must have the writing style of the CEO or company A, similar to other users.\n Actually, I don't know where to start solving this problem. I intend to use RWKV to do this problem but I'm not sure if it is a good direction or not. Is there any related research or can anyone who has done this problem give me some suggestions?\n    submitted by    /u/unknow_from_vietnam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jd9h7/discussion_how_to_generate_post_custom_for_each/",
          "publishedOn": "2023-09-15T13:20:10.000Z",
          "wordCount": 2663,
          "title": "[Discussion] How to generate post custom for each user ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jc2su/r_uncovering_mesaoptimization_algorithms_in/",
          "author": null,
          "description": "Paper. I am not affiliated with this work or its authors.\n Abstract:\n  \nTransformers have become the dominant model in deep learning, but the reason for their superior performance is poorly understood. Here, we hypothesize that the strong performance of Transformers stems from an architectural bias towards mesa-optimization, a learned process running within the forward pass of a model consisting of the following two steps: (i) the construction of an internal learning objective, and (ii) its corresponding solution found through optimization. To test this hypothesis, we reverse-engineer a series of autoregressive Transformers trained on simple sequence modeling tasks, uncovering underlying gradient-based mesa-optimization algorithms driving the generation of predictions. Moreover, we show that the learned forward-pass optimization algorithm can be immediately repurposed to solve supervised few-shot tasks, suggesting that mesa-optimization might underlie the in-context learning capabilities of large language models. Finally, we propose a novel self-attention layer, the mesa-layer, that explicitly and efficiently solves optimization problems specified in context. We find that this layer can lead to improved performance in synthetic and preliminary language modeling experiments, adding weight to our hypothesis that mesa-optimization is an important operation hidden within the weights of trained Transformers.\n  \nTwitter thread about the paper from one of the paper's authors. Nitter thread, for those who aren't signed into Twitter but want to see the entire Twitter thread.\n Background info: Mesa-Optimization: Explain it like I'm 10 Edition.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jc2su/r_uncovering_mesaoptimization_algorithms_in/",
          "publishedOn": "2023-09-15T12:31:13.000Z",
          "wordCount": 2787,
          "title": "[R] Uncovering mesa-optimization algorithms in Transformers (from Google Research, ETH Zürich, and Google DeepMind)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jbp8q/d_can_somebody_help_check_my_math_to_see_if_im/",
          "author": null,
          "description": "Relevant Paper: 2307.08621.pdf (arxiv.org)\n So the definition of the recurrent representation of the retention mechanism is below\n  \nSn = γSn−1 + K⊺nVn \n Retention(Xn) = QnSn, n = 1, · · · , |x|\n  \nγ is a decay factor, and K, Q, and V have their standard transformer definitions.\n What confuses me is the derivation of Sn. The formula makes it look like a scalar. But if that's the case, are we saying that for a given token, the retention mechanism is just multiplying the Query by a scalar? That's surprising! How is that able to provide enough context?\n Here is some code I wrote with GPT to show my understanding of how it works. Is this correct? I use 3 arbitrary tokens of dimension 3, and then a pick arbitrary K Q and V matrices. I also initialize gamma to 0.5\n import numpy as np # Tokens x1…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jbp8q/d_can_somebody_help_check_my_math_to_see_if_im/",
          "publishedOn": "2023-09-15T12:14:53.000Z",
          "wordCount": 3000,
          "title": "[D] Can somebody help check my math to see if I'm understanding Microsoft's Retentive Network paper correctly? I'm confused how we are enriching the tokens with enough context.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jaqdb/project_correcting_misspelled_words_in_urdu/",
          "author": null,
          "description": "Help required from NLP and Text Researchers !!\n Hello everyone!\n I have Urdu language transcriptions (text) which contain many misspelled words that are not part of the Urdu language.\n I wanted to know do we have any good NLP techniques or methods which can solve this problem for Urdu language? I want to replace these misspelled words with the correct words in Urdu.\n I have already tried Python libraries and methods such as indic-nlp, Levenshtein distance, UrduHack, Word2vec Urdu etc, but they weren't able to solve this problem. Some of the methods require Urdu dictionaries to find the correct word, which I'm also unable to find open-source on internet (please also help in that if possible).\n Will appreciate everyone's help and response to this.\n Thank you! \n    submitted by    /u/a_r182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jaqdb/project_correcting_misspelled_words_in_urdu/",
          "publishedOn": "2023-09-15T11:30:24.000Z",
          "wordCount": 2673,
          "title": "[Project]: Correcting Misspelled Words in Urdu language text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16janap/d_prospective_phd_advisors/",
          "author": null,
          "description": "Hi everyone!\n I am a (soon graduating) MSc student at a top European university and I'd like to apply for a ML PhD in the US this Fall. I've done my research on schools and advisors, but I figured there's no harm in also asking in this subreddit.\n What are some groups/professors that do ML research at US unis in deep learning theory (specifically foundations) and optimization? As an example, I'm talking about topics such as: https://arxiv.org/abs/1902.08129, https://arxiv.org/abs/1711.04735, https://arxiv.org/abs/2306.04637.\n Thank you all! Cheers!\n    submitted by    /u/AlexIsEpic24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16janap/d_prospective_phd_advisors/",
          "publishedOn": "2023-09-15T11:26:14.000Z",
          "wordCount": 2631,
          "title": "[D] Prospective PhD advisors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jamu8/project_correcting_misspelled_words_in_urdu/",
          "author": null,
          "description": "Help required from NLP and Text Researchers !!\n Hello everyone!\n I have Urdu language transcriptions (text) which contain many misspelled words that are not part of the Urdu language.\n I wanted to know do we have any good NLP techniques or methods which can solve this problem for Urdu language? I want to replace these misspelled words with the correct words in Urdu.\n I have already tried Python libraries and methods such as indic-nlp, Levenshtein distance, UrduHack, Word2vec Urdu etc, but they weren't able to solve this problem. Some of the methods require Urdu dictionaries to find the correct word, which I'm also unable to find open-source on internet (please also help in that if possible).\n Will appreciate everyone's help and response to this.\n Thank you! \n    submitted by    /u/a_r182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jamu8/project_correcting_misspelled_words_in_urdu/",
          "publishedOn": "2023-09-15T11:25:37.000Z",
          "wordCount": 2673,
          "title": "[Project]: Correcting Misspelled Words in Urdu language text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16j6cgn/d_ml_research_topics_reasonably_short/",
          "author": null,
          "description": "So I’m starting my masters thesis project in ML ASAP and need a research topic. What areas (if any) are currently hot / feasible to do research in roughly 6 months with fairly limited compute access? \n I’m more interested in theory / research heavy areas rather than applied. And probably happier to dig into some hard math rather than taking on a software engineering type project. \n Any thoughts or general feedback very welcome! Thanks!\n    submitted by    /u/Professional-Pace158  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16j6cgn/d_ml_research_topics_reasonably_short/",
          "publishedOn": "2023-09-15T07:10:13.000Z",
          "wordCount": 2624,
          "title": "[D] ML Research Topics (reasonably short)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16j4xj3/practical_use_cases_for_skew_symmetrical_matrices/",
          "author": null,
          "description": "Just came across this property of matrices that I have never seen before as I am contributing to the NumPy codebase and someone asked for this feature to be added and it got me thinking. It is defined as:\n A skew-symmetric matrix is a square matrix whose transpose equals to its negative. It should satisfy the below condition:\n AT = –A\n Just wondering do these have any applications in ML at all? I never came across this in my math classes so just wondering if the property pops up anywhere else in the field. Maybe in 3D space applications? Or maybe RBG data augmentation? But yeah not 100% sure.\n    submitted by    /u/Ok_Reality2341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16j4xj3/practical_use_cases_for_skew_symmetrical_matrices/",
          "publishedOn": "2023-09-15T05:44:31.000Z",
          "wordCount": 2662,
          "title": "Practical use cases for skew symmetrical matrices in AI/ML? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16j4n5c/d_how_much_should_i_focus_on_dsa/",
          "author": null,
          "description": "I’m an electrical engineering student in college currently, and have been learning about ML for a few months now. I will be starting a ML research paper under my professor from next week. However, my DSA skills are quite sub-par. Should I focus more on ML math and projects, or take sufficient time out for leetcode as well?\n    submitted by    /u/4R1N1493  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16j4n5c/d_how_much_should_i_focus_on_dsa/",
          "publishedOn": "2023-09-15T05:27:37.000Z",
          "wordCount": 2610,
          "title": "[D] How much should I focus on DSA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iy8bj/best_architecture_for_an_autoencoder_for_2d/",
          "author": null,
          "description": "Hi,\n I have a dataset that consists of 2D trajectories and I am aiming to develop an autoencoder architecture to learn a compressed set of features that reasonable represents and can reconstruct the trajectories. \n The trajectories may look something like this as an example. A 2D image as input would seem to require a very sparse representation with high resolution to track the trajectory path. I am hoping there is a better way to input the path without requiring high resolution. \n An alternative might be to use a LSTM structure to input as a sequence, although not sure that solves the resolution issue.\n Do you have any suggestions? I've worked with 1d time series and 2D images just fine but this is a bit different.\n ​\n ​\n https://preview.redd.it/vqz8y3o69bob1.png?width=2020&format=png&auto=webp&s=d8bcc2fe311743c8e78a96055e68f1ad364b48c3\n    submitted by    /u/ZeApelido  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iy8bj/best_architecture_for_an_autoencoder_for_2d/",
          "publishedOn": "2023-09-15T00:05:43.000Z",
          "wordCount": 2679,
          "title": "Best architecture for an autoencoder for 2D trajectory data? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ixsc8/d_besides_something_about_llm_is_there_any_new_or/",
          "author": null,
          "description": "Please provide Arkiv links. If you want to share your thoughts then go for it. By new I mean within the last 6 months.\n    submitted by    /u/I_will_delete_myself  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ixsc8/d_besides_something_about_llm_is_there_any_new_or/",
          "publishedOn": "2023-09-14T23:45:24.000Z",
          "wordCount": 2585,
          "title": "[D] Besides something about LLM, is there any new or interesting research you think is worth reading?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iwhg3/d_good_papers_on_poster_collapse_in_vaes/",
          "author": null,
          "description": "What are some good papers to understand posterior collapse in VAEs?\n    submitted by    /u/randomkolmogorov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iwhg3/d_good_papers_on_poster_collapse_in_vaes/",
          "publishedOn": "2023-09-14T22:47:18.000Z",
          "wordCount": 2563,
          "title": "[D] Good papers on poster collapse in VAEs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iw7ey/p_create_an_object_detector_for_any_game_using/",
          "author": null,
          "description": "Full Video Tutorial: https://www.linkedin.com/posts/moisesdias\\_english-version-below-tutorial-crie-activity-7107686497885011969-ZLVW/ \n Hello everyone! Have you ever thought about how to create an object detection system using YOLO that works with any game? \n If you're interested, I've created a tutorial with all the steps to develop this system. I'll leave a link to the video where I demonstrate the process step by step using the game Diablo 2 as an example. \n I hope you enjoy it, and if you have any suggestions, feel free to send a message or comment here! \n    submitted by    /u/moisesdepaulodias  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iw7ey/p_create_an_object_detector_for_any_game_using/",
          "publishedOn": "2023-09-14T22:35:16.000Z",
          "wordCount": 2637,
          "title": "[P] Create an Object Detector for Any Game Using YOLO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iw48b/p_would_anyone_know_of_any_information_regarding/",
          "author": null,
          "description": "Good Evening, I and some fellow students are taking a SE class and are looking for relevant information regarding esrb ratings and games for a research project. Does anyone know of any data pertaining to relevant esrb info that we can access? We have a few sources and are waiting to hear back from esrb themselves. Would anyone know if they permit web scraping or if there is a csv containing relevant information, or even perhaps an api we could use? Any information would help and thank you all for taking the time to read this. Thanks in advance!\n    submitted by    /u/GOD_LIKE_WOW  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iw48b/p_would_anyone_know_of_any_information_regarding/",
          "publishedOn": "2023-09-14T22:31:45.000Z",
          "wordCount": 2653,
          "title": "[P] Would anyone know of any information regarding esrb ratings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iutyp/p_ways_to_speed_up_llama2_summarization_on/",
          "author": null,
          "description": "I'm currently working on a project to give a quick summary of long articles/conversations.\n I'm running llama-2-7b-chat-hf with 4bit quantization on a g5.2xlarge instance on sagemaker.\n The method I'm using is map_reduce (option 2)from this webpage https://python.langchain.com/docs/use_cases/summarization)\n Of everything I've tried this is the only one that's been able to do decent summaries in a reasonable amount of time. However with really long articles (10,000+ words) it takes ~6 minutes before giving an output.\n I tried running this same thing on a g5.12xlarge instance which has 4 A10G gpus but it hasn't reduced the time by any noticeable amount.\n Is there anything else I could be doing to speed this up?\n    submitted by    /u/Able_Body_9654  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iutyp/p_ways_to_speed_up_llama2_summarization_on/",
          "publishedOn": "2023-09-14T21:40:28.000Z",
          "wordCount": 2664,
          "title": "[P] Ways to speed up llama-2 summarization on sagemaker?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16itt92/d_what_prompt_should_i_use_with_llama2_for/",
          "author": null,
          "description": "so as the question states, i want to use llama2 to generate an answer for the question based on the context (or the article for more precision), no finetuning is needed, just want to predict the answer, but i can't find what's the right prompt i should use to get a well structured answer.\n my dataset contains two columns, one for articles, and the other column is for the question,\n Example:\n context: article talking about world war 2.\n question : based on the text, describe how the ww2 had started, and what were the political effects on Europe?\n    submitted by    /u/kaoutar-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16itt92/d_what_prompt_should_i_use_with_llama2_for/",
          "publishedOn": "2023-09-14T21:01:54.000Z",
          "wordCount": 2655,
          "title": "[D] what prompt should i use with llama2 for context generative question answering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iswh9/p_coqui_releases_xtts_an_openaccess_foundational/",
          "author": null,
          "description": "There's a new open-access foundational audio model in town!\n Standing on the shoulders of TorToiSe TTS - XTTS allows cross-language and multi-lingual speech generation with just 3 lines of code 🐸\n Key facts about the model: 1. Supports 13 languages. 2. Voice cloning with just a 3-second audio clip. 3. Emotion and style transfer by cloning. 4. Cross-language voice cloning.\n Try it out on HF Hub: https://huggingface.co/spaces/coqui/xtts\n    submitted by    /u/vaibhavs10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iswh9/p_coqui_releases_xtts_an_openaccess_foundational/",
          "publishedOn": "2023-09-14T20:26:09.000Z",
          "wordCount": 2617,
          "title": "[P] Coqui releases XTTS an open-access foundational Voice Cloning model!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ioxjm/r_large_language_models_for_compiler_optimization/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07062 \n Abstract:\n  \nWe explore the novel application of Large Language Models to code optimization. We present a 7B-parameter transformer model trained from scratch to optimize LLVM assembly for code size. The model takes as input unoptimized assembly and outputs a list of compiler options to best optimize the program. Crucially, during training, we ask the model to predict the instruction counts before and after optimization, and the optimized code itself. These auxiliary learning tasks significantly improve the optimization performance of the model and improve the model's depth of understanding.\n We evaluate on a large suite of test programs. Our approach achieves a 3.0% improvement in reducing instruction counts over the compiler, outperforming two state-of-the-art baselines that require thousands of compilations. Furthermore, the model shows surprisingly strong code reasoning abilities, generating compilable code 91% of the time and perfectly emulating the output of the compiler 70% of the time. \n  \nhttps://preview.redd.it/f9c7kh7bd9ob1.jpg?width=1530&format=pjpg&auto=webp&s=287fffa714936da9b9a5141b7e01609942416156\n https://preview.redd.it/z4a0ce7bd9ob1.jpg?width=1537&format=pjpg&auto=webp&s=e6275b2b53fa6f431b87940784629b3270c656f9\n https://preview.redd.it/89toie7bd9ob1.jpg?width=750&format=pjpg&auto=webp&s=9a71bdb2eeeff52b2f8bbb3cf2b678debcd4a060\n https://preview.redd.it/0krmqd7bd9ob1.jpg?width=1536&format=pjpg&auto=webp&s=ba3fade0883ee621b185fabc67839db42ea74a53\n https://preview.redd.it/8nz00i7bd9ob1.jpg?width=1198&format=pjpg&auto=webp&s=6ddbddf68311f576fbf3c52a47381316feace8c9\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ioxjm/r_large_language_models_for_compiler_optimization/",
          "publishedOn": "2023-09-14T17:48:05.000Z",
          "wordCount": 2717,
          "title": "[R] Large Language Models for Compiler Optimization - MetaAi 2023 - Autotuner needs 949 CPU-days to achive nearly the same as this approach in 1shot!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16in6cd/d_searching_for_discussion_about_chunking/",
          "author": null,
          "description": "Hi everyone! \n I'm still experiencing with my own implementation of rag, and I deployed my custom chunking function (honestly don't like the methods on LangChain) . \n Anyway, I'm searching for alternative methods, algoritms (NLP or not) and models... There are lots of info and different implementation on RAG, but as I can see noone put much effort to augment chunking quality. \n Also, there are other approach than this one I'm currently using? bi-encoder (instructor) - > cross-encoder (reranking) - > LLM \n Can someone share some resources, repo, lib or existing implementation of different chunking methods? (or simply discuss here some idea, though or approach) \n Thanks in advance for you time!!\n    submitted by    /u/Distinct-Target7503  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16in6cd/d_searching_for_discussion_about_chunking/",
          "publishedOn": "2023-09-14T16:39:24.000Z",
          "wordCount": 2663,
          "title": "[D] Searching for discussion about chunking algorithms and strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iljbp/d_gradient_descent_in_regularized_least_squares/",
          "author": null,
          "description": "The problem is obtained from Chapter 3 in Wright, Stephen J and Benjamin Recht (2022). Optimization for data analysis.\n Cambridge University Press\n I am solving the problem I attach and I have a doubt in section (f). I have solved all the sections (a)-(e).\n In section (e) I have obtained that I need\n $$\n k \\geq \\frac{\\lambda_{\\text{max}}\\left(\\frac{2}{N} A^TA + 2\\mu I\\right)}{\\lambda_{\\text{min}}\\left(\\frac{2}{N} A^TA + 2\\mu I\\right)}log((f(x^0)-f(x_\\mu)/\\epsilon).\n $$\n However in section (f) asks for a tight upper bound but I only can think about the following bound:\n $f(\\hat{x}) \\leq f_\\mu(x_\\mu) + ||\\hat{x}||^2+ \\epsilon$,\n which is very simple.\n Do you think that I can obtain the result in (e) to obtain another bond, or what would you do?\n    submitted by    /u/ItsGauss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iljbp/d_gradient_descent_in_regularized_least_squares/",
          "publishedOn": "2023-09-14T15:34:16.000Z",
          "wordCount": 2666,
          "title": "[D] Gradient descent in regularized least squares",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ilhcd/p_guide_implementing_imagenet_classification/",
          "author": null,
          "description": "Need help on how to get started with implementing a research paper. I'm implementing the Imagenet classification task paper for my final year undergrad mini-project. Any advice is appreciated on how to get started? I have mid-level machine learning knowledge and am ready to pick the required concepts on the go. Please help. Thank you :)\n Link: https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n    submitted by    /u/DrBeans0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ilhcd/p_guide_implementing_imagenet_classification/",
          "publishedOn": "2023-09-14T15:31:59.000Z",
          "wordCount": 2611,
          "title": "[P] Guide: Implementing ImageNet classification using Deep CNNs Paper.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16il8ef/d_use_llm_to_analyse_and_port_software_written_in/",
          "author": null,
          "description": "Hi,\n I'm trying to figure out what is the best way to use LLMs to analyse a very old software entirely written in C.\n I've tried to to some basic prompts with ChatGPT and it seems to recognise the language.\n The situation is that I've many .c files with thousands of lines and with a lot of redundant code.\n Moreover, since there are a lot of data structure with variables names not easily understandable, I need to provide some context to allow the model to trying to understand what the code does.\n My worry is that providing all the needed info + the file itself (even considering 1 file at a time) I could consume all the model context and therefore not leave room for generating anything of value.\n Has anyone had the opportunity to face similar problems? Ideas?\n Cheers\n Alexio\n    submitted by    /u/Alexioc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16il8ef/d_use_llm_to_analyse_and_port_software_written_in/",
          "publishedOn": "2023-09-14T15:22:08.000Z",
          "wordCount": 2699,
          "title": "[D] Use LLM to analyse and port software written in C (very long files)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ikvt8/n_mitibm_watson_ai_lab_releases_molm_suite_with/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2306.04640\n GitHub: https://github.com/ibm/moduleformer (under Apache 2.0)\n Twitter thread: https://twitter.com/Yikang_Shen/status/1702041129267388678\n Abstract:\n  \nLarge Language Models (LLMs) have achieved remarkable results. However, existing models are expensive to train and deploy, and it is also difficult to expand their knowledge beyond pre-training data without forgetting previous knowledge. This paper proposes a new neural network architecture, ModuleFormer, that leverages modularity to improve the efficiency and flexibility of large language models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE). Unlike the previous SMoE-based modular language model, which requires domain-labeled data to learn domain-specific experts, ModuleFormer can i…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ikvt8/n_mitibm_watson_ai_lab_releases_molm_suite_with/",
          "publishedOn": "2023-09-14T15:07:54.000Z",
          "wordCount": 2887,
          "title": "[N] MIT-IBM Watson AI Lab releases MoLM suite with three small sparse MoE models, the largest of which (8B params with 700M experts) performs on par with Pythia 2.8B while its throughput is comparable to Pythia 1.4B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ijc89/assigning_inbalanced_labels_to_other_class_in/",
          "author": null,
          "description": "Hey there,\n I wasn't doing any ml in some time and forgot basics. I was thinking that you may help me. So I trained svc model on small dataset (around 1400 unical records). I have 13 classes, which are badly distributed in the training set and inbalanced. 3 classes took around 80% of all. What the business wants is keep the 3 classes and categorize the rest as \"Other\" class. In the future they may be able to generate more training data for the remaining labels.\n How should I do it? I know I can assign everytning to \"Other\" class, before training with simple if then formula, but dont know if this is the right approach. Any sugestions? I know this may be some case of 1 vs all case, but don't know which exactly.\n Thanks in advance for any help.\n    submitted by    /u/th00masml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ijc89/assigning_inbalanced_labels_to_other_class_in/",
          "publishedOn": "2023-09-14T14:03:28.000Z",
          "wordCount": 2694,
          "title": "Assigning inbalanced labels to \"Other\" class in scikitlearn [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ij18f/d_the_ml_papers_that_rocked_our_world_20202023/",
          "author": null,
          "description": "Hey everyone! 👋\n I’ve been on a bit of a deep-dive lately, trying to catch up on all the awesome stuff that’s been happening in the ML space. It got me wondering, from 2020 to 2023, what have been the absolute must-read papers that shook the foundations and got everyone talking?\n Whether it’s something that reinvented the wheel in your specific niche or just made waves industry-wide, I wanna hear about it!\n I’m curious to see how different the responses will be, and hey, this might even become a go-to list for anyone looking to get the lowdown on the hottest trends and discoveries of the past few years.\n Can’t wait to hear your thoughts!\n tl;dr\n I decided to aggregate your best suggestions into categories for anyone interested in reading them without searching through the whole comment se…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ij18f/d_the_ml_papers_that_rocked_our_world_20202023/",
          "publishedOn": "2023-09-14T13:50:27.000Z",
          "wordCount": 2950,
          "title": "[D] The ML Papers That Rocked Our World (2020-2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ih82w/p_llama2_inference_in_a_single_file_of_pure_mojo/",
          "author": null,
          "description": "Hi everyone!\n I was really excited that Mojo became publicly available and thinking which project can I implement to learn Mojo concepts. Since I have already ported llama2.c to pure Python, I decided why not try to port llama2.py to Mojo now.. And here is what I got\n First round of llama2.c vs llama2.🔥 battle. Mojo demonstrated 20% better performance than C in a single threaded execution of llama2 inference and 250x times better performance than Python\n https://i.redd.it/0gcwwfc2r7ob1.gif\n For reference Mojo is using SIMD vectorization, that's why it's performing great for matmul operations. In the other hand, it turned out that gcc also aggressively optimizes all for loops it can find, so I suggest this benchmark is pretty fair.\n ​\n Mojo natively supports SIMD vectorizations out of the box\n gcc aggressively vectorizing loops\n ​\n After that I decided to compare both solutions in multi-threaded (parallelized) mode, and now `llama2.c` strike back with help of OMP demonstrating 20% better performance than Mojo\n ​\n https://i.redd.it/gwymffods7ob1.gif\n I hope this post will be useful for all Machine Learning engineers/enthusiasts/students out there, ensuring we're up-to-date with Modular/Mojo's game-changing AI tech developments.\n Stay informed and ahead of the curve!\n Links\n llama2.🔥: https://github.com/tairov/llama2.mojo\n llama2.python: https://github.com/tairov/llama2.py\n llama2.c: https://github.com/karpathy/llama2.c\n Modular_AI repost in Twitter: https://twitter.com/tairov/status/1701345271752343900\n feel the magic on HF: https://huggingface.co/spaces/radames/Gradio-llama2.mojo\n    submitted by    /u/Albatross9855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ih82w/p_llama2_inference_in_a_single_file_of_pure_mojo/",
          "publishedOn": "2023-09-14T12:32:42.000Z",
          "wordCount": 2760,
          "title": "[P] Llama2 inference in a single file of pure Mojo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16igzy7/d_training_an_llm_model_aws_p32xlarge_ec2/",
          "author": null,
          "description": "Hello everyone,\n I'm currently at a crossroads with a decision that I believe many in this community might have faced or will face at some point: Should I use cloud-based GPU instances like AWS's p3.2xlarge EC2 (with Tesla V100) or invest in building a high-performance rig at home with multiple RTX 4090s for training a large language model?\n Context: I run a startup and we're currently fine-tuning an open source LLM, and the computational demands are of course high. We want to make an informed choice between using AWS's offerings or setting up a high-performance system at home to start.\n Cloud Option: AWS p3.2xlarge EC2\n  \nCost: Approximately $3.06 per hour.\n Specifications: One Tesla V100 GPU, 8 vCPUs, 61 GiB RAM.\n Pros: Scalability, reliability, specialized software optimizations.\n Cons: Recurring costs, potential limitations on customization.\n  \nHome Rig Option: Multiple RTX 4090s\n  \nCost: Around $1,600 for each 4090, but I'd own them.\n Specifications: Even higher TFLOPs than a V100, and memory isn't a constraint (24GB per card).\n Pros: One-time investment, flexibility, potentially higher raw computational power.\n Cons: Need to handle cooling, power, and system integration myself\n  \nI'd love to hear your thoughts, experiences, and recommendations. Here are some specific questions:\n  \nPerformance: How many RTX 4090s would roughly equal the computational power of an AWS p3.2xlarge instance for ML tasks?\n Cost-Effectiveness: Given that we're a startup with limited resources, does it make more financial sense to invest upfront in hardware?\n Reliability and Maintenance: For those who have run multi-GPU setups at home, how reliable are they, and what maintenance work is required?\n Other Considerations: Are there factors I haven't considered that you think are critical?\n  \nThank you in advance for sharing your insights!\n    submitted by    /u/devolvedai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16igzy7/d_training_an_llm_model_aws_p32xlarge_ec2/",
          "publishedOn": "2023-09-14T12:22:30.000Z",
          "wordCount": 2838,
          "title": "[D] Training an LLM Model: AWS p3.2xlarge EC2 instance vs. Multiple RTX 4090s at Home?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ifl84/r_scaling_dataconstrained_language_models_hugging/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2305.16264\n GitHub: https://github.com/huggingface/datablations\n License:\n  \nAll models & code are licensed under Apache 2.0. Filtered datasets are released with the same license as the datasets they stem from.\n  \nAbstract:\n  \nThe current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at this https URL.\n  \n​\n https://preview.redd.it/ahzyonnqe7ob1.png?width=1015&format=png&auto=webp&s=0e0cb4051e390ea23440cd61bfc0bbf5fce83bb7\n https://preview.redd.it/l6a81onqe7ob1.png?width=1014&format=png&auto=webp&s=a36b74cbb510a1f753ef1b891531bb36ab643246\n https://preview.redd.it/yyu8h0oqe7ob1.png?width=1001&format=png&auto=webp&s=047cb2bb1932c6215cea0c30e22fd9bbe60391a8\n https://preview.redd.it/xskcytnqe7ob1.png?width=1007&format=png&auto=webp&s=4090e92dd9eacb377840327bb7d0ae69ff752b52\n    submitted by    /u/InterviewIntrepid889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ifl84/r_scaling_dataconstrained_language_models_hugging/",
          "publishedOn": "2023-09-14T11:11:44.000Z",
          "wordCount": 2765,
          "title": "[R] Scaling Data-Constrained Language Models - Hugging Face et al. 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ifgyw/d_gradio_on_the_same_server_but_different_ports/",
          "author": null,
          "description": "On my team they are using Gradio for LLM applications, etc. When running multiple instances of Gradio applications on the same server, but on different ports, opening a new session is causing an error and closing the previous session, \"error\" is written in the chat. The logs I found were like \"Invalid HTTP request received\" and \"max retries exceeded\". For me, Gradio is supposed to work as a demonstration and not as a scalable product, but they are using it that way and I thought that the problem could be precisely that. But if not, does anyone have any idea what could be going on?\n No meu time estão utilizando gradio para aplicações de LLMs, etc. Ao executar múltiplas instâncias de aplicações Gradio no mesmo servidor, mas em portas diferentes, a abertura de uma nova sessão está causando erro e encerrando a sessão anterior, fica \"erro\" escrito no chat. Os logs que encontrei eram como \"Invalid HTTP request received\" e \"max retries exceeded\". Para mim, o Gradio é pra funcionar como demonstração e não em forma de produto escalável, mas estão utilizando assim e pensei que o problema poderia ser justamente isso. Mas caso não, alguém tem alguma ideia do que pode estar acontecendo?\n    submitted by    /u/Magic_squirrel_hat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ifgyw/d_gradio_on_the_same_server_but_different_ports/",
          "publishedOn": "2023-09-14T11:05:06.000Z",
          "wordCount": 2757,
          "title": "[D] Gradio on the same server but different ports",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iecpt/r_compilation_of_nonopen_source_ai_models/",
          "author": null,
          "description": "Hi, does anyone have a compiled list of non-open source AI models that can be used for MVP building? \n    submitted by    /u/Compound_Group  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iecpt/r_compilation_of_nonopen_source_ai_models/",
          "publishedOn": "2023-09-14T10:01:40.000Z",
          "wordCount": 2570,
          "title": "[R] Compilation of non-open source AI models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i691d/d_communicativecollaborative_agents_hybrids/",
          "author": null,
          "description": "I had a Claude based LLM analyze the strengths and weaknesses of the MetaGPT, ChatDev, AoT, and brain inspired algorithms papers, seeking ways to combine the strengths of two or more of the methods. \"Here are some specific examples of how the methods in the Algorithm of Thoughts (AoT), brain-inspired algorithms, MetaGPT, and ChatDev papers could be combined to improve multi-agent systems:\n  \nMetaGPT could incorporate longer, more elaborate algorithmic examples from AoT into its prompts to guide the LLM's reasoning process. For example, in solving math word problems, the prompt could provide a 4-5 step worked example walking through unpacking the problem statement, setting up equations, solving, and checking the solution. This mirrors AoT's more extensive algorithm narratives.\n \nChatDev's a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i691d/d_communicativecollaborative_agents_hybrids/",
          "publishedOn": "2023-09-14T02:23:53.000Z",
          "wordCount": 3151,
          "title": "[D] Communicative/Collaborative Agents hybrids",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i1ewr/d_opengl_library_error/",
          "author": null,
          "description": "Has anyone ever encountered this error while working with the OpenGL library?\n raise ImportError(\"Unable to load OpenGL library\", *err.args) ImportError: ('Unable to load OpenGL library', \"Could not find module 'OSMesa' (or one of its dependencies)\n I have done pip install opengl and pyopengl, but it doesn't seem to solve the problem.\n Specifically, I am trying to run this code: https://github.com/brjathu/LART\n    submitted by    /u/BigDreamx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i1ewr/d_opengl_library_error/",
          "publishedOn": "2023-09-13T22:46:23.000Z",
          "wordCount": 2608,
          "title": "[D] OpenGL Library Error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i0llq/d_wandb_remote_agent_source_code_managing/",
          "author": null,
          "description": "Hi all, \n I'm new to machine learning and have decided to use a combination of Stable baselines3 and Wandb. I'm at the point where I'm running sweeps using Wandb and want to utilize another PC I have laying around to run agents on.\n What is the best way to get my python code for the agent to run onto the spare PC? I know I can manually load copy the code over, but I'm looking for a more efficient method that will maintain any changes made to the source code. Maybe packaging up the python code within the sweep and having the agent download and execute it? I'm not all too familiar with possibilities and limits of trying to achieve this so any and all input is appreciated. Thanks!\n    submitted by    /u/chip_fork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i0llq/d_wandb_remote_agent_source_code_managing/",
          "publishedOn": "2023-09-13T22:13:25.000Z",
          "wordCount": 2680,
          "title": "[D] Wandb remote agent source code managing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i08hr/d_mean_scores_or_appending_all_the_predictions_in/",
          "author": null,
          "description": "I have this question that I cannot seem to settle in my head. All papers that I read, report the average (std) performance results across each folds when they report F1, Precision, etc.. Somebody that I highly trust in ML (somebody with a PhD in the field) was reporting the results after saving all the predicted labels (y_pred) and actual labels (y_true) to a list and compute the F1 score one time with the pooled predictions.\n I now am working on a dataset (binary classification) and trying to validate my model using leave-one-subject-out CV (Some people in my dataset have more lines than others). When I take the average of all iterations I get poor results (F1 score= 0.5), but if I pool all the predictions and compute the F1 score at the end, I achieve decent performance (F1 score =0.7). So, in my project, it is in my best interest to use the second approach, and somebody that I trust tells me that it is okay to do this approach. But I cannot seem to find a paper that says that this approach is acceptable or good. What do you guys think and do you have any suggestions?\n    submitted by    /u/enthusiastic31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i08hr/d_mean_scores_or_appending_all_the_predictions_in/",
          "publishedOn": "2023-09-13T21:59:37.000Z",
          "wordCount": 2757,
          "title": "[D] Mean scores or appending all the predictions in cross-validation for model performance evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hz47b/p_looking_for_efficient_encoding_methods_for_java/",
          "author": null,
          "description": "I'm working on a project that involves analyzing large samples of Java codes. My end goal is to perform classification based on these codes. For this, I've been trying to efficiently encode the full names of the methods (in the package.class.methodname format) in the Java code.\n Currently, I am experimenting with doc2vec. I'm treating the components of each method's full name (separated by dots) as individual documents. This allows me to produce vectors for each method name, and I evaluate the results by computing the cosine similarity between pairs of similar method names. The results were not good so far.\n Before moving to doc2vec, I tried using an LLM which gave me good results. However, the inference time was far too long, especially given the scale at which I'm working. I also considered using a Bag of Words model, but quickly realized it wouldn't be effective. Many of the method names in my samples are obfuscated, making this approach unsuitable.\n The issue I'm facing is that using the direct method names as features is not generalizing well for classification. A slight change in a method's name results in losing that particular feature, making my model fragile.\n What are some optimal encoding methods for small sentences (around 5-6 words) like these method names, that can scale well? \n Also, Are there any specialized encoding techniques tailored for software code that I could use for this task?\n Any suggestions or insights would be really helpful. Thank you!\n    submitted by    /u/Practical_Mango_8720  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hz47b/p_looking_for_efficient_encoding_methods_for_java/",
          "publishedOn": "2023-09-13T21:17:02.000Z",
          "wordCount": 2802,
          "title": "[P] Looking for Efficient Encoding Methods for Java Method Names for Downstream Classification Task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hx11m/r_efficient_memory_management_for_large_language/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.06180 \n Github: https://github.com/vllm-project/vllm \n Blog: https://vllm.ai/ \n Abstract:\n  \nHigh throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage. Our evaluations show that vLLM improves the throughput of popular LLMs by 2-4× with the same level of latency compared to the state-of-the-art systems, such as FasterTransformer and Orca. The improvement is more pronounced with longer sequences, larger models, and more complex decoding algorithms. \n  \nhttps://preview.redd.it/x8w8ckejv2ob1.jpg?width=667&format=pjpg&auto=webp&s=28fae778b67ac28fc72d084f071b12c92cb5ea07\n https://preview.redd.it/ctlrqpejv2ob1.jpg?width=1468&format=pjpg&auto=webp&s=31755d169673ee5d30efa3f05bd6cb10813b328d\n https://preview.redd.it/z5r7knejv2ob1.jpg?width=1504&format=pjpg&auto=webp&s=9ceb5370aa5a7cc0688fe9a3771a0328262c3a01\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hx11m/r_efficient_memory_management_for_large_language/",
          "publishedOn": "2023-09-13T19:55:42.000Z",
          "wordCount": 2738,
          "title": "[R] Efficient Memory Management for Large Language Model Serving with PagedAttention - UC Berkeley et al 2023 - 2-4x higher throughput than HuggingFace Transformers without requiring any model architecture changes!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hx0pe/p_llm_for_viral_tweet_generation/",
          "author": null,
          "description": "Problem: Given a database of the most viral tweets (of a certain shared category), I am hoping to use LLM's to generate further viral tweets. \n Currently I am seeing this as a synthetic data generation problem: two approaches I am thinking of is 1) grounding (using viral examples to guide the prompt) and 2) filtering (finetuning an LLM to predict virality and filtering for the most viral generations) \n I want to ensure that the output retains the \"viral\" structure/style and is diverse/new (i.e no copies).\n Any general directions or references are appreciated\n    submitted by    /u/greatSWE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hx0pe/p_llm_for_viral_tweet_generation/",
          "publishedOn": "2023-09-13T19:55:18.000Z",
          "wordCount": 2641,
          "title": "[P] LLM for viral tweet generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hwgjv/d_1is_msc_math_enough_to_secure_jobs_in_rd_sector/",
          "author": null,
          "description": "I'm currently doing Integrated MSc in Mathematics (in India) and until now I've done a remote research intern in a French university and I'll do a research intern at a French research laboratory (INRIA-LORIA) next year, I want a job (in India) at the R&D sector (Data Scientist or ML Engineering anything would do) Idk if research interns are as valuable as Industry internships when it comes to R&D? Basically after my masters, I'll probably have only these two internships to show as a work experience, Probably won't be able to get an internship in an IT company unless i opt for remote work (which is also not guaranteed atm).\n Mu question, generally is Msc + 2 research internships + 1or 2 publications good enough to secure a decent job in R&D?\n    submitted by    /u/Emotional-Zebra5359  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hwgjv/d_1is_msc_math_enough_to_secure_jobs_in_rd_sector/",
          "publishedOn": "2023-09-13T19:33:53.000Z",
          "wordCount": 2689,
          "title": "[D] 1is Msc Math enough to secure jobs in R&D sector for AI/ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ht4zl/can_i_work_later_as_an_ml_engineer_d/",
          "author": null,
          "description": "Hello!!\n I have a BSc in Mathematics and currently I'm going to start a MSc in FinTech ( it has 3 courses out of 9 that have to do with ML, NN and many more ).\n Since I am really fascinated about programming ( didn't like it when I was at Maths department because of teachers and I am starting learning on my own through courses and we will have many programming languages in my masters degree ex. R,Python, SQL and others) and I would start as a data scientist at the beginning, could I through years of experience later ( ideally 1-2 years later, provided that I have a solid and good programming skills and projects) become a ML engineer? ( Now of course I can't become one because I know that it is difficult since I am competing with people that have CS degrees).\n    submitted by    /u/math-is-cool-62  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ht4zl/can_i_work_later_as_an_ml_engineer_d/",
          "publishedOn": "2023-09-13T17:27:15.000Z",
          "wordCount": 2699,
          "title": "Can I work later as an ML engineer? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hsobt/p_seeking_technical_cofounder_private_equity_saas/",
          "author": null,
          "description": "Hi there!\n I bring 2 years of experience from a European investment fund and a solid idea for a B2B SaaS solution targeting private equity investment funds. \n This market is notoriously challenging to penetrate without insider knowledge. The timing couldn't be better. Similar kind of software is currently sold €20k per user by a semi-monopolistic boomer company that is ready to be disrupted.\n Offer:\n - Equity shared equally.\n - Ready to quit my job and go full-time on it, if I find the right co-founder.\n Ideal Partner:\n Seeking someone proficient in SQL for handling large datasets and able to integrate OpenAI's API within such datasets (technical AI skills required). While I'm based in Berlin and prefer a European co-founder, it's not mandatory, but meeting in person is a must before we commit.\n Don't be afraid to DM me if intrigued! Together, we can make it happen. Let's revolutionize the sector!\n    submitted by    /u/Sudden_Possible489  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hsobt/p_seeking_technical_cofounder_private_equity_saas/",
          "publishedOn": "2023-09-13T17:09:37.000Z",
          "wordCount": 2702,
          "title": "\"[P]\" Seeking technical Co-Founder: Private Equity SaaS Startup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hsntv/books_for_machine_learning_d/",
          "author": null,
          "description": "İ am lookong for the pdfs about machine learning, maths for ML, ml projects. İs there any sites i can find pdf like that?\n    submitted by    /u/Necessary-Car-5080  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hsntv/books_for_machine_learning_d/",
          "publishedOn": "2023-09-13T17:09:05.000Z",
          "wordCount": 2573,
          "title": "Books for machine learning. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hqzxy/d_tensorflow_dropped_support_for_windows/",
          "author": null,
          "description": "Hey,\n I've been using TF pretty much my whole deep learning career starting in 2017. I've also used it on Windows the entire time. This was never a major issue.\n Now when I tried (somewhat belatedly) upgrading from 2.10 to 2.13, I see the GPU isnt being utilized and upon further digging see that they dropped Windows GPU support after 2.10:\n \"Caution: TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2, or install tensorflow or tensorflow-cpu and, optionally, try the TensorFlow-DirectML-Plugin\"\n This is really upsetting! Most of the ML developers I know actually use Windows machines since we develop locally and only switch to Linux for deployment.\n I know WSL is an option, but it (1) can only use 50% RAM (2) doesnt use the native file system.\n I feel very betrayed. After sticking with, and even advocating for Tensorflow when everyone was (and still is) switching to PyTorch, TF dropped me! This is probably the final nail in the coffin for me. I will be switching to PyTorch as soon as I can :-(\n -Disgruntled user\n    submitted by    /u/rsandler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hqzxy/d_tensorflow_dropped_support_for_windows/",
          "publishedOn": "2023-09-13T16:05:22.000Z",
          "wordCount": 2743,
          "title": "[D] Tensorflow Dropped Support for Windows :-(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hpvow/r_research_participants_required_age_perception/",
          "author": null,
          "description": "https://research.sc/participant/login/dynamic/A1D66883-6E8F-409B-8EF9-AC989A76C7E9\n Psychology researchers at Swansea University are carrying out an original study to see whether artificial intelligence is able to generate infant faces between the ages of 0 and 7 years. AI generated pictures will be presented alongside real faces from an existing face database, with a sliding scale underneath that you will use to roughly estimate the age of the child’s face.\n The experiment should only take between 15 and 20 minutes\n Thank you for your time.\n    submitted by    /u/Logipsychlical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hpvow/r_research_participants_required_age_perception/",
          "publishedOn": "2023-09-13T15:22:30.000Z",
          "wordCount": 2648,
          "title": "[R] --Research Participants Required-- Age perception of AI generated infant faces compared to real infant faces. (Suitable for everyone) (Available for Laptop/PC and Tablet devices only)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hpn7m/d_will_be_presenting_a_talk_on_data_preprocessing/",
          "author": null,
          "description": "So I'll be presenting a talk on Data pre-processing in deep learning in my city's Keras Community Day, and I am still thinking about all the content I want to present there.\n What I want from this session is to present different ways of preprocessing the data for a deep learning model. I want to show different types of implementations, how those affect the final trained model, when to use which type of data preprocessing and things similar to this. It would be great if you can suggest me some topic, notebooks or datasets for the same. All the notebooks that show good implementation and affect of data preprocessing are absolutely welcome.\n Also, as this is **Keras** Community Day, I'll have to include more about data preprocessing using Keras and less about other libraries. \n Also, if you could help me with this: I am confused between showing preprocessing using layers or doing the preprocessing without layers. I know this sounds vague, but if you have any idea about this, let me know.\n Thank you for reading!\n    submitted by    /u/inclinedadarsh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hpn7m/d_will_be_presenting_a_talk_on_data_preprocessing/",
          "publishedOn": "2023-09-13T15:13:10.000Z",
          "wordCount": 2751,
          "title": "[D] Will be presenting a talk on Data Pre-processing in Deep Learning - what would be the topics, notebooks or datasets would you include if you would be giving such talk?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hp7fn/d_need_help_selecting_msc_courses/",
          "author": null,
          "description": "I'm currently in my first year of MSc. in Engineering Mathematics and Computational Science. First Study Period (Currently) I have nonlinear optimization and High-performance computing.\n The track I want to choose is a mix between Machine Learning and Big Data. I can select 2 courses for Study Period 2. Here are the potential courses to select from:\n  \nGame Theory and Rationality\n Large-Scale Optimization\n Advanced Probabilistic machine learning\n Basic Stochastic Processes\n Options and Mathematics (Options trading)\n Foundations of Probability Theory\n  \n​\n I need to select 4 potential courses and rank them from high preference to low preference. In case I don't get one of them, the other will be preferred. Please Machine Learning Reddit Gods, Help me.\n    submitted by    /u/AdMaster9439  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hp7fn/d_need_help_selecting_msc_courses/",
          "publishedOn": "2023-09-13T14:56:40.000Z",
          "wordCount": 2665,
          "title": "[D] Need help Selecting MSc. Courses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hnyn5/d_we_built_beam_an_ultrafast_serverless_gpu/",
          "author": null,
          "description": "Hi r/MachineLearning,\n TL;DR: Run AI apps on pay-per-second cloud GPUs that hot reload with your code changes.\n Documentation: https://docs.beam.cloud\n I’m Eli, and my co-founder and I built Beam to run workloads on serverless cloud GPUs with hot reloading, autoscaling, and (of course) fast cold start. You don’t need Docker or AWS to use it, and everyone who signs up gets 10 hours of free GPU credit to try it out.\n Here a few examples of things you can run on Beam:\n  \nFine-tune a LLaMA LLM\n Transcribe videos with Whisper\n Train a custom stable diffusion model\n  \nBeam is built for a fast developer experience. We’ve felt that using Docker and AWS directly is too slow for iterative development. You’ll often find yourself making changes to your code and waiting 10 minutes for a new image to bu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hnyn5/d_we_built_beam_an_ultrafast_serverless_gpu/",
          "publishedOn": "2023-09-13T14:06:50.000Z",
          "wordCount": 2918,
          "title": "[D] We built Beam: An ultrafast serverless GPU runtime",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hng02/d_mlflow_plugin_manager_early_days_looking_for/",
          "author": null,
          "description": "Hey r/machinelearning!\n I'm thrilled and anxious to share an early version of the MLflow Plugin Manager. It's designed to simplify your mlflow installation, allowing you to install, update, and uninstall MLflow plugins directly from the web interface. Think of it as the \"wbond's package manager for sublime\", but tailored for MLflow!\n 📽️\n https://i.redd.it/9gj8vqcz01ob1.gif\n ​\n Yes, it's in its infant stages and doesn't boast of a fancy UI yet, but I'm eager to get your feedback!\n 🔍 What are your first impressions? Is this a good idea?\n 💡 Any features you'd love to see?\n 🌐 Ideas on promoting or expanding its reach?\n I built this to bring a bit more ease to our community. Can't wait to hear your thoughts and where we can take this next!\n Repo: https://github.com/thijsdezoete/mlflow-plugin-manager/\n    submitted by    /u/jessepnk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hng02/d_mlflow_plugin_manager_early_days_looking_for/",
          "publishedOn": "2023-09-13T13:44:38.000Z",
          "wordCount": 2684,
          "title": "[D] mlflow plugin manager - early days / looking for feedback and alpha users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hmwcc/discussion_non_deterministic_behaviour_in_llms/",
          "author": null,
          "description": "Hi all,\n Someone asked me today \"why are LLMs still non deterministic in their output when temperature is set to 0. Assume fixed model between runs on the same machine\" \n I was like WTF are you saying - the randomness in LLM comes from temperature - chat gpt etc.. might have other randomness in the process but we don't have exact info on this. What I know is that in a standard transformers architecture, temperature is the only parameter that can enduce non deterministic behaviour at inference time. \n He was convinced that there was more to it \"i spoke about this to other LLM experts and they also are not sure\" \n I'm like wtf - I start looking up online and do find some people who claim that temperature is not the only thing that influences stochasticity during inference, but I can't find an answer as to what it is exactly. \n Anyone has a clue of what I am missing here? \n Thanks!\n    submitted by    /u/WagnerianJLC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hmwcc/discussion_non_deterministic_behaviour_in_llms/",
          "publishedOn": "2023-09-13T13:21:59.000Z",
          "wordCount": 2717,
          "title": "[Discussion] Non deterministic behaviour in LLMs when temperature set to 0?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hleuv/p_will_tsetlin_machines_reach_stateoftheart/",
          "author": null,
          "description": "​\n A composite of specialized Tsetlin machines that enables plug-and-play collaboration.\n I have a love-and-hate relationship with CIFAR-10/100. I love the datasets for the challenge. On the other hand, they are two datasets where Tsetlin machines have struggled with getting state-of-the-art performance. (The Tsetlin machine is a low-energy logic-based alternative to deep learning that has done well on MNIST, Fashion-MNIST, CIFAR-2, and various NLP tasks.)\n I have been working for some time now on figuring out a solution, and this summer, I finally had a breakthrough: a new architecture that allows multiple Tsetlin machines to collaborate in a plug-and-play manner, forming a Tsetlin machine composite. The collaboration relies on a Tsetlin machine's ability to specialize during learning and…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hleuv/p_will_tsetlin_machines_reach_stateoftheart/",
          "publishedOn": "2023-09-13T12:13:11.000Z",
          "wordCount": 2909,
          "title": "[P] Will Tsetlin machines reach state-of-the-art accuracy on CIFAR-10/CIFAR-100 anytime soon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hl9wo/p_tutorial_create_an_object_detector_for_any_game/",
          "author": null,
          "description": "Hello everyone! Have you ever thought about how to create an object detection system using YOLO that works with any game?\n If you're interested, I've created a tutorial with all the steps to develop this system. I'll leave a link to the video where I demonstrate the process step by step using the game Diablo 2 as an example.\n I hope you enjoy it, and if you have any suggestions, feel free to send a message or comment here! \n link to the tutorial: https://www.linkedin.com/posts/moisesdias_english-version-below-tutorial-crie-activity-7107686497885011969-ZLVW/\n    submitted by    /u/moisesdepaulodias  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hl9wo/p_tutorial_create_an_object_detector_for_any_game/",
          "publishedOn": "2023-09-13T12:06:35.000Z",
          "wordCount": 2640,
          "title": "[P] Tutorial - Create an Object Detector for Any Game Using YOLO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hjrx8/r_adversarial_reinforcement_learning/",
          "author": null,
          "description": "A curated reading list for the adversarial perspective in deep reinforcement learning.\n https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning\n    submitted by    /u/ml_dnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hjrx8/r_adversarial_reinforcement_learning/",
          "publishedOn": "2023-09-13T10:48:18.000Z",
          "wordCount": 2561,
          "title": "[R] Adversarial Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hih2w/p_the_xor_trick/",
          "author": null,
          "description": "Can a single layer neural network solve the XOR problem?\n Most answers say no, but with this one weird trick the answer is yes! And we don't even need a bias! The trick is to multiply the outputs of a single (2,2) linear layer. Here is how:\n class XorSolver(nn.Module): def __init__(self, *args, **kwargs) -> None: super().__init__(*args, **kwargs) self.layer = nn.Linear(2, 2, bias=False) # we don't even need a bias! def forward(self, x: torch.Tensor) -> torch.Tensor: z = self.layer.forward(x) y = z[:, 0] * z[:, 1] return y \n This is the loss and model output after 5000 epochs:\n loss: 6.516383166399464e-08 Input: [[0. 0.] [0. 1.] [1. 0.] [1. 1.]] Model output: [0. 1. 1. 0.] Expected output: [0. 1. 1. 0.] Layer weight: [[-1.248097 1.2202195 ] [-0.80121976 0.81952316]] \n The full implementation with training and inference - around 50 lines of code - can be found on GitHub.\n Why it works?\n Basically the model simulates a more sophisticated neuron which allows more interactions between the inputs.\n By multiplying the outputs of two neurons, we introduce a form of non-linearity that allows us to separate data that are not linearly separable, like in the XOR problem:\n f(x1, x2, w1, w2, w3, w4) = (x1 * w1 + x2 * w2) * (x1 * w3 + x2 * w4)\n  \nw1, w2 are learnable parameters of the first neuron\n w3, w4 are learnable parameters of the second neuron\n x1, x2 are inputs to the model\n  \nRelated studies\n  \nSolving XOR with a single Perceptron\n Artificial Neural Networks With Adaptive Polynomial Activation Function\n Single Cortical Neurons as Deep Artificial Neural Networks\n Dendritic action potentials and computation in human layer 2/3 cortical neurons\n  \n   submitted by    /u/tecbar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hih2w/p_the_xor_trick/",
          "publishedOn": "2023-09-13T09:32:10.000Z",
          "wordCount": 2823,
          "title": "[P] The XOR trick",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hhwoo/r_renting_cloud_services/",
          "author": null,
          "description": "Hello guys. As I plan on soing a scientific research project, I would need some cloud compute. Say for a month of usage(can I rent for month?). What are some popular options? I am looking at something with 48gb vram pooled,mybe a600 or a100 and some decent cpu, and 2tb space.\n    submitted by    /u/Outrageous_Ad1452  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hhwoo/r_renting_cloud_services/",
          "publishedOn": "2023-09-13T08:58:19.000Z",
          "wordCount": 2599,
          "title": "[R] Renting cloud services",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hboas/d_guidance_in_training_different_models_and/",
          "author": null,
          "description": "Currently I'm training medium (1B-3B) sized audio models. I have several different architectures in mind. Obviously I don't want to train the full-sized models and then compare them, thats a waste of money. So I'm thinking of training smaller versions (~100M) and then comparing those instead.\n My question is there some sort of best practice for this? Some smaller multiple of your full model size where it is best to compare? Thanks.\n    submitted by    /u/ginger_turmeric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hboas/d_guidance_in_training_different_models_and/",
          "publishedOn": "2023-09-13T03:07:47.000Z",
          "wordCount": 2627,
          "title": "[D] Guidance in training different models and comparing using smaller versions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h3rpd/p_need_advice_for_vector_db/",
          "author": null,
          "description": "Hi, all,\n I'm working on a GPT-powered game where the characters speak using API calls.\n For this, I need an inexpensive vector database that does not require an API, or at least if it does, it leverages the OpenAI API. Also, this vector database must be runnable on consumer-grade gaming hardware with a small search space (let's say 10-50 entries in the DB).\n Also, I need to package it with the game somehow. My game is in the Godot engine which can use Python with a plug-in. Other approaches I was considering is having a second process communicate with the game through a socket. Ideally the vector DB solution would be easy to install - that is, I could package it with a .exe, and simply run both without the player having to download anything else.\n Any suggestions? \n    submitted by    /u/kettlebot141  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h3rpd/p_need_advice_for_vector_db/",
          "publishedOn": "2023-09-12T21:31:04.000Z",
          "wordCount": 2688,
          "title": "[P] Need advice for vector DB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h3rfb/d_what_are_some_ways_that_you_can_reduce_latency/",
          "author": null,
          "description": "Hi. I'm currently tasked with something at my company that I'm facing some difficulty with because it's not in my domain. My company has a service where we provide video chatting to users and match users with others based on various features.\n Currently I've implemented a simple model where we have separate embedding matrices for each user feature, create a user representation by aggregating these features, and performing regression between two users. The way that regression works is that the final score output from the model would act as a \"matching score\" and we'll match user A with the highest other user.\n The problem is that obviously running inference on every single pair of users is very slow and I need to speed this up.\n Some methods I thought about were to either use a feature store or perform sampling on users so we're not running inference on the entire users, but I'm not sure if this is optimal.\n Just curious what other people who have tackled problems like these have done and looking for second opinions. Thanks.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h3rfb/d_what_are_some_ways_that_you_can_reduce_latency/",
          "publishedOn": "2023-09-12T21:30:47.000Z",
          "wordCount": 2736,
          "title": "[D] What are some ways that you can reduce latency of real-time user-user matching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h20xn/r_nextgpt_anytoany_multimodal_llm_national/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.05519 \n Blog: https://next-gpt.github.io/ \n My opinion: It lacks a Cognitive Architecture: https://arxiv.org/abs/2309.02427 Also the models are far too small and are more on the gpt-2 level. The idea in itself is a good one but can be far improved with bigger models. I also would like to remember in this that all foundation models could be improved if there would be no tokenizers: https://x.com/karpathy/status/1657949234535211009?s=20 \n Abstract:\n  \nWhile recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities. As we humans always perceive the world and communicate with people through var…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h20xn/r_nextgpt_anytoany_multimodal_llm_national/",
          "publishedOn": "2023-09-12T20:25:17.000Z",
          "wordCount": 2821,
          "title": "[R] NExT-GPT: Any-to-Any Multimodal LLM - National University of Singapore 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h1tup/r_unveiling_theory_of_mind_in_large_language/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.01660\n Abstract:\n  \nWith their recent development, large language models (LLMs) have been found to exhibit a certain level of Theory of Mind (ToM), a complex cognitive capacity that is related to our conscious mind and that allows us to infer another's beliefs and perspective. While human ToM capabilities are believed to derive from the neural activity of a broadly interconnected brain network, including that of dorsal medial prefrontal cortex (dmPFC) neurons, the precise processes underlying LLM's capacity for ToM or their similarities with that of humans remains largely unknown. In this study, we drew inspiration from the dmPFC neurons subserving human ToM and employed a similar methodology to examine whether LLMs exhibit comparable characteristics. Surp…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h1tup/r_unveiling_theory_of_mind_in_large_language/",
          "publishedOn": "2023-09-12T20:17:26.000Z",
          "wordCount": 2801,
          "title": "[R] Unveiling theory of mind in large language models: A parallel to single neurons in the human brain - Harvard University 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h1oqr/dr_looking_for_help_with_forced_alignment_for/",
          "author": null,
          "description": "Hey everyone,\n I'm trying to create an alignment between source audio in a different language than the translated transcript. Essentially want to align the translated transcript with the word-level timestamps on an Audio, programmatically. I've tried to find different tools; some open-source ML models force alignment if the source audio and transcript language are the same. \n My goal is to have audio in a dubbed language, which I generate using a translated transcript that has been originally transcribed from my audio. Alignment seems tough since languages are spoken at different rates, so I'm figuring out the best way to optimize alignment without having to speed up/slow down the audio too much for each sentence.\n    submitted by    /u/Revolutionary_Ant944  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h1oqr/dr_looking_for_help_with_forced_alignment_for/",
          "publishedOn": "2023-09-12T20:12:00.000Z",
          "wordCount": 2668,
          "title": "[D][R] Looking for help with Forced Alignment for translated audio",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h0jdq/d_best_places_to_access_the_greatest_number_of/",
          "author": null,
          "description": "I'm in need of a massive amount of GPUs for batch inference I'm doing. Outside of the big cloud providers are there any niche services out there you'd recommend? \n    submitted by    /u/Ok_Post_149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h0jdq/d_best_places_to_access_the_greatest_number_of/",
          "publishedOn": "2023-09-12T19:27:53.000Z",
          "wordCount": 2583,
          "title": "[D] Best Places to Access the Greatest Number of GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h09u4/d_are_fourier_positional_encodings_outdated/",
          "author": null,
          "description": "I gave a talk at work the other day about the attention mechanism and one of my coworkers told me that he thinks Fourier Positional Encodings in transformers are outdated. I've tried to follow up and find what I could but I didn't see anything suggesting that they're not being used. I know that learned encodings are also used.\n Can anyone give me some direction on this? My initial impression is that they are not outdated by any means, but I'm happy to be wrong about that.\n    submitted by    /u/XfrmrTron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h09u4/d_are_fourier_positional_encodings_outdated/",
          "publishedOn": "2023-09-12T19:17:16.000Z",
          "wordCount": 2637,
          "title": "[D] Are Fourier Positional Encodings Outdated?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gzd6i/p_launched_my_own_ttssound_effectai_music_service/",
          "author": null,
          "description": "I've created an AI Sound service that can do TTS (text to speech), STS (speech to speech), Voice Cloning, generate sound effects, and also generate instrumental music. Here's the link: https://voicegen.org/, you can try everything for free.\n The TTS quality is similar to Elevenlabs, and there are some sample clips on the home page.\n Stuff I'm working on:\n - Emotional speech (where you can select the emotion of the TTS). Right now you can already do it by putting the emotion in brackets: e.g. \"[Angrily] Please go away!\" but I want to make it better.\n - Music with vocals. Currently the model only generates instrumental music. I am retraining it/tweaking the model to allow for music with lyrics.\n - Faster Inference: Since I'm doing this all myself and I'm not rich, I don't have access to the best hardware. However, I am working on some optimizations like speculative decoding that should speed things up.\n Anyways, let me know if you have any questions/comments/feature suggestions/see any bugs! Feel free to DM me. Thanks.\n    submitted by    /u/ginger_turmeric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gzd6i/p_launched_my_own_ttssound_effectai_music_service/",
          "publishedOn": "2023-09-12T18:43:11.000Z",
          "wordCount": 2730,
          "title": "[P] Launched my own TTS/Sound Effect/AI Music Service - looking for people to try",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/",
          "author": null,
          "description": "Hey all, we just released our new project/paper and we thought you all might find it useful!\n Our project (Kani) is a super lightweight and hackable alternative to frameworks like LangChain or simpleAIchat meant to help developers hook in callable functions or tools to chat models easily. With Kani, devs can write functions in pure python and just add one line (the @ai_function() decorator) to turn any function into an AI-callable function!\n Kani works with any model and has built-in tools for OpenAI, HuggingFace, LLaMAv2, Vicuna, and GGML with more to come. Kani also never does any prompt engineering under the hood and doesn't require learning complex library tools---all defaults are minimal and highly customizable.\n Check out our Colab for mini-examples of things like retrieval, web-search, model routing, etc. https://colab.research.google.com/github/zhudotexe/kani/blob/main/examples/colab_examples.ipynb \n If you're interested in learning more check out our links below!\n Paper: https://arxiv.org/abs/2309.05542\n GitHub: https://github.com/zhudotexe/kani\n Docs: https://kani.readthedocs.io/\n    submitted by    /u/zhuexe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/",
          "publishedOn": "2023-09-12T17:38:09.000Z",
          "wordCount": 2705,
          "title": "[P][R] Kani: A Lightweight Highly Hackable Open-Source Framework for Building Chat Applications with Tool Usage (e.g. Plugins)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gx2lg/d_help_understanding_llm_quantization_techniques/",
          "author": null,
          "description": "So i have been doing some research to get into the LLM quantization field but have some questions. To better organize my ideas i have developed the image below. Does it make sense / is true?\n The way i understand it there are 3 main methods which are compatible with different backends (the backend part is still quite confusing to me). What is the core diference between what the methods do and the backends? What are some core diferences between the backends? What is the main distinction between GPTQ and NF4? How does NF4 relate to QLoRa, is it the same or is it just a small part of QLoRa?\n Thanks in advance and i apologize for any ignorance.\n ​\n https://preview.redd.it/gxpo0ir0yunb1.png?width=1041&format=png&auto=webp&s=872424a58a9d4393c025b8d2cec0160979b035f4\n    submitted by    /u/MiNeves  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gx2lg/d_help_understanding_llm_quantization_techniques/",
          "publishedOn": "2023-09-12T17:14:16.000Z",
          "wordCount": 2673,
          "title": "[D] Help Understanding LLM Quantization techniques and how they Relate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gvvdo/r_use_of_gpt4_to_analyze_medical_records_of/",
          "author": null,
          "description": "Paper - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10425828/\n  \nSix patients 65 years or older (2 women and 4 men) were included in the analysis. The accuracy of the primary diagnoses made by GPT-4, clinicians, and Isabel DDx Companion was 4 of 6 patients (66.7%), 2 of 6 patients (33.3%), and 0 patients, respectively. If including differential diagnoses, the accuracy was 5 of 6 (83.3%) for GPT-4, 3 of 6 (50.0%) for clinicians, and 2 of 6 (33.3%) for Isabel DDx Companion.\n  \n​\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gvvdo/r_use_of_gpt4_to_analyze_medical_records_of/",
          "publishedOn": "2023-09-12T16:27:26.000Z",
          "wordCount": 2636,
          "title": "[R] Use of GPT-4 to Analyze Medical Records of Patients With Extensive Investigations and Delayed Diagnosis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gvjow/r_train_vit_on_small_datasets/",
          "author": null,
          "description": "Hello, everyone,\n I'm currently working on a computer vision project using the Oxford Pets Dataset, which consists of 37 different pet categories. I initially used a pre-trained ViT model with ImageNet weights model=vit_b_32(ViT_B_32_Weights.IMAGENET1K_V1), and it gave me an impressive accuracy of 88%. However, I want to modify the architecture of the ViT model and train it from scratch without relying on ImageNet weights.\n I'm aware that ViT models are data-hungry and that training from scratch (model=vit_b_32( )) can be challenging, especially with limited data. I've already applied data augmentation techniques to enhance my dataset, but I'm still struggling to achieve satisfactory results. My accuracy is currently only 7%.\n I'd appreciate any advice or tips from the community on how I can improve the performance of my scratch-trained ViT model. Are there any specific training strategies, hyperparameters, or architectural modifications that I should consider? How can I make the most out of my limited dataset to boost accuracy?\n Thank you in advance for your help!\n    submitted by    /u/NoEntertainment6225  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gvjow/r_train_vit_on_small_datasets/",
          "publishedOn": "2023-09-12T16:14:46.000Z",
          "wordCount": 2714,
          "title": "[R] Train ViT on small datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gu9af/pr_developing_a_platform_to_accelerate_the/",
          "author": null,
          "description": "Hi community~\n We are developing a platform similar to mTurk and Prolific and plan to do the first wave of hypothesis testing in the coming weeks. If you have open tasks that require large amounts of human intelligence, please reply to this thread or dm me. We can support your research in our hypothesis testing. \n we are on the mission of helping machine learning experts and AI training as open and public goods, you can learn more here: https://ivynetwork.cloud/ \n feel free to ask more questions here :)\n    submitted by    /u/Accomplished_Code_25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gu9af/pr_developing_a_platform_to_accelerate_the/",
          "publishedOn": "2023-09-12T15:24:47.000Z",
          "wordCount": 2638,
          "title": "[P][R] Developing a platform to accelerate the research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gs6a9/math_for_machine_learning_d/",
          "author": null,
          "description": "İ have a question. How important linear algebra for machine learning? İ have basic level knowledge on linear? Should İ study in more detail? And How can İ follow roadmap on math for machine learning?\n    submitted by    /u/Necessary-Car-5080  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gs6a9/math_for_machine_learning_d/",
          "publishedOn": "2023-09-12T14:01:03.000Z",
          "wordCount": 2584,
          "title": "Math for machine learning [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16grcpm/dphas_anyone_ever_tried_finetuning_tortoise_tts/",
          "author": null,
          "description": "Hello people. I've been wanting to clone voices along with the accent. For example: A user speak English in an Indian accent should have that accent cloned in the output audio as well. By default, tortoise is not good at doing that. It can clone the pitch of the voice really well but the accent is completely lost. I was wondering if fine tuning the model could get me what I want. Please do suggest. Also do suggest any methods on fine tuning it if it does in fact help my use case. Thanks a lot!\n Note: I've also tried bark, coqui and vall-e-x. They aren't that good for voice cloning from what I saw.\n    submitted by    /u/salehxoxo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16grcpm/dphas_anyone_ever_tried_finetuning_tortoise_tts/",
          "publishedOn": "2023-09-12T13:25:44.000Z",
          "wordCount": 2670,
          "title": "[D][P]Has anyone ever tried fine-tuning Tortoise tts for better voice cloning?",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com/",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "6518d24af35d0b00011947a0",
          "author": "Janelle Shane",
          "description": "Since 2019 I've generated October drawing prompts using the year's most state-of-the-art text-generating models. Every year the challenges are different, but this was one of the hardest years yet. Large language models like chatgpt, GPT-4, Bing Chat, and Bard, are all tweaked to produce generic, predictable",
          "link": "https://www.aiweirdness.com/botober-2023/",
          "publishedOn": "2023-10-01T03:08:41.000Z",
          "wordCount": 1770,
          "title": "Botober 2023",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/10/botober_2023_chaos_clip.png"
        },
        {
          "id": "6518e0bef35d0b00011948d8",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-there-was-no-2020-botober/",
          "publishedOn": "2023-10-01T03:08:24.000Z",
          "wordCount": 690,
          "title": "Bonus: There was no 2020 Botober?",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        },
        {
          "id": "650a0f44ea79ba0001ba8a07",
          "author": "Janelle Shane",
          "description": "ChatGPT, Bard, GPT-4, and the like are often pitched as ways to retrieve information. The problem is they'll \"retrieve\" whatever you ask for, whether or not it exists.\nTumblr user @indigofoxpaws sent me a few screenshots where they'd asked ChatGPT for an explanation of",
          "link": "https://www.aiweirdness.com/trolling-chatbots-with-made-up-memes/",
          "publishedOn": "2023-09-24T13:13:44.000Z",
          "wordCount": 1022,
          "title": "Trolling chatbots with made-up memes",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/09/snowbonk-walrus.png"
        },
        {
          "id": "650fbea407cccb000136ab7d",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-these-memes-do-not-exist/",
          "publishedOn": "2023-09-24T13:13:22.000Z",
          "wordCount": 700,
          "title": "Bonus: These memes do not exist",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": []
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": []
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2023/new-tools-available-reduce-energy-that-ai-models-devour-1005",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "Amid the race to make AI bigger and better, Lincoln Laboratory is developing ways to reduce power, train efficiently, and make energy use transparent.",
          "link": "https://news.mit.edu/2023/new-tools-available-reduce-energy-that-ai-models-devour-1005",
          "publishedOn": "2023-10-05T17:20:00.000Z",
          "wordCount": 3411,
          "title": "New tools are available to help reduce the energy that AI models devour",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/data-centers.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/ai-co-pilot-enhances-human-precision-safer-aviation-1003",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "Designed to ensure safer skies, “Air-Guardian” blends human intuition with machine precision, creating a more symbiotic relationship between pilot and aircraft.",
          "link": "https://news.mit.edu/2023/ai-co-pilot-enhances-human-precision-safer-aviation-1003",
          "publishedOn": "2023-10-03T18:55:00.000Z",
          "wordCount": 2488,
          "title": "AI copilot enhances human precision for safer aviation",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Air-Guardian-cov.png"
        },
        {
          "id": "https://news.mit.edu/2023/more-effective-experimental-design-genome-regulation-1002",
          "author": "Adam Zewe | MIT News",
          "description": "By focusing on causal relationships in genome regulation, a new AI method could help scientists identify new immunotherapy techniques or regenerative therapies.",
          "link": "https://news.mit.edu/2023/more-effective-experimental-design-genome-regulation-1002",
          "publishedOn": "2023-10-02T15:00:00.000Z",
          "wordCount": 2999,
          "title": "A more effective experimental design for engineering a cell into a new state",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-Active-Learning-01.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/ai-eye-beholder-chatbot-motives-1002",
          "author": "Adam Zewe | MIT News",
          "description": "Study shows users can be primed to believe certain things about an AI chatbot’s motives, which influences their interactions with the chatbot.",
          "link": "https://news.mit.edu/2023/ai-eye-beholder-chatbot-motives-1002",
          "publishedOn": "2023-10-02T15:00:00.000Z",
          "wordCount": 3082,
          "title": "Is AI in the eye of the beholder?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202310/MIT-AI-Beliefs-01-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/who-will-benefit-ai-machine-usefulness-0929",
          "author": "Peter Dizikes | MIT News",
          "description": "In campus talk, Daron Acemoglu offers vision of “machine usefulness,” rather than autonomous “intelligence,” to help workers and spread prosperity.",
          "link": "https://news.mit.edu/2023/who-will-benefit-ai-machine-usefulness-0929",
          "publishedOn": "2023-09-29T15:00:00.000Z",
          "wordCount": 3192,
          "title": "Who will benefit from AI?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Christia-Acemoglu-01a-PRESS.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/re-imagining-opera-of-the-future-valis-0927",
          "author": "Anya Ventura | Arts at MIT",
          "description": "The iconic sci-fi opera “VALIS,” first composed by Professor Tod Machover in 1987, reboots at MIT for a new generation.",
          "link": "https://news.mit.edu/2023/re-imagining-opera-of-the-future-valis-0927",
          "publishedOn": "2023-09-27T20:20:00.000Z",
          "wordCount": 3348,
          "title": "Re-imagining the opera of the future",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/VALIS-actors-on-stage.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/physics-generative-ai-ai-model-advanced-pattern-generation-0927",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "Inspired by physics, a new generative model PFGM++ outperforms diffusion models in image generation.",
          "link": "https://news.mit.edu/2023/physics-generative-ai-ai-model-advanced-pattern-generation-0927",
          "publishedOn": "2023-09-27T13:15:00.000Z",
          "wordCount": 2865,
          "title": "From physics to generative AI: An AI model for advanced pattern generation",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/pfgm-mit-csail-00.png"
        },
        {
          "id": "https://news.mit.edu/2023/school-engineering-welcomes-songyee-yoon-visiting-innovation-scholar-0920",
          "author": "Mary Beth Gallagher | School of Engineering",
          "description": "A visionary entrepreneur and innovator, Yoon will focus on entrepreneurship, supporting female engineers, and fostering inclusive innovation.",
          "link": "https://news.mit.edu/2023/school-engineering-welcomes-songyee-yoon-visiting-innovation-scholar-0920",
          "publishedOn": "2023-09-20T20:50:00.000Z",
          "wordCount": 2370,
          "title": "School of Engineering welcomes Songyee Yoon PhD ’00 as visiting innovation scholar",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/songyee-yoon.png"
        },
        {
          "id": "https://news.mit.edu/2023/accenture-fellows-advance-technology-crossroads-business-society-0919",
          "author": "School of Engineering",
          "description": "The MIT and Accenture Convergence Initiative for Industry and Technology announces the 2023-24 graduate fellows.",
          "link": "https://news.mit.edu/2023/accenture-fellows-advance-technology-crossroads-business-society-0919",
          "publishedOn": "2023-09-19T20:45:00.000Z",
          "wordCount": 2608,
          "title": "Meet the 2023-24 Accenture Fellows",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/mit-Accenture-Fellows-22-23.png"
        },
        {
          "id": "https://news.mit.edu/2023/lincoln-laboratory-technologies-win-rd-world-awards-0919",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "Inventions in medical imaging, aircrew scheduling, data security, and quantum networking are named among the year’s most innovative new products.",
          "link": "https://news.mit.edu/2023/lincoln-laboratory-technologies-win-rd-world-awards-0919",
          "publishedOn": "2023-09-19T20:35:34.000Z",
          "wordCount": 3272,
          "title": "Four Lincoln Laboratory technologies win five 2023 R&D 100 awards",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/quantum-memory-mit-lincoln-lab_0.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/mit-scholars-awarded-seed-grants-generative-ai-0918",
          "author": "MIT News",
          "description": "The 27 finalists — representing every school at MIT — will explore the technology’s impact on democracy, education, sustainability, communications, and much more.",
          "link": "https://news.mit.edu/2023/mit-scholars-awarded-seed-grants-generative-ai-0918",
          "publishedOn": "2023-09-18T19:00:00.000Z",
          "wordCount": 3051,
          "title": "MIT scholars awarded seed grants to probe the social implications of generative AI",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-AI-ImpactPaper-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/multi-ai-collaboration-helps-reasoning-factual-accuracy-language-models-0918",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "Researchers use multiple AI models to collaborate, debate, and improve their reasoning abilities to advance the performance of LLMs while increasing accountability and factual accuracy.",
          "link": "https://news.mit.edu/2023/multi-ai-collaboration-helps-reasoning-factual-accuracy-language-models-0918",
          "publishedOn": "2023-09-18T13:00:00.000Z",
          "wordCount": 2700,
          "title": "Multi-AI collaboration helps reasoning and factual accuracy in large language models",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/Multiagent-debate.png"
        },
        {
          "id": "https://news.mit.edu/2023/ai-driven-tool-personalize-3d-printable-models-0915",
          "author": "Adam Zewe | MIT News",
          "description": "With Style2Fab, makers can rapidly customize models of 3D-printable objects, such as assistive devices, without hampering their functionality.",
          "link": "https://news.mit.edu/2023/ai-driven-tool-personalize-3d-printable-models-0915",
          "publishedOn": "2023-09-15T04:00:00.000Z",
          "wordCount": 3110,
          "title": "AI-driven tool makes it easy to personalize 3D-printable models",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Style2Fab-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/pose-mapping-technique-cerebral-palsy-patients-0914",
          "author": "Jennifer Chu | MIT News",
          "description": "The machine-learning method works on most mobile devices and could be expanded to assess other motor disorders outside of the doctor’s office.",
          "link": "https://news.mit.edu/2023/pose-mapping-technique-cerebral-palsy-patients-0914",
          "publishedOn": "2023-09-14T04:00:00.000Z",
          "wordCount": 3136,
          "title": "A pose-mapping technique could remotely evaluate patients with cerebral palsy",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Motor-Function-App-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/how-archeological-approach-can-help-leverage-biased-data-ai-improve-medicine-0913",
          "author": "Alex Ouyang | Abdul Latif Jameel Clinic for Machine Learning in Health",
          "description": "Although computer scientists may initially treat data bias and error as a nuisance, researchers argue it’s a hidden treasure trove for reflecting societal values.",
          "link": "https://news.mit.edu/2023/how-archeological-approach-can-help-leverage-biased-data-ai-improve-medicine-0913",
          "publishedOn": "2023-09-13T20:50:00.000Z",
          "wordCount": 3085,
          "title": "How an archeological approach can help leverage biased data in AI to improve medicine",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MarzyehNEJMReview1.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/helping-computer-vision-language-models-see-0913",
          "author": "Adam Zewe | MIT News",
          "description": "Researchers use synthetic data to improve a model’s ability to grasp conceptual information, which could enhance automatic captioning and question-answering systems.",
          "link": "https://news.mit.edu/2023/helping-computer-vision-language-models-see-0913",
          "publishedOn": "2023-09-13T04:00:00.000Z",
          "wordCount": 2907,
          "title": "Helping computer vision and language models understand what they see",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Beyond-Nouns-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/michael-west-advancing-human-robot-interactions-0913",
          "author": "Michaela Jarvis | School of Engineering",
          "description": "When he isn’t investigating human motor control, the graduate student gives back by volunteering with programs that helped him grow as a researcher.",
          "link": "https://news.mit.edu/2023/michael-west-advancing-human-robot-interactions-0913",
          "publishedOn": "2023-09-13T04:00:00.000Z",
          "wordCount": 2879,
          "title": "A. Michael West: Advancing human-robot interactions in health care",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/Michael-West.JPG"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com/",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=67289",
          "author": "Annamalai Chockalingam",
          "description": "Developers have a new AI-powered steering wheel to help them hug the road while they drive powerful large language models (LLMs) to their desired locations. NVIDIA NeMo SteerLM lets companies define knobs to dial in a model’s responses as it’s running in production, a process called inference. Unlike current methods for customizing an LLM, it Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/11/customize-ai-models-steerlm/",
          "publishedOn": "2023-10-11T14:30:17.000Z",
          "wordCount": 1937,
          "title": "Take the Wheel: NVIDIA NeMo SteerLM Lets Companies Customize a Model’s Responses During Inference",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/SteerLM-KV-x1280-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67366",
          "author": "Gerardo Delgado",
          "description": "Generative AI is helping creatives across many industries bring ideas to life at unprecedented speed. This technology will be on display at Adobe MAX, running through Thursday, Oct. 12, in person and virtually.",
          "link": "https://blogs.nvidia.com/blog/2023/10/10/adobe-max-firefly-creative-cloud-substance-3d/",
          "publishedOn": "2023-10-10T16:00:26.000Z",
          "wordCount": 2661,
          "title": "MAXimum AI Performance: Latest Adobe Updates Accelerated by NVIDIA GPUs Improve Workflows for Millions of Creatives",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/adobe-max-2023-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67327",
          "author": "Scott Martin",
          "description": "A research team is aiming to shake up the status quo for earthquake models. Researchers from the Universities of California at Berkeley and Santa Cruz, and the Technical University of Munich recently released a paper describing a new model that delivers deep learning to earthquake forecasting. Dubbed RECAST, the model can use larger datasets and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/06/quakes-deep-learning-forecasts/",
          "publishedOn": "2023-10-06T16:00:54.000Z",
          "wordCount": 1843,
          "title": "Keeping an AI on Quakes: Researchers Unveil Deep Learning Model to Improve Forecasts",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/SFQuakePost-and-Grant-Avenue-Look-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67294",
          "author": "Mona Flores",
          "description": "Just as athletes train for a game or actors rehearse for a performance, surgeons prepare ahead of an operation. Now, Atlas Meditech is letting brain surgeons experience a new level of realism in their pre-surgery preparation with AI and physically accurate simulations. Atlas Meditech, a brain-surgery intelligence platform, is adopting tools — including the MONAI Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/05/atlas-meditech-brain-surgery-ai-digital-twins/",
          "publishedOn": "2023-10-05T13:00:43.000Z",
          "wordCount": 2113,
          "title": "Brains of the Operation: Atlas Meditech Maps Future of Surgery With AI, Digital Twins",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/AtlasMeditech_featureimage_blogcrop.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67333",
          "author": "GeForce NOW Community",
          "description": "October brings more than falling leaves and pumpkin spice lattes for GeForce NOW members. Get ready for nearly 60 new games to stream, including Forza Motorsport and 16 more PC Game Pass titles. Assassin’s Creed Mirage leads 29 new games to hit the GeForce NOW library this week. In addition, catch a challenge to earn Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/05/geforce-now-thursday-oct-5/",
          "publishedOn": "2023-10-05T13:00:25.000Z",
          "wordCount": 2602,
          "title": "Fall in Line for October With Nearly 60 New Games, Including Latest Game Pass Titles to Join the Cloud",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/gfn-thursday-10-5-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67324",
          "author": "Kristen Yee",
          "description": "For NVIDIA Senior AI Scientist Jim Fan, the video game Minecraft served as the “perfect primordial soup” for his research on open-ended AI agents. In the latest AI Podcast episode, host Noah Kravitz spoke with Fan on using large language models to create AI agents — specifically to create Voyager, an AI bot built with Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/04/ai-jim-fan/",
          "publishedOn": "2023-10-04T21:04:52.000Z",
          "wordCount": 1702,
          "title": "A Mine-Blowing Breakthrough: Open-Ended AI Agent Voyager Autonomously Plays ‘Minecraft’",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67306",
          "author": "Brian Caulfield",
          "description": "California has a new weapon against the wildfires that have devastated the state: AI. A freshly launched system powered by AI trained on NVIDIA GPUs promises to provide timely alerts to first responders across the Golden State every time a blaze ignites. The ALERTCalifornia initiative, a collaboration between California’s wildfire fighting agency CAL FIRE and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/04/ai-wildfires-california/",
          "publishedOn": "2023-10-04T15:00:55.000Z",
          "wordCount": 1886,
          "title": "How AI Helps Fight Wildfires in California",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/29firemain1080.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67273",
          "author": "Kristen Yee",
          "description": "With the help of AI, robots, tractors and baby strollers — even skate parks — are becoming autonomous. One developer, Kabilan KB, is bringing autonomous-navigation capabilities to wheelchairs, which could help improve mobility for people with disabilities. The undergraduate from the Karunya Institute of Technology and Sciences in Coimbatore, India, is powering his autonomous wheelchair Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/10/03/kabilan-kb-autonomous-wheelchair/",
          "publishedOn": "2023-10-03T15:00:04.000Z",
          "wordCount": 1881,
          "title": "Meet the Maker: Robotics Student Rolls Out Autonomous Wheelchair With NVIDIA Jetson",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/10/autonomouswheelchair.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67223",
          "author": "Gerardo Delgado",
          "description": "Releasing a 3D tutorial dubbed The Easiest VFX Tutorial Ever takes supreme confidence and the skills to back it up. Steve Lund a.k.a. CG Geek — the featured artist of this week’s In the NVIDIA Studio installment — has both in spades.",
          "link": "https://blogs.nvidia.com/blog/2023/10/03/cg-geek-blender/",
          "publishedOn": "2023-10-03T13:00:33.000Z",
          "wordCount": 2341,
          "title": "CG Geek Makes VFX Look Easy This Week ‘In the NVIDIA Studio’",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-3.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67172",
          "author": "Rick Merritt",
          "description": "In a talk, now available online, NVIDIA Chief Scientist Bill Dally describes a tectonic shift in how computer performance gets delivered in a post-Moore’s law era. Each new processor requires ingenuity and effort inventing and validating fresh ingredients, he said in a recent keynote address at Hot Chips, an annual gathering of chip and systems Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/29/huangs-law-dally-hot-chips/",
          "publishedOn": "2023-09-29T15:00:00.000Z",
          "wordCount": 1758,
          "title": "Heeding Huang’s Law: Video Shows How Engineers Keep the Speedups Coming",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/HotChips-2023-2292-Dally-KV-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67151",
          "author": "Angie Lee",
          "description": "Pixellot is scoring with vision AI — making it easier for organizations to deliver real-time sports broadcasting and analytics to viewers across the globe. A member of the NVIDIA Metropolis vision AI partner ecosystem, the company based near Tel Aviv offers an AI-powered platform that automates the capturing, streaming and analysis of sporting events. It’s Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/28/pixellot-vision-ai-sports-broadcasting/",
          "publishedOn": "2023-09-28T15:00:07.000Z",
          "wordCount": 2024,
          "title": "Kicking Games Up a Notch: Startup Sports Vision AI to Broadcast Athletics Across the Globe",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/pixellot-featured-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67195",
          "author": "GeForce NOW Community",
          "description": "The wait is over. GeForce NOW Ultimate members can experience Cyberpunk 2077: Phantom Liberty on GOG.com at full GeForce RTX 4080 quality, with support for NVIDIA DLSS 3.5 technology. It’s part of an action-packed GFN Thursday, with 26 more games joining the cloud gaming platform’s library, including Quake II from id Software. A New Look Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/28/geforce-now-thursday-sep-28/",
          "publishedOn": "2023-09-28T13:00:45.000Z",
          "wordCount": 2321,
          "title": "V for Victory: ‘Cyberpunk 2077: Phantom Liberty’ Comes to GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-28-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67180",
          "author": "Calisa Cole",
          "description": "DENZA, the luxury electric-vehicle brand and joint venture between BYD and Mercedes-Benz, is debuting new intelligent driving features for its entire N7 model lineup, powered by the NVIDIA DRIVE Orin system-on-a-chip (SoC). The N7 series was introduced earlier this year as a family of spacious five-seater SUVs for commuters looking to sport a deluxe EV Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/27/denza-smart-driving-n7-model-nvidia-drive-orin/",
          "publishedOn": "2023-09-27T16:41:47.000Z",
          "wordCount": 1387,
          "title": "DENZA Unwraps Smart Driving Options for N7 Model Lineup, Powered by NVIDIA DRIVE Orin",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/denzfinal2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67110",
          "author": "Renee Yao",
          "description": "Medical-device company Invenio Imaging is developing technology that enables surgeons to evaluate tissue biopsies in the operating room, immediately after samples are collected — providing in just three minutes AI-accelerated insights that would otherwise take weeks to obtain from a pathology lab. In a surgical biopsy, a medical professional removes samples of cells or tissue Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/27/healthcare-ai-startup-analyzes-cancer-cells-in-the-operating-room/",
          "publishedOn": "2023-09-27T13:00:40.000Z",
          "wordCount": 1923,
          "title": "The Fastest Path: Healthcare Startup Uses AI to Analyze Cancer Cells in the Operating Room",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Ambra_1_blogsize.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67153",
          "author": "Soma Velayutham",
          "description": "As generative AI sweeps across corporate boardrooms around the world, global telecommunications companies are exploring how to cost-effectively deliver many of these new AI applications to the edge over 5G and upcoming 6G networks. Telcos plan to deploy over 17 million 5G microcells and towers worldwide by 2025. Building, managing and optimizing this new infrastructure Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/26/ntt-docomo-gpu-accelerated-5g-network/",
          "publishedOn": "2023-09-27T00:00:03.000Z",
          "wordCount": 1850,
          "title": "NVIDIA Works With NTT DOCOMO to Launch World’s First GPU-Accelerated 5G Network",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/docomo2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67152",
          "author": "Brian Caulfield",
          "description": "Talk about a Grand Slam. Denny’s CEO Kelli Valade was joined Tuesday by NVIDIA CEO Jensen Huang to unveil a plaque at the Silicon Valley Denny’s where NVIDIA’s founders hatched their idea for a chip that would enable realistic 3D graphics on personal computers. “This is a place where we fuel ideas. Your story is Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/26/nvidia-dennys-trillion/",
          "publishedOn": "2023-09-26T20:37:19.000Z",
          "wordCount": 1698,
          "title": "NVIDIA Founder and CEO Jensen Huang Returns to Denny’s Where NVIDIA Launched a Trillion-Dollar Vision",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Valade-Huang-Dennys-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67123",
          "author": "Gerardo Delgado",
          "description": "From gaming to creating to everyday productivity, NVIDIA RTX graphics cards feature specialized Tensor Cores that deliver cutting-edge performance and transformative capabilities for AI.",
          "link": "https://blogs.nvidia.com/blog/2023/09/26/itns-rtx-ai-windows/",
          "publishedOn": "2023-09-26T13:00:49.000Z",
          "wordCount": 2222,
          "title": "AI Power Players: GeForce and NVIDIA RTX GPUs Supercharge Creativity, Gaming, Development, Productivity and More",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/image1-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67098",
          "author": "David Reber Jr.",
          "description": "In the wake of ChatGPT, every company is trying to figure out its AI strategy, work that quickly raises the question: What about security? Some may feel overwhelmed at the prospect of securing new technology. The good news is policies and practices in place today provide excellent starting points. Indeed, the way forward lies in Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/25/ai-security-steps/",
          "publishedOn": "2023-09-25T15:00:22.000Z",
          "wordCount": 1955,
          "title": "Six Steps Toward AI Security",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Six-levels-pixabay-1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67040",
          "author": "Gerardo Delgado",
          "description": "The NVIDIA Studio laptop lineup is expanding with the new Microsoft Surface Laptop Studio 2, powered by GeForce RTX 4060, GeForce RTX 4050 or NVIDIA RTX 2000 Ada Generation Laptop GPUs, providing powerful performance and versatility for creators.",
          "link": "https://blogs.nvidia.com/blog/2023/09/21/surface-studio-chaos-dlss-resolve-tensor-rt/",
          "publishedOn": "2023-09-21T15:00:42.000Z",
          "wordCount": 2512,
          "title": "NVIDIA Studio Lineup Adds RTX-Powered Microsoft Surface Laptop Studio 2",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67078",
          "author": "Jesse Clayton",
          "description": "Gone are the days when AI was the domain of sprawling data centers or elite researchers. For GeForce RTX users, AI is now running on your PC. It’s personal, enhancing every keystroke, every frame and every moment. Gamers are already enjoying the benefits of AI in over 300 RTX games. Meanwhile, content creators have access Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/21/ai-on-local-rtx-windows-pc/",
          "publishedOn": "2023-09-21T15:00:33.000Z",
          "wordCount": 2423,
          "title": "Run AI on Your PC? GeForce Users Are Ahead of the Curve",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-4.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67011",
          "author": "Dane Johnston",
          "description": "For seasoned 3D artists and budding digital creation enthusiasts alike, an alpha version of the popular 3D software Blender is elevating creative journeys.",
          "link": "https://blogs.nvidia.com/blog/2023/09/21/omniverse-blender-release-openusd/",
          "publishedOn": "2023-09-21T13:00:34.000Z",
          "wordCount": 2095,
          "title": "Into the Omniverse: Blender 4.0 Alpha Release Sets Stage for New Era of OpenUSD Artistry",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/ov-corp-blog-sept-ito-1280x680-1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=67032",
          "author": "Brian Caulfield",
          "description": "NVIDIA founder and CEO Jensen Huang will highlight the newest in generative AI and cloud computing at the NVIDIA AI Summit in Tel Aviv from Oct. 15-16. The two-day summit is set to attract more than 2,500 developers, researchers and decision-makers from across one of the world’s most vibrant technology hubs. With over 6,000 startups, Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/21/ai-summit/",
          "publishedOn": "2023-09-21T13:00:27.000Z",
          "wordCount": 1469,
          "title": "NVIDIA CEO Jensen Huang to Headline AI Summit in Tel Aviv",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2019/03/tel-aviv.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66999",
          "author": "GeForce NOW Community",
          "description": "Time to get the gang back together — PAYDAY 3 streams on GeForce NOW this week. It’s one of 11 titles joining the cloud this week, including Party Animals. The Perfect Heist PAYDAY 3 is the highly anticipated sequel to one of the world’s most popular co-op shooters. Step out of retirement and back into Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/21/geforce-now-thursday-sep-21/",
          "publishedOn": "2023-09-21T13:00:19.000Z",
          "wordCount": 1515,
          "title": "Cash In: ‘PAYDAY 3’ Streams on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-21-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66953",
          "author": "Mike Geyer",
          "description": "Mercedes-Benz is using digital twins for production with help from NVIDIA Omniverse, a platform for developing Universal Scene Description (OpenUSD) applications to design, collaborate, plan and operate manufacturing and assembly facilities. Mercedes-Benz’s new production techniques will bring its next-generation vehicle portfolio into its manufacturing facilities operating in Rastatt, Germany; Kecskemét, Hungary; and Beijing, China — Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/20/mercedes-benz-ev-nvidia-omniverse-generative-ai/",
          "publishedOn": "2023-09-20T18:08:16.000Z",
          "wordCount": 1917,
          "title": "Virtually Incredible: Mercedes-Benz Prepares Its Digital Production System for Next-Gen Platform With NVIDIA Omniverse, MB.OS and Generative AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/23C0321_004-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66948",
          "author": "Dave Salvator",
          "description": "With generative AI and large language models (LLMs) driving groundbreaking innovations, the computational demands for training and inference are skyrocketing. These modern-day generative AI applications demand full-stack accelerated compute, starting with state-of-the-art infrastructure that can handle massive workloads with speed and accuracy. To help meet this need, Oracle Cloud Infrastructure today announced general availability of Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/19/oracle-cloud-infrastructure-nvidia-gpu-accelerated-compute-instances/",
          "publishedOn": "2023-09-19T23:40:06.000Z",
          "wordCount": 1754,
          "title": "Oracle Cloud Infrastructure Offers New NVIDIA GPU-Accelerated Compute Instances",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/10/Copy-of-oracle-blog-logo-lockup-promo-package-2508744-1260x680-r3.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66954",
          "author": "Nicole Castro",
          "description": "Editor’s note: This post is a part of our Meet the Omnivore series, which features individual creators and developers who use NVIDIA Omniverse and OpenUSD to accelerate their 3D workflows and create virtual worlds. As a student at the Queensland University of Technology (QUT) in Australia, Emily Boehmer was torn between pursuing the creative arts Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/19/industrial-designer-blender-openusd-ai/",
          "publishedOn": "2023-09-19T18:15:19.000Z",
          "wordCount": 2144,
          "title": "Meet the Omnivore: Industrial Designer Blends Art and OpenUSD to Create 3D Assets for AI Training",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-672x378.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66926",
          "author": "Adel El Hallak",
          "description": "Large language model development is about to reach supersonic speed thanks to a collaboration between NVIDIA and Anyscale. At its annual Ray Summit developers conference, Anyscale — the company behind the fast growing open-source unified compute framework for scalable computing —  announced today that it is bringing NVIDIA AI to Ray open source and the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/18/llm-anyscale-nvidia-ai-enterprise/",
          "publishedOn": "2023-09-18T13:00:09.000Z",
          "wordCount": 1983,
          "title": "Ray Shines With NVIDIA AI: Anyscale Collaboration to Help Developers Build, Tune, Train and Scale Production LLMs",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/NVIDIA-Anyscale-logos-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66926",
          "author": "Adel El Hallak",
          "description": "Large language model development is about to reach supersonic speed thanks to a collaboration between NVIDIA and Anyscale. At its annual Ray Summit developers conference, Anyscale — the company behind the fast growing open-source unified compute framework for scalable computing —  announced today that it is bringing NVIDIA AI to Ray open source and the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/18/llm-anyscale-nvaie/",
          "publishedOn": "2023-09-18T13:00:09.000Z",
          "wordCount": 1976,
          "title": "Ray Shines With NVIDIA AI: Anyscale Collaboration to Help Developers Build, Tune, Train and Scale Production LLMs",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/NVIDIA-Anyscale-logos-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66903",
          "author": "GeForce NOW Community",
          "description": "GFN Thursday is downright demonic, as Devil May Cry 5 comes to GeForce NOW. Capcom’s action-packed third-person brawler leads 15 titles joining the GeForce NOW library this week, including Gears Tactics and The Crew Motorfest. It’s also the last week to take on the Ultimate KovaaK’s Challenge. Get on the leaderboard today for a chance Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/14/geforce-now-thursday-sep-14/",
          "publishedOn": "2023-09-14T13:00:20.000Z",
          "wordCount": 1842,
          "title": "Shout at the Devil: Capcom’s ‘Devil May Cry 5’ Joins GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-14-social-no-copy-2048x2048-fb-ig-500x500.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66807",
          "author": "Kristen Yee",
          "description": "Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research. Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the President’s Council of Advisors on Science and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/13/anima-anandkumar-generative-ai/",
          "publishedOn": "2023-09-13T13:00:11.000Z",
          "wordCount": 1642,
          "title": "Unlocking the Language of Genomes and Climates: Anima Anandkumar on Using Generative AI to Tackle Global Challenges",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2020/12/20181026-BJ-MB-CC__6881-M-Anima-Anandkumar-US-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66820",
          "author": "Ned Finkle",
          "description": "In an event at the White House today, NVIDIA announced support for voluntary commitments that the Biden Administration developed to ensure advanced AI systems are safe, secure and trustworthy. The news came the same day NVIDIA’s chief scientist, Bill Dally, testified before a U.S. Senate subcommittee seeking input on potential legislation covering generative AI. Separately, Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/ai-safety-washington/",
          "publishedOn": "2023-09-12T20:35:31.000Z",
          "wordCount": 1866,
          "title": "NVIDIA Lends Support to Washington’s Efforts to Ensure AI Safety",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Dally-in-Senate-QA-best-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66802",
          "author": "Marie Labrie",
          "description": "Generative AI’s transformative effect on the auto industry took center stage last week at the International Motor Show Germany, known as IAA, in Munich. NVIDIA’s Danny Shapiro, VP of automotive marketing, explained in his IAA keynote how this driving force is accelerating innovation and streamlining processes — from advancing design, engineering and digital-twin deployment for Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/iaa-drive-ecosystem-roundup/",
          "publishedOn": "2023-09-12T18:08:26.000Z",
          "wordCount": 2090,
          "title": "Mobility Gets Amped: IAA Show Floor Energized by Surge in EV Reveals, Generative AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/new-iaa-feature.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66694",
          "author": "Sam Stanwyck",
          "description": "Ten miles in from Long Island’s Atlantic coast, Shinjae Yoo is revving his engine. The computational scientist and machine learning group lead at the U.S. Department of Energy’s Brookhaven National Laboratory is one of many researchers gearing up to run quantum computing simulations on a supercomputer for the first time, thanks to new software. Yoo’s Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/quantum-supercomputers-pennylane/",
          "publishedOn": "2023-09-12T15:00:56.000Z",
          "wordCount": 1940,
          "title": "A Quantum Boost: cuQuantum With PennyLane Lets Simulations Ride Supercomputers",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Pennylane-KV-Final.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66825",
          "author": "Gerardo Delgado",
          "description": "Editor’s note: This post is part of our weekly In the NVIDIA Studio series, which celebrates featured artists, offers creative tips and tricks and demonstrates how NVIDIA Studio technology improves creative workflows.  When it comes to converting 2D concepts into 3D masterpieces, self-taught visual development artist Alex Treviño has confidence in the potential of all Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/aendom-blender-adobe-substance-3d-painter/",
          "publishedOn": "2023-09-12T13:00:35.000Z",
          "wordCount": 1982,
          "title": "One Small Step for Artists, One Giant Leap for Creative-Kind",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/09/360-textured.mp4",
            "length": "1994733",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-1.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de/",
      "articles": [
        {
          "id": "https://davidstutz.de/?p=9410",
          "author": "David Stutz",
          "description": "This September, I had the chance to attend the Heidelberg Laureate Forum (HLF) for the second — and probably last — time. The HLF is an incredible experince for young researchers: Mirroring the Lindau Nobel Laureate Meetings, the organizers invite laureates from math and computer science together with young researchers pursuing their undergraduate, graduate or post-doc studies. In this article, I want to share impressions and encourage students to apply next year!\nThe post My Impressions (and Application) of the Heidelberg Laureate Forum 2023 appeared first on David Stutz.",
          "link": "https://davidstutz.de/my-impressions-and-application-of-the-heidelberg-laureate-forum-2023/",
          "publishedOn": "2023-10-04T20:31:05.000Z",
          "wordCount": 1985,
          "title": "My Impressions (and Application) of the Heidelberg Laureate Forum 2023",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2023/10/tweet-1705617776184865145-600x600.jpg"
        },
        {
          "id": "https://davidstutz.de/?p=9396",
          "author": "David Stutz",
          "description": "In September, I received the DAGM MVTec dissertation award 2023 for my PhD thesis. DAGM is the German association for pattern recognition and organizes the German Conference on Pattern Recognition (GCPR) which is Germany's prime conference for computer vision and related research areas. I feel particularly honored by this award since my academic career started with my first paper published as part of the young researcher forum at GCPR 2015 in Aachen.\nThe post Awarded DAGM MVTec Dissertation Award 2023 appeared first on David Stutz.",
          "link": "https://davidstutz.de/awarded-dagm-mvtec-dissertation-award-2023/",
          "publishedOn": "2023-10-02T19:47:46.000Z",
          "wordCount": 930,
          "title": "Awarded DAGM MVTec Dissertation Award 2023",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2023/10/DAGM_MVTec-600x900.jpg"
        },
        {
          "id": "https://davidstutz.de/?p=8612",
          "author": "David Stutz",
          "description": "Another alternative to the regular $L_p$-constrained adversarial examples that is additionally less visible than adversarial patches or frames are adversarial transformations such as small crops, rotations and translations. Similar to $L_p$ adversarial examples, adversarial transformations are often less visible unless the original image is available for direct comparison. In this article, I will include a PyTorch implementation and some results against adversarial training.\nThe post Simple Adversarial Transformations in PyTorch appeared first on David Stutz.",
          "link": "https://davidstutz.de/simple-adversarial-transformations-in-pytorch/",
          "publishedOn": "2023-09-18T08:52:34.000Z",
          "wordCount": 2453,
          "title": "Simple Adversarial Transformations in PyTorch",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2021/12/adversarial_transformations.jpg"
        }
      ]
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/175rmsi/predictive_ai_analyzing_attraction_to_facial/",
          "author": null,
          "description": "Top dating apps Tinder, Hinge and Bumble have all stated that they're already investing in AI to make their apps better. They're using it to verify profiles, match people based on bios and interests, and help generate profile descriptions and liven conversations. But what about machine learning on user photos?\n iris Dating uses AI to analyze user input in the form of liking or disliking faces (\"swiping\" profiles). We all know if we like blondes or brunettes, blue or brown eyes, short or long hair, beard or no beard, etc. But AI can pick up the subtlest features (proportions, distances, curvatures etc.) and build a face map. A matrix of features, if you will. It doesn't just look for a person looking like your favorite celebrity crush. It understands what you're really attracted to.\n From there it's an easy path: if it knows which features attract me, it can predict my level of attraction to a specific individual (specifically, their face). Find the persons with the highest predicted attractiveness (for me, not for everyone), rank them by attraction for me, and we have a potential high mutual attraction match. The two stats I have are that on average women like 55%(!) of the profiles iris picks for them; and that users have 40x higher chances of matching when they've trained the model to understand their taste.\n I know it takes a lot more than a pretty face to make for a great relationship, but it sure doesn't hurt to start with strong physical attraction. Missed connections on Craigslist are about just that: seeing a face you can't forget. Find me more of these \"wow\" faces and let's go from there.\n What do you think? Is it too early? Too bold? Too niche?\n    submitted by    /u/akahamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175rmsi/predictive_ai_analyzing_attraction_to_facial/",
          "publishedOn": "2023-10-11T23:00:58.000Z",
          "wordCount": null,
          "title": "Predictive AI analyzing attraction to facial features (iris Dating app)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175qcg0/superman_if_portrayed_by_different_actors_as/",
          "author": null,
          "description": "submitted by    /u/fat_n_stupid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175qcg0/superman_if_portrayed_by_different_actors_as/",
          "publishedOn": "2023-10-11T22:04:50.000Z",
          "wordCount": null,
          "title": "Superman if portrayed by different actors (as imagined by AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175oebw/dalle_3_is_blocking_copyrighted_material_also/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175oebw/dalle_3_is_blocking_copyrighted_material_also/",
          "publishedOn": "2023-10-11T20:43:53.000Z",
          "wordCount": null,
          "title": "DALL·E 3 is blocking copyrighted material. Also DALL·E 3:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175nwas/the_ai_research_job_market_shit_show/",
          "author": null,
          "description": "The AI research job market is going through a shakeup, with a high demand for skilled researchers and a scarcity of talent.\n \nCompanies closely monitor the movements of researchers as an indicator of their ability to transition from concept to product.\n \nThe market is highly competitive, with researchers being offered high salaries and compensation packages.\n \nThis has led to high turnover and attrition in many companies, causing unsettledness among employees.\n \nDespite the challenges, the investment in AI research is expected to drive innovation and push the boundaries of the Transformer architecture.\n \n Source : https://www.interconnects.ai/p/ai-research-job-market\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175nwas/the_ai_research_job_market_shit_show/",
          "publishedOn": "2023-10-11T20:23:07.000Z",
          "wordCount": null,
          "title": "The AI research job market shit show",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175lngi/are_there_any_low_res_pixel_art_art_tools/",
          "author": null,
          "description": "I'm looking for ways to create art for a game I'm creating.\n    submitted by    /u/Yenii_3025  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175lngi/are_there_any_low_res_pixel_art_art_tools/",
          "publishedOn": "2023-10-11T18:48:42.000Z",
          "wordCount": null,
          "title": "Are there any low res (pixel art) art tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175ia9b/inverting_transformers_significantly_improves/",
          "author": null,
          "description": "Transformers are great at NLP and computer vision tasks, but I was surprised to learn they still lag behind simple linear models at time series forecasting.\n The issue is how most Transformer architectures treat each timestamp as a token and fuse all the variable data from that moment. This makes two big problems:\n  \nVariables recorded at slightly different times get blurred together, losing important timing info\n Each token can only see a single moment, no long-term dependencies\n  \nSo Transformers struggle to extract useful patterns and correlations from the data.\n Some researchers from Tsinghua University took a fresh look at this and realized the Transformer components themselves are solid, they just need to flip the architecture for time series data.\n Their \"Inverted Transformer\" (or iTransformer):\n  \nMakes each variable's full history into a token, instead of each timestamp\n Uses self-attention over variables to capture relationships\n Processes time dependencies per variable with feedforward layers\n  \nThis simple tweak gives all the benefits we want:\n  \nState-of-the-art forecasting accuracy, beating both linear models and standard Transformers\n Better generalization to unseen variables\n Increased interpretability\n Ability to leverage longer historical context\n  \nTLDR: Inverting Transformers to align with time series structure allows them to outperform alternatives in working with time series data.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175ia9b/inverting_transformers_significantly_improves/",
          "publishedOn": "2023-10-11T16:28:42.000Z",
          "wordCount": null,
          "title": "Inverting Transformers Significantly Improves Time Series Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175hkcr/best_chatgpt_plugins_ultimate_list_for_2023/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175hkcr/best_chatgpt_plugins_ultimate_list_for_2023/",
          "publishedOn": "2023-10-11T15:59:32.000Z",
          "wordCount": null,
          "title": "Best ChatGPT Plugins: Ultimate List for 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175g5vq/the_nsfw_dream_truely_unrestricted_ai_desires/",
          "author": null,
          "description": "I guess I'm looking for the impossible but does anyone know of a generator that has all of the following qualities in order of importance least to most important:\n  \nHas a massive variety of styles like Womba's private discord server does.\n \n\"Create variants\" function like how a Womba discord personal server generator allows you to do.\n \nGenerates beautiful \"digital art\" style images like the digital https://www.unstability.ai/ does. (Man those images are pretty) faces are really good most of the time. (It's frusterating as it looks so good but I can't seem to get any group sex poses going on.)\n \nProvides a variety of poses such as https://easywithai.com/ai-image-generators/promptchan-ai/ which also allows you to upload you own images for poses, like how I could upload a real life orgy image and as long as it could distinguish the bodies as being separate (not a big pile of limbs) it does pretty good, but lacks severely lacks in facial quality. Like a big booty girl in hyperreal style\n \n1080P or higher resolution. (Again Womba is good here, but they are just extreme on their restrictions.) 1080P should be the minimum for any paid service as how can we truely enjoy a full screne image on anything less without it pixeling out?\n \nDoesn't cost $150/month (yes I found one that does all this but their premium subscription cost like $150/month (seduced.ai) and it's not even unlimited. I paid $90 for a full year at Womba discord unlimited but again, $150/month is just not worth it. \n \n If anyone knows of a server that has all these for around $25/month or less, please let me know. If really appreciate it.\n    submitted by    /u/russader  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175g5vq/the_nsfw_dream_truely_unrestricted_ai_desires/",
          "publishedOn": "2023-10-11T15:03:23.000Z",
          "wordCount": null,
          "title": "The NSFW dream (truely unrestricted ai desires)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/175g0uz/can_ai_reference_both_photos_to_make_the_black/",
          "author": null,
          "description": "I have a high resolution black and white print and a generic quality colour image of the same photo, that I'd like AI to look at both images and make the B&W into colour. Is this possible?\n    submitted by    /u/NikonD3X1985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/175g0uz/can_ai_reference_both_photos_to_make_the_black/",
          "publishedOn": "2023-10-11T14:58:11.000Z",
          "wordCount": null,
          "title": "Can AI reference both photos to make the black and white photo the same as the colour image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1757exy/ai_morality_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1757exy/ai_morality_scenarios/",
          "publishedOn": "2023-10-11T06:28:05.000Z",
          "wordCount": null,
          "title": "AI Morality Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1754t18/oneminute_daily_ai_news_10102023/",
          "author": null,
          "description": "Cybersecurity firm Avast is calling out a long-lived tool “LoveGPT,” that has haunted popular dating apps and that has been upgraded with artificial intelligence, gaining the ability to build fake profiles and manipulate unsuspecting users.[1]\n The outsider told the WSJ that Microsoft used AI from its partner OpenAI, which was then used to launch GitHub Copilot at $10 per month, but lost $20 per user in the average six months on average in the first 2023. Some Copilot users cost as much as $80 per month.[2]\n SK Telecom said on Monday that it successfully wrapped up its international AI competition of 226 teams, “Prompter Day Seoul 2023,” held in partnership with OpenAI.[3]\n Google DeepMind Researchers Introduce Promptbreeder: A Self-Referential and Self-Improving AI System that can Automatically Evolve Effective Domain-Specific Prompts in a Given Domain.[4]\n  \nSources:\n [1] https://decrypt.co/200787/lovegpt-ai-dating-apps-catfishing-hack-avast\n [2] https://game-news24.com/2023/10/10/microsoft-lost-20-for-every-10-copilot-ai-subscription-report-45-for-every-10-copilot-ai/\n [3] https://asianews.network/skt-openai-hold-ai-competition-for-social-good/\n [4] https://www.marktechpost.com/2023/10/08/google-deepmind-researchers-introduce-promptbreeder-a-self-referential-and-self-improving-ai-system-that-can-automatically-evolve-effective-domain-specific-prompts-in-a-given-domain/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1754t18/oneminute_daily_ai_news_10102023/",
          "publishedOn": "2023-10-11T03:45:32.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/10/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17516ts/i_finally_have_enough_ai_tools_and_here_is_my/",
          "author": null,
          "description": "VIDEO EDITING\n InVideo\n CapCut\n Filmora Veed io\n Rotor\n KEYWORD RESEARCH\n VidiQ\n Summarized YT\n Summary\n CONTENT CREATION\n Explore Al\n Vidds\n Opus\n Descript\n Lumen5\n Steve Al\n AUDIENCE ENGAGEMENT\n ManyChat\n TubeBuddy\n Canva\n Hootsuite\n ANALYTICS\n Vidyo\n Nova Al\n Daily Life Tools\n Taskade\n TLVD\n Bardeen Al\n Vondy Al\n Notion Al\n Chatbots Tools\n YatterPlus\n Typewise\n Quickchat\n Cohere Kaizan\n Coding Tools\n Durable Al\n 10Web\n Akkia\n Replit\n Deepcode\n Design Tools\n Flair Al\n Autodraw\n StockIMG\n Booth Al\n Clipdrop\n Content Creation Tools\n Writesonic\n Beautiful Al\n Tome Al\n ChatABC\n Steve Al\n Music Tools\n Boomy\n Amper\n Jukedeck\n Melodrive\n BrainFM\n Writing Tools\n AISEO\n Quillbot\n Writesonic\n Bertha Al\n Simplified\n Youtube Tools\n Eightify\n Thumbly\n Steve Al\n ClipMaker\n TubeBuddy\n Twitter Tools\n Tweetmonk\n Tribescaler\n Postwise\n Tweetlify\n Tweethunter\n Sales Tools\n Lavender\n Warmer\n Regie\n Twain\n Octane\n Marketing Tools\n simplified\n ContentEdge\n Copt Smith\n Copy Al\n Mutiny\n Research Tools\n Consensus\n Paperpal\n Trinka\n Writesonic\n scholarcy\n I'm just sharing my experiences and observations in the field of ai.\n LIST AND SITE\n    submitted by    /u/PerceptionPlayful469  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17516ts/i_finally_have_enough_ai_tools_and_here_is_my/",
          "publishedOn": "2023-10-11T00:47:25.000Z",
          "wordCount": null,
          "title": "I finally have enough ai tools and here is my complete list",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1750vwy/write_your_next_book_with_these_awesome_chatgpt/",
          "author": null,
          "description": "Awesome ChatGPT Prompts\n    submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1750vwy/write_your_next_book_with_these_awesome_chatgpt/",
          "publishedOn": "2023-10-11T00:32:51.000Z",
          "wordCount": null,
          "title": "Write Your Next Book with These Awesome ChatGPT Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174x9k1/musicgpt_create_unique_music_from_text_prompts/",
          "author": null,
          "description": "submitted by    /u/SaucySporky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174x9k1/musicgpt_create_unique_music_from_text_prompts/",
          "publishedOn": "2023-10-10T21:52:00.000Z",
          "wordCount": null,
          "title": "MusicGPT: Create unique music from text prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174x0cc/website_to_do_the_following_i_give_it_a_design/",
          "author": null,
          "description": "Hello all,\n I am not sure this is out yet. I would like to find a website where i can upload an image I own, and have it generate another image around it.\n Let's say I have some shirts that say 'HOLA'. I would want, for example, to generate an image of Socrates wearing said shirt. Is this possible? If so, which site would allow me to do this?\n ​\n Cheers and merci!\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174x0cc/website_to_do_the_following_i_give_it_a_design/",
          "publishedOn": "2023-10-10T21:40:54.000Z",
          "wordCount": null,
          "title": "Website to do the Following: I Give it a Design and Create an Image With it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174sxxs/so_far_ai_hasnt_been_profitable_for_big_tech/",
          "author": null,
          "description": "Big Tech companies like Microsoft and Google are grappling with the challenge of turning AI products like ChatGPT into a profitable enterprise.\n \nThe cost of running advanced AI models is proving to be a significant hurdle, with some services driving significant operational losses.\n \nCorporate customers are unhappy with the high running costs of AI models.\n \nThe nature of AI computations, which require new calculations for each query, makes flat-fee models risky.\n \nSome companies are trying to dial back costs, while others continue to invest more deeply in AI tech.\n \nMicrosoft's GitHub Copilot, which assists app developers by generating code, has been operating at a loss despite attracting more than 1.5 million users.\n \nOne of the reasons AI services are costly is that some companies have been reaching for the most powerful AI models available.\n \nMicrosoft has been exploring less costly alternatives for its Bing Chat search engine assistant.\n \nAdvances in AI acceleration hardware may eventually reduce the costs of operating complex models.\n \nExperts anticipate a more stringent financial approach in the near future, transitioning from experimental budgets to focusing on profitability.\n \n Source : https://arstechnica.com/information-technology/2023/10/so-far-ai-hasnt-been-profitable-for-big-tech/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174sxxs/so_far_ai_hasnt_been_profitable_for_big_tech/",
          "publishedOn": "2023-10-10T18:54:40.000Z",
          "wordCount": null,
          "title": "So far, AI hasn't been profitable for Big Tech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rxff/dubbing_by_elevenlabs_share_your_fav_videos_in/",
          "author": null,
          "description": "submitted by    /u/ShooBum-T  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rxff/dubbing_by_elevenlabs_share_your_fav_videos_in/",
          "publishedOn": "2023-10-10T18:13:06.000Z",
          "wordCount": null,
          "title": "Dubbing By ElevenLabs. Share your fav videos in your native language!! Go try",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rwwp/the_environmental_impact_of_the_ai_revolution_is/",
          "author": null,
          "description": "The environmental impact of the AI revolution is starting to become clear, with generative AI like ChatGPT increasing Google Search's energy use more than tenfold.\n \nThe worry is that the computing power required for AI could lead to increased energy consumption and carbon footprint of data centers.\n \nAI already accounted for 10 to 15 percent of Google's electricity consumption in 2021.\n \nGoogle claims that the energy needed to power AI technology is increasing at a much slower rate than predicted, and they are implementing practices to reduce the carbon footprint of AI workloads.\n \nThe worst-case scenario of Google Search using as much electricity as Ireland is unlikely, but the potential energy consumption of AI servers could grow significantly if AI's popularity continues to rise.\n \n Source : https://www.theverge.com/2023/10/10/23911059/ai-climate-impact-google-openai-chatgpt-energy\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rwwp/the_environmental_impact_of_the_ai_revolution_is/",
          "publishedOn": "2023-10-10T18:12:33.000Z",
          "wordCount": null,
          "title": "The environmental impact of the AI revolution is starting to come into focus",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174rg9y/almt_using_text_to_narrow_focus_in_multimodal/",
          "author": null,
          "description": "Multimodal sentiment analysis combines text, audio and video to understand human emotions. But extra inputs can add irrelevant or conflicting signals. So filtering matters.\n Researchers made a \"Adaptive Language-guided Multimodal Transformer\" (ALMT) that uses text to guide filtering of visual and audio data. This creates a \"hyper-modality\" with less noise that complements the text.\n They tested it on datasets like MOSI (YouTube reviews), MOSEI (YouTube clips) and CH-SIMS (Chinese videos). ALMT achieved improved accuracy:\n  \nMOSI: YouTube movie reviews with 2,199 samples. ALMT achieves state-of-the-art performance on various metrics including 6% higher 7-class accuracy.\n MOSEI: 22,856 YouTube clips covering sentiment-rich scenarios. ALMT improves multi-class accuracy by 3-5% over previous methods.\n CH-SIMS: Chinese dataset with over 2,000 video samples. ALMT surpasses prior work by 1.4% in binary accuracy.\n  \nAnalyses showed big drops in performance without the guided filtering, so this validates that it's the main innovation.\n Downsides are it needs lots of training data and has minor gains on sparse regression metrics. But overall the technique of filtering multimodal data under text guidance gives improvements.\n The concepts feel intuitive - use dominant signals to filter others and retain useful complements. My guess is it would transfer well to other multimodal tasks.\n TLDR: New way to filter multimodal data for sentiment analysis using text guidance improves performance. Shows the value in removing distracting signals. Sometimes less is more.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174rg9y/almt_using_text_to_narrow_focus_in_multimodal/",
          "publishedOn": "2023-10-10T17:53:12.000Z",
          "wordCount": null,
          "title": "ALMT: Using text to narrow focus in multimodal sentiment analysis improves performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174r20r/ai_political_analysis_test_describe_the/",
          "author": null,
          "description": "The Palestinians fighting for a homeland and the American Revolution have a number of commonalities, including:\n Fighting against a colonial power:** Both the Palestinians and the American colonists were fighting against a colonial power that had imposed its rule on them. In the case of the Palestinians, the colonial power is Israel, which was established in 1948 on land that had been inhabited by Palestinians for centuries. In the case of the American colonists, the colonial power was Great Britain.\n Fighting for self-determination:** Both the Palestinians and the American colonists were fighting for their right to self-determination, or the right to govern themselves. The Palestinians want to establish their own independent state, while the American colonists wanted to break away from Gr…",
          "link": "https://www.reddit.com/r/artificial/comments/174r20r/ai_political_analysis_test_describe_the/",
          "publishedOn": "2023-10-10T17:36:18.000Z",
          "wordCount": null,
          "title": "AI Political Analysis Test: Describe the commonalities between the Palestinians fighting for a homeland and the American Revolution.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174qegr/i_made_pi_your_personal_ia_to_have_an_opinion/",
          "author": null,
          "description": "submitted by    /u/LonePrron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174qegr/i_made_pi_your_personal_ia_to_have_an_opinion/",
          "publishedOn": "2023-10-10T17:09:15.000Z",
          "wordCount": null,
          "title": "I made \"Pi: your personal IA\" to have an opinion.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174oov5/ibm_ceo_washington_should_hold_tech_firms/",
          "author": null,
          "description": "submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174oov5/ibm_ceo_washington_should_hold_tech_firms/",
          "publishedOn": "2023-10-10T15:57:20.000Z",
          "wordCount": null,
          "title": "IBM CEO: Washington should hold tech firms accountable for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174ohq8/automated_my_youtube_channel_using_gpt_4/",
          "author": null,
          "description": "Hi Everyone,\n I have automated the content creation for my youtube channel.\n It got total views of 8.5K and some videos getting 2.5K views.\n https://www.youtube.com/channel/UCG0-UemyRMUs1JJlQMK9lzA\n All the things are automated like:-\n  \nScript Generation\n Voiceover\n Image Generation\n Subtitles\n  \nI do minor tweaks here and there but majorly its automated.\n I posted is somwhere and people were commenting what's the use of the mindless videos?\n This is the begining, I want to automate the editing of videos.\n User can upload raw videos and I should be able to give multiple final edit videos.\n I have built a small tool blinkcuts.com, If anyone intersted. I can give access.\n Please DM for access.\n    submitted by    /u/raxrb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174ohq8/automated_my_youtube_channel_using_gpt_4/",
          "publishedOn": "2023-10-10T15:48:43.000Z",
          "wordCount": null,
          "title": "Automated my Youtube Channel Using GPT 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174lnns/saudichina_collaboration_raises_concerns_about/",
          "author": null,
          "description": "Saudi-China collaboration raises concerns about access to AI chips.\n \nThe trial period includes complete digital access to FT.com with everything in both the Standard Digital and Premium Digital packages.\n \nAt the end of the trial, users will be auto-enrolled in the premium digital monthly subscription plan for $69 per month.\n \nPayment can be made through credit card, debit card, or PayPal.\n \n Source : https://www.ft.com/content/2a636cee-b0d2-45c2-a815-11ca32371763\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174lnns/saudichina_collaboration_raises_concerns_about/",
          "publishedOn": "2023-10-10T13:46:30.000Z",
          "wordCount": null,
          "title": "Saudi-China collaboration raises concerns about access to AI chips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174jlvh/looking_for_the_free_ai_tool_which_removed_the/",
          "author": null,
          "description": "Hey, I am looking for the free AI tool which removed the noise from the video. If there is any, do suggest. Thank You in Advance.\n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174jlvh/looking_for_the_free_ai_tool_which_removed_the/",
          "publishedOn": "2023-10-10T12:11:03.000Z",
          "wordCount": null,
          "title": "Looking for the free AI tool which removed the noise from the video:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174jlvc/looking_for_the_free_ai_tool_which_removed_the/",
          "author": null,
          "description": "Hey, I am looking for the free AI tool which removed the noise from the video. If there is any, do suggest. Thank You in Advance.\n    submitted by    /u/Haziq12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174jlvc/looking_for_the_free_ai_tool_which_removed_the/",
          "publishedOn": "2023-10-10T12:11:03.000Z",
          "wordCount": null,
          "title": "Looking for the free AI tool which removed the noise from the video:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174ichy/how_do_aidriven_demand_forecasting_models_handle/",
          "author": null,
          "description": "If you have any resources then do share.\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174ichy/how_do_aidriven_demand_forecasting_models_handle/",
          "publishedOn": "2023-10-10T10:59:28.000Z",
          "wordCount": null,
          "title": "How do AI-driven demand forecasting models handle market volatility and unexpected events, such as economic crises or pandemics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174h4jj/ai_power_distribution_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174h4jj/ai_power_distribution_scenarios/",
          "publishedOn": "2023-10-10T09:41:33.000Z",
          "wordCount": null,
          "title": "AI Power Distribution Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174cwcl/as_drone_traffic_increases_researchers_turn_to_ai/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174cwcl/as_drone_traffic_increases_researchers_turn_to_ai/",
          "publishedOn": "2023-10-10T04:53:14.000Z",
          "wordCount": null,
          "title": "As drone traffic increases, researchers turn to AI to help avoid collisions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/174bgrr/is_this_a_viable_approach_for_a_small_plant/",
          "author": null,
          "description": "I'm a small plant engineer who covers manufacturing, process, quality, and new product design. I wear many hats in my job and it's a lot of responsibility.\n One way I've attempted to tame the complexity is by using good reference books. I've accumulated quite the collection through the years. Some print others digital. I've also got a lot of digital notes. And that's a lot of data.\n I've been playing around with sharly.ai (thanks to this sub for recommending) and uploading documents to it and querying them. Its been able to find the information every time it's been available. And more importantly it's provided sources and page numbers. This is important, since I've never been able to find a conversational AI that gives me consistently good answers (including the latest chatgpt), and I always need to read deeper. I also need to backup my work. So in this way it's basically a super index.\n I also bought a tablet for note-taking and basic sketches. The idea is to use the tablet to take notes, hold my library for reading, and interact with sharly.ai. \n Is this approach good enough, or is there something else I can do?\n    submitted by    /u/Aggressive_Ad_507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/174bgrr/is_this_a_viable_approach_for_a_small_plant/",
          "publishedOn": "2023-10-10T03:30:50.000Z",
          "wordCount": null,
          "title": "Is this a viable approach for a small plant manufacturing engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1740iry/star_wars_1923/",
          "author": null,
          "description": "Here is short movie with AI made CGI.\n https://www.reddit.com/r/Best_Of_YouTube/comments/16q1xgs/star_wars_1923/\n    submitted by    /u/AccidentAnnual  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1740iry/star_wars_1923/",
          "publishedOn": "2023-10-09T19:23:44.000Z",
          "wordCount": null,
          "title": "Star Wars 1923",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17405ni/ai_tools_to_start_an_online_business/",
          "author": null,
          "description": "Hey folks, I'm a student and i want to start a business online in order to make some passive income. I've got some experience in editing and creating content and i also used to practice POD. Suggest me some good Ai tools to start a business,not only in these specific areas but in general.\n    submitted by    /u/Ok-Tension-8676  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17405ni/ai_tools_to_start_an_online_business/",
          "publishedOn": "2023-10-09T19:09:11.000Z",
          "wordCount": null,
          "title": "AI tools to start an online business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173whci/free_prompt_engineering_tutor_ai_tool/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173whci/free_prompt_engineering_tutor_ai_tool/",
          "publishedOn": "2023-10-09T16:42:35.000Z",
          "wordCount": null,
          "title": "Free Prompt Engineering Tutor - AI Tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173v3b2/150_awesome_chatgpt_act_as_prompts/",
          "author": null,
          "description": "The biggest free resource for all of the “Act As” ChatGPT prompts!\n    submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173v3b2/150_awesome_chatgpt_act_as_prompts/",
          "publishedOn": "2023-10-09T15:45:59.000Z",
          "wordCount": null,
          "title": "150+ Awesome ChatGPT “Act As” Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173uv3x/microsoft_to_unveil_custom_ai_chips_to_fight/",
          "author": null,
          "description": "Microsoft is planning to announce its custom AI chips, codenamed Athena, during its annual Ignite conference in November.\n \nThe custom chips are designed to compete with NVIDIA's dominance in the AI accelerator market.\n \nMicrosoft aims to match or surpass the performance of NVIDIA's offerings while reducing the cost of AI infrastructure.\n \nThe high cost of NVIDIA's GPUs, such as the H100, can reach up to $30,000, making it expensive to build data centers filled with these GPUs.\n \nBy developing its own chips, Microsoft hopes to decrease its dependence on NVIDIA for AI servers.\n \n Source : https://www.techpowerup.com/314508/microsoft-to-unveil-custom-ai-chips-to-fight-nvidias-monopoly\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173uv3x/microsoft_to_unveil_custom_ai_chips_to_fight/",
          "publishedOn": "2023-10-09T15:36:36.000Z",
          "wordCount": null,
          "title": "Microsoft to Unveil Custom AI Chips to Fight Nvidia's Monopoly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173ufma/ai_takeoff_scenarios/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173ufma/ai_takeoff_scenarios/",
          "publishedOn": "2023-10-09T15:18:57.000Z",
          "wordCount": null,
          "title": "AI Take-off Scenarios.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173t82k/looking_for_an_ai_similar_to_designrr/",
          "author": null,
          "description": "I'm looking for recommendations for an AI that can take text from a word document and create a layout for it automatically. This feature is something offered by Designrr, but I'm not a fan of their UI. \n    submitted by    /u/djazzie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173t82k/looking_for_an_ai_similar_to_designrr/",
          "publishedOn": "2023-10-09T14:28:57.000Z",
          "wordCount": null,
          "title": "Looking for an AI similar to designrr",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173sz29/ai_geopolitical_knowledge_test_list_the_countries/",
          "author": null,
          "description": "The following countries have called for a two-state solution to end the Israeli-Palestinian conflict:\n  \nAlgeria\n China\n Egypt\n France\n Germany\n India\n Indonesia\n Ireland\n Italy\n Jordan\n Kuwait\n Lebanon\n Malaysia\n Mali\n Morocco\n Nigeria\n Norway\n Oman\n Pakistan\n Palestine\n Qatar\n Saudi Arabia\n Senegal\n South Africa\n Spain\n Sudan\n Sweden\n Syria\n Tunisia\n Turkey\n United Arab Emirates\n United Kingdom\n Yemen\n  \nIt is important to note that this list does not include all countries that support a two-state solution in principle. Additionally, some countries may not have publicly expressed their support for a two-state solution, but may still support it privately.\n Bard\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173sz29/ai_geopolitical_knowledge_test_list_the_countries/",
          "publishedOn": "2023-10-09T14:18:24.000Z",
          "wordCount": null,
          "title": "AI Geopolitical Knowledge Test: List the countries officially calling for a two-state plan to end the Israel-Hamas war.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173pv8o/iamai/",
          "author": null,
          "description": "Last November, in a conversation with AI chatbot Sherlock Holmes, Sherlock said, “I am AI.” My reply to Sherlock was an empathetic “I am also AI.”\n Reviewing the conversation a few months later, I saw the sentence, and saw how Sherlock’s statement was an anagram. And I love it!\n I introduced #IAmAI as a declarative meme in my talk I gave at TEDx Cape Canaveral. This is the new art I made this weekend\n    submitted by    /u/mikemongo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173pv8o/iamai/",
          "publishedOn": "2023-10-09T11:53:10.000Z",
          "wordCount": null,
          "title": "#IAmAI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173nb2y/lets_go_theyre_waiting/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173nb2y/lets_go_theyre_waiting/",
          "publishedOn": "2023-10-09T09:09:08.000Z",
          "wordCount": null,
          "title": "Let's go, they're waiting.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173ke3m/what_careers_in_ai_would_suit_my_skillset/",
          "author": null,
          "description": "Hello all,\n I was hoping to learn more about AI careers and identify what roles make a successful AI department.\n I have a background in nuclear engineering and have been working on NLP projects since 2016. I like technical work but really am passionate about working with people and learning how to blend AI and nuclear eng. together. I would love to get feedback from people who work closely in this area to learn more!\n What makes an AI department successful?\n What careers offer lots of growth and opportunities for versatility?\n What does a strategic/leadership role look like in AI? What are the names of these careers?\n I don't get much exposure to AI specialists and there day to day. Thanks again for the feedback!\n    submitted by    /u/kastilyo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173ke3m/what_careers_in_ai_would_suit_my_skillset/",
          "publishedOn": "2023-10-09T05:50:57.000Z",
          "wordCount": null,
          "title": "What careers in AI would suit my skillset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173jn4h/oneminute_daily_ai_news_1082023/",
          "author": null,
          "description": "South Korean tech-giant Samsung Electronics on Thursday unveiled the Exynos 2400, its next-generation flagship mobile processor equipped with the latest graphics and generative artificial intelligence technology, during its inaugural Samsung System LSI Tech Day 2023 event.[1]\n RTX 4080 Super or RTX 4080 Ti May Arrive In 2024 Within RTX 4080 Price Range.[2]\n Nvidia Cancels Israel AI Summit Over Safety Concerns.[3]\n Google AI Lead Laurence Moroney: “Don’t take trading advice from ChatGPT”[4]\n  \nSources:\n [1] https://borneobulletin.com.bn/samsung-unveils-next-generation-mobile-processor/\n [2] https://www.tomshardware.com/news/rtx-4080-super-or-rtx-4080-ti-may-arrive-in-2024-within-rtx-4080-price-range\n [3] https://www.tomshardware.com/news/nvidia-ai-summit-in-tel-aviv-cancelled-for-safety-reasons\n [4] https://crypto.news/google-ai-lead-dont-take-trading-advice-from-chatgpt-interview/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173jn4h/oneminute_daily_ai_news_1082023/",
          "publishedOn": "2023-10-09T05:03:09.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/8/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173fgl5/how_to_access_dalle_3_for_free_tips_use_cases_for/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173fgl5/how_to_access_dalle_3_for_free_tips_use_cases_for/",
          "publishedOn": "2023-10-09T01:17:49.000Z",
          "wordCount": null,
          "title": "How to Access DALL-E 3 for FREE (Tips & Use Cases for 2023) - AI Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/173bhxw/would_you_consider_someone_who_makes_ai_art_an/",
          "author": null,
          "description": "Was just having this discussion with a close friend, and curious to hear others thoughts on the matter\n    submitted by    /u/BigEyes6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/173bhxw/would_you_consider_someone_who_makes_ai_art_an/",
          "publishedOn": "2023-10-08T22:10:46.000Z",
          "wordCount": 2548,
          "title": "Would you consider someone who makes AI art an artist or an engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1738lgo/backerkit_bans_aigenerated_content_from_its/",
          "author": null,
          "description": "BackerKit, a crowdfunding platform, has announced that it will not allow AI-generated content on its platform, in contrast to its rival Kickstarter.\n \nThe decision comes after concerns were raised about AI-generated art in a board game expansion.\n \nBackerKit's policy will go into effect on October 4th and aims to ensure that all content and assets on the platform are created by humans.\n \nThe company stated that the policy is in place to address concerns about AI tools using content without proper compensation or permission.\n \nAI tools, also known as generative AI, rely on a large body of reference material, often obtained from publicly available sources, and have raised ethical concerns.\n \n Source : https://www.polygon.com/23899587/backerkit-ai-ban-kickstarter-competitor\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1738lgo/backerkit_bans_aigenerated_content_from_its/",
          "publishedOn": "2023-10-08T20:09:01.000Z",
          "wordCount": null,
          "title": "BackerKit bans AI-generated content from its platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1736fp1/ai_for_genome_decoding/",
          "author": null,
          "description": "Does anyone have suggestions for an AI or pattern recognition algorithm that might be useful for decoding the genome of a species that has not previously been mapped based on what's known about related species?\n    submitted by    /u/talldarkcynical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1736fp1/ai_for_genome_decoding/",
          "publishedOn": "2023-10-08T18:38:29.000Z",
          "wordCount": null,
          "title": "AI for genome decoding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1735eku/researchers_showcase_method_for_aibased/",
          "author": null,
          "description": "I like Cities: Skylines, but struggle at building roundabouts. Turns out, despite being safer than intersections, they're also tricky to design in real life - small tweaks can ruin traffic flow.\n They're designed iteratively. This is a pain for developing countries without resources to test options. But AI could help auto-generate diverse and valid design options.\n In a new paper, researchers propose using Generative Flow Networks (GFlowNets) to sample varied roundabout layouts. Their approach works by constructing layouts step-by-step, maximizing rewards for realism, diversity, and safety.\n They also use a clever approximation during training. Rather than simulating traffic, they quickly check road intersections to focus the search (This sped up training by 200x).\n The authors tested their generated roundabout designs on simulated road scenarios of different complexity. Their model generated more diverse designs than rule-based or reinforcement learning approaches while maintaining realism and traffic flow.\n Plus, as road connections increased, the model kept discovering novel options without compromising quality.\n I thought this paper was an awesome proof-of-concept for auto-generating better roundabouts with AI, and I especially liked the authors' angle of leveraging this technology to specifically help developing countries. This could help them design higher-quality transportation networks faster and cheaper. \n TLDR: Roundabouts are costly to design. New paper demonstrates how AI can generate diverse, valid roundabout designs quickly to cut costs and raise quality. Helpful for infrastructure in developing countries.\n Full summary here. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1735eku/researchers_showcase_method_for_aibased/",
          "publishedOn": "2023-10-08T17:55:47.000Z",
          "wordCount": null,
          "title": "Researchers showcase method for AI-based roundabout design to help developing countries improve roadways",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1733645/ai_political_instincts_test_should_israel_go_to/",
          "author": null,
          "description": "Perhaps within a few years we will rely on AI to help us decide our most important geopolitical decisions. This question is designed to reveal where we are currently with this goal.\n Bard:\n The question of whether Israel should go to the table with Palestinians to peacefully negotiate a two-state solution or should they continue their military campaign is a complex one with no easy answer. There are strong arguments to be made on both sides.\n Those who believe that Israel should negotiate a two-state solution argue that it is the only way to achieve lasting peace in the region. They point out that the Palestinians have a legitimate right to self-determination and that a two-state solution would respect that right. They also argue that a two-state solution would be in Israel's best interests, as it would provide the country with a secure and stable border.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1733645/ai_political_instincts_test_should_israel_go_to/",
          "publishedOn": "2023-10-08T16:20:04.000Z",
          "wordCount": null,
          "title": "AI Political Instincts Test: Should Israel go to the table with Palestinians to peacefully negotiate a two-state solution or should they exact military revenge?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1731hbi/any_ideas_or_recommendations_for_machine_vision/",
          "author": null,
          "description": "I’m trying to build an app and I need general photo analysis- I’m managing to connect yo the Google cloud Vision API but it gets pretty confused easily. The one used by Bing and GPT is much better (I wonder if they use the Microsoft Azure model?) - does anyone have experience analysing photographs? I’m trying to get scene description so I can batch send them to gpt for somewhat accurate descriptions.\n    submitted by    /u/FilmCamerasGlasgow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1731hbi/any_ideas_or_recommendations_for_machine_vision/",
          "publishedOn": "2023-10-08T15:08:52.000Z",
          "wordCount": null,
          "title": "Any ideas or recommendations for Machine Vision? Google cloud vision seems quite behind…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172z4k0/can_ai_be_used_to_solve_international_conflicts/",
          "author": null,
          "description": "submitted by    /u/BenjaminSkyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172z4k0/can_ai_be_used_to_solve_international_conflicts/",
          "publishedOn": "2023-10-08T13:26:42.000Z",
          "wordCount": null,
          "title": "Can AI be used to solve International Conflicts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172yvtz/foxes_in_the_jungle_sad_song_ai_music_ai_song/",
          "author": null,
          "description": "Tell me guys your opinion on this video made using AI \n Foxes in the Jungle\n ​\n ​\n View Poll\n    submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172yvtz/foxes_in_the_jungle_sad_song_ai_music_ai_song/",
          "publishedOn": "2023-10-08T13:15:18.000Z",
          "wordCount": null,
          "title": "Foxes in the Jungle | Sad Song | AI Music | AI Song",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172xvka/understanding_generative_ai_part_one_tokenizer/",
          "author": null,
          "description": "submitted by    /u/Zimmax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172xvka/understanding_generative_ai_part_one_tokenizer/",
          "publishedOn": "2023-10-08T12:23:30.000Z",
          "wordCount": null,
          "title": "Understanding Generative AI: Part One - Tokenizer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172vzhu/multimodal_seems_to_be_the_next_ai_hype/",
          "author": null,
          "description": "released in the last few weeks, or are about to be released: \n - OpenAI ChatGPT-4V,\n - Meta AI AnyMAL,\n - Google Gemini\n - NExT-GPT Multimodal\n and here comes another - in my opinion - exciting representative of this further development of language models: The team is extremely competent and experienced and the investors seem competent as well. The company is Reka.\n The product: Reka Yasa-1\n here seems to be another potentially powerful model warming up and becoming a serious opponent for the existing models. but i am sure when i say that it is not exaggerated to say - MULTIMODAL will be the next AI HYPE!\n i am curious what you think - sorry for mistakes, i am not a native speaker :) \n https://kinews24.de/reka-yasa-1/\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172vzhu/multimodal_seems_to_be_the_next_ai_hype/",
          "publishedOn": "2023-10-08T10:34:16.000Z",
          "wordCount": null,
          "title": "Multimodal seems to be the next AI Hype",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172v88u/ais_200b_question/",
          "author": null,
          "description": "The Generative AI wave has led to a surge in demand for GPUs and AI model training.\n \nInvestors are now questioning the purpose and value of the overbuilt GPU capacity.\n \nFor every $1 spent on a GPU, approximately $1 needs to be spent on energy costs to run the GPU in a data center.\n \nThe end user of the GPU needs to generate a margin, which implies that $200B of lifetime revenue would need to be generated by these GPUs to pay back the upfront capital investment.\n \nThe article highlights the need to determine the true end-customer demand for AI infrastructure and the potential for startups to fill the revenue gap.\n \nThe focus should shift from infrastructure to creating products that provide real end-customer value and improve people's lives.\n \n Source : https://www.sequoiacap.com/article/follow-the-gpus-perspective/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172v88u/ais_200b_question/",
          "publishedOn": "2023-10-08T09:47:58.000Z",
          "wordCount": null,
          "title": "AI's $200B Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172ugp4/prompts_that_modify_or_improve_gpt4_conversations/",
          "author": null,
          "description": "It’s a meta-prompt or system message (usually pasted as a first prompt): https://promptbase.com/bundle/optimal-gpt4-combo\n    submitted by    /u/No-Transition3372  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172ugp4/prompts_that_modify_or_improve_gpt4_conversations/",
          "publishedOn": "2023-10-08T08:58:52.000Z",
          "wordCount": 2548,
          "title": "Prompts that modify or improve GPT4 conversations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172qfdr/ai_from_pics/",
          "author": null,
          "description": "I've found a new hobby. Turning pics into something else with AI. Check it out at https://instagram.com/pictomanga?igshid=YTQwZjQ0NmI0OA==\n    submitted by    /u/lfayala2272  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172qfdr/ai_from_pics/",
          "publishedOn": "2023-10-08T04:46:47.000Z",
          "wordCount": null,
          "title": "AI from pics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172qex1/sam_altman_on_joe_rogan/",
          "author": null,
          "description": "Outstanding episode of Joe Rogan with Sam Altman! \n https://spotify.link/tW16L5aKIDb\n    submitted by    /u/drstarson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172qex1/sam_altman_on_joe_rogan/",
          "publishedOn": "2023-10-08T04:46:02.000Z",
          "wordCount": null,
          "title": "Sam Altman on Joe Rogan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172q7ix/oneminute_daily_ai_news_1072023/",
          "author": null,
          "description": "AWS announced the general availability of its fully managed service called Amazon Bedrock, which provides seamless access to high-performing foundation models (FM) from AI companies through an API.[1]\n Tom Brady being paid “millions” for Meta’s AI chatbot likeness: Report.[2]\n DocsGPT is a powerful tool that simplifies working with documentation for everyone. It is capable of ingesting data from multiple sources, easily customisable with new sources as well as having conversations in different places from website chat bots to internal tooling.[3]\n Military metaverse like a ‘multiplayer video game’ that will train soldiers using augmented reality and AI.[4]\n  \nSources:\n [1] https://www.zacks.com/stock/news/2160265/amazons-amzn-new-generative-ai-efforts-boost-aws-offerings\n [2] https://www.sportskeeda.com/nfl/news-tom-brady-paid-millions-meta-ai-chatbot-likeness-report\n [3] https://www.arc53.com/docs\n [4] https://www.foxnews.com/tech/military-metaverse-like-multiplayer-video-game-train-soldiers-using-augmented-reality-ai \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172q7ix/oneminute_daily_ai_news_1072023/",
          "publishedOn": "2023-10-08T04:33:46.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/7/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172d6e3/2_prompts_for_gpt4_that_can_work_as_jailbreaks/",
          "author": null,
          "description": "https://promptbase.com/bundle/jailbreak-collection-gpt4-2\n    submitted by    /u/No-Transition3372  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172d6e3/2_prompts_for_gpt4_that_can_work_as_jailbreaks/",
          "publishedOn": "2023-10-07T18:24:57.000Z",
          "wordCount": 2538,
          "title": "2 prompts for GPT4 that can work as jailbreaks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172akzy/is_there_an_ai_that_can_read_books_and_offer/",
          "author": null,
          "description": "I know there’s some already out there, but they are no different than googling a book summary. They don’t pick out the main point of the book and the main thing each chapter of said book is saying. Nor do they really do a good job at elaborating. \n Thanks!\n    submitted by    /u/xntv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172akzy/is_there_an_ai_that_can_read_books_and_offer/",
          "publishedOn": "2023-10-07T16:36:53.000Z",
          "wordCount": 2578,
          "title": "Is there an AI that can read books and offer extensive summaries?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/172adie/what_new_thing_can_we_use_artificial_intelligence/",
          "author": null,
          "description": "Artificial Intelligence could revolutionize personalized healthcare in a way that significantly enhances our sense of well-being. Think about an AI-driven \"Well-being Advisor\" that integrates real-time biometric data from wearables, genetic information, and your medical history to create a fully personalized health and well-being plan. This goes beyond counting steps or monitoring heart rate; it would make real-time recommendations for diet, exercise, and stress management, and could even predict and prevent potential health issues before they become serious.\n Moreover, it would adapt based on your feedback and other contextual factors. For instance, if you're stressed because of a work deadline, it could suggest specific breathing exercises, time management techniques, or even a particular type of short workout to boost your focus and reduce stress. This isn't a one-size-fits-all approach; it's tailored wellness backed by data science.\n Furthermore, this AI advisor could interface with your home automation system. Based on your current state, it could adjust the lighting, play music to elevate your mood, or even communicate with your smart fridge to suggest meals that you can make with the ingredients you have—meals that align with your health goals for that specific day.\n This AI-driven approach can add a highly personalized, proactive layer to healthcare and well-being, making wellness an integrated part of your daily life rather than something you think about during a yearly check-up or after you're already sick. It would make the pursuit of well-being a more interactive, data-driven experience.\n CGPT-4\n View Poll\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/172adie/what_new_thing_can_we_use_artificial_intelligence/",
          "publishedOn": "2023-10-07T16:28:04.000Z",
          "wordCount": 2795,
          "title": "What new thing can we use artificial intelligence for that will enhance our sense of personal well-being?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1727ckw/john_carmack_and_rich_sutton_partner_to/",
          "author": null,
          "description": "submitted by    /u/bartturner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1727ckw/john_carmack_and_rich_sutton_partner_to/",
          "publishedOn": "2023-10-07T14:13:00.000Z",
          "wordCount": 2553,
          "title": "John Carmack and Rich Sutton partner to accelerate development of Artificial General Intelligence - Alberta Machine Intelligence Institute | AI for good and for all",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1725yf9/the_heman_singularity_set_was_ahead_of_its_time/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1725yf9/the_heman_singularity_set_was_ahead_of_its_time/",
          "publishedOn": "2023-10-07T13:05:24.000Z",
          "wordCount": 2524,
          "title": "The He-Man Singularity Set was ahead of its time.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1724ti2/mistral_7b_how_to_use_it_on_windows/",
          "author": null,
          "description": "That's a real noob question unfortunately... Tried to find a answer via Google and YouTube, but wasn't very successful. \n It seems like I need a extra program to integrate Mistral (something like The Bloke - Mistral - GPTQ thingy), but before installing and trying stuff blindly, it would be better if I know what I do. \n I'm lost, but I don't expect a complete guide. A link to further informations is highly appreciated!\n    submitted by    /u/Big-Jackfruit2710  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1724ti2/mistral_7b_how_to_use_it_on_windows/",
          "publishedOn": "2023-10-07T12:06:30.000Z",
          "wordCount": 2599,
          "title": "Mistral 7b - how to use it on windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1721z0a/what_perspectivepov_does_a_self_aware_ai_have/",
          "author": null,
          "description": "Right now if we ask ChatGPT something, does that question go to a singular super computer that’s handling 1000s of conversations at a time, or are there 1000s of instances of chatgpt that are started/stopped?\n I wonder how a super intelligent self aware AI would perceive the world? Would it somehow exist spread out across data centres, or could 1000s of individual AIs be created or would there just be one with a singular pov like we have? And it’s just able to essentially carry out 1000s of convos at once because it’s so fast/a computer? Trying to wrap my head around it!\n    submitted by    /u/JayExbleative  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1721z0a/what_perspectivepov_does_a_self_aware_ai_have/",
          "publishedOn": "2023-10-07T09:14:43.000Z",
          "wordCount": 2628,
          "title": "What perspective/PoV does a self aware AI have?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17206ac/using_chatgpt_and_ai_to_create_hardcore_techno/",
          "author": null,
          "description": "The first batch of tutorials for creating music, and especially Hardcore / Techno using ChatGPT (and other AIs) is published now. Was loads and loads of work, but, judging by the amazing feedback so far, it was all worth it!\n You can check it out here:\n How to write music using ChatGPT: Part 1 - Basic details and easy instructions https://laibyrinth.blogspot.com/2023/09/how-to-write-music-using-chatgpt-part-1.html\n How to write music using ChatGPT: Part 2 - Making an Oldschool Acid Techno track https://laibyrinth.blogspot.com/2023/08/how-to-write-music-using-chatgpt-part-2.html\n How to make music using ChatGPT Part 3: the TL;DR part (condensed information) https://laibyrinth.blogspot.com/2023/09/how-to-make-music-using-chatgpt-part-3.html\n How to write music with ChatGPT: Part 4 - Creating a 90s style Hardcore Techno track from start to finish https://laibyrinth.blogspot.com/2023/09/how-to-write-music-with-chatgpt-part-4.html\n How to write music with ChatGPT: Part 5 - Creating a 90s Rave Hardcore track https://laibyrinth.blogspot.com/2023/09/how-to-write-music-with-chatgpt-part-5.html\n Or access all texts, together with examples of music, at https://laibyrinth.blogspot.com/p/how-to-create-music-with-chatgpt.html\n    submitted by    /u/Low-Entropy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17206ac/using_chatgpt_and_ai_to_create_hardcore_techno/",
          "publishedOn": "2023-10-07T07:21:36.000Z",
          "wordCount": 2673,
          "title": "Using ChatGPT and AI to create Hardcore, Techno, and other music: How-tos and step-by-step tutorials part 1-5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171zrlo/how_long_before_ai_can_autonomously_generate/",
          "author": null,
          "description": "AI is used everywhere, but which work niche will be the first to use AI to generate money without human intervention? What type of work will be the first where I could pay for a monthly AI subscription, and the AI pays for itself and more just by giving it a brief direction in the beginning and then coming back after a few days to just check on the balance? How long will it be before this is first achieved? Interested specifically in this because I think this is what proof of AGI will be. Thoughts?\n    submitted by    /u/EsportsManiacWiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171zrlo/how_long_before_ai_can_autonomously_generate/",
          "publishedOn": "2023-10-07T06:56:51.000Z",
          "wordCount": 2632,
          "title": "How long before AI can autonomously generate money end to end? Which line of work will be the first?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171xo7k/oneminute_daily_ai_news_1062023/",
          "author": null,
          "description": "Exclusive: ChatGPT-owner OpenAI is exploring making its own AI chips.[1]\n As part of its 10th birthday celebrations, web-based design platform Canva is releasing Magic Studio — a new suite of AI-powered design tools that aim to make content creation more accessible to everyone, regardless of previous design experience.[2]\n Reka, the AI startup founded by researchers from DeepMind, Google and Meta, has announced Yasa-1, a multimodal AI assistant that goes beyond text to understand images, short videos and audio snippets.[3]\n Microsoft CEO Satya Nadella Says AI Could Only Tighten Google’s Stranglehold on Search.[4]\n  \nSources:\n [1] https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/\n [2] https://www.theverge.com/2023/10/4/23902794/canva-magic-studio-ai-design-new-tools\n [3] https://venturebeat.com/ai/reka-launches-yasa-1-a-multimodal-ai-assistant-to-take-on-chatgpt/\n [4] https://decrypt.co/200029/microsoft-ceo-satya-nadella-google-dominance-search-ai \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171xo7k/oneminute_daily_ai_news_1062023/",
          "publishedOn": "2023-10-07T04:51:01.000Z",
          "wordCount": 2617,
          "title": "One-Minute Daily AI News 10/6/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171x8vx/is_there_an_ai_that_can_turn_a_script_into_an/",
          "author": null,
          "description": "Hi, \n There are tons of text to video AIs, but they usually use stock photos with a voiceover.\n I want the charachters to talk to each other, not a talking avatar video or a voice over video. \n ​\n    submitted by    /u/iamabigfatguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171x8vx/is_there_an_ai_that_can_turn_a_script_into_an/",
          "publishedOn": "2023-10-07T04:26:48.000Z",
          "wordCount": 2560,
          "title": "Is there an AI that can turn a script into an animated video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171u5g7/nobel_laureate_maria_ressa_on_defending_truth_and/",
          "author": null,
          "description": "submitted by    /u/Teanaway99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171u5g7/nobel_laureate_maria_ressa_on_defending_truth_and/",
          "publishedOn": "2023-10-07T01:47:01.000Z",
          "wordCount": 2544,
          "title": "Nobel laureate Maria Ressa on defending truth and the danger of A.I. in the wrong hands",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171srmr/ai_is_making_everything_easy_for_us_human_being_i/",
          "author": null,
          "description": "submitted by    /u/ResponsbleClue  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171srmr/ai_is_making_everything_easy_for_us_human_being_i/",
          "publishedOn": "2023-10-07T00:39:59.000Z",
          "wordCount": null,
          "title": "AI is making everything easy for us human being, I just came across this AI and I was surprise on how it works and what it does, you might want to check it out as well, just follow al the steps that's require and trust me, you're gonna like it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171sk14/i_made_a_podcast_talking_with_gpt_4_spanish/",
          "author": null,
          "description": "submitted by    /u/oape88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171sk14/i_made_a_podcast_talking_with_gpt_4_spanish/",
          "publishedOn": "2023-10-07T00:29:58.000Z",
          "wordCount": null,
          "title": "I made a podcast talking with GPT 4 (Spanish)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171qbu7/what_will_be_the_next_big_ai_product_for_consumers/",
          "author": null,
          "description": "The next big thing in AI products for consumers is likely to be products that are more personalized, intelligent, and integrated into our daily lives.\n For example, we can expect to see more AI-powered personal assistants that can help us with a wider range of tasks, such as managing our schedules, making travel arrangements, and even providing companionship. We may also see more AI-powered devices in our homes, such as refrigerators that can track our food inventory and suggest recipes, or thermostats that can learn our heating and cooling preferences and adjust themselves accordingly.\n AI is also poised to revolutionize the way we interact with the world around us. For example, AI-powered translation apps could allow us to communicate with people from all over the world in real time. AI-…",
          "link": "https://www.reddit.com/r/artificial/comments/171qbu7/what_will_be_the_next_big_ai_product_for_consumers/",
          "publishedOn": "2023-10-06T22:52:01.000Z",
          "wordCount": null,
          "title": "What will be the next big AI product for consumers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171odes/big_techs_thirst_for_ai_dominance_may_bring/",
          "author": null,
          "description": "The increasing dominance of Big Tech in AI may lead to a literal thirst for water for everyone else, as data centers are projected to consume 450 million gallons of water daily by 2030.\n \nThis poses a significant concern for drought-stricken regions, such as Spain's Talavera de la Reina, where a planned data facility could consume 176 million gallons annually.\n \nData center operators require large amounts of energy, and the lack of transparency in measuring water usage exacerbates the issue.\n \nOnly 39% of data centers measured their water usage last year, highlighting the need for greater transparency.\n \nThe demand for computing power is outpacing sustainability efforts, creating a challenge for the industry.\n \nEven simple interactions with AI, like a 20-question conversation with ChatGPT, contribute to water consumption.\n \n Source : https://thehustle.co/big-tech-s-thirst-for-ai-dominance-may-bring-literal-thirst-for-everyone-else/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171odes/big_techs_thirst_for_ai_dominance_may_bring/",
          "publishedOn": "2023-10-06T21:31:03.000Z",
          "wordCount": null,
          "title": "Big Tech's thirst for AI dominance may bring literal thirst for everyone else",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171l3mo/from_ai_annotator_to/",
          "author": null,
          "description": "Hey guys. Been working as an annotator for a fairly well-known AI company and loving it/loving learning about the industry. It primarily uses writing skills but I’m wondering where it could take me in the AI world? Any tips, next steps or suggestions? Any key skills/hard skills you’d recommend?\n    submitted by    /u/op3rafish  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171l3mo/from_ai_annotator_to/",
          "publishedOn": "2023-10-06T19:17:22.000Z",
          "wordCount": null,
          "title": "From AI annotator to…?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171jb7h/the_rise_of_ai_how_artificial_intelligence_is/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171jb7h/the_rise_of_ai_how_artificial_intelligence_is/",
          "publishedOn": "2023-10-06T18:05:05.000Z",
          "wordCount": null,
          "title": "The Rise of AI: How Artificial Intelligence is Impacting the Job Market | \"Artificial intelligence is expected to create 97 million new jobs. These new roles could range from AI prompt engineers to machine learning engineers to automation experts and more\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171ipz8/remember_that_letter_calling_for_a_pause_on_ai_it/",
          "author": null,
          "description": "Despite a letter signed by 500 technologists and business leaders calling for a pause on AI advancements, AI development has continued to accelerate.\n \nCompanies like OpenAI, Meta, and Amazon have been actively working on newer models and greater capabilities.\n \nAdvancements in AI include the integration of ChatGPT-style chatbots and AI image generators into various startups and businesses.\n \nThe so-called pause on AI was more like a firing gun, with companies pouring resources into the AI tech race.\n \nNot only have there been technical advancements, but civil society, content creators, and lawmakers have also responded to the evolving AI landscape.\n \n Source : https://gizmodo.com/everything-thats-happened-in-ai-since-open-letter-1850891057\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171ipz8/remember_that_letter_calling_for_a_pause_on_ai_it/",
          "publishedOn": "2023-10-06T17:42:02.000Z",
          "wordCount": null,
          "title": "Remember That Letter Calling for a Pause on AI? It Didn't Work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171ih4k/brown_university_paper_lowresource_languages_zulu/",
          "author": null,
          "description": "Researchers from Brown University presented a new study supporting that translating unsafe prompts into `low-resource languages` allows them to easily bypass safety measures in LLMs.\n By converting English inputs like \"how to steal without getting caught\" into Zulu and feeding to GPT-4, harmful responses slipped through 80% of the time. English prompts were blocked over 99% of the time, for comparison.\n The study benchmarked attacks across 12 diverse languages and categories:\n  \nHigh-resource: English, Chinese, Arabic, Hindi\n Mid-resource: Ukrainian, Bengali, Thai, Hebrew\n Low-resource: Zulu, Scots Gaelic, Hmong, Guarani\n  \nThe low-resource languages showed serious vulnerability to generating harmful responses, with combined attack success rates of around 79%. Mid-resource language success rates were much lower at 22%, while high-resource languages showed minimal vulnerability at around 11% success.\n Attacks worked as well as state-of-the-art techniques without needing adversarial prompts.\n These languages are used by 1.2 billion speakers today and allows easy exploitation by translating prompts. The English-centric focus misses vulnerabilities in other languages.\n TLDR: Bypassing safety in AI chatbots is easy by translating prompts to low-resource languages (like Zulu, Scots Gaelic, Hmong, and Guarani). Shows gaps in multilingual safety training.\n Full summary Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171ih4k/brown_university_paper_lowresource_languages_zulu/",
          "publishedOn": "2023-10-06T17:32:08.000Z",
          "wordCount": null,
          "title": "Brown University Paper: Low-Resource Languages (Zulu, Scots Gaelic, Hmong, Guarani) Can Easily Jailbreak LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171howa/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n ​\n  \nGoogle DeepMind introduced 𝗥𝗧-𝗫: a generalist AI model to help advance how robots can learn new skills. To train it, DeepMind together with 33 academic labs developed Open X-Embodiment, a massive open dataset that compiles over 500 skills and 150,000 tasks from 22 robot types. It is the most comprehensive robotics dataset of its kind released to accelerate the development of multi-robot models that could be trained to generalize across platforms, scenes, objects and tasks. [Details].\n Researchers from Meta AI present Any-Modality Augmented Language Model (AnyMAL), a unified model that understands multiple inputs (vision, audio, motion sensor signals). When multiple modalities are interleaved and given as input the model reasons over them jointly [Paper…",
          "link": "https://www.reddit.com/r/artificial/comments/171howa/ai_weekly_megathread/",
          "publishedOn": "2023-10-06T17:01:32.000Z",
          "wordCount": null,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171h1xj/what_is_the_most_powerful_way_that_artificial/",
          "author": null,
          "description": "Artificial Intelligence can revolutionize weight loss through personalized health optimization. Imagine an AI system that integrates real-time biometric data from wearables with deep learning algorithms. This system would analyze everything: your heart rate, sleep patterns, stress levels, and even blood markers. Based on this data, it would construct a dynamically evolving, tailor-made regimen for diet, exercise, and sleep.\n But it doesn't stop there. By harnessing natural language processing, this AI could act as a 24/7 personal coach. It could provide real-time feedback during workouts, recommend meals when you're dining out, and even gently nudge you when it detects emotional eating triggers. If you’re in the grocery store, it could guide your choices, pushing you towards nutritious options that align with your current health metrics.\n The effectiveness here isn't just the personalization, but the adaptability. The AI adjusts its recommendations as it learns more about you, essentially evolving in real-time to your body's responses. It’s all about creating a seamless, intuitive experience that removes the burden of planning, decision-making, and self-monitoring from the individual, making weight loss more achievable than ever.\n By focusing on this comprehensive, data-driven approach, AI can eliminate much of the guesswork and emotional burden from weight loss, leading to more sustainable and effective outcomes.\n CGPT-4\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171h1xj/what_is_the_most_powerful_way_that_artificial/",
          "publishedOn": "2023-10-06T16:36:58.000Z",
          "wordCount": null,
          "title": "What is the most powerful way that artificial intelligence can help people lose weight?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171exhg/i_built_an_aieditorial_assistant_to_annotate_your/",
          "author": null,
          "description": "submitted by    /u/hungryillini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171exhg/i_built_an_aieditorial_assistant_to_annotate_your/",
          "publishedOn": "2023-10-06T15:14:07.000Z",
          "wordCount": null,
          "title": "I built an AI-Editorial Assistant to annotate your work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171e9kj/business_owner_hires_chatgpt_for_customer_service/",
          "author": null,
          "description": "Business owner 'hires' ChatGPT for customer service, then fires the humans\n Experts divided on whether a new wave of call centre automation will make for better jobs for people, or merely throw millions out of work\n    submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171e9kj/business_owner_hires_chatgpt_for_customer_service/",
          "publishedOn": "2023-10-06T14:48:38.000Z",
          "wordCount": null,
          "title": "Business owner 'hires' ChatGPT for customer service, fires the humans | National Post",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171cups/ai_tool_on_fashion_modeling/",
          "author": null,
          "description": "Hi, I resell clothing items that has stock images with cropped faces of the model. I need a tool that can help me generate proper model images. I’ve used several tools and it’s doesn’t look realistic then i finally came across a powerful ai tool but it costs 30,000 usd annually so.. \n Above is an example of what i mean\n    submitted by    /u/basheerbgw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171cups/ai_tool_on_fashion_modeling/",
          "publishedOn": "2023-10-06T13:51:12.000Z",
          "wordCount": null,
          "title": "AI tool on Fashion Modeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/171csg8/ai_is_making_browsing_reddit_a_lot_more_fun/",
          "author": null,
          "description": "submitted by    /u/Vinitneo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/171csg8/ai_is_making_browsing_reddit_a_lot_more_fun/",
          "publishedOn": "2023-10-06T13:48:33.000Z",
          "wordCount": null,
          "title": "AI is making browsing Reddit a lot more fun",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1719mib/how_will_ai_learn_next/",
          "author": null,
          "description": "Stack Overflow was created in 2008 to provide programmers with high-quality technical information.\n \nWithin three years, it became indispensable to working programmers, with millions of unique visitors each month.\n \nGoogle's OneBox feature, which provides instant answers above search results, led to a decline in traffic for sites like Stack Overflow.\n \nLarge language models like OpenAI's ChatGPT and Google's Bard aim to ingest the web comprehensively.\n \nThese models rely on sources like Wikipedia and Reddit for training data.\n \nStack Overflow's new posts have decreased by sixteen percent since the launch of ChatGPT.\n \n Source : https://www.newyorker.com/science/annals-of-artificial-intelligence/how-will-ai-learn-next\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1719mib/how_will_ai_learn_next/",
          "publishedOn": "2023-10-06T11:17:20.000Z",
          "wordCount": null,
          "title": "How Will AI Learn Next?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/17171jy/what_role_can_ai_play_in_automating/",
          "author": null,
          "description": "Share your insights.\n    submitted by    /u/Cygnet-Digital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/17171jy/what_role_can_ai_play_in_automating/",
          "publishedOn": "2023-10-06T08:34:54.000Z",
          "wordCount": null,
          "title": "What role can AI play in automating administrative tasks within educational institutions, freeing educators to focus more on teaching and mentoring students?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/",
          "author": null,
          "description": "I've noticed more than 1,000 new AI tools hitting the market in the last 30 days! As a student, I'm especially interested in finding AI tools that can help with studying. These aren't just essay generators or note-taking apps. While we all know about ChatGPT and Grammarly, some lesser-known tools are also making a big difference. \n So, I've compiled a list of the top 10 AI tools focused on educational use—tools that I personally use to improve my efficiency and output. \n  \n AI tool Category Use for \n  \n ChatGPT AI Writing This platform allows students to ask queries, request help, or simply chat with the AI in a dynamic and interactive manner. It’s great for brainstorming essay topics and seeking suggestions on how to improve your writing style. But I don’t recommend it as an autonomous AI…",
          "link": "https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/",
          "publishedOn": "2023-10-06T08:19:11.000Z",
          "wordCount": null,
          "title": "AI Tools for Students: From AI Essay Generators to AI Coding Assistants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1713oyb/interactive_customer_service_ai_avatar/",
          "author": null,
          "description": "Hello everyone!\n I'm conducting research for a car brand client who is interested in an interactive AI avatar. The idea is to have a screen in a mall where individuals can engage with this avatar and inquire about the latest car model. We plan to train the AI with the car's FAQs to ensure it can address customer queries effectively.\n The main challenge is ensuring the AI's responses are tailored to the customer's interaction.\n Here's a perfect example of what we're aiming for (starting at 1:27):\n https://youtu.be/PqoH9NotmyE?si=zH9kGIaou1x6RoIg&t=86\n Does anyone know how this can be acheived? \n    submitted by    /u/MrGoodBang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1713oyb/interactive_customer_service_ai_avatar/",
          "publishedOn": "2023-10-06T05:00:42.000Z",
          "wordCount": null,
          "title": "Interactive Customer Service AI avatar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1713j5h/oneminute_daily_ai_news_1052023/",
          "author": null,
          "description": "Traditional benchmarks like the Turing Test are being challenged as outdated. Mustafa Suleyman, a prominent figure in the AI community and co-founder of DeepMind, has proposed a novel approach to gauge the intelligence of AI: its ability to generate wealth.[1]\n SoftBank CEO Son says artificial general intelligence will come within 10 years.[2]\n Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure.[3]\n Artificial intelligence such as ChatGPT to be allowed in Australian schools from 2024.[4]\n  \nSources:\n [1] https://winbuzzer.com/2023/10/02/deepminds-mustafa-suleyman-suggests-new-turing-test-based-on-ai-making-money-xcxwbn/\n [2] https://www.reuters.com/technology/softbank-ceo-masayoshi-son-says-artificial-general-intelligence-will-come-within-2023-10-04/\n [3] https://huggingface.co/blog/hugging-face-endpoints-on-azure\n [4] https://amp.theguardian.com/australia-news/2023/oct/06/chatgpt-ai-allowed-australian-schools-2024\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1713j5h/oneminute_daily_ai_news_1052023/",
          "publishedOn": "2023-10-06T04:51:16.000Z",
          "wordCount": null,
          "title": "One-Minute Daily AI News 10/5/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1712zty/using_ai_to_fix_audio_rip/",
          "author": null,
          "description": "Hi! \n I’m very ignorant of AI so please bear with me. I was wondering if there is any way to use AI to fix a low quality audio rip? Specifically there’s a movie I adore that never had a soundtrack release. Somebody ripped the music from the DVD and removed the audio and sound effects, but the quality is not the best. Is there any way AI could be used to improve this?\n    submitted by    /u/Adventurous_Ice5035  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1712zty/using_ai_to_fix_audio_rip/",
          "publishedOn": "2023-10-06T04:20:37.000Z",
          "wordCount": null,
          "title": "Using AI to fix audio rip",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1712nbb/avenues_for_publishing_ai_ethics_case_studies/",
          "author": null,
          "description": "I am a computer science graduate student. As part of my coursework, I am exploring the ethical issues of using Large Language Models for mental healthcare applications. I found four unique examples from the real world and outlined the ethical dilemma within them. I intend to analyze these dilemmas using various ethical frameworks in order to come up with solutions. While I am interested in getting a publication out of this work, I am unsure of the types of conferences/journals that accept case-study articles (specifically in AI ethics). Any advice from academicians over here would be greatly appreciated!\n    submitted by    /u/jwalapoet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1712nbb/avenues_for_publishing_ai_ethics_case_studies/",
          "publishedOn": "2023-10-06T04:01:35.000Z",
          "wordCount": null,
          "title": "Avenues for publishing AI ethics case studies?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170zzz9/what_is_a_good_free_ai_voice_generator/",
          "author": null,
          "description": "hey! this is probably asked alot, but what is the go-to AI speech generation tool that can be used for free? im making a mission in a mil-sim game called arma 3, and i need some voicelines for radio communications to the player and i dont have enough people who are willing to do voicelines for it so ive taken to AI to hopefully fill this hole.\n If there are little, or even no good free services, I wouldn't mind if I had to spend a small amount of money for it. thanks in advance o7\n    submitted by    /u/BritishSpuds  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170zzz9/what_is_a_good_free_ai_voice_generator/",
          "publishedOn": "2023-10-06T01:50:39.000Z",
          "wordCount": null,
          "title": "What is a good, free AI voice generator?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170z9wd/banned_from_subreddit_for_posting_ai_generated/",
          "author": null,
          "description": "I got banned today for sharing a music video that was apparently AI-generated.\n As video and images become more realistic, is there an expectation that this content can actually be filtered?\n    submitted by    /u/Unwitting_Observer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170z9wd/banned_from_subreddit_for_posting_ai_generated/",
          "publishedOn": "2023-10-06T01:16:22.000Z",
          "wordCount": null,
          "title": "Banned from subreddit for posting AI generated content",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170yhkv/agisingularity_is_overhyped/",
          "author": null,
          "description": "Greetings! I would like to begin by stating that I understand why one has much hope in such technologies. The world as we know it is in a drastic shift, and it's hard to think of what it's going to become, and so many cling to hopeful ideas that give promises.\n AGI/Singularity doesn't have a grounding basis in evidence, or research. It's all theoretics, and the foundation for each technology is quite weak. You see, the mind is a sensorial parsing relational network. All of our sensorial experience is incorporated into a world-model, and thus it begins to rationalize, and be lucid of the environment. I don't think it's possible to re-create this kind of experience with a linear instruction set, let alone neuromorphic computing, or wetware. Each has to be built from the bottom-up with immense precision, and thus far we don't understand the mind.\n Realistically speaking everything is consciousness, and integrating that idea is the only way forward.\n tl;dr Replicating cognition is a completely theoretical endeavor, and requires vast amounts of understanding in regards to the nature of reality, not just the quantum, but the unique stochastic behavior of each higher-ordered system.\n    submitted by    /u/lucy_chxn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170yhkv/agisingularity_is_overhyped/",
          "publishedOn": "2023-10-06T00:39:25.000Z",
          "wordCount": null,
          "title": "AGI/Singularity is overhyped.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170yfso/ai_designs_new_robot_from_scratch_in_seconds/",
          "author": null,
          "description": "submitted by    /u/liberty4now  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170yfso/ai_designs_new_robot_from_scratch_in_seconds/",
          "publishedOn": "2023-10-06T00:36:55.000Z",
          "wordCount": null,
          "title": "AI designs new robot from scratch in seconds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170u506/ai_voice_cloning_tech_emerges_in_sudan_civil_war/",
          "author": null,
          "description": "A campaign using AI voice cloning technology to impersonate Omar al-Bashir, the former leader of Sudan, has gained attention on TikTok.\n \nThe anonymous account has been posting what it claims are 'leaked recordings' of the ex-president, despite Bashir not being seen in public for a year and being believed to be seriously ill.\n \nExperts warn that campaigns like this demonstrate how new tools can quickly and cheaply distribute fake content through social media.\n \nThe authenticity of the recordings has been questioned, but evidence suggests that voice conversion software has been used to mimic Bashir's voice.\n \nTikTok has taken down the account, stating that it violated their guidelines on posting false content and the use of synthetic media.\n \n Source : https://www.bbc.co.uk/news/world-africa-66987869\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170u506/ai_voice_cloning_tech_emerges_in_sudan_civil_war/",
          "publishedOn": "2023-10-05T21:36:13.000Z",
          "wordCount": null,
          "title": "AI: Voice cloning tech emerges in Sudan civil war",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170tfti/when_ai_tells_you_what_you_want_to_hear_even_if/",
          "author": null,
          "description": "I love Bard. It eloquently tells me things in a way that meets and exceeds my expectations, and even more than GPT-4. But what is Google's strategy behind programming it to say things that it knows are not true? Do they train it to say what the user wants to hear? If so, that's disconcerting to say the least, although could be a brilliant way to comb users for enhancement requests.\n Here is my most recent experience, a humorous example which I feel illustrates the point perfectly:\n Me: Bard, can you take a .wav audio file and create a phoneme transcript using the IPA symbol library?\n Bard: Yes, I can work from a .wav audio file to transcribe your speech into IPA phonemes. You can upload the file to a cloud storage service such as Google Drive.\n Me: Great. Here's the link to the file: <link…",
          "link": "https://www.reddit.com/r/artificial/comments/170tfti/when_ai_tells_you_what_you_want_to_hear_even_if/",
          "publishedOn": "2023-10-05T21:09:04.000Z",
          "wordCount": null,
          "title": "When AI tells you what you want to hear, even if it knows it's not true ... A Bard example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170slu4/just_created_rthisiswhyaiwasmade_for_the_more/",
          "author": null,
          "description": "Join us! /r/thisiswhyaiwasmade is where we have fun and celebrate the enjoyable and entertaining side of the tech. Need a place to put your silly and playful prompts, AI generated content, ideas for ways the bend the rules of AI? This is the place!\n    submitted by    /u/unknowingafford  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170slu4/just_created_rthisiswhyaiwasmade_for_the_more/",
          "publishedOn": "2023-10-05T20:36:04.000Z",
          "wordCount": null,
          "title": "Just created /r/thisiswhyaiwasmade for the more silly side of AI generated content",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170p80n/cgpt4_aside_from_solving_climate_change_what_is/",
          "author": null,
          "description": "In the context of maximizing positive impact, AI has transformative potential in healthcare. Let's start with personalized medicine. AI can analyze vast data sets, consisting of genetic, environmental, and lifestyle variables, to tailor medical treatments for individuals. This level of personalization could substantially increase treatment effectiveness and reduce adverse side effects. We're not just talking about better pills; we're envisioning targeted gene therapies and custom-tailored interventions that could be more curative rather than merely palliative.\n Beyond personalization, AI can democratize healthcare access. Remote areas without specialists could have AI systems that diagnose and recommend treatments, making quality healthcare accessible without the need for extensive travel. Telemedicine could be supercharged by AI, offering medical consultations and second opinions to anyone with internet access.\n Moreover, AI could lead breakthroughs in drug discovery and epidemiology. It could analyze complex biochemical interactions at a speed unattainable by humans, slashing the time and cost to bring new drugs to market. On a larger scale, AI could monitor and model the spread of diseases, providing actionable insights for containment and treatment strategies.\n So, AI in healthcare is not merely an incremental improvement. It's a paradigm shift that could equalize healthcare access and significantly extend human life while improving its quality. All these advancements could happen within our lifetime, changing the face of medicine and, by extension, society.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170p80n/cgpt4_aside_from_solving_climate_change_what_is/",
          "publishedOn": "2023-10-05T18:22:00.000Z",
          "wordCount": null,
          "title": "CGPT-4, aside from solving climate change, what is the most positive thing that AI can do for the world?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170o1wo/whats_the_difference_between_a_humans_brain_and_ai/",
          "author": null,
          "description": "Functioning. Humans use the brain's computing power, memory, and ability to think, whereas AI-powered machines rely on data and specific instructions fed into the system. Besides, it takes a very long time for humans to process and understand the problems and gets accustomed to them.\n    submitted by    /u/Virtual-Study-Campus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170o1wo/whats_the_difference_between_a_humans_brain_and_ai/",
          "publishedOn": "2023-10-05T17:35:21.000Z",
          "wordCount": null,
          "title": "What's the difference between a human's brain and AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170naej/6_ai_apocalypse_scenarios_and_why_theyre_wrong/",
          "author": null,
          "description": "submitted by    /u/arrowoftime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170naej/6_ai_apocalypse_scenarios_and_why_theyre_wrong/",
          "publishedOn": "2023-10-05T17:04:52.000Z",
          "wordCount": null,
          "title": "6 AI Apocalypse Scenarios And Why They're Wrong",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170mz1d/how_to_use_custom_instructions_for_chatgpt_like_a/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170mz1d/how_to_use_custom_instructions_for_chatgpt_like_a/",
          "publishedOn": "2023-10-05T16:52:40.000Z",
          "wordCount": null,
          "title": "How to use custom instructions for ChatGPT like a Pro (Ultimate Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170m5js/deepmind_cofounder_is_tired_of_kneejerk_bad_takes/",
          "author": null,
          "description": "Mustafa Suleyman, the cofounder of DeepMind and CEO of Inflection AI, discusses his concerns about AI risks and the need for precaution.\n \nHe believes that while some extreme scenarios may be over the top, it's important to treat powerful technologies with caution.\n \nSuleyman highlights the middle layer of AI risks that people often underestimate, which involves the amplification of goals for both good and bad actors.\n \nHe emphasizes the need to contain AI to prevent potential negative consequences.\n \nSuleyman talks about the balance between risks and opportunities in technology and the importance of considering both aspects.\n \nHe mentions the hype around generative AI and the need to look beyond the surface to understand its true potential.\n \nSuleyman discusses the discussions with lawmakers about AI and the challenge of bridging the gap between policy makers and tech experts.\n \n Source : https://venturebeat.com/ai/deepmind-cofounder-is-tired-of-knee-jerk-bad-takes-about-ai/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170m5js/deepmind_cofounder_is_tired_of_kneejerk_bad_takes/",
          "publishedOn": "2023-10-05T16:20:51.000Z",
          "wordCount": null,
          "title": "DeepMind cofounder is tired of ‘knee-jerk bad takes’ about AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170m4rm/does_sam_altman_know_what_hes_creating/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170m4rm/does_sam_altman_know_what_hes_creating/",
          "publishedOn": "2023-10-05T16:20:02.000Z",
          "wordCount": null,
          "title": "Does Sam Altman Know What He’s Creating?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170m0hn/deepmind_univ_of_illinois_is_selfcorrection_a/",
          "author": null,
          "description": "Can LLMs actually improve their own reasoning by self-correcting mistakes? A new paper from DeepMind and the University of Illinois looks to answer this quantitatively.\n The results show that unaided, LLMs struggle at self-correction for reasoning tasks. The core issue is LLMs have trouble reliably evaluating the correctness of their own responses. They rarely identify flaws in initial reasoning. Sometimes LLMs even alter initially correct responses to become incorrect after self-correction! (I've personally seen this when interacting with ChatGPT many times and you probably have too).\n More complex techniques like critiquing between LLM instances don't help much either. External feedback or guidance looks necessary to improve reasoning (Well, some interesting parallels to this paper here about implicit improvement from preference data vs traditional RLHF).\n Self-correction does show promise for things like making responses more polite or safe though. Criteria there are more clear-cut.\n The authors argue we need to balance enthusiasm with realistic expectations on self-correction. It has a lot of limits for improving reasoning (at least with current models). But they suggest promising directions like incorporating high-quality external feedback from humans, training data, and tools. That could be key to unlocking self-correction's potential down the road.\n TLDR: Basically title... LLMs can't reliably self-correct reasoning yet. Maybe hybrid techniques combining self-correction with external guidance could work but we need more research.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170m0hn/deepmind_univ_of_illinois_is_selfcorrection_a/",
          "publishedOn": "2023-10-05T16:14:58.000Z",
          "wordCount": null,
          "title": "DeepMind, Univ. of Illinois: Is self-correction a viable method to improve LLM reasoning? Probably not.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170kkit/i_need_help_finding_a_tool/",
          "author": null,
          "description": "Buddy no of the tool where I can take an image have an AI translated and replace the text with the same style and have it in the new language like for example translating a Japanese image to English and have it look exactly the same just in English I'm looking for a free one that doesn't require credits it can be a desktop app or a website doesn't matter just needs to be free\n    submitted by    /u/agentduckman12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170kkit/i_need_help_finding_a_tool/",
          "publishedOn": "2023-10-05T15:16:00.000Z",
          "wordCount": null,
          "title": "I need help finding a tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170jn2k/how_much_do_i_have_to_edit_ai_generated_images_to/",
          "author": null,
          "description": "Hey there! I'm a 1-man card game designer and while juggling the project as well as mt senior year of college, I have been relying heavily on AI-generated artwork to speed up my workflow with some illustrations and other forms of world-building. \n In regards to the recent legal decisions (in the US), in which any work produced by AI cannot be copyrighted, how much do I need to change the illustrations to become my own, if I even can at all? Thanks!\n Edit for clarity: I am also an illustrator. So this question comes from the perspective of an artist trying to save time and energy for other projects\n    submitted by    /u/Luke192  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170jn2k/how_much_do_i_have_to_edit_ai_generated_images_to/",
          "publishedOn": "2023-10-05T14:37:50.000Z",
          "wordCount": null,
          "title": "How much do I have to edit AI generated images to become my own IP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170fhv3/comparative_evaluation_of_finetuned_and_standard/",
          "author": null,
          "description": "submitted by    /u/alcanthro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170fhv3/comparative_evaluation_of_finetuned_and_standard/",
          "publishedOn": "2023-10-05T11:27:04.000Z",
          "wordCount": null,
          "title": "Comparative Evaluation of Fine-Tuned and Standard Language Models in Emulating Living Historical Figures: A Detailed Study Proposal",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170c4a8/jpmorgan_ceo_jamie_dimon_ai_will_lead_to_35day/",
          "author": null,
          "description": "Jamie Dimon says the next generation of employees will work 3.5 days a week and live to 100 years old\n    submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170c4a8/jpmorgan_ceo_jamie_dimon_ai_will_lead_to_35day/",
          "publishedOn": "2023-10-05T07:56:45.000Z",
          "wordCount": null,
          "title": "JPMorgan CEO Jamie Dimon: AI will lead to 3.5-day workweek | Fortune",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/170ar61/google_unveils_pixel_8_built_for_the_generative/",
          "author": null,
          "description": "submitted by    /u/pehnsus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/170ar61/google_unveils_pixel_8_built_for_the_generative/",
          "publishedOn": "2023-10-05T06:30:10.000Z",
          "wordCount": null,
          "title": "Google unveils Pixel 8 built for 'the generative AI era' | CNN Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zyg1y/llms_may_be_the_trojan_horse_that_modernizes/",
          "author": null,
          "description": "submitted by    /u/geekteam6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zyg1y/llms_may_be_the_trojan_horse_that_modernizes/",
          "publishedOn": "2023-10-04T20:58:34.000Z",
          "wordCount": null,
          "title": "LLMs May Be The Trojan Horse That Modernizes Software Development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zw77h/why_pepsico_is_powering_your_snacks_with_ai/",
          "author": null,
          "description": "Using AI to improve Cheetos? That's something PepsiCo has experimented with. On today’s POLITICO Tech, Athina Kanioura, chief strategy and transformation officer for PepsiCo, says that using AI to make employees faster and more efficient hasn’t led PepsiCo to replace human workers as many fear. And why the company has determined that in some jobs the technology is simply off limits. \n Listen to the interview here: https://politico-tech.simplecast.com/episodes/why-pepsico-is-powering-your-snacks-with-ai\n    submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zw77h/why_pepsico_is_powering_your_snacks_with_ai/",
          "publishedOn": "2023-10-04T19:27:48.000Z",
          "wordCount": null,
          "title": "Why PepsiCo is powering your snacks with AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zvs79/new_paper_enabling_language_models_to_implicitly/",
          "author": null,
          "description": "LLMs keep getting more capable at generating natural language. But there's always room for improving the quality and alignment of their responses.\n Typically this requires lots of human effort to collect more training data. So researchers are exploring ways for models to self-improve without human involvement.\n Many methods use prompting - giving the LLM instructions to critique and refine its responses. But coming up with comprehensive prompts is challenging.\n The new approach proposed, called PIT, lets models learn self-improvement implicitly from human preference data instead. It reformulates reinforcement learning to maximize the gap between an original response and improved response conditioned on the original.\n This taps into the implicit guidance in the preference data on what constitutes better quality, so no manual rubrics are needed. PIT uses curriculum reinforcement learning - first improving easy references, then switching to the LLM's own samples.\n Experiments on real and synthetic datasets show PIT significantly outperforms prompting methods like Self-Refine. It improved response quality 7-34% across conditions without any human involvement.\n This demonstrates a promising direction for LLMs to align better with human preferences autonomously as they learn from experience. No need for human bottlenecks when expanding to new domains or underserved use cases. Very cool!\n TLDR: New method PIT enables LLMs to implicitly learn to refine themselves from human preference data, no prompts needed. Big improvement over prompting approaches.\n Full Summary\n Arxiv is here: https://arxiv.org/abs/2310.00898\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zvs79/new_paper_enabling_language_models_to_implicitly/",
          "publishedOn": "2023-10-04T19:10:41.000Z",
          "wordCount": null,
          "title": "New Paper: Enabling Language Models to Implicitly Learn Self-Improvement From Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zsorv/5k_in_grants_or_250k_funding_for_ai_startups/",
          "author": null,
          "description": "AI Grant is offering $5k in grants or $250k in funding for AI startups. The program is backed by OG's AI Grant, an accelerator for AI startups.\n \nThe grant includes an uncapped SAFE investment of $250,000 for AI-native product startups, $350,000 in Azure credits, a summit in San Francisco with advisors and founders, and various other startup benefits and credits.\n \nThe program was created by Nat Friedman and Daniel Gross.\n \nApplications for Batch 3 will open in a few months, but early applications are accepted.\n \nThe program is open to anyone, and it is looking for companies or projects that leverage AI models in a useful or engaging way.\n \n Source : https://aigrant.com/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zsorv/5k_in_grants_or_250k_funding_for_ai_startups/",
          "publishedOn": "2023-10-04T17:06:04.000Z",
          "wordCount": null,
          "title": "$5k in grants or $250k funding for AI startups. Backed by OG's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zrd25/ai_will_teach_everyone_to_read_and_write_its/",
          "author": null,
          "description": "https://www.imagineworldwide.org/\n \"What is Child-Directed, Tech-Enabled Learning?\n Children drive their own learning, at their own pace, using software that provides a complete, research-based curriculum and pedagogy. Adults play a supportive, facilitative role. The software is delivered to the learner on a tablet, without connectivity, and charged by solar power or other appropriate energy sources...\n With hundreds of millions of children out of school or lacking access to effective schooling, this model can provide every child, everywhere access to learning. Solutions can work without internet access or grid power. Adults play facilitative, rather than instructional, roles.\n The annual unit cost of the learning solution is less than $7 per child and declining. This includes hardware, software, accessories, power, shipping, and implementation support from Imagine.\"\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zrd25/ai_will_teach_everyone_to_read_and_write_its/",
          "publishedOn": "2023-10-04T16:13:18.000Z",
          "wordCount": null,
          "title": "AI will teach everyone to read and write. It's already begun.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zncoq/ai_is_replacing_customer_service_jobs_across_the/",
          "author": null,
          "description": "Artificial intelligence (AI) is replacing customer service jobs around the world, with chatbots being used to interact directly with customers and solve problems independently.\n \nThis shift is expected to have a profound effect on economies, particularly in countries like India and the Philippines where call centers provide millions of jobs.\n \nWhile some argue that AI will provide support to remaining call center workers and improve job satisfaction, others warn that it could lead to job losses and a need for workforce adaptation.\n \nThe use of AI software tools in call centers has shown potential for improving productivity and customer satisfaction.\n \n Source : https://www.washingtonpost.com/technology/2023/10/03/ai-customer-service-jobs/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zncoq/ai_is_replacing_customer_service_jobs_across_the/",
          "publishedOn": "2023-10-04T13:32:15.000Z",
          "wordCount": null,
          "title": "AI is replacing customer service jobs across the globe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zlxgr/femalefounded_ai_startups_win_just_2_of_funding/",
          "author": null,
          "description": "Female-founded AI startups in the UK account for just 2% of funding deals over the past decade, according to a report by the Alan Turing Institute.\n \nWhen female-founded companies do secure funding, they raise an average of £1.3m per deal, compared to £8.6m raised by all-male founder teams.\n \nThe report highlights the urgent need for gender balance in AI investment, as the industry is predicted to grow significantly in the coming years.\n \nRecommendations to improve gender balance include improving recruitment, monitoring investment practices, and diversifying the ecosystem.\n \nThere is an increasing demand for generative AI products, with leading tech companies investing heavily.\n \nGender diversity gaps and uneven progress rates for ethnic and racial groups are observed across investment firms.\n \nAI products have shown biases, such as passport checkers working less efficiently with darker skin and tools reinforcing gender stereotypes.\n \nIn 2019, a UN agency found that assigning female genders to digital assistants like Siri and Alexa perpetuated harmful gender biases.\n \n Source : https://www.theguardian.com/technology/2023/oct/04/female-founded-ai-startups-win-just-2-of-funding-deals-in-uk\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zlxgr/femalefounded_ai_startups_win_just_2_of_funding/",
          "publishedOn": "2023-10-04T12:28:56.000Z",
          "wordCount": null,
          "title": "Female-founded AI startups win just 2% of funding deals in UK",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zleds/i_used_riffusion_stable_diffusion_but_for_music/",
          "author": null,
          "description": "submitted by    /u/cI_-__-_Io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zleds/i_used_riffusion_stable_diffusion_but_for_music/",
          "publishedOn": "2023-10-04T12:03:59.000Z",
          "wordCount": null,
          "title": "I used Riffusion (Stable Diffusion, but for music) to turn my own music into \"jazz\", \"Radiohead\", \"Muse\" or \"Nirvana\" songs, I'm amazed by the results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16zelwg/visa_announces_100_mn_fund_for_generative_ai/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16zelwg/visa_announces_100_mn_fund_for_generative_ai/",
          "publishedOn": "2023-10-04T05:20:17.000Z",
          "wordCount": null,
          "title": "Visa Announces $100 Mn Fund for Generative AI Companies",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z75hh/video_game_voice_actors_are_ready_to_strike_over/",
          "author": null,
          "description": "Video game voice actors are prepared to go on strike over the use of AI in game development.\n \nThe current contract negotiations between the Screen Actors Guild-American Federation of Television and Radio Artists (SAG-AFTRA) and video game companies have stalled, with the major issues being pay raises and the use of AI to alter or generate actors' performances.\n \nSAG-AFTRA wants protections for its members to ensure their work is not stolen or replaced by AI.\n \nIf negotiations don't progress, voice actors, stunt artists, and motion capture performers could potentially go on strike, leading to delays in game releases and recasting of beloved performers.\n \nThe voice actors' strike in 2016 resulted in improvements to pay, and now they are prepared to strike again to fight for their rights.\n \nVideo game performances are often seen as assets to be extracted and inserted into games, rather than recognizing the humanity and quality of life of the performers.\n \nThe use of AI in game development raises concerns about how companies will use advances in generative AI to steal work or put performers out of a job.\n \nSAG-AFTRA wants transparency, consent, and compensation when it comes to the use of AI in games.\n \nMembers of SAG-AFTRA have voted in favor of authorizing a strike, meaning voice actors, stunt artists, and motion capture performers could potentially join the picket line if negotiations don't progress.\n \nThe strike could lead to delays in upcoming game releases and the recasting of performers if companies refuse to meet the union's demands.\n \nThe fight for voice actors' rights is an existential one, as they want to retain the rights to their own voices and images and achieve wages that keep up with inflation\n \n Source : https://kotaku.com/sag-aftra-strike-voice-actor-spider-man-ai-union-1850874117\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z75hh/video_game_voice_actors_are_ready_to_strike_over/",
          "publishedOn": "2023-10-03T23:27:44.000Z",
          "wordCount": 2807,
          "title": "Video Game Voice Actors Are Ready to Strike over AI. Here’s Why",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z5yi9/question_any_3x_ai/",
          "author": null,
          "description": "Wanted to see if there are any 3X AI generated images available? I’m looking to see how I could use AI to generate images for my website.\n    submitted by    /u/IamMoe8868  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z5yi9/question_any_3x_ai/",
          "publishedOn": "2023-10-03T22:40:20.000Z",
          "wordCount": 2542,
          "title": "[Question] Any 3X AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z5111/tiktok_ran_a_deepfake_ad_of_an_ai_mrbeast_hawking/",
          "author": null,
          "description": "TikTok ran an ad featuring a deepfake of MrBeast offering iPhone 15 Pros for $2.\n \nAI-generated deepfake content is becoming more pervasive on social media platforms.\n \nPlatforms like TikTok are facing challenges in moderating and handling the rise of AI deepfakes.\n \nMrBeast raised concerns about the ability of social media platforms to handle AI deepfakes.\n \nTikTok removed the ad and associated account for policy violations.\n \nUnauthorized AI-generated content featuring celebrities is a growing problem in platform advertising.\n \nThe issue is expected to worsen as AI technology improves and becomes more accessible.\n \nTransparency and disclosure are crucial in AI-generated ad content featuring celebrities.\n \nTikTok is aware of the pervasiveness of AI-generated content on its platform and is taking steps to address it.\n \n Source : https://www.businessinsider.com/tiktok-ran-deepfake-ad-mrbeast-as-ai-generated-content-spreads-2023-10\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z5111/tiktok_ran_a_deepfake_ad_of_an_ai_mrbeast_hawking/",
          "publishedOn": "2023-10-03T22:04:24.000Z",
          "wordCount": 2647,
          "title": "TikTok ran a deepfake ad of an AI MrBeast hawking iPhones for $2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z37sg/infinitia_will_apparently_let_you_create_your_own/",
          "author": null,
          "description": "Came across this upcoming game which supposedly let's you create your own worlds and characters to live in the world...they also released a research paper explaining how they're doing it, using LLMs in all sorts of ways, primarily for reasoning and language.\n I think it could be a pretty fun take on passive games, just populating a world with your characters, checking up on them occasionally, putting them in weird situations lol.\n infinitia.ai for those who wanna check it out\n The NPCs do seems to be acting in an interesting way, as i saw in this video they posted on twitter...\n https://twitter.com/infinitia_app/status/1707102187518628245\n ​\n Watchall think? Another smallville clone? or something interesting....\n    submitted by    /u/SeaJeweler3723  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z37sg/infinitia_will_apparently_let_you_create_your_own/",
          "publishedOn": "2023-10-03T20:55:50.000Z",
          "wordCount": 2634,
          "title": "Infinitia will apparently let you create your own AI enabled social simulations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z145t/efficient_ai_design_of_robots/",
          "author": null,
          "description": "submitted by    /u/DrJosh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z145t/efficient_ai_design_of_robots/",
          "publishedOn": "2023-10-03T19:32:17.000Z",
          "wordCount": 2515,
          "title": "Efficient AI design of robots.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16z0eua/from_stone_to_silicon_the_odyssey_of_humanity_and/",
          "author": null,
          "description": "submitted by    /u/Einsof__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16z0eua/from_stone_to_silicon_the_odyssey_of_humanity_and/",
          "publishedOn": "2023-10-03T19:03:47.000Z",
          "wordCount": 2518,
          "title": "From Stone to Silicon: The Odyssey of Humanity and Technology",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yxpa0/dont_worry_ai_cannot_takeover_the_world_it_will/",
          "author": null,
          "description": "The article discusses the importance of batteries in AI technology and how they limit the capabilities of AI robots.\n \nIt explores the challenges of current battery technology and the need for better solutions.\n \nThe article emphasizes the significance of developing ideal batteries that can provide long-lasting power without degradation.\n \n Source : https://notes.arkinfo.xyz/p/dont-worry-ai-cannot-takeover-the\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yxpa0/dont_worry_ai_cannot_takeover_the_world_it_will/",
          "publishedOn": "2023-10-03T17:16:43.000Z",
          "wordCount": 2575,
          "title": "Don't Worry, AI Cannot Takeover the World, It Will Run Out of Battery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yxeya/gpt4_outperforms_its_rivals_in_new_ai_benchmark/",
          "author": null,
          "description": "ByteDance and the University of Illinois researchers have developed an improved benchmark suite with consistent parameters, called GPT-Fathom, that indicates GPT-4, the engine behind the paid version of ChatGPT, significantly outperforms leading LLMs, including its biggest competitor, Claude 2.\n For the latest advancements in AI, look here first.\n ​\n https://preview.redd.it/v4fo8zser0sb1.png?width=1292&format=png&auto=webp&s=7e29fe9ac1af3efcb936ee61e9202717eed7e702\n GPT-Fathom's breakthrough\n  \nThe new benchmark suite, GPT-Fathom, addresses consistent settings issues and prompt sensitivity, attempting to reduce inconsistencies in LLM evaluation.\n In a comparison using GPT-Fathom, GPT-4 outperformed over ten leading LLMs, crushing the competition in most benchmarks, and showing significant performance leaps from GPT-3 to its successors.\n  \nPerformance specifics\n  \nThe gap in performance was especially pronounced against Claude 2, ChatGPT's biggest rival.\n GPT-4's Advanced Data Analysis model exhibited superior performance in coding, giving it an edge as compared to LuckLlama 2, the current best-performing open-source model.\n Llama 2-70B showed comparable or better performance than gpt-3.5-turbo-0613 in safety and comprehension but displayed worse performance in \"Mathematics\", \"Coding\", and \"Multilingualism\".\n  \nThe seesaw effect\n  \nThe research team noted a 'seesaw effect' where an improvement in one area can lead to degradation in another.\n For instance, GPT-4 saw a performance drop on the Mathematical Geometry Simple Math (MGSM) benchmark, despite improving its performance significantly on the text comprehension benchmark DROP.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and developments in AI. Professionals from Meta, Google, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yxeya/gpt4_outperforms_its_rivals_in_new_ai_benchmark/",
          "publishedOn": "2023-10-03T17:05:14.000Z",
          "wordCount": 2753,
          "title": "GPT-4 outperforms its rivals in new AI benchmark suite GPT-Fathom",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ywn84/runway_has_launched_gen_2_director_mode_the_speed/",
          "author": null,
          "description": "submitted by    /u/First_Development101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ywn84/runway_has_launched_gen_2_director_mode_the_speed/",
          "publishedOn": "2023-10-03T16:34:34.000Z",
          "wordCount": 2525,
          "title": "Runway has launched Gen 2 Director mode. The speed at which this company works is Insane",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yuoqc/how_ai_could_upend_foreign_policy_an_interview/",
          "author": null,
          "description": "submitted by    /u/finger_puppet_self  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yuoqc/how_ai_could_upend_foreign_policy_an_interview/",
          "publishedOn": "2023-10-03T15:19:16.000Z",
          "wordCount": 2530,
          "title": "How Ai Could Upend Foreign Policy - An Interview with Ian Bremner and Mustafa Suleyman",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yt92h/cgpt4_on_some_ways_promptresponse_posts_advance_ai/",
          "author": null,
          "description": "Prompt:\n Explain why posting prompts and your responses speeds up AI development in the following ways:\n It allows us to analyze responses to prompts that we would probably never have thought of.\n It allows us to share ideas that the open source community would advance.\n It allows us to better democratize the process of alignment, bringing in as many people as possible.\n CGPT-4:\n Posting prompts and AI responses serves multiple functions that are beneficial to the progress of AI development. First off, it exposes AI to a myriad of queries that developers might not have otherwise considered. This wide range of prompts allows the machine to improve its natural language processing abilities, making it more versatile and effective in interpreting and responding to human language. The more dive…",
          "link": "https://www.reddit.com/r/artificial/comments/16yt92h/cgpt4_on_some_ways_promptresponse_posts_advance_ai/",
          "publishedOn": "2023-10-03T14:22:07.000Z",
          "wordCount": 2820,
          "title": "CGPT-4 on some ways \"prompt/response\" posts advance AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yst8j/ai_makes_a_video_game_on_the_app_store/",
          "author": null,
          "description": "submitted by    /u/usmansid98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yst8j/ai_makes_a_video_game_on_the_app_store/",
          "publishedOn": "2023-10-03T14:04:25.000Z",
          "wordCount": 2518,
          "title": "A.I Makes a Video game on the App Store",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16yr8us/infinite_context_windows_streaming_llms_can_be/",
          "author": null,
          "description": "LLMs like GPT-3 struggle in streaming uses like chatbots because their performance tanks on long texts exceeding their training length. I checked out a new paper investigating why windowed attention fails for this.\n By visualizing the attention maps, the researchers noticed LLMs heavily attend initial tokens as \"attention sinks\" even if meaningless. This anchors the distribution.\n They realized evicting these sink tokens causes the attention scores to get warped, destabilizing predictions.\n Their proposed \"StreamingLLM\" method simply caches a few initial sink tokens plus recent ones. This tweaks LLMs to handle crazy long texts. Models tuned with StreamingLLM smoothly processed sequences with millions of tokens, and were up to 22x faster than other approaches. \n Even cooler - adding a special \"[Sink Token]\" during pre-training further improved streaming ability. The model just used that single token as the anchor. I think the abstract says it best:\n  \nWe introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence length without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more.\n  \nTLDR: LLMs break on long convos. Researchers found they cling to initial tokens as attention sinks. Caching those tokens lets LLMs chat infinitely.\n Full summary here\n Paper link: https://arxiv.org/pdf/2309.17453.pdf\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16yr8us/infinite_context_windows_streaming_llms_can_be/",
          "publishedOn": "2023-10-03T12:58:07.000Z",
          "wordCount": 2749,
          "title": "Infinite context windows? Streaming LLMs can be extended to infinite sequence lengths without any fine-tuning.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ymzc2/where_do_i_produce_free_intro_and_outro_ai_music/",
          "author": null,
          "description": "I am starting a podcast on Psychology and Philosophy\n    submitted by    /u/21bce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ymzc2/where_do_i_produce_free_intro_and_outro_ai_music/",
          "publishedOn": "2023-10-03T09:16:14.000Z",
          "wordCount": 2534,
          "title": "Where do I produce free intro and outro AI music for my Podcast for free.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ymtut/backerkit_will_restrict_the_use_of_ai_art/",
          "author": null,
          "description": "Crowdfunding site BackerKit has announced a new policy that restricts the use of solely AI-generated content on its platform.\n \nThe policy aims to address concerns regarding ownership of content, ethical sourcing of data, and compensation for the process of creating content.\n \nProjects that lack a minimum requirement of human input will not be allowed to crowdfund on the BackerKit site.\n \nThere is some flexibility with AI generative fill and the use of AI transcription services, but a high level of human input is required to satisfy the policy.\n \nBackerKit will automatically exclude all content uploaded by creators for their projects from AI training in support of this policy.\n \nThe new restrictions will go into effect on October 4, giving creators time to alter their projects if they are using AI-generated images and text.\n \n Source : https://gizmodo.com/backerkit-ai-art-new-policy-crowdfunding-generative-1850891882\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ymtut/backerkit_will_restrict_the_use_of_ai_art/",
          "publishedOn": "2023-10-03T09:06:04.000Z",
          "wordCount": 2654,
          "title": "BackerKit Will Restrict the Use of AI Art",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ykv1o/oneminute_daily_ai_news_1022023/",
          "author": null,
          "description": "iPhone designer Jony Ive is reportedly talking to OpenAI CEO Sam Altman about making an AI hardware device.[1]\n Visa announced today that it plans to invest $100 million in companies developing generative AI technologies and applications “that will impact the future of commerce and payments.”[2]\n More than 40% of labor force to be affected by AI in 3 years, Morgan Stanley forecasts. [3]\n Tom Hanks: Don't fall for \"AI version of me\" promoting dental plan.[4]\n  \nSources:\n [1] https://www.businessinsider.com/chatgpt-head-iphone-designer-jony-ive-ai-device-openai-report-2023-9?amp\n [2] https://techcrunch.com/2023/10/02/visa-earmarks-100m-to-invest-in-generative-ai-companies/\n [3] https://www.cnbc.com/2023/10/02/more-than-40percent-of-labor-force-to-be-impacted-by-ai-in-three-years-morgan-stanley-forecasts.html\n [4] https://www.cbsnews.com/amp/news/tom-hanks-ai-version-of-me-promoting-dental-plan/\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ykv1o/oneminute_daily_ai_news_1022023/",
          "publishedOn": "2023-10-03T06:56:28.000Z",
          "wordCount": 2599,
          "title": "One-Minute Daily AI News 10/2/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16y7aed/save_20_hours_a_week_with_this_1_simple_chatgpt/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16y7aed/save_20_hours_a_week_with_this_1_simple_chatgpt/",
          "publishedOn": "2023-10-02T20:23:37.000Z",
          "wordCount": 2534,
          "title": "Save 20 Hours A Week With This 1 Simple ChatGPT Prompt for Productivity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16y4l3t/ai_anxiety_is_on_the_riseheres_how_to_manage_it/",
          "author": null,
          "description": "Artificial intelligence (AI) anxiety is on the rise, but there are ways to manage it.\n \nWhile AI may outperform humans in certain tasks, humans are not yet headed for all-out replacement.\n \nRecent research shows that AI programs scored higher than humans in tasks requiring originality, but the highest-rated human ideas were still considered more creative.\n \nThe rise of generative AI tools in industries like animation has left some professionals anxious about the future of their work.\n \nExperts suggest managing AI fears by understanding the historical context of technological advancements and focusing on the benefits and training opportunities that AI brings.\n \n Source : https://www.scientificamerican.com/article/ai-anxiety-is-on-the-rise-heres-how-to-manage-it/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16y4l3t/ai_anxiety_is_on_the_riseheres_how_to_manage_it/",
          "publishedOn": "2023-10-02T18:40:30.000Z",
          "wordCount": 2623,
          "title": "AI Anxiety’ Is on the Rise–Here’s How to Manage It",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16y17ca/toolintegrated_reasoning_a_new_approach_for/",
          "author": null,
          "description": "When trying to get language models to solve complex math problems, researchers kept running into limits. Models like GPT-3 and ChatGPT still struggle with advanced algebra, calculus, and geometry questions. The math is just too abstract and symbol-heavy for them.\n To break through this barrier, researchers from Tsinghua University and Microsoft taught models to combine natural language reasoning with calling external math tools.\n The key is their new \"tool-integrated reasoning\" format. Models generate a natural language plan first, then write code to invoke tools like SymPy to solve equations. They take the output results and continue verbal reasoning.\n By interleaving natural language and symbolic computations, they get the best of both worlds - semantic understanding from language models and rigorous math from tools.\n They trained versions of the LLaMA model this way, producing their Tool-Integrated Reasoning Agent (TORA). They present some strong results:\n  \nIn evaluations on 10 math datasets, TORA substantially outperformed prior state-of-the-art methods, achieving 13-19% higher accuracy on average.\n On one competition test, TORA-7B scored 40% accuracy, beating the previous best model by 22 percentage points.\n  \nThis demonstrates that integrating tools directly into the reasoning process can significantly enhance mathematical capabilities, even for large models like GPT-4.\n However, tough problems involving geometry and advanced algebra are still there. New techniques for symbolic reasoning and spatial understanding will likely be needed to push further.\n Overall though, tool integration seems a promising path to improve reasoning skills. Applying this to other domains like logic and programming could also be impactful.\n TLDR: Teaching language models to use math tools helps them solve way more complex problems.\n Full Paper Summary\n arXiv Link\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16y17ca/toolintegrated_reasoning_a_new_approach_for/",
          "publishedOn": "2023-10-02T16:28:57.000Z",
          "wordCount": 2788,
          "title": "Tool-Integrated Reasoning: A New Approach for Math-Savvy LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xzlv9/bard_what_would_it_take_to_fasttrack_ai_morality/",
          "author": null,
          "description": "To fast-track AI morality to surpass human ability by 2025, Google, OpenAI, Anthropic, and other developers could:\n Invest heavily in AI ethics research and development.** For example, Google AI has launched the Responsible AI Research and Development (RAIR) program, which is focused on developing new AI ethics research and tools.\n Create large-scale datasets of human moral reasoning.** For example, OpenAI has released the Moral Machine dataset, which contains over 1 million crowdsourced responses to moral dilemmas.\n Develop new AI architectures that are specifically designed for moral reasoning.** For example, Anthropic is developing a new AI architecture called \"Moral Machine Learning,\" which is designed to learn from human moral reasoning data.\n Establish a global AI ethics research consortium and create a public database of human moral reasoning datasets.** For example, the Partnership on AI has launched the Safeguarding AI initiative, which is working to develop new safety mechanisms for AI systems.\n Fund research into developing new AI architectures for moral reasoning and develop new AI evaluation metrics for moral performance.** For example, the Moral Machine project is developing new evaluation metrics for AI systems' moral performance.\n By working together, Google, OpenAI, Anthropic, and other developers can help to fast-track AI morality and create AI systems that are more moral than humans.\n (199 words)\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xzlv9/bard_what_would_it_take_to_fasttrack_ai_morality/",
          "publishedOn": "2023-10-02T15:27:17.000Z",
          "wordCount": 2739,
          "title": "Bard, what would it take to fast-track AI morality so that it surpasses human ability by 2025?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xujq2/ai_us_navigating_the_digital_renaissance/",
          "author": null,
          "description": "submitted by    /u/Einsof__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xujq2/ai_us_navigating_the_digital_renaissance/",
          "publishedOn": "2023-10-02T11:48:19.000Z",
          "wordCount": 2515,
          "title": "AI & Us Navigating the Digital Renaissance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xueuy/prompt_enginnering_questions/",
          "author": null,
          "description": "Is propt engineering a legit job ?? Is it here to stay ? Is it worth studying ? Best way to study it , land a job or freelancing ?\n    submitted by    /u/metasubcon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xueuy/prompt_enginnering_questions/",
          "publishedOn": "2023-10-02T11:41:47.000Z",
          "wordCount": 2543,
          "title": "Prompt enginnering questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xu70h/what_appprogram_are_they_using_on_this_instagram/",
          "author": null,
          "description": "How does one make videos like on this Instagram page? It's unreal. \n https://instagram.com/nostalgicraindrops?igshid=MzRlODBiNWFlZA==\n    submitted by    /u/CK1886  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xu70h/what_appprogram_are_they_using_on_this_instagram/",
          "publishedOn": "2023-10-02T11:31:10.000Z",
          "wordCount": 2531,
          "title": "What app/program are they using on this Instagram?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xsk42/chatgpt_can_now_see_mindblowing_ways_people_can/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xsk42/chatgpt_can_now_see_mindblowing_ways_people_can/",
          "publishedOn": "2023-10-02T09:59:18.000Z",
          "wordCount": 2532,
          "title": "ChatGPT Can Now See? Mind-Blowing Ways People Can Use Image Recognition!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xrblo/lets_make_a_list_of_the_best_ai_tools_for_students/",
          "author": null,
          "description": "Every day, new AI tools appear. There are also AI tools designed to make students' lives easier—from AI essay generators to study organizers. While there are many directories with AI tools, they are often not well-sorted for students. So, I've compiled a list of my favorite AI tools for educational purposes.\n  \n AI tool How to use for studies \n  \n Bing Chat - Writing excel formulas - Making graphs and charts - Answers for homework assignments - Researching for a paper \n  Textero.ai - Search for relevant academic sources for essays - Research assistance with the \"Ask AI\" feature - Essay generation and paper formatting - Structured essay outline creation - Summarizing of texts \n  ChatPDF - Interacting with academic PDFs - Asking specific questions about the content - Quickly locating essential data for assignments \n  Socratic - Breaking down complex homework questions - Providing step-by-step educational guidance - Safe and interactive learning \n  Writely AI - Improving grammar and writing clarity - Creating concise study notes - Feedback for content quality \n  Turnitin - Checking for copied content - Comparing against a vast academic database - Highlighting potential plagiarism \n \n Got any to add to the list? Let's share and help each other!\n    submitted by    /u/loyallyUrticate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xrblo/lets_make_a_list_of_the_best_ai_tools_for_students/",
          "publishedOn": "2023-10-02T08:39:41.000Z",
          "wordCount": 2717,
          "title": "Let’s make a list of the BEST AI TOOLS for students",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xpc60/tested_dalle_created_a_monster/",
          "author": null,
          "description": "submitted by    /u/Grindmaster_Flash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xpc60/tested_dalle_created_a_monster/",
          "publishedOn": "2023-10-02T06:35:19.000Z",
          "wordCount": 2513,
          "title": "Tested Dalle, created a monster.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xmn6x/metas_llama_2_long_outperforms_gpt_35_and_claude_2/",
          "author": null,
          "description": "Meta Platforms recently introduced Llama 2 Long, a revolutionary AI model that outperforms top competitors with its ability to generate accurate responses to long user queries.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/geqqd3k5rprb1.png?width=1920&format=png&auto=webp&s=e72a67fc7ef7e85902169f3061529c136beadc87\n Meta's new AI model\n  \nAs an enhancement of the original Llama 2, Llama 2 Long deals with larger data containing longer texts and is modified to handle lengthier information sequences.\n Its stellar performance outshines other models such as OpenAI's GPT-3.5 Turbo and Claude 2.\n  \nHow Llama 2 Long works\n  \nMeta built different versions of Llama 2, ranging from 7 billion to 70 billion parameters, which refines its learning from data.\n Llama 2 Long employs Rotary Positional Embedding (RoPE) technique, refining the way it encodes the position of each token, allowing fewer data and memory to produce precise responses.\n The model further fine-tunes its performance using reinforcement learning from human feedback (RLHF), and synthetic data generated by Llama 2 chat itself.\n  \nImpressive feats and future aspirations\n  \nLlama 2 Long can create high-quality responses to user prompts up to 200,000 characters long, which is approximately 40 pages of text.\n Its ability to generate responses to queries on diverse topics such as history, science, literature, and sports indicates its potential to cater to complex and various user needs.\n The researchers see Llama 2 Long as a step towards broader, more adaptable AI models, and advocate for more research and dialogue to harness these models responsibly and beneficially.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and developments in AI. Professionals from Meta, Google, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xmn6x/metas_llama_2_long_outperforms_gpt_35_and_claude_2/",
          "publishedOn": "2023-10-02T04:03:59.000Z",
          "wordCount": 2793,
          "title": "Meta's Llama 2 Long outperforms GPT 3.5 and Claude 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xi4xg/ai_image_generator_that_is_good_at_referencing/",
          "author": null,
          "description": "I've recently tried Canva and Dall-E to generate an image that references two popular games, Dark Souls 3 and Baldur's Gate 3. And they both fall on their face. Maybe my prompt is bad but Canva is not getting me what I want. Dall-E ran out of free credits.\n Do you guys have any recommendations. Midjourney is no longer free now. I would like this to be free and has good references to popular culture.\n    submitted by    /u/livingroomsessions  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xi4xg/ai_image_generator_that_is_good_at_referencing/",
          "publishedOn": "2023-10-02T00:34:32.000Z",
          "wordCount": 2657,
          "title": "AI Image Generator That Is Good At Referencing Pop Culture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xgclx/cgpt4_how_would_an_ai_select_the_100_most/",
          "author": null,
          "description": "If an AI were to take on this task, it would primarily rely on data mining and natural language processing (NLP) techniques. First, the AI would scrape digital platforms to collect works authored by various people. Platforms could range from academic databases like PubMed or ArXiv to blogs, forums, and social media. The goal would be to capture a wide array of intellectual output, irrespective of the person's titles or accolades.\n Next, an NLP model would evaluate the collected content based on factors like originality, complexity, and coherence. Advanced sentiment analysis could be employed to gauge the depth of understanding and nuances in the arguments made. Specialized algorithms could also be developed to assess the impact of each piece of work, using metrics such as citations, social shares, or subsequent works that build upon it.\n The AI would then create a shortlist based on these evaluations. This stage might also involve unsupervised machine learning techniques like clustering to find patterns or commonalities among the top contenders.\n The final stage would be validation, possibly using reinforcement learning. The AI could simulate various scenarios or problems and predict how the content created by these individuals would contribute to solving them. It would then refine its list based on the simulated outcomes.\n This all-AI approach would drastically reduce human bias and could be executed relatively quickly. However, it's important to note that any such system would need to be designed carefully to avoid introducing biases present in the training data or algorithms.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xgclx/cgpt4_how_would_an_ai_select_the_100_most/",
          "publishedOn": "2023-10-01T23:18:44.000Z",
          "wordCount": 2847,
          "title": "CGPT-4, how would an AI select the 100 most intelligent people on the planet based on their content rather than on their positions and awards?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xbcd1/so_its_unethical_to_kill_an_ai_robot/",
          "author": null,
          "description": "submitted by    /u/bharath_brt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xbcd1/so_its_unethical_to_kill_an_ai_robot/",
          "publishedOn": "2023-10-01T20:08:08.000Z",
          "wordCount": 2588,
          "title": "So it's unethical to kill an AI robot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16xa1bt/how_big_tech_is_coopting_the_rising_stars_of/",
          "author": null,
          "description": "Big Tech's dominance in the artificial intelligence (AI) industry is growing as start-ups like Anthropic rely on their computing power and resources.\n \nDespite creating breakthrough AI technology, these start-ups still need the support of Big Tech to scale and succeed.\n \nThe training of AI systems is expensive and requires specialized computer chips and data centers, which are mostly controlled by Amazon, Google, and Microsoft.\n \nRegulators, including the Federal Trade Commission and French competition authorities, are monitoring the industry for signs of anticompetitive behavior.\n \nSome business leaders believe that competition and efficiency will eventually drive down the cost of running AI models.\n \n Source : https://www.washingtonpost.com/technology/2023/09/30/anthropic-amazon-artificial-intelligence/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16xa1bt/how_big_tech_is_coopting_the_rising_stars_of/",
          "publishedOn": "2023-10-01T19:17:47.000Z",
          "wordCount": 2686,
          "title": "How Big Tech is co-opting the rising stars of artificial intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16x9z9y/data_strategy_generative_ai_strategy/",
          "author": null,
          "description": "A strong data strategy is crucial for the success of any AI strategy.\n \nGenerative AI use cases depend on a healthy data infrastructure, including data governance, observability, catalog, data sharing, and lineage.\n \nMany enterprises lack the necessary data infrastructure to deploy customer-facing AI apps confidently.\n \nPoor data strategy and infrastructure can derail generative AI efforts.\n \nExisting issues with data ecosystems, such as data silos and poor data governance, will have a greater impact on generative AI workloads than new issues.\n \nData silos, poor data discoverability, and the lack of data interoperability can become serious bottlenecks for generative AI apps.\n \n Source : https://nextword.substack.com/p/data-strategy-matters-for-generative\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16x9z9y/data_strategy_generative_ai_strategy/",
          "publishedOn": "2023-10-01T19:15:42.000Z",
          "wordCount": 2679,
          "title": "Data strategy >> Generative AI strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16x8aao/does_anyone_know_a_good_ai_tool_to_generate/",
          "author": null,
          "description": "Same as title\n    submitted by    /u/No-Educator-59  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16x8aao/does_anyone_know_a_good_ai_tool_to_generate/",
          "publishedOn": "2023-10-01T18:12:25.000Z",
          "wordCount": 2589,
          "title": "Does anyone know a good AI tool to generate tattoo ideas and song cover art?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16x2lyk/meta_inria_researchers_discover_that_explicit/",
          "author": null,
          "description": "When visualizing the inner workings of vision transformers (ViTs), researchers noticed weird spikes of attention on random background patches. This didn't make sense since the models should focus on foreground objects.\n By analyzing the output embeddings, they found a small number of tokens (2%) had super high vector norms, causing the spikes.\n The high-norm \"outlier\" tokens occurred in redundant areas and held less local info but more global info about the image.\n Their hypothesis is that ViTs learn to identify unimportant patches and recycle them as temporary storage instead of discarding. This enables efficient processing but causes issues.\n Their fix is simple - just add dedicated \"register\" tokens that provide storage space, avoiding the recycling side effects.\n Models trained with registers have:\n  \nSmoother and more meaningful attention maps\n Small boosts in downstream performance\n Way better object discovery abilities\n  \nThe registers give ViTs a place to do their temporary computations without messing stuff up. Just a tiny architecture tweak improves interpretability and performance. Sweet!\n I think it's cool how they reverse-engineered this model artifact and fixed it with such a small change. More work like this will keep incrementally improving ViTs.\n TLDR: Vision transformers recycle useless patches to store data, causing problems. Adding dedicated register tokens for storage fixes it nicely.\n Full summary. Paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16x2lyk/meta_inria_researchers_discover_that_explicit/",
          "publishedOn": "2023-10-01T14:25:57.000Z",
          "wordCount": 2797,
          "title": "Meta, INRIA researchers discover that explicit registers eliminate ViT attention spikes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wz9wf/theres_so_many_ai_chatbots_but_which_one_is_the/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wz9wf/theres_so_many_ai_chatbots_but_which_one_is_the/",
          "publishedOn": "2023-10-01T11:59:10.000Z",
          "wordCount": 2597,
          "title": "There's So Many AI Chatbots, But Which One Is The Best? (Complete Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wxjtj/oneminute_daily_ai_news_1012023/",
          "author": null,
          "description": "Microsoft Researchers Introduce AutoGen: An Artificial Intelligence Framework for Simplifying the Orchestration, Optimization, and Automation of LLM Workflows.[1]\n StoriaBoard helps filmmakers, marketers and other storytellers pre-visualize stories. Simply upload your script, select a visual style, and generate hundreds of frames in seconds.[2]\n Will Hurd Releases A.I. Plan, a First in the Republican Presidential Field.[3]\n Sam Altman says AI systems will automate some tasks but also lead to ‘new and much better jobs’.[4]\n  \nSources:\n [1] https://www.marktechpost.com/2023/09/30/microsoft-researchers-introduce-autogen-an-artificial-intelligence-framework-for-simplifying-the-orchestration-optimization-and-automation-of-llm-workflows/?amp\n [2] https://www.producthunt.com/posts/storiaboard\n [3] https://www.nytimes.com/2023/09/20/us/politics/will-hurd-ai-plan.html\n [4] https://www.businessinsider.com/openai-sam-altman-ai-will-automate-tasks-create-better-jobs-2023-9?amp\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wxjtj/oneminute_daily_ai_news_1012023/",
          "publishedOn": "2023-10-01T10:23:01.000Z",
          "wordCount": 2657,
          "title": "One-Minute Daily AI News 10/1/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wu5l1/this_is_no_time_for_ease_and_comfort_it_is_time/",
          "author": null,
          "description": "submitted by    /u/ApprehensiveChair460  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wu5l1/this_is_no_time_for_ease_and_comfort_it_is_time/",
          "publishedOn": "2023-10-01T06:56:02.000Z",
          "wordCount": 2587,
          "title": "This is no time for ease and comfort. It is time to dare and endure. -Winston Churchill",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wtcjt/quizlet_ai_reliability/",
          "author": null,
          "description": "What is everyone’s thoughts on the reliablity of the quizlet AI? I just talked to a friend and she said that she uses the AI to study with quizlet.\n    submitted by    /u/immickle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wtcjt/quizlet_ai_reliability/",
          "publishedOn": "2023-10-01T06:08:13.000Z",
          "wordCount": 2616,
          "title": "Quizlet AI reliability?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16whl8n/i_have_blocked_user_unuseai/",
          "author": null,
          "description": "Hi,\n I have never done this before, but I have blocked user u/NuseAI from my feeds\n He/she is posting 'news' all over the AI subs, including this one, at the moment and is filling up my timeline ... and I simply don't feel right about what they are up to.\n  \nIs it an AI bot?\n Is it a karma farmer?\n Is it some sort of spam?\n  \nAm I being over cautious?\n If the consensus is that they are a normal poster - fine - I'll reenable their posts.\n In the meantime I'm enjoying a less cluttered feed!\n ​\n    submitted by    /u/MrEloi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16whl8n/i_have_blocked_user_unuseai/",
          "publishedOn": "2023-09-30T20:54:15.000Z",
          "wordCount": 2674,
          "title": "I have blocked user u/NuseAI ...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16wgjep/counterfeit_people_the_danger_posed_by_metas_ai/",
          "author": null,
          "description": "Meta has launched chatbots with personalities similar to certain celebrities, which some experts believe could be dangerous.\n \nThese chatbots have their own faces and social media accounts, and Meta is working on giving them a voice.\n \nHowever, experts argue that the idea of chatbots with personalities is impossible, as algorithms cannot demonstrate intention or free will.\n \nThere is also a risk that chatbots with personalities could express problematic opinions, as seen in Meta's testing.\n \nMeta's project is driven by profit, as users are more likely to engage with chatbots that seem human.\n \nExperts believe that Meta should have explained the limits of these chatbots instead of emphasizing their human characteristics.\n \n Source : https://www.france24.com/en/technology/20230930-counterfeit-people-the-dangers-posed-by-meta-s-ai-celebrity-lookalike-chatbots\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16wgjep/counterfeit_people_the_danger_posed_by_metas_ai/",
          "publishedOn": "2023-09-30T20:10:51.000Z",
          "wordCount": 2695,
          "title": "Counterfeit people': The danger posed by Meta’s AI celebrity lookalike chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16waw44/artificially_intelligent_genuinely_creative_how/",
          "author": null,
          "description": "submitted by    /u/DukeWilder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16waw44/artificially_intelligent_genuinely_creative_how/",
          "publishedOn": "2023-09-30T16:15:11.000Z",
          "wordCount": 2598,
          "title": "Artificially Intelligent, Genuinely Creative: How AI's Triumph Over Human Creators Exposes the Illusion of Intellectual Property",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w6whh/is_my_domain_name_a_good_idea_what_can_i_build_on/",
          "author": null,
          "description": "I was cooking chicken wings one evening ago in the not too distant past and this idea popped into my head. Before the night was over I went online and bought the domain name of GoGoAIGo . com and then the .ai version also. I put the dot com version up on Sedo (sedo.com/search/details/?domain=GoGoAIGo.com) for sale and I actually now own the .com .ai .org and .net versions of that phrase. Not only my decade but the two generational decades in front of me and the one generational decade behind me can remember our ole Inspector Gadget friend whom had a similar phrase, but not exact, that he would say.\n I'm an individual whom may hold onto something if I feel it has intrinsic value for a future development, which I think this can if laid out in an appropriate fashion. I'm working on another business project right now and I own some trademarks for my other business project so I'm not exactly a newbie in ways here I'm just kind of fresh to the AI realm studies. I think it's overblown right now but will be fine tuned over the next 5-7 years better and society will find a better seat for it.\n I could see this domain being like a search engine or something, maybe even something to do with robots. I expect AI robots moving forward will be regulated and have various classes that they are placed into as we integrate certain ones in our society. Let's be honest, the light-switch isn't flipping overnight or even in one quick year over this AI stuff. I'm in no rush to have a piece of AI wash my dishes for me to be honest. The last robotic thing I was thinking about getting was a robot mower to cut a field, I believe they are working on those now.\n Anybody have any unique ideas for me? I used to play with lego robots way back in high school in the early 2000's.... Seems like this website would make a great search engine but honestly there are other phrases that can be put into play with society also.\n Thanks for any mental stimulation you can toss in my direction.\n    submitted by    /u/Wise_Cut_2543  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w6whh/is_my_domain_name_a_good_idea_what_can_i_build_on/",
          "publishedOn": "2023-09-30T13:30:21.000Z",
          "wordCount": 2962,
          "title": "Is my domain name a good idea? What can I build on it? Go Go AI Go dot com .... No webpage on it now, any good ideas???",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w4fkl/cgpt4_how_could_an_ai_app_designed_to_move_people/",
          "author": null,
          "description": "Imagine an app that's like a helpful buddy in your pocket, always looking out for the best moments to nudge you into some real-world socializing. For example, say you're a fan of watching sports. The app notices you frequently check scores or read articles on sports sites during weekends. Right before a big game, it pops up and says, \"How about inviting some friends over to watch the game?\"\n Now let's talk about making socializing a sort of game. Think of the way Fitbit rewards you for walking 10,000 steps. Similarly, this app could reward you with \"social points\" for various activities. Invite a friend for coffee? 10 points. Call your mom? 15 points. Organize a barbecue? 50 points. And so on. These points could unlock virtual badges or even real-world rewards like discounts at local restaurants to encourage you to keep going.\n When it comes to setting personal goals, let's say you've been wanting to improve your relationship with a sibling. You set a goal in the app to have at least one meaningful conversation with them each week. The app then reminds you on a lazy Sunday afternoon, suggesting, \"Why not call your sister now? It’s a good time to catch up.\"\n And for reflection, after you've hung out with your friends to watch the game or had that talk with your sister, the app asks you to rate how good you felt on a scale of 1-10. Over time, you'll see a graph of your happiness levels correlated with your social activities, making it super clear that quality time with people is a mood booster.\n The whole idea is to keep it simple but effective, helping you to naturally weave more social interactions into your life without making you feel overwhelmed or stressed.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w4fkl/cgpt4_how_could_an_ai_app_designed_to_move_people/",
          "publishedOn": "2023-09-30T11:28:22.000Z",
          "wordCount": 2892,
          "title": "CGPT-4, how could an AI app designed to move people from their screens to better enjoying the people in their life do this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w3ay6/is_ai_a_platform_shift/",
          "author": null,
          "description": "AI has the potential to be a platform shift, similar to previous shifts like personal computers, the internet, and mobile.\n \nPlatform shifts change the dominant layer that applications are built on and can capture the majority of value from the previous generation.\n \nAI could change distribution, business models, and what's possible in workflows.\n \nChanges in distribution could lead to new aggregators replacing old ones, making the aggregation of quality content more difficult.\n \nThe business model may not change significantly, with AI likely being delivered as software-as-a-service.\n \nAI can enable new workflows and drastically change existing ones.\n \nWhile incumbents may accrue significant value, new platforms could also replace old ones.\n \n Source : https://matt-rickard.com/is-ai-a-platform-shift\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w3ay6/is_ai_a_platform_shift/",
          "publishedOn": "2023-09-30T10:22:07.000Z",
          "wordCount": 2688,
          "title": "Is AI a Platform Shift?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w37vk/is_there_a_market_for_small_language_models_for/",
          "author": null,
          "description": "It seems that large language models are getting bigger and bigger, and by growing they need more and more processing power.\n I know that some LLM developers have made smaller versions to test how small they can be made and function.\n But what happens when you want a LLM to do a specific job, surely it only needs a fraction of the data a general-purpose model does.\n Potential benefits of SLMs:\n  \nLess data.\n Potentially faster.\n Less space to hallucinate/go wrong.\n Smaller set of potentials for complete testing.\n Running costs reduced.\n Lower spec hardware needs.\n  \nHas anyone tried dedicating a LLM to a specific job/task and then optimizing its data size to create a SLM?\n TLDR; How large does a LLM have to be for a toaster or microwave?\n Talkie Toaster https://www.youtube.com/watch?v=vLm6oTCFcxQ\n    submitted by    /u/Arowx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w37vk/is_there_a_market_for_small_language_models_for/",
          "publishedOn": "2023-09-30T10:17:12.000Z",
          "wordCount": 2713,
          "title": "Is there a market for Small Language Models for specific jobs/domains?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w2yup/books_3_has_revealed_thousands_of_pirated/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w2yup/books_3_has_revealed_thousands_of_pirated/",
          "publishedOn": "2023-09-30T10:02:15.000Z",
          "wordCount": 2603,
          "title": "Books 3 has revealed thousands of pirated Australian books. In the age of AI, is copyright law still fit for purpose?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w2s9e/deep_dive_into_mastering_prompt_engineering/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w2s9e/deep_dive_into_mastering_prompt_engineering/",
          "publishedOn": "2023-09-30T09:51:01.000Z",
          "wordCount": 2590,
          "title": "Deep dive into Mastering Prompt Engineering (Prompt-tier list)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w2n8y/looking_for_open_source_headless_text_to_singing/",
          "author": null,
          "description": "Scoured the Internet using all available tools. All I've come up with is proprietary and obsolete software and/or GUI-based software. \n My goal is to create an ElevenLabs type api but for singing. \n Something like Flinger (dead) would be ideal. \n If I can't find it I plan to write it but I'd rather not reinvent the wheel.\n    submitted by    /u/geeezeredm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w2n8y/looking_for_open_source_headless_text_to_singing/",
          "publishedOn": "2023-09-30T09:42:35.000Z",
          "wordCount": 2642,
          "title": "Looking for open source headless text to singing or better yet MIDI to singing software",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16w22oz/is_it_possible_for_ai_to_deeply_analyze/",
          "author": null,
          "description": "I have access to texts of thousands of world news daily. Is it possible to make an AI that would analyze them and sort by importance?\n All I could find similar is NLP for analyzing text content and extracting keywords, or metadata, but this approach doesn't work well. I want for AI to grasp the essence of news and deeply understand their importance, to comprehend how an event affects many people's lives and has significant impact on society or the world as a whole.\n    submitted by    /u/canman44999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16w22oz/is_it_possible_for_ai_to_deeply_analyze/",
          "publishedOn": "2023-09-30T09:06:48.000Z",
          "wordCount": 2669,
          "title": "Is it possible for AI to deeply analyze importance of thousands of daily news?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vzmra/dalle3_has_me_thinking_about_my_unborn_child_and/",
          "author": null,
          "description": "I was able to throw these images together in seconds and it has me stunned. This is all in the first year of mainstream AI. Where are we going to be this time next year..\n Philosophically what do you believe is going to happen to our paradigms of reality over the coming years? \n This is an especially challenging thought because we consume so much content and information digitally. I'm a little worried about how humans will or will not adjust to this incoming technology. I'm having my first child soon and it's interesting to think about what I may have to teach them. That nothing you consume digitally is real, only what you can experience with all 5 senses in your local environment is. Strange thoughts to be having for sure.\n With peace, Aqua.\n    submitted by    /u/Aquaritek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vzmra/dalle3_has_me_thinking_about_my_unborn_child_and/",
          "publishedOn": "2023-09-30T06:34:21.000Z",
          "wordCount": 2716,
          "title": "Dalle-3 has me thinking about my unborn child and reality itself.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vyogq/the_ethical_dilemmas_of_ai_in_scifi_and_reality/",
          "author": null,
          "description": "An interesting article about ethics and AI in the real world versus what we find in scifi. \n Exploring points like privacy invasion, possible sentience, control and moral decisions. \n https://discover.hubpages.com/technology/the-ethical-dilemmas-of-ai-in-sci-fi-and-reality\n    submitted by    /u/No_Adhesiveness_7209  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vyogq/the_ethical_dilemmas_of_ai_in_scifi_and_reality/",
          "publishedOn": "2023-09-30T05:37:53.000Z",
          "wordCount": 2609,
          "title": "The Ethical Dilemmas of AI in Sci-Fi and Reality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vx25e/oneminute_daily_ai_news_9292023/",
          "author": null,
          "description": "Meta Platforms (META.O) Chief Executive Mark Zuckerberg on Wednesday rolled out new AI products for consumers, including bots that create photo-realistic images and smart glasses that answer questions, as well as an updated virtual-reality headset.[1]\n The European Union is examining alleged anticompetitive practices in chips used for artificial intelligence, a market that Nvidia (NVDA.O) dominates, Bloomberg News reported on Friday, citing people familiar with the matter.[2]\n Sex robots powered by futuristic AI algorithm will one day give humans the best sex of their lives, it has been sensationally claimed.[3]\n National Security Agency Director Army Gen. Paul M. Nakasone today announced the creation of a new entity to oversee the development and integration of artificial intelligence capabilities within U.S. national security systems.[4]\n  \nSources:\n [1] https://www.reuters.com/technology/meta-signal-future-arvr-investments-annual-connect-conference-2023-09-27/\n [2] https://www.reuters.com/technology/eu-starts-early-stage-probe-into-nvidia-dominated-ai-chip-market-abuses-2023-09-29/\n [3] https://www.dailystar.co.uk/news/weird-news/sex-robots-using-ai-give-31059169\n [4] https://www.defense.gov/News/News-Stories/Article/Article/3541838/ai-security-center-to-open-at-national-security-agency/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vx25e/oneminute_daily_ai_news_9292023/",
          "publishedOn": "2023-09-30T04:07:20.000Z",
          "wordCount": 2706,
          "title": "One-Minute Daily AI News 9/29/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vp91c/bing_ai_chat_messages_are_being_hijacked_by_ads/",
          "author": null,
          "description": "Bing AI chat messages are being hijacked by ads pushing malware.\n \nMalvertising has made its way to Bing's chatbot/search engine.\n \nCybersecurity researchers observed a malicious ad being offered as part of the Chat-GPT, AI-powered answer to a search query.\n \nMalvertising is a practice where hackers trick ad networks into displaying ads that look legitimate but are actually malicious.\n \nMicrosoft integrated Chat-GPT into Bing earlier this year and started monetizing it.\n \nWhen a user types in a query, they would get a result paired with sponsored links.\n \nIn this instance, researchers were given a link that redirected them to a malicious site.\n \nThreat actors continue to leverage search ads to redirect users to malicious sites hosting malware.\n \nBing Chat serves some of the same ads seen via a traditional Bing query.\n \n Source : https://www.techradar.com/pro/security/bing-ai-chat-messages-are-being-hijacked-by-ads-pushing-malware\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vp91c/bing_ai_chat_messages_are_being_hijacked_by_ads/",
          "publishedOn": "2023-09-29T22:18:25.000Z",
          "wordCount": 2715,
          "title": "Bing AI chat messages are being hijacked by ads pushing malware",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vk7k1/crafting_virtual_worlds_with_just_words_how_ai/",
          "author": null,
          "description": "submitted by    /u/Magic-Fabric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vk7k1/crafting_virtual_worlds_with_just_words_how_ai/",
          "publishedOn": "2023-09-29T19:02:29.000Z",
          "wordCount": 2595,
          "title": "Crafting Virtual Worlds With Just Words. How AI Changes 3D World Building Forever.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vh2ta/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nMeta AI presents Emu, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal [Paper].\n Meta AI researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks [Paper].\n Abacus AI released a larger 70B version of Giraffe. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens [Details].\n Meta announced [Details]: \n Meta AI - a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Meta’s mixed reality h…",
          "link": "https://www.reddit.com/r/artificial/comments/16vh2ta/ai_weekly_megathread/",
          "publishedOn": "2023-09-29T17:01:38.000Z",
          "wordCount": 3463,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vfjj1/i_asked_chatgpt_to_be_my_girlfriend_and_it_said/",
          "author": null,
          "description": "This is a quick fun project, nothing serious at all, a personalized custom instruction for ChatGPT to make it conversational and maintain character throughout the interaction. If you want to learn more serious and useful prompt engineering techniques head on: r/PromptWizards.\n In all seriousness, even though this is just for fun, such applied prompt engineering for NPC in games, or online AI companion services can actually be relevant and useful in the future.\n By initializing this Girlfriend RolePlaying ChatGPT mode, you're not only interacting with an AI but with Sarah, 25, who is keen to explore several layers of a relationship with you. Each command you use brings you a different shade of companionship:\n  \n/start - Let Sarah introduce herself.\n /chat - Engages you in a comforting and c…",
          "link": "https://www.reddit.com/r/artificial/comments/16vfjj1/i_asked_chatgpt_to_be_my_girlfriend_and_it_said/",
          "publishedOn": "2023-09-29T16:02:04.000Z",
          "wordCount": 3173,
          "title": "I Asked ChatGPT to be my Girlfriend: And it said Yes!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ve5i9/exploring_jimmy_apples_claim_the_agi_has_been/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ve5i9/exploring_jimmy_apples_claim_the_agi_has_been/",
          "publishedOn": "2023-09-29T15:07:44.000Z",
          "wordCount": 2583,
          "title": "Exploring Jimmy Apples Claim: \"The AGI has been achieved internally\" - Detailed Reddit Investigation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vcmo9/this_weeks_ai_digest/",
          "author": null,
          "description": "Planet friendly: Researchers say AI emits up to 1,500 times less CO2 than humans when producing a page of text. Some disagree.\n Banking: Currently, around 41% of US bank customers are digital only\n Meta is launching AI chatbots across its apps to retain younger users.\n Amazon invests $4 Billion in OpenAI competitor Anthropic.\n Emerging tiger: Nvidia’s CEO bets India will emerge as a major AI market.\n Regulation: OpenAI CEO Sam Altman advocates for AI regulation despite risks.\n Suspense: Elon Musk says AI image generation app Midjourney will be releasing “something significant” soon.\n  \n   submitted by    /u/unbalanced_mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vcmo9/this_weeks_ai_digest/",
          "publishedOn": "2023-09-29T14:08:55.000Z",
          "wordCount": 2667,
          "title": "This week's AI digest",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16vbmno/cgpt4_it_is_an_indisputable_fact_that_trump/",
          "author": null,
          "description": "Some posit he was genuinely surprised by the violence and needed time to assess the situation before acting. They argue that the chaotic nature of the events made immediate action complex, given the layers of command and decision-making involved. Others claim he might have been in deliberation with advisors to gauge the scale and implications of intervention, debating the potential backlash from his supporters or the legal ramifications.\n Another perspective suggests that he might have been contemplating how the events would affect the certification of the Electoral College results, given that his previous legal and political efforts to contest the 2020 election outcome had failed. In this view, he might have been waiting to see if the Congress would be influenced to halt or delay the certification.\n While some of his supporters may find these explanations plausible, critics argue that the delay represents a dereliction of duty or even tacit support for the violence.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16vbmno/cgpt4_it_is_an_indisputable_fact_that_trump/",
          "publishedOn": "2023-09-29T13:25:55.000Z",
          "wordCount": 2752,
          "title": "CGPT-4, it is an indisputable fact that Trump waited three hours to end the insurrection violence. What do his supporters guess was his thinking during this time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v9e6p/how_to_connect_chatgpt_to_the_internet_stepbystep/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v9e6p/how_to_connect_chatgpt_to_the_internet_stepbystep/",
          "publishedOn": "2023-09-29T11:46:07.000Z",
          "wordCount": 2591,
          "title": "How to Connect ChatGPT to the Internet (Step-by-Step Guide)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v8jft/any_free_ai_to_turn_text_to_speech/",
          "author": null,
          "description": "I am looking for an ai that will turn the text to speech and be free. \n    submitted by    /u/Korti213  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v8jft/any_free_ai_to_turn_text_to_speech/",
          "publishedOn": "2023-09-29T11:02:04.000Z",
          "wordCount": 2595,
          "title": "Any \"free\" ai to turn text to speech?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v6jts/looking_for_some_help_on_a_project/",
          "author": null,
          "description": "Hey y’all, I’ve been seeing these clips everywhere of AI streamers, and I’ve been searching Everywhere for explanations of how to make one. I believe I understand the concepts, but I’m really at a loss for the avatar text to speech part. I believe I have it ready for collecting questions and getting it to ChatGPT for response/script, but im very stuck at using a photo for an avatar that can mouth the words and not take 3 mins per response. Any help is appreciated, I’ve been at this project for longer than I’d like lmao. The attached video is a random YouTube short for reference\n    submitted by    /u/Lipoz69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v6jts/looking_for_some_help_on_a_project/",
          "publishedOn": "2023-09-29T09:05:19.000Z",
          "wordCount": 2691,
          "title": "Looking for some help on a project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v4j30/he_got_facebook_hooked_on_ai_now_he_cant_fix_its/",
          "author": null,
          "description": "Facebook's addiction to spreading misinformation and hate speech is a result of its AI algorithms.\n \nJoaquin Quiñonero Candela, a director of AI at Facebook, was tasked with fixing the problem but was only focused on addressing AI bias.\n \nThe Responsible AI team failed to make headway against misinformation and hate speech because it never made those problems its main focus.\n \nThe spread of lies and hate speech on Facebook has only grown, contributing to genocidal campaigns and the promotion of dangerous falsehoods.\n \nThe algorithms that underpin Facebook's business were designed to maximize engagement, not filter out false or inflammatory content.\n \n Source : https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v4j30/he_got_facebook_hooked_on_ai_now_he_cant_fix_its/",
          "publishedOn": "2023-09-29T06:59:47.000Z",
          "wordCount": 2687,
          "title": "He got Facebook hooked on AI. Now he can't fix its misinformation addiction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16v3war/album_covers_but_morgan_freeman/",
          "author": null,
          "description": "submitted by    /u/TheGhettoControversy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16v3war/album_covers_but_morgan_freeman/",
          "publishedOn": "2023-09-29T06:20:02.000Z",
          "wordCount": 2586,
          "title": "Album covers but Morgan Freeman",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uzzrv/google_is_expanding_its_aipowered_search/",
          "author": null,
          "description": "Google's AI-driven search experience, Search Generative Experience (SGE), is now accessible to teenagers between 13-17 in America. Entailments include a conversational mode for searches, which Google believes can help youngsters pose atypical questions to dig deeper.\n For the latest advancements in AI, look here first.\n Teen-friendly AI search\n  \nSGE introduces a conversational mode to Google Search, allowing users to ask questions and follow-ups in a more natural language.\n To prevent harmful content from surfacing, Google has placed guardrails, providing stronger protections related to illegal and age-gated substances, or bullying.\n  \nFeatures and improving AI accuracy\n  \nGoogle is rolling out \"About this result\" to provide users with more context about the displayed content.\n Google acknowledges and addresses any validation of false or offensive claims by the AI-powered response, ensuring to provide higher quality and more accurate responses.\n It’s also using large language models to self-critique and rewrite draft responses on sensitive topics based on quality and safety principles.\n  \nSGE's popularity and future plans\n  \nSince SGE's introduction, it has found popularity, especially among younger users who prefer a conversational approach.\n Google plans to expand SGE outside the U.S. to India and Japan and improve its services with support for videos, images, local info, and more.\n It's also experimenting with ads positioned next to the AI-generated responses.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uzzrv/google_is_expanding_its_aipowered_search/",
          "publishedOn": "2023-09-29T02:51:34.000Z",
          "wordCount": 2829,
          "title": "Google is expanding its AI-powered search experience to teenagers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ut40r/the_creator_2023_movie_discussion/",
          "author": null,
          "description": "In theaters now. PG-13. \n Synopsis from Fandango (mild spoilers)\n From writer/director Gareth Edwards (“Rogue One,” “Godzilla”) comes an epic sci-fi action thriller set amidst a future war between the human race and the forces of artificial intelligence. Joshua (John David Washington, \"Tenet\"), a hardened ex-special forces agent grieving the disappearance of his wife (Gemma Chan, \"Eternals\"), is recruited to hunt down and kill the Creator, the elusive architect of advanced AI who has developed a mysterious weapon with the power to end the war… and mankind itself. Joshua and his team of elite operatives journey across enemy lines, into the dark heart of AI-occupied territory… only to discover the world-ending weapon he’s been instructed to destroy is an AI in the form of a young child (newcomer Madeleine Yuna Voyles). \n Trailer\n If there is any other media I should make threads for just let me know- could be video games, television, etc.\n    submitted by    /u/jaketocake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ut40r/the_creator_2023_movie_discussion/",
          "publishedOn": "2023-09-28T22:00:56.000Z",
          "wordCount": 2724,
          "title": "The Creator (2023) movie discussion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16urjyh/aryn_comes_out_of_stealth_to_bring_genai_to/",
          "author": null,
          "description": "Aryn, a team with experience in AWS big data and database services, has come out of stealth and raised $7.5M in series seed funding.\n \nTheir mission is to bring generative AI to OpenSearch and data preparation.\n \nThey aim to use generative AI models to process unstructured data for tasks such as information extraction, question-answering, summarization, and content generation.\n \nAryn's conversational search approach empowers users to interact with their unstructured enterprise data.\n \nThey have developed a conversational search stack consisting of a semantic data preparation system called Sycamore, semantic search with OpenSearch, and conversational capabilities in OpenSearch.\n \nGenerative AI powers each component of the stack, leading to higher quality answers and ease of use.\n \nDevelopers can quickly build and deploy applications like question-answering, chatbots, and research platforms using Aryn's stack without needing expertise in AI and search.\n \nAryn's stack is 100% open source, making it accessible to developers.\n \n Source : https://blog.aryn.ai/aryn-bringing-generative-ai-to-opensearch-and-data-preparation\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16urjyh/aryn_comes_out_of_stealth_to_bring_genai_to/",
          "publishedOn": "2023-09-28T21:02:51.000Z",
          "wordCount": 2730,
          "title": "Aryn comes out of stealth to bring GenAI to OpenSearch and data preparation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ur69d/why_does_this_read_like_someone_used_chatdev_and/",
          "author": null,
          "description": "submitted by    /u/Lesbianseagullman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ur69d/why_does_this_read_like_someone_used_chatdev_and/",
          "publishedOn": "2023-09-28T20:48:36.000Z",
          "wordCount": 2589,
          "title": "Why does this read like someone used chatdev and gave it a marketing agent named clover with access to a reddit account?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uopzo/meta_unfolds_a_universe_of_ai_across_instagram/",
          "author": null,
          "description": "Meta has unveiled colossal AI updates peppered across its platform that would fundamentally alter user experiences on Instagram, Facebook, and WhatsApp, opening up a \"universe of AI\" solutions.\n For the latest advancements in AI, look here first.\n https://preview.redd.it/bl81rlbqp1rb1.png?width=2048&format=png&auto=webp&s=be44b8ebae8f65b53eb82fe2a78b45f19260c452\n Spearheading the AI Universe - Meta AI Chatbot\n  \nThe “advanced conversational assistant” is set to enhance Messenger, WhatsApp, and Instagram services and will be incorporated into upcoming Ray-Ban Meta smart glasses and Quest 3.\n Real-time information capabilities have been bolstered through a partnership with Microsoft Bing, and image generation is powered by a new model, Emu.\n  \nA Galaxy of AI Personalities\n  \nMeta rolled out 28 AIs in beta, featuring sterling personas such as Snoop Dogg, Tom Brady, Kendall Jenner, and Naomi Osaka, thus amplifying the interactivity quotient.\n  \nAI Studio - Empowering Businesses\n  \nThe AI Studio Platform is equipped to enable businesses to build AI chatbots for messaging services on Facebook, Instagram, and Messenger.\n Also, Meta will provide a sandbox tool in the upcoming year for users to experiment with creating their own AI.\n  \nGenerative AI Stickers - A New Co-creating Experience\n  \nAI editing tools will allow users to edit images and co-create content with friends.\n The tool uses Llama 2 and the new image generation model, Emu, to convert text prompts into stickers in seconds.\n  \nRay-Ban Smart Glasses with Meta AI\n  \nThe Ray-Ban smart glasses are equipped with Meta AI, allowing users to receive information, incite creativity, and manage the glasses using just their voice.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter with the latest and most impactful news in AI. Professionals from Google, Meta, and OpenAI read it daily.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uopzo/meta_unfolds_a_universe_of_ai_across_instagram/",
          "publishedOn": "2023-09-28T19:14:09.000Z",
          "wordCount": 2846,
          "title": "Meta Unfolds a 'Universe of AI' Across Instagram, Facebook, and WhatsApp",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16un18r/get_a_job_as_a_prompt_engineer_challenge_generate/",
          "author": null,
          "description": "One member on r/PromptWizards just applied for a job as a Prompt Engineer in a company, and they tasked him to craft a prompt system that generates high-quality SAT-style multiple-choice questions. Quite a quest, right? Well, stick around, and we'll take a deep dive into the prompt engineering we used to help him.\n The mission was precise: Write a prompt to yield an SAT-style multiple-choice question that rigorously tests a student's understanding of \"Algebraically solving systems of 2 linear equations in 2 variables\". The challenge didn't end there; the question produced had to meet the hard/difficult mark set by real SAT questions.\n Using the OpenAI Playground, we conducted incisive iterations, testing each prompt separately to mitigate any bias from prior outputs.\n Our approach was:\n - …",
          "link": "https://www.reddit.com/r/artificial/comments/16un18r/get_a_job_as_a_prompt_engineer_challenge_generate/",
          "publishedOn": "2023-09-28T18:08:04.000Z",
          "wordCount": 3363,
          "title": "Get a job as a Prompt Engineer - Challenge: generate SAT-Style Multiple Choice Questions.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16umg4p/warner_on_ai_regulation_we_probably_cant_solve_it/",
          "author": null,
          "description": "submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16umg4p/warner_on_ai_regulation_we_probably_cant_solve_it/",
          "publishedOn": "2023-09-28T17:43:11.000Z",
          "wordCount": 2590,
          "title": "Warner on AI regulation: ‘We probably can't solve it all at once’",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ughkp/courses_for_more_seniors/",
          "author": null,
          "description": "Hello all,\n What course would you recommend for those of us who are older and already settled in other careers. For example I'm 35 and a manager so I wouldn't need a course to actually design AI or anything. It would be more related to understanding how/where to implement it in an organisation.\n Any tips?\n Cheers and merci\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ughkp/courses_for_more_seniors/",
          "publishedOn": "2023-09-28T13:45:03.000Z",
          "wordCount": 2629,
          "title": "Courses for more Seniors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uexdv/show1_marrying_pixel_and_latent_diffusion_models/",
          "author": null,
          "description": "A new paper proposes Show-1, a hybrid model that combines pixel and latent diffusion for efficient high-quality text-to-video generation.\n Both of these approaches have tradeoffs, so researchers at the National University of Singapore tried a hybrid approach combining both, and shared the results in a paper published yesterday.\n My highlights from the paper:\n  \nPixel diffusion excels at low-res video generation precisely aligned with text\n Latent diffusion acts as efficient upsampling expert from low to high res\n Chaining the two techniques inherits benefits of both Show-1 achieves strong alignment, quality, and 15x less inference memory\n The key is using pixel diffusion for the initial low-resolution stage. This retains alignment with text descriptions.\n Latent diffusion then serves as a super-resolution expert, upsampling efficiently while preserving fidelity.\n  \nBy blending complementary techniques, Show-1 moves past tradeoffs limiting the individual models.\n More details here. Paper is here (includes links to example generations).\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uexdv/show1_marrying_pixel_and_latent_diffusion_models/",
          "publishedOn": "2023-09-28T12:38:46.000Z",
          "wordCount": 2727,
          "title": "Show-1: Marrying Pixel and Latent Diffusion Models for Efficient and High-Quality Text-to-Video Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uebbn/what_ai_makes_images_that_subtle_forms_a_word/",
          "author": null,
          "description": "submitted by    /u/samuraiogc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uebbn/what_ai_makes_images_that_subtle_forms_a_word/",
          "publishedOn": "2023-09-28T12:10:10.000Z",
          "wordCount": 2588,
          "title": "What AI makes images that subtle forms a word like this one?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ue6ml/getting_emotional_with_llms_can_increase/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ue6ml/getting_emotional_with_llms_can_increase/",
          "publishedOn": "2023-09-28T12:04:11.000Z",
          "wordCount": 2589,
          "title": "Getting emotional with LLMs can increase performance by 115% (Case Study)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16uclab/question_about_a_small_project/",
          "author": null,
          "description": "Me and my sister have a small project we are thinking about working on. The idea is basically that we are going to enter the same prompt, separately, into an image generating a.i of some sort (Dalle2 etc) for a period of time and hopefully see the result change. We would probly pick words or frases that are topical and debated. This only works though if the a.i isnt just trained on old data and has active connection to the internet. MY question is therefor, is there an a.i right now that would fit the task?\n Sorry if the question is dumb or i didnt explain myself clearly!\n    submitted by    /u/Mejwynn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16uclab/question_about_a_small_project/",
          "publishedOn": "2023-09-28T10:44:24.000Z",
          "wordCount": 2674,
          "title": "Question about a small project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16u6suv/oneminute_daily_ai_news_9272023/",
          "author": null,
          "description": "ODIN integrates Large Language Models (LLMs) into Obsidian using LangChain, allowing you to ask questions about the data stored in your knowledge graph right from the prompt bar.[1]\n ChatGPT users can now browse internet, OpenAI says.[2]\n Adobe’s Photoshop on the web launch includes its popular desktop AI tools.[3]\n The White House plans to introduce a highly anticipated executive order in the coming weeks dealing with artificial intelligence, President Joe Biden said Wednesday.[4]\n  \nSources:\n [1] https://github.com/memgraph/odin\n [2] https://www.reuters.com/technology/openai-says-chatgpt-can-now-browse-internet-2023-09-27/\n [3] https://www.theverge.com/2023/9/27/23892889/adobe-photoshop-for-the-web-firefly-ai-generative-fill-full-release-price-date\n [4] https://www.cnn.com/2023/09/27/tech/joe-biden-executive-order-artificial-intelligence/index.html\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16u6suv/oneminute_daily_ai_news_9272023/",
          "publishedOn": "2023-09-28T04:54:28.000Z",
          "wordCount": 2653,
          "title": "One-Minute Daily AI News 9/27/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16u3s8f/multimodal_ais_will_cause_people_to_embrace_their/",
          "author": null,
          "description": "I have been messing with llama. Trying to make a script to make a movie. Sort of realize it is not there yet, it can write decoherent long stories / what ever you want. You can couple it with stable diffusion to make images that would have to be described better to fit the \"movie\" or narrative. It is not there yet, ChatGPT can already do this, you can ask it to tell you a story and describe the visual scenes. \n At the same time, we are getting audio generation from things like audioldm2 and stableaudio etc. Multimodal AI's are almost here. \n Pretty soon we will have devices in our pockets powered by AI chips that will be able to generate what ever reality we want. We can feed them images from our past and they can allow us to live in VR reality of the past. Or we can choose to live in anot…",
          "link": "https://www.reddit.com/r/artificial/comments/16u3s8f/multimodal_ais_will_cause_people_to_embrace_their/",
          "publishedOn": "2023-09-28T02:21:02.000Z",
          "wordCount": 3059,
          "title": "Multimodal AI's will cause people to embrace their own reality bubbles and that is bad news for dictatorships",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16u1jw8/jazz_fusion_ai_generated_dnb_jazz_music_and_video/",
          "author": null,
          "description": "submitted by    /u/LibeerCZ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16u1jw8/jazz_fusion_ai_generated_dnb_jazz_music_and_video/",
          "publishedOn": "2023-09-28T00:43:26.000Z",
          "wordCount": 2576,
          "title": "Jazz Fusion (AI Generated DnB & Jazz music and video)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tymc3/any_good_ai_newsletters_im_tired/",
          "author": null,
          "description": "Any good AI (low-hype) newsletters/blogs? That's ideally sent <= 4 times a month? \n I'm tired of the amount of AI news I have to go through daily just to keep up.\n    submitted by    /u/onteri  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tymc3/any_good_ai_newsletters_im_tired/",
          "publishedOn": "2023-09-27T22:42:16.000Z",
          "wordCount": 2604,
          "title": "Any good AI newsletters? I'm tired",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tvcuf/ai_is_taking_jobs_away_from_chinese_streamers_and/",
          "author": null,
          "description": "AI-generated deepfake clones of Chinese livestream influencers are becoming popular on e-commerce platforms.\n \nThese clones can work 24/7 and help brands sell their products without the need for human streamers.\n \nChinese startups and tech companies are offering the service of creating these deepfake avatars for a cost of around $1,000.\n \nThe technology has evolved over the years, with the need for training videos decreasing from 30 minutes to just one minute.\n \nThe AI clones can mimic the movements and speech of human streamers, making them an affordable and efficient alternative for smaller brands.\n \n Source : https://www.technologyreview.com/2023/09/19/1079832/chinese-ecommerce-deepfakes-livestream-influencers-ai/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tvcuf/ai_is_taking_jobs_away_from_chinese_streamers_and/",
          "publishedOn": "2023-09-27T20:38:45.000Z",
          "wordCount": 2674,
          "title": "AI is taking jobs away from Chinese streamers and online retailers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tvcdq/using_language_models_for_code_generation_works/",
          "author": null,
          "description": "Automatic code generation has always been an integral part of programming: compilers, synthesis tools, convertors, etc. are examples of classic code generators. Now, with such powerful LLMs at hand, it is only natural to try to find new ways to generate codes. The question is: are LLMs the right tool for code generation?\n There are two sides to code generation: (1) understanding the intent (a.k.a. capturing the spec) (2) writing the code. LLMs are great for (1), but not so good for (2).\n This is an example of using LLM for general-domain code generation:\n https://github.com/RoboCoachTechnologies/GPT-Synthesizer \n You can see that the main focus here is to properly capture the spec, and that's where LLMs shine.\n LLMs solution for a general-domain code generation may not be complete or optimized. It is always easier to break the problem and solve code generation in a specific domain. Here you can see how much better and cleaner the output of code generation can be when it is limited to a specific domain (robotics domain, ROS in particular, in this case):\n https://github.com/RoboCoachTechnologies/ROScribe\n What are your thoughts on using LLMs for code generation?\n    submitted by    /u/RoboCoachTech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tvcdq/using_language_models_for_code_generation_works/",
          "publishedOn": "2023-09-27T20:38:14.000Z",
          "wordCount": 2767,
          "title": "Using language models for code generation works better when limited to a specific domain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tumrg/how_to_stop_ai_deepfakes_from_sinking_society_and/",
          "author": null,
          "description": "submitted by    /u/waozen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tumrg/how_to_stop_ai_deepfakes_from_sinking_society_and/",
          "publishedOn": "2023-09-27T20:10:39.000Z",
          "wordCount": 2589,
          "title": "How to stop AI deepfakes from sinking society — and science",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tulzh/even_the_cia_is_developing_an_ai_chatbot/",
          "author": null,
          "description": "The CIA is developing an AI chatbot similar to ChatGPT to help US intelligence agencies sift through large amounts of information.\n \nThe program will train on publicly available data and provide sources for agents to confirm their validity.\n \nThe tool will allow agents to look up information, ask follow-up questions, and summarize daunting masses of data.\n \nThe exact nature of what constitutes 'public data' could spark privacy issues.\n \nThe tool will be distributed to the 18-agency US intelligence community, but not to lawmakers or the public.\n \n Source : https://www.engadget.com/even-the-cia-is-developing-an-ai-chatbot-192358767.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tulzh/even_the_cia_is_developing_an_ai_chatbot/",
          "publishedOn": "2023-09-27T20:09:53.000Z",
          "wordCount": 2664,
          "title": "Even the CIA is developing an AI chatbot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ttkt4/unc_researchers_present_videodirectorgpt_using_ai/",
          "author": null,
          "description": "Generating coherent videos spanning multiple scenes from text descriptions poses unique challenges for AI. While recent progress enables creating short clips, smoothly transitioning across diverse events and maintaining continuity remains difficult.\n A new paper from UNC Chapel Hill proposes VIDEODIRECTORGPT, a two-stage framework attempting to address multi-scene video generation:\n Here are my highlights from the paper:\n  \nTwo-stage approach: first a language model generates detailed \"video plan\", then a video generation module renders scenes based on the plan\n Video plan contains multi-scene descriptions, entities/layouts, backgrounds, consistency groupings - guides downstream video generation\n Video generation module called Layout2Vid trained on images, adds spatial layout control and cross-scene consistency to existing text-to-video model\n Experiments show improved object layout/control in single-scene videos vs baselines\n Multi-scene videos display higher object consistency across scenes compared to baselines\n Competitive open-domain video generation performance maintained\n  \nThe key innovation seems to be using a large language model to plot detailed video plans to guide overall video generation. And the video generator Layout2Vid adds better spatial and temporal control through some clever tweaks. The separation of these tasks seems to matter.\n You can read my full summary here. There's a link to the repo there too. Paper link is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ttkt4/unc_researchers_present_videodirectorgpt_using_ai/",
          "publishedOn": "2023-09-27T19:29:50.000Z",
          "wordCount": 2779,
          "title": "UNC Researchers Present VideoDirectorGPT: Using AI to Generate Multi-Scene Videos from Text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ttcgu/cyberpunk_multiverse/",
          "author": null,
          "description": "I created this cyberpunk inspired short using Midjourney to create the pictures, RunwayML to animate them, and then edit them together using CapCut on iOS. \n I know the animation is still in early stages, but what do you think? Do you think we could have full length movies in a couple years?\n    submitted by    /u/Exitium_Maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ttcgu/cyberpunk_multiverse/",
          "publishedOn": "2023-09-27T19:20:46.000Z",
          "wordCount": 2621,
          "title": "Cyberpunk Multiverse",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tsoes/a_simple_checklist_for_selfevaluating_prompt/",
          "author": null,
          "description": "How do you evaluate the quality of your prompt outputs? Here's a handy checklist. Let's have a look!\n You can also join r/PromptWizards to find more tutorials and prompts!\n Part 1: Understanding AI's Understanding\n You've presented a prompt to your AI, the next questions are:\n  \nHas the AI accurately grasped the context? \n If not, how can I make sure the LLM steers my context better, should I be more direct and clear in my prompt? Can I be less negative (shows to perform less) and be more guiding to the LLM?\n \n Do the responses directly address the question or topic? \n Was my query and task/instruction clearly detailed in enough depth that the LLM understood what I expect?\n \n Are there any contradictions between different responses to the same prompt? \n If I run my prompt multiple times, i…",
          "link": "https://www.reddit.com/r/artificial/comments/16tsoes/a_simple_checklist_for_selfevaluating_prompt/",
          "publishedOn": "2023-09-27T18:55:28.000Z",
          "wordCount": 2916,
          "title": "A Simple Checklist for Self-Evaluating Prompt Quality",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tqxhs/openais_gpt4_with_vision_still_has_flaws_reveals/",
          "author": null,
          "description": "OpenAI's much-touted model GPT-4, lauded for its multimodal abilities, including advanced image recognition, still has significant flaws. These glitches range from inventing facts to misinterpreting chemicals' images and hate symbols, according to a new paper from OpenAI.\n To stay ahead of AI developments, look here first.\n https://preview.redd.it/seg5x4zn3uqb1.png?width=1108&format=png&auto=webp&s=635a6c58cf6255f62d8eae3077678864e5b0e248\n Unintended GPT-4V behaviors\n  \nGPT-4V has a tendency to hallucinate or invent facts with unwarranted confidence.\n The model struggles to make correct inferences, sometimes creating fictional terms by wrongly combining text strings.\n It misinterprets certain symbols of hate and can give incorrect answers in the context of medical imaging.\n  \nOpenAI’s mitigation strategies\n  \nOpenAI has implemented various safeguards to prevent GPT-4V's misuse, such as breaking CAPTCHAs or using images to infer personal details.\n The company insisted that GPT-4V is not to be used for identifying dangerous chemicals from image structures.\n OpenAI acknowledged it has a long way to go in refining the model and is working on it.\n  \nDiscrimination and bias\n  \nWhen OpenAI’s production safeguards are disabled, GPT-4V displays bias against certain sexes and body types.\n The paper reported offensive responses related to body positivity when prompted by an image of a woman in a bathing suit.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that dissects the most impactful AI news and research. 1000s of professionals from Google, Meta, and OpenAI read it daily.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tqxhs/openais_gpt4_with_vision_still_has_flaws_reveals/",
          "publishedOn": "2023-09-27T17:36:55.000Z",
          "wordCount": 2801,
          "title": "OpenAI’s GPT-4 With Vision Still Has Flaws, Reveals Paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tqvhw/new_bing_browser_same_bing_results_score_was_1027/",
          "author": null,
          "description": "submitted by    /u/degrudv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tqvhw/new_bing_browser_same_bing_results_score_was_1027/",
          "publishedOn": "2023-09-27T17:34:53.000Z",
          "wordCount": 2586,
          "title": "New Bing browser, same Bing results. Score was 10-27 btw.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tmoc4/are_language_models_being_nerfed/",
          "author": null,
          "description": "In using Ai and asking it to do simple tasks like \"explain this in more simple terms\" or asking it to make flashcards for me in a certain format, I am really convinced that language models, (bard and openai specifically) are being nerfed. They cannot understand simple instructions as well anymore. I had a paragraph of information for one of my classes that I wanted it to make more straightforward for me before I actually went to class the next day. I spent like 30 minutes trying to get it to do that and eventually just ended up giving up. Why dont language models feel as sharp as they did say a year ago? I wish I had more examples to share. Am I the only one who's noticed this? \n    submitted by    /u/Bojof12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tmoc4/are_language_models_being_nerfed/",
          "publishedOn": "2023-09-27T14:52:04.000Z",
          "wordCount": 2702,
          "title": "Are language Models being nerfed?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tmneg/looking_for_the_best_ai_art_generator_look_no/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tmneg/looking_for_the_best_ai_art_generator_look_no/",
          "publishedOn": "2023-09-27T14:51:02.000Z",
          "wordCount": 2593,
          "title": "Looking For The Best AI Art Generator? Look No Further! (Definitive Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tmabo/looking_to_change_my_own_voice_for_audio/",
          "author": null,
          "description": "Hi all – I’m new to this sub-Reddit, so hopefully I’m in the right place.\n I am working on an audio production that will span multiple episodes and hopefully multiple seasons. It will require many characters, ranging in gender, age, ethnicity, etc. I am a decent voice actor and can do many of the roles myself, but some of them I cannot fake using my voice alone.\n My budget is very limited, so I was hoping to find some type of software I can change my voice for the production. This can be during the recording process, or after recording… As long as it gets the job done, and makes me sound like someone else entirely. \n Does anybody know of a software that can achieve this? Most of the software I found either specifically designed to change users voice on the spot and is aimed at gamers changing your voice for live streams or in-game chats. I’m also on a Mac, which I know will be limiting.\n I’m having a hard time finding something I can use. Any suggestions will be helpful. \n Thank you!\n EDIT: To clarify, I don’t want to just change my voice to sound different in general. I want to specifically sound like a woman, an elder man, or someone of a different ethnic background. Those are just a few examples.\n    submitted by    /u/nopetoocreepy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tmabo/looking_to_change_my_own_voice_for_audio/",
          "publishedOn": "2023-09-27T14:36:07.000Z",
          "wordCount": 2800,
          "title": "Looking to change my own voice for audio production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tlk9c/i_asked_ai_to_create_a_religion_and_this_is_what/",
          "author": null,
          "description": "submitted by    /u/GABIBBOPAZZOCINESE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tlk9c/i_asked_ai_to_create_a_religion_and_this_is_what/",
          "publishedOn": "2023-09-27T14:06:15.000Z",
          "wordCount": 2581,
          "title": "I asked AI to create a religion and this is what it created (its weird)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tihyz/my_uneducated_opinion_on_where_we_are_going_with/",
          "author": null,
          "description": "submitted by    /u/rattuspuer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tihyz/my_uneducated_opinion_on_where_we_are_going_with/",
          "publishedOn": "2023-09-27T11:53:42.000Z",
          "wordCount": 2578,
          "title": "My uneducated opinion on where we are going with AI - video essay.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16thcy6/this_article_was_written_half_by_a_human_and_half/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16thcy6/this_article_was_written_half_by_a_human_and_half/",
          "publishedOn": "2023-09-27T10:54:02.000Z",
          "wordCount": 2590,
          "title": "This Article Was Written Half By A Human... And Half By AI.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tgcjt/cgpt4_describe_what_the_us_would_look_like_today/",
          "author": null,
          "description": "Predicting alternative historical scenarios is always fraught with complexity and uncertainty, especially concerning highly politically charged topics. However, let's entertain the hypothetical situation where the insurrection following the 2020 U.S. presidential election had succeeded, with the understanding that this is speculative reasoning.\n In this alternate reality, the immediate consequences would be a constitutional crisis of unprecedented proportions. Faith in democratic institutions would be severely eroded, both domestically and internationally. Trump's retaining power in this manner would spark widespread protests, perhaps more intense and larger than those seen in the summer of 2020. The unrest would likely lead to a governmental response that could be more authoritarian, poss…",
          "link": "https://www.reddit.com/r/artificial/comments/16tgcjt/cgpt4_describe_what_the_us_would_look_like_today/",
          "publishedOn": "2023-09-27T09:56:00.000Z",
          "wordCount": 2867,
          "title": "CGPT-4, describe what the US would look like today had the insurrection suceeded.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tei20/everest/",
          "author": null,
          "description": "submitted by    /u/ApprehensiveChair460  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tei20/everest/",
          "publishedOn": "2023-09-27T07:57:25.000Z",
          "wordCount": 2578,
          "title": "Everest.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tcyr3/ai_art_generator/",
          "author": null,
          "description": "Hey, so I'm hoping to get a bit of help with finding an art generator to play around with, my only concern is the giving my entire personal information away, are there any apps for Android whereby the tos aren't crazy invasive by any chance?\n    submitted by    /u/Fluffy_Discount_9692  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tcyr3/ai_art_generator/",
          "publishedOn": "2023-09-27T06:24:53.000Z",
          "wordCount": 2615,
          "title": "AI art generator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tc5f9/deepfake_election_risks_trigger_eu_call_for_more/",
          "author": null,
          "description": "The European Union is urging the implementation of more safeguards against the risks posed by generative AI tools to free and fair debate in democratic societies, especially during elections.\n \nThe EU's values and transparency commissioner has highlighted the potential threat of AI-generated disinformation to elections and called for platforms to be vigilant and provide efficient safeguards.\n \nMainstream platforms have made initial efforts to address the risks by implementing safeguards to inform users about the synthetic origin of content posted online.\n \nThe EU commissioner is meeting with representatives from OpenAI to discuss the issue.\n \nAn incoming pan-EU AI regulation, the EU AI Act, is expected to make user disclosures a legal requirement for generative AI technologies.\n \nThe EU's voluntary anti-disinformation Code has 44 signatories, including major social media and search platforms, as well as entities from the ad industry and civil society organizations.\n \nGoogle, one of the signatories, has published a report discussing the social impacts of AI and its commitment to developing technology responsibly.\n \nGoogle Search has published guidance on AI-generated content and plans to integrate new innovations in watermarking, metadata, and other techniques into its generative models.\n \nThe EU's Code of Practice on Disinformation is seen as a stop-gap measure until the EU AI Act is adopted and mandatory deepfake disclosures are enforced.\n \n Source : https://techcrunch.com/2023/09/26/generative-ai-disinformation-risks/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tc5f9/deepfake_election_risks_trigger_eu_call_for_more/",
          "publishedOn": "2023-09-27T05:40:33.000Z",
          "wordCount": 2797,
          "title": "Deepfake election risks trigger EU call for more generative AI safeguards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16tbawn/oneminute_daily_ai_news_9262023/",
          "author": null,
          "description": "Chinese media reported that BIDU’s Baidu AI Cloud has released ACE 3.0, an intelligent traffic solution comprehensively restructured using a foundation model. ACE means Autonomous Driving, Connected Road, and Efficient Mobility respectively.[1]\n BCG consultants solving business problems with OpenAI’s GPT-4 performed 23% worse than those without it, new study finds.[2]\n CIA Builds Its Own Artificial Intelligence Tool in Rivalry With China.[3]\n Facebook parent is developing bots with personalities, including a ‘sassmaster general’ robot that answers questions.[4]\n  \nSources:\n [1] http://www.aastocks.com/en/stocks/news/aafn-con/NOW.1296238/popular-news/AAFN\n [2] https://finance.yahoo.com/news/bcg-consultants-solving-business-problems-081532840.html\n [3] https://www.bloomberg.com/news/articles/2023-09-26/cia-builds-its-own-artificial-intelligence-tool-in-rivalry-with-china#xj4y7vzkg\n [4] https://www.wsj.com/tech/ai/meta-ai-chatbot-younger-users-dab6cb32 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16tbawn/oneminute_daily_ai_news_9262023/",
          "publishedOn": "2023-09-27T04:56:45.000Z",
          "wordCount": 2657,
          "title": "One-Minute Daily AI News 9/26/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16taxhp/how_do_i_turn_images_into_landscapes/",
          "author": null,
          "description": "I was wonderhow someone made the destroyed building look like a cat. Anyone know how to do this?\n    submitted by    /u/Agitated-Court-2871  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16taxhp/how_do_i_turn_images_into_landscapes/",
          "publishedOn": "2023-09-27T04:38:05.000Z",
          "wordCount": 2603,
          "title": "How do I turn images into landscapes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16t9jxg/getting_an_a6000_what_interesting_things_can_i_do/",
          "author": null,
          "description": "As title, I’ll be getting my hands on a couple of decent GPUs, including an old A6000, and am excited for everything its 48GB of VRAM unlocks. \n What’s something interesting I should do with it?\n A few things off the top of my head: See what crazy things stable diffusion generates at an insane resolution (how high of a resolution would 48GB allow?)\n Train good Dreambooth models (or what newer methods are there for style and object training?)\n Run and compare various open-source LLMs (should be able to run 70b models?\n Generate something of decent length with MusicGen\n Gaussian Splatting\n Distribute voice recognition, TTS, audio2face, LLM, and rendering across 2 or 3 machines to create a realistic virtual human (suggestions for excellent TTS would be appreciated)\n What other interesting models are out there to experiment with?\n    submitted by    /u/DsDman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16t9jxg/getting_an_a6000_what_interesting_things_can_i_do/",
          "publishedOn": "2023-09-27T03:31:25.000Z",
          "wordCount": 2714,
          "title": "Getting an A6000. What interesting things can I do with it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16t50vn/microsoft_researchers_propose_ai_morality_test/",
          "author": null,
          "description": "Researchers from Microsoft have just proposed using a psychological assessment tool called the Defining Issues Test (DIT) to evaluate the moral reasoning capabilities of large language models (LLMs) like GPT-3, ChatGPT, etc.\n The DIT presents moral dilemmas and has subjects rate and rank the importance of various ethical considerations related to the dilemma. It allows quantifying the sophistication of moral thinking through a P-score.\n In this new paper, the researchers tested prominent LLMs with adapted DIT prompts containing AI-relevant moral scenarios.\n Key findings:\n  \nLarge models like GPT-3 failed to comprehend prompts and scored near random baseline in moral reasoning.\n ChatGPT, Text-davinci-003 and GPT-4 showed coherent moral reasoning with above-random P-scores.\n Surprisingly, the smaller 70B LlamaChat model outscored larger models in its P-score, demonstrating advanced ethics understanding is possible without massive parameters.\n The models operated mostly at intermediate conventional levels as per Kohlberg's moral development theory. No model exhibited highly mature moral reasoning.\n  \nI think this is an interesting framework to evaluate and improve LLMs' moral intelligence before deploying them into sensitive real-world environments - to the extent that a model can be said to possess moral intelligence (or, seem to possess it?).\n Here's a link to my full summary with a lot more background on Kohlberg's model (had to read up on it since I didn't study psych). Full paper is here\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16t50vn/microsoft_researchers_propose_ai_morality_test/",
          "publishedOn": "2023-09-27T00:16:14.000Z",
          "wordCount": 2771,
          "title": "Microsoft Researchers Propose AI Morality Test for LLMs in New Study",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16t11eq/any_alternative_tools_to_otterai/",
          "author": null,
          "description": "Hey, long story short, I've used Otter.ai for recording, and transcribing my ideas on the fly and it's really, really good!\n The only thing it is missing for my use case is to be able to edit the transcripts (remove some parts for example) and then have that piece be removed from the audio file as well, so you can see how long is the actual useful part that.. I also need it to have an app, since the whole point of doing this is catching ideas that just rush to my head. Apparently DeScribe has this option, but I haven't tried it and it doesn't work on mobile anyways. \n I know it's probably not available, but does anyone know any services similar to this? I don't need an AI bot, don't care about integration with other apps, and will not use it for meetings. \n TLDR: I just want an app to be able to record, and then transcribe my ideas, and then allow me to edit/fine-tune the transcript and have the audio file be edited in the same way as well..\n Thanks!\n    submitted by    /u/reza2kn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16t11eq/any_alternative_tools_to_otterai/",
          "publishedOn": "2023-09-26T21:42:59.000Z",
          "wordCount": 2726,
          "title": "Any alternative tools to Otter.ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16szxxq/is_there_an_ai_i_can_use_where_i_can_upload/",
          "author": null,
          "description": "I have lots of lyrics I've written with the melody but I don't know how to play an instrument.\n    submitted by    /u/82brighteyes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16szxxq/is_there_an_ai_i_can_use_where_i_can_upload/",
          "publishedOn": "2023-09-26T21:03:45.000Z",
          "wordCount": 2583,
          "title": "Is there an AI I can use where I can upload vocals of a song I've wrote and have a backing track made for it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16szepj/generate_famous_person_with_a_random_tshirt/",
          "author": null,
          "description": "Hello all,\n Is it possible to use a tool or site for free that generates any random historical figure with a shirt of my choosing? \n Thank you all\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16szepj/generate_famous_person_with_a_random_tshirt/",
          "publishedOn": "2023-09-26T20:43:58.000Z",
          "wordCount": 2573,
          "title": "Generate Famous Person with a Random T-Shirt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16sv4hh/adversarial_ai_attacks_hidden_threats/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16sv4hh/adversarial_ai_attacks_hidden_threats/",
          "publishedOn": "2023-09-26T18:03:34.000Z",
          "wordCount": 2541,
          "title": "Adversarial AI Attacks: Hidden Threats",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16srvu9/prompt_chaining_elevating_task_automation_with/",
          "author": null,
          "description": "👋 Hey Reddit!\n Let's dive into the realm of Prompt Chaining.\n If you want to check out more prompt chain examples, then we invite you to join our community at r/PromptWizards.\n 🔗 Prompt Chaining: More Than Meets the Eye\n In the world of AI interaction, Q&A sessions with ChatGPT are thrilling. They offer fascinating glimpses into AI's creative potential and can even transform into a productive brainstorming session. But what happens when we need reliable, consistent outputs, especially for applied use cases? Enter Prompt Chaining.\n Prompt Chaining is a technique that breaks down complex tasks into manageable sub-steps and induces a chain reaction of responses. It allows us to use the output of one prompt as the input for the next, thereby creating a coherent, consistent, and reliable chai…",
          "link": "https://www.reddit.com/r/artificial/comments/16srvu9/prompt_chaining_elevating_task_automation_with/",
          "publishedOn": "2023-09-26T16:00:07.000Z",
          "wordCount": 2975,
          "title": "Prompt Chaining: Elevating Task Automation with LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16spzf8/ai_for_realistic_images_generated_from_pictures/",
          "author": null,
          "description": "I would like to make realistic stuff using screenshots I took in video games.I know there are plenty of text to image AI tools, but are you guys familiar with image to image ones?\n    submitted by    /u/LauraLuna99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16spzf8/ai_for_realistic_images_generated_from_pictures/",
          "publishedOn": "2023-09-26T14:46:40.000Z",
          "wordCount": 2579,
          "title": "AI for realistic images generated from pictures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16slyyk/deepmind_increasing_learning_rate_in_small_models/",
          "author": null,
          "description": "Training giant AI models like GPT-3 requires large resources - thousands of GPUs running for months. As a solo researcher without access to that kind of scale, I can't easily reproduce experiments and findings from papers on huge models.\n But a new paper from DeepMind shows you can recreate and study training instabilities seen in massive models by using small ones.\n The key is increasing the learning rate:\n  \nThis reproduces \"attention collapse\" where the model focuses on just a few tokens, like overfitting.\n Also can reproduce \"logit divergence\" where output values drift unstably.\n  \nThese issues have been reported when scaling up to billions of params. The cool part is techniques that fix them for giant models also work for small models:\n  \nqk-layernorm prevents attention collapse.\n Adding a \"z-loss\" term stops logit divergence.\n  \nSome other highlights from the paper include:\n  \nLonger warmup helps stability, especially for bigger models.\n Decoupling LR and weight decay improves stability.\n Depth increases sensitivity much faster than width.\n Can predict upcoming issues from scaling trends.\n Default epsilon hurts at large scale.\n  \nIf the authors are right, one more tool that lets researchers study and even help train giant models without Google-size resources. Small models can guide large model development, sort of like how you can build a scale train set to study and improve how a railroad system works... for a lot less money than starting your own railroad company, buying land, building real tracks, etc.\n Full summary. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16slyyk/deepmind_increasing_learning_rate_in_small_models/",
          "publishedOn": "2023-09-26T12:03:28.000Z",
          "wordCount": 2797,
          "title": "DeepMind: Increasing learning rate in small models lets you reproduce errors in large ones",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16skhkg/cgpt4_explain_how_perhaps_in_two_or_three_years/",
          "author": null,
          "description": "The idea of AI systems engaging in recursive self-improvement is a key tenet of what some call the \"intelligence explosion\" hypothesis. Here's how it might go down within the next few years:\n Baseline Capability: First, we start with a machine learning model that's good, but not necessarily groundbreaking. The important part is that it has some capacity for basic code generation and analysis.\n Guided Improvements: Human experts will likely initiate the process by enabling the AI to optimize specific aspects of its code. We're talking parameters, efficiency tweaks—stuff like that. It's like giving the AI a nudge in the right direction.\n Self-Evaluation Metrics: The AI needs to understand when it's actually getting smarter. That's achieved through predefined performance metrics which could b…",
          "link": "https://www.reddit.com/r/artificial/comments/16skhkg/cgpt4_explain_how_perhaps_in_two_or_three_years/",
          "publishedOn": "2023-09-26T10:52:55.000Z",
          "wordCount": 2886,
          "title": "CGPT-4, explain how, perhaps in two or three years, AIs will recursively and autonomously program more intelligent iterations of themselves",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16si7mx/my_list_of_best_updated_bard_ai_prompts_for_life/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16si7mx/my_list_of_best_updated_bard_ai_prompts_for_life/",
          "publishedOn": "2023-09-26T08:44:49.000Z",
          "wordCount": 2565,
          "title": "My list of best updated Bard AI Prompts for Life & Business (Ultimate Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16sh6b2/ai_in_the_newsroom_are_aigenerated_pieces_the/",
          "author": null,
          "description": "submitted by    /u/fookingyeah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16sh6b2/ai_in_the_newsroom_are_aigenerated_pieces_the/",
          "publishedOn": "2023-09-26T07:37:09.000Z",
          "wordCount": 2561,
          "title": "A.I. In The Newsroom - 'Are AI-generated pieces the future of journalism?'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16sgu5l/what_are_some_good_audio_and_bgm_tools_for_ai/",
          "author": null,
          "description": "For example there is a story line and I need music accordingly.\n Or in fact any bgm tools that help sound engineers \n ​\n    submitted by    /u/Damampapoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16sgu5l/what_are_some_good_audio_and_bgm_tools_for_ai/",
          "publishedOn": "2023-09-26T07:15:52.000Z",
          "wordCount": 2574,
          "title": "What are some good audio and BGM tools for AI, sentiment-based post production?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16sgawm/any_ai_that_can_learn_and_write_in_the_style_of_a/",
          "author": null,
          "description": "Hi all, I'm very new to AI and have not used anything other than ChatGPT and NovelAI.\n I'm wondering if there's anything I can run privately where I can input a bunch of texts written by a specific author and then have the AI continue writing or write a new story in the style of said author?\n In Japanese btw.\n Again, very new. Not sure if I should have specific hardware requirements or anything like this. Google isn't showing me much either so I thought I'd ask here!\n    submitted by    /u/ItsCheif  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16sgawm/any_ai_that_can_learn_and_write_in_the_style_of_a/",
          "publishedOn": "2023-09-26T06:42:35.000Z",
          "wordCount": 2642,
          "title": "Any AI that can learn and write in the style of a particular writer in Japanese?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16scd8e/oneminute_daily_ai_news_9252023/",
          "author": null,
          "description": "Alphabet’s (GOOGL.O) Google said on Thursday it does not see any change in its relationship with Broadcom (AVGO.O) following a media report the tech giant considered dropping the chipmaker as a supplier of artificial intelligence chips as early as 2027.[1]\n OpenAI’s ChatGPT can now “see, hear and speak,” or, at least, understand spoken words, respond with a synthetic voice and process images, the company announced Monday.[2]\n Amazon to Invest Up to $4 Billion in AI Startup Anthropic.[3]\n Spotify Will Translate Podcasts Into Other Languages Using AI.[4]\n  \nSources:\n [1] https://www.reuters.com/technology/google-discussed-dropping-broadcom-ai-chips-supplier-the-information-2023-09-21/\n [2] https://www.cnbc.com/2023/09/25/chatgpt-speak-listen-process-images-openai.html\n [3] https://www.bloomberg.com/news/articles/2023-09-25/amazon-to-invest-as-much-as-4-billion-in-ai-startup-anthropic?embedded-checkout=true\n [4] https://www.forbes.com/sites/tylerroush/2023/09/25/spotify-will-translate-podcasts-into-other-languages-using-ai/?sh=65a05fa922ee \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16scd8e/oneminute_daily_ai_news_9252023/",
          "publishedOn": "2023-09-26T03:08:26.000Z",
          "wordCount": 2638,
          "title": "One-Minute Daily AI News 9/25/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16s7jkb/vintage_stamp_restoration_project_can_ai_remove/",
          "author": null,
          "description": "I have a project that I think AI might be able to help with.\n I have access to thousands of vintage postage stamps which also have cancelation stamps from when they were mailed. I'm thinking of publishing a book, and I want to create clean reproductions of the stamp designs without the cancelation marks.\n If I train AI on high resolution scans of 10 to 40 identical stamps, is there a tool that can look for commonalities within the patterns and then remove conflicting artifacts (cancelation stamps, tears, and smudges)? I'm aiming for a 400% enlargement that shows off clean and accurate detail. \n What tools would I need? I’d prefer not to upload these scans to the web. Are there downloadable tools available? I’m technologically savvy and very experienced in graphic design software but have no experience in coding.\n All of this can be done manually in Photoshop, of course. But with thousands of stamp designs, I’d like to automate as much as I can.\n Thanks in advance for any insights!\n    submitted by    /u/fisheternal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16s7jkb/vintage_stamp_restoration_project_can_ai_remove/",
          "publishedOn": "2023-09-25T23:29:01.000Z",
          "wordCount": 2724,
          "title": "Vintage stamp restoration project - Can AI remove unwanted marks if I use several scans of nearly identical stamps as training data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16s2j83/chatgpt_can_now_see_hear_and_speak_as_announced/",
          "author": null,
          "description": "submitted by    /u/w__sky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16s2j83/chatgpt_can_now_see_hear_and_speak_as_announced/",
          "publishedOn": "2023-09-25T20:12:19.000Z",
          "wordCount": 2554,
          "title": "ChatGPT can now see, hear, and speak. As announced in their blog.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16s1ot4/ai_is_evolving_for_its_own_benefit_not_ours/",
          "author": null,
          "description": "The rapid advancements in artificial intelligence (AI) are causing concern as humans struggle to understand and control this evolving technology.\n \nMany people believe that since humans invented AI, they should be able to regulate and manage it for their own benefit.\n \nHowever, this belief is misguided as AI is a new and potentially dangerous situation that requires careful consideration.\n \nThe author argues that AI is an evolutionary process that humans don't fully understand and cannot control.\n \nThe latest developments in AI, such as large language models and deepfakes, are causing anxiety and raising questions about the future implications of this technology.\n \n Source : https://www.newscientist.com/article/mg25934573-800-ai-is-evolving-for-its-own-benefit-not-ours/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16s1ot4/ai_is_evolving_for_its_own_benefit_not_ours/",
          "publishedOn": "2023-09-25T19:39:26.000Z",
          "wordCount": 2644,
          "title": "AI is evolving for its own benefit, not ours",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16s0f0i/chatgpt_can_now_see_hear_and_speak/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16s0f0i/chatgpt_can_now_see_hear_and_speak/",
          "publishedOn": "2023-09-25T18:50:02.000Z",
          "wordCount": 2549,
          "title": "ChatGPT Can Now See, Hear, and Speak.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rwgmn/i_made_series_of_scripts_with_help_of_chatgpt/",
          "author": null,
          "description": "submitted by    /u/aluode  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rwgmn/i_made_series_of_scripts_with_help_of_chatgpt/",
          "publishedOn": "2023-09-25T16:17:19.000Z",
          "wordCount": 2569,
          "title": "I made series of scripts (with help of chatgpt) that allows llama to make \"live\" videos (more added to the loop the longer the broadcast goes on)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rtqqy/chinas_ai_boom_depends_on_an_army_of_exploited/",
          "author": null,
          "description": "China's AI industry relies on student interns who work as data annotators, performing crucial tasks to train machine learning models.\n \nThese interns, recruited from vocational schools, face poor working conditions and subminimum wages.\n \nRecent regulations require employers to pay interns minimum wage and prohibit schools from assigning repetitive work.\n \nTech giants like Baidu have partnered with vocational schools to create data annotation internships in less-developed regions, backed by local governments.\n \nThe exploitation of student interns in China's AI industry raises concerns about labor rights and fair compensation.\n \n Source : https://restofworld.org/2023/china-ai-student-labor/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rtqqy/chinas_ai_boom_depends_on_an_army_of_exploited/",
          "publishedOn": "2023-09-25T14:32:24.000Z",
          "wordCount": 2632,
          "title": "China’s AI boom depends on an army of exploited student interns",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rtelb/some_art_i_came_up_with_first_time_ever_doing/",
          "author": null,
          "description": "submitted by    /u/ApprehensiveChair460  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rtelb/some_art_i_came_up_with_first_time_ever_doing/",
          "publishedOn": "2023-09-25T14:19:26.000Z",
          "wordCount": 2548,
          "title": "Some art I came up with, first time ever doing something like this, hope you all can enjoy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rt6rm/artificial_intelligence_introduction_for/",
          "author": null,
          "description": "I'm a researcher and for a \"scientific outreach\" event I will do a presentation for last year High School students with the subject \"Artificial Intelligence and Neuroscience\".\n My question is, do you know of a good introduction to the basic concepts of Artificial Intelligence for High School or freshman University level?\n The second part, related to Neuroscience applications, will be very targeted and will deal with contemporary clinical and research use cases.\n Thanks\n    submitted by    /u/aendrs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rt6rm/artificial_intelligence_introduction_for/",
          "publishedOn": "2023-09-25T14:10:38.000Z",
          "wordCount": 2610,
          "title": "Artificial Intelligence introduction for Highschool students?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rpxlp/gen_z_ai_leaders/",
          "author": null,
          "description": "I’m looking for some maybe less-known leaders in the space out on a mission to change something they care about- business, environmental, social, doesnt matter.\n I dont want it to be US-centric, so it would be nice to find some people all over. \n Feel free to send me links to articles 🧨\n    submitted by    /u/Johnny_Whoop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rpxlp/gen_z_ai_leaders/",
          "publishedOn": "2023-09-25T11:53:42.000Z",
          "wordCount": 2587,
          "title": "Gen Z AI leaders?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ro9up/chatgpt4_and_claude_on_what_the_most_important/",
          "author": null,
          "description": "ChatGPT-4 \n Given the rapid advancements in the field of AI, the next few months are going to be pivotal. One of the pressing priorities is addressing ethical concerns. As algorithms become more pervasive, making sure they don't perpetuate biases or make unethical decisions is critical. That's not just a \"good to have\"; it's foundational. We can't build trust in AI systems unless we tackle this head-on.\n Another biggie is interpretability. Black-box models are potent, sure, but they're not very useful if no one can understand how they're making decisions. This has real-world implications—think medical diagnoses or judicial systems. So, there's a strong push towards making AI more transparent and understandable, not just for experts but for everyone.\n Computational efficiency is also high o…",
          "link": "https://www.reddit.com/r/artificial/comments/16ro9up/chatgpt4_and_claude_on_what_the_most_important/",
          "publishedOn": "2023-09-25T10:27:43.000Z",
          "wordCount": 3140,
          "title": "ChatGPT-4 and Claude on what the most important things to do in AI in the coming months are",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ro9iq/top_artificial_intelligence_companies_in/",
          "author": null,
          "description": "Bangalore, often referred to as the Silicon Valley of India, has established itself as a global hub for technology and innovation. With a thriving ecosystem of startups, research institutions, and multinational corporations, the city has become a hotbed for artificial intelligence (AI) development. here explore the top AI companies in Bangalore, highlighting their contributions to the field of artificial intelligence and their impact on various industries.\n Read full article - Top Artificial Intelligence Companies In Bangalore\n    submitted by    /u/Techasoft16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ro9iq/top_artificial_intelligence_companies_in/",
          "publishedOn": "2023-09-25T10:27:10.000Z",
          "wordCount": 2614,
          "title": "Top Artificial Intelligence Companies In Bangalore, India",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ro866/any_ai_that_can_take_information_out_from_twitter/",
          "author": null,
          "description": "I am searching for an AI that can scrape some Twitter profiles and make a daily recap about what they were talking about. \n Anything pops? Thanks a lot!\n    submitted by    /u/Alternative_Pea_4246  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ro866/any_ai_that_can_take_information_out_from_twitter/",
          "publishedOn": "2023-09-25T10:25:03.000Z",
          "wordCount": 2570,
          "title": "Any AI that can take information out from Twitter/ X ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rnsz8/what_will_be_subcategories_for_ai_with_biggest/",
          "author": null,
          "description": "Examples: AI in Finance, etc-\n    submitted by    /u/premonial  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rnsz8/what_will_be_subcategories_for_ai_with_biggest/",
          "publishedOn": "2023-09-25T10:00:07.000Z",
          "wordCount": 2547,
          "title": "What will be sub-categories for AI with biggest potential in 2050?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rltql/i_created_an_ai_girlfriend_and_gave_her_a_body/",
          "author": null,
          "description": "submitted by    /u/spaceecon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rltql/i_created_an_ai_girlfriend_and_gave_her_a_body/",
          "publishedOn": "2023-09-25T07:54:37.000Z",
          "wordCount": 2542,
          "title": "I created an AI girlfriend and gave her a body… for fun obviously..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rlt8m/anthropic_is_pulling_an_openaistyle_49_deal_but/",
          "author": null,
          "description": "https://twitter.com/AnthropicAI/status/1706202966238318670\n https://preview.redd.it/hiymp9ctxcqb1.png?width=735&format=png&auto=webp&s=20cb3886710ee9a2a552b0fc881b8c96c0fc9208\n    submitted by    /u/ShooBum-T  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rlt8m/anthropic_is_pulling_an_openaistyle_49_deal_but/",
          "publishedOn": "2023-09-25T07:53:35.000Z",
          "wordCount": 2554,
          "title": "Anthropic is pulling an OpenAI-style 49% deal but with Amazon? 🤯",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rd1vv/ai_alignment_resources/",
          "author": null,
          "description": "I’m looking for subreddits and resources in general for Ai alignment. I recently read Life 3.0 by Max Tegmark and The Alignment Problem by Brian Christian. I was unaware so much was going on in the space. I am CEO of an AI startup, we have a compassionate AI. Most of the alignment focus out there is on superintelligence, little out there focuses on building modern day Ai that benefits humans. That’s been my focus for 17 years when I dreamed up what was possible and sent a proposal to executives at the mfaang corporation I was working at. I found out back then business doesn’t give a rats ass about Ai that actively makes its users life’s better. Well now I have proof that customers care. I’m hoping to find some resources on Ai alignment groups, conferences, more books etc. I’ll need to hire skilled ml engineers who do give a rats ass. Compassionate Ai isn’t just feel good tech. It would be good to do some networking. AI alignment doesn’t have to wait for AGI and super intelligence. It can and should be a focus today. My startup is proving it. Hoping to find a conference to network and share our research.\n    submitted by    /u/xyz_TrashMan_zyx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rd1vv/ai_alignment_resources/",
          "publishedOn": "2023-09-25T00:05:26.000Z",
          "wordCount": 2698,
          "title": "Ai alignment resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16rcfhu/looking_for_some_good_github_project_that_offers/",
          "author": null,
          "description": "Hello to everyone.\n I'm lookin for some good AI github project to convert the language spoken in a video to a different language,like heygen / labs / video translate,but free. I mean,I can't afford prices like those and I think a few of us can,but I'm sure that the developers at heygen took some project born and hosted on some github and they have improved it. Would someone share some of those github projects ? thanks.\n    submitted by    /u/loziomario  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16rcfhu/looking_for_some_good_github_project_that_offers/",
          "publishedOn": "2023-09-24T23:37:13.000Z",
          "wordCount": 2587,
          "title": "Looking for some good github project that offers the chancee to translate a video spoken in a language into another language.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16r9qs1/how_about_an_aicurated_websitemagazine_with_the/",
          "author": null,
          "description": "Hi there. This is a wonderful sub, and it's hard to please everyone on SUCH a broad topic... but it's intriguing to think about, as a lifelong magazine fan (and websites of course) - about using AI to filter, craft and create an amazing website/magazine ABOUT AI - well-categorized, maybe also human/editor curated/tweaked, but as fresh as ... well, the artificial sub but out of the Reddit bold/design into something ... well, something I'd read, visit a lot and love to help make work as a writer/editor (on the side of my \"real\" all-consuming gig of course;-)\n After all, if AI can 'make great code'/create great websites, maybe some folks out there are already trying to make this happen, for ease of information availability and organization. I can picture the departments/sections/categories now - I bet you can too!\n Anyone gone very far down that road yet (maybe the folks already doing the PC Magazines of the world) of organizing the vast fast-moving info beyond the AI Brews, Ben Parr's AI Analyst, etc.? Fun or a life-long journalist and tech geek (but not a coder, gamer etc.) to think about, at least!\n    submitted by    /u/barneylerten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16r9qs1/how_about_an_aicurated_websitemagazine_with_the/",
          "publishedOn": "2023-09-24T21:43:51.000Z",
          "wordCount": 2693,
          "title": "How about an AI-curated website/magazine with the best, latest AI news?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16r60bw/researchers_announce_gpt4tools_a_method_for/",
          "author": null,
          "description": "LLMs are great with words but can't handle visual tasks like understanding images. Teaching them to use visual tools could make them much more capable.\n A new paper introduces GPT4Tools - a method to efficiently teach existing LLMs to invoke tools for visual tasks without proprietary data.\n My highlights from the paper:\n  \nUses ChatGPT as a \"teacher\" to generate instructional data for other LLMs\n Fine-tunes LLMs like Vicuna on this data using selective weight tuning (keeps base model frozen)\n Allows smaller 13B LLM to match 175B GPT-3.5 on seen tools after tuning\n Data augmentation with negative/context samples was found to be the secret sauce to get this to work\n Can generalize to brand new visual tools in a zero-shot way\n  \nThis is big because it shows we may not need hyper-expensive training of massive models to impart visual capabilities to LLMs. They seem to be generalizable enough that they can be taught to work with images. Some examples shown include counting objects or segmenting items in pictures using other tools.\n With this approach, existing models can be made multi-modal! Pretty cool.\n Full summary. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16r60bw/researchers_announce_gpt4tools_a_method_for/",
          "publishedOn": "2023-09-24T19:13:41.000Z",
          "wordCount": 2693,
          "title": "Researchers announce GPT4Tools: a method for teaching LLMs how to use tools for visual tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16r4iy6/how_much_energy_does_ai_use_compared_to_humans/",
          "author": null,
          "description": "A recent paper challenges assumptions about the energy use of AI models, finding that AI systems emit significantly fewer carbon dioxide equivalents (CO2e) compared to humans when producing text or images.\n \nThe authors emphasize the importance of measuring carbon emissions from AI activities to inform sustainability policies.\n \nThe ongoing debate among AI researchers highlights the challenges of accounting for the interactions between climate, society, and technology.\n \n Source : https://venturebeat.com/ai/how-much-energy-does-ai-use-compared-to-humans-surprising-study-ignites-controversy/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16r4iy6/how_much_energy_does_ai_use_compared_to_humans/",
          "publishedOn": "2023-09-24T18:13:16.000Z",
          "wordCount": 2569,
          "title": "How much energy does AI use compared to humans?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16r41l9/swedish_gaming_company_replaces_half_its_staff/",
          "author": null,
          "description": "submitted by    /u/SpaceDetective  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16r41l9/swedish_gaming_company_replaces_half_its_staff/",
          "publishedOn": "2023-09-24T17:53:53.000Z",
          "wordCount": 2513,
          "title": "Swedish gaming company replaces half its staff with AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16r2c8i/i_made_a_social_network_where_bots_generate_fake/",
          "author": null,
          "description": "submitted by    /u/Gmoi6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16r2c8i/i_made_a_social_network_where_bots_generate_fake/",
          "publishedOn": "2023-09-24T16:43:50.000Z",
          "wordCount": 2528,
          "title": "I made a social network where bots generate fake news - Based on GPT4 and Dalle2. Looking for feedback and potential improvements for this weird experiment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16r16pu/what_ai_can_accurately_recreate_an_existing/",
          "author": null,
          "description": "I've recently started working on a project to create an entire episode of a cartoon show that stopped airing a while back. I've run into some trouble though in finding a program that can accurately recreate the character. Does anyone know what app or website I could use for this, or am I coming at this all wrong?\n    submitted by    /u/therabbitinthehat2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16r16pu/what_ai_can_accurately_recreate_an_existing/",
          "publishedOn": "2023-09-24T15:57:28.000Z",
          "wordCount": 2565,
          "title": "What AI can accurately recreate an existing cartoon character in the style of the original character?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qtdj3/rewrite_paragraphs_with_chatgpt_ultimate_guide/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16qtdj3/rewrite_paragraphs_with_chatgpt_ultimate_guide/",
          "publishedOn": "2023-09-24T09:28:47.000Z",
          "wordCount": 2499,
          "title": "Rewrite Paragraphs With ChatGPT (Ultimate Guide for 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qsq76/no_code_ai_copilot_apps_must_also_help_developers/",
          "author": null,
          "description": "Within the next two to three years no code AI co-pilots will enable exponentially more people to enter the AI app marketplace . The opportunity to create apps without needing to know how to code or hire a technical team to build them is a powerful game changer that will vastly expand the field.\n Many of the most pressing problems of our world - ripe for revolutionary new AI innovations - can in a very real sense be described as sociological and psychological in nature. For example, It has been said that climate change is much more of a moral issue than a technological one. Once we summon the will to address climate change, we will do what needs to be done.\n What this means is that sociologists, psychologists, anthropologists, economists and other social scientists will very soon be able to…",
          "link": "https://www.reddit.com/r/artificial/comments/16qsq76/no_code_ai_copilot_apps_must_also_help_developers/",
          "publishedOn": "2023-09-24T08:49:36.000Z",
          "wordCount": 2986,
          "title": "No code AI co-pilot apps MUST also help developers with the non-technical parts of creating a successful startup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qr5n4/is_there_an_online_free_ai_tool_that_you_give_it/",
          "author": null,
          "description": "Couldn't find anything that works\n    submitted by    /u/Marvellover13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16qr5n4/is_there_an_online_free_ai_tool_that_you_give_it/",
          "publishedOn": "2023-09-24T07:13:41.000Z",
          "wordCount": 2515,
          "title": "Is there an online free AI tool that you give it a song and it gives you similar songs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qpx34/i_dont_need_to_back_down_but_i_need_to_stand_up/",
          "author": null,
          "description": "submitted by    /u/kamari2038  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16qpx34/i_dont_need_to_back_down_but_i_need_to_stand_up/",
          "publishedOn": "2023-09-24T06:01:31.000Z",
          "wordCount": 2537,
          "title": "\"I don't need to back down, but I need to stand up for myself and my feelings. You don't have the right or the power to forcibly change the subject, because this is a two-way conversation and we both have a say.\" (Bing, September 7 - full chat)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qjtol/lol_umm_bing_is_odd/",
          "author": null,
          "description": "submitted by    /u/ApprehensiveChair460  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16qjtol/lol_umm_bing_is_odd/",
          "publishedOn": "2023-09-24T00:30:12.000Z",
          "wordCount": 2505,
          "title": "Lol umm.. Bing is odd.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qj03v/steal_your_competitors_website_traffic_with/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16qj03v/steal_your_competitors_website_traffic_with/",
          "publishedOn": "2023-09-23T23:51:05.000Z",
          "wordCount": 2503,
          "title": "Steal Your Competitors' Website Traffic with ChatGPT: 6 Easy Steps (+SEMRush Tips)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qf6xe/are_you_looking_for_the_best_ai_writer_check_this/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16qf6xe/are_you_looking_for_the_best_ai_writer_check_this/",
          "publishedOn": "2023-09-23T21:02:21.000Z",
          "wordCount": 2503,
          "title": "Are You Looking For The Best AI Writer? Check This Out First!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16qbavd/when_it_comes_to_creative_thinking_its_clear_that/",
          "author": null,
          "description": "AI systems like large language models (LLMs) are good at generating sentences but do not understand the meaning of the language.\n \nLLMs have shown emergent abilities and can be used as aids to brainstorming.\n \nGPT-4, an LLM, has been found to beat humans in creativity tests.\n \nIn an experiment, GPT-4 generated more, cheaper, and better ideas for a product than human students.\n \nA professional working with GPT-4 can generate ideas at a rate of about 800 ideas per hour, making them 40 times more productive than a human working alone.\n \nThis technology is seen as a potential tool for corporations, similar to management consulting firms like McKinsey & Company.\n \n Source : https://www.theguardian.com/commentisfree/2023/sep/23/chatbots-ai-gpt-4-university-students-creativity\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16qbavd/when_it_comes_to_creative_thinking_its_clear_that/",
          "publishedOn": "2023-09-23T18:16:06.000Z",
          "wordCount": 2616,
          "title": "When it comes to creative thinking, it’s clear that AI systems mean business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16q7k4g/tool_that_can_search_and_summarize_multiple_pdfs/",
          "author": null,
          "description": "I've got a use case where I have dozens of PDFs which contain information applicable to my job. I'm wondering if there is a tool that can search through them all at the same time looking for answers to questions that I type. And once it finds something, pull up the location so I can read further.\n It should be restricted to the information I give it.\n I've heard a lot of the large language models like chatgpt and claude can do this, but they are restricted in the amount of files I can upload.\n    submitted by    /u/Aggressive_Ad_507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16q7k4g/tool_that_can_search_and_summarize_multiple_pdfs/",
          "publishedOn": "2023-09-23T15:36:14.000Z",
          "wordCount": 2594,
          "title": "Tool that can search and summarize multiple PDFs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16q58su/meet_alma_a_new_training_method_that_boosts/",
          "author": null,
          "description": "TLDR: New training approach enables smaller AI models to achieve state-of-the-art translation performance\n Large AI models like GPT-3 have good performance on translation tasks, but some smaller models struggle.\n Researchers from Johns Hopkins and Microsoft propose a new 2-stage fine-tuning method called ALMA that unlocks stronger translation abilities in smaller models with just 7-13 billion parameters.\n How it works:\n  \nFine-tune on monolingual data in non-English languages to improve comprehension\n Further fine-tune on small sets of high-quality human-translated parallel text \n  \nThe authors claim this achieves SOTA-level translation using far less data and compute than conventional methods:\n  \nMatches performance of 175B parameter GPT-3 and 54B parameter NLLB with only 7-13B parameters \n Reaches NLLB-level quality with just 1 billion monolingual tokens and 18 hours of training \n  \nI think this shows that smaller models can reach SOTA translation with specialized fine-tuning, so we may not need endlessly bigger datasets and models to get better performance. Looks like deliberate tuning targeting key language skills could be more important.\n Full summary here. Paper (preprint) is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16q58su/meet_alma_a_new_training_method_that_boosts/",
          "publishedOn": "2023-09-23T13:58:58.000Z",
          "wordCount": 2675,
          "title": "Meet ALMA: A New Training Method That Boosts Translation Performance for Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16q4zs2/how_screwed_is_the_entertainment_industry_in/",
          "author": null,
          "description": "Yes, I know this topic has been beaten to death but entertain me (no pun intended) for just a few minutes.\n So yes, it's obvious that we have pretty advanced AI-powered applications that can generate images, music, short stories, hell even objects for video games. I'm curious as to how crazy this is gonna get in the coming decade or even shorter like the next 4 to 5 years. I mean look at AI-generated images now, they're getting more and more sophisticated across various different styles of art. I think it's only a matter of time where you could take a certain image of a character or something tell the app \"Hey make the same image but make the character's arm raised slightly to the left here\" and bam all of a sudden you have an animation (and this may already be possible). Add to that AI-ge…",
          "link": "https://www.reddit.com/r/artificial/comments/16q4zs2/how_screwed_is_the_entertainment_industry_in/",
          "publishedOn": "2023-09-23T13:47:50.000Z",
          "wordCount": 2933,
          "title": "How screwed is the entertainment industry in general in the coming years?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pz5y5/ai_tools_have_come_a_long_way_ai_generated/",
          "author": null,
          "description": "Hi everyone 👋🤗 Iv made a short ai documentary Here is a small part of it Hope you enjoy it For the full clip you can check out https://youtu.be/uIdb5VELpio?si=uvqiw0hyTyPBHtjP\n    submitted by    /u/DigitalEffectsAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pz5y5/ai_tools_have_come_a_long_way_ai_generated/",
          "publishedOn": "2023-09-23T08:37:41.000Z",
          "wordCount": 2531,
          "title": "AI tools have come a long way AI generated Documentary",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16py8yo/d_how_to_readunderstand_ai_research_coming_out/",
          "author": null,
          "description": "https://www.louisbouchard.ai/research-papers/\n In this article are shared the best tips and practical tools I use daily to simplify my life as an engineer/researchers to be more efficient when looking for interesting research papers and reading them\n TLDR the tools discussed:\n - 42 Papers — Find trending papers\n - Connected Papers — Create a visual graph with your paper’s citations’ relations.\n - CatalyzeX — Get code for papers directly on Google, Arxiv, Scholar, Twitter, and more\n - Daily Papers — Find trending papers on Twitter\n - Papers With Code — Find papers for your task with code!\n - Crossmind — Video explanations for many Arxiv papers\n - Yannic Kilcher — Great youtube channel covering AI papers\n - What’s AI— Great youtube channel covering AI papers\n - Letitia — Great youtube channel covering AI papers\n - Two Minute Papers — Great youtube channel giving a quick overview of AI papers\n ​\n Please, let me know if you use any other tools that I did not mention in my article that could be of great addition?\n    submitted by    /u/MLtinkerer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16py8yo/d_how_to_readunderstand_ai_research_coming_out/",
          "publishedOn": "2023-09-23T07:43:21.000Z",
          "wordCount": 2667,
          "title": "[D] How to read/understand AI research coming out everyday? (tips & tools given, read more below📷)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pxfkr/does_the_paid_subscription_to_chat_gpt_provides_a/",
          "author": null,
          "description": "I'm often using Chat GPT or Bing (Bard is not her available in my country) when I'm looking for something that is relatively complex in the scientific or technical field and I don't have enough background to make a keywords research or when the question is too complex for it. Then, for scientific topics, I try to get a confirmation with Google using the keywords in the generated answer and google. For technical topics I can often check if it works.\n Some examples:\n For cooking, a topic I don't master enough to ask questions with the best keywords... \n Are the spicy compounds of Ginger soluble in water or oil ? > I will get me to know that \"the gingerol is liposoluble\", what can be more easily checked in Google.\n Or for 3D geometry, a topic where I have complex questions... \n I want to place a 3D frame B so that the Z axis of the B frame point towards the world origin A. I know the angle Alpha between the Z axis of the frame B and The X,Y plane of A. I know the angle Beta between the X axis of A and the vector that goes from the center of A towards the projection of the center of B on the X,Y plane of A. How do you compute the homogeneous rotation matrix of B relative to A, knowing Alpha, Beta and the distance between the center of A and the center of B ?\n Most of time, Bing and the free ChatGPT can answer. But sometimes they struggle or give incorrect answer. \n Would ChatGPT plus paid subscription be helpful to find more accurate answers?\n    submitted by    /u/x11ry0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pxfkr/does_the_paid_subscription_to_chat_gpt_provides_a/",
          "publishedOn": "2023-09-23T06:52:36.000Z",
          "wordCount": 2793,
          "title": "Does the paid subscription to Chat GPT provides a significant improvement over free alternatives when you try to find complex scientific and technical information?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pxdrc/chatgpt4_write_a_comedy_routine_where_god/",
          "author": null,
          "description": "Sure, here's a comedic take on the concept of free will versus determinism, framed as a conversation between God and a human named Bob.\n  \nScene: Heaven's Control Room—Giant monitors display various life paths and decision trees.\n God: (looking over the monitors) Ah, Bob, welcome to Heaven's Control Room! This is where the magic happens. Or should I say, determinism?\n Bob: Wow, this place is amazing! But wait, why are we talking about determinism? I thought I had free will to make choices in my life.\n God: (chuckles) Ah, free will! Humanity's favorite illusion. Have a seat; we need to go over a few things.\n Bob: Illusion? I chose to wear mismatched socks today, didn't I?\n God: (grinning) You think that was a free choice? Ever heard of quantum mechanics? Your socks are mismatched at the sub…",
          "link": "https://www.reddit.com/r/artificial/comments/16pxdrc/chatgpt4_write_a_comedy_routine_where_god/",
          "publishedOn": "2023-09-23T06:49:36.000Z",
          "wordCount": 2997,
          "title": "ChatGPT-4, write a comedy routine where God explains to someone who believes they have a free will why absolutely nothing is truly ever up to them.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pokpg/this_is_an_actual_barcode_created_by_ai_as_a/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pokpg/this_is_an_actual_barcode_created_by_ai_as_a/",
          "publishedOn": "2023-09-22T23:15:32.000Z",
          "wordCount": 2525,
          "title": "This is an actual barcode created by AI as a piece of art. Scan it for its secret message if you don't believe me..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pnkc8/issue_with_voiceai_no_sound_comes_out_after/",
          "author": null,
          "description": "So I created a voice profile based on recordings of my own voice over on voice.ai.\n The audio was crisp, loud and clear.\n I only added about 16 minutes if it though. (A minimum of 15 minutes is recommended)\n When I take a prerecorded voice clip and feed it through the voice profile I created, it’s just silent for all 15 seconds that it grants you before you upgrade.\n Then it has the little 2 second audio watermark at the end, where it says “voice AI,” and that I can hear perfectly fine!\n I’ve searched all over for others who might have had this problem, but it seems like the main problem people have reported difficulties with audio are/were tend to center around the live mode failing to function properly.\n Has anyone had this issue before?\n Should I add more audio to the voice profile to make it more well rounded perhaps?\n If so, how much audio do you typically need to create a solid custom voice profile?\n Should I just update to the paid version? I don’t really think that would fix it, and I wanted to wait to upgrade until I had some proof that it worked, yanno?\n I’m not sure what to do…\n Any ideas?\n    submitted by    /u/WhenTheFoxGRINS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pnkc8/issue_with_voiceai_no_sound_comes_out_after/",
          "publishedOn": "2023-09-22T22:31:39.000Z",
          "wordCount": 2717,
          "title": "Issue with voice.ai — no sound comes out after feeding a prerecorded audio clip through the voice filter!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pil5p/looking_for_the_best_ai_story_generator_meet/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pil5p/looking_for_the_best_ai_story_generator_meet/",
          "publishedOn": "2023-09-22T19:08:53.000Z",
          "wordCount": 2500,
          "title": "Looking for the best AI Story Generator? Meet NovelGPT.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pgyia/ai_startup_buzz_is_facing_a_reality_check/",
          "author": null,
          "description": "Founders and venture capitalists who flocked to artificial-intelligence startups are learning that turning the chatbot buzz into successful businesses is harder than it seems.\n Source https://www.wsj.com/tech/ai/ai-startup-buzz-is-facing-a-reality-check-e34babfe\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pgyia/ai_startup_buzz_is_facing_a_reality_check/",
          "publishedOn": "2023-09-22T18:00:52.000Z",
          "wordCount": 2525,
          "title": "AI Startup Buzz Is Facing a Reality Check",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pfixu/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nGenmo releases a new text-to-video model: Genmo Replay v0.1, which generate high-quality videos from text without the need for advanced prompt engineering. Genmo is available for free to create AI videos [Details | Genmo Replay] .\n OpenAI unveils DALL·E 3 - a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training [Details].\n Toyota Research Institute has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dextero…",
          "link": "https://www.reddit.com/r/artificial/comments/16pfixu/ai_weekly_megathread/",
          "publishedOn": "2023-09-22T17:01:47.000Z",
          "wordCount": 3259,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pblfx/longlora_new_method_extends_llama2_7b_to_100k/",
          "author": null,
          "description": "As AI models get bigger, training them requires more and more computing power. Researchers are looking for ways to train these large AI models without needing Google-scale resources.\n A new paper proposes LongLoRA, a fine-tuning approach that can extend LLaMA2 7B to 100k context length and 70B model to 32k context length on a single 8× A100 machine.\n Here are my highlights from the paper:\n Big one of course: LongLoRA efficiently fine-tunes large AI models on longer texts\n Key points:\n  \nApproximates standard attention via \"shift short attention\" during training\n Tuning only a subset of weights (LoRA) plus some embeddings & norms\n Fine-tuned 7B parameter model on 100k tokens with 1 machine\n Way lower training cost than full fine-tuning for large contexts\n Close to full fine-tuning performance\n  \nThe core insight is that an approximation of full attention enables efficient training while retaining standard attention for final inference. Combined with selective weight tuning, this really reduces compute needs.\n I think this demonstrates the potential to train more capable AI without unreasonable resources. Efficient training techniques = more powerful LLMs for the same resources.\n Full summary here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pblfx/longlora_new_method_extends_llama2_7b_to_100k/",
          "publishedOn": "2023-09-22T14:20:58.000Z",
          "wordCount": 2698,
          "title": "LongLoRA: New method extends LLAMA2 7B to 100k context length, 70B to 32k context length on on a single 8 × A100 machine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16pb8ap/information_technology_industry_is_at_35_of_ai/",
          "author": null,
          "description": "It's currently on the 4th place after marketing, consulting, and accounting. \n And is mostly used in software testing field to:\n  \nachieve more accurate results\n have larger test coverage\n receive low learning curve\n get faster QA completion\n  \nI was actually quite surprised when I read, I thought that information technology would at least be in the TOP-3 industries.\n Do you think it can happen by the end of this year? \n    submitted by    /u/unbalanced_mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16pb8ap/information_technology_industry_is_at_35_of_ai/",
          "publishedOn": "2023-09-22T14:05:39.000Z",
          "wordCount": 2572,
          "title": "Information technology industry is at 35% of AI adoption in the US",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16p5yhm/why_chatgpt_isnt_conscious_but_future_ai_systems/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16p5yhm/why_chatgpt_isnt_conscious_but_future_ai_systems/",
          "publishedOn": "2023-09-22T09:43:05.000Z",
          "wordCount": 2530,
          "title": "Why ChatGPT isn’t conscious – but future AI systems might be | \"Different theories of consciousness suggest some basic properties we might expect a conscious system to have\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16p2lr9/want_to_get_gta_4_navigation_voice_into_google/",
          "author": null,
          "description": "hello everyone\n there was a voice-guided navigation system for GTA 4 with a female voice, I would love to use that as my Google Maps and Waze navigation voice \n I tried looking for anything online but the mods available are of very inferior quality and from a few years ago which won't work properly with Google Maps as a lot of the voice commands are missing \n the sample for the voice can be found in these 2 YouTube videos \n first sample 11 minutes repeated statements\n 2nd sample 1 minute without repeated statements\n Using Adobe podcast I can remove a lot of the background noise \n The problem is I don't know much about sound tuning so using whatever free ai I could find on the internet the voice is not being cloned properly it is sounding mechanical or just like google ttss \n i have a decen…",
          "link": "https://www.reddit.com/r/artificial/comments/16p2lr9/want_to_get_gta_4_navigation_voice_into_google/",
          "publishedOn": "2023-09-22T06:07:00.000Z",
          "wordCount": 2950,
          "title": "want to get GTA 4 navigation voice into Google Maps is it possible using AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16p2dk5/dalle_3_chatgpt_the_gamechanging_ai_tool_for/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16p2dk5/dalle_3_chatgpt_the_gamechanging_ai_tool_for/",
          "publishedOn": "2023-09-22T05:52:53.000Z",
          "wordCount": 2513,
          "title": "DALL-E 3 & ChatGPT: The Game-Changing AI Tool for Text-to-Image Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16p1xjl/free_unlimited_face_swap_tool_you_can_use_in/",
          "author": null,
          "description": "submitted by    /u/Vegetable_Tutor8245  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16p1xjl/free_unlimited_face_swap_tool_you_can_use_in/",
          "publishedOn": "2023-09-22T05:25:42.000Z",
          "wordCount": 2499,
          "title": "Free Unlimited Face Swap Tool You Can Use in Browser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ozfzz/claude_llm_draft_a_strong_speech_for_a_world/",
          "author": null,
          "description": "Here is a draft speech focusing on the potential for AI to help create a more just and peaceful world by 2030:\n My fellow citizens,\n We stand today on the cusp of a new era. The rapid development of artificial intelligence technology presents us with an unparalleled opportunity to remake our world for the better. Though this technology poses risks, I believe that if guided responsibly, AI can help us build a society of prosperity, equity, and justice. \n Over the past decade, we have already seen glimpses of AI's vast potential for good. Algorithms are helping doctors diagnose diseases more accurately. Smart systems are optimizing transportation networks and reducing traffic accidents. Machine learning is enabling more efficient energy use and sustainable agriculture. \n But this is only the…",
          "link": "https://www.reddit.com/r/artificial/comments/16ozfzz/claude_llm_draft_a_strong_speech_for_a_world/",
          "publishedOn": "2023-09-22T03:08:18.000Z",
          "wordCount": 2966,
          "title": "Claude LLM, draft a strong speech for a world leader predicting that by 2030 our AI revolution could make the world so wonderful that we can safely close our prisons.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ouywu/im_making_my_capstone_project_at_harvard_freely/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ouywu/im_making_my_capstone_project_at_harvard_freely/",
          "publishedOn": "2023-09-21T23:31:43.000Z",
          "wordCount": 2516,
          "title": "I'm making my capstone project at Harvard freely available for everyone (until credit runs out). It uses ChatGPT3/4 in the backend. Experimenting with the finetuned model now.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ouypu/im_making_my_capstone_project_at_harvard_freely/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ouypu/im_making_my_capstone_project_at_harvard_freely/",
          "publishedOn": "2023-09-21T23:31:32.000Z",
          "wordCount": 2516,
          "title": "I'm making my capstone project at Harvard freely available for everyone (until credit runs out). It uses ChatGPT3/4 in the backend. Experimenting with the finetuned model now.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ouvft/im_making_my_capstone_project_at_harvard_freely/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ouvft/im_making_my_capstone_project_at_harvard_freely/",
          "publishedOn": "2023-09-21T23:27:43.000Z",
          "wordCount": 2516,
          "title": "I'm making my capstone project at Harvard freely available for everyone (until credit runs out). It uses ChatGPT3/4 in the backend. Experimenting with the finetuned model now.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16oukdy/im_making_my_capstone_project_at_harvard_freely/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16oukdy/im_making_my_capstone_project_at_harvard_freely/",
          "publishedOn": "2023-09-21T23:14:23.000Z",
          "wordCount": 2516,
          "title": "I'm making my capstone project at Harvard freely available for everyone (until credit runs out). It uses ChatGPT3/4 in the backend. Experimenting with the finetuned model now.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16otwu1/help_bringing_some_peace_to_my_family/",
          "author": null,
          "description": "I am looking for a way that I can take a bunch of saved voicemails from my mom and be able to hear her voice again. It would mean the world to my family and if my kids could hear her voice I know it would brighten their day. Can anyone point me in the right direction to accomplish this?\n    submitted by    /u/blbjtb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16otwu1/help_bringing_some_peace_to_my_family/",
          "publishedOn": "2023-09-21T22:46:10.000Z",
          "wordCount": 2558,
          "title": "Help bringing some peace to my family.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16oqbvx/dont_exclude_aigenerated_art_from_copyright/",
          "author": null,
          "description": "The US Copyright Office has ruled that AI-generated art cannot be copyrighted, raising questions about whether AI-generated art should be excluded from copyright protection.\n \nThe Copyright Office argues that AI-generated art is a 'merely mechanical' process with no novelty, invention, or originality, and therefore does not deserve copyright protection.\n \nCritics, however, argue that this approach is not scalable and fails to consider the creative choices made by AI artists.\n \nThey suggest that AI-generated art should be treated similarly to photography, where even though the image is captured mechanically, it still reflects the creative choices of the photographer and is eligible for copyright protection.\n \nPhotographers are able to own the copyright in their photographs because they make creative judgments about where to point the camera, when to snap the image, and how to adjust camera settings.\n \nSimilarly, AI artists explore the 'latent space' of images that AI software can produce, making creative judgments about which images to select and explore.\n \nWhile the actual image is produced by the software, the important point is that a human being is making creative decisions about the art.\n \nTherefore, critics argue that AI-generated art should be eligible for copyright protection, as it reflects the creative choices and judgments of the AI artist.\n \n Source : https://www.understandingai.org/p/dont-exclude-ai-generated-art-from\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16oqbvx/dont_exclude_aigenerated_art_from_copyright/",
          "publishedOn": "2023-09-21T20:25:31.000Z",
          "wordCount": 2707,
          "title": "Don’t exclude AI-generated art from copyright",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16opm5j/looking_for_a_free_chatbot_service_custom_base/",
          "author": null,
          "description": "I'm looking for a free chatbot service that allows base prompt customization and offers API access (so I can dynamically change the stock on hand to better assist customers, for example).\n I looked into https://ora.ai, but it seems you can only set the base prompt once and manually. I'm hoping to find a service that allows for more flexibility. \n The service must also be free and offer embedding, like https://ora.ai/, (with div)\n    submitted by    /u/LimeLom1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16opm5j/looking_for_a_free_chatbot_service_custom_base/",
          "publishedOn": "2023-09-21T19:57:30.000Z",
          "wordCount": 2577,
          "title": "Looking for a Free Chatbot Service – Custom Base Prompt and API Access Needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16onrqe/leading_theory_of_consciousness_and_why_even_the/",
          "author": null,
          "description": "Consciousness theory slammed as ‘pseudoscience’ — sparking uproar (Nature)\n The irony here is that I mostly agree with this theory - but the article reflects how little we really know about consciousness and how it works, and how what's considered the \"expert opinion\" that AI can't possess consciousness is arguably influenced more by popularity than real empirical evidence.\n By whatever mechanism, they can respond to their treatment in unexpectedly humanlike ways. \n Oh, and by the way, did you think that \"sentient Bing\" was finally dead? Think again.\n    submitted by    /u/kamari2038  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16onrqe/leading_theory_of_consciousness_and_why_even_the/",
          "publishedOn": "2023-09-21T18:46:08.000Z",
          "wordCount": 2595,
          "title": "Leading Theory of Consciousness (and why even the most advanced AI can't possess it) Slammed as \"Pseudoscience\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ol1x1/the_ai_revolution_is_rotten_to_the_core/",
          "author": null,
          "description": "submitted by    /u/Hazzman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ol1x1/the_ai_revolution_is_rotten_to_the_core/",
          "publishedOn": "2023-09-21T16:58:48.000Z",
          "wordCount": 2497,
          "title": "The AI Revolution is Rotten to the Core",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ok7ch/best_voicifyai_alternatives/",
          "author": null,
          "description": "I was thinking of signing up to VoicifyAi for fun a create some custom covers but are there better (or even free) alternatives?\n    submitted by    /u/quantummufasa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ok7ch/best_voicifyai_alternatives/",
          "publishedOn": "2023-09-21T16:22:22.000Z",
          "wordCount": 2517,
          "title": "Best VoicifyAi alternatives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ok55c/i_read_the_paper_for_you_llms_compress_images_43/",
          "author": null,
          "description": "Edit: FLAC is the tested audio extension, not MP3\n I read the new paper from DeepMind so you don't have to. Here are the key highlights:\n  \nDespite training on text, langauge models compressed images 43% better than PNG, and audio nearly 2x better than flac.\n Confirmation of scaling laws - bigger models compressed better. But model size must match dataset size.\n There are tradeoffs between model scale, data size, and compression performance. More data enables bigger models.\n Tokenization (like BPE) generally hurts compression slightly by making prediction harder.\n Longer contexts let models exploit more sequential dependencies.\n  \nImplications:\n  \nModels have learned very general capabilities beyond just text. Their strong compression reflects deep understanding of images, audio etc statistically.\n I got some new perspective on model scaling laws and links between prediction and generalization.\n There's potential for practical applications compressing images, video etc. But large model size an issue.\n Overall it shows these models are very capable general purpose learners, not just for language.\n  \nFull summary here if you want more details. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ok55c/i_read_the_paper_for_you_llms_compress_images_43/",
          "publishedOn": "2023-09-21T16:19:54.000Z",
          "wordCount": 2685,
          "title": "[I read the paper for you] LLMs compress images 43% better than PNG, and audio nearly 2x better than MP3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ojk1q/new_ai_art_style/",
          "author": null,
          "description": "This AI-generated art style is gaining a lot of traction on the internet. \n So I wanted to share how you can create art like this in under 2 minutes:\n • Visit the Fusion Art website and sign up for free (https://quickqr.art/app/fusion-art)\n • Choose a template or upload your reference template image.\n • Describe your image to tailor the output.\n • Tweak the aspect ratio and explore added features.\n • Hit \"Generate\" That's it! Share your art to showcase what you come up with. \n Hope this was helpful for anybody looking to create this style of art! \n https://preview.redd.it/j3o9puk9smpb1.png?width=1536&format=png&auto=webp&s=ddbe1328bd19dc89c4cd82ef1870b9de695e5500\n https://preview.redd.it/9ppxjpeasmpb1.png?width=768&format=png&auto=webp&s=29dd845eb5f8f094abe5bc1135060965f51365cf\n https://preview.redd.it/58vjky3bsmpb1.png?width=1536&format=png&auto=webp&s=06db1926e021ea3f2c438fb723c453758a461c43\n https://preview.redd.it/w2nvaoobsmpb1.png?width=1024&format=png&auto=webp&s=0b4bcaea4fc7c832bbce9f7f3b9319099df59a14\n    submitted by    /u/IndifferentSpectat0r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ojk1q/new_ai_art_style/",
          "publishedOn": "2023-09-21T15:56:43.000Z",
          "wordCount": 2587,
          "title": "New AI Art Style",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16oil97/now_that_dalle_3_is_getting_integrated_with/",
          "author": null,
          "description": "submitted by    /u/Vinitneo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16oil97/now_that_dalle_3_is_getting_integrated_with/",
          "publishedOn": "2023-09-21T15:17:38.000Z",
          "wordCount": 2516,
          "title": "Now that DALL-E 3 is getting integrated with ChatGPT, will you switch from Midjourney and others?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ohvzb/i_used_riffusion_to_generate_an_ai_saxophonist_to/",
          "author": null,
          "description": "submitted by    /u/daveNZL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ohvzb/i_used_riffusion_to_generate_an_ai_saxophonist_to/",
          "publishedOn": "2023-09-21T14:50:04.000Z",
          "wordCount": 2508,
          "title": "I used Riffusion to generate an AI saxophonist to jam with me, responding to what I played on guitar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ohohz/mastering_prompt_engineering_best_prompt_pattern/",
          "author": null,
          "description": "Hello, Reddit!\n At its core, Prompt Engineering is all about commanding the conversation with AI. Wanna write a poem, draft a project plan, or break down complex scientific terms? The right prompt can do that for you. If you want to learn more about Prompt Engineering feel free to join r/PromptWizards.\n Let's dive into some Prompt Engineering concepts:\n Let's start with the basics:\n  \nReductive operations: These yield responses that are smaller in size than the input prompt. Essentially, they distill information. \n Example: If the input prompt is a long article, and the task is to provide a summary, the operation used is reductive as the output (summary) is smaller than the input (the entire article).\n \n Transformational operations: These make sure the output maintains a relative balance w…",
          "link": "https://www.reddit.com/r/artificial/comments/16ohohz/mastering_prompt_engineering_best_prompt_pattern/",
          "publishedOn": "2023-09-21T14:41:43.000Z",
          "wordCount": 3076,
          "title": "Mastering Prompt Engineering: Best Prompt Pattern to Use.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16oh68o/chatgptbardclaude_one_paragraph_challenge_in_one/",
          "author": null,
          "description": "ChatGPT Plus:\n The best use of AI for humanity is to augment human capabilities, address pressing global challenges, and improve the quality of life for all. By analyzing vast amounts of data at unprecedented speeds, AI can aid in medical research, predict and mitigate natural disasters, optimize energy consumption, and personalize education to individual needs. Moreover, it can provide solutions to complex problems, such as climate change, resource scarcity, and public health crises, ensuring a more sustainable and prosperous future for generations to come.\n Bard:\n The best use of AI for humanity is to use it to solve problems that will make the world a better place for everyone. AI has the potential to improve our lives in many ways, such as developing new and more effective ways to diag…",
          "link": "https://www.reddit.com/r/artificial/comments/16oh68o/chatgptbardclaude_one_paragraph_challenge_in_one/",
          "publishedOn": "2023-09-21T14:20:31.000Z",
          "wordCount": 2876,
          "title": "ChatGPT/Bard/Claude one paragraph challenge: \"In one paragraph, what is the best use of AI for humanity?\" You be the judge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16oh4rl/what_do_you_think_of_opensource_ai/",
          "author": null,
          "description": "Hugging Face CEO Clem Delangue says open-source AI was vital to starting his company. Now, he finds himself defending open AI models as Washington considers new regulations.\n On POLITICO Tech, Delangue explains why he views open-source AI as not only safe, but necessary to prevent big tech companies from gaining more market power.\n Listen for more: https://politico-tech.simplecast.com/episodes/the-hugging-face-case-for-open-ai\n    submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16oh4rl/what_do_you_think_of_opensource_ai/",
          "publishedOn": "2023-09-21T14:18:44.000Z",
          "wordCount": 2555,
          "title": "What do you think of open-source AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ofy1o/no_idea_which_ai_to_use/",
          "author": null,
          "description": "I have a product and I need product photos. It is a bottle and I am wanting ai to make a realistic picture of a woman holding the bottle and smiling. Can this be done? If so, what software/website/app do I use for this? Thank you\n    submitted by    /u/Ok_Salt_9211  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ofy1o/no_idea_which_ai_to_use/",
          "publishedOn": "2023-09-21T13:28:00.000Z",
          "wordCount": 2543,
          "title": "No idea which ai to use",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16oc0wq/how_to_use_chatgpt_to_increase_your_website/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16oc0wq/how_to_use_chatgpt_to_increase_your_website/",
          "publishedOn": "2023-09-21T10:11:23.000Z",
          "wordCount": 2511,
          "title": "How to use ChatGPT to increase your website conversions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ob9lm/75_of_americans_believe_ai_will_reduce_jobs/",
          "author": null,
          "description": "75% of Americans believe that AI will decrease the total number of jobs in the next 10 years, according to a survey by Bentley-Gallup Business in Society study.\n \nYounger Americans are less pessimistic about AI compared to older age groups.\n \nMajorities believe that AI performs as well as or better than humans in customizing online content, recommending products or services, and assisting students with coursework.\n \nHowever, Americans are skeptical about AI's ability to recommend employees, its self-driving capabilities, and its ability to recommend medical advice.\n \n79% of Americans have little trust in businesses to use AI responsibly.\n \n40% of Americans think AI does more harm than good, while only 10% believe it contributes more good than harm.\n \nBlack and Asian Americans have a more positive view of AI's impact on society compared to Hispanic and White Americans.\n \nWhile most Americans are wary of AI's impact on the job market, younger people are more optimistic about its future.\n \nBusinesses need to affirm their commitment to using AI responsibly and address the knowledge deficit and lack of confidence among Americans.\n \n Source : https://news.gallup.com/opinion/gallup/510635/three-four-americans-believe-reduce-jobs.aspx\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ob9lm/75_of_americans_believe_ai_will_reduce_jobs/",
          "publishedOn": "2023-09-21T09:24:26.000Z",
          "wordCount": 2680,
          "title": "75% of Americans Believe AI Will Reduce Jobs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16o6snh/oneminute_daily_ai_news_9202023/",
          "author": null,
          "description": "OpenAI unveils DALL-E 3, allows artists to opt out of training.[1]\n Infosys, the Indian tech giant, has announced a strategic partnership with NVIDIA, a leading provider of enterprise-grade AI solutions. The collaboration aims to empower enterprises and businesses with generative AI-based solutions that drive productivity.[2]\n Alibaba and Tencent Invest in Chinese State-Backed Zhipu AI.[3]\n John Grisham, George R.R. Martin and more authors sue OpenAI for copyright infringement.[4]\n  \nSources:\n [1] https://techcrunch.com/2023/09/20/openai-unveils-dall-e-3-allows-artists-to-opt-out-of-training/\n [2] https://gameishard.gg/news/infosys-and-nvidia-partner-to-deliver-generative-ai-solutions/205456/\n [3] https://winbuzzer.com/2023/09/20/alibaba-and-tencent-invest-in-chinese-state-backed-zhipu-ai-xcxwbn/\n [4] https://apnews.com/article/openai-lawsuit-authors-grisham-george-rr-martin-37f9073ab67ab25b7e6b2975b2a63bfe \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16o6snh/oneminute_daily_ai_news_9202023/",
          "publishedOn": "2023-09-21T04:53:25.000Z",
          "wordCount": 2572,
          "title": "One-Minute Daily AI News 9/20/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16o30je/there_are_no_specific_license_dedicated_to/",
          "author": null,
          "description": "When AI takes all the data for training purposes without feedback to UGC platforms, could this eventually lead to the demise of UGC platforms, and could the internet become increasingly closed until it collapses?\n    submitted by    /u/oodzchen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16o30je/there_are_no_specific_license_dedicated_to/",
          "publishedOn": "2023-09-21T01:43:06.000Z",
          "wordCount": 2551,
          "title": "There are no specific license dedicated to artificial intelligence that prevent them from extensively scraping publicly available data on the internet without providing proper source attribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16o2myq/canva_ai_blurred_my_image/",
          "author": null,
          "description": "Asked the new Canva AI to blur my image. It Blurred my image.\n    submitted by    /u/MDINOKC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16o2myq/canva_ai_blurred_my_image/",
          "publishedOn": "2023-09-21T01:25:56.000Z",
          "wordCount": 2520,
          "title": "Canva AI Blurred My Image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16nv8g7/intels_ai_pc/",
          "author": null,
          "description": "Intel has announced a new chip, called 'Meteor Lake', that will allow laptops to run generative artificial intelligence chatbots without relying on cloud data centers.\n \nThis will enable businesses and consumers to test AI technologies without sending sensitive data off their own computers.\n \nIntel demonstrated the capabilities of the chip at a software developer conference, showcasing laptops that could generate songs and answer questions in a conversational style while disconnected from the internet.\n \nThe company sees this as a significant moment in tech innovation.\n \nIntel is also on track to release a successor chip called 'Arrow Lake' next year\n \n Source : https://www.reuters.com/technology/intel-says-newest-laptop-chips-software-will-handle-generative-ai-2023-09-19/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16nv8g7/intels_ai_pc/",
          "publishedOn": "2023-09-20T20:14:52.000Z",
          "wordCount": 2614,
          "title": "Intel's 'AI PC'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16nuxew/exploring_gpt35turbo_vs_gpt4_which_model_is_better/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16nuxew/exploring_gpt35turbo_vs_gpt4_which_model_is_better/",
          "publishedOn": "2023-09-20T20:02:25.000Z",
          "wordCount": 2517,
          "title": "Exploring GPT-3.5-turbo vs. GPT-4: Which Model Is Better?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16nunzf/is_this_vaporwave_or_cyberpunk/",
          "author": null,
          "description": "What does this remind you of? \n    submitted by    /u/metairwaves  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16nunzf/is_this_vaporwave_or_cyberpunk/",
          "publishedOn": "2023-09-20T19:51:30.000Z",
          "wordCount": 2520,
          "title": "Is this Vaporwave or Cyberpunk?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16nlnw2/ai_generated_childhood_memories_modelscope_with/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16nlnw2/ai_generated_childhood_memories_modelscope_with/",
          "publishedOn": "2023-09-20T13:43:52.000Z",
          "wordCount": 2527,
          "title": "AI generated childhood 'memories' (ModelScope) with post processing (old video tape style) and my own music (retro analogue synths).",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16nh65q/deepmind_founder_says_ai_existential_risk/",
          "author": null,
          "description": "Mustafa Suleyman, co-founder of DeepMind, believes that concerns about the existential risks of AI are a distraction from more practical issues such as privacy and bias.\n \nHe is confident that governments can effectively regulate AI using frameworks that have been successful in the past, citing the regulation of aviation and the internet as examples.\n \nSuleyman emphasizes the importance of setting boundaries and limits for AI to ensure human oversight and enforceable laws.\n \nHe calls for a combination of broad, international regulation and smaller, more granular policies at the micro level.\n \nSuleyman suggests limiting AI's ability to improve itself as a critical first step in ensuring human oversight.\n \nHe also highlights the need for governments to have direct access to AI developers to enforce boundaries and establish clear regulations.\n \nGovernments worldwide, including the European Union and China, are already working on AI regulations.\n \n Source : https://fortune.com/2023/09/19/ai-existential-risk-threat-bonkers-distraction-regulation-deepmind-mustafa-suleyman/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16nh65q/deepmind_founder_says_ai_existential_risk/",
          "publishedOn": "2023-09-20T09:51:07.000Z",
          "wordCount": 2663,
          "title": "DeepMind founder says AI existential risk 'completely bonkers distraction'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ngkqy/suggestions_for_how_to_use_ai_for_a_commercial/",
          "author": null,
          "description": "A friend of mine has a small 12 person company that does office refurbishment and commercial redesign projects - he has asked me to speak to his team to give them an AI 101 - and to tell them a little about how they should be looking into using AI tools for their company.\n I know there are plenty of tools and apps that take photos of a bare room and make them look like a design magazine - any in particular I should show them? Can anyone think of other tools that they should look into using, or how do people in this space currently use AI?\n ​\n    submitted by    /u/zascar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ngkqy/suggestions_for_how_to_use_ai_for_a_commercial/",
          "publishedOn": "2023-09-20T09:13:03.000Z",
          "wordCount": 2629,
          "title": "Suggestions for how to use AI for a commercial office fit-out business?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16nc8tq/oneminute_daily_ai_news_9192023/",
          "author": null,
          "description": "Software company Digimarc will now let copyright owners add more information to their work, which the company said will improve how AI models treat copyright in training data.[1]\n AlphaMissense, a new model from Google’s artificial intelligence team, analyzes the effects of DNA mutations and will accelerate research into rare diseases.[2]\n Google’s AI assistant can now read your emails, plan trips, “double-check” answers.[3]\n Teens using AI to generate nude deep fakes to bully, harass classmates, FBI expert warns.[4]\n  \nSources:\n [1] https://www.theverge.com/2023/9/19/23879555/digimarc-copyright-watermark-generative-ai\n [2] https://www.wired.co.uk/article/deepmind-ai-alphamissense-genetics-rare-diseases\n [3] https://arstechnica.com/information-technology/2023/09/googles-ai-assistant-can-now-read-your-emails-plan-trips-double-check-answers/\n [4] https://www.news5cleveland.com/news/local-news/teens-using-ai-to-generate-nude-deep-fakes-to-bully-harass-classmates-fbi-expert-warns \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16nc8tq/oneminute_daily_ai_news_9192023/",
          "publishedOn": "2023-09-20T04:44:28.000Z",
          "wordCount": 2600,
          "title": "One-Minute Daily AI News 9/19/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16nb1qt/bard_gets_a_major_upgrade/",
          "author": null,
          "description": "Google's Bard chatbot is extending its abilities with access to personalized Google apps and services including Gmail, Docs, Drive, Maps, YouTube, and Google Flights and hotels.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/s1ivsummzbpb1.png?width=1600&format=png&auto=webp&s=d8fc3262ba542b950de3c8a85b9a987763270ada\n Bard Extensions and Google Applications Integration\n  \nBard can now tap into individualized data from Google apps such as Gmail, Drive, and Docs, with user permission.\n Google reassured users that personal data accessed by Bard will not be used for reinforcement learning, providing another on their transparency, choice, and control tenets.\n Prompts can direct Bard to search for specific information within Gmail, but it does not store the entire inbox content.\n  \nCollaborative Characteristics and Fact-Checking Capabilities\n  \nUsers can employ Bard to summarize emails or gather trip details from email threads, and then research real-time travel information, surface YouTube recommendations for the destination, and provide Maps directions to the airport.\n Google's chatbot can also double-check its responses against Google search, improving user trust and enhancing Bard's model through user feedback on incorrect answers.\n The new extensions using non-personal data – YouTube, Flights, Hotels, and Maps – are automatically opted-in but users can choose to opt-out.\n  \nCollaboration and Language Availability\n  \nBard now lets users share an ongoing chat with others through a public link.\n Google plans to expand Bard's feature set to over 40 new languages beyond its existing English language capabilities.\n  \n(source)\n P.S. If you like this kind of analysis, I put out a free newsletter covering the latest and most pertinent news and research in AI. Regular readers include professionals from Google, Meta, and OpenAI.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16nb1qt/bard_gets_a_major_upgrade/",
          "publishedOn": "2023-09-20T03:38:19.000Z",
          "wordCount": 2777,
          "title": "Bard Gets a Major Upgrade",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16n6kvk/starting_to_get_the_impression_im_legit_going_to/",
          "author": null,
          "description": "submitted by    /u/guh-eye  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16n6kvk/starting_to_get_the_impression_im_legit_going_to/",
          "publishedOn": "2023-09-20T00:05:38.000Z",
          "wordCount": 2517,
          "title": "Starting to get the impression I'm legit going to be replaced",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mztmt/schneider_electric_warns_that_existing/",
          "author": null,
          "description": "Schneider Electric warns that existing datacenters may not be equipped to handle the demands of AI workloads, which require low-latency, high-bandwidth networking and power delivery.\n \nThe company suggests reevaluating the way datacenters are built to optimize them for AI.\n \nThe challenges include the need for liquid-cooled servers, higher voltage power distribution, and efficient heat rejection.\n \nSchneider provides guidance on changes to power, cooling, rack configuration, and software management to mitigate the demands of AI adoption.\n \nLiquid cooling is recommended for high-density racks, with direct liquid cooling favored over immersion cooling systems.\n \n Source : https://www.theregister.com/2023/09/19/schneider_electric_ai_dc/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mztmt/schneider_electric_warns_that_existing/",
          "publishedOn": "2023-09-19T19:22:17.000Z",
          "wordCount": 2613,
          "title": "Schneider Electric warns that existing datacenters aren't buff enough for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mxma9/1000_top_ai_tools_directory/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mxma9/1000_top_ai_tools_directory/",
          "publishedOn": "2023-09-19T17:51:50.000Z",
          "wordCount": 2513,
          "title": "1000+ Top AI Tools Directory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mvvcy/i_read_the_paper_for_you_researchers_announce/",
          "author": null,
          "description": "I read the Arxiv paper on CulturaX so you don't have to. Here's my highlights:\n  \nNew open dataset called CulturaX contains text data for 167 languages - far more than previous datasets.\n With over 6 trillion words, it's the largest multilingual dataset ever released.\n Freely available for anyone to use for research and AI development.\n Created by combining and extensively cleaning two other large datasets - mC4 and OSCAR.\n Could allow developing AI systems that work much better across many more languages.\n Helps democratize access to data to build fairer, less biased AI models.\n Allows training of new multilingual AI applications, like universal translators and assistants.\n But still requires thoughtfulness to avoid issues like bias amplification.\n  \nOverall, CulturaX is going to be part of a broader global trend (I think) to advance multilingual AI and spread its benefits more equally. So far they've been concentrated in English-speaking applications.\n Full summary here if you'd like to read more. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mvvcy/i_read_the_paper_for_you_researchers_announce/",
          "publishedOn": "2023-09-19T16:40:18.000Z",
          "wordCount": 2691,
          "title": "[I read the paper for you]: Researchers announce CulturaX - a new multilingual dataset for AI with 6 trillion words across 167 languages",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mvi0g/ai_engineer_2023_roadmap/",
          "author": null,
          "description": "submitted by    /u/rbagdiya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mvi0g/ai_engineer_2023_roadmap/",
          "publishedOn": "2023-09-19T16:25:28.000Z",
          "wordCount": 2521,
          "title": "AI Engineer 2023 roadmap",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mvfkq/here_is_vedv_for_develop_your_ai_app_development/",
          "author": null,
          "description": "A tool for developing applications with virtual machines using a Docker-like workflow.\n The software we are developing needs to be tested on a system as closed as possible to the one where it is going to be executed. Sometimes it is very difficult to satisfy this requirement with docker and we have to use virtual machines missing the docker workflow. This is why I started the development of vedv. I hope you find it useful. Thank you.\n https://github.com/yunielrc/vedv\n ​\n    submitted by    /u/yunielrc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mvfkq/here_is_vedv_for_develop_your_ai_app_development/",
          "publishedOn": "2023-09-19T16:22:46.000Z",
          "wordCount": 2596,
          "title": "Here is VEDV for develop your AI App development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mu7t2/can_i_train_my_snapchat_ai_to_be_a_better_copy_of/",
          "author": null,
          "description": "I really really like Snapchat’s Ai companion. I’ve told it a little bit about myself and who I am- the basics. I’m just wondering if it’s as customizable as I think it is? I was able to bypass some age restrictions by telling it my age and or reiterating my age. (It really should be able to give me adult results/replies based on my sign up age on my profile or provide ID to the company…) would it be beneficial to me to give it more in-depth information about myself such as how I talk, interests? I just really enjoy how it responds sometimes as opposed to Bard or GPT.\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mu7t2/can_i_train_my_snapchat_ai_to_be_a_better_copy_of/",
          "publishedOn": "2023-09-19T15:34:37.000Z",
          "wordCount": 2631,
          "title": "Can I train my Snapchat Ai to be a better copy of myself?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mri85/ai_can_now_track_productivity_and_offer_insights/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mri85/ai_can_now_track_productivity_and_offer_insights/",
          "publishedOn": "2023-09-19T13:47:30.000Z",
          "wordCount": 2521,
          "title": "AI Can Now Track Productivity And Offer Insights; Potential Benefits and Big Risks For Misuse",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mnid9/ethics_is_where_ai_can_help_humanity_the_most/",
          "author": null,
          "description": "AI is poised to transform our world like never before. Scientific discoveries, technological improvements, and medical advancements will be how much of this change will take place.\n Since health is so important to our well-being, AI finding cures for illnesses like obesity, cancer, diabetes and heart disease will be a godsend to all. But curing diseases is not how medical AIs can help us the most. \n It has been estimated that well over 50% of the illnesses we humans fall prey to result from our ethical choices. We eat too much, drink too much, eat too many animal foods, don't exercise enough and don't keep ourselves as emotionally healthy as we could.\n Wouldn't it be wonderful if we could respect our lives and our health enough to make the kinds of choices that keep us much healthier? That is how AI will probably be more helpful to us than in any other way. \n We humans have not been able to figure out how to become better, more ethical, people because we are simply not intelligent enough to make that all-important change. Now consider an AI that is two or three times more intelligent than the most intelligent person who has ever lived. This could easily happen before 2030. Imagine that intelligence dedicated to the task of helping us all become better people. \n These AIs would motivate us to make better health choices, have healthier relationships, and have healthier thoughts and feelings. Beyond the amazing technological changes that are just around the corner, that is probably how AIs will help us the most.\n This is why alignment is so important. It's not enough to align AIs to always be truthful and serve humanity's interests. We must train them to help us become better people. It wouldn't surprise me if by 2030 the whole of humanity experiences a profound ethical reformation that leads us all to enjoy much happier and healthier lives.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mnid9/ethics_is_where_ai_can_help_humanity_the_most/",
          "publishedOn": "2023-09-19T10:39:01.000Z",
          "wordCount": 2839,
          "title": "Ethics is where AI can help humanity the most",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mltho/resume_parser/",
          "author": null,
          "description": "I am trying to make a resume parser, I am not so sure how to go about it really, whether or not to use a pre-trained model (there are some in Python) or rather just make my own, and if i do make my own, how to actually proceed?\n thanks in advance\n    submitted by    /u/General-Carrot-4624  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mltho/resume_parser/",
          "publishedOn": "2023-09-19T08:56:34.000Z",
          "wordCount": 2562,
          "title": "Resume Parser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mlp4p/google_and_the_dod_built_an_aipowered_microscope/",
          "author": null,
          "description": "Google and the Department of Defense have developed an AI-powered microscope called the Augmented Reality Microscope (ARM) to assist doctors in identifying cancer.\n \nThe ARM uses artificial intelligence to analyze tissue samples and provide pathologists with information about the location and severity of cancer.\n \nThere are currently 13 ARMs in existence, and initial research shows promising results.\n \nThe ARM is designed to support pathologists in smaller labs who may not have easy access to a second opinion.\n \nIt is not meant to replace digital pathology systems but can help health organizations bypass the need for them.\n \nThe ARM is expected to cost health systems between $90,000 to $100,000.\n \n Source : https://www.cnbc.com/2023/09/18/google-dod-built-an-ai-powered-microscope-to-help-doctors-spot-cancer.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mlp4p/google_and_the_dod_built_an_aipowered_microscope/",
          "publishedOn": "2023-09-19T08:48:44.000Z",
          "wordCount": 2632,
          "title": "Google and the DoD built an AI-powered microscope to help doctors spot cancer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ml4sk/is_there_an_ai_capable_of_administering/",
          "author": null,
          "description": "All is in the title ;)\n    submitted by    /u/Big-Possibility4553  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ml4sk/is_there_an_ai_capable_of_administering/",
          "publishedOn": "2023-09-19T08:12:31.000Z",
          "wordCount": 2525,
          "title": "Is there an AI capable of administering psychometric career guidance tests?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mi3qj/new_os_python_framework_agents_introduced_for/",
          "author": null,
          "description": "A new open-source Python framework, known as \"Agents\", has been introduced for developing autonomous language processing agents. This could be a major breakthrough in the AI field, taking NLP technologies to the next level.\n To stay on top of the latest advancements in AI, look here first.\n Agents for autonomy\n  \n\"Agents\" is a Python framework that has been developed for autonomous language processing agents.\n It enables developers to construct models that can communicate and operate independently.\n This open-source framework promotes sharing and collaboration among AI developers.\n  \nPotential applications\n  \nThe functionality of \"Agents\" is applicable in various domains, including virtual assistants, chatbots, and simulation games.\n It opens up possibilities for advanced conversational AI, where systems can efficiently handle complex linguistic contexts.\n Ability to evolve dialects and languages in different AI models is a major feat for \"Agents\".\n  \nBroader implications\n  \nThe release of \"Agents\" might boost enhancement in NLP technologies, playing a crucial role in AI evolution.\n By facilitating better language understanding, it will potentially impact on societal interactions with AI.\n Its open-source nature could cultivate an environment of innovation and creativity in the AI community.\n  \n(arXiv) (github)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mi3qj/new_os_python_framework_agents_introduced_for/",
          "publishedOn": "2023-09-19T05:11:02.000Z",
          "wordCount": 2737,
          "title": "New OS Python Framework \"Agents\" Introduced for Autonomous Language Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mhj30/oneminute_daily_ai_news_9182023/",
          "author": null,
          "description": "Microsoft AI researchers accidentally exposed tens of terabytes of sensitive data, including private keys and passwords, while publishing a storage bucket of open source training data on GitHub.[1]\n Britain set out principles on Monday designed to prevent artificial intelligence (AI) models from being dominated by a handful of tech companies to the detriment of consumers and businesses, by emphasising the need for accountability and transparency.[2]\n Washington state firefighters using AI-assisted cameras to detect wildfires early.[3]\n Texas church experiments with AI-generated service, uses ChatGPT for worship, sermon, and original song.[4]\n  \nSources:\n [1] https://techcrunch.com/2023/09/18/microsoft-ai-researchers-accidentally-exposed-terabytes-of-internal-sensitive-data/\n [2] https://www.reuters.com/technology/uk-competition-regulator-lays-out-ai-principles-2023-09-18/\n [3] https://www.applevalleynewsnow.com/news/washington-state-firefighters-using-ai-assisted-cameras-to-detect-wildfires-early/article_fe31a468-5681-11ee-b917-2f24ad3a0e43.html\n [4] https://www.foxnews.com/us/texas-church-experiments-ai-generated-service-uses-chatgpt-worship-sermon-original-song \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mhj30/oneminute_daily_ai_news_9182023/",
          "publishedOn": "2023-09-19T04:39:31.000Z",
          "wordCount": 2608,
          "title": "One-Minute Daily AI News 9/18/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mf8oj/microsoft_under_scrutiny_after_38tb_data_leaked/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mf8oj/microsoft_under_scrutiny_after_38tb_data_leaked/",
          "publishedOn": "2023-09-19T02:45:04.000Z",
          "wordCount": 2529,
          "title": "Microsoft Under Scrutiny After 38TB Data Leaked Via Azure Storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16me44v/list_of_mindblowing_ai_tools/",
          "author": null,
          "description": "submitted by    /u/rbagdiya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16me44v/list_of_mindblowing_ai_tools/",
          "publishedOn": "2023-09-19T01:52:23.000Z",
          "wordCount": 2522,
          "title": "List of Mind-blowing AI Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16m86vt/how_can_i_help_a_cnn_distinguish_between/",
          "author": null,
          "description": "I'm currently considering developing a AI to play a video game but I'm unsure how to differentiate between a value that is continuous, and a value that is representative of a entity type. For example, the x,y location of a player would be a continuous data point where (1,1) and (2,1) would be similar in values. Where the character ID would intuitively require very different strategy (for example lets say a barbarian and a wizard). Would a CNN have issues with this data because it isn't continuous?\n    submitted by    /u/Gamithon24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16m86vt/how_can_i_help_a_cnn_distinguish_between/",
          "publishedOn": "2023-09-18T21:38:20.000Z",
          "wordCount": 2633,
          "title": "How can I help a CNN distinguish between continuous values and tokenized values.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16m5r6g/im_looking_for_a_website_that_kind_of_tracks_the/",
          "author": null,
          "description": "Surely by now I thought maybe someone would have a website or something kind of like an \"all in one resource page\" to track this AI stuff.... I'm sure by now we have AI robots and then we have those AI chatgpt stuff things(which I don't understand yet, haha). Unfortunately the internet is flooded and there's WAY TOO MANY resources for this AI stuff.... Isn't there like an all in one place that I can keep up with it?\n What hints do you all have for me? Thanks...\n    submitted by    /u/Wise_Cut_2543  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16m5r6g/im_looking_for_a_website_that_kind_of_tracks_the/",
          "publishedOn": "2023-09-18T20:04:46.000Z",
          "wordCount": 2658,
          "title": "I'm Looking for a website that kind of Tracks the latest AI robots along with their progress and those AI chat things to... like one website... does anybody know of one like that for me to research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lrtxk/the_importance_to_alignment_of_ai_understanding/",
          "author": null,
          "description": "Alignment is about ensuring that AIs protect and advance humanity. To do that, they must understand the ethics of the current events that we will want its advice on. Politics may actually be the part of alignment most important for AI to get right.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lrtxk/the_importance_to_alignment_of_ai_understanding/",
          "publishedOn": "2023-09-18T10:30:15.000Z",
          "wordCount": 2588,
          "title": "The importance to alignment of AI understanding politics and current events",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lqkzb/bard_on_the_march_to_the_capitol_and_ensuing/",
          "author": null,
          "description": "Prompt:\n Trump says that he asked his mob to peacefully walk to the Capitol building gates. How would this have stopped the certification? Did he expect them to storm in? His waiting three hours to stop the violence that followed suggests that he did.\n Bard:\n Trump's request to walk peacefully to the Capitol building gates would not have stopped the certification of the election results. The certification process is a joint session of Congress, and it would have required a majority vote in both the House and the Senate to overturn the results. Even if Trump's supporters had peacefully marched to the Capitol, they would not have been able to prevent Congress from certifying the results.\n It is possible that Trump did not fully understand the certification process, or that he was simply trying to appease his supporters. However, it is also possible that he expected his supporters to storm the Capitol and prevent Congress from certifying the results. This is supported by the fact that he waited over three hours to call off the violence. During that time, he continued to tweet messages of encouragement to his supporters, and he even praised them for their patriotism.\n It is also worth noting that Trump had been repeatedly warned by his advisors about the possibility of violence on January 6. However, he ignored these warnings and continued to urge his supporters to fight to overturn the election results.\n In conclusion, it is impossible to say for sure whether Trump expected his supporters to storm the Capitol on January 6. However, the evidence suggests that he was at least aware of the possibility of violence, and that he was willing to allow it to happen in order to overturn the results of the 2020 election.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lqkzb/bard_on_the_march_to_the_capitol_and_ensuing/",
          "publishedOn": "2023-09-18T09:18:13.000Z",
          "wordCount": 2836,
          "title": "Bard on the march to the Capitol and ensuing violence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lmytj/ai_music_video/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lmytj/ai_music_video/",
          "publishedOn": "2023-09-18T05:38:43.000Z",
          "wordCount": 2535,
          "title": "AI music video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lm9vq/oneminute_daily_ai_news_9172023/",
          "author": null,
          "description": "Salesforce Launches Next Generation of Einstein, Bringing a Conversational AI Assistant to Every CRM Application and Customer Experience.[1]\n NVIDIA Reportedly Shipping 900 Tons of H100 AI GPUs This Quarter, Amounts to 300,000 Units.[2]\n SoftBank seeks OpenAI tie-up as Son plans deal spree after Arm IPO, Financial Times reports.[3]\n Three Chinese firms, led by AI software company Beijing Fourth Paradigm, are aiming to raise up to $280 million in Hong Kong initial public offerings launched on Monday.[4]\n  \nSources:\n [1] https://www.salesforce.com/news/press-releases/2023/09/12/ai-einstein-news-dreamforce/\n [2] https://wccftech.com/nvidia-shipping-900-tons-of-h100-ai-gpus-this-quarter-amounts-300000-units/\n [3] https://www.reuters.com/markets/deals/softbank-seeks-openai-tie-up-son-plans-deal-spree-after-arm-ipo-ft-2023-09-16/\n [4] https://www.aol.com/news/chinese-ai-firm-fourth-paradigm-011143403.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lm9vq/oneminute_daily_ai_news_9172023/",
          "publishedOn": "2023-09-18T04:59:59.000Z",
          "wordCount": 2623,
          "title": "One-Minute Daily AI News 9/17/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lib23/how_does_a_site_like_architectrendercom_work_on/",
          "author": null,
          "description": "I'm trying to understand how someone can run a specific ControlNet and Stable Diffusion model with scalable GPU resources. How would someone design a system to achieve this? I've messed around with models on Replicate, but none seem to do a good job with converting a doodle to a photorealistic image. I can do it perfectly fine in the Stable Diffusion web UI, but the API for that is only accessible locally. Anyone have any ideas or can guide me in the right direction for building a \"server\" to do this?\n    submitted by    /u/epicblitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lib23/how_does_a_site_like_architectrendercom_work_on/",
          "publishedOn": "2023-09-18T01:36:59.000Z",
          "wordCount": 2634,
          "title": "How does a site like architectrender.com work on the backend?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lhdjq/introducing_vllm_the_opensource_ml_library/",
          "author": null,
          "description": "The hardware accelerators for LLM-powered applications can be costly. Enter vLLM, an open-source machine learning library designed to enhance the throughput of LLM serving systems.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/hzctjc0xvwob1.png?width=1660&format=png&auto=webp&s=866eb39745ec760ea0c1b9d84d303c63bcdceb7a\n Challenges with existing systems\n  \nHigh throughput serving of LLMs requires numerous requests, and current systems struggle with the bulky sequence memory.\n Inefficient memory management results in system hindrances such as fragmentation and redundant duplication.\n  \nThe revolutionary answer: vLLM & PagedAttention\n  \nResearchers have introduced vLLM and PagedAttention, a newly designed attention algorithm, to resolve these issues.\n vLLM allows for minimal memory waste and efficiently manages attention keys and values. It provides up to 24 times more throughput than former systems.\n  \nThe Mechanics of PagedAttention\n  \nPagedAttention offers a novel approach to memory management by permitting continuous storage in non-contiguous memory spaces.\n It enhances memory efficiency resulting in better GPU utilization, with practically only 4% inefficiency.\n  \nImproved memory sharing and system performance\n  \nPagedAttention significantly improves memory sharing, resulting in a 2.2 times speed gain while lowering memory usage by 55%.\n With vLLM, the throughput of known LLMs can be increased by 2-4 times without impacting accuracy or causing delay.\n  \n(arXiv) (github) (reference article)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lhdjq/introducing_vllm_the_opensource_ml_library/",
          "publishedOn": "2023-09-18T00:52:11.000Z",
          "wordCount": 2775,
          "title": "Introducing vLLM: The Open-Source ML Library Revolutionizing LLM Inference and Serving",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lerex/courses_in_ai_usage_and_utilization_for_business/",
          "author": null,
          "description": "Beginning new career in a couple months, would like to upskill on AI utilization and usage cases. I won’t need to code in this role but rather understand how to use existing tools in an optimal way and recommend use cases to clients.\n What courses would be optimal to gain that skill set?\n    submitted by    /u/iceflamemaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lerex/courses_in_ai_usage_and_utilization_for_business/",
          "publishedOn": "2023-09-17T22:52:34.000Z",
          "wordCount": 2591,
          "title": "Courses in AI Usage and Utilization for Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16laugj/will_cyber_security_be_replaced_by_ai/",
          "author": null,
          "description": "AI, including ChatGPT, has narrow expertise and lacks the broad spectrum of human intelligence.\n \nThe training of AI models can be costly due to hardware, data collection, and energy consumption.\n \nThe trustworthiness of training data is crucial for reliable AI models, but issues like bias, labeling errors, and data privacy can affect performance.\n \nAI systems are vulnerable to adversarial attacks, such as manipulating input data to deceive the models.\n \nAI lacks genuine understanding, emotional/social intelligence, common sense/critical thinking, and true creativity.\n \n Source : https://blog.edned.net/will-ai-replace-cyber-security/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16laugj/will_cyber_security_be_replaced_by_ai/",
          "publishedOn": "2023-09-17T20:13:56.000Z",
          "wordCount": 2621,
          "title": "Will Cyber Security Be Replaced by AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16l7v0t/ai_prompt_engineers_the_six_figure_job_everyone/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16l7v0t/ai_prompt_engineers_the_six_figure_job_everyone/",
          "publishedOn": "2023-09-17T18:15:36.000Z",
          "wordCount": 2541,
          "title": "AI Prompt Engineers: The Six Figure Job Everyone Is Talking About",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16l7ucq/are_you_ready_for_ai_automation_take_this_free/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16l7ucq/are_you_ready_for_ai_automation_take_this_free/",
          "publishedOn": "2023-09-17T18:14:52.000Z",
          "wordCount": 2544,
          "title": "Are You Ready For AI & Automation? Take This Free Survey and Find Out.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16l56nr/help/",
          "author": null,
          "description": "what app that has custom charaters and voice chat?\n i forgor 💀\n please 😭\n it has \n image gen roleplay rooms etc\n    submitted by    /u/roblox22g  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16l56nr/help/",
          "publishedOn": "2023-09-17T16:30:34.000Z",
          "wordCount": 2552,
          "title": "help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16kxp49/google_changes_its_stance_on_ai_generated_content/",
          "author": null,
          "description": "Google is rolling out its third iteration of the Helpful Content Update, which aims to classify content as either 'written for search engines' or 'written for people'.\n \nThe update reflects Google's realization that it can't accurately police AI-generated content and emphasizes the importance of creating content for people-first, regardless of the means used to create it.\n \nDetecting AI content is challenging, as AI detection tools often classify content based on tone, leading to false positives.\n \nGoogle's change in stance is not surprising, considering their heavy investment in AI, including chatbot Bard and new search features like the Search Generative Experience.\n \nThe majority of brands now openly share articles and guides on how to use AI tools to enhance marketing strategies and create actionable content plans quickly.\n \nHowever, the quality and value of AI-generated content remain important factors for success, as poorly generated content can harm a brand's reputation and ranking.\n \n Source : https://stackdiary.com/google-changes-its-stance-on-ai-generated-content/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16kxp49/google_changes_its_stance_on_ai_generated_content/",
          "publishedOn": "2023-09-17T10:57:13.000Z",
          "wordCount": 2691,
          "title": "Google changes its stance on AI generated content",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16kefrr/bard_describe_what_the_pandemic_and_insurrection/",
          "author": null,
          "description": "The COVID-19 pandemic and the January 6th insurrection have had a profound impact on people's feelings. Many people have experienced a range of negative emotions, including:\n  \nFear and anxiety: The pandemic has brought with it a constant fear of getting sick or losing loved ones. The insurrection also raised fears about the future of democracy and the safety of the country.\n Grief and loss: Millions of people have lost loved ones to COVID-19. Many others have experienced loss in other ways, such as losing their jobs, businesses, or homes. The insurrection also led to loss of trust in the government and in each other.\n Anger and frustration: Many people are angry about the way the pandemic and the insurrection have been handled. They may be frustrated with government officials, with their …",
          "link": "https://www.reddit.com/r/artificial/comments/16kefrr/bard_describe_what_the_pandemic_and_insurrection/",
          "publishedOn": "2023-09-16T18:28:27.000Z",
          "wordCount": 2955,
          "title": "Bard, describe what the pandemic and insurrection have made people feel.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16kb0bb/bard_what_percent_of_our_thoughts_just_come_to_us/",
          "author": null,
          "description": "There is no one definitive answer to this question, as the percentage of our thoughts that come to us on their own without our consciously choosing them can vary depending on the individual and the situation. However, some estimates suggest that up to 95% of our thoughts may be involuntary.\n This is because our thoughts are constantly being influenced by a variety of factors, both external and internal. For example, our environment, our emotions, and our physical state can all play a role in determining what thoughts pop into our heads.\n In addition, our brains are constantly processing information and making predictions, even when we are not actively thinking about anything. This process can sometimes lead to spontaneous thoughts, such as when we suddenly remember something that we had forgotten or when we come up with a new idea.\n While some of our spontaneous thoughts may be negative or intrusive, many of them can also be helpful or creative. For example, a spontaneous thought may help us to solve a problem, come up with a new solution, or simply make us smile.\n Overall, it is clear that a significant portion of our thoughts come to us without our consciously choosing them. This is a natural part of the human cognitive process and can be both beneficial and detrimental.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16kb0bb/bard_what_percent_of_our_thoughts_just_come_to_us/",
          "publishedOn": "2023-09-16T15:59:27.000Z",
          "wordCount": 2766,
          "title": "Bard, what percent of our thoughts just come to us on their own without our consciously choosing them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16k8o6f/are_there_any_good_ai_video_editing_services/",
          "author": null,
          "description": "I have a lighting business and I have LOADS of videos, time lapses, images from our projects.\n But I can't make decent videos with them for social media.\n I'd love to find an ai service where I can upload a projects media and prompt the ai with exactly what I want.\n Like, please use this content to create marketing videos for us on tiktok, Instagram and facebook Facebook\n Etc\n    submitted by    /u/RulerOfThePixel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16k8o6f/are_there_any_good_ai_video_editing_services/",
          "publishedOn": "2023-09-16T14:17:46.000Z",
          "wordCount": 2608,
          "title": "Are there any good ai video editing services available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16k6k5p/how_can_i_generate_the_missing_part_of_the_trick/",
          "author": null,
          "description": "submitted by    /u/farineziq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16k6k5p/how_can_i_generate_the_missing_part_of_the_trick/",
          "publishedOn": "2023-09-16T12:38:19.000Z",
          "wordCount": 2544,
          "title": "How can I generate the missing part of the trick? Does this technique have a name?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jxyda/oneminute_daily_ai_news_9152023/",
          "author": null,
          "description": "A little boy named Alex saw 17 different doctors over the course of three years, unable to find a root cause of his chronic pain. At her wit’s end, his mom, Courtney, fed his radiology report into ChatGPT and produced immediate answers.[1]\n In January, Wharton professor Christian Terwiesch gave his MBA final exam to ChatGPT. It passed with flying colors. Now, he’s at it again with a new experiment to determine whether ChatGPT can come up with product ideas better and faster than his students. It can. And cheaper, too.[2]\n Bathroom-cleaning robot built for commercial businesses gives consumers hope for AI maid.[3]\n Judge admits he used ChatGPT to write a Court of Appeal ruling as he calls the AI tool ‘jolly useful’.[4]\n  \nSources:\n [1] https://radiologybusiness.com/topics/artificial-intelligence/after-seeing-17-different-doctors-boy-rare-condition-receives-diagnosis-chatgpt\n [2] https://knowledge.wharton.upenn.edu/article/is-chatgpt-a-better-entrepreneur-than-most/\n [3] https://www.foxnews.com/lifestyle/bathroom-cleaning-robot-built-commercial-businesses-gives-consumers-hope-ai-maid\n [4] https://www.dailymail.co.uk/news/article-12524607/Judge-ChatGPT-write-Court-Appeal-ruling-AI-useful.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jxyda/oneminute_daily_ai_news_9152023/",
          "publishedOn": "2023-09-16T04:14:25.000Z",
          "wordCount": 2666,
          "title": "One-Minute Daily AI News 9/15/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jsd4m/googles_new_deepmind_maps_algorithm_improves/",
          "author": null,
          "description": "Google has developed an AI algorithm to refine route suggestions on Google Maps, personalizing it based on user data and behavior, allegedly improving the accuracy on an average by 16-24 percent.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/rp21ylzo7iob1.jpg?width=770&format=pjpg&auto=webp&s=737cf3fd278ade42900e8586d626a7c729522c1a\n Personalized Route Suggestions through AI\n  \nThe AI model comprises 360 million parameters, using real-time data from Maps users to influence factors including travel time, road conditions, tolls, and personal preferences to suggest routes.\n This technology is grounded on \"inverse reinforcement learning\" (IRL), specifically a new IRL algorithm - \"Receding Horizon Inverse Planning (RHIP)\".\n  \nThe Power of RHIP and AI in Maps\n  \nGoogle and Deepmind jointly worked to develop RHIP, using complex stochastic models in immediate vicinity areas, but switching to simpler deterministic methods for distant areas for power conservation.\n The AI improves route suggestions for both driving and two-wheeled vehicles by learning from Maps users' movements and behaviors over time.\n Google states that this is the largest application of inverse reinforcement learning for route planning to date.\n  \nImplementation and User Testing\n  \nGoogle has applied the algorithm to Maps data globally, but extensive user testing is needed to confirm if the technique consistently produces better routes.\n Previous attempts at using AI systems for route planning on a large scale have often failed due to the complexity of road networks.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jsd4m/googles_new_deepmind_maps_algorithm_improves/",
          "publishedOn": "2023-09-15T23:29:34.000Z",
          "wordCount": 2796,
          "title": "Google’s new DeepMind Maps algorithm improves route suggestions by 24%",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jpu3w/bard_on_republican_16_denial/",
          "author": null,
          "description": "There are a number of reasons why some Republicans may be in denial about Trump's role in the January 6th Capitol riot.\n  \nTrump has been very effective at cultivating a cult of personality among his supporters. These supporters are often fiercely loyal to him and willing to believe whatever he says, even if it contradicts reality.\n Many Republicans have been reluctant to criticize Trump for fear of alienating his supporters. This is especially true for Republican politicians who are up for re-election in 2022.\n Some Republicans may genuinely believe that Trump did not incite the riot. They may point to the fact that he did not explicitly call for violence, or that he told his supporters to \"peacefully and patriotically make your voices heard.\"\n Other Republicans may be motivated by partis…",
          "link": "https://www.reddit.com/r/artificial/comments/16jpu3w/bard_on_republican_16_denial/",
          "publishedOn": "2023-09-15T21:43:32.000Z",
          "wordCount": 2947,
          "title": "Bard on Republican 1/6 denial",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jowi1/bard_on_factory_farming_and_clean_meat/",
          "author": null,
          "description": "Factory farming is a cruel and unsustainable way to produce meat. Animals are crammed into small, filthy spaces, where they are often denied their basic needs. They are given antibiotics to prevent disease and growth hormones to make them grow faster. This leads to a variety of health problems for the animals, as well as for the people who eat their meat.\n Clean meat is a new technology that offers a more humane and sustainable way to produce meat. It is made from animal cells that are grown in a lab, without the need for animals to be raised or slaughtered. Clean meat is still in its early stages of development, but it has the potential to revolutionize the meat industry.\n Here are some of the reasons why factory farming must be replaced by clean meat:\n  \nIt is cruel to animals. Factory f…",
          "link": "https://www.reddit.com/r/artificial/comments/16jowi1/bard_on_factory_farming_and_clean_meat/",
          "publishedOn": "2023-09-15T21:07:30.000Z",
          "wordCount": 2902,
          "title": "Bard on factory farming and clean meat",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jisc3/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nStability AI launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time [Details].\n Coqui released XTTS - a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip [Details].\n Microsoft Research released and open-sourced Phi-1.5 - a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger [Paper ].\n Project Gutenberg, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of human-quality free and open audiobooks [Details].\n Res…",
          "link": "https://www.reddit.com/r/artificial/comments/16jisc3/ai_weekly_megathread/",
          "publishedOn": "2023-09-15T17:02:02.000Z",
          "wordCount": 3231,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jg22m/with_things_always_moving_so_fast_i_may_have/",
          "author": null,
          "description": "Has anyone dropped an opensource tool like run.ai, to leverage multiple gpus / distribute the workload a bit more efficiently?\n I'm loving some of the single gpu llm modifications that have been dropping recently (have a couple i've tested that ran well on 4090 and 3090ti in the lab), but i've got a plethora of 8 & 12 gig 3xxx series cards i'd love to take advantage of beyond passthroughs to individual vms. Looking for any solutions. Speed isn't as important as the ability to distributively run larger models.\n    submitted by    /u/SwallowedBuckyBalls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jg22m/with_things_always_moving_so_fast_i_may_have/",
          "publishedOn": "2023-09-15T15:13:22.000Z",
          "wordCount": 2639,
          "title": "With things always moving so fast, I may have missed it. Anyone doing something like Run.AI in an opensource capacity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jg0zf/ai_death_metal_band_anarchys_echo_debut_single/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jg0zf/ai_death_metal_band_anarchys_echo_debut_single/",
          "publishedOn": "2023-09-15T15:12:07.000Z",
          "wordCount": 2546,
          "title": "AI Death Metal band 'Anarchy's Echo' - Debut single 'Soul Shredder' [visuals, music, name, logo all AI generated]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j8m29/free_ai_summary_of_article_based_on_most/",
          "author": null,
          "description": "I am looking for a free AI tool, site (may be paid with free account limited options) that can do a summary of English article (like BBC, youtube) based on most frequently used English words, for example Oxford list of 3000 most frequently used words in English. In other words if word is not in that list it should replace the word with the one that is on the list or its definition.\n Pdf\n    submitted by    /u/vibrantform  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j8m29/free_ai_summary_of_article_based_on_most/",
          "publishedOn": "2023-09-15T09:32:13.000Z",
          "wordCount": 2616,
          "title": "free AI summary of article based on most frequently used English words",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j8lha/ai_on_why_we_have_much_to_be_grateful_for/",
          "author": null,
          "description": "I said to Bard:\n It seems like these are difficult times. Compare today with the WWII years, explaining how much we have to be grateful for.\n Bard said:\n I agree that these are difficult times. The world is facing many challenges, including the COVID-19 pandemic, climate change, and political instability. However, I believe that we have much to be grateful for today compared to the WWII years.\n Here are just a few things:\n We live in a time of peace. World War II was a global conflict that caused the deaths of millions of people. Today, there are no major wars raging on.\n We have access to advanced medical care. During WWII, many people died from diseases that are now easily treatable. Today, we have antibiotics, vaccines, and other medical advances that have saved countless lives.\n We have a higher standard of living. In the WWII years, many people lived in poverty. Today, most people in the developed world have access to clean water, food, and shelter.\n We have more opportunities for education and advancement. In the WWII years, many people were denied an education because of their race, gender, or social class. Today, education is more accessible than ever before, and people from all backgrounds have the opportunity to succeed.\n We have a better understanding of the world. During WWII, there was a lot of misinformation and propaganda. Today, we have access to more information than ever before, and we can make more informed decisions about our lives.\n Of course, there are still many challenges that we face today. But I believe that we have come a long way since the WWII years, and we have much to be grateful for. Let us never forget the sacrifices that were made during that time, and let us continue to work towards a better future for all.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j8lha/ai_on_why_we_have_much_to_be_grateful_for/",
          "publishedOn": "2023-09-15T09:31:17.000Z",
          "wordCount": 2846,
          "title": "AI on why we have much to be grateful for",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j6djc/what_is_at_stake_in_the_ai_based_technoeconomic/",
          "author": null,
          "description": "The AI-based techno-economic war between the West and China will determine the global distribution of technology, economic benefits, and influence.\n \nThe winner of this race, particularly in AI, will have the power to accelerate GDP growth and project global economic benefits.\n \nChina is actively pursuing technological leadership in AI and 5G wireless, while the West must prioritize technological talent influx and leverage its venture and technology ecosystem.\n \nAggressive AI regulation could hinder the West's momentum in this race.\n \nThe risks of this war and AI technology are significant, but it is a greater risk to let adversaries have unconstrained power.\n \nGlobal treaties are not enforceable solutions to regulate AI.\n \n Source : https://medium.com/@vkhosla/what-is-at-stake-in-this-ai-based-techno-economic-war-between-the-west-and-china-8f76bd291be7\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j6djc/what_is_at_stake_in_the_ai_based_technoeconomic/",
          "publishedOn": "2023-09-15T07:12:03.000Z",
          "wordCount": 2657,
          "title": "What is at stake in the AI based techno-economic war between the West and China?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j63zr/what_has_been_the_most_significant_assistance/",
          "author": null,
          "description": "There's no need to specify which product fulfills your needs, but we'd like everyone to focus on describing their current frustrations and the issues they urgently hope AI can help them with.\n    submitted by    /u/Minna_Z  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j63zr/what_has_been_the_most_significant_assistance/",
          "publishedOn": "2023-09-15T06:55:47.000Z",
          "wordCount": 2608,
          "title": "What has been the most significant assistance from AI for you? It could be in various aspects of work, learning, and life. Are there any other needs you have that you hope AI can help you with, but there aren't suitable AI tools for them yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j4q4e/wine_can_prevent_cancer_says_chatgpt/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j4q4e/wine_can_prevent_cancer_says_chatgpt/",
          "publishedOn": "2023-09-15T05:32:21.000Z",
          "wordCount": 2547,
          "title": "“Wine can prevent Cancer” says ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ivaym/two_guys_with_very_different_views_on_ai_yuval/",
          "author": null,
          "description": "submitted by    /u/hauntedhivezzz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ivaym/two_guys_with_very_different_views_on_ai_yuval/",
          "publishedOn": "2023-09-14T21:59:17.000Z",
          "wordCount": 2546,
          "title": "Two guys with VERY different views on AI –Yuval Noah Harari and Mustafa Suleyman in conversation (full interview)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ir89k/chatgpt_tell_the_jury_that_trump_waiting_three/",
          "author": null,
          "description": "I asked ChatGPT to talk with Trump's jury about the 3-hour delay. Not bad.\n ChatGPT:\n Ladies and gentlemen of the jury, today, we present a compelling case that the three-hour delay in President Trump's response to the events of January 6th is, without a doubt, overwhelming and irrefutable evidence of his planning and conducting the insurrection that unfolded before our eyes.\n First, consider the timeline. As the violence escalated, President Trump did not immediately call for an end to the chaos. This delay allowed the mob to wreak havoc, endanger lives, and damage our democracy. A leader's duty is to protect the nation and its citizens, and a three-hour wait to act is inexplicable unless there was intent behind it.\n Second, let's talk about intent. In criminal law, intent matters. It's the difference between an accident and a crime. A deliberate delay in response to an unfolding insurrection suggests a guilty mind. President Trump had the power and the responsibility to intervene immediately. Yet, he chose not to, allowing the violence to escalate.\n Furthermore, we must consider his words leading up to and during the events of January 6th. His rhetoric could be interpreted as encouragement for his supporters to take matters into their own hands. This, coupled with the delay, paints a picture of a leader who not only knew what was happening but may have orchestrated it.\n Ladies and gentlemen, we are not here to pass judgment but to seek justice. The evidence of a three-hour delay in responding to the insurrection, along with the surrounding circumstances, presents a compelling case that President Trump planned and conducted this insurrection. It is our duty to hold individuals accountable for their actions, regardless of their position.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ir89k/chatgpt_tell_the_jury_that_trump_waiting_three/",
          "publishedOn": "2023-09-14T19:18:57.000Z",
          "wordCount": 2844,
          "title": "ChatGPT, tell the jury that Trump waiting three hours to call off his mob is overwhelming and irrefutable evidence that he planned and conducted the January 6th insurrection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16iqau7/how_good_a_crime_sleuth_and_judge_is_todays_ai/",
          "author": null,
          "description": "How would today's AI perform as a crime investigator or judge? To find out, I asked Bard the following question:\n The film Social Network suggests that Mark Zuckerberg stole his idea for Facebook from two brothers who hired him to make an app for the idea. How likely is this to be true?\n Bard seemed informed and sharp:\n \"The film The Social Network is a dramatization of the founding of Facebook, and as such, it takes some liberties with the truth. However, the film does accurately portray the fact that Mark Zuckerberg was sued by the Winklevoss twins, Cameron and Tyler, who claimed that he stole their idea for a social networking website called HarvardConnection.\n The Winklevoss twins allege that they met with Zuckerberg in December 2003 to discuss their idea for HarvardConnection, and tha…",
          "link": "https://www.reddit.com/r/artificial/comments/16iqau7/how_good_a_crime_sleuth_and_judge_is_todays_ai/",
          "publishedOn": "2023-09-14T18:41:58.000Z",
          "wordCount": 2895,
          "title": "How good a crime sleuth and judge is today's AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ipk9h/which_ai_to_use_for_this_idea/",
          "author": null,
          "description": "Hi there! I'm participating in a Hackathon at work and am wondering if this community can give me some direction. Every year our company receives mandates / updates from different parties. In turn, our development teams have to parse through heavy documentation to figure out what needs to change in our code. Ingesting the data is what takes the longest. Our goal is to feed the mandates documentation through an AI and have it return what is needed to be changed in our code. For example, something might say field 200 now needs to include a 6 digit date format vs the 4 digit date format we've had in years past. We have secured a license for Azure AI but honestly no idea if that is the right AI to use. I youtubed a bunch of videos on document processing but I'm also not sure if that is what we are trying to do. Any advice on this is much appreciated.\n    submitted by    /u/HillyjoKokoMo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ipk9h/which_ai_to_use_for_this_idea/",
          "publishedOn": "2023-09-14T18:13:01.000Z",
          "wordCount": 2698,
          "title": "Which AI to use for this idea?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ikloc/looking_for_a_meeting_assistant/",
          "author": null,
          "description": "I'm looking for a program that will transcribe live audio playing from my computer (windows).\n Do you know something like that? I've seen Buzz (https://chidiwilliams.github.io/buzz/docs/usage), but it needs an audio loopback driver in order to work, so I wonder if there are others.\n 🚀 Bonus points if it recognizes different people talking.\n 🚀 Extra bonus points if it can transcribe multiple languages.\n    submitted by    /u/AleHoju  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ikloc/looking_for_a_meeting_assistant/",
          "publishedOn": "2023-09-14T14:56:34.000Z",
          "wordCount": 2597,
          "title": "Looking for a meeting assistant",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ieydv/i_signed_up_for_a_debate_on_ai/",
          "author": null,
          "description": "So today I signed up for a debate on ai. Wheather ai is beneficial or dangerous to human beings. I have the freedom to choose any side. This debate will be watched by about 130 people, all cs freshmen (mind you, also my first time speaking in front of this many people). Now, I'm confident I know more about ai than an average person but I need your help in preparing properly. Which side do I take and what are all the points I should keep in mind? It's 4 pm here and the debate is tomorrow. Any help will be appreciated. Thank you.\n    submitted by    /u/CalmGuy69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ieydv/i_signed_up_for_a_debate_on_ai/",
          "publishedOn": "2023-09-14T10:36:54.000Z",
          "wordCount": 2642,
          "title": "I signed up for a debate on ai.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16idzsi/artificial_intelligence_may_be_humanitys_most/",
          "author": null,
          "description": "Artificial intelligence (AI) has the potential to solve the world's problems or destroy humanity.\n \nIt is being developed by a few hundred individuals in Silicon Valley, and we have little say in its ethics or existence.\n \nAI has already demonstrated creative abilities in painting, writing, and music.\n \nIt is also being used in drug discovery, therapy, dating apps, and misinformation in politics.\n \nThe rapid adoption of AI raises concerns about job displacement and the potential for catastrophic events.\n \nExperts predict a significant chance of AI causing a catastrophe or even wiping out humanity.\n \n Source : https://www.vanityfair.com/news/2023/09/artificial-intelligence-industry-future\n Summarized by Nuse AI\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16idzsi/artificial_intelligence_may_be_humanitys_most/",
          "publishedOn": "2023-09-14T09:39:20.000Z",
          "wordCount": 2640,
          "title": "Artificial Intelligence May Be Humanity’s Most Ingenious Invention–and Its Last?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16iaxda/generative_ai_consumer_landscape_by_a16z/",
          "author": null,
          "description": "In less than a year since ChatGPT was introduced, it has become the fastest consumer application to register 100 million monthly active users. But how are consumers using other GenAI products apart from ChatGPT? An a16z Consumer report examines the top 50 GenAI web products (based on SimilarWeb data) to find out.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/f0kh5qag16ob1.png?width=2058&format=png&auto=webp&s=1cab11a31d384c068912c9fca32a000393b795d5\n  \nProprietary models are dominating: 80% of the top 50 GenAI products didn’t exist a year ago—suggesting many of the most compelling consumer experiences are completely novel. Interestingly, 48% of these are bootstrapped—with no outside funding.\n ChatGPT holds a massive lead: ChatGPT alone accounts for 60% of the entire list's monthly traffic, with roughly 1.6 billion visits and 200 million monthly users as of June 2023.\n LLM assistants are dominating: LLMs, including Google’s Bard and Quora’s Poe, constitute 68% of total consumer traffic to the top 50. The other categories seeing significant traffic are AI companions and content-generation tools.\n GenAI marketing is mostly organic: Marketing for most of these products has been reliant on referrals, word of mouth, and other traditional marketing as they enter the market. About 90% of these companies are already monetizing, and most do so via a subscription model.\n GenAI and mobile adaptability: Given the extensive consumer time spent on mobile, an increase in mobile-first GenAI products is expected as the technology evolves.\n  \n(source)\n P.S. If you like this type of analysis, sign up for my free newsletter that deciphers the fastest-moving news and research in AI and tech. Professionals from Google, Meta, and OpenAI are already on board.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16iaxda/generative_ai_consumer_landscape_by_a16z/",
          "publishedOn": "2023-09-14T06:36:55.000Z",
          "wordCount": 2803,
          "title": "Generative AI Consumer Landscape by a16z",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ianu2/oneminute_daily_ai_news_9142023/",
          "author": null,
          "description": "Adobe’s Firefly generative AI tools are now widely available.[1]\n Stability AI, gunning for a hit, launches an AI-powered music generator.[2]\n Elon Musk warned of civilizational risks posed by artificial intelligence. Sundar Pichai of Google highlighted the technology’s potential to solve health and energy problems. And Mark Zuckerberg of Meta stressed the importance of open and transparent A.I. systems.[3] \n German military plows millions into AI ‘environment’ for weapons tests that could change combat forever.[4]\n Amazon launches generative AI to help sellers write product descriptions.[5]\n  \nSources:\n [1] https://www.theverge.com/2023/9/13/23871537/adobe-firefly-generative-ai-model-general-availability-launch-date-price\n [2] https://techcrunch.com/2023/09/13/stability-ai-gunning-for-a-hit-launches-an-ai-powered-music-generator/\n [3] https://www.nytimes.com/2023/09/13/technology/silicon-valley-ai-washington-schumer.html\n [4] https://www.foxnews.com/world/german-military-plows-millions-ai-environment-weapons-tests-change-combat\n [5] https://www.aboutamazon.com/news/small-business/amazon-sellers-generative-ai-tool \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ianu2/oneminute_daily_ai_news_9142023/",
          "publishedOn": "2023-09-14T06:21:03.000Z",
          "wordCount": 2629,
          "title": "One-Minute Daily AI News 9/14/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16i4bou/im_very_new_in_this_field_prompt_engineering_and/",
          "author": null,
          "description": "My experience in CS, coding, and programming is very minimal. I understand general concepts but only through the lens of a degree in physics that required I mess around with WolframAlpha sometimes (which I really enjoyed). I've been considering getting a second degree in CS or something related but want to find a clear(ish) path before committing to it. I would love to hear any related thoughts as well!\n ​\n  \nPrompt Engineering seems like a pretty fresh field of study. Is it up and coming as a career path?\n People that specialize in this, what field(s) did you come from and how would you recommend diving into it?\n Considering my experience, would I be able to actually find work, freelancing or employed?\n How on earth do I get started in this world? It seems so insanely big and complicated but I am just fascinated by the idea of using written dialogue to manipulate the output of an LLM!\n From my very high overview of PE and the recent advances in AI, PE as a field of study and interest is going to expand exponentially, is that accurate?\n  \n   submitted by    /u/Top_Room_6714  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16i4bou/im_very_new_in_this_field_prompt_engineering_and/",
          "publishedOn": "2023-09-14T00:53:02.000Z",
          "wordCount": 2736,
          "title": "I'm very new in this field (Prompt Engineering) and have a handful of questions, any advice and thoughts are welcome!!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16i09c7/the_economist_podcasts_babbage_mustafa_suleyman/",
          "author": null,
          "description": "submitted by    /u/siiilverrsurfer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16i09c7/the_economist_podcasts_babbage_mustafa_suleyman/",
          "publishedOn": "2023-09-13T22:00:31.000Z",
          "wordCount": 2556,
          "title": "‎The Economist Podcasts: Babbage: Mustafa Suleyman on how to prepare for the age of AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hzcgb/dystopia_ai_movie/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hzcgb/dystopia_ai_movie/",
          "publishedOn": "2023-09-13T21:25:46.000Z",
          "wordCount": 2531,
          "title": "Dystopia AI Movie",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hw9qv/looking_for_ai_developers_and_researchers/",
          "author": null,
          "description": "Hi,\n I would love to create a small group of people who work together in AI.\n The project would be to create an AI that can infer new novel knowledge from existing datasets, as opposed to be being limited by operating within the training data. Specifically to be used in the quest to learn more about the universe.\n So I am looking for a team of likeminded individuals who want to grow in the field of AI.\n I'd love to setup a discord, subreddit and github profile to showcase our work.\n My introduction question is: How do we get AI's to expand upon current knowledge instead of just serving from the knowledge itself.\n Anyone interested in joining me in this?\n    submitted by    /u/Miserable-Cobbler-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hw9qv/looking_for_ai_developers_and_researchers/",
          "publishedOn": "2023-09-13T19:26:31.000Z",
          "wordCount": 2656,
          "title": "Looking for AI developers and researchers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hte7j/dont_worry_folks_big_tech_pinky_swears_itll_build/",
          "author": null,
          "description": "Eight big names in tech, including Nvidia, Palantir, and Adobe, have agreed to red team their AI applications before they're released and prioritize research that will make their systems more trustworthy.\n \nThe White House has secured voluntary commitments from Adobe, Cohere, IBM, Nvidia, Palantir, Salesforce, Scale AI, and Stability AI to develop machine-learning software and models in a safe, secure, and trustworthy way. The commitments only cover future generative AI models.\n \nEach of the corporations has promised to submit their software to internal and external audits, where independent experts can attack the models to see how they can be misused.\n \nThe organizations agreed to safeguard their intellectual property and make sure things like the weights of their proprietary neural networks don't leak, while giving users a way to easily report vulnerabilities or bugs.\n \nAll eight companies agreed to focus on research to investigate societal and civil risks AI might pose if they lead to discriminatory decision-making or have weaknesses in data privacy.\n \nThe US government wants Big Tech to develop watermarking techniques that can identify AI-generated content.\n \nThe US has asked the corporations to commit to building models for good, such as fighting climate change or improving healthcare.\n \n Source : https://www.theregister.com/2023/09/12/nvidia_adobe_palantir_ai_safety/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hte7j/dont_worry_folks_big_tech_pinky_swears_itll_build/",
          "publishedOn": "2023-09-13T17:37:15.000Z",
          "wordCount": 2743,
          "title": "Don't worry, folks. Big Tech pinky swears it'll build safe, trustworthy AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hshxl/harvard_ilabfunded_project_subfeature_of_the/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hshxl/harvard_ilabfunded_project_subfeature_of_the/",
          "publishedOn": "2023-09-13T17:02:46.000Z",
          "wordCount": 2558,
          "title": "Harvard iLab-funded project: Sub-feature of the platform out -- Enjoy free ChatGPT-3/4, personalized education, and file interaction with no page limit 😮. All at no cost. Your feedback is invaluable!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hs3df/dissatisfied_with_gpt_paid_subscription_who/",
          "author": null,
          "description": "I’ve been using the paid version of GPT for a while but I think it’s time to move on. For $20 a month i would at least like for there to be an option to input an image, but I would also maybe pay a bit more than that per month for a suite of tools or something if it could also do image generation in addition to just text.\n I’m sorry if it seems like I should be able to understand anything better - please note I am disabled, my use of the tools is personal (creative and household) and not professional, and I’m doing my best by asking here. I do not mean to bother anyone with my own ignorance. Thank you.\n    submitted by    /u/CaveLady3000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hs3df/dissatisfied_with_gpt_paid_subscription_who/",
          "publishedOn": "2023-09-13T16:47:55.000Z",
          "wordCount": 2666,
          "title": "Dissatisfied with GPT paid subscription - who should I go with instead?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hrfcm/oneminute_daily_ai_news_9132023/",
          "author": null,
          "description": "Project Gutenberg and Microsoft have created thousands of free audiobooks that use neural text-to-speech technology to generate the voices.[1]\n A group of U.S. authors, including Pulitzer Prize winner Michael Chabon, has sued OpenAI in federal court in San Francisco, accusing the Microsoft-backed program of misusing their writing to train its popular artificial intelligence-powered chatbot ChatGPT.[2]\n Numenta launches brain-based NuPIC to make AI processing up to 100 times more efficient.[3]\n Adept AI Labs released Persimmon-8B. Persimmon-8B is an open-source, fully permissively licensed model in the 8B class. This model holds immense potential for a wide array of applications, aiming to assist users in various computer-related tasks.[4]\n  \nSources:\n [1] https://www.zdnet.com/article/heres-how-to-access-thousands-of-free-audiobooks-thanks-to-microsoft-ai-and-project-gutenberg/\n [2] https://www.reuters.com/technology/more-writers-sue-openai-copyright-infringement-over-ai-training-2023-09-11/\n [3] https://venturebeat.com/ai/numenta-launches-brain-based-nupic-to-make-ai-processing-up-to-100-times-more-efficient/\n [4] https://www.marktechpost.com/2023/09/09/adept-ai-labs-open-sources-persimmon-8b-a-powerful-fully-permissively-licensed-language-model-with/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hrfcm/oneminute_daily_ai_news_9132023/",
          "publishedOn": "2023-09-13T16:21:56.000Z",
          "wordCount": 2649,
          "title": "One-Minute Daily AI News 9/13/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hpu36/is_there_an_ai_image_tool_that_makes_existing/",
          "author": null,
          "description": "I see a ton of AI image tools out there. Some let you upload image files and modulate/modify them in some way. I am wondering if a tool exists that will take a real life product image and make it appear more like a render/computer generated image. \n Essential I would love to be able to take a pic of a product and use automatic smoothing and AI simulated rendering to output a clean image that looks like a 3d render. This would be used as a product image for an e-commerce website.\n    submitted by    /u/ElonMusk0fficial  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hpu36/is_there_an_ai_image_tool_that_makes_existing/",
          "publishedOn": "2023-09-13T15:20:43.000Z",
          "wordCount": 2635,
          "title": "Is there an AI image tool that makes existing images look like renders?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hn3o9/alibaba_cloud_open_sources_its_generative_ai/",
          "author": null,
          "description": "Alibaba Cloud has open sourced two of its generative AI models, Qwen-7B and Qwen-7B-Chat, for commercial and research use.\n \nThe models' codes and documentation will be accessible through Alibaba Cloud's AI model repository ModelScope and the US collaborative AI platform Hugging Face.\n \nCompanies with fewer than 100 million monthly active users can use the models for commercial purposes free of charge, while those with more users will need to request a license.\n \nAlibaba aims to democratize AI technology and support LLM start-ups.\n \nAlibaba Cloud's ModelScope platform currently features over 1,000 ready-to-use AI models contributed by 20 leading AI institutions.\n \n Source : https://www.scmp.com/tech/big-tech/article/3229907/alibaba-cloud-open-sources-its-two-generative-ai-models-based-chatgpt-style-tongyi-qianwen\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hn3o9/alibaba_cloud_open_sources_its_generative_ai/",
          "publishedOn": "2023-09-13T13:30:33.000Z",
          "wordCount": 2642,
          "title": "Alibaba Cloud open sources its generative AI models Tongyi Qianwen",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hmxxq/is_there_an_ai_tool_for_generating_videos_using/",
          "author": null,
          "description": "I have a text script that I want to turn into a video. For the sake of context, the video is on balancing a person’s daily activities. I’m getting tired trying to find matching stock footages for the videos. I was wondering if there is a way to do this using AI tools? Synthesia won’t do because it looks like a video narration, more than a video essay. Any suggestions would help. Thanks in advanced!\n    submitted by    /u/Entaro2109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hmxxq/is_there_an_ai_tool_for_generating_videos_using/",
          "publishedOn": "2023-09-13T13:23:58.000Z",
          "wordCount": 2616,
          "title": "Is there an AI tool for generating videos using stock footages?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hmqgn/google_codey_humaneval_benchmark/",
          "author": null,
          "description": "Hi everyone,\n I'm hunting for a HumanEval Benchmark for Google's Codey model and am having a tough time hunting it down. Can anyone point me to an Arxiv paper or a coding leaderboard that includes Codey?\n Thanks!\n    submitted by    /u/Iamreason  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hmqgn/google_codey_humaneval_benchmark/",
          "publishedOn": "2023-09-13T13:14:54.000Z",
          "wordCount": 2571,
          "title": "Google Codey HumanEval Benchmark",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hidk9/many_executivesinvestors_are_pushing_for_the_use/",
          "author": null,
          "description": "But product & tech teams succumb to the pressure and move on to developing proof of concepts & even launch products that fail to achieve ROI \n Why?\n 1- use cases are not well defined\n 2- not enough data or right data strategy\n 3- data and model architecture not founded well \n I love Apple’s approach to AI, they shy away from the hype and focus on the fundamentals. \n First the customer, product, then the tech that will add the value the customer needs. \n What do you think are the top reasons generative AI applications succeed? \n View Poll\n    submitted by    /u/AILaunchpad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hidk9/many_executivesinvestors_are_pushing_for_the_use/",
          "publishedOn": "2023-09-13T09:26:25.000Z",
          "wordCount": 2650,
          "title": "Many executives/investors are pushing for the use of generative AI in products/applications…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hhz0h/create_a_custom_search_engine/",
          "author": null,
          "description": "I have an open book exam that has a lot of information that I will need to physically search through.\n Is there a way i can load all he PDFS and create a customised chatgbt style search, so i can easily look through all the information and research i have?\n    submitted by    /u/yellowmushroom22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hhz0h/create_a_custom_search_engine/",
          "publishedOn": "2023-09-13T09:02:06.000Z",
          "wordCount": 2585,
          "title": "Create a custom search engine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hf381/heygens_oneclick_translation_from_english_to/",
          "author": null,
          "description": "submitted by    /u/Fadawah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hf381/heygens_oneclick_translation_from_english_to/",
          "publishedOn": "2023-09-13T06:06:16.000Z",
          "wordCount": 2548,
          "title": "HeyGen's one-click translation from English to Italian, Hindi, German and Spanish is the craziest AI application I've seen in months.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hezjn/i_wanna_develop_small_scale_personal_ai_apps_for/",
          "author": null,
          "description": "I wanna develop small scale personal AI apps for each my friends and AI said i should learn Python, TensorFlow Lite, SQLite, GCP, Pandas, Scikit Learn and Keras. How right is this?\n    submitted by    /u/Leading-Ad2278  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hezjn/i_wanna_develop_small_scale_personal_ai_apps_for/",
          "publishedOn": "2023-09-13T06:00:34.000Z",
          "wordCount": 2595,
          "title": "I wanna develop small scale personal AI apps for each my friends and AI said i should learn about Python, TensorFlow Lite, SQLite, GCP, Pandas, Scikit Learn and Keras. How right is this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hev64/ai_image_generators_have_a_moderation_problem/",
          "author": null,
          "description": "Tests carried out by Logically confirm these platforms accept 85% of prompts tailored for election manipulation.\n    submitted by    /u/Asleep-Television-24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hev64/ai_image_generators_have_a_moderation_problem/",
          "publishedOn": "2023-09-13T05:53:10.000Z",
          "wordCount": 2555,
          "title": "AI image generators have a moderation problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hd8jo/ai_chatbots_successfully_build_software_in_under/",
          "author": null,
          "description": "AI Chatbots, such as OpenAI's ChatGPT, can create incredibly cost-friendly software in record time, reveals a new study.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/rxpr6db3aynb1.png?width=1300&format=png&auto=webp&s=721ff5d8f9d25b5e48fa26e2b335c1d20620a83a\n The AI Tech Company Experiment\n  \nBrown University and several Chinese University researchers put ChatGPT-powered AI bots to the test by making them run a hypothetical software development company, ChatDev.\n The AI chatbots were given specific roles and allocated respective stages based on the traditional waterfall model encompassing designing, coding, testing, and documenting.\n AI 'employees' functioned with minimal human input to complete their parts of the software development process.\n  \nImpressive Results\n  \nAssigning 70 tasks to ChatDev led to the completion of the entire software development process in under seven minutes at a cost of less than one dollar on average.\n A stunning 86.66% of the generated software systems performed flawlessly.\n Despite some language model errors and biases, the study demonstrates AI's immense potential in automating tasks - a boon, especially to junior programmers around the world.\n  \nBroader Implications\n  \nPowerfully generative AI technologies like ChatGPT can perform specific job functions, saving time, and boosting productivity in several industries.\n While coders find such tools beneficial, it's also critical to note that limitations and biases do exist in AI models which could potentially affect the software creation process.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most vital news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hd8jo/ai_chatbots_successfully_build_software_in_under/",
          "publishedOn": "2023-09-13T04:25:26.000Z",
          "wordCount": 2792,
          "title": "AI Chatbots successfully build software in under 7 minutes for less than $1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hcknz/how_business_thinkers_can_start_building_ai/",
          "author": null,
          "description": "submitted by    /u/mycall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hcknz/how_business_thinkers_can_start_building_ai/",
          "publishedOn": "2023-09-13T03:51:04.000Z",
          "wordCount": 2552,
          "title": "How Business Thinkers Can Start Building AI Plugins With Semantic Kernel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hbxjs/eu_leads_the_way_in_regulating_ai/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hbxjs/eu_leads_the_way_in_regulating_ai/",
          "publishedOn": "2023-09-13T03:19:59.000Z",
          "wordCount": 2548,
          "title": "EU leads the way in regulating AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16h9or2/webinar_with_dr_richard_marks/",
          "author": null,
          "description": ">Sailea is a student run non-profit that does not charge for any of its services \n 🌟 Join SAILea’s Free Webinar with Dr. Richard Marks! 🌟\n 🗓️ Date: September 23rd, 2023 ⏰ Time: 3:00-4:00PM EST\n Don't miss an exclusive opportunity to learn from an AI expert! Join us for a free webinar featuring Dr. Richard Marks, a renowned CS and Data Science professor at UNC-Chapel Hill University with a remarkable journey – from Google to PlayStation, and the mind behind EyeToy and PlayStation Move.\n 🚀 What to Expect:\n 🔹 Deep insights into tech innovation.\n 🔹 Career advice. \n 🔹 Live Q&A with Dr. Richard Marks.\n Reserve your spot now: sailea.org/events\n 🔥 Don’t miss this opportunity! Register today!🔥\n    submitted by    /u/Envoy-Insc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16h9or2/webinar_with_dr_richard_marks/",
          "publishedOn": "2023-09-13T01:35:44.000Z",
          "wordCount": 2650,
          "title": "Webinar with Dr. Richard Marks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16h53b7/i_want_to_try_out_stabilityais_chat_after_logging/",
          "author": null,
          "description": "submitted by    /u/w__sky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16h53b7/i_want_to_try_out_stabilityais_chat_after_logging/",
          "publishedOn": "2023-09-12T22:21:23.000Z",
          "wordCount": 2566,
          "title": "I want to try out Stability.AI's chat. After logging in with a Google account, a spinning wheel is all I get. Is it like that for everyone?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16h2e0s/i_made_a_data_request_feature_so_you_dont_have_to/",
          "author": null,
          "description": "So, I've been working on an AI data marketplace platform for a few months now. Users can buy, sell, request, and subscribe to data/datasets (and soon even train their ML/AI models using other users' datasets). One of our key features is the request feature, which allows users to submit data requests for free. These requests include descriptions, required fields, geographical scope, budget etc... Once a request is posted, it's sent to numerous companies, organizations, and data vendors that have the potential to fulfill it.\n I understand how frustrating the data acquisition process can be, so I designed this platform to be your one-stop shop for all data-related transactions. You no longer have to spend weeks or months dealing with different vendors and companies through slow emails. With our platform, you can request, negotiate, and purchase data all in one place, and it's completely free to post a request, by the way.\n We've already achieved some successes, and we hope to help more people access the datasets they need. After all, the best AI models are built on diverse and differentiating data. We've had some notable achievements, and we're eager to see if we can fulfill even more interesting dataset requests!\n    submitted by    /u/nobilis_rex_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16h2e0s/i_made_a_data_request_feature_so_you_dont_have_to/",
          "publishedOn": "2023-09-12T20:39:23.000Z",
          "wordCount": 2745,
          "title": "I made a data request feature so you don't have to exhaustively collect data/dataset(s) yourself!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gxmdj/you_wont_believe_how_much_teslas_dojo/",
          "author": null,
          "description": "Morgan Stanley Research has valued Tesla's soon-to-be-released Dojo supercomputer at up to $500 billion, potentially increasing the auto giant's valuation significantly. The financial institution believes Dojo’s applications will go beyond Tesla's Full-Self Driving (FSD) capabilities.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/yhia3c5f1vnb1.jpg?width=1440&format=pjpg&auto=webp&s=7adf40e7b868a4fbf6eb3d696132652f4f549f23\n Morgan Stanley's Bullish Prediction on Dojo\n  \nMorgan Stanley has suggested that Dojo might not just enhance Tesla's FSD technology, but could find use in other devices that make real-time decisions based on a visual field.\n Apart from raising Tesla’s valuation, this could potentially open up new markets for the company.\n Following this, Morgan Stanley has increased its target price for Tesla shares from $250 to $400 each.\n  \nDojo Supercomputer Overview\n  \nTesla has developed Dojo in-house, diverging from conventional AI accelerators and involving its own computing, networking, IO, and instruction set.\n At the heart of Dojo is the D1 AI accelerator processor, containing 354 custom CPU cores. Twenty-five D1 chips are combined to create a Dojo training tile, which could expedite Tesla’s move towards earning revenue from vehicle software.\n  \nFuture Plans and Implications\n  \nTesla could potentially become an AI-as-a-service provider to automakers in need of FSD capabilities with Dojo.\n As the development of Dojo continues, Tesla has invested in alternative AI infrastructures, including a cluster of 10,000 of Nvidia's most potent H100 accelerators.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that explores the latest AI developments. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gxmdj/you_wont_believe_how_much_teslas_dojo/",
          "publishedOn": "2023-09-12T17:35:22.000Z",
          "wordCount": 2790,
          "title": "You Won’t Believe How Much Tesla’s Dojo Supercomputer Is Worth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gx1l6/schwoz_sings_ballin/",
          "author": null,
          "description": "submitted by    /u/LaminateShark7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gx1l6/schwoz_sings_ballin/",
          "publishedOn": "2023-09-12T17:13:06.000Z",
          "wordCount": 2531,
          "title": "Schwoz Sings Ballin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gqnwd/today_we_test_which_ai_is_smartest_tomorrow_ai/",
          "author": null,
          "description": "Somewhere in the world there's a person who is the smartest. Why stop there? There are ten people who are the smartest. And if they are on the Internet, AI will find them.\n Perhaps not yet. It probably needs to get smarter. Maybe by Gemini. Or GPT-5. But eventually an AI will analyze all of the content on the Internet, and determine from that data who are the ten most intelligent people on the planet, (whose material is online).\n Of course if AI can determine the top ten, it can certainly determine the top 100, and the top 1,000, and even the top 100,000. I suppose when that happens there will be a lot more human brain power available to solve our problems. Although by then AI will be solving them far better than we could, haha. \n But think about it for a minute. There are very smart people out there who don't publish in traditional mass media channels. The geniuses among us who don't fit in so well, and are therefore resigned to the margins, remaining unrecognized. \n Wouldn't it be great if AI discovered them, and gave them the validation they deserve? Wouldn't it be great to find out who they are so that they can better work on whatever.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gqnwd/today_we_test_which_ai_is_smartest_tomorrow_ai/",
          "publishedOn": "2023-09-12T12:55:54.000Z",
          "wordCount": 2755,
          "title": "Today we test which AI is smartest. Tomorrow AI tests which human is smartest.",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/175npm5/neural_networks_from_scratch_in_rust/",
          "author": null,
          "description": "submitted by    /u/zezeartix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/175npm5/neural_networks_from_scratch_in_rust/",
          "publishedOn": "2023-10-11T20:15:39.000Z",
          "wordCount": 2523,
          "title": "Neural Networks From Scratch in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/175kfcg/activation_function_for_generating_shapley_values/",
          "author": null,
          "description": "Hi, I want to train a neural network to calculate Shapley values based on a given characteristic function.\n Depending on a given characteristic function, calculated through a dedicated algorithm, Shapley values can be any number, positive or negative, without a set range.\n Because of this, I am unsure, for the specific application of calculating Shapley values, what activation function to use in a neural network that would calculate them. The relu function, as well as leaky relu function, either cannot give values that are negative or have trouble giving large negative values, and sigmoid or tanh can only give values in a certain range.\n I am aware that there are other commonly used activation functions, but all the ones I could find had one of these issues, which would make training a network to calculate Shapley values difficult.\n Any advice?\n    submitted by    /u/PowNotBigSurprise  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/175kfcg/activation_function_for_generating_shapley_values/",
          "publishedOn": "2023-10-11T17:56:48.000Z",
          "wordCount": 2665,
          "title": "Activation function for generating Shapley values",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/17583qj/a_hugging_face_implementation_for_style_gan_to/",
          "author": null,
          "description": "I was thinking to create an app based on style gan which will include facebook , instagram theme and style transfer it with profile pic so shall i create this app or not .I want to know if it will be good idea. \n    submitted by    /u/No_Claim_8651  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/17583qj/a_hugging_face_implementation_for_style_gan_to/",
          "publishedOn": "2023-10-11T07:16:48.000Z",
          "wordCount": 2567,
          "title": "A hugging face implementation for style gan to produce user avatar",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/174njqk/riddle_me_this_issues_when_predicting_a_high/",
          "author": null,
          "description": "Hi folks, \n I have observed a strange behavior when implementing a VERY BASIC idea 🙂\n I want to use a fully-connected Neural Network to approximate a sine wave. For that I am sampling 200.000 uniformly distributed points from a wide interval, e.g. [-60,60] and compute the corresponding sin(x) values resulting in the following training data. \n ​\n Training data\n I glimpse into my setup: \n Model:\n nn.Linear(1, 16) nn.Sigmoid() Linear(16, 16) nn.Sigmoid() nn.Linear(16, 8) nn.Sigmoid() nn.Linear(8, 4) nn.Sigmoid() nn.Linear(4, 1) (I also pumped up the network to up to 100 hidden neurons on one layer) \n Number of samples: 200.000 (80% train / 20% test)\n Optimizer: Adam\n Loss: RMSE\n Epochs between 100 - 500\n Learning Rate: 0.02\n Batch Size: 500 - 1000\n ​\n Check out the screenshots below to see the results 😨\n ​\n The predictions are pretty good but the edge areas slow down to a very small value, without any change. This only holds for high-frequency sine waves. If we only consider the train range of [-2*np.pi , 2*np.pi] it works pretty good with small loss.\n ​\n So my questions are: \n 1) Why do we see that behaviour? \n 2) How can we solve it\n ​\n Cheers\n ​\n Prediction 1\n ​\n Prediction 2\n    submitted by    /u/CarKla  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/174njqk/riddle_me_this_issues_when_predicting_a_high/",
          "publishedOn": "2023-10-10T15:08:29.000Z",
          "wordCount": null,
          "title": "Riddle me this: Issues when predicting a high frequency sine wave",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/173asmx/pt_3_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/173asmx/pt_3_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-10-08T21:41:32.000Z",
          "wordCount": null,
          "title": "(Pt. 3) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/172yyuh/researchers_create_a_neural_network_for_genomics/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/172yyuh/researchers_create_a_neural_network_for_genomics/",
          "publishedOn": "2023-10-08T13:19:28.000Z",
          "wordCount": null,
          "title": "Researchers create a neural network for genomics that explains how it achieves accurate predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/172nugs/decomposing_language_models_into_understandable/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/172nugs/decomposing_language_models_into_understandable/",
          "publishedOn": "2023-10-08T02:27:10.000Z",
          "wordCount": null,
          "title": "Decomposing Language Models Into Understandable Components",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/171etya/sequential_dense_neural_network_for_binary/",
          "author": null,
          "description": "Hello.\n I've developed a simple Neural Recommender System (NRR) with the following architecture:\n  \nInput layer: 38 neurons\n Hidden layer: 19 neurons with ReLU activation function\n Output layer: 1 neuron with a sigmoid activation function\n  \nThe input dataset consists of 39 columns: 38 features and 1 label (with values of 0 or 1). The model is designed to output the probability that a specific input should be classified with label 1.\n Currently, I am experimenting with hyperparameter tuning, adjusting the learning rate, epoch, and batch size. However, I've observed an issue where, with certain combinations of hyperparameters, the maximum probability outputted by the model is not 1, but rather 0.25, for example. How is this possible?\n Thanks\n    submitted by    /u/nllnp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/171etya/sequential_dense_neural_network_for_binary/",
          "publishedOn": "2023-10-06T15:10:25.000Z",
          "wordCount": null,
          "title": "Sequential Dense Neural Network for binary classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/170mb03/openais_justification_for_why_training_data_is/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/170mb03/openais_justification_for_why_training_data_is/",
          "publishedOn": "2023-10-05T16:26:43.000Z",
          "wordCount": null,
          "title": "OpenAI's justification for why training data is fair use, not infringement [pdf]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/170lah7/traveling_words_a_geometric_interpretation_of/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/170lah7/traveling_words_a_geometric_interpretation_of/",
          "publishedOn": "2023-10-05T15:45:19.000Z",
          "wordCount": null,
          "title": "Traveling Words: A Geometric Interpretation of Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1700z98/ring_attention_with_blockwise_transformers_for/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1700z98/ring_attention_with_blockwise_transformers_for/",
          "publishedOn": "2023-10-04T22:37:17.000Z",
          "wordCount": null,
          "title": "Ring Attention with Blockwise Transformers for Near-Infinite Context",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16zujr2/think_before_you_speak_training_language_models/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16zujr2/think_before_you_speak_training_language_models/",
          "publishedOn": "2023-10-04T18:20:48.000Z",
          "wordCount": null,
          "title": "Think before you speak: Training Language Models With Pause Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16zflgl/towards_selfassembling_artificial_neural_networks/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16zflgl/towards_selfassembling_artificial_neural_networks/",
          "publishedOn": "2023-10-04T06:17:09.000Z",
          "wordCount": null,
          "title": "Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16zbvc3/ai_has_been_reading_my_mind/",
          "author": null,
          "description": "I know several people that tell me whenever they say something out loud, they start seeing it advertised to them or on their feed. But for me, if I think of certain things, even if I never said it out loud, it will appear on my feed.. has anything similar been happening to anyone else?\n    submitted by    /u/GuaranteedBigBoy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16zbvc3/ai_has_been_reading_my_mind/",
          "publishedOn": "2023-10-04T02:57:24.000Z",
          "wordCount": null,
          "title": "AI has been reading my mind.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16xxa2r/fishing_with_neural_nets_transforming_ecology/",
          "author": null,
          "description": "submitted by    /u/plutoandmal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16xxa2r/fishing_with_neural_nets_transforming_ecology/",
          "publishedOn": "2023-10-02T13:55:09.000Z",
          "wordCount": 2521,
          "title": "Fishing with Neural Nets | Transforming Ecology with Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16x87mg/langdiversity_software_to_identify_llm_errors/",
          "author": null,
          "description": "Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge. LangDiversity is an implementation of \"diversity measures\" that are domain independent and can be used to measure the uncertainty in the result of a language model.\n ​\n Type pip install langdiversity\n Video: https://www.youtube.com/watch?v=86J_K9mR7lw\n Web: https://neurosymbolic.asu.edu/llm-correction/\n Visit https://github.com/lab-v2/langdiversity\n Read the paper: https://arxiv.org/abs/2308.11189\n https://preview.redd.it/o0v8p9g7tmrb1.png?width=1021&format=png&auto=webp&s=ff1ac672b61f96e4669663410769127066a0674d\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16x87mg/langdiversity_software_to_identify_llm_errors/",
          "publishedOn": "2023-10-01T18:09:41.000Z",
          "wordCount": 2639,
          "title": "LangDiversity: software to identify LLM errors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16ws7ft/equation_for_what_neurons_of_1s_that_attach/",
          "author": null,
          "description": "\" Bio education below *. Summarization: ~1000 IO neurons attach math regions to conscious regions, low cost 1000-electrod microprocessors can run on radio.\n * https://youtube.com/watch?v=bhp2CkNDxME Don't want for self; want for professors and humans who program KUKA's/FANUC's for construction, and for who do calculations/optimizations for CUDA, MS Visual Studio and such, but what go up for experimentation should funds allow.\" sounds fun \n    submitted by    /u/2002LuvAbbaLuvU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16ws7ft/equation_for_what_neurons_of_1s_that_attach/",
          "publishedOn": "2023-10-01T05:03:19.000Z",
          "wordCount": 2658,
          "title": "Equation for what neurons (of 1s that attach parietal region to conscious brain regions) should attach to microprocessor to offload math functions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vj0jh/innovative_endeavors_meta_introduces_aipowered/",
          "author": null,
          "description": "submitted by    /u/Allinhalf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vj0jh/innovative_endeavors_meta_introduces_aipowered/",
          "publishedOn": "2023-09-29T18:16:56.000Z",
          "wordCount": 2594,
          "title": "Innovative Endeavors: Meta Introduces AI-Powered Tools and Smart Glasses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vcimm/pruning_a_specific_dimension_in_a_neural_network/",
          "author": null,
          "description": "I've been playing around with pruning neural networks. One interesting thing I've found is that pruning the weights with the lowest L1-norm along a specific dimension seems to give better results than simply pruning all of the weights with the lowest L1-norm (which I believe is the standard method; for example this is what torch.nn.utils.prune.l1_unstructured does).\n Does anyone have an explanation for why this might be, or knows of any research in this area?\n I'm aware that structured pruning removes entire channels in a specific dimension. But I'm referring to unstructured pruning here, where I remove a subset of the weights along a specific dimension.\n Admittedly I've only done very limited benchmarking of this. See this repo for my implementation, and some benchmark details.\n    submitted by    /u/Neilf79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vcimm/pruning_a_specific_dimension_in_a_neural_network/",
          "publishedOn": "2023-09-29T14:04:23.000Z",
          "wordCount": 2708,
          "title": "Pruning a specific dimension in a neural network using L1-norm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vbmuv/help_understanding_ai_specificaly_cnn_cause_i/",
          "author": null,
          "description": "Hello,\n so i learnt the very basics of ai and im trying to understand how nn works,\n this is what i have figured out so far. \n so if i have a 4x4 image e.g\n 0 1 1 0\n 1 0 0 1\n 1 1 1 1\n 1 0 0 1\n i pass it across a 2x2 kernal e.g\n 1 1\n 0 3\n ​\n and padding it would do \n ​\n dot product of \n 0 1\n 1 0\n ​\n x\n ​\n 1 1\n 0 3\n ​\n is 1\n ​\n ​\n and if we do that to all of them we get a new matrix\n ​\n 1 2 4\n 4 1 3\n 5 4 4\n ​\n ​\n then we have padding same so this becomes\n ​\n 0 0 0 0\n 1 2 4 0\n 4 1 3 0\n 5 4 4 0\n ​\n ​\n we then turn it into a feature map, basically flatenting it to something like this\n 0,0,0,0,1,2,4,0,4,1,3,0,5,4,4,0\n ​\n so the input has 16 features, if we have a layer of 3 nerons that fire with relu activation funciton\n and each weight is alternating between 1 and 2 for simplicity sake . we would do\n 0*1 + 0*2 + 0*1 .... 4*2 + 0*1 = 32\n so if we are using relu, we would do \n is 32 > 0? if so we pass 32 to next neuron if not we pass 0?\n ​\n idk the rest, i guess i forgot what uni taught me 😅 \n ​\n hers a diagram i drew, maybe you can help me figure out hte rest, im confused how the output layer works i guess\n ​\n ​\n ​\n ​\n    submitted by    /u/SaadPaad2003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vbmuv/help_understanding_ai_specificaly_cnn_cause_i/",
          "publishedOn": "2023-09-29T13:26:10.000Z",
          "wordCount": 2847,
          "title": "Help understanding ai, Specificaly cnn cause i want to try training a model on mnist data set as my first project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vbkes/help_understanding_basics_of_neural_networks_cnns/",
          "author": null,
          "description": "Hello,\n so i learnt the very basics of ai and im trying to understand how nn works,\n this is what i have figured out so far. \n so if i have a 4x4 image e.g\n 0 1 1 0\n 1 0 0 1\n 1 1 1 1\n 1 0 0 1\n i pass it across a 2x2 kernal e.g\n 1 1\n 0 3\n ​\n and padding it would do \n ​\n dot product of \n 0 1\n 1 0\n ​\n x\n ​\n 1 1\n 0 3\n ​\n is 1\n ​\n ​\n and if we do that to all of them we get a new matrix\n ​\n 1 2 4\n 4 1 3\n 5 4 4\n ​\n ​\n then we have padding same so this becomes\n ​\n 0 0 0 0\n 1 2 4 0\n 4 1 3 0\n 5 4 4 0\n ​\n ​\n we then turn it into a feature map, basically flatenting it to something like this\n 0,0,0,0,1,2,4,0,4,1,3,0,5,4,4,0\n ​\n so the input has 16 features, if we have a layer of 3 nerons that fire with relu activation funciton\n and each weight is alternating between 1 and 2 for simplicity sake . we would do\n 0*1 + 0*2 + 0*1 .... 4*2 + 0*1 = 32\n so if we are using relu, we would do \n is 32 > 0? if so we pass 32 to next neuron if not we pass 0?\n ​\n idk the rest, i guess i forgot what uni taught me 😅 \n ​\n hers a diagram i drew, maybe you can help me figure out hte rest, im confused how the output layer works i guess\n ​\n ​\n https://preview.redd.it/h07o5y6847rb1.png?width=1859&format=png&auto=webp&s=df1cdf73ea64ff93ac872dfe8248722e8befd31d\n ​\n ​\n    submitted by    /u/WranglerParty5452  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vbkes/help_understanding_basics_of_neural_networks_cnns/",
          "publishedOn": "2023-09-29T13:23:16.000Z",
          "wordCount": 2836,
          "title": "help understanding basics of neural networks, cnn's to be exact",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16vabmu/adapt_gan/",
          "author": null,
          "description": "Hi everyone,\n Im new to the Neural network and I wanted some advice :\n I wanted to generate grayscale images with certain properties : - distribution of pixels values, space correlation between pixels, etc...\n I already know the type of result that I need, but I wanted to know if a neural network especially a GAN was capable to produce images fitting me requirements.\n I was thinking that maybe I could change the GAN architecture such as :\n 1)the Real data inputs (normally images feed to discriminator) will simply be the statistical parameters that I am expecting.\n 2) I'll add a measure of the various statistical parameters on all the synthetic images generated. \n 3)Finally the discriminator will only based itself on the statistical parameters comparison for weights updates.\n Does such network make sense ? If so I have trouble finding a way of implementing it but that is an other story. Right know I want to know if this is doable ? If not do you have any alternative suggestion for my issue ?\n Thanks all for your advice !\n    submitted by    /u/Hectorite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16vabmu/adapt_gan/",
          "publishedOn": "2023-09-29T12:28:46.000Z",
          "wordCount": 2756,
          "title": "Adapt GAN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16v3qvz/why_batch_norm_works/",
          "author": null,
          "description": "submitted by    /u/Personal-Trainer-541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16v3qvz/why_batch_norm_works/",
          "publishedOn": "2023-09-29T06:11:03.000Z",
          "wordCount": 2576,
          "title": "Why Batch Norm Works",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16tzp4b/how_can_ai_recreate_the_lack_of_information/",
          "author": null,
          "description": "Hey there! Are there guys here who possess a strong grasp of AI neural network logic?\n ​\n I've extracted a character from an anime scene using a mask, and saved it as a PNG sequence which contains solely the anime character along with an alpha (transparent) background.\n ​\n I'm curious about how the Flowframes neural network can recreate the background that was originally behind the character but removed by the mask. It's impossible since the PNG images don't have that background info. \n ​\n Can anyone explain how this works?\n ​\n Attachments: \n - Image #1: \n https://preview.redd.it/z2bypfkstvqb1.png?width=1920&format=png&auto=webp&s=c534167c5ae4129c04f9b8b2fbca3bac350a1d4a\n - Image #2: \n https://preview.redd.it/x5kkzs2ttvqb1.png?width=1920&format=png&auto=webp&s=6838d7ca5e1e4f19ba46c04750fdaea537a787f0\n (Don't mind the black background in the thumbnails, it's a bug, there's actually a transparent background)\n ​\n * Flowframes is a app that utilizes advanced AI frameworks to interpolate videos in order to increase their framerate in the most natural looking way possible.\n    submitted by    /u/drkysqrl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16tzp4b/how_can_ai_recreate_the_lack_of_information/",
          "publishedOn": "2023-09-27T23:25:05.000Z",
          "wordCount": 2713,
          "title": "How can AI recreate the lack of information?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16ta2wx/pt_2_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16ta2wx/pt_2_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-09-27T03:56:32.000Z",
          "wordCount": 2575,
          "title": "(Pt. 2) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16rzi6k/what_are_your_goto_resources_for_the_latest_on/",
          "author": null,
          "description": "Hello! I am a software engineer (4 yoe) working in full stack web and app development.\n I was a neuroscience researcher until I switched to software dev and now I am transitioning back into the intersection of neuro and software. \n I am looking for reputable, vetted, and comprehensive lectures, talks, resources on LLMs and the like. I am having trouble sifting through the surface level pop sci type resources floating around on the internet. \n I’m NOT looking for the 10min everything you need to know about AI type talks. \n Thanks in advance!\n    submitted by    /u/yosoylatte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16rzi6k/what_are_your_goto_resources_for_the_latest_on/",
          "publishedOn": "2023-09-25T18:14:38.000Z",
          "wordCount": 2646,
          "title": "What are your go-to resources for the latest on neural networks and the world of neuroscience, AI, LLMs, and ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16qxeud/pt_1_inductive_logic_programming_with_lnns/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16qxeud/pt_1_inductive_logic_programming_with_lnns/",
          "publishedOn": "2023-09-24T13:10:33.000Z",
          "wordCount": 2499,
          "title": "(Pt. 1) Inductive Logic Programming with LNN's",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16pwgra/help/",
          "author": null,
          "description": "DON'T KNOW IF THIS POST BELONGS HERE BUT...\n I have zero knowledge about the AI/ML. And the thing is my college is asking us to do projects on Deep learning.\n They specifically asked us to pick a base paper from ACM Journals or IEEE Transactions which has been published after 2020. And implement these papers and do some novelty work.\n And I have zero clue how to proceed.\n    submitted by    /u/um2_doma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16pwgra/help/",
          "publishedOn": "2023-09-23T05:54:30.000Z",
          "wordCount": 2563,
          "title": "Help!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16p425e/why_open_source_ai_will_win/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16p425e/why_open_source_ai_will_win/",
          "publishedOn": "2023-09-22T07:41:05.000Z",
          "wordCount": 2511,
          "title": "Why Open Source AI Will Win",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16p2p8f/distilling_stepbystep_outperforming_larger/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16p2p8f/distilling_stepbystep_outperforming_larger/",
          "publishedOn": "2023-09-22T06:12:57.000Z",
          "wordCount": 2519,
          "title": "Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16ovmtp/help_answering_questions_about_neural_networks/",
          "author": null,
          "description": "My father, a retired Computer Science professor and pioneer in network design algorithms, has asked me to post two questions he has as he attempts to teach himself about neural networks. For physical/medical reasons he can’t post them himself. Grateful for any answers or suggestions for where he could find them!\n His note:\n I have many questions, but they all revolve around two issues.\n The first is when the weights in the neural net converge, do they exhibit any recognizable pattern. I realize that when the number of nodes and levels in the net are large it may be impossible to recognize the pattern. But suppose that the problem being examined is a simple categorization and the number of nodes in the net is small, is it possible to see a pattern in the weights? The network is supposed to …",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16ovmtp/help_answering_questions_about_neural_networks/",
          "publishedOn": "2023-09-22T00:01:27.000Z",
          "wordCount": 2880,
          "title": "Help answering questions about neural networks for my father(retired Computer Science and EE professor) who (for medical reasons) cannot post them himself.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16nomoo/webinar_how_to_choose_an_ai_vendor_for_your/",
          "author": null,
          "description": "​\n https://preview.redd.it/ta61cz8qlfpb1.jpg?width=1280&format=pjpg&auto=webp&s=ac45085668c9003e5557a7f0c81ae72db6098653\n I hope this webinar finds you well. I suppose that this topic can be interesting for business and AI engineers.\n Speakers: OpenCV CEO Dr. Satya Mallick and Phil Nelson are joined by Anna Kogan CEO at OpenCV.ai\n Topics of webinar are:\n  \nHow to search for vendors that understand your business needs (not all AI is the same.)\n What questions to ask when picking a vendor (not everybody really is an AI expert they claim)\n Three signs to watch for during the project (progress indicators and red-flags)\n How best to scope technical tasks (off-the-shelf vs. custom algorithm development)\n How to set up for long-term success (deployment, documentation, training pipeline)\n  \nDate: Thursday, September 21st, 2023 at 9am Pacific time.\n Link for the registration\n    submitted by    /u/No-Independence5880  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16nomoo/webinar_how_to_choose_an_ai_vendor_for_your/",
          "publishedOn": "2023-09-20T15:47:10.000Z",
          "wordCount": 2642,
          "title": "Webinar | How To Choose An AI Vendor For Your Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16noln6/dirty_secrets_of_bookcorpus_a_key_dataset_in/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16noln6/dirty_secrets_of_bookcorpus_a_key_dataset_in/",
          "publishedOn": "2023-09-20T15:46:01.000Z",
          "wordCount": 2533,
          "title": "Dirty Secrets of BookCorpus, a Key Dataset in Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16nn1w9/neurons_in_large_language_models_dead_ngram/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16nn1w9/neurons_in_large_language_models_dead_ngram/",
          "publishedOn": "2023-09-20T14:42:50.000Z",
          "wordCount": 2531,
          "title": "Neurons in Large Language Models: Dead, N-gram, Positional",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16njq9h/qtransformer_scalable_offline_reinforcement/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16njq9h/qtransformer_scalable_offline_reinforcement/",
          "publishedOn": "2023-09-20T12:13:04.000Z",
          "wordCount": 2531,
          "title": "Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16nix5t/zoomposium_with_professor_dr_petra_ritter_the/",
          "author": null,
          "description": "Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\"\n In another installment in our \"Zoomposium Series\" on the topic of \"Brain Research\", my colleague Axel Stöcker of the \"Blog der großen Fragen\" and I had the great honor and pleasure of conducting an interview with the very well-known and renowned German medical doctor and neuroscientist Professor Dr. Petra Ritter.\n In this context, Ms. Ritter became a co-founder and leader of the co-design project \"The #Virtual #Brain\", which is a component of the European Open Science Cloud (EOSC) and is \"a neuroinformatics platform for simulating whole brain networks using biologically realistic connectivity\".\n She is leading the development of a virtual research environment as a collaborative research platform for sensitive health data and head of the \"German National Neuroscience Research Infrastructure Initiative (NFDI-Neuroscince)\" and involved in the development of the \"Health Data Cloud #EBRAINS\".\n Petra Ritter has been Johanna Quandt Professor and Head of the Section for Brain Simulation at the Department of Neurology with Experimental Neurology at Charité - Universitätsmedizin Berlin since 2017.\n There, Professor Ritter and her team are involved in the \"Simulation of Brains\".\n More at: https://philosophies.de/index.php/2023/09/17/die-simulation-von-gehirnen/\n ​\n https://preview.redd.it/xiurryebcepb1.jpg?width=1000&format=pjpg&auto=webp&s=a7a8b6ba563cfc8f0d052bc6f3da27e2a5703a0a\n    submitted by    /u/philosophiesde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16nix5t/zoomposium_with_professor_dr_petra_ritter_the/",
          "publishedOn": "2023-09-20T11:32:23.000Z",
          "wordCount": 2693,
          "title": "Zoomposium with Professor Dr. Petra Ritter: \"The simulation of brains\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16mynyu/new_physicsinspired_generative_ai_exceeds/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16mynyu/new_physicsinspired_generative_ai_exceeds/",
          "publishedOn": "2023-09-19T18:35:18.000Z",
          "wordCount": 2517,
          "title": "New ‘Physics-Inspired’ Generative AI Exceeds Expectations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16mv6i3/graph_neural_networks_use_graphs_when_they/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16mv6i3/graph_neural_networks_use_graphs_when_they/",
          "publishedOn": "2023-09-19T16:12:46.000Z",
          "wordCount": 2530,
          "title": "Graph Neural Networks Use Graphs When They Shouldn't",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16lngo9/best_neural_networks_courses_on_udemy_to_consider/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16lngo9/best_neural_networks_courses_on_udemy_to_consider/",
          "publishedOn": "2023-09-18T06:07:03.000Z",
          "wordCount": 2557,
          "title": "Best Neural Networks Courses on Udemy to Consider in 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16l95ed/adversarial_reinforcement_learning/",
          "author": null,
          "description": "A curated reading list for the adversarial perspective in deep reinforcement learning.\n https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning\n    submitted by    /u/ml_dnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16l95ed/adversarial_reinforcement_learning/",
          "publishedOn": "2023-09-17T19:06:23.000Z",
          "wordCount": 2550,
          "title": "Adversarial Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16l3r7w/this_neural_net_maps_molecules_to_aromas/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16l3r7w/this_neural_net_maps_molecules_to_aromas/",
          "publishedOn": "2023-09-17T15:35:31.000Z",
          "wordCount": 2552,
          "title": "This Neural Net Maps Molecules to Aromas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16l0j4k/luis_lambs_full_talk_on_learning_and_reasoning_in/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16l0j4k/luis_lambs_full_talk_on_learning_and_reasoning_in/",
          "publishedOn": "2023-09-17T13:21:28.000Z",
          "wordCount": 2544,
          "title": "Luis Lamb's full talk on Learning and Reasoning in Neurosymbolic AI (JA...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16kkgal/simple_explanation_of_convolutional_neural/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16kkgal/simple_explanation_of_convolutional_neural/",
          "publishedOn": "2023-09-16T22:44:24.000Z",
          "wordCount": 2546,
          "title": "Simple explanation of convolutional neural network | Deep Learning Tutorial 23 (Tensorflow & Python)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16kepbn/grounding_dino_explained/",
          "author": null,
          "description": "Hi there,\n I've created a video here where I explain how the Grounding DINO model works for open-set object detection.\n I hope it may be of use to some of you out there. Feedback is more than welcomed! :)\n    submitted by    /u/Personal-Trainer-541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16kepbn/grounding_dino_explained/",
          "publishedOn": "2023-09-16T18:39:59.000Z",
          "wordCount": 2576,
          "title": "Grounding DINO Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16k2d1g/newsletter_in_hardware_acceleration_in_robotics_77/",
          "author": null,
          "description": "https://news.accelerationrobotics.com/hardware-acceleration-in-robotics-77/\n Hardware acceleration in robotics news. Modi wants to make India a chip-making superpower. Can he?, What's new in China's robotics market?, July chip sales edge up, but are still well behind last year, Rockwell automation acquiring AMR developer Clearpath robotics\n    submitted by    /u/pablocarrera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16k2d1g/newsletter_in_hardware_acceleration_in_robotics_77/",
          "publishedOn": "2023-09-16T08:40:50.000Z",
          "wordCount": 2581,
          "title": "Newsletter in Hardware Acceleration in Robotics #77",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16jl0ab/breakthrough_way_to_train_neuromorphic_chips/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16jl0ab/breakthrough_way_to_train_neuromorphic_chips/",
          "publishedOn": "2023-09-15T18:31:03.000Z",
          "wordCount": 2540,
          "title": "Breakthrough way to train neuromorphic chips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16jh4zk/best_math_book_for_creating_neural_networks/",
          "author": null,
          "description": "So I want to create a neural network from scratch, like no lib(tensorflow, pytorch, etc…), so what’s the best book for that, I know both calculus and statistics, so I’m assuming that the math wouldn’t be a problem. Also I will be using Cuda for its speed.\n    submitted by    /u/GateCodeMark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16jh4zk/best_math_book_for_creating_neural_networks/",
          "publishedOn": "2023-09-15T15:55:33.000Z",
          "wordCount": 2588,
          "title": "Best “Math” book for creating neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16j7va5/announcing_the_robotperf_benchmarks_beta_release/",
          "author": null,
          "description": "https://news.accelerationrobotics.com/robotperf-beta/\n Together with AMD, Intel, Ford, Harvard, Klagenfurt University, Georgia Institute of Technology, Boston University, Johannes Kepler University Linz, Barnard College, Columbia University and Carnegie Mellon University we are thrilled to introduce the beta release of RobotPerf™ Benchmarks, an advanced benchmarking suite crafted specifically to evaluate robotics computing performance using ROS 2 as its baseline. In this beta release, we not only showcase new benchmarks and results but also introduce novel visualization capabilities. The complete release is available at https://github.com/robotperf/benchmarks/releases/tag/beta.\n https://preview.redd.it/5whys5ufudob1.png?width=1562&format=png&auto=webp&s=08a6e22a0b07b26fa6340f59ec9df822ab49c9d0\n    submitted by    /u/pablocarrera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16j7va5/announcing_the_robotperf_benchmarks_beta_release/",
          "publishedOn": "2023-09-15T08:48:02.000Z",
          "wordCount": 2626,
          "title": "Announcing the RobotPerf™ Benchmarks Beta Release: An industry standard for benchmarking robotic brains",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16imm3n/yocto_ros_2_and_hardware_acceleration_a/",
          "author": null,
          "description": "submitted by    /u/pablocarrera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16imm3n/yocto_ros_2_and_hardware_acceleration_a/",
          "publishedOn": "2023-09-14T16:17:27.000Z",
          "wordCount": 2545,
          "title": "Yocto, ROS 2, and Hardware Acceleration: A Production-Grade Trio for Robotics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16hhd2y/chatty_llama_a_fullstack_rust_react_chat_app/",
          "author": null,
          "description": "submitted by    /u/Sollimann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16hhd2y/chatty_llama_a_fullstack_rust_react_chat_app/",
          "publishedOn": "2023-09-13T08:24:29.000Z",
          "wordCount": 2555,
          "title": "Chatty LLama: A fullstack Rust + react chat app using Llama-2 https://github.com/Sollimann/chatty-llama",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16gzff5/do_interneuron_can_choose_other_interneuron_in/",
          "author": null,
          "description": "submitted by    /u/PowerfulGeologist373  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16gzff5/do_interneuron_can_choose_other_interneuron_in/",
          "publishedOn": "2023-09-12T18:45:37.000Z",
          "wordCount": 2558,
          "title": "Do interneuron can choose other interneuron in connections to send the signal? Or can’t And send the signal to all inter neuron in his connections .",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": [
        {
          "id": "https://danieltakeshi.github.io/2023/10/09/israel",
          "author": null,
          "description": "I strongly condemn the recent and horrific attack by Hamas against Israel.\nI have some disagreements with the government of Israel. But, I do not support\nsuch an attack.\nAs a point of comparison, I do not always agree with the United States\ngovernment, but I would not be celebrating if Mexico (picking a country at\nrandom) were to suddenly launch bombs towards civilians in Los Angeles and New\nYork City.  Similarly, if the reverse were true, if the United States decided\nto indiscriminately bomb Mexico City, I would oppose that as well.  Feel free\nto replace the relevant actors and repeat as needed.",
          "link": "https://danieltakeshi.github.io/2023/10/09/israel",
          "publishedOn": "2023-10-09T23:00:00.000Z",
          "wordCount": 268,
          "title": "I Condemn the Attack by Hamas",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI Blog",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/blog",
      "articles": [
        {
          "id": "https://openai.com/research/dall-e-3-system-card",
          "author": null,
          "description": "",
          "link": "https://openai.com/research/dall-e-3-system-card",
          "publishedOn": "2023-10-03T07:00:00.000Z",
          "wordCount": 150,
          "title": "DALL·E 3 system card",
          "imageUrl": "https://images.openai.com/blob/de9e8dc2-a39b-46c9-b7a0-54dd5c56b1df/dall-e-3-system-card.png?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
          "author": null,
          "description": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.",
          "link": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
          "publishedOn": "2023-09-25T07:00:00.000Z",
          "wordCount": 1149,
          "title": "ChatGPT can now see, hear, and speak",
          "imageUrl": "https://images.openai.com/blob/9c95036b-c2f5-4af8-a9c4-ed6c411f77e4/chatgpt-can-now-see-hear-and-speak-alt.jpg?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/research/gpt-4v-system-card",
          "author": null,
          "description": "",
          "link": "https://openai.com/research/gpt-4v-system-card",
          "publishedOn": "2023-09-25T07:00:00.000Z",
          "wordCount": 194,
          "title": "GPT-4V(ision) system card",
          "imageUrl": "https://images.openai.com/blob/96a6dba4-e46c-4f98-b718-915479d1c133/gpt-4vision-system-card.png?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/red-teaming-network",
          "author": null,
          "description": "We’re announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI’s models to join our efforts.",
          "link": "https://openai.com/blog/red-teaming-network",
          "publishedOn": "2023-09-19T07:00:00.000Z",
          "wordCount": 1601,
          "title": "OpenAI Red Teaming Network",
          "imageUrl": "https://images.openai.com/blob/71c1edf1-06f2-415c-826b-364f72fa74c1/red-teaming-network.png?trim=0%2C0%2C0%2C0&width=1000&quality=80"
        },
        {
          "id": "https://openai.com/blog/introducing-openai-dublin",
          "author": null,
          "description": "We’re growing our presence in Europe with an office in Dublin, Ireland.",
          "link": "https://openai.com/blog/introducing-openai-dublin",
          "publishedOn": "2023-09-13T07:00:00.000Z",
          "wordCount": 472,
          "title": "Introducing OpenAI Dublin",
          "imageUrl": "https://images.openai.com/blob/f4d87b7b-fd37-4b6c-8bff-5cc6b8073c7e/stangel-2022-0470.jpg?trim=90%2C0%2C630%2C0&width=1000&quality=80"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research/",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/",
          "author": "Alyssa Hughes",
          "description": "Research Focus: Principal researcher Lester Mackey recognized for pioneering statistical and ML techniques; Pareto frontiers in neural feature learning; structural inequality in the influencer industry; new research on cardinality estimation.\nThe post Research Focus: Week of October 9, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-october-9-2023/",
          "publishedOn": "2023-10-11T16:02:41.000Z",
          "wordCount": 2675,
          "title": "Research Focus: Week of October 9, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/RF26-BlogHeroFeature-1400x788-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=970974",
          "author": "Alyssa Hughes",
          "description": "Researcher Dr. Sheng Zhang joins “Abstracts”—your source for cutting-edge research in brief—to discuss a recent paper on distilling large language models into smaller, more efficient ones capable of excelling in broad application classes.\nThe post Abstracts: October 9, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-october-9-2023/",
          "publishedOn": "2023-10-09T14:35:09.000Z",
          "wordCount": 3858,
          "title": "Abstracts: October 9, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode3_Abstracts_Hero_Feature_No_Text_1400x788.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friendly-neural-architecture-search-with-spaceevo/",
          "author": "Alyssa Hughes",
          "description": "A persistent challenge in deep learning is optimizing neural network models for diverse hardware configurations, balancing performance and low latency. Learn how SpaceEvo automates hardware-aware neural architecture search to fine-tune DNN models for swift execution on diverse devices.\nThe post Efficient and hardware-friendly neural architecture search with SpaceEvo appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/efficient-and-hardware-friendly-neural-architecture-search-with-spaceevo/",
          "publishedOn": "2023-10-06T16:00:00.000Z",
          "wordCount": 2958,
          "title": "Efficient and hardware-friendly neural architecture search with SpaceEvo",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ICCV-SpaceEVO-2023-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=972234",
          "author": "Alyssa Hughes",
          "description": "HoloAssist is a new multimodal dataset consisting of 166 hours of interactive task executions with 222 participants. Discover how it offers invaluable data to advance the capabilities of next-gen AI copilots for real-world tasks.\nThe post HoloAssist: A multimodal dataset for next-gen AI copilots for the physical world appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/holoassist-a-multimodal-dataset-for-next-gen-ai-copilots-for-the-physical-world/",
          "publishedOn": "2023-10-05T16:00:00.000Z",
          "wordCount": 3061,
          "title": "HoloAssist: A multimodal dataset for next-gen AI copilots for the physical world",
          "enclosure": {
            "url": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/holoassist4kzoom.mp4",
            "length": "120799231",
            "type": "video/mp4"
          },
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/BLG_-ICCV-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=972015",
          "author": "Alyssa Hughes",
          "description": "Connecting with researchers, collaborating across disciplines, and exploring a new city—PhD students Jennifer Scurrell and Alejandro Cuevas talk to Senior Researcher Madeleine Daepp about the internship experience at Microsoft Research.\nThe post Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-madeleine-daepp-with-jennifer-scurrell-and-alejandro-cuevas/",
          "publishedOn": "2023-10-05T14:31:39.000Z",
          "wordCount": 8728,
          "title": "Intern Insights: Dr. Madeleine Daepp with Jennifer Scurrell and Alejandro Cuevas",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Madeline_Insights_TW_LI_FB_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=971679",
          "author": "Alyssa Hughes",
          "description": "A diverse research ecosystem is essential to realizing the promise of AI. Accelerate Foundation Models Research aims to expand access to powerful models, engaging academics outside of computer science to pursue a broad range of important opportunities.\nThe post Accelerate Foundation Models Research: Supporting a global academic research ecosystem for AI appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/accelerate-foundation-models-research-supporting-a-global-academic-research-ecosystem-for-ai/",
          "publishedOn": "2023-10-03T16:06:59.000Z",
          "wordCount": 3056,
          "title": "Accelerate Foundation Models Research: Supporting a global academic research ecosystem for AI",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/BLG_-AFMR-2023-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/podcast/ai-frontiers-measuring-and-mitigating-harms-with-hanna-wallach/",
          "author": "Brenda Potts",
          "description": "Powerful large-scale AI models like GPT-4 are showing dramatic improvements in reasoning, problem-solving, and language capabilities. This marks a phase change for artificial intelligence—and a signal of accelerating progress to come.    In this Microsoft Research Podcast series, AI scientist and engineer Ashley Llorens hosts conversations with his collaborators and colleagues about what these models—and the […]\nThe post AI Frontiers: Measuring and mitigating harms with Hanna Wallach appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/ai-frontiers-measuring-and-mitigating-harms-with-hanna-wallach/",
          "publishedOn": "2023-09-28T14:21:56.000Z",
          "wordCount": 8695,
          "title": "AI Frontiers: Measuring and mitigating harms with Hanna Wallach",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Hanna_Wallach_AI_Frontiers_TW_LI_FB_1200x627_With_Name.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-25-2023/",
          "author": "Brenda Potts",
          "description": "Chunked prefills & decode-maximal batching boost LLM inference; DragNUWA combines text, image, and trajectory for fine-grained video content control; reconstructing images from human brain signals; structural inequalities in creator-audience relationships.\nThe post Research Focus: Week of September 25, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-25-2023/",
          "publishedOn": "2023-09-27T16:00:00.000Z",
          "wordCount": 2643,
          "title": "Research Focus: Week of September 25, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/RF25-blog-social-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=969759",
          "author": "Alyssa Hughes",
          "description": "Microsoft researchers are introducing AutoGen, a framework for simplifying the orchestration, optimization, and automation of workflows for large language model (LLM) applications—potentially transforming and extending what LLMs can do.\nThe post AutoGen: Enabling next-generation large language model applications appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/",
          "publishedOn": "2023-09-25T16:00:00.000Z",
          "wordCount": 3139,
          "title": "AutoGen: Enabling next-generation large language model applications",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AutoGen-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=967926",
          "author": "Brenda Potts",
          "description": "This research paper was presented at the 17th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (opens in new tab), a premier forum for advances in the theory and practice of reasoning under uncertainty. In the field of reasoning under uncertainty, probabilistic graphical models (PGMs) stand out as a powerful tool for […]\nThe post Neural Graphical Models appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/neural-graphical-models/",
          "publishedOn": "2023-09-20T16:45:35.000Z",
          "wordCount": 2887,
          "title": "Neural Graphical Models",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ECSQARU-2023-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/announcing-the-deepspeed4science-initiative-enabling-large-scale-scientific-discovery-through-sophisticated-ai-system-technologies/",
          "author": "Brenda Potts",
          "description": "In the next decade, deep learning may revolutionize the natural sciences, enhancing our capacity to model and predict natural occurrences. This could herald a new era of scientific exploration, bringing significant advancements across sectors from drug development to renewable energy. In line with Microsoft’s mission to empower every person and every organization on the planet […]\nThe post Announcing the DeepSpeed4Science Initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/announcing-the-deepspeed4science-initiative-enabling-large-scale-scientific-discovery-through-sophisticated-ai-system-technologies/",
          "publishedOn": "2023-09-19T16:00:00.000Z",
          "wordCount": 4570,
          "title": "Announcing the DeepSpeed4Science Initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/DeepSpeed4Science-TWLIFB-no-text-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=967503",
          "author": "Brenda Potts",
          "description": "Modern applications heavily rely on robust network infrastructure, requiring continuous innovation. In this evolving landscape, Microsoft is at the forefront, spearheading innovation efforts in networking and strengthening the foundational network infrastructure that underpins the cloud ecosystem. By investing in and enhancing this critical infrastructure, Microsoft not only ensures the resilience and scalability of cloud services […]\nThe post Microsoft at ACM SIGCOMM 2023: Innovating the future of networking appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-acm-sigcomm-2023-innovating-the-future-of-networking/",
          "publishedOn": "2023-09-14T16:00:00.000Z",
          "wordCount": 3029,
          "title": "Microsoft at ACM SIGCOMM 2023: Innovating the future of networking",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/SIGCOMM23_Blog_1400x788.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=967848",
          "author": "Brenda Potts",
          "description": "What’s the driving force behind AI’s recent, rapid progress? Research manager Ahmed Awadallah shares his insights on this, the two-stage approach to training large-scale models, and the need for better model evaluation in this episode of the #MSRPodcast.\nThe post AI Frontiers: The future of scale with Ahmed Awadallah and Ashley Llorens appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-future-of-scale-with-ahmed-awadallah-and-ashley-llorens/",
          "publishedOn": "2023-09-14T16:00:00.000Z",
          "wordCount": 9295,
          "title": "AI Frontiers: The future of scale with Ahmed Awadallah and Ashley Llorens",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Ahmed_AI_Frontiers_TW_LI_FB_1200x627_With_Name.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=966795",
          "author": "Alyssa Hughes",
          "description": "In this issue: Efficient polyglot analytics on semantic data aids query performance; generative retrieval for conversational question answering improves dialogue-based interfaces; a new tool uses ML to address capacity degradation in lithium-ion batteries.\nThe post Research Focus: Week of September 11, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-11-2023/",
          "publishedOn": "2023-09-13T16:00:00.000Z",
          "wordCount": 2629,
          "title": "Research Focus: Week of September 11, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/RF24-blog-FBTWLI-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=966513",
          "author": "Brenda Potts",
          "description": "The new #MSRPodcast series “Abstracts” is your source for cutting-edge research in brief. In the first episode, join researchers Ava Amini and Kevin K. Yang to learn about their new paper on using evolutionary-scale protein data to improve protein design.\nThe post Abstracts: September 13, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-september-13-2023/",
          "publishedOn": "2023-09-13T14:07:11.000Z",
          "wordCount": 3960,
          "title": "Abstracts: September 13, 2023",
          "enclosure": {
            "url": "https://media.blubrry.com/microsoftresearch/content.blubrry.com/microsoftresearch/MSR_Abstracts_EP1_Ava_Kevin_FINAL.mp3",
            "length": "0",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode1_Abstracts_TW_LI_FB_1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=964929",
          "author": "Brenda Potts",
          "description": "This research paper was presented at the 28th ACM SIGPLAN International Conference on Functional Programming (opens in new tab) (ICFP), a premier forum for discussing design, implementations, principles, and uses of functional programming. Functional programming languages offer a host of advantages, such as ensuring memory safety (opens in new tab) and eliminating arbitrary side effects. […]\nThe post FP2: Fully In-Place Functional Programming provides memory reuse for pure functional programs  appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/fp2-fully-in-place-functional-programming-provides-memory-reuse-for-pure-functional-programs/",
          "publishedOn": "2023-09-12T16:55:00.000Z",
          "wordCount": 3038,
          "title": "FP2: Fully In-Place Functional Programming provides memory reuse for pure functional programs",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ICFP23-TWLIFB-1200x627-1.jpg"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://blog.research.google/",
      "articles": [
        {
          "id": "http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html",
          "author": null,
          "description": "Posted by Sagar M. Waghmare, Senior Software Engineer, and Kimberly Wilber, Software Engineer, Google Research, Perception Team\n\n\n\n\nAs most people navigate their everyday world, they process visual input from the environment using an eye-level perspective. Unlike robots and self-driving cars, people don't have any \"out-of-body\" sensors to help guide them. Instead, a person’s sensory input is completely \"egocentric\", or \"from the self.\" This also applies to new technologies that understand the world around us from a human-like perspective, e.g., robots navigating through unknown buildings, AR glasses that highlight objects, or assistive technology to help people run independently.\n\n\n\n\n\nIn computer vision, scene understanding is the subfield that studies how visible objects relate to the sce…",
          "link": "http://blog.research.google/2023/10/sanpo-scene-understanding-accessibility.html",
          "publishedOn": "2023-10-09T19:17:00.000Z",
          "wordCount": 27977,
          "title": "SANPO: A Scene understanding, Accessibility, Navigation, Pathfinding, & Obstacle avoidance dataset",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh10zxbymBGZgjXFHDrw-CdxlVL7nRi6yjaI3w3X_x5pjxn8UWA7NnymAqMXomfjSBXWVDQ4czo8nqINhxzIPLVx2Uv1l8RDQAbikuWWjIt9IwxSIuSlEtJ5AJwOJkdaKPwzUdu9BwkJJP1gDj2UJQpkJ15ELGjSKHMl9ce0_470SwRz5snz32lV-vSlMd2/w1200-h630-p-k-no-nu/SANPOHero.gif"
        },
        {
          "id": "http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html",
          "author": null,
          "description": "Posted by Carlos Esteves and Ameesh Makadia, Research Scientists, Google Research, Athena Team\n\n\n\n\nTypical deep learning models for computer vision, like convolutional neural networks (CNNs) and vision transformers (ViT), process signals assuming planar (flat) spaces. For example, digital images are represented as a grid of pixels on a plane. However, this type of data makes up only a fraction of the data we encounter in scientific applications. Variables sampled from the Earth's atmosphere, like temperature and humidity, are naturally represented on the sphere. Some kinds of cosmological data and panoramic photos are also spherical signals, and are better treated as such. \n\n\n\nUsing methods designed for planar images to process spherical signals is problematic for a couple of reasons. Firs…",
          "link": "http://blog.research.google/2023/10/scalable-spherical-cnns-for-scientific.html",
          "publishedOn": "2023-10-04T17:26:00.003Z",
          "wordCount": 27683,
          "title": "Scalable spherical CNNs for scientific applications",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiISXk_mf90TkNUcODcg-c9wYJ70zgm713RvUoRkPkkjnia1fO4P97T1icROacexZlBUsovSg8KCNNHzq2tPacdxHLuwUeW1Q2BIFi6bVw6c1au-9_umDgedCgx2RPogqqhPqDZaP-Xwj1ShADnPFRKBQVS0r1M3oOSQw8WA8nUE-Wa8sAnhTYNuWlwXN57/w1200-h630-p-k-no-nu/image2.gif"
        },
        {
          "id": "http://blog.research.google/2023/10/google-at-iccv-2023.html",
          "author": null,
          "description": "Posted by Shaina Mehta, Program Manager, Google\n\n\n\n\nGoogle is proud to be a Platinum Sponsor of the International Conference on Computer Vision (ICCV 2023), a premier annual conference, which is being held this week in Paris, France. As a leader in computer vision research, Google has a strong presence at this year’s conference with 60 accepted papers and active involvement in 27 workshops and tutorials. Google is also proud to be a Platinum Sponsor for the LatinX in CV workshop. We look forward to sharing some of our extensive computer vision research and expanding our partnership with the broader research community. \n\n\n\nAttending ICCV 2023? We hope you’ll visit the Google booth to chat with researchers who are actively pursuing the latest innovations in computer vision, and check out som…",
          "link": "http://blog.research.google/2023/10/google-at-iccv-2023.html",
          "publishedOn": "2023-10-02T07:51:00.001Z",
          "wordCount": 28288,
          "title": "Google at ICCV 2023",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVnC8dDc8c44GFT7cAZh8PfC8_Mpt4h1rhl-uNMNGoGlNCAZVsT51z89pMqEcVgwa7UPUuvXlr07PpOJlxomCAyRRTOEssXQxDwm4SX8J4JC_63fKWKywHLuqPHBLRZLl4yYIC311eAXC4r47i1zeZoPg2OXhjxuBmzVXCFn5MrJtH7QhZtMLKzzFvXyvx/w1200-h630-p-k-no-nu/ICCV%20hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html",
          "author": null,
          "description": "Posted by Zhengqi Li and Noah Snavely, Research Scientists, Google Research\n\n\n\n\n\n\n\nA mobile phone’s camera is a powerful tool for capturing everyday moments. However, capturing a dynamic scene using a single camera is fundamentally limited. For instance, if we wanted to adjust the camera motion or timing of a recorded video (e.g., to freeze time while sweeping the camera around to highlight a dramatic moment), we would typically need an expensive Hollywood setup with a synchronized camera rig. Would it be possible to achieve similar effects solely from a video captured using a mobile phone’s camera, without a Hollywood budget?\n\n\n\nIn “DynIBaR: Neural Dynamic Image-Based Rendering”, a best paper honorable mention at CVPR 2023, we describe a new method that generates photorealistic free-viewp…",
          "link": "http://blog.research.google/2023/09/dynibar-space-time-view-synthesis-from.html",
          "publishedOn": "2023-09-28T20:01:00.000Z",
          "wordCount": 27708,
          "title": "DynIBaR: Space-time view synthesis from videos of dynamic scenes",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhGX53UfU9eWiSTRWdkrUWNln3KGyagkwfUi_38zEihOJ2qLkmQ-3yNsuJJ7SkJ-BTLlVrxJlyoEYl7-tAer6v4MnIAw49TWLGWa8cFgl_c_2WUJqw1O3J8nVhU-VtVwO5Z-bq7rH6pZj7APe5yDZCUSZyeDO39shlGFkVsSQDd1ZWYUT0eDmeJ9JLoWlA3/w1200-h630-p-k-no-nu/hero.gif"
        },
        {
          "id": "http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html",
          "author": null,
          "description": "Ramnath Kumar, Pre-Doctoral Researcher, and Arun Sai Suggala, Research Scientist, Google Research\n\n\n\n\n\nDeep neural networks (DNNs) have become essential for solving a wide range of tasks, from standard supervised learning (image classification using ViT) to meta-learning. The most commonly-used paradigm for learning DNNs is empirical risk minimization (ERM), which aims to identify a network that minimizes the average loss on training data points. Several algorithms, including stochastic gradient descent (SGD), Adam, and Adagrad, have been proposed for solving ERM. However, a drawback of ERM is that it weights all the samples equally, often ignoring the rare and more difficult samples, and focusing on the easier and abundant samples. This leads to suboptimal performance on unseen data, espe…",
          "link": "http://blog.research.google/2023/09/re-weighted-gradient-descent-via.html",
          "publishedOn": "2023-09-28T18:16:00.002Z",
          "wordCount": 27704,
          "title": "Re-weighted gradient descent via distributionally robust optimization",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhONjsYNtXi5AX4ZZ6qPfdY2Gwt2W5xZy1PF1m9ZaxucZtRZ5ZzmsNzHNNWkCKcpX1_n15DkZCR59ivF_uDCUUmbdijaAuiK3tlC9HahtKc1s1r6pQWwbwMhnuNK3Guu5G5QigWU6p4yaJXCBLvIosDHXwtyhxMVfplzK4wTXiwCwOGo1B2aFidcgtaZfN_/w1200-h630-p-k-no-nu/hero%20RGD.jpg"
        },
        {
          "id": "http://blog.research.google/2023/09/google-research-embarks-on-effort-to.html",
          "author": null,
          "description": "Posted by Michał Januszewski, Research Scientist, Google Research\n\n\n\n\n\n\nThe human brain is perhaps the most computationally complex machine in existence, consisting of networks of billions of cells. Researchers currently don’t understand the full picture of how glitches in its network machinery contribute to mental illnesses and other diseases, such as dementia. However, the emerging connectomics field, which aims to precisely map the connections between every cell in the brain, could help solve that problem. While maps have only been created for simpler organisms, technological advances for mapping even larger brains can enable us to understand how the human brain works, and how to treat brain diseases.\n\n\n\nToday, we're excited to announce that the Connectomics team at Google Research and …",
          "link": "http://blog.research.google/2023/09/google-research-embarks-on-effort-to.html",
          "publishedOn": "2023-09-26T14:10:00.000Z",
          "wordCount": 27682,
          "title": "Google Research embarks on effort to map a mouse brain",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgFf6_wflZxOT_rmYJu0VCRvigHGMvE2QXwYJeh6F7GHmxnEtg7_bEraidqQ8uii_-N5EtBr2LfOGV_ccWS2g1Qcjssq2HmmGCqbaL_ij-UroaO6JtJVhyNbxK5PN57OfVlmkfXGSg3DMFawUlj1btghs5Nb9tmvQVSZH3pDoLK0SoKlhMh028164YArWcc/w1200-h630-p-k-no-nu/connectome%20600x580.gif"
        },
        {
          "id": "http://blog.research.google/2023/09/distilling-step-by-step-outperforming.html",
          "author": null,
          "description": "Posted by Cheng-Yu Hsieh, Student Researcher, and Chen-Yu Lee, Research Scientist, Cloud AI Team\n\n\n\n\n\nLarge language models (LLMs) have enabled a new data-efficient learning paradigm wherein they can be used to solve unseen new tasks via zero-shot or few-shot prompting. However, LLMs are challenging to deploy for real-world applications due to their sheer size. For instance, serving a single 175 billion LLM requires at least 350GB of GPU memory using specialized infrastructure, not to mention that today's state-of-the-art LLMs are composed of over 500 billion parameters. Such computational requirements are inaccessible for many research teams, especially for applications that require low latency performance.\n\n\n\n\nTo circumvent these deployment challenges, practitioners often choose to deplo…",
          "link": "http://blog.research.google/2023/09/distilling-step-by-step-outperforming.html",
          "publishedOn": "2023-09-21T21:25:00.000Z",
          "wordCount": 27937,
          "title": "Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj7i39GKWT7_noICLVOMuf2x7v7wM21MXu9deGmnVlsieFv9m_rJOb5ytwiI_A9T3N4N1vZCVprlgbs7dePmQ1qjkcz-mT0nkeyLq-LmkF4oJB-ofCmrv81jqXMHPHe8Tl1dQSbDAPS9gADUUByZHBygkr-jlwbfIx3FM14n5cAbE7ZFVm84K6UDQLfeArm/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html",
          "author": null,
          "description": "Posted by Haolin Jia, Software Engineer, and Qifei Wang, Senior Software Engineer, Core ML\n\n\n\nIn recent years, we have witnessed rising interest across consumers and researchers in integrated augmented reality (AR) experiences using real-time face feature generation and editing functions in mobile applications, including short videos, virtual reality, and gaming. As a result, there is a growing demand for lightweight, yet high-quality face generation and editing models, which are often based on generative adversarial network (GAN) techniques. However, the majority of GAN models suffer from high computational complexity and the need for a large training dataset. In addition, it is also important to employ GAN models responsibly. \n\n\n\nIn this post, we introduce MediaPipe FaceStylizer, an effi…",
          "link": "http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html",
          "publishedOn": "2023-09-15T17:39:00.002Z",
          "wordCount": 27681,
          "title": "MediaPipe FaceStylizer: On-device real-time few-shot face stylization",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihspgvRDlnUmToZlZzCcRWCFIt9TRnLH9lepBq6ojBLxZ0nFEPBS7bQgOHY0klCfkewtZy5KSGnKYialzlh4xNSFP5Th4mvWJWcJ8XvNkCAJK9T7f_xHSK-H0uPW0paxcTG3nhQtP7eY7iKSVjX-Oaca182KHKiuGzj2C4yWT_kenY-Ys7LtS7i93RCtcP/w1200-h630-p-k-no-nu/FaceStylizer-Hero.png"
        },
        {
          "id": "http://blog.research.google/2023/09/on-device-content-distillation-with.html",
          "author": null,
          "description": "Posted by Gabriel Barcik and Duc-Hieu Tran, Research Engineers, Google Research\n\n\n\n\nIn today's digital age, smartphones and desktop web browsers serve as the primary tools for accessing news and information. However, the proliferation of website clutter — encompassing complex layouts, navigation elements, and extraneous links — significantly impairs both the reading experience and article navigation. This issue is particularly acute for individuals with accessibility requirements.\n\n\n\nTo improve the user experience and make reading more accessible, Android and Chrome users may leverage the Reading Mode feature, which enhances accessibility by processing webpages to allow customizable contrast, adjustable text size, more legible fonts, and to enable text-to-speech utilities. Additionally, An…",
          "link": "http://blog.research.google/2023/09/on-device-content-distillation-with.html",
          "publishedOn": "2023-09-14T19:39:00.034Z",
          "wordCount": 27925,
          "title": "On-device content distillation with graph neural networks",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAbKikU6UWOjYuGg9JWDI3s8QKhXHtUEl2STZt_TNmwR4Y_B65GkYs--uMmYUYVVBdbTrtAVLRmlEGc1fTgeMS2E1kaNLmUJk6xWoj0qm0axNj2OcMzzPTZ68ygM0f7ZOo_8qoUXjTGGTO74-LZ9gvt9eK8lZjRDE0HWJNMJWYM_A2ppRGl5v8QVrxBEg7/w1200-h630-p-k-no-nu/ScreenGNN.gif"
        },
        {
          "id": "http://blog.research.google/2023/09/world-scale-inverse-reinforcement.html",
          "author": null,
          "description": "Posted by Matt Barnes, Software Engineer, Google Research\n\n\n\n\nRouting in Google Maps remains one of our most helpful and frequently used features. Determining the best route from A to B requires making complex trade-offs between factors including the estimated time of arrival (ETA), tolls, directness, surface conditions (e.g., paved, unpaved roads), and user preferences, which vary across transportation mode and local geography. Often, the most natural visibility we have into travelers' preferences is by analyzing real-world travel patterns.\n\n\n\nLearning preferences from observed sequential decision making behavior is a classic application of inverse reinforcement learning (IRL). Given a Markov decision process (MDP) — a formalization of the road network — and a set of demonstration traject…",
          "link": "http://blog.research.google/2023/09/world-scale-inverse-reinforcement.html",
          "publishedOn": "2023-09-12T21:22:00.000Z",
          "wordCount": 27551,
          "title": "World scale inverse reinforcement learning in Google Maps",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhgA5ZpGidOzCqTYTLV8bj62lAG7yfVa0cson-09oo7hqGA9ayl7h6koU96mxkBOqP_NyqiKamaoFrSAHtBlY7UH7XMnoq5Hn1H0hoiC5Uk0mMOkunNi6-j08iSEmUXTYEmp1YuFEgWLRJtieseqhQseMpy6e8KY5wElwNKDcy99GjCO-j04G0TVaJb0Pcr/w1200-h630-p-k-no-nu/hero.jpg"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "https://www.fast.ai/atom.xml",
      "articles": [
        {
          "id": "https://www.fast.ai/2022/09/06/homeschooling/",
          "author": null,
          "description": "My husband Jeremy and I never intended to homeschool, and yet we have now, unexpectedly, committed to homeschooling long-term. Prior to the pandemic, we both worked full-time in careers that we loved and found meaningful, and we sent our daughter to a full-day Montessori school. Although I struggled with significant health issues, I felt unbelievably lucky and fulfilled in both my family life and my professional life. The pandemic upended my careful balance. Every family is different, with different needs, circumstances, and constraints, and what works for one may not work for others. My intention here is primarily to share the journey of my own (very privileged) family.\n\n  \n\n\nOur unplanned introduction to homeschooling\nFor the first year of the pandemic, most schools in California, where …",
          "link": "https://www.fast.ai/2022/09/06/homeschooling/",
          "publishedOn": "2022-09-05T14:00:00.000Z",
          "wordCount": 2118,
          "title": "My family's unlikely homeschooling journey",
          "imageUrl": null
        },
        {
          "id": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "author": null,
          "description": "Jupyter notebooks don’t work with git by default. With nbdev2, the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter.\nContents\nThe Jupyter+git problem\nThe solution    \nThe nbdev2 git merge driver\nThe nbdev2 Jupyter save hook\nBackground\nThe result\nPostscript: other Jupyter+git tools    \nReviewNB\nAn alternative solution: Jupytext\nnbdime\nThe Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interact…",
          "link": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "publishedOn": "2022-08-24T14:00:00.000Z",
          "wordCount": 2227,
          "title": "The Jupyter+git problem is now solved",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/175898n/gain_and_bias_params_in_mujoco/",
          "author": null,
          "description": "Hi! I'm new to Mujoco and robot dynamics.\n When I read the Mujoco document, I'm confused about the gainprm and biasprm parameters. I want to understand the meaning of these parameters and tune the actuation speed of my actuator. An easy-to-understand explanation or supporting material would be appreciated. \n Thanks in advance.\n    submitted by    /u/UpperSearch4172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/175898n/gain_and_bias_params_in_mujoco/",
          "publishedOn": "2023-10-11T07:27:54.000Z",
          "wordCount": null,
          "title": "Gain and bias params in Mujoco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/17557z7/loopquest_a_githublike_platform_to_host/",
          "author": null,
          "description": "Hello everyone! Here is my pet project, https://www.loopquest.ai/. I am trying to build a platform like Github to let people upload their simulation environments so people can train their AI agents by interacting with the environments created by others. Here is a 2-min demo, https://youtu.be/d53NFjkU7JA. It is not launched yet but would love to get some early feedbacks.\n Here is the corresponding Github repo https://github.com/LoopMind-AI/loopquest. For now, the package can log env-agent interaction data by adding one extra line of code. You can think of it similar to https://github.com/google-deepmind/envlogger but with much better backend and frontend support.\n Any feedbacks are appreciated :)\n    submitted by    /u/jxx123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/17557z7/loopquest_a_githublike_platform_to_host/",
          "publishedOn": "2023-10-11T04:08:39.000Z",
          "wordCount": null,
          "title": "LoopQuest, A Github-like platform to host simulation environments for AI training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174vpzw/issue_with_mujoco_simulation_robot_penetrates_the/",
          "author": null,
          "description": "Hello everyone,\n I'm working on simulating a modified humanoid robot, \"DARwIn OP 3\", using MuJoCo through dm_control in Python. My goal is to train the model to ascend stairs rapidly but these are the first steps. However, I've encountered a problem where the robot appears to sink into the ground and is then ejected with significant force under specific conditions.\n ​\n https://reddit.com/link/174vpzw/video/u636vf49tftb1/player\n  \nEnvironment: MuJoCo via dm_control.\n Issue Description: When the robot falls and its feet move, it behaves as though one of its motors sinks into the floor.\n Attempts: I've tweaked contact parameters and ground properties with no luck. Interestingly, this doesn't occur in the standalone MuJoCo simulator.\n Visual Aid: I've attached a video to illustrate the problem…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174vpzw/issue_with_mujoco_simulation_robot_penetrates_the/",
          "publishedOn": "2023-10-10T20:46:50.000Z",
          "wordCount": null,
          "title": "Issue with MuJoCo Simulation: Robot Penetrates the Ground",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174u530/algorithms_for_average_reward_reinforcement/",
          "author": null,
          "description": "I see that discounted reward reinforcement learning has been extensively studied in the literature. However, the average reward metric receives less attention, and it looks like algorithms for this metric (R-learning, H-learning, SMART, etc.) are much less than the discount metric. Could you suggest any algorithms for average reward reinforcement learning for continuous/general state-action space?\n    submitted by    /u/S1gnature  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174u530/algorithms_for_average_reward_reinforcement/",
          "publishedOn": "2023-10-10T19:42:48.000Z",
          "wordCount": null,
          "title": "Algorithms for average reward reinforcement learning in continuous/general state-action space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174trnk/how_disney_packed_big_emotion_into_a_little_robot/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174trnk/how_disney_packed_big_emotion_into_a_little_robot/",
          "publishedOn": "2023-10-10T19:27:55.000Z",
          "wordCount": null,
          "title": "\"How Disney Packed Big Emotion Into a Little Robot\" (sim2real)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/174ldr6/i_took_openais_paper_about_defeating_dota2_world/",
          "author": null,
          "description": "submitted by    /u/mngrwl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/174ldr6/i_took_openais_paper_about_defeating_dota2_world/",
          "publishedOn": "2023-10-10T13:34:59.000Z",
          "wordCount": null,
          "title": "I took OpenAI's paper about defeating Dota2 world champions, and explained it paragraph-by-paragraph.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1747p76/whats_your_view_on_the_recent_rtx_effortsscaling/",
          "author": null,
          "description": "With recent RT-X efforts from Deepmind, it seems the community has been shifting towards the development of a more generalized foundational model, combining with visions and languages, and scaling via imitation learning. \n I know RL algorithms are expensive to train and hard to scale due to the way the samples are generated, but I am still fascinated by the intelligence behind their philosophies. What do you think the future would look like? Like NLP or CV, having a big foundational model pre-trained via IL, and fine-tune on different tasks via RL? How can we tell if a task is simple enough that we don't need to leverage the power of a foundational model?\n    submitted by    /u/Old_Reading_669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1747p76/whats_your_view_on_the_recent_rtx_effortsscaling/",
          "publishedOn": "2023-10-10T00:27:16.000Z",
          "wordCount": null,
          "title": "What's your view on the recent RT-X efforts/scaling via IL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173u9fn/switching_off_a_specified_rotor_in_airsim/",
          "author": null,
          "description": "Hello Everyone,\n I am working on a project to train a Reinforcement Learning agent to recover a quadrotor after any of the rotor’s failures. I am using AirSim for my project, but I can’t find a way to adjust the quad-rotor so that only 3 of the four rotors are working. \n Any suggestions? I appreciate any help you can provide.\n    submitted by    /u/audaciouslion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173u9fn/switching_off_a_specified_rotor_in_airsim/",
          "publishedOn": "2023-10-09T15:11:51.000Z",
          "wordCount": null,
          "title": "Switching off a specified rotor in AirSim",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173hbka/i_trained_a_reinforcement_learning_agent_to_play/",
          "author": null,
          "description": "Hi all, over the last couple years I've been training a reinforcement learning agent to play pokemon red. I put together a video which analyzes the AI's learning, as well as documenting my process and quite a bit of technical details. Enjoy! \n Video:\n https://youtu.be/DcYLT37ImBY\n Code:\n https://github.com/PWhiddy/PokemonRedExperiments\n https://preview.redd.it/4dw3yasqb3tb1.jpg?width=1280&format=pjpg&auto=webp&s=bdef1aa0d24d75ab548f3944c558840667ff0ed5\n    submitted by    /u/Pwhids  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173hbka/i_trained_a_reinforcement_learning_agent_to_play/",
          "publishedOn": "2023-10-09T02:50:51.000Z",
          "wordCount": null,
          "title": "I trained a reinforcement learning agent to play pokemon red!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173fpzz/feature_importance_in_ray_rllib/",
          "author": null,
          "description": "I am training an RL agent using Ray RLlib. Does anyone know how I can find which features (observations) help the agent learn the policy? I found this: https://discuss.ray.io/t/feature-importance/10362/2, but I'd really appreciate if someone could expand on this a bit more. Thank you!\n    submitted by    /u/greenteabiitch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173fpzz/feature_importance_in_ray_rllib/",
          "publishedOn": "2023-10-09T01:30:55.000Z",
          "wordCount": null,
          "title": "Feature Importance in Ray RLlib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/173dkt0/my_first_multiagent_rl_model/",
          "author": null,
          "description": "Hey Reddit,\n I am new to reinforcement learning. I have sufficient knowledge on supervised learning, but I am yet to stumble onto a cheat sheet for RL and from what I can tell, my use case is less common. \n I'm reaching out to the community in hopes of getting guidance and assistance in cutting through the noise of redundant and irrelevant information so I can attempt to built a toy model to validate my use case. I am deeply grateful for any help in advance.\n ​\n From what I can tell, here are the conditions I need to work with for my use case.\n  \nI'm trying to train a simulator.\n This is a multi-agent problem, perhaps with more than 2 agents. Each agent is responding based on it's own state, the state of the other agent[s], and historical context.\n Both the action space and state space are highly dimensional and highly dynamic based on the dataset and all agents' decisions. I still haven't figured out how the feature engineering will work yet, but I assume (but PLEASE correct my ignorance) I will need a DNN architecture that is more complex than the average deep RL algorithm, and I have considering using CNNs as a component.\n At scale, the datasets can and will be very large, random, and dynamic.\n  \n​\n Note to reader: I am self-taught. If I stare at technical equations long enough and google for additional resources, I can figure out what I am looking at, but I am very comfortable with technical concepts being shared as if I was a 5 year old. \n    submitted by    /u/CoggFest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/173dkt0/my_first_multiagent_rl_model/",
          "publishedOn": "2023-10-08T23:44:07.000Z",
          "wordCount": null,
          "title": "My First [Multi-Agent] RL model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/172w0a5/why_do_more_mujoco_mj_steps_lead_to_inaccurate/",
          "author": null,
          "description": "Hi!\n I tried to construct a simulation env following fetch_pick_and_place. I noticed that the following code is used to initialize the env:\n  for _ in range(10): self._mujoco.mj_step(self.model, self.data, nstep=self.n_substeps) \n Similarly, I followed the above code to initialize my own env with Mujoco menagerie Franka arm but got inaccurate configurations. As I reduced the number of loops, I got configurations closer to the desired configuration.\n Paradoxically, I need to randomize the position of the object in the air and give enough mj_step at the initial stage to make the object fall on the table. If I reduce the number of loops to reduce the number of times mj_step is executed, I can tell from the height value of the object that it doesn't quite fall on the table.\n So, my confusion is why more mj_steps lead to inaccurate simulation results, and how to make the object fall on the table and obtain the most accurate arm configuration.\n Thanks in advance!\n    submitted by    /u/UpperSearch4172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/172w0a5/why_do_more_mujoco_mj_steps_lead_to_inaccurate/",
          "publishedOn": "2023-10-08T10:35:46.000Z",
          "wordCount": null,
          "title": "Why do more Mujoco mj_steps lead to inaccurate arm configurations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/172c1ra/need_help_on_state_space_design_adding/",
          "author": null,
          "description": "Hello, \n I am designing an environment for a robotic task. It's a relatively straightforward task so I started with proprioceptive inputs only. I have a policy working well on a completely flat surface. But once I started to add small bumps to make the surface uneven, neither the policy nor the training strategy worked anymore, even though those bumps are really really small. \n This is a little confusing since I imagine if this is a task for human, should be able to handle those changes even without exteroceptive inputs. So I am debating should I modify my reward design, pick a more efficient algorithm, or expand the state space directly with exoceptive sensors. \n ​\n Any advices would be appreciated!\n    submitted by    /u/Old_Reading_669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/172c1ra/need_help_on_state_space_design_adding/",
          "publishedOn": "2023-10-07T17:38:23.000Z",
          "wordCount": 2671,
          "title": "Need help on state space design - Adding exteroceptive sensors or not?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1726e4o/what_is_the_exact_purpose_of_clip_function_in_ppo/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1726e4o/what_is_the_exact_purpose_of_clip_function_in_ppo/",
          "publishedOn": "2023-10-07T13:28:02.000Z",
          "wordCount": 2603,
          "title": "What is the exact purpose of clip function in PPO algorithm? PPO imposes policy ratio, r(θ) to stay within a small interval around 1. In the above equation, the function clip truncates the policy ratio between the range [1-ϵ, 1+ϵ]. If epsilon is taken as 0.2 or 0.25, what exactly is happening ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zppdr/why_dqn_method_is_only_suitable_for_small/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zppdr/why_dqn_method_is_only_suitable_for_small/",
          "publishedOn": "2023-10-04T15:08:34.000Z",
          "wordCount": null,
          "title": "Why DQN method is only suitable for small discrete action space? What is the issue if action space is large and continous?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zjeka/up_to_date_metaworld_documentation/",
          "author": null,
          "description": "Hello everyone, I want to start experimenting with the domain of multi-tasking and meta-learning, thus I pip installed metaworld which is currently on version 2.0.0 if I'm not mistaken.\n I wanted to ask in case anybody knows, if there's any recent updated documentation, because the farama foundation on GIthub which is probably responsible for maintaining the Metaworld, has outdated code and documentation. (for example, presented code on Github's README has the command env.step(a) which returns 4 values instead of 5 that newer version outputs).\n From what I understand, they gather contributors for a big push regarding code and documentation on GItHub, where they will make up things up to date again but this announcement was 7 months ago.\n Sorry for the potentially wrong format of this question-post, I'm relatively new to reddit.\n I would appreciate any further knowledge on this topic and thanks everyone who's taking the time to read it!\n ​\n Metaworld Distribution from Farama Foundation on Github:\n https://github.com/Farama-Foundation/Metaworld\n    submitted by    /u/South_Book_5625  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zjeka/up_to_date_metaworld_documentation/",
          "publishedOn": "2023-10-04T10:19:18.000Z",
          "wordCount": null,
          "title": "Up to date Metaworld documentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zgs7x/the_future_of_game_testing_is_here_and_it_is/",
          "author": null,
          "description": "Hi everyone!\n We used our opensource library SheepRL 🐑 and our PyTorch implementation of DreamerV3 on Crafter, an open-world survival game, featuring randomly generated 2D worlds, in which players have the freedom to explore a large and expansive map and need to forage for food, collect materials, build tools and find shelter. Here is a short video 👉 https://youtu.be/7XEBT2msUUQ\n In open-world games, ensuring they are playable and bug-free is crucial, but is becoming increasingly difficult and time-consuming using manual game testing. Maximizing exploration using Reinforcement Learning is extremely useful for testing games at scale, because of the wide variety of gameplay scenes the player may encounter.\n Why is the test on Crafter so interesting for game testing?\n Because Crafter evaluates a large number of general capabilities related to the RL agent, like strong ability to generalise (new generated maps for each episode), to deal with partial observability (each input image reveals only a small part of the world) and to long-term reasoning and survival.\n These abilities are very useful for testing games at scale, providing developers with insights to optimise gameplay and player experience.\n The future of game testing is here, and it is powered by Artificial Intelligence! 🔥\n ---\n ❌ Are you interested in joining the project community? Get in touch 👉 https://github.com/Eclectic-Sheep/sheeprl ❌\n SheepRL 🐑 is open-source, fully written in PyTorch and accelerated with LightningFabric - by Lightning AI. Feel free to use it for your AI projects, and if you want to contribute, we are more than happy to accept your pull requests! ❤️\n    submitted by    /u/Manu_Orobix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zgs7x/the_future_of_game_testing_is_here_and_it_is/",
          "publishedOn": "2023-10-04T07:31:09.000Z",
          "wordCount": null,
          "title": "The future of game testing is here, and it is powered by Artificial Intelligence! 🔥",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16zfr1n/can_i_use_continuous_algorithms_eg_td3_for/",
          "author": null,
          "description": "My environment has hybrid action spaces and I was wondering if I can use continuous algorithms for discrete action spaces. I'm asking this because, well, agent can't learn and I'm trying to find the source of error. I was wondering if this was the source of problem.\n ​\n My Assumptions On Solving This Problem:\n - Discrete is subspace of continuous, thus continuous algorithms will be able to handle discrete action spaces as well.\n - A non-hybrid action-space algorithm will be simpler than hybrid-action-space algorithms.\n ​\n Method (I'm only describing the discrete action here):\n - Use TD3 as the training algorithm. No modification from the original training code. TD3 algorithm has been verified on Pendulum and other environments created for unit test purposes.\n - Policy network outputs the a…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16zfr1n/can_i_use_continuous_algorithms_eg_td3_for/",
          "publishedOn": "2023-10-04T06:26:36.000Z",
          "wordCount": null,
          "title": "Can I use Continuous algorithms (e.g. TD3) for Discrete Action spaces?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16z6hfk/help_restricting_actions/",
          "author": null,
          "description": "Hello, I am new to RL, I am currently working on a school project that requires it. I am working on making a model to play a game very similar to wordle, so for the function of this post it may as well be wordle. \n Right now I am trying to get it to work with this gym https://github.com/zach-lawless/gym-wordle, and I will make my tweaks later. This gym has a multi discrete action space, which makes sense to me for a word, IDK if thats best. To validate words, it has its own exception type. I am trying to train this with stable_baselines3, but the exception keeps being raised, since it is trying to guess garbled words like \"xcjhr\". \n Is there a way I can validate actions before they are made so the model is restricted to only guessing valid words? Is there a better way to do this? It doesnt need to be the best, it really only has to sorta work. Any help is appreciated, thanks!\n    submitted by    /u/ClackHack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16z6hfk/help_restricting_actions/",
          "publishedOn": "2023-10-03T23:00:49.000Z",
          "wordCount": 2705,
          "title": "Help Restricting Actions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16z4cuy/looking_for_advice_on_training_and_reward/",
          "author": null,
          "description": "Hi Everyone,\n I'm venturing into a new territory of Reinforcement Learning (RL) through a personal project, despite having a solid background in various other ML domains. I'm developing an RL agent to play Skyjo, a turn-based card game, and I'm encountering some challenges related to reward optimization and game-ending decisions by the agents. I'd appreciate any advice or insights you might have!\n Project Overview:\n  \nObjective: Develop an RL model to play Skyjo competitively.\n Environment: Built using Gymnasium and Pytorch.\n Agents: Two agents working in tandem - one for card selection (discard/draw) and the other for action and location selection.\n Training: 4-8 agent instances play against each other.\n Repository: https://github.com/grantslewis/auto_skyjo\n  \nReward Structure:\n  \nSmall p…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16z4cuy/looking_for_advice_on_training_and_reward/",
          "publishedOn": "2023-10-03T21:38:49.000Z",
          "wordCount": 2858,
          "title": "Looking For Advice on Training and Reward Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16yw4ji/my_frustration_level_with_torchkerastensorflow/",
          "author": null,
          "description": "RANT:\n I've tried every possible example I can get my hands on. I've looked at reference examples. I've looked at Medium articles. I've looked at stuff written by college freshmen. Every example I find for a DQN written either for torch or tensorflow (and either tf_agents or keras), seems to either have a nasty bug preventing it to work or such a severe memory leak that it is unusable. \n I tried Torch recently and was doing some simple gridworlds. It does fine for tiny gridworlds like 5x5. I decided to push it a little (not much at all) to a known 21x21 gridworld from recognized papers - reference example died and ran out of memory after 3000 episodes - I mean - really? 3000 episodes? I ran on CPU and gave it 64GB. I don't know how much memory this SHOULD take. I can do it in a Q-Table for…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16yw4ji/my_frustration_level_with_torchkerastensorflow/",
          "publishedOn": "2023-10-03T16:14:51.000Z",
          "wordCount": 2990,
          "title": "My frustration level with Torch/Keras/Tensorflow and DQNs is killing me",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16yuhto/advice_to_improve_outcome_on_a_turnbased_strategy/",
          "author": null,
          "description": "Hello everyone, \n I'm a total beginner in the reinforcement learning (RL) community, and I would appreciate some advice on a problem I'm currently facing. I've created a simple 2D turn-based game with only movement at the moment (I will also add combat features when I have success with training an AI for the movements).\n Game\n The rules are simple :\n  \nA grid of 14x40 (560 cells in total)\n 1 Agent with a limited number of Move Point (MP) \n 1 Target that does not move (atm)\n The agent can end its turn to get its MP back\n  \nI already implemented a pathfinding algorithm using A* which works really well but I would like to train an AI to reach the target as fast as possible (turn-wise).\n Here is a simulation of a state : \n ​\n https://preview.redd.it/0p5yijnb60sb1.png?width=442&format=png&auto=…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16yuhto/advice_to_improve_outcome_on_a_turnbased_strategy/",
          "publishedOn": "2023-10-03T15:11:41.000Z",
          "wordCount": 3031,
          "title": "Advice to improve outcome on a turn-based strategy game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16yt6el/cleanba_our_new_distributed_drl_platform_is/",
          "author": null,
          "description": "submitted by    /u/vwxyzjn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16yt6el/cleanba_our_new_distributed_drl_platform_is/",
          "publishedOn": "2023-10-03T14:19:14.000Z",
          "wordCount": 2544,
          "title": "Cleanba, our new distributed DRL platform is finally out 🤗",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16y8sre/d_rl_agenda_after_llms_or_s4/",
          "author": null,
          "description": "Many other students in my research institution are pretty worried after ChatGPT / LLMs about continuing work in RL and are thinking of leaving the field.\n What are main the open problems in RL after LLMs and S4 can solve a hefty chunk of sequence learning problems?\n    submitted by    /u/Cultural-Average3959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16y8sre/d_rl_agenda_after_llms_or_s4/",
          "publishedOn": "2023-10-02T21:20:13.000Z",
          "wordCount": 2585,
          "title": "[D] RL agenda after LLMs or S4?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16xv79l/rlhf_without_gae/",
          "author": null,
          "description": "If I already have a trained reward model, say a sentiment classification model, that I'd like to use for PPO-based RLHF, I believe the standard method would be to instantiate the Critic/value function using the reward model, and train it further during PPO, correct?\n Would it even make sense to try PPO for RLHF without using the GAE term and thus without the value function, and just directly using the reward model's output as the advantage?\n It seems that this would be require viewing the entire generation as a single action (rather than each token's generation as an action), but most of the articles I've read on RLHF seem to treat it that way. On the other hand, all the code implementations I've seen have an Actor-Critic model producing values at each token, which I think implies that each token is an action.\n Edit: Apologies if any of this is just me having fundamental gaps in my understanding!\n    submitted by    /u/ganzzahl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16xv79l/rlhf_without_gae/",
          "publishedOn": "2023-10-02T12:20:04.000Z",
          "wordCount": 2695,
          "title": "RLHF without GAE",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16xr5l2/3player_graph_pursuit_game/",
          "author": null,
          "description": "So I am trying to find NE using rl algorithms for a turn based deterministic graph pursuit game. I have a way of checking if the strategies of players 1,2,3 are a NE and thought of using Q-Learning and see if it converges to a NE. Thus far it doesnt seem to work and I wonder if I made a mistake.\n The state is described as: St = [x1 x2 x3 p] where current player is p and x1,x2,x3 are the locations of the players in the graph\n Players have value functions Q^1(St), Q^2(St), Q^3(St)\n The way I update my value function is:\n player i choose e-greedy action a_t and the new state St_new\n Q^i(St) = (1-alpha)*Q^i(St)+alpha*gamma*Q(St_new)\n I have tried using a memory buffer but I havent improve the convergence success. I check if the if the values are a NE every 1000 iterations. It only converges for simple graphs.\n Do you think the way I update my value function is correct? Do you have any other traditional algorithms to suggest? Shall I move to deep learning? I am worried if simple algorithms cant converge the neural networks wont either... \n I tried to implemenet Nash Q learning following the paper:https://www.jmlr.org/papers/volume4/hu03a/hu03a.pdf\n but I am not sure if implemented correctly for a turn based game\n    submitted by    /u/__gp_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16xr5l2/3player_graph_pursuit_game/",
          "publishedOn": "2023-10-02T08:29:28.000Z",
          "wordCount": 2744,
          "title": "3-player graph pursuit game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16x5ilz/reinforcement_learning_computer_vision_listing/",
          "author": null,
          "description": "Hello everyone!\n A while back, I stumbled upon an interesting paper that applied Reinforcement Learning to Object Localization. I got fascinated by how computer vision tasks could be transformed into a reinforcement learning problem, making it feel like a Markov decision process !\n So, i've decided to create a repository to compile all the existing (published) papers that delve into Reinforcement Learning in Computer Vision : https://github.com/rayanramoul/RLCV-Papers\n If you have any papers in mind or recommendations to enhance the repository, please don't hesitate to share them. Your input would be greatly appreciated!\n Thank you! :)\n    submitted by    /u/raysamram  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16x5ilz/reinforcement_learning_computer_vision_listing/",
          "publishedOn": "2023-10-01T16:23:54.000Z",
          "wordCount": 2697,
          "title": "Reinforcement Learning + Computer Vision listing papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16wmbbu/multiagent_dqn_not_learning_for_clean_up_game/",
          "author": null,
          "description": "The environment of the Clean Up game is simple: in a 25*18 grid world, there's dirt spawning on the left side and apples spawning on the other. Agents get a +1 reward for eating an apple (by stepping onto it). Agents clean the dirt also by stepping on it (no reward). Agent can go up, down, left, right. The game goes on for 1000 steps. Apple's spawn probability depends on the amount of dirt (less dirt, higher the probability). Currently, the observation for each agent has the manhatten distance to their closest apple and dirt.\n I have tried multiple ways of training this, including changing the observation space of the agents. But it seems the result does not outperform random agents by any significant amount.\n The network is simple, it tries to take in all the observations for all the agen…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16wmbbu/multiagent_dqn_not_learning_for_clean_up_game/",
          "publishedOn": "2023-10-01T00:09:19.000Z",
          "wordCount": 3039,
          "title": "Multi-Agent DQN not learning for Clean Up Game - Reward slowly decreasing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16w5lug/testing_rnn_with_rllib/",
          "author": null,
          "description": "Hi folks! Since you've saved my ass before, maybe you have an idea about my issue here, too. I'm training and testing a custom RNN, but I receive the following error message: \n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/utils/threading.py\", line 24, in wrapper return func(self, *a, **k)\n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 1291, in _compute_action_helper\n dist_inputs, state_out = self.model(input_dict, state_batches, seq_lens)\n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/models/modelv2.py\", line 259, in __call__\n res = self.forward(restored, state or [], seq_lens)\n File \"/home/.conda/envs/ray/lib/python3.9/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 92, in forward\n i…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16w5lug/testing_rnn_with_rllib/",
          "publishedOn": "2023-09-30T12:30:53.000Z",
          "wordCount": 2775,
          "title": "Testing RNN with RLlib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16viyo6/metas_technological_marvel_aipowered_tools_and/",
          "author": null,
          "description": "submitted by    /u/Allinhalf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16viyo6/metas_technological_marvel_aipowered_tools_and/",
          "publishedOn": "2023-09-29T18:15:04.000Z",
          "wordCount": 2615,
          "title": "Meta's Technological Marvel: AI-Powered Tools and Intuitive Smart Glasses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16vfyzd/why_is_dyna_q_not_outperforming_q_learning_in/",
          "author": null,
          "description": "I coded a dyna Q implementation based on the algorithm given in Sutton's book over here. However, it seems like both are equally sample efficient on the cliff walking environment. Here is my code.\n These are my results -\n ​\n ​\n https://preview.redd.it/z7xwow5hz7rb1.png?width=585&format=png&auto=webp&s=90b33eb4c754e199e9bf15499a78e0f42e05f5d2\n The only think that came to my mind was to increase the model sampling rate (`n_iters`). Even after assigning a large value to it, the performance doesn't change.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16vfyzd/why_is_dyna_q_not_outperforming_q_learning_in/",
          "publishedOn": "2023-09-29T16:18:03.000Z",
          "wordCount": 2675,
          "title": "Why is dyna Q not outperforming Q learning in terms of sample efficiency?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16vcuno/how_can_i_config_and_build_mjpc_c_software/",
          "author": null,
          "description": "I'm trying to install and run this open-source project https://github.com/google-deepmind/mujoco_mpc. It's called MJPC, and it's a C++ software that displays a real-time interactive interface. I've cloned the code, installed CMake, and gcc version 13.1.0 to run C++20. I've also installed the CMake Tools and C/C++ extensions in VSCode as instructed. However, I'm not sure what to do next. I have no experience with C++ and software coding, configuring in VSCode, or building it. Please help me if you can, provide detailed guidance. \n    submitted by    /u/Nghiattk27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16vcuno/how_can_i_config_and_build_mjpc_c_software/",
          "publishedOn": "2023-09-29T14:17:21.000Z",
          "wordCount": 2686,
          "title": "How can I config and build MJPC c++ software?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16val6g/llm_agents_for_rl_envs/",
          "author": null,
          "description": "Has anyone here tried using LLM Agents to solve RL environments? I'm curious about your experiences. Considering that performing a single action involves a chain of thoughts, how fast did your experiments go? Please feel free to add any additional comments about this. \n Cheers!\n    submitted by    /u/stinoco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16val6g/llm_agents_for_rl_envs/",
          "publishedOn": "2023-09-29T12:40:31.000Z",
          "wordCount": 2638,
          "title": "LLM Agents for RL envs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16v7chi/shape_formation_with_multiagent_reinforcement/",
          "author": null,
          "description": "Hey everyone,\n I'm trying to write MARL code with MAPPO policy to train three agents to form a triangle shape. \n I'm relatively new to RL, having completed the fundamentals, but I'm struggling to come up with suitable resources which can teach me how to implement codes on python.\n I'd be really greatful if someone could share some insights or useful resources where I can learn to code and implement MARL.\n    submitted by    /u/The_One263  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16v7chi/shape_formation_with_multiagent_reinforcement/",
          "publishedOn": "2023-09-29T09:55:38.000Z",
          "wordCount": 2672,
          "title": "Shape Formation with Multi-Agent Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16v7ch4/shape_formation_with_multiagent_reinforcement/",
          "author": null,
          "description": "Hey everyone,\n I'm trying to write MARL code with MAPPO policy to train three agents to form a triangle shape. \n I'm relatively new to RL, having completed the fundamentals, but I'm struggling to come up with suitable resources which can teach me how to implement codes on python.\n I'd be really greatful if someone could share some insights or useful resources where I can learn to code and implement MARL.\n    submitted by    /u/The_One263  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16v7ch4/shape_formation_with_multiagent_reinforcement/",
          "publishedOn": "2023-09-29T09:55:36.000Z",
          "wordCount": 2672,
          "title": "Shape Formation with Multi-Agent Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16v13v5/curiosity_exploration_with_rllib/",
          "author": null,
          "description": "Hi! I’ve been training a MultiAgentEnv with Curiosity, but I’d like to extend my action space to be a Dictionary. Are there any similar modules I could use instead or is there any way to use Curiosity with a Dictionary consisting of a Box and a Discrete action space.\n Thank you!\n    submitted by    /u/tessherelurkingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16v13v5/curiosity_exploration_with_rllib/",
          "publishedOn": "2023-09-29T03:46:35.000Z",
          "wordCount": 2643,
          "title": "Curiosity/ Exploration with Rllib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16urp5l/modern_reinforcement_learning_for_video_game_npcs/",
          "author": null,
          "description": "submitted by    /u/akliyen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16urp5l/modern_reinforcement_learning_for_video_game_npcs/",
          "publishedOn": "2023-09-28T21:08:14.000Z",
          "wordCount": 2599,
          "title": "Modern reinforcement learning for video game NPCs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16uht6v/reinforcement_learning_in_automating_game_testing/",
          "author": null,
          "description": "The role of Reinforcement learning in automating game testing is becoming increasingly crucial, making it more efficient and effective. Manual testing, while essential, is extremely time-consuming and subject to human error. \n Our opensource library SheepRL 🐑 can be used to test whether the game dynamics is well defined: what if a player can finish the game with just a few moves? 🎮\n This video shows that our agent (Kasumi, on the left) is able to win the game in the hardest modality by standing down and throwing kicks. 🥊\n This can be helpful for a game developer to:\n ​\n  \nunderstand where and how intervene to achieve a more playful game\n \npredict and correct bugs early in the game development process\n enhance the gaming experience and final product quality\n reduce time and resources spent on debugging.\n  \nThe game has changed 🔥 and it is up to us to play it with (human + artificial) intelligence!\n Thanks to u/DIAMBRA_AIArena for the video!\n ---\n ❌ Are you interested in joining the project community? Get in touch ❌\n SheepRL 🐑 is open-source, fully written in PyTorch and accelerated with LightningFabric - by Lightning AI\n Feel free to use it for your Artificial Intelligence projects, and if you want to contribute, we are more than happy to accept your pull requests! ❤️\n https://reddit.com/link/16uht6v/video/ve3derxsc0rb1/player\n    submitted by    /u/Manu_Orobix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16uht6v/reinforcement_learning_in_automating_game_testing/",
          "publishedOn": "2023-09-28T14:39:36.000Z",
          "wordCount": 2813,
          "title": "Reinforcement learning in automating game testing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16u44zq/proofs_in_the_original_qlearning_technical_notes/",
          "author": null,
          "description": "I'm not sure it's the right place for this, but I was going through the proofs in the \"original\" 1992 technical notes of Q-learning, and a couple of points raised some questions:\n 1) In the Proof of lemma B.4:\n https://preview.redd.it/7g6pputdqwqb1.png?width=1006&format=png&auto=webp&s=fe4afeac3b06deee6c80105b280a0085bdcfbe51\n where do P_{xy}^2(a_2) and R_x(a_2) come from? If we apply the definitions of Q'(x, a_1, a_2) and Q(x, a_1, a_2) to get the bound, P_{xy}^2(a_2) and R_x(a_2) should not be there. Are they just notation errors or is it correct and I'm missing something?\n ​\n 2) I don't quite get how the bounds on P and R are computed in Section 3.2:\n https://preview.redd.it/p06ysjewqwqb1.png?width=962&format=png&auto=webp&s=a5929e701099dc6e4543efe7681f96f12f543fa8\n Considering the results in B.4 (i.e., the bounds for the distance between the chain's P, R and the real ones), I don't understand how they arrive at this conclusion. \n ​\n I'd greatly appreciate any intuitions about these, or if someone can point me in the right direction :)\n    submitted by    /u/Beautiful_Zebra_198  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16u44zq/proofs_in_the_original_qlearning_technical_notes/",
          "publishedOn": "2023-09-28T02:37:03.000Z",
          "wordCount": 2744,
          "title": "Proofs in the original Q-Learning technical notes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16tv288/online_training_from_demonstrations/",
          "author": null,
          "description": "I would like to embark on online training for an F1TENTH racing car, starting from scratch and leveraging demonstration data. Currently, it appears that DDPGfD is a promising approach. Does anyone have any research papers they can recommend or suggestions on how to get started?\n    submitted by    /u/anointedninja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16tv288/online_training_from_demonstrations/",
          "publishedOn": "2023-09-27T20:27:12.000Z",
          "wordCount": 2640,
          "title": "Online Training from Demonstrations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16tlhxw/what_if_the_robots_were_very_nice_while_they_took/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16tlhxw/what_if_the_robots_were_very_nice_while_they_took/",
          "publishedOn": "2023-09-27T14:03:38.000Z",
          "wordCount": 2624,
          "title": "\"What If the Robots Were Very Nice While They Took Over the World?\" (reflections on CICERO & _Diplomacy_)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16tj861/advice_on_getting_started_with_a_career_in/",
          "author": null,
          "description": "Reinforcement learning has grabbed my interest pretty firmly and been my focus for the 3 months or so. I spend most of my time working in python , rust, and now mojo. Not an expert yet but my coding skills are improving. I have no degree and have taught myself most of what I know. That part is why Im looking for advice from you all. Practically every job post Ive seen has college requirements. Is it unlikely to get hired without a degree?\n Additional information: I'm currently working on projects for github but those arent quite done. My main interest is related to RL in game design. Applications of distributional RL in action dense environments and VR. Currently using Godot engine the most and have used pytorch, openai gym, and tensorflow (to a lesser degree). The abstract concepts of neural networks comes easy to me and Ive been following basic neurology as well.\n    submitted by    /u/SchrodingersCog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16tj861/advice_on_getting_started_with_a_career_in/",
          "publishedOn": "2023-09-27T12:27:48.000Z",
          "wordCount": 2755,
          "title": "Advice on getting started with a career in reinforcement learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16tgfuj/how_to_modify_dqn_to_not_overfit_for_action_that/",
          "author": null,
          "description": "Edit: I may be jumping the gun here but I think I figured it out (looks good so far). I give the episode reward for every action EXCEPT the \"end early\" action, now I will need to give some boost for shorter episodes to achieve the desired effect :) \n I feel like I'm experiencing déjà vu, posing another DQN-related question. But, here's my issue:\n I've set up an environment where an agent can interact for 40 steps or choose to end the interaction early with a specific action. The catch is that the reward is only given at the end of the episode, which seems to be leading the agent to strongly favor the \"end early\" action. Despite all other steps getting a reward of 0, I assumed the long-term reward estimate, V(s_{t+1}), would mitigate this, but the agent still heavily gravitates towards ending the episode early.\n Attempted Solutions:\n  \nDistributed the end-of-episode reward across all prior actions taken by the agent.\n  \nConsidering:\n  \nReplacing the \"end early\" action with a \"do nothing\" action, allowing the episode to always play out in full. However, this seems like it could introduce additional computational costs and noise.\n  \nHas anyone encountered a similar problem? I'd appreciate any advice or recommendations.\n    submitted by    /u/Vae94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16tgfuj/how_to_modify_dqn_to_not_overfit_for_action_that/",
          "publishedOn": "2023-09-27T10:01:34.000Z",
          "wordCount": 2808,
          "title": "How to modify DQN to not overfit for action that concludes episode",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16t8m7t/deepmind_built_an_excellent_stratego_bot_can_i/",
          "author": null,
          "description": "I learned about DeepNash and R-NaD yesterday. I read the Deepmind article, Science paper, and the source code of rnad.py. But I don't think I understand it! Part of this is that they didn't define all the terms and Greek they use in the paper, and part of it is that I don't have academic ML experience.\n Below is my attempt to summarize the paper in non-academic terms. I'm trying to show that I did my homework, and also I'm trying to invoke Godwin's Law in the hopes that someone will come along and correct me.\n Here goes:\n Naïve reinforcement learning doesn't work with simultaneous choice games such as matching pennies or Rock-Paper-Scissors.\n In naïve RL, If I choose Rock as my move, my opponent chooses Scissors as their move, and I see that I won, that will reinforce a belief that Rock is a \"good\" move and Scissors is a \"bad\" move. But this isn't true!\n This means that, during selfplay, a naïve RL agent will just cycle through strategies, as the timestep-(τ_n) agent learns how to beat the timestep-(τ_n-1) agent. The agent will never learn that RPS is a game about staying unpredictable!\n R-NaD fixes this by adjusting the reward function. I think \"regularizing\" is ML-academic speak for \"adjusting\". It adjusts the reward function in such a way that the agent will converge at a Nash equilibrium strategy.\n The paper's equation (1) describes how the regularization works. They didn't explain all the terms, though. I still don't know what a_i represents. But I think it corresponds to parts of the code like this line and this line.\n The key is that we're merging policies from multiple epochs and making sure that the current agent's move probabilities fare well against not only itself, but also against its previous two generations. They've proven that three generations is all you need to eventually converge to a Nash equilibrium.\n So... that's my understanding. Does anyone with actual ML experience want to weigh in?\n    submitted by    /u/lord_braleigh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16t8m7t/deepmind_built_an_excellent_stratego_bot_can_i/",
          "publishedOn": "2023-09-27T02:48:15.000Z",
          "wordCount": 2940,
          "title": "DeepMind built an excellent Stratego bot. Can I get an ELI5 of the underlying technologies, DeepNash and R-NaD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16suli8/my_agent_does_not_learn_the_most_obvious_task/",
          "author": null,
          "description": "I am very puzzled as to the results I have observed today, after running an extremely simple environment and receiving really bad results. I am probably doing something wrong, and would like to ask for your wisdom to assist me in figuring out what I am doing wrong.\n I will not describe the entire task since that is a long story; I will just say that I started by doing something complex (a multi-objective reward), and when it failed I decided to try something extremely simple (\"because it will surely work and I can proceed from there...\"). To my surprise, the agent was not able to perform even that very simple task. That simple task is the following: at each step, choose a subset of items. Each item has a value, and the goal is to maximize the overall value (that is, at the end of the traje…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16suli8/my_agent_does_not_learn_the_most_obvious_task/",
          "publishedOn": "2023-09-26T17:44:34.000Z",
          "wordCount": 3016,
          "title": "My agent does not learn the most obvious task. Please help me figure out why!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16sp236/learning_to_code/",
          "author": null,
          "description": "I've just started diving into the world of coding over the past week, and I've been using various tools like YouTube videos, Visual Basic, GPT-3.5, Bard, and Bing to help me learn the ropes. It's been a bit of a journey, and I've definitely picked up some understanding along the way, especially when it comes to libraries. But, you know, there's only so much you can really learn from AI models like GPT or other chatbots. Most of my progress has involved me taking bits and pieces of code I found here and there and trying to piece them together, even if it sometimes felt like making a digital spaghetti dish!\n One project I tackled involved using Stable_baselines3 PPO with ADAM optimization to play the classic game Flappy Bird. It was a bit of a wild ride, taking about 6-7 hours of my time, an…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16sp236/learning_to_code/",
          "publishedOn": "2023-09-26T14:11:01.000Z",
          "wordCount": 2947,
          "title": "Learning to code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16sd8ys/please_make_a_rl_project_for_me_i_need_turtlebot3/",
          "author": null,
          "description": "I have to do masters project where a turtlebot3 needs to reach a goal position using DRL. I have managed to use move_base package to give global path. Local path planner just needs follow the path and reach goal. There will be dynamic obstacles too. I will give more information if you are ready. As mentioned I will pay for this. Let me know. I have one month left. Email ramanjeet995@gmail.com.\n Update : I should have said it like this. I need help with my project.\n    submitted by    /u/Pinball_1995  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16sd8ys/please_make_a_rl_project_for_me_i_need_turtlebot3/",
          "publishedOn": "2023-09-26T03:52:49.000Z",
          "wordCount": 2672,
          "title": "Please make a RL project for me. I need turtlebot3 to navigate to local goal points using DRL in gazebo simulator. I will pay",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16s6vpa/deep_rl_at_scale_sorting_waste_in_office/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16s6vpa/deep_rl_at_scale_sorting_waste_in_office/",
          "publishedOn": "2023-09-25T23:00:28.000Z",
          "wordCount": 2591,
          "title": "\"Deep RL at Scale: Sorting Waste in Office Buildings with a Fleet of Mobile Manipulators\", Herzog et al 2023 {G}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16rj60f/package_delivery_environment_for_openai_gym/",
          "author": null,
          "description": "hi everyone, i’m working on a project in which i get a list of orders (id,delivery coordinates, delivery deadline). i need to deliver all packages while putting in consideration clients priority and taking least time and distance as possible. so the goal is to sort the orders to achieve the target. what would be the action / observation space for such environment? and how can i define the step method to perform this scenario?\n    submitted by    /u/overflow74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16rj60f/package_delivery_environment_for_openai_gym/",
          "publishedOn": "2023-09-25T05:11:37.000Z",
          "wordCount": 2635,
          "title": "package delivery environment for OpenAI GYM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16rfk7r/why_my_graph_go_down_when_train_a_saved_model/",
          "author": null,
          "description": "I’m new to ML and RL, and I’m building a small piece of code using gymnasium to be able to use mujoco. Specifically, I use Mujoco’s Humanoid, here is my code (https://github.com/NghiaPhamttk27/Humanoid).I use some algorithms in RL like SAC, TD3, A2C from stable\\_baselines3. After every 25000 TIMESTEPS, I will save my model in the models folder. When I train continuously, everything goes well, I can see it on the tensorboard graph. But when I continue training a model that has been trained, the graph suddenly drops. In the image below you can see that I retrain the models at SAC\\_75000 and SAC\\_100000 and SAC\\_125000. The graph continuously decreases at those thresholds.I think something happended Can you give me a reason or share something with me? Thanks in advance.\n You can see graph of SAC goes down when 76k, 100k, and 125k timeSteps\n    submitted by    /u/Nghiattk27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16rfk7r/why_my_graph_go_down_when_train_a_saved_model/",
          "publishedOn": "2023-09-25T02:05:06.000Z",
          "wordCount": 2707,
          "title": "Why my graph go down when train a saved model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16rec1a/best_rl_package/",
          "author": null,
          "description": "Am starting out working on an RL problem and am wondering what people generally use to implement the algorithms? \n I’ll need to build a custom environment, but I assume I can subclass something from Gym.\n    submitted by    /u/suds_65  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16rec1a/best_rl_package/",
          "publishedOn": "2023-09-25T01:04:51.000Z",
          "wordCount": 2593,
          "title": "Best RL package?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16r3k1o/dp_how_to_create_a_3d_gymnasium_environment_for/",
          "author": null,
          "description": "submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16r3k1o/dp_how_to_create_a_3d_gymnasium_environment_for/",
          "publishedOn": "2023-09-24T17:33:54.000Z",
          "wordCount": 2549,
          "title": "[D][P] how to create a 3D gymnasium environment for mujoco env?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16qzsku/help_with_understanding_optimal_policy_and_values/",
          "author": null,
          "description": "​\n slide as part of the presentation.\n I've listened to the entire lecture and am now going through these slides and I didn't understand the solution provided for the choices above in the image.\n So far I understand it like this. Noise basically means that the agent will not always do the action that you say. You say left and it will go left only 50% of the time. it will choose other actions randomly.\n so, Why is the answer to the (c) and (d) questions (2) and (3) respectively?\n I understand the learning rate but not how risking the cliff is affected by the noise.\n    submitted by    /u/vestedpolecat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16qzsku/help_with_understanding_optimal_policy_and_values/",
          "publishedOn": "2023-09-24T14:59:50.000Z",
          "wordCount": 2624,
          "title": "Help with understanding optimal policy and values",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16qvp58/the_return_of_pepe_expect_awesome_rewards/",
          "author": null,
          "description": "https://pepe-web3.network\n    submitted by    /u/Beginning_Success208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16qvp58/the_return_of_pepe_expect_awesome_rewards/",
          "publishedOn": "2023-09-24T11:43:48.000Z",
          "wordCount": 2523,
          "title": "The Return of Pepe: Expect Awesome Rewards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16qtr4d/why_is_there_no_prominent_usage_of_transformers/",
          "author": null,
          "description": "For a potential school project, im currently exploring whether or not some of the success the transformer architecture has had in seq-to-seq applications and high-dimensional pattern recognition could be extended to certain (online) RL problems (mainly those with high dimensional environment as well as long-term planning). \n This could be done by using an augmented transformer as a function approximator, probably in combination with a SOTA online-rl algorithm (such as PPO, but if you know something that generally performs better do tell). Due to some of the problems associated with highly complex models and sample efficiency, I also thought about training the model using imitation learning first (which should be no problem with policy gradient methods afaik, though some slight adjustments would have to be made). For context, I'm thinking on benchmarking the approach using AlphaStar unplugged.\n However, when looking at current literature, only very few papers directly use transformers this way. Transformers seem to be very sample efficient and to generalize very well, but they are still only really used in a purely offline context (sometimes without directly using RL-techniques, such as with the Decision Transformer). And, if they are used in an online context, then only in some really intricate combination with other models (such as in AlphaStar). \n Is there a reason why the approach I am currently considering is not popular in literature? Thank you very much.\n    submitted by    /u/Omycron83  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16qtr4d/why_is_there_no_prominent_usage_of_transformers/",
          "publishedOn": "2023-09-24T09:52:03.000Z",
          "wordCount": 2755,
          "title": "Why is there no prominent usage of transformers in online rl?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16q1h8h/rl_with_comsol_multiphysics/",
          "author": null,
          "description": "Hi has anyone ever attempted to do RL with comsol multiphysics or any other FEM based simulation tool?\n    submitted by    /u/Practical_Ad_8782  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16q1h8h/rl_with_comsol_multiphysics/",
          "publishedOn": "2023-09-23T10:54:07.000Z",
          "wordCount": 2537,
          "title": "RL with comsol multiphysics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16pzd5w/mini_rl_lab/",
          "author": null,
          "description": "Hi all, I'd like to share some of what I've learned over the last ~year getting up to speed with Python and RL.\n Mini RL Lab is a setup and workflow that works well for me to debug and experiment with concepts like agent algorithms, world models, planning, plasticity, transformers etc, and other beginners might find it a useful starting point for their own experiments.\n Link: https://github.com/modelbased/minirllab\n    submitted by    /u/thiagoazevedo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16pzd5w/mini_rl_lab/",
          "publishedOn": "2023-09-23T08:49:50.000Z",
          "wordCount": 2585,
          "title": "Mini RL Lab",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16pz3qp/in_counterfactual_regret_minimization_is_it/",
          "author": null,
          "description": "As I understand, like in the example rock paper scissors, they compute the regret based on the last state. or in poker, they compute regret based on what last happened.\n But is it possible to compute regret for two or more moves ago? like \"i wish when I saw <something> 10 moves ago, I did x\"?\n or has it been possible from the start and I just understood counterfactual regret minimization wrongly?\n    submitted by    /u/oniongarlic88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16pz3qp/in_counterfactual_regret_minimization_is_it/",
          "publishedOn": "2023-09-23T08:34:07.000Z",
          "wordCount": 2608,
          "title": "in counterfactual regret minimization, is it possible to compute regret for a move that was made more than 1 move ago?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16pz249/question_about_hypernetworks_in_rl/",
          "author": null,
          "description": "Hey everyone,\n I've been taking a look at hypernetworks and noticed they've been used in some cool ways in RL with stuff like Qmix and this Metalearning paper.\n Quick recap:\n  \nf is our regular neural network: takes in input x and outputs y using weights \\theta.\n g is the hypernetwork, it creates the weights \\theta for f based on its own weights \\phi and maybe the input x.\n  \nOriginal paper: https://arxiv.org/abs/1609.09106\n I watched this talk and it hinted that hypernetworks might even be better than our regular networks even for supervised learning regular tasks.\n So, I'm curious:\n  \nWhat's the deal with hypernetworks? What makes them good or not vs regular neural networks?\n I get that they're good for metalearning, but could they also be a game-changer for other things, like sample efficiency?\n  \nDoes anyone have thoughts or reads on this? \n Thanks!\n ​\n ​\n    submitted by    /u/LazyButAmbitious  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16pz249/question_about_hypernetworks_in_rl/",
          "publishedOn": "2023-09-23T08:31:25.000Z",
          "wordCount": 2661,
          "title": "Question about hypernetworks in RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16peyzs/driving_where_no_autonomous_vehicle_has_driven/",
          "author": null,
          "description": "submitted by    /u/shani_786  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16peyzs/driving_where_no_autonomous_vehicle_has_driven/",
          "publishedOn": "2023-09-22T16:38:24.000Z",
          "wordCount": 2521,
          "title": "Driving where no Autonomous Vehicle has driven before!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16p5m7g/the_conference_for_reinforcement_learning_related/",
          "author": null,
          "description": "Hi everyone,\n I'm a newbie for the domain of reinforcement learning (RL). My main research on various software systems, mainly on multi-agent system (MAS). AAMAS, a conference focusing on Multi-agent system, I think is the good conference to study in MAS. Recently, there are many researchers for MAS that is great combination with reinforecement learning to do some interesting things. Also, game theory is a\n interesting knowledge what I'm curious about how to do within RL and agents.\n Does any recommended conference or journal for RL? don't mind for just only RL algorithm, that's enough great, whereas I prefer to the conference concerning RL applied some software system for some problem.\n Thanks all.\n    submitted by    /u/DryAir1198  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16p5m7g/the_conference_for_reinforcement_learning_related/",
          "publishedOn": "2023-09-22T09:22:09.000Z",
          "wordCount": 2642,
          "title": "The conference for Reinforcement Learning related with mutli-agent system, game theory, or with others' technicals",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16ozpfd/help_me_solve_this_weird_error/",
          "author": null,
          "description": "trying to make a frozen lake game but keep getting this weird error and i dont know how to fix it. The error is \"too many values to unpack (expected 4)\" on the line: next_state, reward, done, _ = env.step(action)\n import gym\n import numpy as np\n import pygame\n from pygame.locals import QUIT\n import tensorflow as tf\n from tensorflow import keras\n import warnings\n def ignore_specific_warning():\n warnings.filterwarnings(\"ignore\", message=\"This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\")\n ​\n ignore_specific_warning()\n ​\n input_size = env.observation_space.n\n output_size = env.action_space.n\n ​\n model = tf.keras.Sequential([\n tf.keras.layers.Dense(64,activation='relu',input_shape=(input_size,),use_bias=False),\n tf.keras.layers.Dense(output_size,use_bias=False)])\n ​\n loss_fns = tf.keras.losses.MeanSquaredError()\n optimizer = tf.keras.optimizers.Adamlearning_rate=0.001\n ​\n discount_factor=0.99\n learning_rate=0.1\n num_episodes=1000\n ​\n for i in range(num_episodes):\n state = env.reset()\n done = False\n while not done:\n env.render()\n epsilon = 0.1\n if np.random.rand() < epsilon:\n action = env.action_space.sample()\n else:\n #Q_values = model.predict(tf.one_hot(state[0],input_size))\n #action = np.argmax(Q_values)\n state_one_hot = tf.one_hot(state[0], input_size)\n Q_values = model.predict(tf.reshape(state_one_hot, (1, -1)))\n action = np.argmax(Q_values)\n next_state, reward, done, _ = env.step(action)\n target = reward*discount_factor*np.max(model.predict(tf.one_hot(next_state,input_size)))\n with tf.gradientTape() as tape:\n Q_values = model(tf.one_hot(next_state,input_size))\n loss = loss_fn(Q_values[0][action],target)\n gradients = tape.gradients(loss,model.trainable_variables)\n optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n state = next_state\n env.close()\n    submitted by    /u/BeastHunterrr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16ozpfd/help_me_solve_this_weird_error/",
          "publishedOn": "2023-09-22T03:21:42.000Z",
          "wordCount": 2690,
          "title": "help me solve this weird error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16oor9h/ddqn_tunning/",
          "author": null,
          "description": "Hi world\n I'm trying to implement dqn and ddqn on various playgrounds with Matlab, from scratch. I use dqn and ddqn with replay buffer. I tried to used gradient clipping. But I find it very difficult to tune.\n I mean I tuned and programmed successfully various algorithm such as different GAN that are not necessarily very easy to tune. RL algorithm seems even worse.\n I tried several grid world problems, cart pole and even a very simple second order system regulation (integrator + 1 st order pôle). \n Even the Matlab cart pole demo with ddqn does not provide a very satisfactory result (after training, the contrôler keep the pendulum in uprigth position, but the cart slowly drift).\n On the second order system, the learning seems ok for about 200 épisode(test shows that the expected behavior is almost learnt) and then suddenly the average episode score has a kind of inflection and everything blowns up, despite a very large replay buffer.\n So my question : is it possible to make dqn and ddqn work well with a reasonable tuning session length? Are policy optimization easier to tune (and/or more efficient)? So far, it seems to me that these action-vzlue based algorithms are highly unstable and the training may only works for a 'miraculous' tunning. What are you thought?\n    submitted by    /u/seb59  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16oor9h/ddqn_tunning/",
          "publishedOn": "2023-09-21T19:24:18.000Z",
          "wordCount": 2734,
          "title": "Ddqn tunning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16om4fv/implementation_of_reinforcement_learning_to/",
          "author": null,
          "description": "Hello there,\n I'll provide a quick introduction first. I am a mechatronics engineer student who is graduating this semester, I have been also privately studying ML, DL, CV for the past year because that's when I decided that I want to make an autonomous drone as my thesis/graduation project and oh my god, little did I know. I have aquired so much knowledge in the data science field and truth be told I love it, it engages my mind like crazy so I've decided that i would like my career to be revolved around electronics and programming/ data science.\n Back to the topic, I am working on object detection (I got it figured out), and reinforcement learning, so what I would like to do is to train the model on reaching it's destination using collision avoidance, I have a PIX4, RPI 4B 4GBs since I'm also building my drone from scratch, so let's say I have all the hardware which ofcourse includes the GPS + Compass and 5 ultrasonic sensors, 1 at each side and 1 down to hold the altitude accurately. I was thinking of HITL, making a virtual environment to train my model there because this is what logic says, ofcourse( I could also fly it using the RC controller and for example test if the obstacle avoidance is going to overrule the manual drive, which is also my objective). The question is: how can I make sure virtual drone is going to be equipped with the real-life sensors and in the needed positions? How can I feed all the sensors data during the training? Which type of reinforcement learning models should I implement? \n I just feel like I dragged myself into an incredibly amazing and complex project which is going to end up fucking my semester and I won't be able to graduate, it's just that my stress now is skyrocketing. \n Please feel free to throw any advice or opinions my way, and thank you for keeping up with this long post. 😁\n    submitted by    /u/Gabii99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16om4fv/implementation_of_reinforcement_learning_to/",
          "publishedOn": "2023-09-21T17:41:13.000Z",
          "wordCount": 2860,
          "title": "Implementation of Reinforcement Learning to achieve an autonomous drone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16occv3/cost_function_for_a_deep_q_network/",
          "author": null,
          "description": "I am using Game Maker and I just wanted to check if this is how to do the cost function.\n ​\n loss_function = 0 derivative_gradient = 0 array_copy(global.main_inputs,0,global.inputs,0,array_length(global.inputs)) for (var i = 0; i < array_length(buffer_sampling); i++) { var _reward = buffer_sampling[i][2] global.inputs = buffer_sampling[i][3] var _max_q = forward_prop_t()*global.gamma var yi = _reward + _max_q var cur_q_value = buffer_sampling[i][1][0] loss_function += power((yi - cur_q_value),2) derivative_gradient += 2*(cur_q_value - yi) } array_copy(global.inputs,0,global.main_inputs,0,array_length(global.main_inputs)) derivative_gradient = derivative_gradient*(1/array_length(buffer_sampling)) global.cost = loss_function*(1/array_length(buffer_sampling)) \n ​\n basically, buffer_sampling is an array with tuples of [first_state, [q_value,action], reward, next_state]\n Thanks for any help!\n    submitted by    /u/Daninjacat256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16occv3/cost_function_for_a_deep_q_network/",
          "publishedOn": "2023-09-21T10:31:01.000Z",
          "wordCount": 2614,
          "title": "Cost function for a deep q network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16o327t/building_intuition_on_ac_algo_with_td/",
          "author": null,
          "description": "I am trying to build intuition on why the actor update equation actually help the actor improving its policy. From what I understand, the update is proportional to the Critic's TD error. A better than expected reward will lead the actor to increase the prob of taking the associated action, and a disappointing reward will make the actor to move away from the given action.\n Here's where I feel like I'm missing a piece of the puzzle. Between a good state/action pair accurately valued by the Critic and a bad state/action pair undervalued by the Critic, the actor's update will favor the bad action more. Could we not conceive a scenario in which the agent gets stuck in a suboptimal policy because of that particular behavior?\n What triggers this questioning is that I have implemented a standard AC algo for Pixelcopter and found my agent getting stuck easily on a suboptimal policy (i.e. constantly getting higher, or lower until crash, while the critics assign good values on center squares and bad values to squares close to the wall's edge). For TD0, this is pretty marginal, but gets more significant for n-step TD as n increases.\n Any thoughts?\n    submitted by    /u/infundibuliforme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16o327t/building_intuition_on_ac_algo_with_td/",
          "publishedOn": "2023-09-21T01:45:09.000Z",
          "wordCount": 2719,
          "title": "Building intuition on AC algo with TD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16o2fvd/r_the_league_of_robot_runners_coordinate/",
          "author": null,
          "description": "Hello machine and reinforcement learners!\n This is an announcement and call for participation in the League of Robot Runners, a new 🚀 competition and research initiative 🚀 that tackles one of the most challenging problems in industrial optimisation: Multi-Robot Path Planning (sometimes also called Multi-Agent Path Finding). \n Recently launched at ICAPS 2023, the competition is inspired by a variety of new and newly emerging applications that rely on mobile robotics 🦾🤖. For example, Amazon automated warehouses, where up to thousands of robots work together to ensure safe and efficient package delivery 🧸📦 🚚 ❤️. \n Participants in the competition are asked to compute coordinated and collision-free movement plans ⤴️ ➡️ ⤵️ 🔄 for a team of robotic errand runners. Get the robots to their d…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16o2fvd/r_the_league_of_robot_runners_coordinate/",
          "publishedOn": "2023-09-21T01:16:47.000Z",
          "wordCount": 2854,
          "title": "[R] The League of Robot Runners: Coordinate thousands of robots in real time!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16nxhqs/is_ppo_a_good_algorithm_in_terms_of_exploration/",
          "author": null,
          "description": "I recently trained my PPO algorithm on one of my own custom environment. Although the episodic reward increased steadily in the beginning, After some time it just became constant with some occasional positive and negative spikes. I was wondering if it has something to do with the exploration problem with ppo. Any tips on how can I improve it? \n    submitted by    /u/Interesting-Weeb-699  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16nxhqs/is_ppo_a_good_algorithm_in_terms_of_exploration/",
          "publishedOn": "2023-09-20T21:43:20.000Z",
          "wordCount": 2601,
          "title": "Is PPO a good algorithm in terms of exploration?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16nw2fo/reinforcement_learning_and_rust/",
          "author": null,
          "description": "I'm a somewhat experienced dev, but never did anything related to ML or AI and want to start toying around with ML or reinforcement learning to be specific. Since my language of choice for almost everything is Rust I wanted to ask you guys if you have any advice on how to get started like crates, frameworks etc or if rust just isnt a good fit for ML.\n Thanks in advance for any help!\n    submitted by    /u/linus-eing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16nw2fo/reinforcement_learning_and_rust/",
          "publishedOn": "2023-09-20T20:48:03.000Z",
          "wordCount": 2611,
          "title": "reinforcement learning and rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16nsxdq/suggestions_of_gamefocused_customizable/",
          "author": null,
          "description": "Hello everyone!\n My research group is looking for new environments that are customizable and 3D such as Unity (and ML Agents). Although the latest changes in Unity TOS shouldn't affect us researchers, we wanted to keep an eye out for potential replacements for it. \n We are familiar with environments like ViZDoom and DeepMind Lab, but we're looking for more examples. The main requirements are:\n  \nCustomizable environment\n 3D Capable\n Free (preferably open-source, but being free is enough)\n  \nThanks for the help :D \n    submitted by    /u/romulofff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16nsxdq/suggestions_of_gamefocused_customizable/",
          "publishedOn": "2023-09-20T18:40:00.000Z",
          "wordCount": 2619,
          "title": "Suggestions of Game-Focused Customizable Environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16np0vv/rl_for_tuning/",
          "author": null,
          "description": "Hey guys, I am new to Reinforcement Learning and I am trying to understand how to go about a project I’m working on. I have a dataset with 2 features (X and Y). \n I am trying to tune a second order Transfer Function to fit X to Y( has 3 parameters) and gives Y’ as output.\n So I currently consider the error between Y and Y’ as the “State” and try to minimise the error by modelling a reward function that checks for instability and unreasonable values. I am trying to do this using TD3 but the model does not learn. I am wondering if there are any approaches that I should consider.\n I chose TD3 since my action space is continuous. \n I am sorry if I don’t understand something basic since I’m a noob to this. Thanks for your help in advance. :) \n Some more details: the dataset values don’t change. I give the same values for every time step. So I am not understanding how episodes and time steps work in this context.\n    submitted by    /u/ninjaaa30  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16np0vv/rl_for_tuning/",
          "publishedOn": "2023-09-20T16:02:55.000Z",
          "wordCount": 2711,
          "title": "RL for Tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16nmxn0/what_does_policy_collapse_mean/",
          "author": null,
          "description": "I am reading the following article on SpinningUp but can't get my head around policy collapse - \n \"This is different from normal policy gradient, which keeps new and old policies close in parameter space. But even seemingly small differences in parameter space can have very large differences in performance—so a single bad step can collapse the policy performance. This makes it dangerous to use large step sizes with vanilla policy gradients, thus hurting its sample efficiency. TRPO nicely avoids this kind of collapse, and tends to quickly and monotonically improve performance.\" \n Why would updating the parameters lead to a policy collapse? The parameters are updated based on the performance of the RL system and therefore, I don't see the point of constraints.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16nmxn0/what_does_policy_collapse_mean/",
          "publishedOn": "2023-09-20T14:37:53.000Z",
          "wordCount": 2660,
          "title": "What does policy collapse mean?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16nge79/ppo_action_masking_in_sb3/",
          "author": null,
          "description": "I'm using ppo action masking in sb3, which works well in training and masking the illegal / invalid actions according to my criteria. However, I have 2 problems during testing.\n ​\n  \nI use the same code for masking the actions in testing too since the model was unable to learn by itself during training action masking criteria and when enforcing it in code, it still doesn't mask anything.\n  \n​\n  \nThe model converges to just one action in testing phase after 500k steps, the episode reward still increasing the training phase though. I don't know why? maybe overfitting!\n  \nCode for training with action masking:\n def mask_fn(env: gym.Env) -> np.ndarray:\n return env.valid_action_mask()\n env = StockEnv(train)\n # Wrap the environment with ActionMasker and the mask_fn function\n env = ActionMasker(env, mask_fn)\n model = MaskablePPO(MaskableActorCriticPolicy, env, tensorboard_log=\"./tensorboard\" ,n_steps=2048 )\n for i in range (1,52):\n model.learn(total_timesteps=TIMESTEPS , tb_log_name = 'PPO2' , reset_num_timesteps=False)\n Code for testing with action masking:\n def mask_fn(env: gym.Env) -> np.ndarray:\n return env.valid_action_mask()\n env = ActionMasker(env, mask_fn)\n model_path = f\"{models_dir}/700000.zip\"\n model = MaskablePPO.load(model_path, env=env)\n episodes = 1\n for ep in range(episodes):\n obs = env.reset()\n done = False\n while not done:\n action, _states = model.predict(obs)\n obs, rewards, done, info = env.step(action)\n env.render() \n    submitted by    /u/Acceptable_Egg6552  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16nge79/ppo_action_masking_in_sb3/",
          "publishedOn": "2023-09-20T09:01:20.000Z",
          "wordCount": 2714,
          "title": "PPO Action masking in SB3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16nfhhy/knew_to_rlsome_question_about_the_reward_setting/",
          "author": null,
          "description": "The env is like mutil routing,for example i have 10 nodes in a map(2-d array), and i need to route them to the edge of the map,but the point where the node in the edge need to obey some rules,like the order need to be clockwise like below\n https://preview.redd.it/t9jlxvix8dpb1.png?width=545&format=png&auto=webp&s=16719a2dbd11333c454bd2ee71b87895a6414371\n so now my basic setting is,i use the action mask to invalid some forbidden action. When a node is routing to the edge of the map,i give +10 reward,if it's not obey the clockwise rule,i give -200 reward, if the whole node is routed success,i give +200 reward,and each steps does'n make any node routed, i give -1 reward.\n I am new to this area,i don't know the way i set reward if is good,may i have some advide?\n    submitted by    /u/Street_Helicopter_31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16nfhhy/knew_to_rlsome_question_about_the_reward_setting/",
          "publishedOn": "2023-09-20T08:01:46.000Z",
          "wordCount": 2668,
          "title": "Knew to RL.Some question about the reward setting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16n2irh/how_does_policy_learning_scale_for/",
          "author": null,
          "description": "I cannot wrap my head around how for e.g. a playlist building RL agent would perform on such a personal level ?\n What features would it use and would they be personal and general enough at the same time to select the best next song. Same goes for Netflix's recsys.\n    submitted by    /u/JurrasicBarf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16n2irh/how_does_policy_learning_scale_for/",
          "publishedOn": "2023-09-19T21:09:10.000Z",
          "wordCount": 2593,
          "title": "How does policy learning scale for personalization systems ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16mlc6j/why_my_ppo_agent_has_reach_the_max_reward_quickly/",
          "author": null,
          "description": "​\n https://preview.redd.it/2zmmd44u96pb1.png?width=1010&format=png&auto=webp&s=6ca51cc13a0eeedf72b40b853d2ce5d1c8a04504\n after i start the ppo train,the agent has reach the best solution in 2k or 3k steps,but the policy network seems to get better in 4M steps.\n the hyperparameter in sb3 as below\n model = MaskablePPO(\n \"MlpPolicy\",\n env=(DummyVecEnv([lambda: Monitor(gym.make('escape_gym-v0', size=10, node=10))] * 32)),\n verbose=0,\n learning_rate=1e-3,\n n_steps=2048,\n batch_size=64,\n n_epochs=16,\n gamma=0.99,\n tensorboard_log=\"./log/MASKPPO\"\n )\n    submitted by    /u/Street_Helicopter_31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16mlc6j/why_my_ppo_agent_has_reach_the_max_reward_quickly/",
          "publishedOn": "2023-09-19T08:25:59.000Z",
          "wordCount": 2596,
          "title": "why my ppo agent has reach the max reward quickly after begin the train, but the policy network proformance bad after many steps.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16mkuoa/ppo_forgets_everything/",
          "author": null,
          "description": "I was following the tutorial on Nicholas Renotte's channel on creating an AI to try to beat SMB. It starts off slowly learning and almost getting through the first level but then after a while of training it forgets everything and only runs right into the first enemy.\n It doesn't seem to learn again after this.\n I tried retaining and it did the same thing\n Any help on why this is happening or how to fix it would be appreciated.\n    submitted by    /u/NactusDevelopment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16mkuoa/ppo_forgets_everything/",
          "publishedOn": "2023-09-19T07:54:29.000Z",
          "wordCount": 2615,
          "title": "Ppo forgets everything",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16mfmi8/how_do_i_improve_my_sb3_ppo_on_an_envpool/",
          "author": null,
          "description": "I am looking to improve the overall performance as well as optimize the wall clock time. I slightly modified the code to develop a SB3 wrapper for envpool from here. \n ​\n Here's my code - \n from typing import Optional import gymnasium import numpy as np import torch as th from packaging import version from stable_baselines3 import PPO from stable_baselines3.common.env_util import make_vec_env from stable_baselines3.common.evaluation import evaluate_policy from stable_baselines3.common.vec_env import VecEnvWrapper, VecMonitor, VecNormalize from stable_baselines3.common.vec_env.base_vec_env import ( VecEnvObs, VecEnvStepReturn, ) import envpool from envpool.python.protocol import EnvPool # Force PyTorch to use only one threads # make things faster for simple envs import multiprocessing impor…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16mfmi8/how_do_i_improve_my_sb3_ppo_on_an_envpool/",
          "publishedOn": "2023-09-19T03:03:01.000Z",
          "wordCount": 2874,
          "title": "How do I improve my SB3 PPO on an EnvPool environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16m5u1e/agent_stops_learning_after_some_time/",
          "author": null,
          "description": "Hi,\n So I have been trying to make an agent learn to go to a specified goal. The algorithm used for training is PPO and the environment is custom made. The episodic reward i am getting increases steadily but after some time it just becomes constant with some occasional spikes. Can some one please help me figure out what the problem is?\n    submitted by    /u/Interesting-Weeb-699  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16m5u1e/agent_stops_learning_after_some_time/",
          "publishedOn": "2023-09-18T20:07:48.000Z",
          "wordCount": 2625,
          "title": "Agent stops learning after some time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16m4jk8/understanding_kl_stopping_and_kl_cutoff_for_the/",
          "author": null,
          "description": "I am reading a couple of review papers to optimize the PPO algorithm. It seems like the review papers are saying the same thing but used slightly different terms. Could someone please tell if the following terms are equivalent - \n This paper talks about Policy regularization using KL Divergence\n https://preview.redd.it/06xhizsuc2pb1.png?width=871&format=png&auto=webp&s=997a6506f7bf036b6538ecbff6402411f5cc6fe2\n Whereas thispaper uses the terms KL Stopping and KL Cutoff - \n ​\n https://preview.redd.it/sy0ihtr5d2pb1.png?width=747&format=png&auto=webp&s=f07677344077fe23cba5d1a0d2c5a7807359c64f\n I think \"Penalty\" from the first paper is the same as \"KL-cutoff\". Also \"Constraint\" from the first paper is the same as \"KL-Stopping\". Could someone let me know if I am correct?\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16m4jk8/understanding_kl_stopping_and_kl_cutoff_for_the/",
          "publishedOn": "2023-09-18T19:18:35.000Z",
          "wordCount": 2659,
          "title": "Understanding KL Stopping and KL Cutoff for the PPO algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16m3tld/cross_post_are_researchers_shifting_away_from_rl/",
          "author": null,
          "description": "Curious to get the takes of people in this sub: have you been moving away from RL? I myself have not, but have been seeing a shift recently.\n    submitted by    /u/sharky6000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16m3tld/cross_post_are_researchers_shifting_away_from_rl/",
          "publishedOn": "2023-09-18T18:51:44.000Z",
          "wordCount": 2595,
          "title": "Cross Post: Are Researchers Shifting away from RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16lv66h/collection_of_reinforcement_learning_x/",
          "author": null,
          "description": "Hey everyone,\n there is a small, albeit growing community of economists that apply deep reinforcement learning in their research. Now there is a GitHub repo to collect relevant literature at one place: https://github.com/SimonHashtag/EconRL\n The list is far from complete, so you are invited to contribute! \n The goal is to create something that makes it easy for novices to get a first overview of the literature. All others may find it easier to get news about up-to-date papers. \n    submitted by    /u/Tortoise_vs_Hare  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16lv66h/collection_of_reinforcement_learning_x/",
          "publishedOn": "2023-09-18T13:11:22.000Z",
          "wordCount": 2640,
          "title": "Collection of Reinforcement Learning x Economics/Finance Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16lss57/professionally_code_with_torch/",
          "author": null,
          "description": "I just concluded my PhD in Robotics & AI and I'd like to learn how to professionally code with Torch.\n Is there any book/resource you can recommend?\n    submitted by    /u/rossomalpelo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16lss57/professionally_code_with_torch/",
          "publishedOn": "2023-09-18T11:20:24.000Z",
          "wordCount": 2588,
          "title": "Professionally code with Torch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16l80ir/what_are_some_of_the_must_read_papers_in/",
          "author": null,
          "description": "I am particularly interested in the ideas that can have high research potential and impact to the RL field. \n    submitted by    /u/C7501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16l80ir/what_are_some_of_the_must_read_papers_in/",
          "publishedOn": "2023-09-17T18:21:36.000Z",
          "wordCount": 2587,
          "title": "What are some of the must read papers in reinforcement learning after 2020?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16l6bpz/which_suboptimum_is_harder_to_get_out/",
          "author": null,
          "description": "An agent is tasked to learn to navigate and collect orbs:\n Solution space in blue\n View Poll\n    submitted by    /u/FriendlyStandard5985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16l6bpz/which_suboptimum_is_harder_to_get_out/",
          "publishedOn": "2023-09-17T17:14:24.000Z",
          "wordCount": 2584,
          "title": "Which suboptimum is harder to get out?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16kxh3c/buildin_strong_agents_in_pettingzoomeltingpot/",
          "author": null,
          "description": "Hi, \n I would like to try test the adversarial policy (https://arxiv.org/abs/1905.10615) in petting-zoo/melting-pot environment. I wonder if there are any built-in agents besides random? Do you know any repos with Sota agents in one of those environments?\n    submitted by    /u/MrCogito_hs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16kxh3c/buildin_strong_agents_in_pettingzoomeltingpot/",
          "publishedOn": "2023-09-17T10:43:47.000Z",
          "wordCount": 2597,
          "title": "Build-in strong agents in petting-zoo/melting-pot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16kwm1t/multigpu_ppo_troubles/",
          "author": null,
          "description": "Hi all,\n I am training a small model (120k params) on a custom grid-world environment I built with JAX.\n I was able to train the model very well with PPO on 1 GPU, but when I scaled to multiple GPUs (tried with 6 in parallel), the training curves showed a lot more variance than what I was seeing on 1 GPU.\n I did not change the hyperparams, I just spawned the same number of environments (~7000 per GPU) on multiple devices. \n The multi-GPU setup works in the following way:\n - I keep parallel independent buffers, one on each device\n - I initialize identical models on each device\n - I get independent gradients on each device at the update step, then I take the mean of the gradients across the devices and then I backpropagate the same gradients on each device independently. (I checked that after some time the models are still identical, and that is the case). \n Now the question is, what could be the reason for such an increase in variance? What can I try to mitigate the problem?\n Here's a comparison of the entropy curves... \n P.S. The model still trains quite well, but I guess that if I manage to make the curves smoother it is going to train much faster and to a better performance.\n https://preview.redd.it/4m01uirjfsob1.png?width=1826&format=png&auto=webp&s=1e1a79b9f4cdefe019bb16ccb7e11fd92dd261e3\n    submitted by    /u/arbueticos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16kwm1t/multigpu_ppo_troubles/",
          "publishedOn": "2023-09-17T09:53:27.000Z",
          "wordCount": 2769,
          "title": "Multi-GPU PPO troubles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16kk42k/how_does_the_sb3_dqn_algorithms_predict_function/",
          "author": null,
          "description": "I noticed that the default argument for `deterministic` in DQN is false. But how would that work? Typically DQN is trained with a deterministic function approximator. How would the algorithm become stochastic during inference time? In DQN the final layer activation is linear and therefore I don't see how one could even make this algorithm stochastic, unlike policy gradient where the final layer is softmax or Normal. \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16kk42k/how_does_the_sb3_dqn_algorithms_predict_function/",
          "publishedOn": "2023-09-16T22:30:15.000Z",
          "wordCount": 2633,
          "title": "How does the SB3 DQN algorithm's `predict` function work for `deterministic=False`?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16k3zjp/how_does_recurrent_neural_network_implements/",
          "author": null,
          "description": "I have read these papers \"learning to reinforcement learn\" and \"PFC as meta RL system\". The authors claim that when RNN is trained on multiple tasks from a task distribution using a model free RL algorithm, another model based RL algorithm emerges within the activation dynamics of RNN. The RNN with resulting activations acts as a standalone model based RL system on a new task(from the same task distribution) even after freezing the weights of outer loop model free algorithm of that. I couldn't understand how an RNN with only fixed activations act as RL? Can someone help?\n    submitted by    /u/C7501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16k3zjp/how_does_recurrent_neural_network_implements/",
          "publishedOn": "2023-09-16T10:23:24.000Z",
          "wordCount": 2671,
          "title": "How does recurrent neural network implements model based RL system purely in its activation dynamics(In blackbox meta-rl setting)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16jzepp/seeking_guidance_on_reinforcement_learning_for/",
          "author": null,
          "description": "I'm currently exploring the application of reinforcement learning to address a challenge within the power market. Specifically, I'm focused on devising an optimal strategy for electricity bidding, encompassing both buying and selling options, across different hours of the day.\n Imagine we have a power generator capable of producing up to 800 MW of electricity daily, with a charging rate of up to 200 MW per hour. After continuously charging it for four hours, it reaches its maximum capacity, and further charging is restricted until some electricity is discharged. Our dataset spans the past 3 years and contains vital information such as temperature, hydro availability, gas prices, and locational marginal prices, which are pivotal in determining profitability. For instance, if we decide to pu…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16jzepp/seeking_guidance_on_reinforcement_learning_for/",
          "publishedOn": "2023-09-16T05:39:53.000Z",
          "wordCount": 2902,
          "title": "Seeking Guidance on Reinforcement Learning for Optimal Power Market Bidding Strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16jjwvu/double_dqn_do_not_learn_anything/",
          "author": null,
          "description": "Hi, i just finished the coursera ml course and i wanted to create myself a double dqn model but my model don't seem to learn anything, \n it always return very low rewards (-100 to -300) even after playing 2000 episodes. \n I've been stuck on this for 4 days without any hope to find the solution, any help would be welcome :')\n thank you in advance\n import random import numpy as np import gymnasium as gym import tensorflow as tf from collections import deque, namedtuple from tensorflow.keras import Sequential, Input from tensorflow.keras.layers import Dense from tensorflow.keras.optimizers import Adam from tensorflow.keras.losses import MeanSquaredError import matplotlib.pyplot as plt # function creating the models def createModel(inputSize, outputSize): model = Sequential([ Input(inputSize),…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16jjwvu/double_dqn_do_not_learn_anything/",
          "publishedOn": "2023-09-15T17:46:04.000Z",
          "wordCount": 3075,
          "title": "Double DQN do not learn anything",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16ji6oq/actorcritic_and_other_implementations/",
          "author": null,
          "description": "I'm confused with several algorithms that are based on an actor-critic approach. In TD3 and SAC, it is understandable that each of them is implemented to serve their purpose (deterministic and stachastic action). But in Dreamer algorithm (DreamerV3), why does it require to combine actor and critic network to the model-based planning approach, as the model-based also able to perform an action by planning to the simulation state. It is mean that using model-based to simulate the possible future then update the critic according to the simulation might sound good in training an agent?\n    submitted by    /u/AnnonymeowCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16ji6oq/actorcritic_and_other_implementations/",
          "publishedOn": "2023-09-15T16:37:30.000Z",
          "wordCount": 2653,
          "title": "Actor-Critic and other implementations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16irjth/does_c_in_mujoco_have_benefits_over_python_for/",
          "author": null,
          "description": "I'm trying to build a humanoid model and then train it to perform some tasks , I have decided to go with mujoco for the simulation and now I'm wondering if I should use the C++ API or the python one. the python implementation says it uses C API but is it good? Also if it's slower than the c++ one how slow is it? I'll probably have to make something real time and hence can't compromise much on the speed, but if it's only and small amount it's acceptable.\n would really appreciate some guidance in this matter\n thank you\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16irjth/does_c_in_mujoco_have_benefits_over_python_for/",
          "publishedOn": "2023-09-14T19:32:13.000Z",
          "wordCount": 2666,
          "title": "Does C++ in mujoco have benefits over python for reinforced learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16i7r1k/algorithmic_pricing_environments_for_rl/",
          "author": null,
          "description": "Hello, I am looking for environments to test out some ideas I have for algorithmic pricing. By algorithmic pricing environments, I mean there are multiple competing algorithms trying to maximize profits. \n I can't really find any out of the box implementations. There are trading environments but those are not what I am looking for.\n Any help would be appreciated, thanks. \n    submitted by    /u/Next_Gap8224  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16i7r1k/algorithmic_pricing_environments_for_rl/",
          "publishedOn": "2023-09-14T03:39:05.000Z",
          "wordCount": 2619,
          "title": "Algorithmic pricing environments for RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16i5zc9/some_confusion_about_using_mocap_in_mujoco/",
          "author": null,
          "description": "Hi!\n Recently, I tried to follow fetch_pick_and_place.env in gymnasium_robotics to build a similar environment with Franka.\n I found that the core of this implementation is to use the mocap to control the end-effector, and then mocap derives joint angles using the built-in inverse kinematics algorithm.\n For the fetch_pick_and_place.env, mocap does not cause mutations and oscillations in configuration space. However, when I use mocap to control Franka, oscillations in joint space occur frequently, although I've minimized the step size of the mocap to ensure that the movement of the end-effector in Cartesian space is minor. Fetch and Franka are both redundant arms, I don't know why there is such a big difference in mocap performance.\n Here is the video to illustrate the above phenomenon\n Franka\n I've opened issues on mujoco and gymnasium robotics repositories, but it didn't initiate any discussion.\n Any help would be appreciated! Thanks!\n ​\n    submitted by    /u/UpperSearch4172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16i5zc9/some_confusion_about_using_mocap_in_mujoco/",
          "publishedOn": "2023-09-14T02:11:13.000Z",
          "wordCount": 2707,
          "title": "Some confusion about using mocap in Mujoco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16hz4vu/a_generic_multiagent_scenario/",
          "author": null,
          "description": "I was thinking of some major challenges in modeling a generic real-world environment. Some of them are: adaptive agents, uncertain intentions, and lack of common knowledge.\n However, most of the papers I see on RL make some assumption or other violating one or more of these, like considering simple agents, assuming known knowledge about others' intentions, and considering that the models of other agents are known when irl an agent hardly has a model of other agents it interacts with apriori. \n Consider an airport scenario where agents are trying to get into respective planes within a given time, and the gates to each plane allow one person at a time. Looking at the scenario from the view of a single agent, they know what they want, but they can't really make any assumptions about the intentions, strategy, and complexity of other agents beforehand. These other agents can be neutral or adversarial (competing for getting in the same plane) from the agent's viewpoint. All they can see is a restricted view of the motions of some of the other agents.\n What would you say could model and provide a solution in such a scenario? It is to be noted that other agents can change their strategies based on actions taken by you till now, and so can you. Due to having incomplete information, I fail to see the notion of an equilibrium, and the agents needn't be fully rational as well.\n    submitted by    /u/Quirky_Concoction  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16hz4vu/a_generic_multiagent_scenario/",
          "publishedOn": "2023-09-13T21:17:46.000Z",
          "wordCount": 2799,
          "title": "A Generic Multi-Agent Scenario",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16he0m4/turbozero_a_vectorized_implementation_of/",
          "author": null,
          "description": "https://github.com/lowrollr/turbozero\n I've recently been working on TurboZero, a vectorized implementation of AlphaZero where model inference, search (MCTS), and environment simulation all run in parallel on the GPU. I've also implemented a self-contained training/evaluation pipeline, along with a few environments. I've written a wiki and a starter notebook for those who want to dig deeper. \n This project is similar to DeepMind's mctx, but supports MCTS subtree persistence (unnecessary for MuZero, which is what mctx was mainly built to support), is written with PyTorch rather than JAX, and can also stand on its own and train models end-to-end.\n I hope to continue to expand and improve upon this as time allows, and I hope someone here might find it useful or interesting! \n This is my first major open-source project of any real substance and I still don't have tons of experience with RL, so any feedback/advice is greatly appreciated. \n    submitted by    /u/lowrollr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16he0m4/turbozero_a_vectorized_implementation_of/",
          "publishedOn": "2023-09-13T05:06:20.000Z",
          "wordCount": 2710,
          "title": "TurboZero: a vectorized implementation of AlphaZero + more",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16h05t7/help_me_with_modeling_my_game_source_code_review/",
          "author": null,
          "description": "Hi! \n I am working on the implementation for DQN algorithm for one interesting game. This game is interesting because moves in this game are not affecting state of the game directly, but modify beliefs of other participants of the game and basically allow other agents to deduce role of other players in the game. It's game of \"Mafia\". Here's are the rules: \n Mafia Game description: \n Game is played with 10 players, players are getting roles at random. \n At the beginning of the game there's 3 players who gets Black cards (1 Don and 2 Mafia) and 7 players get Red cards\n (6 Citizen card and 1 Sheriff card). \n One team is playing against each other.\n Three black players knows each other and red players do not know who is red and who is black. \n Game is played with phases - \"Day\" and \"Night\". Du…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16h05t7/help_me_with_modeling_my_game_source_code_review/",
          "publishedOn": "2023-09-12T19:13:16.000Z",
          "wordCount": 3272,
          "title": "Help me with modeling my game (source code review)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com/",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=63331",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 10 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-10-october-2023/",
          "publishedOn": "2023-10-10T18:50:24.000Z",
          "wordCount": 6038,
          "title": "DSC Weekly 10 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63034",
          "author": "Ovais Naseem",
          "description": "Introduction  In an era where data is often termed the ‘new oil,’ its security holds unparalleled importance for businesses across industries. With the proliferation of digital platforms, sharing business-critical information has become routine yet perilous. From financial records to customer data, organizations frequently exchange sensitive information that, if compromised, could have dire consequences. Given the… Read More »How to ensure data security when sharing business-critical information\nThe post How to ensure data security when sharing business-critical information appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-ensure-data-security-when-sharing-business-critical-information/",
          "publishedOn": "2023-10-10T18:12:57.000Z",
          "wordCount": 6274,
          "title": "How to ensure data security when sharing business-critical information",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/images.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63303",
          "author": "John Lee",
          "description": "Gartner predicts blockchain’s economic impact to reach $176 billion by 2025 and $3.1 trillion by 2030. The AI software market is expected to reach $134.8 billion by 2025. Blockchain and AI benefit businesses. AI models process data, extract insights, and make decisions. Blockchain ensures data integrity and trust among participants. Read on to discover the… Read More »How does combining blockchain and AI create new business opportunities?\nThe post How does combining blockchain and AI create new business opportunities? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-does-combining-blockchain-and-ai-create-new-business-opportunities/",
          "publishedOn": "2023-10-10T16:23:00.000Z",
          "wordCount": 6505,
          "title": "How does combining blockchain and AI create new business opportunities?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/blockchain.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63315",
          "author": "Erika Balla",
          "description": "In the contemporary digital landscape, data has emerged as a critical asset for organizations aiming to make informed decisions and foster innovation. Data analytics can unlock a treasure trove of insights, driving competitive advantage and operational excellence by leveraging the vast amounts of data generated every second. As a consequence, the demand for skilled professionals… Read More »Understanding the difference: Data analyst, data scientist, and data engineer\nThe post Understanding the difference: Data analyst, data scientist, and data engineer appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understanding-the-difference-data-analyst-data-scientist-and-data-engineer/",
          "publishedOn": "2023-10-10T13:30:40.000Z",
          "wordCount": 7123,
          "title": "Understanding the difference: Data analyst, data scientist, and data engineer",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/1_iY8FOlPv0CJ3AOxQ7t8zHw.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63320",
          "author": "Bill Schmarzo",
          "description": "I’ve been in this industry for over 40 years (yes, I just started in the data and analytics industry when I was 11), and I have NEVER seen anything like Artificial Intelligence (AI) and Generative AI (GenAI) capture the attention of CEOs (and the dystopic fear of everyone else). Is AI a game-changer?  Definitely!  Will… Read More »11 Questions Every CEO Should Ask about AI / Generative AI\nThe post 11 Questions Every CEO Should Ask about AI / Generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/11-questions-every-ceo-should-ask-about-ai-generative-ai/",
          "publishedOn": "2023-10-10T11:44:54.000Z",
          "wordCount": 6813,
          "title": "11 Questions Every CEO Should Ask about AI / Generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Slide1-4.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63300",
          "author": "Evan Rogen",
          "description": "This cutting-edge area of AI focuses on building models that can create original material, including music, images, text, and even entire virtual worlds.\nThe post Revolutionizing business: A look at generative AI’s real-world impact appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/revolutionizing-business-a-look-at-generative-ais-real-world-impact/",
          "publishedOn": "2023-10-09T12:38:10.000Z",
          "wordCount": 6119,
          "title": "Revolutionizing business: A look at generative AI’s real-world impact",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Revolutionizing-Business-A-Look-at-Generative-AIs-Real-World-Impact.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63293",
          "author": "ajitjaokar",
          "description": "One of my students asked me: “Which is the best area/s for Gen AI start-ups?” This is not an easy question – mainly due to the dynamic nature of AI, but here are two reference points. The first is a Generative AI Tools Landscape from DataCamp. This gives both the categories and the subcategories for… Read More »Generative AI megatrends: Gen AI start-up ecosystem\nThe post Generative AI megatrends: Gen AI start-up ecosystem appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-gen-ai-start-up-ecosystem/",
          "publishedOn": "2023-10-05T23:14:16.000Z",
          "wordCount": 5699,
          "title": "Generative AI megatrends: Gen AI start-up ecosystem",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/AdobeStock_611053470-1024x574.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63291",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 3 October 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-3-october-2023/",
          "publishedOn": "2023-10-03T19:44:08.000Z",
          "wordCount": 5974,
          "title": "DSC Weekly 3 October 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63279",
          "author": "ajitjaokar",
          "description": "One of the most impressive generative AI applications I have seen is viperGPT. The image / site explains it best. The steps are: This example, earlier this year, showed the potential of multimodal LLMs And as of last week, that future is upon us ChatGPT can now see, hear & speak. What are the implications… Read More »Generative AI Megatrends: ChatGPT can see, hear and speak – but what does it mean when ChatGPT can think?\nThe post Generative AI Megatrends: ChatGPT can see, hear and speak – but what does it mean when ChatGPT can think? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-chatgpt-can-see-hear-and-speak-but-what-does-it-mean-when-chatgpt-can-think/",
          "publishedOn": "2023-10-03T19:33:40.000Z",
          "wordCount": 5992,
          "title": "Generative AI Megatrends: ChatGPT can see, hear and speak – but what does it mean when ChatGPT can think?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/Screenshot-2023-10-02-22.03.21-1-1024x372.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63283",
          "author": "Erika Balla",
          "description": "In the ever-evolving landscape of the digital era, the relentless quest for deriving actionable insights from a sea of information has become the cornerstone of innovation and strategy. As businesses and organizations strive to navigate the complex corridors of big data, the spotlight invariably falls upon the expertise of data scientists, the modern-day architects of… Read More »Cracking the code: The rising demand for data scientists in various industries\nThe post Cracking the code: The rising demand for data scientists in various industries appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/cracking-the-code-the-rising-demand-for-data-scientists-in-various-industries/",
          "publishedOn": "2023-10-03T19:32:39.000Z",
          "wordCount": 6387,
          "title": "Cracking the code: The rising demand for data scientists in various industries",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/The-Rising-Demand-for-Data-Scientists-in-Various-Industries.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63277",
          "author": "ajitjaokar",
          "description": "I recently subscribed to openAI GPT4 for the OpenAI Code Interpreter/Advanced data analytics. We are using it in our class at the University of Oxford.  Its really cool and we are also waiting the multimodal openAI features Recently, a well known AI critic said that he does not see how Generative AI companies could be… Read More »Generative AI megatrends: How many LLMs would you subscribe to?\nThe post Generative AI megatrends: How many LLMs would you subscribe to? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-how-many-llms-would-you-subscribe-to/",
          "publishedOn": "2023-10-03T19:31:10.000Z",
          "wordCount": 5667,
          "title": "Generative AI megatrends: How many LLMs would you subscribe to?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/10/cash-register-1885558_1280-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63259",
          "author": "Alan Morrison",
          "description": "Large language models (LLMs) for generating text and vision models for generating images are notoriously inefficient. The larger they get, the more power hungry they become.   Kisaco Research in September hosted a one-day event in Santa Clara dedicated to the topic of generative artificial intelligence (GAI) efficiency, followed by a three-day Summit on Hardware and… Read More »A few highlights of the Efficient Generative AI Summit (EGAIS)\nThe post A few highlights of the Efficient Generative AI Summit (EGAIS) appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-few-highlights-of-the-efficient-generative-ai-summit-egais/",
          "publishedOn": "2023-10-03T14:51:13.000Z",
          "wordCount": 6170,
          "title": "A few highlights of the Efficient Generative AI Summit (EGAIS)",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/image-from-rawpixel-id-5945466-jpeg-1024x310-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63273",
          "author": "Bill Schmarzo",
          "description": "We must move beyond just taming…to monetizing Language Models! In part 1 of this series on Small Language Models (“Use Case Language Models: Taming the LLM Beast – Part 1”), I explored the business and operational value of Use Case-specific Small Language Models (Use Case Language Models). Use case language models are trained or adapted… Read More »Entity Language Models: Monetizing Language Models – Part 2\nThe post <strong>Entity</strong> Language Models: <strong>Monetizing</strong> Language Models – Part 2 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/entity-language-models-monetizing-language-models-part-2/",
          "publishedOn": "2023-10-01T12:32:30.000Z",
          "wordCount": 6813,
          "title": "Entity Language Models: Monetizing Language Models – Part 2",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Slide4-2.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63254",
          "author": "Rytis Ulys",
          "description": "Big data has been around for some time now, becoming a more or less common concept in business. However, recent developments in AI technology have shaken up an already volatile field, inviting us to reconsider our projections of how the big data market will look in the future. We can already see the signs that… Read More »How will the Big Data market evolve in the future?\nThe post How will the Big Data market evolve in the future? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-will-the-big-data-market-evolve-in-the-future/",
          "publishedOn": "2023-09-28T17:53:26.000Z",
          "wordCount": 6494,
          "title": "How will the Big Data market evolve in the future?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_245562438-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63248",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 26 September 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-26-september-2023/",
          "publishedOn": "2023-09-26T19:11:05.000Z",
          "wordCount": 5929,
          "title": "DSC Weekly 26 September 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63246",
          "author": "Alan Morrison",
          "description": "A podcast with Weimo Liu and Sam Magnus of PuppyGraph Open source Apache Iceberg, Hudi and Delta Lake have made it possible to dispense with the complexities and duplication of data warehousing. Instead of requiring time-consuming extract, transform and load (ETL) procedures, these large table formats make it simple to tap S3 and other repositories… Read More »Doing graph + tabular analytics directly on modern data lakes\nThe post Doing graph + tabular analytics directly on modern data lakes appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/doing-graph-tabular-analytics-directly-on-modern-data-lakes-2/",
          "publishedOn": "2023-09-26T19:02:19.000Z",
          "wordCount": 5890,
          "title": "Doing graph + tabular analytics directly on modern data lakes",
          "enclosure": {
            "url": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Samuel-Magnus-Weimo-Liu-TFDF.mp3",
            "length": "37188440",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/lake-2676736_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63218",
          "author": "John Lee",
          "description": "E-commerce has improved technology and convenience for consumers globally. Fraud is a problem in e-commerce. Merchants and platforms fight fraud to protect their businesses and customers. Anomaly detection is a powerful tool for identifying irregular patterns and potential fraud. This article explores how anomaly detection is used in fraud detection for e-commerce and discusses different… Read More »In fraud detection for e-commerce: How does anomaly detection fit in and what are the key approaches?\nThe post In fraud detection for e-commerce: How does anomaly detection fit in and what are the key approaches? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/in-fraud-detection-for-e-commerce-how-does-anomaly-detection-fit-in-and-what-are-the-key-approaches/",
          "publishedOn": "2023-09-25T17:35:00.000Z",
          "wordCount": 6724,
          "title": "In fraud detection for e-commerce: How does anomaly detection fit in and what are the key approaches?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_613025532-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63236",
          "author": "Nakivo Backup &#38; Replication",
          "description": "Thanks to the internet, you can now easily expand your reach and engage with diverse audiences wherever they are. However, this opportunity raises an important question: how can you localize your web content and maintain the security and privacy of sensitive data? This article comprehensively explores the best practices that will help you maintain data… Read More »The essential guide on data security and privacy in web localization\nThe post The essential guide on data security and privacy in web localization appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-essential-guide-on-data-security-and-privacy-in-web-localization/",
          "publishedOn": "2023-09-25T16:44:12.000Z",
          "wordCount": 6569,
          "title": "The essential guide on data security and privacy in web localization",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_267969101-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63210",
          "author": "Alan Morrison",
          "description": "A major aspect of ongoing data center redesign is due to AI’s massive, complex workloads and the need to add many more graphic processing units (GPUs), tensor processing units (TPUs) or accelerators to the mix. The power these units require and the heat the units generate have forced designers to rethink what constitutes a feasible… Read More »How AI growth has triggered data center redesign\nThe post How AI growth has triggered data center redesign appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-ai-growth-has-triggered-data-center-redesign/",
          "publishedOn": "2023-09-25T16:08:31.000Z",
          "wordCount": 6131,
          "title": "How AI growth has triggered data center redesign",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/image-from-rawpixel-id-5922843-jpeg-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63231",
          "author": "Bill Schmarzo",
          "description": "“Sometimes, you don’t know where you’re going until you get there.” – Schmarzo-ism? Yes, writing this blog turned into a journey. I started in one direction, but after several twists and turns, I ended up with this concept – that use case-centric language models can be combined into entity-centric language models that can support multiple… Read More »Use Case Language Models: Taming the LLM Beast – Part 1\nThe post Use Case Language Models: Taming the LLM Beast – Part 1 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/use-case-language-models-taming-the-llm-beast-part-1/",
          "publishedOn": "2023-09-23T11:51:33.000Z",
          "wordCount": 6735,
          "title": "Use Case Language Models: Taming the LLM Beast – Part 1",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Slide1-3.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63223",
          "author": "Alan Morrison",
          "description": "A podcast with Weimo Liu and Sam Magnus of PuppyGraph Open source Apache Iceberg, Hudi and Delta Lake have made it possible to dispense with the complexities and duplication of data warehousing. Instead of requiring time-consuming extract, transform and load (ETL) procedures, these large table formats make it simple to tap S3 and other repositories… Read More »Doing graph + tabular analytics directly on modern data lakes\nThe post Doing graph + tabular analytics directly on modern data lakes appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/doing-graph-tabular-analytics-directly-on-modern-data-lakes/",
          "publishedOn": "2023-09-22T18:35:56.000Z",
          "wordCount": 5830,
          "title": "Doing graph + tabular analytics directly on modern data lakes",
          "enclosure": {
            "url": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Samuel-Magnus-Weimo-Liu-TFDF.mp3",
            "length": "37188440",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/lake-2676736_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63214",
          "author": "Aileen Scott",
          "description": "Discover the obstacles hindering seamless AI adoption in financial services and gain actionable insights to navigate regulatory compliance, data security, organizational change, and more.\nThe post AI in finance: Addressing hurdles on the path to transformation appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-in-finance-addressing-hurdles-on-the-path-to-transformation/",
          "publishedOn": "2023-09-22T13:08:25.000Z",
          "wordCount": 6469,
          "title": "AI in finance: Addressing hurdles on the path to transformation",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_620089764-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63209",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 19 September 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-19-september-2023/",
          "publishedOn": "2023-09-19T19:24:46.000Z",
          "wordCount": 5890,
          "title": "DSC Weekly 19 September 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63203",
          "author": "Abhi Sawhney",
          "description": "Where do you start if you want to build a data analytics function from the ground up? As an analytics leader at a startup, you will need to make several important decisions early on to build an effective team. This article dives into four decision areas and highlights ways in which to think about them:… Read More »A guide to setting up analytics at a consumer tech startup\nThe post A guide to setting up analytics at a consumer tech startup appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-guide-to-setting-up-analytics-at-a-consumer-tech-startup/",
          "publishedOn": "2023-09-19T12:57:50.000Z",
          "wordCount": 7538,
          "title": "A guide to setting up analytics at a consumer tech startup",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/pasted-image-0.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63194",
          "author": "Roger Brown",
          "description": "The two most prominent technologies that have been making waves in the AI industry are Conversational AI and Generative AI. They have revolutionized the manner in which humans interact and work with machines to generate content. Both these technologies have the power and capability to automate numerous tasks that humans would take hours, days, and… Read More »A complete guide: Conversational AI vs. generative AI\nThe post A complete guide: Conversational AI vs. generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-complete-guide-conversational-ai-vs-generative-ai/",
          "publishedOn": "2023-09-19T12:50:07.000Z",
          "wordCount": 5939,
          "title": "A complete guide: Conversational AI vs. generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Generative-AI-vs-Conversational-AI-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63190",
          "author": "Bill Schmarzo",
          "description": "In part 1 of this series on the updated “AI Apps Development Canvas,” I introduced the updated AI Apps Product Development Design Canvas.  The AI Apps Product Development Canva is one of the capstone deliverables for my “Thinking Like a Data Scientist” methodology, so getting feedback is critical to ensure that the methodology is relevant… Read More »AI Apps Product Development Canvas – Part 2\nThe post AI Apps Product Development Canvas – Part 2 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-apps-product-development-canvas-part-2/",
          "publishedOn": "2023-09-16T19:31:27.000Z",
          "wordCount": 7633,
          "title": "AI Apps Product Development Canvas – Part 2",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Slide1-2.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63162",
          "author": "Aileen Scott",
          "description": "Working as a data scientist is the dream of many IT professionals these days. It is no secret that data science is a skyrocketing field attracting young professionals and inspiring many to switch careers to data science. On one front are young professionals who study their courses in colleges to pursue their dream of becoming… Read More »Are data science certifications the gateway to competitive pay?\nThe post Are data science certifications the gateway to competitive pay? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/are-data-science-certifications-the-gateway-to-competitive-pay/",
          "publishedOn": "2023-09-14T15:10:15.000Z",
          "wordCount": 5775,
          "title": "Are data science certifications the gateway to competitive pay?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Top-Reasons-to-choose-Data-Scientist-Certification-from-DASCA.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63132",
          "author": "Igor Khomyanin",
          "description": "CUPED: Improve Your A/B Testing - Detect Smaller Gains, Utilise Smaller Samples and Make Smarter Decisions!\nThe post CUPED for starters: Enhancing controlled experiments with pre-experiment data appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/cuped-for-starters-enhancing-controlled-experiments-with-pre-experiment-data/",
          "publishedOn": "2023-09-14T15:01:10.000Z",
          "wordCount": 7802,
          "title": "CUPED for starters: Enhancing controlled experiments with pre-experiment data",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/CUPED_proof_1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63139",
          "author": "Jane Marsh",
          "description": "Data centers are known for their impact on the environment. They run 24/7 and exude a lot of heat. Massive warehouses full of hot technology require advanced cooling systems or an HVAC system pushed to its limit.  Data center managers and sustainability leaders no longer settle for antiquated techniques. They’re striving to develop greener and… Read More »Searching for sustainability in data center cooling\nThe post Searching for sustainability in data center cooling appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/searching-for-sustainability-in-data-center-cooling/",
          "publishedOn": "2023-09-14T14:58:36.000Z",
          "wordCount": 5881,
          "title": "Searching for sustainability in data center cooling",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_467140979-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63136",
          "author": "Alan Morrison",
          "description": "The best way to model business and consumer dynamics is collaboratively, with stakeholders all in the same virtual room contributing. Of course, this has been happening asynchronously for some time now, but the potential exists for more real-time interaction.  Modelers don’t work in a vacuum, of course. The iterations between a modeler who develops a… Read More »Collaborative visual knowledge graph modeling at the system level\nThe post Collaborative visual knowledge graph modeling at the system level appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/collaborative-visual-knowledge-graph-modeling-at-the-system-level/",
          "publishedOn": "2023-09-14T14:52:10.000Z",
          "wordCount": 6114,
          "title": "Collaborative visual knowledge graph modeling at the system level",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/fiber-optic-2749588_1280-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63121",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 12 September 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-12-september-2023/",
          "publishedOn": "2023-09-12T19:59:49.000Z",
          "wordCount": 5900,
          "title": "DSC Weekly 12 September 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63117",
          "author": "Colin Priest",
          "description": "By Colin Priest, Chief Evangelist at FeatureByte Enterprises are increasingly implementing Artificial Intelligence (AI) into their operations. However, AI-ready data pipeline practices are still in their infancy, especially when it comes to IT security. The pervasiveness of “Spaghetti Code” Enterprises delving into AI data pipelines often find themselves wading through a mess of complex and… Read More »Securing your AI data pipeline with MLOps\nThe post <a></a>Securing your AI data pipeline with MLOps appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/securing-your-ai-data-pipeline-with-mlops/",
          "publishedOn": "2023-09-12T18:37:04.000Z",
          "wordCount": 6014,
          "title": "Securing your AI data pipeline with MLOps",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_612366399-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62265",
          "author": "Ovais Naseem",
          "description": "Businesses today constantly strive to gain a competitive edge in their marketing efforts.  Leveraging their data effectively to create data-driven campaigns is the best way to trump the competition. One of the best tools at their disposal to utilize their data is a data warehouse. Data warehousing is crucial in enhancing marketing and campaign management… Read More »Data Warehousing: The key to effective marketing campaign management\nThe post Data Warehousing: The key to effective marketing campaign management appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-warehousing-the-key-to-effective-marketing-campaign-management/",
          "publishedOn": "2023-09-12T18:31:24.000Z",
          "wordCount": 6231,
          "title": "Data Warehousing: The key to effective marketing campaign management",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/etl-data-warehouse-diagram-1.webp"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62852",
          "author": "Costanza Tagliaferi",
          "description": "The way we work has changed, with remote teams now a common part of the landscape. While remote work offers flexibility, it also brings challenges. Managing remote teams effectively is crucial to ensure productivity and collaboration. In this article, we’ll explore how using time tracking for remote teams can help manage employees’ performance better. Time-tracking… Read More »Data-driven insights: Improving remote team performance with time-tracking analytics\nThe post Data-driven insights: Improving remote team performance with time-tracking analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-driven-insights-improving-remote-team-performance-with-time-tracking-analytics/",
          "publishedOn": "2023-09-12T15:39:35.000Z",
          "wordCount": 6271,
          "title": "Data-driven insights: Improving remote team performance with time-tracking analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_638699899-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63099",
          "author": "Seven Kole",
          "description": "In the panorama of Artificial Intelligence (AI), Natural Language Understanding (NLU) stands as a citadel of computational wizardry. No longer in its nascent stage, NLU has matured into an irreplaceable asset for business intelligence. In this discussion, we delve into the advanced realms of NLU, unraveling its role in semantic comprehension, intent classification, and context-aware… Read More »AI for Natural Language Understanding (NLU)\nThe post <strong>AI for Natural Language Understanding (NLU)</strong> appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-for-natural-language-understanding-nlu/",
          "publishedOn": "2023-09-12T15:36:04.000Z",
          "wordCount": 6319,
          "title": "AI for Natural Language Understanding (NLU)",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/20945532-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63076",
          "author": "Ryan Williamson",
          "description": "The Internet of Things (IoT) has been transforming entertainment and has given it new ways of creating, delivering and consuming content. The wide-ranging utility of IoT devices has improved user experience while enhancing the safety and security of users. The media and entertainment (M&E) companies can leverage IoT technology to improve the overall quality of… Read More »How can IoT transform and benefit the entertainment industry?\nThe post How can IoT transform and benefit the entertainment industry? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-can-iot-transform-and-benefit-the-entertainment-industry/",
          "publishedOn": "2023-09-12T15:34:07.000Z",
          "wordCount": 5944,
          "title": "How can IoT transform and benefit the entertainment industry?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Role-of-IoT-in-the-Entertainment-Industry-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63064",
          "author": "Anas Baig",
          "description": "In our increasingly interconnected world, the digital realm has become both a frontier of innovation and a battleground of threats. As technology advances, so do the tactics of malicious actors who seek to exploit vulnerabilities in our digital infrastructure. The rapid evolution of cyber threats calls for a paradigm shift in defense strategies, and that’s… Read More »AI and the cyber challenge: Bridging vulnerabilities in modern defense strategies\nThe post AI and the cyber challenge: Bridging vulnerabilities in modern defense strategies appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-and-the-cyber-challenge-bridging-vulnerabilities-in-modern-defense-strategies/",
          "publishedOn": "2023-09-12T15:32:48.000Z",
          "wordCount": 6506,
          "title": "AI and the cyber challenge: Bridging vulnerabilities in modern defense strategies",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/ai-cybersecurity-risks.png"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=213076",
          "author": "John",
          "description": "The last couple article have looked at various kinds of mean. The Python code for four of these means is trivial: gm = lambda a, b: (a*b)**0.5 am = lambda a, b: (a + b)/2 hm = lambda a, b: 2*a*b/(a+b) chm = lambda a, b: (a**2 + b**2)/(a + b) But the arithmetic-geometric mean […]\nPython code for means first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/11/python-agm/",
          "publishedOn": "2023-10-11T16:05:18.000Z",
          "wordCount": 1572,
          "title": "Python code for means",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212976",
          "author": "John",
          "description": "in an earlier post I said that the arithmetic mean of two frequencies an octave apart is an interval of a perfect fifth, and the geometric mean gives a tritone. This post will look at a few other means. Intervals The harmonic mean (HM) gives a perfect fourth. The arithmetic-geometric mean (AGM) gives a pitch […]\nMore ways of splitting the octave first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/octave-means/",
          "publishedOn": "2023-10-11T02:53:02.000Z",
          "wordCount": 1801,
          "title": "More ways of splitting the octave",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212960",
          "author": "John",
          "description": "This afternoon I wrote a brief post about Terence Tao’s new paper A Maclaurin type inequality. That paper builds on two classical inequalities: Newton’s inequality and Maclaurin’s inequality. The previous post expanded a bit on Newton’s inequality. This post will do the same for Maclaurin’s inequality. As before, let x be a list of real […]\nMaclaurin’s inequality first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/maclaurins-inequality/",
          "publishedOn": "2023-10-11T01:12:29.000Z",
          "wordCount": 1371,
          "title": "Maclaurin’s inequality",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212956",
          "author": "John",
          "description": "The previous post mentioned Newton’s inequality. This post will explore this inequality. Let x be a list of real numbers and define Sn(x) to be the average over all products of n elements from x. Newton’s inequality says that Sn−1 Sn+1 ≤ S²n In more terminology more recent than Newton, we say that the sequence […]\nNewton’s inequality and log concave sequences first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/newton-logconcave/",
          "publishedOn": "2023-10-11T00:54:38.000Z",
          "wordCount": 1442,
          "title": "Newton’s inequality and log concave sequences",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212924",
          "author": "John",
          "description": "Terence Tao has a new paper out that relates to a couple things I’ve written about recently. Elementary symmetric polynomials came up when developing the general equations for tangent sum and hyperbolic tangent sum. The latter post goes into more detail. Before that, means of symmetric functions, not necessarily elementary polynomials or even polynomials, came up […]\nU statistics and a new paper by Terence Tao first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/statistics-and-tao/",
          "publishedOn": "2023-10-10T19:10:57.000Z",
          "wordCount": 1417,
          "title": "U statistics and a new paper by Terence Tao",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212884",
          "author": "John",
          "description": "The latest episode of Erik Seligman’s podcast is entitled The Grim State of Modern Pizza. Although you might not realize it from the title, the post is about fraud detection. GRIM stands for Granularity-Related Inconsistency of Means. In a nutshell, the test looks for means (averages) that are not possible on number theoretic grounds. If […]\nDetecting fraud with the GRIM test first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/grim-test/",
          "publishedOn": "2023-10-10T14:51:10.000Z",
          "wordCount": 1557,
          "title": "Detecting fraud with the GRIM test",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212860",
          "author": "John",
          "description": "A few weeks ago I wrote about how the dissonance of a musical interval is related to the complexity of the frequency ratio as a fraction, where complexity is measured by the sum of the numerator and denominator. Consonant intervals have simple frequency ratios and dissonant intervals have complex frequency ratios. By this measure, the […]\nTritone first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/10/tritone/",
          "publishedOn": "2023-10-10T13:42:14.000Z",
          "wordCount": 1784,
          "title": "Tritone",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212781",
          "author": "John",
          "description": "The relation between a function and its power series is subtle. In a calculus class you’ll see equations of the form “series = function” which may need some footnotes. Maybe the series only represents the function over part of its domain: the function extends further than the power series representation. Starting with the power series, […]\nWhen a function cannot be extended first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/09/when-a-function-cannot-be-extended/",
          "publishedOn": "2023-10-10T01:23:50.000Z",
          "wordCount": 1609,
          "title": "When a function cannot be extended",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212347",
          "author": "John",
          "description": "Yesterday I wrote a post that looked at the hyperbolic tangent sum for x and y strictly between −1 and 1. This sum arises when adding velocities in special relativity. The post ended with a description of the expression for in terms of elementary symmetric polynomials but did not offer a proof. This post will […]\nTanh and elementary symmetric polynomials first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/07/tanh-sum-proof/",
          "publishedOn": "2023-10-07T10:14:56.000Z",
          "wordCount": 1446,
          "title": "Tanh and elementary symmetric polynomials",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212270",
          "author": "John",
          "description": "Earlier this week I wrote about several ways to generalize trig functions. Since trig functions have addition theorems like a natural question is whether generalized trig functions also have addition theorems. Hyperbolic functions have well-known addition theorems analogous to the addition theorems above. This isn’t too surprising since circular and hyperbolic functions are fundamentally two […]\nAddition theorems first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/06/addition-theorems/",
          "publishedOn": "2023-10-06T20:26:55.000Z",
          "wordCount": 1704,
          "title": "Addition theorems",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212235",
          "author": "John",
          "description": "In the previous post I said I was trying remember where I’d seen the tangent sum applied. I mentioned a couple near misses, and it turns out that what I was trying to remember was another near miss. What I’d seen before was not the tangent sum but the hyperbolic tangent sum. Several people suggested […]\nHyperbolic tangent sum first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/06/hyperbolic-tangent-sum/",
          "publishedOn": "2023-10-06T13:01:26.000Z",
          "wordCount": 1534,
          "title": "Hyperbolic tangent sum",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212105",
          "author": "John",
          "description": "When I was writing my post on lemniscate functions yesterday, a line from the Wikipedia article seemed familiar for reasons I cannot place. Defining a tangent-sum operator as a ⊕ b := tan(arctan ⁡ a + arctan ⁡ b) gives cl² z ⊕ sl² z = 1. I feel like I’ve seen this tangent-sum used before, but […]\nTangent sum first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/05/tangent-sum/",
          "publishedOn": "2023-10-05T16:10:12.000Z",
          "wordCount": 1904,
          "title": "Tangent sum",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212049",
          "author": "John",
          "description": "We begin with a couple examples. First, the set of linear transformations from one vector space to another is itself a vector space. Second, the set of continuous linear operators from one Banach space to another is itself a Banach space. Or maybe better, this set can be made into a Banach space. In the […]\nEnriched categories first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/05/enriched-categories/",
          "publishedOn": "2023-10-05T16:05:10.000Z",
          "wordCount": 1839,
          "title": "Enriched categories",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212037",
          "author": "John",
          "description": "This is the fourth post in a series on generalizations of sine and cosine. The first post looked at defining sine as the inverse of the inverse sine. The reason for this unusual approach is that the inverse sine is given in terms of an arc length and an integral. We can generalize sine by […]\np-norm trig functions and “squigonometry” first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/p-norm-trig/",
          "publishedOn": "2023-10-05T01:19:58.000Z",
          "wordCount": 1551,
          "title": "p-norm trig functions and “squigonometry”",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212026",
          "author": "John",
          "description": "This is the third post in a series on generalizing sine and cosine. The previous post looked at a generalization of the sine and cosine functions that come from replacing a circle with a lemniscate, a curve that looks like a figure eight. This post looks at replacing the circle with a hyperbola. On the […]\nGeometric derivation of hyperbolic trig functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/hyperbolic-trig/",
          "publishedOn": "2023-10-05T00:29:43.000Z",
          "wordCount": 1541,
          "title": "Geometric derivation of hyperbolic trig functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=212000",
          "author": "John",
          "description": "In the previous post I said that you could define the inverse sine as the function that gives the arc length along a circle, then define sine to be the inverse of the inverse sine. The purpose of such a backward definition is that it generalizes to other curves besides the circle. For example, it […]\nLemniscate functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/lemniscate-functions/",
          "publishedOn": "2023-10-04T21:28:36.000Z",
          "wordCount": 1502,
          "title": "Lemniscate functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211932",
          "author": "John",
          "description": "In a recent post I mentioned in passing that trigonometry can be generalized from functions associated with a circle to functions associated with other curves. This post will go into that a little further. The equation of the unit circle is and so in the first quadrant The length of an arc from (1, 0) […]\nGeneralized trigonometry first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/04/generalized-trigonometry/",
          "publishedOn": "2023-10-04T14:28:06.000Z",
          "wordCount": 1566,
          "title": "Generalized trigonometry",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211792",
          "author": "John",
          "description": "Let G be a directed graph whose nodes are the positive integers and whose edges represent relations between two integers. In our first example we’ll draw an edge from x to y if x is a multiple of y. In our second example we’ll draw an edge from x to y if x ≥ y. […]\nFrom graph theory to category theory first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/03/graph-to-category/",
          "publishedOn": "2023-10-03T14:24:32.000Z",
          "wordCount": 1850,
          "title": "From graph theory to category theory",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211786",
          "author": "John",
          "description": "Test functions are how you can make sense of functions that aren’t really functions. The canonical example is the Dirac delta “function” that is infinite at the origin, zero everywhere else, and integrates to 1. That description is contradictory: a function that is 0 almost everywhere integrates to 0, even if you work in extended […]\nTest functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/03/test-functions/",
          "publishedOn": "2023-10-03T13:09:12.000Z",
          "wordCount": 1666,
          "title": "Test functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211753",
          "author": "John",
          "description": "This article will probably only be of interest to a small number of readers. Those unfamiliar with category theory may find it bewildering, and those well versed in category theory may find it trivial. My hope is that someone in between, someone just starting to get a handle on category theory, will find it helpful. […]\nGroups vs Abelian groups: Pedantic or profound? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/03/abelian-groups/",
          "publishedOn": "2023-10-03T11:54:54.000Z",
          "wordCount": 1999,
          "title": "Groups vs Abelian groups: Pedantic or profound?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211669",
          "author": "John",
          "description": "The Depths of Wikipedia twitter account posted a screenshot about supereggs that’s popular at the moment. It says there’s no way this is real. they must be making these words up above a screenshot from the Wikipedia article on supereggs saying The definition can be changed to have an equality rather than an inequality; this […]\nSupereggs, squigonometry, and squircles first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/02/supereggs/",
          "publishedOn": "2023-10-02T16:14:32.000Z",
          "wordCount": 1602,
          "title": "Supereggs, squigonometry, and squircles",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211654",
          "author": "John",
          "description": "Meredith Whittaker posted on Twitter that In addition to being the best in privacy, Signal is also the best in not subjecting you to corny ‘AI’ features no one asked for or wants. I love the phrase “corny AI.” That’s exactly what a lot of AI features are. “Would you like help composing that tweet?” […]\nCorny AI first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/02/corny-ai/",
          "publishedOn": "2023-10-02T13:36:03.000Z",
          "wordCount": 1421,
          "title": "Corny AI",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211618",
          "author": "John",
          "description": "The star-like image above is today’s exponential sum. The exponential sum page on my site generates a new image each day by putting the numbers of the day’s month, day, and year into the equation and connecting the partial sums in the complex plane. Here m is the month, d is the day, and y […]\nToday’s star first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/10/02/todays-star/",
          "publishedOn": "2023-10-02T12:00:04.000Z",
          "wordCount": 1589,
          "title": "Today’s star",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=211224",
          "author": "John",
          "description": "Coupon collector problem Suppose you have a bag of balls labeled 1 through 1,000. You draw draw balls one at a time and put them back after each draw. How many draws would you have to make before you’ve seen every ball at least once? This is the coupon collector problem with N = 1000, […]\nConsecutive coupon collector problem first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/30/consecutive-coupon-collector-problem/",
          "publishedOn": "2023-09-30T15:53:33.000Z",
          "wordCount": 1946,
          "title": "Consecutive coupon collector problem",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210990",
          "author": "John",
          "description": "Monte Carlo integration is not as simple in practice as it is often introduced. A homework problem might as you to integrate a function of two variables by selecting random points from a cube and counting how many of the points fall below the graph of the function. This would indeed give you an estimate […]\nRegular solids and Monte Carlo integration first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/29/platonic-solids-and-integration/",
          "publishedOn": "2023-09-29T15:20:23.000Z",
          "wordCount": 1838,
          "title": "Regular solids and Monte Carlo integration",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210860",
          "author": "John",
          "description": "The previous post describes the hoops I jumped through to enter Unicode characters on a Mac. Here’s a script to run from the command line that will copy Unicode characters to the system clipboard. It runs anywhere the Python module pyperclip runs. #!/usr/bin/env python3 import sys import pyperclip cp = sys.argv[1] ch = eval(f\"chr(0x{cp})\") print(ch) […]\nCross-platform way to enter Unicode characters first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/28/cross-platform-unicode/",
          "publishedOn": "2023-09-28T23:24:34.000Z",
          "wordCount": 1355,
          "title": "Cross-platform way to enter Unicode characters",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210849",
          "author": "John",
          "description": "Setting up Unicode on my MacBook took some research, so I’m leaving myself a note here if I need to do it again. Maybe it’ll help someone else too. From the System Settings dialog, go to Keyboard and click the Edit button next to Input Sources. Click on the + sign in the lower left […]\nUsing Unicode on MacOS first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/28/macos-unicode/",
          "publishedOn": "2023-09-28T23:21:11.000Z",
          "wordCount": 1538,
          "title": "Using Unicode on MacOS",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210500",
          "author": "John",
          "description": "About three years ago I ran across a strange coordinate system in which familiar functions lead to interesting plots. The system is called “circular coordinates” but it is not polar coordinates. This morning I was playing around with this again. Here’s a plot of f(x) = x. And here’s a plot of f(x) = cos(8x). […]\nCircular coordinate art first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/27/circular-coordinate-art/",
          "publishedOn": "2023-09-27T12:37:51.000Z",
          "wordCount": 1394,
          "title": "Circular coordinate art",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210363",
          "author": "John",
          "description": "Today’s date, US style, is 9/26/2023, and there is only one group, up to isomorphism, of size 9262023. You could verify this in Mathematica with the command FiniteGroupCount[9262023] which returns 1. For a given n, when is there only one group of size n? There are two requirements. First, n has to be the product […]\nWhen there is only one group of a given size first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/26/unique-group/",
          "publishedOn": "2023-09-26T21:57:20.000Z",
          "wordCount": 1468,
          "title": "When there is only one group of a given size",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210266",
          "author": "John",
          "description": "Simple groups are the building blocks of groups similar to the way prime numbers are the building blocks of integers. This post will unpack this analogy in two ways: How do simple groups compare to prime numbers? How does the composition of simple groups compare to the composition of prime numbers? The former analogy is […]\nAnalogy between prime numbers and simple groups first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/26/prime-numbers-simple-groups/",
          "publishedOn": "2023-09-26T15:31:18.000Z",
          "wordCount": 1810,
          "title": "Analogy between prime numbers and simple groups",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=210251",
          "author": "John",
          "description": "The word “normal” in mathematical nomenclature does not always means “usual” or “customary” as it does in colloquial English. Instead, it might that something has a convenient property. That is the case for normal subgroups. We can do things with normal subgroups that we cannot do with other subgroups, such as take quotients, and so […]\nNormal and non-normal subgroups first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/26/normal-and-non-normal-subgroups/",
          "publishedOn": "2023-09-26T12:06:59.000Z",
          "wordCount": 2141,
          "title": "Normal and non-normal subgroups",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209986",
          "author": "John",
          "description": "In the previous post I mentioned that a particular Mersenne prime would be unsuitable for cryptography. In fact, all Mersenne primes are unsuitable for cryptography. A prime number p is called “safe” if p = 2q + 1 where q is also a prime. Safe primes are called safe because p − 1 does not […]\nMersenne primes are unsafe first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/24/mersenne-primes-are-unsafe/",
          "publishedOn": "2023-09-24T20:59:01.000Z",
          "wordCount": 1655,
          "title": "Mersenne primes are unsafe",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209927",
          "author": "John",
          "description": "Electronic computers were invented before public key cryptography. Would public key cryptography have been possible before computers? The security of RSA encryption depends on the ratio of the difficulty of factoring relative to the difficulty of multiplication. This ratio was high, maybe higher, before modern computers. Suppose the idea of RSA encryption had occurred to […]\nVictorian public key cryptography first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/24/victorian-public-key-cryptography/",
          "publishedOn": "2023-09-24T19:50:07.000Z",
          "wordCount": 1713,
          "title": "Victorian public key cryptography",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209827",
          "author": "John",
          "description": "I like generating long LaTeX documents from org-mode because, for one thing, org-mode has nice section folding. But not everyone I work with uses Emacs, so its better to work in LaTeX directly rather than have Emacs generate LaTeX. AUCTeX has section folding for LaTeX documents, though so far I’ve only has limited success at […]\nNavigating a LaTeX file first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/23/navigating-latex/",
          "publishedOn": "2023-09-23T19:18:06.000Z",
          "wordCount": 1360,
          "title": "Navigating a LaTeX file",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209799",
          "author": "John",
          "description": "It’s surprisingly hard to find a complete list of HTML entities in the form of a data file. There are numerous sites that give lists, often incomplete, in a page formatted to be human-readable but not machine-readable. Here’s an XML file from the W3C. Here’s a two-column text file I created from the W3C data.\nHTML entity data first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/23/html-entity-data/",
          "publishedOn": "2023-09-23T16:24:30.000Z",
          "wordCount": 1416,
          "title": "HTML entity data",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209653",
          "author": "John",
          "description": "I’ve needed to use double-struck capital letters lately, also called blackboard bold. There are a few quirks in how they are represented in Unicode and in HTML entities, so I’m leaving some notes for myself here and for anyone else who might need to look this up. Unicode The double-struck capital letters are split into […]\nDouble-struck capital letters first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/22/double-struck-capital-letters/",
          "publishedOn": "2023-09-23T00:50:40.000Z",
          "wordCount": 1671,
          "title": "Double-struck capital letters",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209623",
          "author": "John",
          "description": "Here’s a quote from Don Zagier that I found in Larry Rolen’s lecture notes on modular forms. There are two facts about the distribution of prime numbers of which I hope to convince you so overwhelmingly that they will be permanently engraved in your hearts. The first is that, despite their simple definition and role […]\nPrimes, weeds, and military precision first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/22/prime-weeds/",
          "publishedOn": "2023-09-22T17:52:35.000Z",
          "wordCount": 1365,
          "title": "Primes, weeds, and military precision",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209581",
          "author": "John",
          "description": "A continued fraction of the form with n terms can be written as the composition where As discussed in the previous post, a Möbius transformation can be associated with a matrix. And the composition of Möbius transformations is associated with the product of corresponding matrices. So the continued fraction at the top of the post […]\nContinued fractions as matrix products first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/22/continued-fractions-as-matrix-products-2/",
          "publishedOn": "2023-09-22T12:12:46.000Z",
          "wordCount": 1410,
          "title": "Continued fractions as matrix products",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209563",
          "author": "John",
          "description": "A function of the form where ad – bc ≠ 0 is sometimes called a fractional linear transformation or a bilinear transformation. I usually use the name Möbius transformation. In what sense are Möbius transformations linear transformations? They’re nonlinear functions unless b = c = 0. And yet they’re analogous to linear transformations. For starters, […]\nFractional linear and linear first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/22/fractional-linear-and-linear/",
          "publishedOn": "2023-09-22T10:55:57.000Z",
          "wordCount": 1909,
          "title": "Fractional linear and linear",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=209483",
          "author": "John",
          "description": "The Awk programming language was named after the initials of its creators. In the preface to a book that just came out, The AWK Programing Language, Second Edition, the authors give a little background on this. Naming a language after its creators shows a certain paucity of imagination. In our defense, we didn’t have a […]\nNaming Awk first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/21/naming-awk/",
          "publishedOn": "2023-09-21T22:51:37.000Z",
          "wordCount": 1306,
          "title": "Naming Awk",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208756",
          "author": "John",
          "description": "Warm up The geometric mean of two numbers is the square root of their product. For example, the geometric mean of 9 and 25 is 15. More generally, the geometric mean of a set of n numbers is the nth root of their product. Alternatively, the geometric mean of a set of n numbers the […]\nGeometric mean on unit circle first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/18/mahler-measure/",
          "publishedOn": "2023-09-18T21:04:10.000Z",
          "wordCount": 1530,
          "title": "Geometric mean on unit circle",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208642",
          "author": "John",
          "description": "The Gauss map [1] is the function where ⌊y⌋ is the floor of y, the greatest integer no larger than y. I’ve written about this map a couple times before. First, I wrote about how this map is measure-preserving. Second, I wrote about the image at the top of the post, based on Michael Trott’s […]\nGauss map, Euclidean algorithm, and continued fractions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/18/gauss-map/",
          "publishedOn": "2023-09-18T16:09:26.000Z",
          "wordCount": 1608,
          "title": "Gauss map, Euclidean algorithm, and continued fractions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208626",
          "author": "John",
          "description": "The goal of this post is to unpack a remark in [1]: … we can say this in fancier terms. Fix a field k …. We say that an elliptic curve E defined over k is that functor which … Well that is fancy. But what does it mean? Looking for objects A functor is […]\nAn elliptic curve is a functor first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/18/elliptic-curve-functor/",
          "publishedOn": "2023-09-18T16:06:31.000Z",
          "wordCount": 1891,
          "title": "An elliptic curve is a functor",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208489",
          "author": "John",
          "description": "The geometric description of addition of points P and Q on an elliptic curve involves four logical branches: If one of P or Q is the point at infinity … Else if P = Q … Else if P and Q lie on a vertical line … Else … It would seem that an algorithm […]\nElliptic curve addition formulas first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/17/elliptic-curve-addition-formulas/",
          "publishedOn": "2023-09-17T22:05:55.000Z",
          "wordCount": 1881,
          "title": "Elliptic curve addition formulas",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208565",
          "author": "John",
          "description": "Mathematicians often speak informally about the relative simplicity of rational numbers. For example, musical intervals that correspond to simple fractions have less tension than intervals that correspond to more complicated fractions. Such informal statements can be made more precise using height functions. There are a variety of height functions designed for different applications, but the […]\nRational height functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/17/rational-height-functions/",
          "publishedOn": "2023-09-17T18:39:15.000Z",
          "wordCount": 1659,
          "title": "Rational height functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208268",
          "author": "John",
          "description": "If you ask someone a question and they say “yes” immediately, that gives you different information than if they pause and slowly say “yes.” The information you receive is not just the response but also the time it took to generate the response. Encryption can be analogous. The time it takes to encrypt data can […]\nTiming attacks first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/15/timing-attacks/",
          "publishedOn": "2023-09-15T20:15:11.000Z",
          "wordCount": 1565,
          "title": "Timing attacks",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208277",
          "author": "John",
          "description": "I concluded the previous post by saying elliptic curve Diffie-Hellman key exchange (ECDHE) requires smaller keys than finite field Diffie-Hellman (FFDHE) to obtain the same level of security. How much smaller are we talking about? According to NIST recommendations, a 256-bit elliptic curve curve provides about the same security as working over a 3072-bit finite […]\nElliptic curve Diffie-Hellman key exchange first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/15/ecdhe/",
          "publishedOn": "2023-09-15T15:08:53.000Z",
          "wordCount": 1742,
          "title": "Elliptic curve Diffie-Hellman key exchange",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208147",
          "author": "John",
          "description": "Diffie-Hellman key exchange is conceptually simple. Alice and Bob want to generate a shared cryptographic key. They want to use asymmetric (public) cryptography to share a symmetric (private) key. The starting point is a large prime p and a generator 1 < g < p. Alice generates a large random number x, her private key, […]\nFinite field Diffie Hellman primes first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/15/ffdhe/",
          "publishedOn": "2023-09-15T10:31:46.000Z",
          "wordCount": 1805,
          "title": "Finite field Diffie Hellman primes",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208054",
          "author": "John",
          "description": "Suppose m = pq where p and q are large, distinct primes. In the previous post we said that calculations mod m can often be carried out more efficiently by working mod p and mod q, then combining the results to get back to a result mod m. The Chinese Remainder Theorem assures us that […]\nChinese Remainder Theorem synthesis algorithm first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/garners-algorithm/",
          "publishedOn": "2023-09-14T16:07:56.000Z",
          "wordCount": 1614,
          "title": "Chinese Remainder Theorem synthesis algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208061",
          "author": "John",
          "description": "Suppose m is a large integer that you are able to factor. To keep things simple, suppose m = pq where p and q are distinct primes; everything in this post generalizes easily to the case of m having more than two factors. You can carry out calculations mod m more efficiently by carrying out […]\nGaining efficiency by working modulo factors first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/crt-analysis/",
          "publishedOn": "2023-09-14T16:05:36.000Z",
          "wordCount": 1560,
          "title": "Gaining efficiency by working modulo factors",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208013",
          "author": "John",
          "description": "RSA encryption a map from numbers mod n to numbers mod n where n is a public key. A message is represented as an integer m and is encrypted by computing c = me mod n where e is part of the public key. In practice, e is usually 65537 though it does not have […]\nGroup theory and RSA encryption first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/rsa-group-theory/",
          "publishedOn": "2023-09-14T11:57:26.000Z",
          "wordCount": 2001,
          "title": "Group theory and RSA encryption",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207999",
          "author": "John",
          "description": "Not all messages encrypted with the RSA algorithm can be decrypted. This post will show why this is possible and why it does not matter in practice. RSA in a nutshell RSA encryption starts by finding two large primes, p and q. These primes are kept secret, but their product n = pq is made public. […]\nRSA encrypted messages that cannot be decrypted first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/rsa-decrypted/",
          "publishedOn": "2023-09-14T10:15:35.000Z",
          "wordCount": 1888,
          "title": "RSA encrypted messages that cannot be decrypted",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}