{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com/blog/",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=14330",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "The gradient descent algorithm is one of the most popular techniques for training deep neural networks. It has many applications in fields such as computer vision, speech recognition, and natural language processing. While the idea of gradient descent has been around for decades, it’s only recently that it’s been applied to applications related to deep […]\nThe post Implementing Gradient Descent in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/implementing-gradient-descent-in-pytorch/",
          "publishedOn": "2022-11-26T20:28:14.000Z",
          "wordCount": 7592,
          "title": "Implementing Gradient Descent in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/michael-behrens-DA-iYgv8kjE-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14318",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a simple yet powerful technique for predicting the values of variables based on other variables. It is often used for modeling relationships between two or more continuous variables, such as the relationship between income and age, or the relationship between weight and height. Likewise, linear regression can be used to predict continuous […]\nThe post Training a Linear Regression Model in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/training-a-linear-regression-model-in-pytorch/",
          "publishedOn": "2022-11-24T17:24:24.000Z",
          "wordCount": 7119,
          "title": "Training a Linear Regression Model in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/ryan-tasto-chbXE4o0ryU-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14311",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a statistical technique for estimating the relationship between two variables. A simple example of linear regression is to predict the height of someone based on the square root of the person’s weight (that’s what BMI is based on). To do this, we need to find the slope and intercept of the line. […]\nThe post Making Linear Predictions in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/making-linear-predictions-in-pytorch/",
          "publishedOn": "2022-11-24T04:11:30.000Z",
          "wordCount": 6417,
          "title": "Making Linear Predictions in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/daryan-shamkhali-pMCbPPPBSkA-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14301",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Structuring the data pipeline in a way that it can be effortlessly linked to your deep learning model is an important aspect of any deep learning-based system. PyTorch packs everything to do just that. While in the previous tutorial, we used simple datasets, we’ll need to work with larger datasets in real world scenarios in […]\nThe post Loading and Providing Datasets in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/loading-and-providing-datasets-in-pytorch/",
          "publishedOn": "2022-11-19T01:57:22.000Z",
          "wordCount": 5933,
          "title": "Loading and Providing Datasets in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/uriel-sc-11KDtiUWRq4-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14298",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "In machine learning and deep learning problems, a lot of effort goes into preparing the data. Data is usually messy and needs to be preprocessed before it can be used for training a model. If the data is not prepared correctly, the model won’t be able to generalize well. Some of the common steps required […]\nThe post Using Dataset Classes in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/using-dataset-classes-in-pytorch/",
          "publishedOn": "2022-11-17T01:55:54.000Z",
          "wordCount": 6445,
          "title": "Using Dataset Classes in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/nasa-1lfI7wkGWZ4-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13195",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Derivatives are one of the most fundamental concepts in calculus. They describe how changes in the variable inputs affect the function outputs. The objective of this article is to provide a high-level introduction to calculating derivatives in PyTorch for those who are new to the framework. PyTorch offers a convenient way to calculate derivatives for […]\nThe post Calculating Derivatives in PyTorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/calculating-derivatives-in-pytorch/",
          "publishedOn": "2022-11-11T21:30:18.000Z",
          "wordCount": 6011,
          "title": "Calculating Derivatives in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/jossuha-theophile-H-CZjCQfsFw-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13183",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Two-dimensional tensors are analogous to two-dimensional metrics. Like a two-dimensional metric, a two-dimensional tensor also has $n$ number of rows and columns. Let’s take a gray-scale image as an example, which is a two-dimensional matrix of numeric values, commonly known as pixels. Ranging from ‘0’ to ‘255’, each number represents a pixel intensity value. Here, […]\nThe post Two-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/two-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-09T21:30:51.000Z",
          "wordCount": 6286,
          "title": "Two-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/dylan-nolte-NIrgENd0sAY-unsplash-scaled.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13157",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "PyTorch is an open-source deep learning framework based on Python language. It allows you to build, train, and deploy deep learning models, offering a lot of versatility and efficiency. PyTorch is primarily focused on tensor operations while a tensor can be a number, matrix, or a multi-dimensional array. In this tutorial, we will perform some […]\nThe post One-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/one-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-07T21:30:13.000Z",
          "wordCount": 6633,
          "title": "One-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2021/12/jo-szczepanska-9OKGEVJiTKk-unsplash.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14064",
          "author": "MLM Team",
          "description": "Sponsored Post   The unlimited access initiative presents a risk-free way to break into data science.     The online educational platform 365 Data Science launches the #21DaysFREE campaign and provides 100% free unlimited access to all content for three weeks. From November 1 to 21, you can take courses from renowned instructors and earn […]\nThe post 365 Data Science courses free until November 21 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/365-data-science-courses-free-until-november-21/",
          "publishedOn": "2022-11-02T15:50:51.000Z",
          "wordCount": 4628,
          "title": "365 Data Science courses free until November 21",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/mlm-365ds-20221102-1.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14006",
          "author": "MLM Team",
          "description": "Sponsored Post      Attend the Data Science Symposium 2022 on November 8 The Center for Business Analytics at the University of Cincinnati will present its annual Data Science Symposium 2022 on November 8. This all day in-person event will have three featured speakers and two tech talk tracks with four concurrent presentations in each track. The […]\nThe post Attend the Data Science Symposium 2022, November 8 in Cincinnati appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/uccsb-data-science-symposium-2022-cincinnati/",
          "publishedOn": "2022-11-01T15:16:00.000Z",
          "wordCount": 3115,
          "title": "Attend the Data Science Symposium 2022, November 8 in Cincinnati",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/10/mlm-uccsb-221018.png"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": null,
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "ae68f6155c59165ea89c256d155a8aeb692a6a14",
          "author": "Akhilesh Dube",
          "description": "Amazon Redshift is the most popular cloud data warehouse that is used by tens of thousands of customers to analyze exabytes of data every day. Many practitioners are extending these Redshift datasets at scale for machine learning (ML) using Amazon SageMaker, a fully managed ML service, with requirements to develop features offline in a code […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-ml-features-at-scale-with-amazon-sagemaker-feature-store-using-data-from-amazon-redshift/",
          "publishedOn": "2023-08-17T15:31:13.000Z",
          "wordCount": 3652,
          "title": "Build ML features at scale with Amazon SageMaker Feature Store using data from Amazon Redshift",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/03/ML-14589-Solution-overview-1216x630.png"
        },
        {
          "id": "73f54af2cde90c9b321b42fe4ec2f73bfb239a6b",
          "author": "Pranav Murthy",
          "description": "MLOps is a key discipline that often oversees the path to productionizing machine learning (ML) models. It’s natural to focus on a single model that you want to train and deploy. However, in reality, you’ll likely work with dozens or even hundreds of models, and the process may involve multiple complex steps. Therefore, it’s important […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/unlocking-efficiency-harnessing-the-power-of-selective-execution-in-amazon-sagemaker-pipelines/",
          "publishedOn": "2023-08-16T23:00:05.000Z",
          "wordCount": 2674,
          "title": "Unlocking efficiency: Harnessing the power of Selective Execution in Amazon SageMaker Pipelines",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/10/ML-14562-image002-1139x630.jpg"
        },
        {
          "id": "ca6339d52844c5d3cb2bc307303839a3b126a0d6",
          "author": "Ben Veasey",
          "description": "In this post, we demonstrate how to train self-supervised vision transformers on overhead imagery using Amazon SageMaker. Travelers collaborated with the Amazon Machine Learning Solutions Lab (now known as the Generative AI Innovation Center) to develop this framework to support and enhance aerial imagery model use cases.",
          "link": "https://aws.amazon.com/blogs/machine-learning/train-self-supervised-vision-transformers-on-overhead-imagery-with-amazon-sagemaker/",
          "publishedOn": "2023-08-16T16:00:15.000Z",
          "wordCount": 3457,
          "title": "Train self-supervised vision transformers on overhead imagery with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/24/dino_ben-1260x604.png"
        },
        {
          "id": "d391db0ecc44084e2432ff92f12d1b4279b4017a",
          "author": "Shirsha Ray Chaudhuri",
          "description": "In this post, we discuss how Thomson Reuters Labs created Open Arena, Thomson Reuters’s enterprise-wide large language model (LLM) playground that was developed in collaboration with AWS. The original concept came out of an AI/ML Hackathon supported by Simone Zucchet (AWS Solutions Architect) and Tim Precious (AWS Account Manager) and was developed into production using AWS services in under 6 weeks with support from AWS. AWS-managed services such as AWS Lambda, Amazon DynamoDB, and Amazon SageMaker, as well as the pre-built Hugging Face Deep Learning Containers (DLCs), contributed to the pace of innovation.",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-thomson-reuters-developed-open-arena-an-enterprise-grade-large-language-model-playground-in-under-6-weeks/",
          "publishedOn": "2023-08-16T15:48:59.000Z",
          "wordCount": 3708,
          "title": "How Thomson Reuters developed Open Arena, an enterprise-grade large language model playground, in under 6 weeks",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/07/ML-15061-1_Overview_Architecture--1079x630.jpg"
        },
        {
          "id": "472e2e60de6b1d7183f73bb808421396daeb25af",
          "author": "Shipra Kanoria",
          "description": "Customers are increasingly turning to product reviews to make informed decisions in their shopping journey, whether they’re purchasing everyday items like a kitchen towel or making major purchases like buying a car. These reviews have transformed into an essential source of information, enabling shoppers to access the opinions and experiences of other customers. As a […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-amazon-shopping-uses-amazon-rekognition-content-moderation-to-review-harmful-images-in-product-reviews/",
          "publishedOn": "2023-08-15T19:31:24.000Z",
          "wordCount": 1896,
          "title": "How Amazon Shopping uses Amazon Rekognition Content Moderation to review harmful images in product reviews",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/ml-13844-3-1260x542.png"
        },
        {
          "id": "0019967d375c0817b60561a59432efc54f4ce998",
          "author": "Gordon Wang",
          "description": "Digital assets are vital visual representations of products, services, culture, and brand identity for businesses in an increasingly digital world. Digital assets, together with recorded user behavior, can facilitate customer engagement by offering interactive and personalized experiences, allowing companies to connect with their target audience on a deeper level. Efficiently discovering and searching for specific […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/intelligent-video-and-audio-qa-with-multilingual-support-using-llms-on-amazon-sagemaker/",
          "publishedOn": "2023-08-15T15:14:09.000Z",
          "wordCount": 4854,
          "title": "Intelligent video and audio Q&A with multilingual support using LLMs on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/15/intelligent-video-sagemaker-1260x630.jpg"
        },
        {
          "id": "4a5f10994ec26c7690d7dfc241d4fb77690d5c77",
          "author": "Rajakumar Sampathkumar",
          "description": "Amazon SageMaker JumpStart is a machine learning (ML) hub offering algorithms, models, and ML solutions. With SageMaker JumpStart, ML practitioners can choose from a growing list of best performing and publicly available foundation models (FMs) such as BLOOM, Llama 2, Falcon-40B, Stable Diffusion, OpenLLaMA, Flan-T5/UL2, or FMs from Cohere and LightOn. In this post and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/zero-shot-and-few-shot-prompting-for-the-bloomz-176b-foundation-model-with-the-simplified-amazon-sagemaker-jumpstart-sdk/",
          "publishedOn": "2023-08-14T17:07:28.000Z",
          "wordCount": 5647,
          "title": "Zero-shot and few-shot prompting for the BloomZ 176B foundation model with the simplified Amazon SageMaker JumpStart SDK",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/14/zero-shot-prompting-bloomz-sagemaker-jumpstart.jpg"
        },
        {
          "id": "4f1c4b63ee8db9988e922652c22b42cf10dbb6f4",
          "author": "Tuana Celik",
          "description": "In this post, we showcase how to build an end-to-end generative AI application for enterprise search with Retrieval Augmented Generation (RAG) by using Haystack pipelines and the Falcon-40b-instruct model from Amazon SageMaker JumpStart and Amazon OpenSearch Service.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-production-ready-generative-ai-applications-for-enterprise-search-using-haystack-pipelines-and-amazon-sagemaker-jumpstart-with-llms/",
          "publishedOn": "2023-08-14T16:42:40.000Z",
          "wordCount": 3305,
          "title": "Build production-ready generative AI applications for enterprise search using Haystack pipelines and Amazon SageMaker JumpStart with LLMs",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/14/production-ready-genai-haystack.jpg"
        },
        {
          "id": "c64eb9acc71a14728412639ddf24536becadb72f",
          "author": "Sathya Balakrishnan",
          "description": "Amazon Translate is a neural machine translation service that delivers fast, high-quality, affordable, and customizable language translation. When you translate from one language to another, you want your machine translation to be accurate, fluent, and most importantly contextual. Domain-specific and language-specific customizable terminology is a key requirement for many government and commercial organizations. Custom terminology […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/amazon-translate-enhances-its-custom-terminology-to-improve-translation-accuracy-and-fluency/",
          "publishedOn": "2023-08-11T14:59:56.000Z",
          "wordCount": 1562,
          "title": "Amazon Translate enhances its custom terminology to improve translation accuracy and fluency",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/11/amazon-translate-enhances-fluency.jpg"
        },
        {
          "id": "6bcfbfb6e7f1ec95052da8f46eb334f56a323361",
          "author": "David Laredo",
          "description": "Natural language processing (NLP) is the field in machine learning (ML) concerned with giving computers the ability to understand text and spoken words in the same way as human beings can. Recently, state-of-the-art architectures like the transformer architecture are used to achieve near-human performance on NLP downstream tasks like text summarization, text classification, entity recognition, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/zero-shot-text-classification-with-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-08-11T14:56:51.000Z",
          "wordCount": 3394,
          "title": "Zero-shot text classification with Amazon SageMaker JumpStart",
          "enclosure": {
            "length": "49843630",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-13226/ML-13226-zstc-guide.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/31/ML-13226-Picture6-1219x630.png"
        },
        {
          "id": "74d8154c6042af7d531f3290dccfdea3e10fc94e",
          "author": "Jie Dong",
          "description": "In this post, we present a cross-account observability dashboard that provides a centralized view for monitoring SageMaker user activities and resources across multiple accounts. It allows the end-users and cloud management team to efficiently monitor what ML workloads are running, view the status of these workloads, and trace back different account activities at certain points of time.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-centralized-monitoring-and-reporting-solution-for-amazon-sagemaker-using-amazon-cloudwatch/",
          "publishedOn": "2023-08-10T14:48:27.000Z",
          "wordCount": 3522,
          "title": "Build a centralized monitoring and reporting solution for Amazon SageMaker using Amazon CloudWatch",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/28/ML-13521-dashboard-1260x578.png"
        },
        {
          "id": "c31ba9f6161236cada276eab650a8e20bd5e322b",
          "author": "Fabian Benitez-Quiroz",
          "description": "Creative advertising has the potential to be revolutionized by generative AI (GenAI). You can now create a wide variation of novel images, such as product shots, by retraining a GenAI model and providing a few inputs into the model, such as textual prompts (sentences describing the scene and objects to be produced by the model). […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/generate-creative-advertising-using-generative-ai-deployed-on-amazon-sagemaker/",
          "publishedOn": "2023-08-09T15:51:52.000Z",
          "wordCount": 2604,
          "title": "Generate creative advertising using generative AI deployed on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/23/ml14623-pic5.png"
        },
        {
          "id": "fe4b7176ee2cb00d55731c82d55cffc5048de587",
          "author": "Giuseppe Angelo Porcelli",
          "description": "Amazon SageMaker offers several ways to run distributed data processing jobs with Apache Spark, a popular distributed computing framework for big data processing. You can run Spark applications interactively from Amazon SageMaker Studio by connecting SageMaker Studio notebooks and AWS Glue Interactive Sessions to run Spark jobs with a serverless cluster. With interactive sessions, you […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/host-the-spark-ui-on-amazon-sagemaker-studio/",
          "publishedOn": "2023-08-08T14:56:37.000Z",
          "wordCount": 2022,
          "title": "Host the Spark UI on Amazon SageMaker Studio",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/08/host-spark-ui-sagemaker-1260x627.jpg"
        },
        {
          "id": "0d891430918fc0e8d35e838165355924f5d50203",
          "author": "Saurabh Trikande",
          "description": "Artificial intelligence (AI) adoption is accelerating across industries and use cases. Recent scientific breakthroughs in deep learning (DL), large language models (LLMs), and generative AI is allowing customers to use advanced state-of-the-art solutions with almost human-like performance. These complex models often require hardware acceleration because it enables not only faster training but also faster inference […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/deploy-thousands-of-model-ensembles-with-amazon-sagemaker-multi-model-endpoints-on-gpu-to-minimize-your-hosting-costs/",
          "publishedOn": "2023-08-08T14:50:24.000Z",
          "wordCount": 4014,
          "title": "Deploy thousands of model ensembles with Amazon SageMaker multi-model endpoints on GPU to minimize your hosting costs",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/08/deploy-thousands-of-models-1248x630.jpg"
        },
        {
          "id": "77a17a11d0aead706432a73843e10ef5fcb04866",
          "author": "James Poquiz",
          "description": "The video gaming industry has an estimated user base of over 3 billion worldwide1. It consists of massive amounts of players virtually interacting with each other every single day. Unfortunately, as in the real world, not all players communicate appropriately and respectfully. In an effort to create and maintain a socially responsible gaming environment, AWS […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/aws-performs-fine-tuning-on-a-large-language-model-llm-to-classify-toxic-speech-for-a-large-gaming-company/",
          "publishedOn": "2023-08-07T16:19:32.000Z",
          "wordCount": 3834,
          "title": "AWS performs fine-tuning on a Large Language Model (LLM) to classify toxic speech for a large gaming company",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/07/fine-tuning-llm-toxic-speech.jpg"
        },
        {
          "id": "d1805ab7deb9bfb3391ea7c0a40f3de550fb774f",
          "author": "Munish Dabra",
          "description": "Data preparation is a critical step in any data-driven project, and having the right tools can greatly enhance operational efficiency. Amazon SageMaker Data Wrangler reduces the time it takes to aggregate and prepare tabular and image data for machine learning (ML) from weeks to minutes. With SageMaker Data Wrangler, you can simplify the process of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-data-preparation-with-new-features-in-aws-sagemaker-data-wrangler/",
          "publishedOn": "2023-08-04T15:25:07.000Z",
          "wordCount": 3113,
          "title": "Optimize data preparation with new features in AWS SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/optimize-data-prepration.jpg"
        },
        {
          "id": "a2b1bc4198e78d6b2212663d4bbfe35684d07cf1",
          "author": "Arun Anand",
          "description": "Amazon Kendra is a highly accurate and simple-to-use intelligent search service powered by machine learning (ML). Amazon Kendra offers a suite of data source connectors to simplify the process of ingesting and indexing your content, wherever it resides. Valuable data in organizations is stored in both structured and unstructured repositories. An enterprise search solution should […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/index-your-alfresco-content-using-the-new-amazon-kendra-alfresco-connector/",
          "publishedOn": "2023-08-04T15:22:23.000Z",
          "wordCount": 3832,
          "title": "Index your Alfresco content using the new Amazon Kendra Alfresco connector",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/index-alfresco-kendra.jpg"
        },
        {
          "id": "916f79e9bd6042fdeef0f4597c4d9c4d2b84b1cb",
          "author": "Daryl Martis",
          "description": "This post is co-authored by Daryl Martis, Director of Product, Salesforce Einstein AI. This is the second post in a series discussing the integration of Salesforce Data Cloud and Amazon SageMaker. In Part 1, we show how the Salesforce Data Cloud and Einstein Studio integration with SageMaker allows businesses to access their Salesforce data securely […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-and-salesforce-data-cloud-integration-to-power-your-salesforce-apps-with-ai-ml/",
          "publishedOn": "2023-08-04T13:28:06.000Z",
          "wordCount": 4017,
          "title": "Use the Amazon SageMaker and Salesforce Data Cloud integration to power your Salesforce apps with AI/ML",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/featured-images-ML-14831-1120x630.jpg"
        },
        {
          "id": "6dfe21fba320ad0766e221ed41ad1fa0f05ca2a5",
          "author": "Daryl Martis",
          "description": "This post is co-authored by Daryl Martis, Director of Product, Salesforce Einstein AI. We’re excited to announce Amazon SageMaker and Salesforce Data Cloud integration. With this capability, businesses can access their Salesforce data securely with a zero-copy approach using SageMaker and use SageMaker tools to build, train, and deploy AI models. The inference endpoints are […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/bring-your-own-ai-using-amazon-sagemaker-with-salesforce-data-cloud/",
          "publishedOn": "2023-08-04T13:27:49.000Z",
          "wordCount": 1966,
          "title": "Bring your own AI using Amazon SageMaker with Salesforce Data Cloud",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/featured-images-ML-14150-1120x630.jpg"
        },
        {
          "id": "484db3a32281ed52711245b1b2a28e1a0738395f",
          "author": "Sonali Sahu",
          "description": "Data classification, extraction, and analysis can be challenging for organizations that deal with volumes of documents. Traditional document processing solutions are manual, expensive, error prone, and difficult to scale. AWS intelligent document processing (IDP), with AI services such as Amazon Textract, allows you to take advantage of industry-leading machine learning (ML) technology to quickly and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enhancing-aws-intelligent-document-processing-with-generative-ai/",
          "publishedOn": "2023-08-03T21:03:51.000Z",
          "wordCount": 2972,
          "title": "Enhancing AWS intelligent document processing with generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/How-to-get-started.png"
        },
        {
          "id": "d67642ddc18badec3079714f22048736b1af685b",
          "author": "Davide Gallitelli",
          "description": "Training and serving thousands of models requires a robust and scalable infrastructure, which is where Amazon SageMaker can help. SageMaker is a fully managed platform that enables developers and data scientists to build, train, and deploy ML models quickly, while also offering the cost-saving benefits of using the AWS Cloud infrastructure. In this post, we explore how you can use SageMaker features, including Amazon SageMaker Processing, SageMaker training jobs, and SageMaker multi-model endpoints (MMEs), to train and serve thousands of models in a cost-effective way. To get started with the described solution, you can refer to the accompanying notebook on GitHub.",
          "link": "https://aws.amazon.com/blogs/machine-learning/scale-training-and-inference-of-thousands-of-ml-models-with-amazon-sagemaker/",
          "publishedOn": "2023-08-03T15:05:18.000Z",
          "wordCount": 2296,
          "title": "Scale training and inference of thousands of ML models with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/21/ML_14247_001-982x630.jpg"
        },
        {
          "id": "2f187b6559dc9961698a191709d895142a1af1c2",
          "author": "Peter Chung",
          "description": "Amazon SageMaker Canvas is a visual interface that enables business analysts to generate accurate machine learning (ML) predictions on their own, without requiring any ML experience or having to write a single line of code. SageMaker Canvas’s intuitive user interface lets business analysts browse and access disparate data sources in the cloud or on premises, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-business-outcomes-with-70-performance-improvements-to-data-processing-training-and-inference-with-amazon-sagemaker-canvas/",
          "publishedOn": "2023-08-03T15:03:13.000Z",
          "wordCount": 1537,
          "title": "Accelerate business outcomes with 70% performance improvements to data processing, training, and inference with Amazon SageMaker Canvas",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/03/accelerate-business-outcomes.jpg"
        },
        {
          "id": "08cbe64d98b902ecbbf3bdfff6eb742b50522061",
          "author": "Michael Wallner",
          "description": "Computer vision (CV) is one of the most common applications of machine learning (ML) and deep learning. Use cases range from self-driving cars, content moderation on social media platforms, cancer detection, and automated defect detection. Amazon Rekognition is a fully managed service that can perform CV tasks like object detection, video segment detection, content moderation, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-and-train-computer-vision-models-to-detect-car-positions-in-images-using-amazon-sagemaker-and-amazon-rekognition/",
          "publishedOn": "2023-08-03T14:53:06.000Z",
          "wordCount": 3321,
          "title": "Build and train computer vision models to detect car positions in images using Amazon SageMaker and Amazon Rekognition",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/03/ML-5922-demo-v2-1253x630.jpg"
        },
        {
          "id": "a961dec7677d8fc197198ecf9f9fbd3ab483418e",
          "author": "James Wu",
          "description": "Generative AI has become a common tool for enhancing and accelerating the creative process across various industries, including entertainment, advertising, and graphic design. It enables more personalized experiences for audiences and improves the overall quality of the final products. One significant benefit of generative AI is creating unique and personalized experiences for users. For example, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-personalized-avatar-with-generative-ai-using-amazon-sagemaker/",
          "publishedOn": "2023-08-02T18:34:51.000Z",
          "wordCount": 4077,
          "title": "Build a personalized avatar with generative AI using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/02/avatar-generator.jpg"
        },
        {
          "id": "bf1992cff067be622b2fbc0b0528128dcb94e007",
          "author": "Durga Sury",
          "description": "SageMaker Distribution is a pre-built Docker image containing many popular packages for machine learning (ML), data science, and data visualization. This includes deep learning frameworks like PyTorch, TensorFlow, and Keras; popular Python packages like NumPy, scikit-learn, and pandas; and IDEs like JupyterLab. In addition to this, SageMaker Distribution supports conda, micromamba, and pip as Python […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/sagemaker-distribution-is-now-available-on-amazon-sagemaker-studio/",
          "publishedOn": "2023-08-02T16:43:38.000Z",
          "wordCount": 1659,
          "title": "SageMaker Distribution is now available on Amazon SageMaker Studio",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/27/featured-images-ML-14803.jpg"
        },
        {
          "id": "9e5578025e96d9ac193588c84fd557b4a05bb9ce",
          "author": "Bharathi Srinivasan",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning (ML). Amazon Kendra reimagines search for your websites and applications so your employees and customers can easily find the content they are looking for, even when it’s scattered across multiple locations and content repositories within your organization. Amazon Kendra supports a variety of document […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automate-caption-creation-and-search-for-images-at-enterprise-scale-using-generative-ai-and-amazon-kendra/",
          "publishedOn": "2023-08-02T16:41:11.000Z",
          "wordCount": 3865,
          "title": "Automate caption creation and search for images at enterprise scale using generative AI and Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/12/ML-14376-dog.png"
        },
        {
          "id": "4dcd970c366917e179e4ccb0ae4b3226624ac4a5",
          "author": "Cody Collins",
          "description": "In today’s rapidly evolving healthcare landscape, doctors are faced with vast amounts of clinical data from various sources, such as caregiver notes, electronic health records, and imaging reports. This wealth of information, while essential for patient care, can also be overwhelming and time-consuming for medical professionals to sift through and analyze. Efficiently summarizing and extracting […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/exploring-summarization-options-for-healthcare-with-amazon-sagemaker/",
          "publishedOn": "2023-08-01T16:18:11.000Z",
          "wordCount": 3980,
          "title": "Exploring summarization options for Healthcare with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/01/exploring-summarization.jpg"
        },
        {
          "id": "029fa01aab00ba059bb2c4dea65ccb92a529fe52",
          "author": "Sovik Nath",
          "description": "Advertising agencies can use generative AI and text-to-image foundation models to create innovative ad creatives and content. In this post, we demonstrate how you can generate new images from existing base images using Amazon SageMaker, a fully managed service to build, train, and deploy ML models for at scale. With this solution, businesses large and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/unlocking-creativity-how-generative-ai-and-amazon-sagemaker-help-businesses-produce-ad-creatives-for-marketing-campaigns-with-aws/",
          "publishedOn": "2023-08-01T16:07:55.000Z",
          "wordCount": 2361,
          "title": "Unlocking creativity: How generative AI and Amazon SageMaker help businesses produce ad creatives for marketing campaigns with AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/01/unlocking-creativity.jpg"
        },
        {
          "id": "6e0df33339b9d69180135f44d0365aab07316895",
          "author": "Michael Hsieh",
          "description": "Drug development is a complex and long process that involves screening thousands of drug candidates and using computational or experimental methods to evaluate leads. According to McKinsey, a single drug can take 10 years and cost an average of $2.6 billion to go through disease target identification, drug screening, drug-target validation, and eventual commercial launch. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-protein-folding-workflows-to-accelerate-drug-discovery-on-amazon-sagemaker/",
          "publishedOn": "2023-07-31T18:49:40.000Z",
          "wordCount": 4648,
          "title": "Build protein folding workflows to accelerate drug discovery on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/24/ML-13966_image_1-1247x630.png"
        },
        {
          "id": "9e80cb060b91fc116b0d34de8ee6d79177b5440c",
          "author": "Marcos Boaglio",
          "description": "If you are a business analyst, understanding customer behavior is probably one of the most important things you care about. Understanding the reasons and mechanisms behind customer purchase decisions can facilitate revenue growth. However, the loss of customers (commonly referred to as customer churn) always poses a risk. Gaining insights into why customers leave can […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/is-your-model-good-a-deep-dive-into-amazon-sagemaker-canvas-advanced-metrics/",
          "publishedOn": "2023-07-31T18:45:03.000Z",
          "wordCount": 4149,
          "title": "Is your model good? A deep dive into Amazon SageMaker Canvas advanced metrics",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/23/canvas-adv-metric-blog-image033-1260x580.png"
        },
        {
          "id": "ea51ece96c1f0e5780bdeb5ac665bbda0afa5913",
          "author": "June Won",
          "description": "Today we are excited to announce that Stable Diffusion XL 1.0 (SDXL 1.0) is available for customers through Amazon SageMaker JumpStart. SDXL 1.0 is the latest image generation model from Stability AI. SDXL 1.0 enhancements include native 1024-pixel image generation at a variety of aspect ratios. It’s designed for professional use, and calibrated for high-resolution […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-stable-diffusion-xl-with-amazon-sagemaker-jumpstart-in-amazon-sagemaker-studio/",
          "publishedOn": "2023-07-26T21:09:59.000Z",
          "wordCount": 3450,
          "title": "Use Stable Diffusion XL with Amazon SageMaker JumpStart in Amazon SageMaker Studio",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/ml-15160-image018-share.jpg"
        },
        {
          "id": "45df9e13aa8d2c9e4346f4b49aebb96cdcdfa796",
          "author": "Lana Zhang",
          "description": "The increase in online social activities such as social networking or online gaming is often riddled with hostile or aggressive behavior that can lead to unsolicited manifestations of hate speech, cyberbullying, or harassment. For example, many online gaming communities offer voice chat functionality to facilitate communication among their users. Although voice chat often supports friendly […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/flag-harmful-language-in-spoken-conversations-with-amazon-transcribe-toxicity-detection/",
          "publishedOn": "2023-07-26T18:48:17.000Z",
          "wordCount": 2340,
          "title": "Flag harmful language in spoken conversations with Amazon Transcribe Toxicity Detection",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/harmful-language-transcribe-1260x630.jpg"
        },
        {
          "id": "24f6299643a27c604568ebe4a5d18c25792dfae7",
          "author": "Vivek Gangasani",
          "description": "Generative AI models have been experiencing rapid growth in recent months due to its impressive capabilities in creating realistic text, images, code, and audio. Among these models, Stable Diffusion models stand out for their unique strength in creating high-quality images based on text prompts. Stable Diffusion can generate a wide variety of high-quality images, including […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/maximize-stable-diffusion-performance-and-lower-inference-costs-with-aws-inferentia2/",
          "publishedOn": "2023-07-26T16:37:10.000Z",
          "wordCount": 3516,
          "title": "Maximize Stable Diffusion performance and lower inference costs with AWS Inferentia2",
          "enclosure": {
            "length": "8479584",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-14708/ML-14708_demo.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/maximize-stable-diffusion-performance-1260x628.jpg"
        },
        {
          "id": "de48f99409df65a899600721f40313e6f5072b2a",
          "author": "Caleb Wilkinson",
          "description": "Breakthroughs in artificial intelligence (AI) and machine learning (ML) have been in the headlines for months—and for good reason. The emerging and evolving capabilities of this technology promises new business opportunities for customer across all sectors and industries. But the speed of this revolution has made it harder for organizations and consumers to assess what […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/aws-offers-new-artificial-intelligence-machine-learning-and-generative-ai-guides-to-plan-your-ai-strategy/",
          "publishedOn": "2023-07-26T16:30:40.000Z",
          "wordCount": 1874,
          "title": "AWS offers new artificial intelligence, machine learning, and generative AI guides to plan your AI strategy",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/25/generative-ai-guides-1260x630.jpg"
        },
        {
          "id": "fc28b7f09affe471cd04291b543db1974f4b6fb4",
          "author": "Emily Webber",
          "description": "Generative AI Foundations on AWS is a new technical deep dive course that gives you the conceptual fundamentals, practical advice, and hands-on guidance to pre-train, fine-tune, and deploy state-of-the-art foundation models on AWS and beyond. Developed by AWS generative AI worldwide foundations lead Emily Webber, this free hands-on course and the supporting GitHub source code […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/new-technical-deep-dive-course-generative-ai-foundations-on-aws/",
          "publishedOn": "2023-07-26T12:20:13.000Z",
          "wordCount": 1812,
          "title": "New technical deep dive course: Generative AI Foundations on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/25/Gen-AI-Foundations-Course-resized-1260x630.png"
        },
        {
          "id": "f68d0d6b4fc134ccc9ec193efb8173f70bf616d6",
          "author": "Peter Hallinan",
          "description": "As a pioneer in artificial intelligence and machine learning, AWS is committed to developing and deploying generative AI responsibly As one of the most transformational innovations of our time, generative AI continues to capture the world’s imagination, and we remain as committed as ever to harnessing it responsibly. With a team of dedicated responsible AI […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/aws-reaffirms-its-commitment-to-responsible-generative-ai/",
          "publishedOn": "2023-07-26T04:00:36.000Z",
          "wordCount": 1385,
          "title": "AWS Reaffirms its Commitment to Responsible Generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/aws-commitment-to-responsible-generative-ai-1260x628.jpg"
        },
        {
          "id": "e6cf42cd370b365438792942d951302067509d3f",
          "author": "Vikesh Pandey",
          "description": "With recent advancements in generative AI, there are lot of discussions happening on how to use generative AI across different industries to solve specific business problems. Generative AI is a type of AI that can create new content and ideas, including conversations, stories, images, videos, and music. It is all backed by very large models […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-generative-ai-foundation-models-in-vpc-mode-with-no-internet-connectivity-using-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-07-25T16:29:41.000Z",
          "wordCount": 2614,
          "title": "Use generative AI foundation models in VPC mode with no internet connectivity using Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/06/22/14480-sol-arch-1080x630.jpg"
        },
        {
          "id": "5acad1559c5977ab664629f8f12ddd6316f830a0",
          "author": "Hao Huang",
          "description": "This blog post was co-authored, and includes an introduction, by Zilong Bai, senior natural language processing engineer at Patsnap. You’re likely familiar with the autocomplete suggestion feature when you search for something on Google or Amazon. Although the search terms in these scenarios are pretty common keywords or expressions that we use in daily life, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-patsnap-used-gpt-2-inference-on-amazon-sagemaker-with-low-latency-and-cost/",
          "publishedOn": "2023-07-24T21:23:16.000Z",
          "wordCount": 2682,
          "title": "How Patsnap used GPT-2 inference on Amazon SageMaker with low latency and cost",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/24/patsnap-gpt-2.jpg"
        },
        {
          "id": "1258cb4db60d1f090fe8dc73bde2cf5c7e131899",
          "author": "Ankur Srivastava",
          "description": "When deploying Deep Learning models at scale, it is crucial to effectively utilize the underlying hardware to maximize performance and cost benefits. For production workloads requiring high throughput and low latency, the selection of the Amazon Elastic Compute Cloud (EC2) instance, model serving stack, and deployment architecture is very important. Inefficient architecture can lead to […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-aws-inferentia-utilization-with-fastapi-and-pytorch-models-on-amazon-ec2-inf1-inf2-instances/",
          "publishedOn": "2023-07-24T20:55:07.000Z",
          "wordCount": 4483,
          "title": "Optimize AWS Inferentia utilization with FastAPI and PyTorch models on Amazon EC2 Inf1 & Inf2 instances",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/24/optimize-inferentia-utilization.jpg"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2308.03382",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Junzhou Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_Q/0/1/0/all/0/1\">Qian Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yulin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qian_L/0/1/0/all/0/1\">Linyi Qian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_C/0/1/0/all/0/1\">Chengyuan Yu</a>",
          "description": "Nucleus image segmentation is a crucial step in the analysis, pathological\ndiagnosis, and classification, which heavily relies on the quality of nucleus\nsegmentation. However, the complexity of issues such as variations in nucleus\nsize, blurred nucleus contours, uneven staining, cell clustering, and\noverlapping cells poses significant challenges. Current methods for nucleus\nsegmentation primarily rely on nuclear morphology or contour-based approaches.\nNuclear morphology-based methods exhibit limited generalization ability and\nstruggle to effectively predict irregular-shaped nuclei, while contour-based\nextraction methods face challenges in accurately segmenting overlapping nuclei.\nTo address the aforementioned issues, we propose a dual-branch network using\nhybrid attention based residual U-blocks for nucleus instance segmentation. The\nnetwork simultaneously predicts target information and target contours.\nAdditionally, we introduce a post-processing method that combines the target\ninformation and target contours to distinguish overlapping nuclei and generate\nan instance segmentation image. Within the network, we propose a context fusion\nblock (CF-block) that effectively extracts and merges contextual information\nfrom the network. Extensive quantitative evaluations are conducted to assess\nthe performance of our method. Experimental results demonstrate the superior\nperformance of the proposed method compared to state-of-the-art approaches on\nthe BNS, MoNuSeg, CoNSeg, and CPM-17 datasets.",
          "link": "http://arxiv.org/abs/2308.03382",
          "publishedOn": "2023-08-12T00:39:31.817Z",
          "wordCount": null,
          "title": "Enhancing Nucleus Segmentation with HARU-Net: A Hybrid Attention Based Residual U-Blocks Network. (arXiv:2308.03382v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19069",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">Hongru Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tao_R/0/1/0/all/0/1\">Rui Tao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_S/0/1/0/all/0/1\">Shimeng Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jiansong Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_N/0/1/0/all/0/1\">Ning Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_W/0/1/0/all/0/1\">Wujin Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhanhu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>",
          "description": "Lesion segmentation of ultrasound medical images based on deep learning\ntechniques is a widely used method for diagnosing diseases. Although there is a\nlarge amount of ultrasound image data in medical centers and other places,\nlabeled ultrasound datasets are a scarce resource, and it is likely that no\ndatasets are available for new tissues/organs. Transfer learning provides the\npossibility to solve this problem, but there are too many features in natural\nimages that are not related to the target domain. As a source domain, redundant\nfeatures that are not conducive to the task will be extracted. Migration\nbetween ultrasound images can avoid this problem, but there are few types of\npublic datasets, and it is difficult to find sufficiently similar source\ndomains. Compared with natural images, ultrasound images have less information,\nand there are fewer transferable features between different ultrasound images,\nwhich may cause negative transfer. To this end, a multi-source adversarial\ntransfer learning network for ultrasound image segmentation is proposed.\nSpecifically, to address the lack of annotations, the idea of adversarial\ntransfer learning is used to adaptively extract common features between a\ncertain pair of source and target domains, which provides the possibility to\nutilize unlabeled ultrasound data. To alleviate the lack of knowledge in a\nsingle source domain, multi-source transfer learning is adopted to fuse\nknowledge from multiple source domains. In order to ensure the effectiveness of\nthe fusion and maximize the use of precious data, a multi-source domain\nindependent strategy is also proposed to improve the estimation of the target\ndomain data distribution, which further increases the learning ability of the\nmulti-source adversarial migration learning network in multiple domains.",
          "link": "http://arxiv.org/abs/2305.19069",
          "publishedOn": "2023-08-12T00:39:31.798Z",
          "wordCount": null,
          "title": "Multi-source adversarial transfer learning for ultrasound image segmentation with limited similarity. (arXiv:2305.19069v1 [eess.IV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orhan_A/0/1/0/all/0/1\">A. Emin Orhan</a>",
          "description": "This paper asks whether current self-supervised learning methods, if\nsufficiently scaled up, would be able to reach human-level visual object\nrecognition capabilities with the same type and amount of visual experience\nhumans learn from. Previous work on this question only considered the scaling\nof data size. Here, we consider the simultaneous scaling of data size, model\nsize, and image resolution. We perform a scaling experiment with vision\ntransformers up to 633M parameters in size (ViT-H/14) trained with up to 5K\nhours of human-like video data (long, continuous, mostly egocentric videos)\nwith image resolutions of up to 476x476 pixels. The efficiency of masked\nautoencoders (MAEs) as a self-supervised learning algorithm makes it possible\nto run this scaling experiment on an unassuming academic budget. We find that\nit is feasible to reach human-level object recognition capacity at sub-human\nscales of model size, data size, and image size, if these factors are scaled up\nsimultaneously. To give a concrete example, we estimate that a 2.5B parameter\nViT model trained with 20K hours (2.3 years) of human-like video data with a\nspatial resolution of 952x952 pixels should be able to reach roughly\nhuman-level accuracy on ImageNet. Human-level competence is thus achievable for\na fundamental perceptual capability from human-like perceptual experience\n(human-like in both amount and type) with extremely generic learning algorithms\nand architectures and without any substantive inductive biases.",
          "link": "http://arxiv.org/abs/2308.03712",
          "publishedOn": "2023-08-12T00:39:31.783Z",
          "wordCount": null,
          "title": "Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience. (arXiv:2308.03712v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_Carrasco_M/0/1/0/all/0/1\">Manuel P&#xe9;rez-Carrasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cabrera_Vives_G/0/1/0/all/0/1\">Guillermo Cabrera-Vives</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Garcia_L/0/1/0/all/0/1\">Lorena Hern&#xe1;ndez-Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forster_F/0/1/0/all/0/1\">Francisco Forster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Saez_P/0/1/0/all/0/1\">Paula S&#xe1;nchez-S&#xe1;ez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arancibia_A/0/1/0/all/0/1\">Alejandra Mu&#xf1;oz Arancibia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astorga_N/0/1/0/all/0/1\">Nicol&#xe1;s Astorga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_F/0/1/0/all/0/1\">Franz Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayo_A/0/1/0/all/0/1\">Amelia Bayo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cadiz_Leyton_M/0/1/0/all/0/1\">Martina C&#xe1;diz-Leyton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catelan_M/0/1/0/all/0/1\">Marcio Catelan</a>",
          "description": "With the increasing volume of astronomical data generated by modern survey\ntelescopes, automated pipelines and machine learning techniques have become\ncrucial for analyzing and extracting knowledge from these datasets. Anomaly\ndetection, i.e. the task of identifying irregular or unexpected patterns in the\ndata, is a complex challenge in astronomy. In this paper, we propose\nMulti-Class Deep Support Vector Data Description (MCDSVDD), an extension of the\nstate-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically\ndesigned to handle different inlier categories with distinct data\ndistributions. MCDSVDD uses a neural network to map the data into hyperspheres,\nwhere each hypersphere represents a specific inlier category. The distance of\neach sample from the centers of these hyperspheres determines the anomaly\nscore. We evaluate the effectiveness of MCDSVDD by comparing its performance\nwith several anomaly detection algorithms on a large dataset of astronomical\nlight-curves obtained from the Zwicky Transient Facility. Our results\ndemonstrate the efficacy of MCDSVDD in detecting anomalous sources while\nleveraging the presence of different inlier categories. The code and the data\nneeded to reproduce our results are publicly available at\nhttps://github.com/mperezcarrasco/AnomalyALeRCE.",
          "link": "http://arxiv.org/abs/2308.05011",
          "publishedOn": "2023-08-12T00:39:31.783Z",
          "wordCount": null,
          "title": "Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories. (arXiv:2308.05011v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuoxiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yadan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1\">Mahsa Baktashmotlagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zi Huang</a>",
          "description": "Unsupervised domain adaptation (DA) with the aid of pseudo labeling\ntechniques has emerged as a crucial approach for domain-adaptive 3D object\ndetection. While effective, existing DA methods suffer from a substantial drop\nin performance when applied to a multi-class training setting, due to the\nco-existence of low-quality pseudo labels and class imbalance issues. In this\npaper, we address this challenge by proposing a novel ReDB framework tailored\nfor learning to detect all classes at once. Our approach produces Reliable,\nDiverse, and class-Balanced pseudo 3D boxes to iteratively guide the\nself-training on a distributionally different target domain. To alleviate\ndisruptions caused by the environmental discrepancy (e.g., beam numbers), the\nproposed cross-domain examination (CDE) assesses the correctness of pseudo\nlabels by copy-pasting target instances into a source environment and measuring\nthe prediction consistency. To reduce computational overhead and mitigate the\nobject shift (e.g., scales and point densities), we design an overlapped boxes\ncounting (OBC) metric that allows to uniformly downsample pseudo-labeled\nobjects across different geometric characteristics. To confront the issue of\ninter-class imbalance, we progressively augment the target point clouds with a\nclass-balanced set of pseudo-labeled target instances and source objects, which\nboosts recognition accuracies on both frequently appearing and rare classes.\nExperimental results on three benchmark datasets using both voxel-based (i.e.,\nSECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that our\nproposed ReDB approach outperforms existing 3D domain adaptation methods by a\nlarge margin, improving 23.15% mAP on the nuScenes $\\rightarrow$ KITTI task.\nThe code is available at https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet.",
          "link": "http://arxiv.org/abs/2307.07944",
          "publishedOn": "2023-08-12T00:39:31.782Z",
          "wordCount": null,
          "title": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling. (arXiv:2307.07944v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ran Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1\">Charles Nicholas</a>",
          "description": "Machine learning (ML)-based malware detection systems are becoming\nincreasingly important as malware threats increase and get more sophisticated.\nPDF files are often used as vectors for phishing attacks because they are\nwidely regarded as trustworthy data resources, and are accessible across\ndifferent platforms. Therefore, researchers have developed many different PDF\nmalware detection methods. Performance in detecting PDF malware is greatly\ninfluenced by feature selection. In this research, we propose a small features\nset that don't require too much domain knowledge of the PDF file. We evaluate\nproposed features with six different machine learning models. We report the\nbest accuracy of 99.75% when using Random Forest model. Our proposed feature\nset, which consists of just 12 features, is one of the most conciseness in the\nfield of PDF malware detection. Despite its modest size, we obtain comparable\nresults to state-of-the-art that employ a much larger set of features.",
          "link": "http://arxiv.org/abs/2308.04704",
          "publishedOn": "2023-08-12T00:39:31.782Z",
          "wordCount": null,
          "title": "A Feature Set of Small Size for the PDF Malware Detection. (arXiv:2308.04704v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12177",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Pierzyna_M/0/1/0/all/0/1\">Maximilian Pierzyna</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Saathof_R/0/1/0/all/0/1\">Rudolf Saathof</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Basu_S/0/1/0/all/0/1\">Sukanta Basu</a>",
          "description": "Turbulent fluctuations of the atmospheric refraction index, so-called optical\nturbulence, can significantly distort propagating laser beams. Therefore,\nmodeling the strength of these fluctuations ($C_n^2$) is highly relevant for\nthe successful development and deployment of future free-space optical\ncommunication links. In this letter, we propose a physics-informed machine\nlearning (ML) methodology, $\\Pi$-ML, based on dimensional analysis and gradient\nboosting to estimate $C_n^2$. Through a systematic feature importance analysis,\nwe identify the normalized variance of potential temperature as the dominating\nfeature for predicting $C_n^2$. For statistical robustness, we train an\nensemble of models which yields high performance on the out-of-sample data of\n$R^2=0.958\\pm0.001$.",
          "link": "http://arxiv.org/abs/2304.12177",
          "publishedOn": "2023-08-12T00:39:31.779Z",
          "wordCount": null,
          "title": "{\\Pi}-ML: A dimensional analysis-based machine learning parameterization of optical turbulence in the atmospheric surface layer. (arXiv:2304.12177v2 [physics.ao-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.10382",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Certo_S/0/1/0/all/0/1\">Salvatore Certo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pham_A/0/1/0/all/0/1\">Anh Pham</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Robles_N/0/1/0/all/0/1\">Nicolas Robles</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Vlasic_A/0/1/0/all/0/1\">Andrew Vlasic</a>",
          "description": "A framework to learn a multi-modal distribution is proposed, denoted as the\nConditional Quantum Generative Adversarial Network (C-qGAN). The neural network\nstructure is strictly within a quantum circuit and, as a consequence, is shown\nto represent a more efficient state preparation procedure than current methods.\nThis methodology has the potential to speed-up algorithms, such as Monte Carlo\nanalysis. In particular, after demonstrating the effectiveness of the network\nin the learning task, the technique is applied to price Asian option\nderivatives, providing the foundation for further research on other\npath-dependent options.",
          "link": "http://arxiv.org/abs/2304.10382",
          "publishedOn": "2023-08-12T00:39:31.773Z",
          "wordCount": null,
          "title": "Conditional Generative Models for Learning Stochastic Processes. (arXiv:2304.10382v4 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11122",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Febba_D/0/1/0/all/0/1\">Davi M. Febba</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Talley_K/0/1/0/all/0/1\">Kevin R. Talley</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Johnson_K/0/1/0/all/0/1\">Kendal Johnson</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schaefer_S/0/1/0/all/0/1\">Stephen Schaefer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bauers_S/0/1/0/all/0/1\">Sage R. Bauers</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mangum_J/0/1/0/all/0/1\">John S. Mangum</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Smaha_R/0/1/0/all/0/1\">Rebecca W. Smaha</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zakutayev_A/0/1/0/all/0/1\">Andriy Zakutayev</a>",
          "description": "Autonomous experimentation has emerged as an efficient approach to accelerate\nthe pace of materials discovery. Although instruments for autonomous synthesis\nhave become popular in molecular and polymer science, solution processing of\nhybrid materials and nanoparticles, examples of autonomous tools for physical\nvapor deposition are scarce yet important for the semiconductor industry. Here,\nwe report the design and implementation of an autonomous workflow for sputter\ndeposition of thin films with controlled composition, leveraging a highly\nautomated sputtering reactor custom-controlled by Python, optical emission\nspectroscopy (OES), and a Bayesian optimization algorithm. We modeled film\ncomposition, measured by x-ray fluorescence, as a linear function of emission\nlines monitored during the co-sputtering from elemental Zn and Ti targets in\nN$_2$ atmosphere. A Bayesian control algorithm, informed by OES, navigates the\nspace of sputtering power to fabricate films with user-defined composition, by\nminimizing the absolute error between desired and measured emission signals. We\nvalidated our approach by autonomously fabricating Zn$_x$Ti$_{1-x}$N$_y$ films\nwith deviations from the targeted cation composition within relative 3.5 %,\neven for 15 nm thin films, demonstrating that the proposed approach can\nreliably synthesize thin films with specific composition and minimal human\ninterference. Moreover, the proposed method can be extended to more difficult\nsynthesis experiments where plasma intensity depends non-linearly on pressure,\nor the elemental sticking coefficients strongly depend on the substrate\ntemperature.",
          "link": "http://arxiv.org/abs/2305.11122",
          "publishedOn": "2023-08-12T00:39:31.768Z",
          "wordCount": null,
          "title": "Autonomous sputter synthesis of thin film nitrides with composition controlled by Bayesian optimization of optical plasma emission. (arXiv:2305.11122v3 [physics.app-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chuanyang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>",
          "description": "The performance of Large Language Models (LLMs) in reasoning tasks depends\nheavily on prompt design, with Chain-of-Thought (CoT) and self-consistency\nbeing critical methods that enhance this ability. However, these methods do not\nfully exploit the answers generated by the LLM to guide subsequent responses.\nThis paper proposes a new prompting method, named Progressive-Hint Prompting\n(PHP), that enables automatic multiple interactions between users and LLMs by\nusing previously generated answers as hints to progressively guide toward the\ncorrect answers. PHP is orthogonal to CoT and self-consistency, making it easy\nto combine with state-of-the-art techniques to further improve performance. We\nconducted extensive and comprehensive experiments on seven benchmarks. The\nresults show that PHP significantly improves accuracy while remaining highly\nefficient. For instance, with text-davinci-003, we observed a 4.2% improvement\non GSM8K with greedy decoding compared to Complex CoT, and a 46.17% reduction\nin sample paths with self-consistency. With GPT-4 and PHP, we achieve\nstate-of-the-art performances on SVAMP (89.1% -> 91.9%), GSM8K (92% -> 95.5%),\nAQuA (76.4% -> 79.9%) and MATH (50.3% -> 53.9%).",
          "link": "http://arxiv.org/abs/2304.09797",
          "publishedOn": "2023-08-12T00:39:31.765Z",
          "wordCount": null,
          "title": "Progressive-Hint Prompting Improves Reasoning in Large Language Models. (arXiv:2304.09797v5 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Proenca_H/0/1/0/all/0/1\">Hugo Manuel Proen&#xe7;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraes_F/0/1/0/all/0/1\">Felipe Moraes</a>",
          "description": "Promotions play a crucial role in e-commerce platforms, and various cost\nstructures are employed to drive user engagement. This paper focuses on\npromotions with response-dependent costs, where expenses are incurred only when\na purchase is made. Such promotions include discounts and coupons. While\nexisting uplift model approaches aim to address this challenge, these\napproaches often necessitate training multiple models, like meta-learners, or\nencounter complications when estimating profit due to zero-inflated values\nstemming from non-converted individuals with zero cost and profit.\n\nTo address these challenges, we introduce Incremental Profit per Conversion\n(IPC), a novel uplift measure of promotional campaigns' efficiency in unit\neconomics. Through a proposed response transformation, we demonstrate that IPC\nrequires only converted data, its propensity, and a single model to be\nestimated. As a result, IPC resolves the issues mentioned above while\nmitigating the noise typically associated with the class imbalance in\nconversion datasets and biases arising from the many-to-one mapping between\nsearch and purchase data. Lastly, we validate the efficacy of our approach by\npresenting results obtained from a synthetic simulation of a discount coupon\ncampaign.",
          "link": "http://arxiv.org/abs/2306.13759",
          "publishedOn": "2023-08-12T00:39:31.740Z",
          "wordCount": null,
          "title": "Incremental Profit per Conversion: a Response Transformation for Uplift Modeling in E-Commerce Promotions. (arXiv:2306.13759v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chuying Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yasong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianyu Wang</a>",
          "description": "Random Search is one of the most widely-used method for Hyperparameter\nOptimization, and is critical to the success of deep learning models. Despite\nits astonishing performance, little non-heuristic theory has been developed to\ndescribe the underlying working mechanism. This paper gives a theoretical\naccounting of Random Search. We introduce the concept of \\emph{scattering\ndimension} that describes the landscape of the underlying function, and\nquantifies the performance of random search. We show that, when the environment\nis noise-free, the output of random search converges to the optimal value in\nprobability at rate $ \\widetilde{\\mathcal{O}} \\left( \\left( \\frac{1}{T}\n\\right)^{ \\frac{1}{d_s} } \\right) $, where $ d_s \\ge 0 $ is the scattering\ndimension of the underlying function. When the observed function values are\ncorrupted by bounded $iid$ noise, the output of random search converges to the\noptimal value in probability at rate $ \\widetilde{\\mathcal{O}} \\left( \\left(\n\\frac{1}{T} \\right)^{ \\frac{1}{d_s + 1} } \\right) $. In addition, based on the\nprinciples of random search, we introduce an algorithm, called BLiN-MOS, for\nLipschitz bandits in doubling metric spaces that are also endowed with a\nprobability measure, and show that BLiN-MOS achieves a regret rate of order $\n\\widetilde{\\mathcal{O}} \\left( T^{ \\frac{d_z}{d_z + 1} } \\right) $, where $d_z$\nis the zooming dimension of the problem instance.",
          "link": "http://arxiv.org/abs/2305.11509",
          "publishedOn": "2023-08-12T00:39:31.738Z",
          "wordCount": null,
          "title": "From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1\">Ajay Jaiswal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Large pre-trained transformers are show-stealer in modern-day deep learning,\nand it becomes crucial to comprehend the parsimonious patterns that exist\nwithin them as they grow in scale. With exploding parameter counts, Lottery\nTicket Hypothesis (LTH) and its variants, have lost their pragmatism in\nsparsifying them due to high computation and memory bottleneck of repetitive\ntrain-prune-retrain routine of iterative magnitude pruning (IMP) which worsens\nwith increasing model size. This paper comprehensively studies induced sparse\npatterns across multiple large pre-trained vision and language transformers. We\npropose the existence of -- essential sparsity defined with a sharp dropping\npoint beyond which the performance declines much faster w.r.t the rise of\nsparsity level, when we directly remove weights with the smallest magnitudes in\none-shot without re-training. We also find essential sparsity to hold valid for\nN:M sparsity patterns as well as on modern-scale large language models\n(Vicuna-7B). We also present an intriguing emerging phenomenon of abrupt\nsparsification during the pre-training of BERT, i.e., BERT suddenly becomes\nheavily sparse in pre-training after certain iterations. Moreover, our\nobservations also indicate a counter-intuitive finding that BERT trained with a\nlarger amount of pre-training data tends to have a better ability to condense\nknowledge in comparatively relatively fewer parameters. Lastly, we investigate\nthe effect of the pre-training loss on essential sparsity and discover that\nself-supervised learning (SSL) objectives trigger stronger emergent\nsparsification properties than supervised learning (SL). Our codes are\navailable at \\url{https://github.com/VITA-Group/essential_sparsity}.",
          "link": "http://arxiv.org/abs/2306.03805",
          "publishedOn": "2023-08-12T00:39:31.730Z",
          "wordCount": null,
          "title": "The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter. (arXiv:2306.03805v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.04087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindqvist_B/0/1/0/all/0/1\">Blerta Lindqvist</a>",
          "description": "This paper uses symmetry to make Convolutional Neural Network classifiers\n(CNNs) robust against adversarial perturbation attacks. Such attacks add\nperturbation to original images to generate adversarial images that fool\nclassifiers such as road sign classifiers of autonomous vehicles. Although\nsymmetry is a pervasive aspect of the natural world, CNNs are unable to handle\nsymmetry well. For example, a CNN can classify an image differently from its\nmirror image. For an adversarial image that misclassifies with a wrong label\n$l_w$, CNN inability to handle symmetry means that a symmetric adversarial\nimage can classify differently from the wrong label $l_w$. Further than that,\nwe find that the classification of a symmetric adversarial image reverts to the\ncorrect label. To classify an image when adversaries are unaware of the\ndefense, we apply symmetry to the image and use the classification label of the\nsymmetric image. To classify an image when adversaries are aware of the\ndefense, we use mirror symmetry and pixel inversion symmetry to form a symmetry\ngroup. We apply all the group symmetries to the image and decide on the output\nlabel based on the agreement of any two of the classification labels of the\nsymmetry images. Adaptive attacks fail because they need to rely on loss\nfunctions that use conflicting CNN output values for symmetric images. Without\nattack knowledge, the proposed symmetry defense succeeds against both\ngradient-based and random-search attacks, with up to near-default accuracies\nfor ImageNet. The defense even improves the classification accuracy of original\nimages.",
          "link": "http://arxiv.org/abs/2210.04087",
          "publishedOn": "2023-08-12T00:39:31.729Z",
          "wordCount": null,
          "title": "Symmetry Defense Against CNN Adversarial Perturbation Attacks. (arXiv:2210.04087v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_S/0/1/0/all/0/1\">Sangeet Jaiswal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1\">Dhruv Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vempati_S/0/1/0/all/0/1\">Sreekanth Vempati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saiswaroop_K/0/1/0/all/0/1\">Konduru Saiswaroop</a>",
          "description": "In a fashion e-commerce platform where customers can't physically examine the\nproducts on their own, being able to see other customers' text and image\nreviews of the product is critical while making purchase decisions. Given the\nhigh reliance on these reviews, over the years we have observed customers\nproactively sharing their reviews. With an increase in the coverage of User\nGenerated Content (UGC), there has been a corresponding increase in the number\nof customer images. It is thus imperative to display the most relevant images\non top as it may influence users' online shopping choices and behavior. In this\npaper, we propose a simple yet effective training procedure for ranking\ncustomer images. We created a dataset consisting of Myntra (A Major Indian\nFashion e-commerce company) studio posts and highly engaged (upvotes/downvotes)\nUGC images as our starting point and used selected distortion techniques on the\nimages of the above dataset to bring their quality at par with those of bad UGC\nimages. We train our network to rank bad-quality images lower than high-quality\nones. Our proposed method outperforms the baseline models on two metrics,\nnamely correlation coefficient, and accuracy, by substantial margins.",
          "link": "http://arxiv.org/abs/2308.05390",
          "publishedOn": "2023-08-12T00:39:31.712Z",
          "wordCount": 706,
          "title": "Product Review Image Ranking for Fashion E-commerce. (arXiv:2308.05390v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.04702",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1\">Sourav Chatterjee</a>",
          "description": "This paper surveys some recent developments in measures of association\nrelated to a new coefficient of correlation introduced by the author. A\nstraightforward extension of this coefficient to standard Borel spaces (which\nincludes all Polish spaces), overlooked in the literature so far, is proposed\nat the end of the survey.",
          "link": "http://arxiv.org/abs/2211.04702",
          "publishedOn": "2023-08-12T00:39:31.706Z",
          "wordCount": null,
          "title": "A survey of some recent developments in measures of association. (arXiv:2211.04702v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.10822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siddique_A/0/1/0/all/0/1\">Ayesha Siddique</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_R/0/1/0/all/0/1\">Ripan Kumar Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mode_G/0/1/0/all/0/1\">Gautam Raj Mode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoque_K/0/1/0/all/0/1\">Khaza Anuarul Hoque</a>",
          "description": "The state-of-the-art predictive maintenance (PdM) techniques have shown great\nsuccess in reducing maintenance costs and downtime of complicated machines\nwhile increasing overall productivity through extensive utilization of\nInternet-of-Things (IoT) and Deep Learning (DL). Unfortunately, IoT sensors and\nDL algorithms are both prone to cyber-attacks. For instance, DL algorithms are\nknown for their susceptibility to adversarial examples. Such adversarial\nattacks are vastly under-explored in the PdM domain. This is because the\nadversarial attacks in the computer vision domain for classification tasks\ncannot be directly applied to the PdM domain for multivariate time series (MTS)\nregression tasks. In this work, we propose an end-to-end methodology to design\nadversarially robust PdM systems by extensively analyzing the effect of\ndifferent types of adversarial attacks and proposing a novel adversarial\ndefense technique for DL-enabled PdM models. First, we propose novel MTS\nProjected Gradient Descent (PGD) and MTS PGD with random restarts (PGD_r)\nattacks. Then, we evaluate the impact of MTS PGD and PGD_r along with MTS Fast\nGradient Sign Method (FGSM) and MTS Basic Iterative Method (BIM) on Long\nShort-Term Memory (LSTM), Gated Recurrent Unit (GRU), Convolutional Neural\nNetwork (CNN), and Bi-directional LSTM based PdM system. Our results using\nNASA's turbofan engine dataset show that adversarial attacks can cause a severe\ndefect (up to 11X) in the RUL prediction, outperforming the effectiveness of\nthe state-of-the-art PdM attacks by 3X. Furthermore, we present a novel\napproximate adversarial training method to defend against adversarial attacks.\nWe observe that approximate adversarial training can significantly improve the\nrobustness of PdM models (up to 54X) and outperforms the state-of-the-art PdM\ndefense methods by offering 3X more robustness.",
          "link": "http://arxiv.org/abs/2301.10822",
          "publishedOn": "2023-08-12T00:39:31.706Z",
          "wordCount": null,
          "title": "RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks. (arXiv:2301.10822v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00453",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1\">Soufiane Hayou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_G/0/1/0/all/0/1\">Greg Yang</a>",
          "description": "We show that taking the width and depth to infinity in a deep neural network\nwith skip connections, when branches are scaled by $1/\\sqrt{depth}$ (the only\nnontrivial scaling), result in the same covariance structure no matter how that\nlimit is taken. This explains why the standard infinite-width-then-depth\napproach provides practical insights even for networks with depth of the same\norder as width. We also demonstrate that the pre-activations, in this case,\nhave Gaussian distributions which has direct applications in Bayesian deep\nlearning. We conduct extensive simulations that show an excellent match with\nour theoretical findings.",
          "link": "http://arxiv.org/abs/2302.00453",
          "publishedOn": "2023-08-12T00:39:31.706Z",
          "wordCount": null,
          "title": "Width and Depth Limits Commute in Residual Networks. (arXiv:2302.00453v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.13662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sablayrolles_A/0/1/0/all/0/1\">Alexandre Sablayrolles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>",
          "description": "Differential privacy (DP) is by far the most widely accepted framework for\nmitigating privacy risks in machine learning. However, exactly how small the\nprivacy parameter $\\epsilon$ needs to be to protect against certain privacy\nrisks in practice is still not well-understood. In this work, we study data\nreconstruction attacks for discrete data and analyze it under the framework of\nmultiple hypothesis testing. We utilize different variants of the celebrated\nFano's inequality to derive upper bounds on the inferential power of a data\nreconstruction adversary when the model is trained differentially privately.\nImportantly, we show that if the underlying private data takes values from a\nset of size $M$, then the target privacy parameter $\\epsilon$ can be $O(\\log\nM)$ before the adversary gains significant inferential power. Our analysis\noffers theoretical evidence for the empirical effectiveness of DP against data\nreconstruction attacks even at relatively large values of $\\epsilon$.",
          "link": "http://arxiv.org/abs/2210.13662",
          "publishedOn": "2023-08-12T00:39:31.705Z",
          "wordCount": null,
          "title": "Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing: A Lesson From Fano. (arXiv:2210.13662v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.05874",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Klepl_D/0/1/0/all/0/1\">Dominik Klepl</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+He_F/0/1/0/all/0/1\">Fei He</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_M/0/1/0/all/0/1\">Min Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Blackburn_D/0/1/0/all/0/1\">Daniel J. Blackburn</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sarrigiannis_P/0/1/0/all/0/1\">Ptolemaios G. Sarrigiannis</a>",
          "description": "Graph neural network (GNN) models are increasingly being used for the\nclassification of electroencephalography (EEG) data. However, GNN-based\ndiagnosis of neurological disorders, such as Alzheimer's disease (AD), remains\na relatively unexplored area of research. Previous studies have relied on\nfunctional connectivity methods to infer brain graph structures and used simple\nGNN architectures for the diagnosis of AD. In this work, we propose a novel\nadaptive gated graph convolutional network (AGGCN) that can provide explainable\npredictions. AGGCN adaptively learns graph structures by combining\nconvolution-based node feature enhancement with a well-known correlation-based\nmeasure of functional connectivity. Furthermore, the gated graph convolution\ncan dynamically weigh the contribution of various spatial scales. The proposed\nmodel achieves high accuracy in both eyes-closed and eyes-open conditions,\nindicating the stability of learned representations. Finally, we demonstrate\nthat the proposed AGGCN model generates consistent explanations of its\npredictions that might be relevant for further study of AD-related alterations\nof brain networks.",
          "link": "http://arxiv.org/abs/2304.05874",
          "publishedOn": "2023-08-12T00:39:31.705Z",
          "wordCount": null,
          "title": "Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data. (arXiv:2304.05874v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.02495",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ganev_S/0/1/0/all/0/1\">Stoil Ganev</a>",
          "description": "Here, we show that the InfoNCE objective is equivalent to the ELBO in a new\nclass of probabilistic generative model, the recognition parameterised model\n(RPM). When we learn the optimal prior, the RPM ELBO becomes equal to the\nmutual information (MI; up to a constant), establishing a connection to\npre-existing self-supervised learning methods such as InfoNCE. However,\npractical InfoNCE methods do not use the MI as an objective; the MI is\ninvariant to arbitrary invertible transformations, so using an MI objective can\nlead to highly entangled representations (Tschannen et al., 2019). Instead, the\nactual InfoNCE objective is a simplified lower bound on the MI which is loose\neven in the infinite sample limit. Thus, an objective that works (i.e. the\nactual InfoNCE objective) appears to be motivated as a loose bound on an\nobjective that does not work (i.e. the true MI which gives arbitrarily\nentangled representations). We give an alternative motivation for the actual\nInfoNCE objective. In particular, we show that in the infinite sample limit,\nand for a particular choice of prior, the actual InfoNCE objective is equal to\nthe ELBO (up to a constant); and the ELBO is equal to the marginal likelihood\nwith a deterministic recognition model. Thus, we argue that our VAE perspective\ngives a better motivation for InfoNCE than MI, as the actual InfoNCE objective\nis only loosely bounded by the MI, but is equal to the ELBO/marginal likelihood\n(up to a constant).",
          "link": "http://arxiv.org/abs/2107.02495",
          "publishedOn": "2023-08-12T00:39:31.704Z",
          "wordCount": null,
          "title": "InfoNCE is variational inference in a recognition parameterised model. (arXiv:2107.02495v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Durso_Finley_J/0/1/0/all/0/1\">Joshua Durso-Finley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falet_J/0/1/0/all/0/1\">Jean-Pierre Falet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1\">Raghav Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnold_D/0/1/0/all/0/1\">Douglas L. Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawlowski_N/0/1/0/all/0/1\">Nick Pawlowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbel_T/0/1/0/all/0/1\">Tal Arbel</a>",
          "description": "Image-based precision medicine aims to personalize treatment decisions based\non an individual's unique imaging features so as to improve their clinical\noutcome. Machine learning frameworks that integrate uncertainty estimation as\npart of their treatment recommendations would be safer and more reliable.\nHowever, little work has been done in adapting uncertainty estimation\ntechniques and validation metrics for precision medicine. In this paper, we use\nBayesian deep learning for estimating the posterior distribution over factual\nand counterfactual outcomes on several treatments. This allows for estimating\nthe uncertainty for each treatment option and for the individual treatment\neffects (ITE) between any two treatments. We train and evaluate this model to\npredict future new and enlarging T2 lesion counts on a large, multi-center\ndataset of MR brain images of patients with multiple sclerosis, exposed to\nseveral treatments during randomized controlled trials. We evaluate the\ncorrelation of the uncertainty estimate with the factual error, and, given the\nlack of ground truth counterfactual outcomes, demonstrate how uncertainty for\nthe ITE prediction relates to bounds on the ITE error. Lastly, we demonstrate\nhow knowledge of uncertainty could modify clinical decision-making to improve\nindividual patient and clinical trial outcomes.",
          "link": "http://arxiv.org/abs/2305.03829",
          "publishedOn": "2023-08-12T00:39:31.704Z",
          "wordCount": null,
          "title": "Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models. (arXiv:2305.03829v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05305",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yao_W/0/1/0/all/0/1\">Wenjian Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bai_J/0/1/0/all/0/1\">Jiajun Bai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liao_W/0/1/0/all/0/1\">Wei Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yuheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_M/0/1/0/all/0/1\">Mengjuan Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>",
          "description": "Medical image segmentation is an important step in medical image analysis,\nespecially as a crucial prerequisite for efficient disease diagnosis and\ntreatment. The use of deep learning for image segmentation has become a\nprevalent trend. The widely adopted approach currently is U-Net and its\nvariants. Additionally, with the remarkable success of pre-trained models in\nnatural language processing tasks, transformer-based models like TransUNet have\nachieved desirable performance on multiple medical image segmentation datasets.\nIn this paper, we conduct a survey of the most representative four medical\nimage segmentation models in recent years. We theoretically analyze the\ncharacteristics of these models and quantitatively evaluate their performance\non two benchmark datasets (i.e., Tuberculosis Chest X-rays and ovarian tumors).\nFinally, we discuss the main challenges and future trends in medical image\nsegmentation. Our work can assist researchers in the related field to quickly\nestablish medical segmentation models tailored to specific regions.",
          "link": "http://arxiv.org/abs/2308.05305",
          "publishedOn": "2023-08-12T00:39:31.703Z",
          "wordCount": 681,
          "title": "From CNN to Transformer: A Review of Medical Image Segmentation Models. (arXiv:2308.05305v1 [eess.IV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huber_J/0/1/0/all/0/1\">J. Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helenon_F/0/1/0/all/0/1\">F. H&#xe9;l&#xe9;non</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coninx_M/0/1/0/all/0/1\">M. Coninx</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amar_F/0/1/0/all/0/1\">F. Ben Amar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doncieux_S/0/1/0/all/0/1\">S. Doncieux</a>",
          "description": "Quality-Diversity (QD) methods are algorithms that aim to generate a set of\ndiverse and high-performing solutions to a given problem. Originally developed\nfor evolutionary robotics, most QD studies are conducted on a limited set of\ndomains - mainly applied to locomotion, where the fitness and the behavior\nsignal are dense. Grasping is a crucial task for manipulation in robotics.\nDespite the efforts of many research communities, this task is yet to be\nsolved. Grasping cumulates unprecedented challenges in QD literature: it\nsuffers from reward sparsity, behavioral sparsity, and behavior space\nmisalignment. The present work studies how QD can address grasping. Experiments\nhave been conducted on 15 different methods on 10 grasping domains,\ncorresponding to 2 different robot-gripper setups and 5 standard objects. An\nevaluation framework that distinguishes the evaluation of an algorithm from its\ninternal components has also been proposed for a fair comparison. The obtained\nresults show that MAP-Elites variants that select successful solutions in\npriority outperform all the compared methods on the studied metrics by a large\nmargin. We also found experimental evidence that sparse interaction can lead to\ndeceptive novelty. To our knowledge, the ability to efficiently produce\nexamples of grasping trajectories demonstrated in this work has no precedent in\nthe literature.",
          "link": "http://arxiv.org/abs/2308.05483",
          "publishedOn": "2023-08-12T00:39:31.697Z",
          "wordCount": 731,
          "title": "Quality Diversity under Sparse Reward and Sparse Interaction: Application to Grasping in Robotics. (arXiv:2308.05483v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1\">Michael Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritschel_T/0/1/0/all/0/1\">Tobias Ritschel</a>",
          "description": "Gradient-based optimization is now ubiquitous across graphics, but\nunfortunately can not be applied to problems with undefined or zero gradients.\nTo circumvent this issue, the loss function can be manually replaced by a\n\"surrogate\" that has similar minima but is differentiable. Our proposed\nframework, ZeroGrads, automates this process by learning a neural approximation\nof the objective function, the surrogate, which in turn can be used to\ndifferentiate through arbitrary black-box graphics pipelines. We train the\nsurrogate on an actively smoothed version of the objective and encourage\nlocality, focusing the surrogate's capacity on what matters at the current\ntraining episode. The fitting is performed online, alongside the parameter\noptimization, and self-supervised, without pre-computed data or pre-trained\nmodels. As sampling the objective is expensive (it requires a full rendering or\nsimulator run), we devise an efficient sampling scheme that allows for\ntractable run-times and competitive performance at little overhead. We\ndemonstrate optimizing diverse non-convex, non-differentiable black-box\nproblems in graphics, such as visibility in rendering, discrete parameter\nspaces in procedural modelling or optimal control in physics-driven animation.\nIn contrast to more traditional algorithms, our approach scales well to higher\ndimensions, which we demonstrate on problems with up to 35k interlinked\nvariables.",
          "link": "http://arxiv.org/abs/2308.05739",
          "publishedOn": "2023-08-12T00:39:31.618Z",
          "wordCount": null,
          "title": "Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics. (arXiv:2308.05739v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oguz_I/0/1/0/all/0/1\">Ilker Oguz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1\">Junjie Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Feng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yildirim_M/0/1/0/all/0/1\">Mustafa Yildirim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinc_N/0/1/0/all/0/1\">Niyazi Ulas Dinc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_J/0/1/0/all/0/1\">Jih-Liang Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moser_C/0/1/0/all/0/1\">Christophe Moser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psaltis_D/0/1/0/all/0/1\">Demetri Psaltis</a>",
          "description": "Neural networks (NN) have demonstrated remarkable capabilities in various\ntasks, but their computation-intensive nature demands faster and more\nenergy-efficient hardware implementations. Optics-based platforms, using\ntechnologies such as silicon photonics and spatial light modulators, offer\npromising avenues for achieving this goal. However, training multiple trainable\nlayers in tandem with these physical systems poses challenges, as they are\ndifficult to fully characterize and describe with differentiable functions,\nhindering the use of error backpropagation algorithm. The recently introduced\nForward-Forward Algorithm (FFA) eliminates the need for perfect\ncharacterization of the learning system and shows promise for efficient\ntraining with large numbers of programmable parameters. The FFA does not\nrequire backpropagating an error signal to update the weights, rather the\nweights are updated by only sending information in one direction. The local\nloss function for each set of trainable weights enables low-power analog\nhardware implementations without resorting to metaheuristic algorithms or\nreinforcement learning. In this paper, we present an experiment utilizing\nmultimode nonlinear wave propagation in an optical fiber demonstrating the\nfeasibility of the FFA approach using an optical system. The results show that\nincorporating optical transforms in multilayer NN architectures trained with\nthe FFA, can lead to performance improvements, even with a relatively small\nnumber of trainable weights. The proposed method offers a new path to the\nchallenge of training optical NNs and provides insights into leveraging\nphysical transformations for enhancing NN performance.",
          "link": "http://arxiv.org/abs/2305.19170",
          "publishedOn": "2023-08-12T00:39:31.613Z",
          "wordCount": null,
          "title": "Forward-Forward Training of an Optical Neural Network. (arXiv:2305.19170v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.07925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1\">Thomas Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barahona_M/0/1/0/all/0/1\">Mauricio Barahona</a>",
          "description": "We present a robust deep incremental learning framework for regression tasks\non financial temporal tabular datasets which is built upon the incremental use\nof commonly available tabular and time series prediction models to adapt to\ndistributional shifts typical of financial datasets. The framework uses a\nsimple basic building block (decision trees) to build self-similar models of\nany required complexity to deliver robust performance under adverse situations\nsuch as regime changes, fat-tailed distributions, and low signal-to-noise\nratios. As a detailed study, we demonstrate our scheme using XGBoost models\ntrained on the Numerai dataset and show that a two layer deep ensemble of\nXGBoost models over different model snapshots delivers high quality predictions\nunder different market regimes. We also show that the performance of XGBoost\nmodels with different number of boosting rounds in three scenarios (small,\nstandard and large) is monotonically increasing with respect to model size and\nconverges towards the generalisation upper bound. We also evaluate the\nrobustness of the model under variability of different hyperparameters, such as\nmodel complexity and data sampling settings. Our model has low hardware\nrequirements as no specialised neural architectures are used and each base\nmodel can be independently trained in parallel.",
          "link": "http://arxiv.org/abs/2303.07925",
          "publishedOn": "2023-08-12T00:39:31.608Z",
          "wordCount": null,
          "title": "Deep incremental learning models for financial temporal tabular datasets with distribution shifts. (arXiv:2303.07925v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.05869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heinrichs_F/0/1/0/all/0/1\">Florian Heinrichs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heim_M/0/1/0/all/0/1\">Mavin Heim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1\">Corinna Weber</a>",
          "description": "It is desirable for statistical models to detect signals of interest\nindependently of their position. If the data is generated by some smooth\nprocess, this additional structure should be taken into account. We introduce a\nnew class of neural networks that are shift invariant and preserve smoothness\nof the data: functional neural networks (FNNs). For this, we use methods from\nfunctional data analysis (FDA) to extend multi-layer perceptrons and\nconvolutional neural networks to functional data. We propose different model\narchitectures, show that the models outperform a benchmark model from FDA in\nterms of accuracy and successfully use FNNs to classify electroencephalography\n(EEG) data.",
          "link": "http://arxiv.org/abs/2301.05869",
          "publishedOn": "2023-08-12T00:39:31.607Z",
          "wordCount": null,
          "title": "Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification. (arXiv:2301.05869v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boureima_I/0/1/0/all/0/1\">Ismael Boureima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattarai_M/0/1/0/all/0/1\">Manish Bhattarai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eren_M/0/1/0/all/0/1\">Maksim Eren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skau_E/0/1/0/all/0/1\">Erik Skau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_P/0/1/0/all/0/1\">Philip Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eidenbenz_S/0/1/0/all/0/1\">Stephan Eidenbenz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1\">Boian Alexandrov</a>",
          "description": "We propose an efficient distributed out-of-memory implementation of the\nNon-negative Matrix Factorization (NMF) algorithm for heterogeneous\nhigh-performance-computing (HPC) systems. The proposed implementation is based\non prior work on NMFk, which can perform automatic model selection and extract\nlatent variables and patterns from data. In this work, we extend NMFk by adding\nsupport for dense and sparse matrix operation on multi-node, multi-GPU systems.\nThe resulting algorithm is optimized for out-of-memory (OOM) problems where the\nmemory required to factorize a given matrix is greater than the available GPU\nmemory. Memory complexity is reduced by batching/tiling strategies, and sparse\nand dense matrix operations are significantly accelerated with GPU cores (or\ntensor cores when available). Input/Output (I/O) latency associated with batch\ncopies between host and device is hidden using CUDA streams to overlap data\ntransfers and compute asynchronously, and latency associated with collective\ncommunications (both intra-node and inter-node) is reduced using optimized\nNVIDIA Collective Communication Library NCCL based communicators. Benchmark\nresults show significant improvement, from 32X to 76x speedup, with the new\nimplementation using GPUs over the CPU-based NMFk. Good weak scaling was\ndemonstrated on up to 4096 multi-GPU cluster nodes with approximately 25,000\nGPUs when decomposing a dense 340 Terabyte-size matrix and an 11 Exabyte-size\nsparse matrix of density 10e-6.",
          "link": "http://arxiv.org/abs/2202.09518",
          "publishedOn": "2023-08-12T00:39:31.606Z",
          "wordCount": null,
          "title": "Distributed Out-of-Memory NMF on CPU/GPU Architectures. (arXiv:2202.09518v3 [cs.DC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zelin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaolin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaojun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fournier_Viger_P/0/1/0/all/0/1\">Philippe Fournier-Viger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>",
          "description": "Node classification is the task of predicting the labels of unlabeled nodes\nin a graph. State-of-the-art methods based on graph neural networks achieve\nexcellent performance when all labels are available during training. But in\nreal-life, models are often applied on data with new classes, which can lead to\nmassive misclassification and thus significantly degrade performance. Hence,\ndeveloping open-set classification methods is crucial to determine if a given\nsample belongs to a known class. Existing methods for open-set node\nclassification generally use transductive learning with part or all of the\nfeatures of real unseen class nodes to help with open-set classification. In\nthis paper, we propose a novel generative open-set node classification method,\ni.e. $\\mathcal{G}^2Pxy$, which follows a stricter inductive learning setting\nwhere no information about unknown classes is available during training and\nvalidation. Two kinds of proxy unknown nodes, inter-class unknown proxies and\nexternal unknown proxies are generated via mixup to efficiently anticipate the\ndistribution of novel classes. Using the generated proxies, a closed-set\nclassifier can be transformed into an open-set one, by augmenting it with an\nextra proxy classifier. Under the constraints of both cross entropy loss and\ncomplement entropy loss, $\\mathcal{G}^2Pxy$ achieves superior effectiveness for\nunknown class detection and known class classification, which is validated by\nexperiments on benchmark graph datasets. Moreover, $\\mathcal{G}^2Pxy$ does not\nhave specific requirement on the GNN architecture and shows good\ngeneralizations.",
          "link": "http://arxiv.org/abs/2308.05463",
          "publishedOn": "2023-08-12T00:39:31.605Z",
          "wordCount": null,
          "title": "$\\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs with Proxy Unknowns. (arXiv:2308.05463v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_K/0/1/0/all/0/1\">Keqiang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xiaohao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niranjan_M/0/1/0/all/0/1\">Mahesan Niranjan</a>",
          "description": "Automated medical report generation has become increasingly important in\nmedical analysis. It can produce computer-aided diagnosis descriptions and thus\nsignificantly alleviate the doctors' work. Inspired by the huge success of\nneural machine translation and image captioning, various deep learning methods\nhave been proposed for medical report generation. However, due to the inherent\nproperties of medical data, including data imbalance and the length and\ncorrelation between report sequences, the generated reports by existing methods\nmay exhibit linguistic fluency but lack adequate clinical accuracy. In this\nwork, we propose an image-to-indicator hierarchical transformer (IIHT)\nframework for medical report generation. It consists of three modules, i.e., a\nclassifier module, an indicator expansion module and a generator module. The\nclassifier module first extracts image features from the input medical images\nand produces disease-related indicators with their corresponding states. The\ndisease-related indicators are subsequently utilised as input for the indicator\nexpansion module, incorporating the \"data-text-data\" strategy. The\ntransformer-based generator then leverages these extracted features along with\nimage features as auxiliary information to generate final reports. Furthermore,\nthe proposed IIHT method is feasible for radiologists to modify disease\nindicators in real-world scenarios and integrate the operations into the\nindicator expansion module for fluent and accurate medical report generation.\nExtensive experiments and comparisons with state-of-the-art methods under\nvarious evaluation metrics demonstrate the great performance of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2308.05633",
          "publishedOn": "2023-08-12T00:39:31.605Z",
          "wordCount": null,
          "title": "IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer. (arXiv:2308.05633v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orabona_F/0/1/0/all/0/1\">Francesco Orabona</a>",
          "description": "In this short note, I show how to adapt to H\\\"{o}lder smoothness using\nnormalized gradients in a black-box way. Moreover, the bound will depend on a\nnovel notion of local H\\\"{o}lder smoothness. The main idea directly comes from\nLevy [2017].",
          "link": "http://arxiv.org/abs/2308.05621",
          "publishedOn": "2023-08-12T00:39:31.603Z",
          "wordCount": null,
          "title": "Normalized Gradients for All. (arXiv:2308.05621v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuanshun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ton_J/0/1/0/all/0/1\">Jean-Francois Ton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_R/0/1/0/all/0/1\">Ruocheng Guo Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klochkov_Y/0/1/0/all/0/1\">Yegor Klochkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taufiq_M/0/1/0/all/0/1\">Muhammad Faaiz Taufiq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hang Li</a>",
          "description": "Ensuring alignment, which refers to making models behave in accordance with\nhuman intentions [1,2], has become a critical task before deploying large\nlanguage models (LLMs) in real-world applications. For instance, OpenAI devoted\nsix months to iteratively aligning GPT-4 before its release [3]. However, a\nmajor challenge faced by practitioners is the lack of clear guidance on\nevaluating whether LLM outputs align with social norms, values, and\nregulations. This obstacle hinders systematic iteration and deployment of LLMs.\nTo address this issue, this paper presents a comprehensive survey of key\ndimensions that are crucial to consider when assessing LLM trustworthiness. The\nsurvey covers seven major categories of LLM trustworthiness: reliability,\nsafety, fairness, resistance to misuse, explainability and reasoning, adherence\nto social norms, and robustness. Each major category is further divided into\nseveral sub-categories, resulting in a total of 29 sub-categories.\nAdditionally, a subset of 8 sub-categories is selected for further\ninvestigation, where corresponding measurement studies are designed and\nconducted on several widely-used LLMs. The measurement results indicate that,\nin general, more aligned models tend to perform better in terms of overall\ntrustworthiness. However, the effectiveness of alignment varies across the\ndifferent trustworthiness categories considered. This highlights the importance\nof conducting more fine-grained analyses, testing, and making continuous\nimprovements on LLM alignment. By shedding light on these key dimensions of LLM\ntrustworthiness, this paper aims to provide valuable insights and guidance to\npractitioners in the field. Understanding and addressing these concerns will be\ncrucial in achieving reliable and ethically sound deployment of LLMs in various\napplications.",
          "link": "http://arxiv.org/abs/2308.05374",
          "publishedOn": "2023-08-12T00:39:31.601Z",
          "wordCount": null,
          "title": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment. (arXiv:2308.05374v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levi_M/0/1/0/all/0/1\">Meir Yossef Levi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilboa_G/0/1/0/all/0/1\">Guy Gilboa</a>",
          "description": "The ability to cope accurately and fast with Out-Of-Distribution (OOD)\nsamples is crucial in real-world safety demanding applications. In this work we\nfirst study the interplay between critical points of 3D point clouds and OOD\nsamples. Our findings are that common corruptions and outliers are often\ninterpreted as critical points. We generalize the notion of critical points\ninto importance measures. We show that training a classification network based\nonly on less important points dramatically improves robustness, at a cost of\nminor performance loss on the clean set. We observe that normalized entropy is\nhighly informative for corruption analysis. An adaptive threshold based on\nnormalized entropy is suggested for selecting the set of uncritical points. Our\nproposed importance measure is extremely fast to compute. We show it can be\nused for a variety of applications, such as Explainable AI (XAI), Outlier\nRemoval, Uncertainty Estimation, Robust Classification and Adversarial Defense.\nWe reach SOTA results on the two latter tasks.",
          "link": "http://arxiv.org/abs/2308.05525",
          "publishedOn": "2023-08-12T00:39:31.575Z",
          "wordCount": null,
          "title": "Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI. (arXiv:2308.05525v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1\">Oleksandr Shchur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turkmen_C/0/1/0/all/0/1\">Caner Turkmen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erickson_N/0/1/0/all/0/1\">Nick Erickson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huibin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shirkov_A/0/1/0/all/0/1\">Alexander Shirkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Tony Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>",
          "description": "We introduce AutoGluon-TimeSeries - an open-source AutoML library for\nprobabilistic time series forecasting. Focused on ease of use and robustness,\nAutoGluon-TimeSeries enables users to generate accurate point and quantile\nforecasts with just 3 lines of Python code. Built on the design philosophy of\nAutoGluon, AutoGluon-TimeSeries leverages ensembles of diverse forecasting\nmodels to deliver high accuracy within a short training time.\nAutoGluon-TimeSeries combines both conventional statistical models,\nmachine-learning based forecasting approaches, and ensembling techniques. In\nour evaluation on 29 benchmark datasets, AutoGluon-TimeSeries demonstrates\nstrong empirical performance, outperforming a range of forecasting methods in\nterms of both point and quantile forecast accuracy, and often even improving\nupon the best-in-hindsight combination of prior methods.",
          "link": "http://arxiv.org/abs/2308.05566",
          "publishedOn": "2023-08-12T00:39:31.573Z",
          "wordCount": null,
          "title": "AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting. (arXiv:2308.05566v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prentzas_N/0/1/0/all/0/1\">Nicoletta Prentzas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakas_A/0/1/0/all/0/1\">Antonis Kakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pattichis_C/0/1/0/all/0/1\">Constantinos S. Pattichis</a>",
          "description": "Artificial Intelligence in Medicine has made significant progress with\nemerging applications in medical imaging, patient care, and other areas. While\nthese applications have proven successful in retrospective studies, very few of\nthem were applied in practice.The field of Medical AI faces various challenges,\nin terms of building user trust, complying with regulations, using data\nethically.Explainable AI (XAI) aims to enable humans understand AI and trust\nits results. This paper presents a literature review on the recent developments\nof XAI solutions for medical decision support, based on a representative sample\nof 198 articles published in recent years. The systematic synthesis of the\nrelevant articles resulted in several findings. (1) model-agnostic XAI\ntechniques were mostly employed in these solutions, (2) deep learning models\nare utilized more than other types of machine learning models, (3)\nexplainability was applied to promote trust, but very few works reported the\nphysicians participation in the loop, (4) visual and interactive user interface\nis more useful in understanding the explanation and the recommendation of the\nsystem. More research is needed in collaboration between medical and AI\nexperts, that could guide the development of suitable frameworks for the\ndesign, implementation, and evaluation of XAI solutions in medicine.",
          "link": "http://arxiv.org/abs/2308.05411",
          "publishedOn": "2023-08-12T00:39:31.571Z",
          "wordCount": null,
          "title": "Explainable AI applications in the Medical Domain: a systematic review. (arXiv:2308.05411v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05407",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mena_F/0/1/0/all/0/1\">Francisco Mena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arenas_D/0/1/0/all/0/1\">Diego Arenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nuske_M/0/1/0/all/0/1\">Marlon Nuske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1\">Andreas Dengel</a>",
          "description": "With a rapidly increasing amount and diversity of remote sensing (RS) data\nsources, there is a strong need for multi-view learning modeling. This is a\ncomplex task when considering the differences in resolution, magnitude, and\nnoise of RS data. The typical approach for merging multiple RS sources has been\ninput-level fusion, but other - more advanced - fusion strategies may\noutperform this traditional approach. This work assesses different fusion\nstrategies for crop classification in the CropHarvest dataset. The fusion\nmethods proposed in this work outperform models based on individual views and\nprevious fusion methods. We do not find one single fusion method that\nconsistently outperforms all other approaches. Instead, we present a comparison\nof multi-view fusion methods for three different datasets and show that,\ndepending on the test region, different methods obtain the best performance.\nDespite this, we suggest a preliminary criterion for the selection of fusion\nmethods.",
          "link": "http://arxiv.org/abs/2308.05407",
          "publishedOn": "2023-08-12T00:39:31.542Z",
          "wordCount": null,
          "title": "A Comparative Assessment of Multi-view fusion learning for Crop Classification. (arXiv:2308.05407v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1\">Anusuya Krishnan</a>",
          "description": "Deceptive text classification is a critical task in natural language\nprocessing that aims to identify deceptive or fraudulent content. This study\npresents a comparative analysis of machine learning and transformer-based\napproaches for deceptive text classification. We investigate the effectiveness\nof traditional machine learning algorithms and state-of-the-art transformer\nmodels, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptive\ntext. A labeled dataset consisting of deceptive and non-deceptive texts is used\nfor training and evaluation purposes. Through extensive experimentation, we\ncompare the performance metrics, including accuracy, precision, recall, and F1\nscore, of the different approaches. The results of this study shed light on the\nstrengths and limitations of machine learning and transformer-based methods for\ndeceptive text classification, enabling researchers and practitioners to make\ninformed decisions when dealing with deceptive content",
          "link": "http://arxiv.org/abs/2308.05476",
          "publishedOn": "2023-08-12T00:39:31.541Z",
          "wordCount": null,
          "title": "Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis. (arXiv:2308.05476v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yiling He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhan Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Kui Ren</a>",
          "description": "Deep learning classifiers achieve state-of-the-art performance in various\nrisk detection applications. They explore rich semantic representations and are\nsupposed to automatically discover risk behaviors. However, due to the lack of\ntransparency, the behavioral semantics cannot be conveyed to downstream\nsecurity experts to reduce their heavy workload in security analysis. Although\nfeature attribution (FA) methods can be used to explain deep learning, the\nunderlying classifier is still blind to what behavior is suspicious, and the\ngenerated explanation cannot adapt to downstream tasks, incurring poor\nexplanation fidelity and intelligibility. In this paper, we propose FINER, the\nfirst framework for risk detection classifiers to generate high-fidelity and\nhigh-intelligibility explanations. The high-level idea is to gather explanation\nefforts from model developer, FA designer, and security experts. To improve\nfidelity, we fine-tune the classifier with an explanation-guided multi-task\nlearning strategy. To improve intelligibility, we engage task knowledge to\nadjust and ensemble FA methods. Extensive evaluations show that FINER improves\nexplanation quality for risk detection. Moreover, we demonstrate that FINER\noutperforms a state-of-the-art tool in facilitating malware analysis.",
          "link": "http://arxiv.org/abs/2308.05362",
          "publishedOn": "2023-08-12T00:39:31.532Z",
          "wordCount": null,
          "title": "FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis. (arXiv:2308.05362v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puvvada_K/0/1/0/all/0/1\">Krishna C. Puvvada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavrukhin_V/0/1/0/all/0/1\">Vitaly Lavrukhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1\">Boris Ginsburg</a>",
          "description": "We propose CONF-TSASR, a non-autoregressive end-to-end time-frequency domain\narchitecture for single-channel target-speaker automatic speech recognition\n(TS-ASR). The model consists of a TitaNet based speaker embedding module, a\nConformer based masking as well as ASR modules. These modules are jointly\noptimized to transcribe a target-speaker, while ignoring speech from other\nspeakers. For training we use Connectionist Temporal Classification (CTC) loss\nand introduce a scale-invariant spectrogram reconstruction loss to encourage\nthe model better separate the target-speaker's spectrogram from mixture. We\nobtain state-of-the-art target-speaker word error rate (TS-WER) on\nWSJ0-2mix-extr (4.2%). Further, we report for the first time TS-WER on\nWSJ0-3mix-extr (12.4%), LibriSpeech2Mix (4.2%) and LibriSpeech3Mix (7.6%)\ndatasets, establishing new benchmarks for TS-ASR. The proposed model will be\nopen-sourced through NVIDIA NeMo toolkit.",
          "link": "http://arxiv.org/abs/2308.05218",
          "publishedOn": "2023-08-12T00:39:31.531Z",
          "wordCount": null,
          "title": "Conformer-based Target-Speaker Automatic Speech Recognition for Single-Channel Audio. (arXiv:2308.05218v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hawlader_F/0/1/0/all/0/1\">Faisal Hawlader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robinet_F/0/1/0/all/0/1\">Fran&#xe7;ois Robinet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_R/0/1/0/all/0/1\">Rapha&#xeb;l Frank</a>",
          "description": "Environmental perception is a key element of autonomous driving because the\ninformation received from the perception module influences core driving\ndecisions. An outstanding challenge in real-time perception for autonomous\ndriving lies in finding the best trade-off between detection quality and\nlatency. Major constraints on both computation and power have to be taken into\naccount for real-time perception in autonomous vehicles. Larger object\ndetection models tend to produce the best results, but are also slower at\nruntime. Since the most accurate detectors cannot run in real-time locally, we\ninvestigate the possibility of offloading computation to edge and cloud\nplatforms, which are less resource-constrained. We create a synthetic dataset\nto train object detection models and evaluate different offloading strategies.\nUsing real hardware and network simulations, we compare different trade-offs\nbetween prediction quality and end-to-end delay. Since sending raw frames over\nthe network implies additional transmission delays, we also explore the use of\nJPEG and H.265 compression at varying qualities and measure their impact on\nprediction metrics. We show that models with adequate compression can be run in\nreal-time on the cloud while outperforming local detection performance.",
          "link": "http://arxiv.org/abs/2308.05234",
          "publishedOn": "2023-08-12T00:39:31.530Z",
          "wordCount": null,
          "title": "Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving. (arXiv:2308.05234v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dadauto_C/0/1/0/all/0/1\">Caio Vinicius Dadauto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonseca_N/0/1/0/all/0/1\">Nelson Luis Saldanha da Fonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torres_R/0/1/0/all/0/1\">Ricardo da Silva Torres</a>",
          "description": "This paper introduces a novel deep-learning based generator of synthetic\ngraphs that represent intra-Autonomous System (AS) in the Internet, named\nDeep-generative graphs for the Internet (DGGI). It also presents a novel\nmassive dataset of real intra-AS graphs extracted from the project Internet\nTopology Data Kit (ITDK), called Internet Graphs (IGraphs). To create IGraphs,\nthe Filtered Recurrent Multi-level (FRM) algorithm for community extraction was\ndeveloped. It is shown that DGGI creates synthetic graphs which accurately\nreproduce the properties of centrality, clustering, assortativity, and node\ndegree. The DGGI generator overperforms existing Internet topology generators.\nOn average, DGGI improves the Maximum Mean Discrepancy (MMD) metric 84.4%,\n95.1%, 97.9%, and 94.7% for assortativity, betweenness, clustering, and node\ndegree, respectively.",
          "link": "http://arxiv.org/abs/2308.05254",
          "publishedOn": "2023-08-12T00:39:31.530Z",
          "wordCount": null,
          "title": "Data-driven Intra-Autonomous Systems Graph Generator. (arXiv:2308.05254v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05326",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ahdritz_G/0/1/0/all/0/1\">Gustaf Ahdritz</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bouatta_N/0/1/0/all/0/1\">Nazim Bouatta</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kadyan_S/0/1/0/all/0/1\">Sachin Kadyan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jarosch_L/0/1/0/all/0/1\">Lukas Jarosch</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Berenberg_D/0/1/0/all/0/1\">Daniel Berenberg</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Fisk_I/0/1/0/all/0/1\">Ian Fisk</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Watkins_A/0/1/0/all/0/1\">Andrew M. Watkins</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ra_S/0/1/0/all/0/1\">Stephen Ra</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bonneau_R/0/1/0/all/0/1\">Richard Bonneau</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+AlQuraishi_M/0/1/0/all/0/1\">Mohammed AlQuraishi</a>",
          "description": "Multiple sequence alignments (MSAs) of proteins encode rich biological\ninformation and have been workhorses in bioinformatic methods for tasks like\nprotein design and protein structure prediction for decades. Recent\nbreakthroughs like AlphaFold2 that use transformers to attend directly over\nlarge quantities of raw MSAs have reaffirmed their importance. Generation of\nMSAs is highly computationally intensive, however, and no datasets comparable\nto those used to train AlphaFold2 have been made available to the research\ncommunity, hindering progress in machine learning for proteins. To remedy this\nproblem, we introduce OpenProteinSet, an open-source corpus of more than 16\nmillion MSAs, associated structural homologs from the Protein Data Bank, and\nAlphaFold2 protein structure predictions. We have previously demonstrated the\nutility of OpenProteinSet by successfully retraining AlphaFold2 on it. We\nexpect OpenProteinSet to be broadly useful as training and validation data for\n1) diverse tasks focused on protein structure, function, and design and 2)\nlarge-scale multimodal machine learning research.",
          "link": "http://arxiv.org/abs/2308.05326",
          "publishedOn": "2023-08-12T00:39:31.529Z",
          "wordCount": null,
          "title": "OpenProteinSet: Training data for structural biology at scale. (arXiv:2308.05326v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Metz_C/0/1/0/all/0/1\">Christopher A. Metz</a>",
          "description": "Efficient and timely calculations of Machine Learning (ML) algorithms are\nessential for emerging technologies like autonomous driving, the Internet of\nThings (IoT), and edge computing. One of the primary ML algorithms used in such\nsystems is Convolutional Neural Networks (CNNs), which demand high\ncomputational resources. This requirement has led to the use of ML accelerators\nlike GPGPUs to meet design constraints. However, selecting the most suitable\naccelerator involves Design Space Exploration (DSE), a process that is usually\ntime-consuming and requires significant manual effort. Our work presents\napproaches to expedite the DSE process by identifying the most appropriate\nGPGPU for CNN inferencing systems. We have developed a quick and precise\ntechnique for forecasting the power and performance of CNNs during inference,\nwith a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer\narchitects to estimate power and performance in the early stages of\ndevelopment, reducing the necessity for numerous prototypes. This saves time\nand money while also improving the time-to-market period.",
          "link": "http://arxiv.org/abs/2308.05364",
          "publishedOn": "2023-08-12T00:39:31.529Z",
          "wordCount": null,
          "title": "Machine Learning aided Computer Architecture Design for CNN Inferencing Systems. (arXiv:2308.05364v1 [cs.AR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1\">Tianchang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munkberg_J/0/1/0/all/0/1\">Jacob Munkberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasselgren_J/0/1/0/all/0/1\">Jon Hasselgren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kangxue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenzheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gojcic_Z/0/1/0/all/0/1\">Zan Gojcic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharp_N/0/1/0/all/0/1\">Nicholas Sharp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jun Gao</a>",
          "description": "This work considers gradient-based mesh optimization, where we iteratively\noptimize for a 3D surface mesh by representing it as the isosurface of a scalar\nfield, an increasingly common paradigm in applications including\nphotogrammetry, generative modeling, and inverse physics. Existing\nimplementations adapt classic isosurface extraction algorithms like Marching\nCubes or Dual Contouring; these techniques were designed to extract meshes from\nfixed, known fields, and in the optimization setting they lack the degrees of\nfreedom to represent high-quality feature-preserving meshes, or suffer from\nnumerical instabilities. We introduce FlexiCubes, an isosurface representation\nspecifically designed for optimizing an unknown mesh with respect to geometric,\nvisual, or even physical objectives. Our main insight is to introduce\nadditional carefully-chosen parameters into the representation, which allow\nlocal flexible adjustments to the extracted mesh geometry and connectivity.\nThese parameters are updated along with the underlying scalar field via\nautomatic differentiation when optimizing for a downstream task. We base our\nextraction scheme on Dual Marching Cubes for improved topological properties,\nand present extensions to optionally generate tetrahedral and\nhierarchically-adaptive meshes. Extensive experiments validate FlexiCubes on\nboth synthetic benchmarks and real-world applications, showing that it offers\nsignificant improvements in mesh quality and geometric fidelity.",
          "link": "http://arxiv.org/abs/2308.05371",
          "publishedOn": "2023-08-12T00:39:31.528Z",
          "wordCount": null,
          "title": "Flexible Isosurface Extraction for Gradient-Based Mesh Optimization. (arXiv:2308.05371v1 [cs.GR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05226",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Spall_J/0/1/0/all/0/1\">James Spall</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guo_X/0/1/0/all/0/1\">Xianxin Guo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lvovsky_A/0/1/0/all/0/1\">A. I. Lvovsky</a>",
          "description": "Optics is an exciting route for the next generation of computing hardware for\nmachine learning, promising several orders of magnitude enhancement in both\ncomputational speed and energy efficiency. However, to reach the full capacity\nof an optical neural network it is necessary that the computing not only for\nthe inference, but also for the training be implemented optically. The primary\nalgorithm for training a neural network is backpropagation, in which the\ncalculation is performed in the order opposite to the information flow for\ninference. While straightforward in a digital computer, optical implementation\nof backpropagation has so far remained elusive, particularly because of the\nconflicting requirements for the optical element that implements the nonlinear\nactivation function. In this work, we address this challenge for the first time\nwith a surprisingly simple and generic scheme. Saturable absorbers are employed\nfor the role of the activation units, and the required properties are achieved\nthrough a pump-probe process, in which the forward propagating signal acts as\nthe pump and backward as the probe. Our approach is adaptable to various analog\nplatforms, materials, and network structures, and it demonstrates the\npossibility of constructing neural networks entirely reliant on analog optical\nprocesses for both training and inference tasks.",
          "link": "http://arxiv.org/abs/2308.05226",
          "publishedOn": "2023-08-12T00:39:31.445Z",
          "wordCount": null,
          "title": "Training neural networks with end-to-end optical backpropagation. (arXiv:2308.05226v1 [physics.optics])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1\">Armin Moin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1\">Atta Badii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Challenger_M/0/1/0/all/0/1\">Moharram Challenger</a>",
          "description": "Several architecture frameworks for software, systems, and enterprises have\nbeen proposed in the literature. They identified various stakeholders and\ndefined architecture viewpoints and views to frame and address stakeholder\nconcerns. However, the stakeholders with data science and Machine Learning (ML)\nrelated concerns, such as data scientists and data engineers, are yet to be\nincluded in existing architecture frameworks. Therefore, they failed to address\nthe architecture viewpoints and views responsive to the concerns of the data\nscience community. In this paper, we address this gap by establishing the\narchitecture frameworks adapted to meet the requirements of modern applications\nand organizations where ML artifacts are both prevalent and crucial. In\nparticular, we focus on ML-enabled Cyber-Physical Systems (CPSs) and propose\ntwo sets of merit criteria for their efficient development and performance\nassessment, namely the criteria for evaluating and benchmarking ML-enabled\nCPSs, and the criteria for evaluation and benchmarking of the tools intended to\nsupport users through the modeling and development pipeline. In this study, we\ndeploy multiple empirical and qualitative research methods based on literature\nreview and survey instruments including expert interviews and an online\nquestionnaire. We collect, analyze, and integrate the opinions of 77 experts\nfrom more than 25 organizations in over 10 countries to devise and validate the\nproposed framework.",
          "link": "http://arxiv.org/abs/2308.05239",
          "publishedOn": "2023-08-12T00:39:31.443Z",
          "wordCount": 726,
          "title": "AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS). (arXiv:2308.05239v1 [cs.SE])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_M/0/1/0/all/0/1\">Ming Gu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Gaoming Yang</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sheng Zhou</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Ma_N/0/1/0/all/0/1\">Ning Ma</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiawei Chen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Q/0/1/0/all/0/1\">Qiaoyu Tan</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Meihan Liu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1\">Jiajun Bu</a> (1) ((1) College of Computer Science and Technology, Zhejiang University, (2) School of Software Technology, Zhejiang University, (3) Zhejiang Provincial Key Laboratory of Service Robot, Zhejiang University, (4) Department of Computer Science, New York University Shanghai)",
          "description": "Graph clustering is a fundamental task in graph analysis, and recent advances\nin utilizing graph neural networks (GNNs) have shown impressive results.\nDespite the success of existing GNN-based graph clustering methods, they often\noverlook the quality of graph structure, which is inherent in real-world graphs\ndue to their sparse and multifarious nature, leading to subpar performance.\nGraph structure learning allows refining the input graph by adding missing\nlinks and removing spurious connections. However, previous endeavors in graph\nstructure learning have predominantly centered around supervised settings, and\ncannot be directly applied to our specific clustering tasks due to the absence\nof ground-truth labels. To bridge the gap, we propose a novel method called\n\\textbf{ho}mophily-enhanced structure \\textbf{le}arning for graph clustering\n(HoLe). Our motivation stems from the observation that subtly enhancing the\ndegree of homophily within the graph structure can significantly improve GNNs\nand clustering outcomes. To realize this objective, we develop two\nclustering-oriented structure learning modules, i.e., hierarchical correlation\nestimation and cluster-aware sparsification. The former module enables a more\naccurate estimation of pairwise node relationships by leveraging guidance from\nlatent and clustering spaces, while the latter one generates a sparsified\nstructure based on the similarity matrix and clustering assignments.\nAdditionally, we devise a joint optimization approach alternating between\ntraining the homophily-enhanced structure learning and GNN-based clustering,\nthereby enforcing their reciprocal effects. Extensive experiments on seven\nbenchmark datasets of various types and scales, across a range of clustering\nmetrics, demonstrate the superiority of HoLe against state-of-the-art\nbaselines.",
          "link": "http://arxiv.org/abs/2308.05309",
          "publishedOn": "2023-08-12T00:39:31.435Z",
          "wordCount": 807,
          "title": "Homophily-enhanced Structure Learning for Graph Clustering. (arXiv:2308.05309v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhengzhi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1\">Ziyi Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guoan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1\">Hubert P. H. Shum</a>",
          "description": "Recently, methods for skeleton-based human activity recognition have been\nshown to be vulnerable to adversarial attacks. However, these attack methods\nrequire either the full knowledge of the victim (i.e. white-box attacks),\naccess to training data (i.e. transfer-based attacks) or frequent model queries\n(i.e. black-box attacks). All their requirements are highly restrictive,\nraising the question of how detrimental the vulnerability is. In this paper, we\nshow that the vulnerability indeed exists. To this end, we consider a new\nattack task: the attacker has no access to the victim model or the training\ndata or labels, where we coin the term hard no-box attack. Specifically, we\nfirst learn a motion manifold where we define an adversarial loss to compute a\nnew gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our\ngradient contains information of the motion dynamics, which is different from\nexisting gradient-based attack methods that compute the loss gradient assuming\neach dimension in the data is independent. The SMI gradient can augment many\ngradient-based attack methods, leading to a new family of no-box attack\nmethods. Extensive evaluation and comparison show that our method imposes a\nreal threat to existing classifiers. They also show that the SMI gradient\nimproves the transferability and imperceptibility of adversarial samples in\nboth no-box and transfer-based black-box settings.",
          "link": "http://arxiv.org/abs/2308.05681",
          "publishedOn": "2023-08-12T00:39:31.410Z",
          "wordCount": 739,
          "title": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient. (arXiv:2308.05681v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hagedorn_S/0/1/0/all/0/1\">Steffen Hagedorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hallgarten_M/0/1/0/all/0/1\">Marcel Hallgarten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoll_M/0/1/0/all/0/1\">Martin Stoll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Condurache_A/0/1/0/all/0/1\">Alexandru Condurache</a>",
          "description": "Automated driving has the potential to revolutionize personal, public, and\nfreight mobility. Besides the enormous challenge of perception, i.e. accurately\nperceiving the environment using available sensor data, automated driving\ncomprises planning a safe, comfortable, and efficient motion trajectory. To\npromote safety and progress, many works rely on modules that predict the future\nmotion of surrounding traffic. Modular automated driving systems commonly\nhandle prediction and planning as sequential separate tasks. While this\naccounts for the influence of surrounding traffic on the ego-vehicle, it fails\nto anticipate the reactions of traffic participants to the ego-vehicle's\nbehavior. Recent works suggest that integrating prediction and planning in an\ninterdependent joint step is necessary to achieve safe, efficient, and\ncomfortable driving. While various models implement such integrated systems, a\ncomprehensive overview and theoretical understanding of different principles\nare lacking. We systematically review state-of-the-art deep learning-based\nprediction, planning, and integrated prediction and planning models. Different\nfacets of the integration ranging from model architecture and model design to\nbehavioral aspects are considered and related to each other. Moreover, we\ndiscuss the implications, strengths, and limitations of different integration\nmethods. By pointing out research gaps, describing relevant future challenges,\nand highlighting trends in the research field, we identify promising directions\nfor future research.",
          "link": "http://arxiv.org/abs/2308.05731",
          "publishedOn": "2023-08-12T00:39:31.402Z",
          "wordCount": null,
          "title": "Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review. (arXiv:2308.05731v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jialu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yicong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1\">Hao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>",
          "description": "Recent research in language-guided visual navigation has demonstrated a\nsignificant demand for the diversity of traversable environments and the\nquantity of supervision for training generalizable agents. To tackle the common\ndata scarcity issue in existing vision-and-language navigation datasets, we\npropose an effective paradigm for generating large-scale data for learning,\nwhich applies 1200+ photo-realistic environments from HM3D and Gibson datasets\nand synthesizes 4.9 million instruction trajectory pairs using fully-accessible\nresources on the web. Importantly, we investigate the influence of each\ncomponent in this paradigm on the agent's performance and study how to\nadequately apply the augmented data to pre-train and fine-tune an agent. Thanks\nto our large-scale dataset, the performance of an existing agent can be pushed\nup (+11% absolute with regard to previous SoTA) to a significantly new best of\n80% single-run success rate on the R2R test split by simple imitation learning.\nThe long-lasting generalization gap between navigating in seen and unseen\nenvironments is also reduced to less than 1% (versus 8% in the previous best\nmethod). Moreover, our paradigm also facilitates different models to achieve\nnew state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuous\nenvironments.",
          "link": "http://arxiv.org/abs/2307.15644",
          "publishedOn": "2023-08-12T00:39:31.402Z",
          "wordCount": null,
          "title": "Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Torres_M/0/1/0/all/0/1\">Miguel-&#xc1;ngel Fern&#xe1;ndez-Torres</a>",
          "description": "This PhD. Thesis concerns the study and development of hierarchical\nrepresentations for spatio-temporal visual attention modeling and understanding\nin video sequences. More specifically, we propose two computational models for\nvisual attention. First, we present a generative probabilistic model for\ncontext-aware visual attention modeling and understanding. Secondly, we develop\na deep network architecture for visual attention modeling, which first\nestimates top-down spatio-temporal visual attention, and ultimately serves for\nmodeling attention in the temporal domain.",
          "link": "http://arxiv.org/abs/2308.05189",
          "publishedOn": "2023-08-12T00:39:31.401Z",
          "wordCount": 573,
          "title": "Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding. (arXiv:2308.05189v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Torren_Peraire_P/0/1/0/all/0/1\">Paula Torren-Peraire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassen_A/0/1/0/all/0/1\">Alan Kai Hassen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genheden_S/0/1/0/all/0/1\">Samuel Genheden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verhoeven_J/0/1/0/all/0/1\">Jonas Verhoeven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clevert_D/0/1/0/all/0/1\">Djork-Arne Clevert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preuss_M/0/1/0/all/0/1\">Mike Preuss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tetko_I/0/1/0/all/0/1\">Igor Tetko</a>",
          "description": "Retrosynthesis consists of breaking down a chemical compound recursively\nstep-by-step into molecular precursors until a set of commercially available\nmolecules is found with the goal to provide a synthesis route. Its two primary\nresearch directions, single-step retrosynthesis prediction, which models the\nchemical reaction logic, and multi-step synthesis planning, which tries to find\nthe correct sequence of reactions, are inherently intertwined. Still, this\nconnection is not reflected in contemporary research. In this work, we combine\nthese two major research directions by applying multiple single-step\nretrosynthesis models within multi-step synthesis planning and analyzing their\nimpact using public and proprietary reaction data. We find a disconnection\nbetween high single-step performance and potential route-finding success,\nsuggesting that single-step models must be evaluated within synthesis planning\nin the future. Furthermore, we show that the commonly used single-step\nretrosynthesis benchmark dataset USPTO-50k is insufficient as this evaluation\ntask does not represent model performance and scalability on larger and more\ndiverse datasets. For multi-step synthesis planning, we show that the choice of\nthe single-step model can improve the overall success rate of synthesis\nplanning by up to +28% compared to the commonly used baseline model. Finally,\nwe show that each single-step model finds unique synthesis routes, and differs\nin aspects such as route-finding success, the number of found synthesis routes,\nand chemical validity, making the combination of single-step retrosynthesis\nprediction and multi-step synthesis planning a crucial aspect when developing\nfuture methods.",
          "link": "http://arxiv.org/abs/2308.05522",
          "publishedOn": "2023-08-12T00:39:31.396Z",
          "wordCount": 767,
          "title": "Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning. (arXiv:2308.05522v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.02279",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cipriani_C/0/1/0/all/0/1\">Cristina Cipriani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fornasier_M/0/1/0/all/0/1\">Massimo Fornasier</a>, <a href=\"http://arxiv.org/find/math/1/au:+Scagliotti_A/0/1/0/all/0/1\">Alessandro Scagliotti</a>",
          "description": "The connection between Residual Neural Networks (ResNets) and continuous-time\ncontrol systems (known as NeurODEs) has led to a mathematical analysis of\nneural networks which has provided interesting results of both theoretical and\npractical significance. However, by construction, NeurODEs have been limited to\ndescribing constant-width layers, making them unsuitable for modeling deep\nlearning architectures with layers of variable width. In this paper, we propose\na continuous-time Autoencoder, which we call AutoencODE, based on a\nmodification of the controlled field that drives the dynamics. This adaptation\nenables the extension of the mean-field control framework originally devised\nfor conventional NeurODEs. In this setting, we tackle the case of low Tikhonov\nregularization, resulting in potentially non-convex cost landscapes. While the\nglobal results obtained for high Tikhonov regularization may not hold globally,\nwe show that many of them can be recovered in regions where the loss function\nis locally convex. Inspired by our theoretical findings, we develop a training\nmethod tailored to this specific type of Autoencoders with residual\nconnections, and we validate our approach through numerical experiments\nconducted on various examples.",
          "link": "http://arxiv.org/abs/2307.02279",
          "publishedOn": "2023-08-12T00:39:31.390Z",
          "wordCount": 726,
          "title": "From NeurODEs to AutoencODEs: a mean-field control framework for width-varying Neural Networks. (arXiv:2307.02279v2 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.16361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Q/0/1/0/all/0/1\">Qiufan Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Cong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengshan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yingying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>",
          "description": "Deep Neural Networks (DNNs) for 3D point cloud recognition are vulnerable to\nadversarial examples, threatening their practical deployment. Despite the many\nresearch endeavors have been made to tackle this issue in recent years, the\ndiversity of adversarial examples on 3D point clouds makes them more\nchallenging to defend against than those on 2D images. For examples, attackers\ncan generate adversarial examples by adding, shifting, or removing points.\nConsequently, existing defense strategies are hard to counter unseen point\ncloud adversarial examples. In this paper, we first establish a comprehensive,\nand rigorous point cloud adversarial robustness benchmark to evaluate\nadversarial robustness, which can provide a detailed understanding of the\neffects of the defense and attack methods. We then collect existing defense\ntricks in point cloud adversarial defenses and then perform extensive and\nsystematic experiments to identify an effective combination of these tricks.\nFurthermore, we propose a hybrid training augmentation methods that consider\nvarious types of point cloud adversarial examples to adversarial training,\nsignificantly improving the adversarial robustness. By combining these tricks,\nwe construct a more robust defense framework achieving an average accuracy of\n83.45\\% against various attacks, demonstrating its capability to enabling\nrobust learners. Our codebase are open-sourced on:\n\\url{https://github.com/qiufan319/benchmark_pc_attack.git}.",
          "link": "http://arxiv.org/abs/2307.16361",
          "publishedOn": "2023-08-12T00:39:31.371Z",
          "wordCount": 759,
          "title": "Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples. (arXiv:2307.16361v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_I/0/1/0/all/0/1\">Iknoor Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>",
          "description": "The task of retrieving already debunked narratives aims to detect stories\nthat have already been fact-checked. The successful detection of claims that\nhave already been debunked not only reduces the manual efforts of professional\nfact-checkers but can also contribute to slowing the spread of misinformation.\nMainly due to the lack of readily available data, this is an understudied\nproblem, particularly when considering the cross-lingual task, i.e. the\nretrieval of fact-checking articles in a language different from the language\nof the online post being checked. This paper fills this gap by (i) creating a\nnovel dataset to enable research on cross-lingual retrieval of already debunked\nnarratives, using tweets as queries to a database of fact-checking articles;\n(ii) presenting an extensive experiment to benchmark fine-tuned and\noff-the-shelf multilingual pre-trained Transformer models for this task; and\n(iii) proposing a novel multistage framework that divides this cross-lingual\ndebunk retrieval task into refinement and re-ranking stages. Results show that\nthe task of cross-lingual retrieval of already debunked narratives is\nchallenging and off-the-shelf Transformer models fail to outperform a strong\nlexical-based baseline (BM25). Nevertheless, our multistage retrieval framework\nis robust, outperforming BM25 in most scenarios and enabling cross-domain and\nzero-shot learning, without significantly harming the model's performance.",
          "link": "http://arxiv.org/abs/2308.05680",
          "publishedOn": "2023-08-12T00:39:31.365Z",
          "wordCount": 736,
          "title": "Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning. (arXiv:2308.05680v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_M/0/1/0/all/0/1\">Meng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budd_C/0/1/0/all/0/1\">Charlie Budd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Peraza_Herrera_L/0/1/0/all/0/1\">Luis C. Garcia-Peraza-Herrera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dorent_R/0/1/0/all/0/1\">Reuben Dorent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1\">Miaojing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vercauteren_T/0/1/0/all/0/1\">Tom Vercauteren</a>",
          "description": "Surgical instrument segmentation is recognised as a key enabler to provide\nadvanced surgical assistance and improve computer assisted interventions. In\nthis work, we propose SegMatch, a semi supervised learning method to reduce the\nneed for expensive annotation for laparoscopic and robotic surgical images.\nSegMatch builds on FixMatch, a widespread semi supervised classification\npipeline combining consistency regularization and pseudo labelling, and adapts\nit for the purpose of segmentation. In our proposed SegMatch, the unlabelled\nimages are weakly augmented and fed into the segmentation model to generate a\npseudo-label to enforce the unsupervised loss against the output of the model\nfor the adversarial augmented image on the pixels with a high confidence score.\nOur adaptation for segmentation tasks includes carefully considering the\nequivariance and invariance properties of the augmentation functions we rely\non. To increase the relevance of our augmentations, we depart from using only\nhandcrafted augmentations and introduce a trainable adversarial augmentation\nstrategy. Our algorithm was evaluated on the MICCAI Instrument Segmentation\nChallenge datasets Robust-MIS 2019 and EndoVis 2017. Our results demonstrate\nthat adding unlabelled data for training purposes allows us to surpass the\nperformance of fully supervised approaches which are limited by the\navailability of training data in these challenges. SegMatch also outperforms a\nrange of state-of-the-art semi-supervised learning semantic segmentation models\nin different labelled to unlabelled data ratios.",
          "link": "http://arxiv.org/abs/2308.05232",
          "publishedOn": "2023-08-12T00:39:31.358Z",
          "wordCount": 739,
          "title": "SegMatch: A semi-supervised learning method for surgical instrument segmentation. (arXiv:2308.05232v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Uhlemann_N/0/1/0/all/0/1\">Nico Uhlemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fent_F/0/1/0/all/0/1\">Felix Fent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lienkamp_M/0/1/0/all/0/1\">Markus Lienkamp</a>",
          "description": "In this paper, the state of the art in the field of pedestrian trajectory\nprediction is evaluated alongside the constant velocity model (CVM) with\nrespect to its applicability in autonomous vehicles. The evaluation is\nconducted on the widely-used ETH/UCY dataset where the Average Displacement\nError (ADE) and the Final Displacement Error (FDE) are reported. To align with\nrequirements in real-world applications, modifications are made to the input\nfeatures of the initially proposed models. An ablation study is conducted to\nexamine the influence of the observed motion history on the prediction\nperformance, thereby establishing a better understanding of its impact.\nAdditionally, the inference time of each model is measured to evaluate the\nscalability of each model when confronted with varying amounts of agents. The\nresults demonstrate that simple models remain competitive when generating\nsingle trajectories, and certain features commonly thought of as useful have\nlittle impact on the overall performance across different architectures. Based\non these findings, recommendations are proposed to guide the future development\nof trajectory prediction algorithms.",
          "link": "http://arxiv.org/abs/2308.05194",
          "publishedOn": "2023-08-12T00:39:31.350Z",
          "wordCount": 699,
          "title": "Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving. (arXiv:2308.05194v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05564",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Deng_L/0/1/0/all/0/1\">Lin Deng</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Smith_M/0/1/0/all/0/1\">Michael Stanley Smith</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Maneesoonthorn_W/0/1/0/all/0/1\">Worapree Maneesoonthorn</a>",
          "description": "Large skew-t factor copula models are attractive for the modeling of\nfinancial data because they allow for asymmetric and extreme tail dependence.\nWe show that the copula implicit in the skew-t distribution of Azzalini and\nCapitanio (2003) allows for a higher level of pairwise asymmetric dependence\nthan two popular alternative skew-t copulas. Estimation of this copula in high\ndimensions is challenging, and we propose a fast and accurate Bayesian\nvariational inference (VI) approach to do so. The method uses a conditionally\nGaussian generative representation of the skew-t distribution to define an\naugmented posterior that can be approximated accurately. A fast stochastic\ngradient ascent algorithm is used to solve the variational optimization. The\nnew methodology is used to estimate copula models for intraday returns from\n2017 to 2021 on 93 U.S. equities. The copula captures substantial heterogeneity\nin asymmetric dependence over equity pairs, in addition to the variability in\npairwise correlations. We show that intraday predictive densities from the\nskew-t copula are more accurate than from some other copula models, while\nportfolio selection strategies based on the estimated pairwise tail\ndependencies improve performance relative to the benchmark index.",
          "link": "http://arxiv.org/abs/2308.05564",
          "publishedOn": "2023-08-12T00:39:31.343Z",
          "wordCount": 710,
          "title": "Efficient Variational Inference for Large Skew-t Copulas with Application to Intraday Equity Returns. (arXiv:2308.05564v1 [econ.EM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.03942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1\">Kamalika Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stock_P/0/1/0/all/0/1\">Pierre Stock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Mike Rabbat</a>",
          "description": "In private federated learning (FL), a server aggregates differentially\nprivate updates from a large number of clients in order to train a machine\nlearning model. The main challenge in this setting is balancing privacy with\nboth classification accuracy of the learnt model as well as the number of bits\ncommunicated between the clients and server. Prior work has achieved a good\ntrade-off by designing a privacy-aware compression mechanism, called the\nminimum variance unbiased (MVU) mechanism, that numerically solves an\noptimization problem to determine the parameters of the mechanism. This paper\nbuilds upon it by introducing a new interpolation procedure in the numerical\ndesign process that allows for a far more efficient privacy analysis. The\nresult is the new Interpolated MVU mechanism that is more scalable, has a\nbetter privacy-utility trade-off, and provides SOTA results on\ncommunication-efficient private FL on a variety of datasets.",
          "link": "http://arxiv.org/abs/2211.03942",
          "publishedOn": "2023-08-12T00:39:31.321Z",
          "wordCount": 680,
          "title": "Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design. (arXiv:2211.03942v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05619",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Otles_E/0/1/0/all/0/1\">Erkin &#xd6;tle&#x15f;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Denton_B/0/1/0/all/0/1\">Brian T. Denton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wiens_J/0/1/0/all/0/1\">Jenna Wiens</a>",
          "description": "As data shift or new data become available, updating clinical machine\nlearning models may be necessary to maintain or improve performance over time.\nHowever, updating a model can introduce compatibility issues when the behavior\nof the updated model does not align with user expectations, resulting in poor\nuser-model team performance. Existing compatibility measures depend on model\ndecision thresholds, limiting their applicability in settings where models are\nused to generate rankings based on estimated risk. To address this limitation,\nwe propose a novel rank-based compatibility measure, $C^R$, and a new loss\nfunction that aims to optimize discriminative performance while encouraging\ngood compatibility. Applied to a case study in mortality risk stratification\nleveraging data from MIMIC, our approach yields more compatible models while\nmaintaining discriminative performance compared to existing model selection\ntechniques, with an increase in $C^R$ of $0.019$ ($95\\%$ confidence interval:\n$0.005$, $0.035$). This work provides new tools to analyze and update risk\nstratification models used in clinical care.",
          "link": "http://arxiv.org/abs/2308.05619",
          "publishedOn": "2023-08-12T00:39:31.313Z",
          "wordCount": 708,
          "title": "Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance. (arXiv:2308.05619v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.16021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohan_A/0/1/0/all/0/1\">Aditya Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "Reinforcement Learning (RL), bolstered by the expressive capabilities of Deep\nNeural Networks (DNNs) for function approximation, has demonstrated\nconsiderable success in numerous applications. However, its practicality in\naddressing various real-world scenarios, characterized by diverse and\nunpredictable dynamics, noisy signals, and large state and action spaces,\nremains limited. This limitation stems from issues such as poor data\nefficiency, limited generalization capabilities, a lack of safety guarantees,\nand the absence of interpretability, among other factors. To overcome these\nchallenges and improve performance across these crucial metrics, one promising\navenue is to incorporate additional structural information about the problem\ninto the RL learning process. Various sub-fields of RL have proposed methods\nfor incorporating such inductive biases. We amalgamate these diverse\nmethodologies under a unified framework, shedding light on the role of\nstructure in the learning problem, and classify these methods into distinct\npatterns of incorporating structure. By leveraging this comprehensive\nframework, we provide valuable insights into the challenges of structured RL\nand lay the groundwork for a design pattern perspective on RL research. This\nnovel perspective paves the way for future advancements and aids in developing\nmore effective and efficient RL algorithms that can potentially handle\nreal-world scenarios better.",
          "link": "http://arxiv.org/abs/2306.16021",
          "publishedOn": "2023-08-12T00:39:31.307Z",
          "wordCount": 721,
          "title": "Structure in Reinforcement Learning: A Survey and Open Problems. (arXiv:2306.16021v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rane_C/0/1/0/all/0/1\">Chinmay Rane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_K/0/1/0/all/0/1\">Kanishka Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manry_M/0/1/0/all/0/1\">Michael Manry</a>",
          "description": "Deep learning training training algorithms are a huge success in recent years\nin many fields including speech, text,image video etc. Deeper and deeper layers\nare proposed with huge success with resnet structures having around 152 layers.\nShallow convolution neural networks(CNN's) are still an active research, where\nsome phenomena are still unexplained. Activation functions used in the network\nare of utmost importance, as they provide non linearity to the networks. Relu's\nare the most commonly used activation function.We show a complex piece-wise\nlinear(PWL) activation in the hidden layer. We show that these PWL activations\nwork much better than relu activations in our networks for convolution neural\nnetworks and multilayer perceptrons. Result comparison in PyTorch for shallow\nand deep CNNs are given to further strengthen our case.",
          "link": "http://arxiv.org/abs/2308.05724",
          "publishedOn": "2023-08-12T00:39:31.237Z",
          "wordCount": null,
          "title": "Optimizing Performance of Feedforward and Convolutional Neural Networks through Dynamic Activation Functions. (arXiv:2308.05724v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tu Anh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAvirro_A/0/1/0/all/0/1\">Antony D&#x27;Avirro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1\">Itai Gat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazel_Zarani_M/0/1/0/all/0/1\">Maryam Fazel-Zarani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1\">Tal Remez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Copet_J/0/1/0/all/0/1\">Jade Copet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassid_M/0/1/0/all/0/1\">Michael Hassid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1\">Emmanuel Dupoux</a>",
          "description": "Recent work has shown that it is possible to resynthesize high-quality speech\nbased, not on text, but on low bitrate discrete units that have been learned in\na self-supervised fashion and can therefore capture expressive aspects of\nspeech that are hard to transcribe (prosody, voice styles, non-verbal\nvocalization). The adoption of these methods is still limited by the fact that\nmost speech synthesis datasets are read, severely limiting spontaneity and\nexpressivity. Here, we introduce Expresso, a high-quality expressive speech\ndataset for textless speech synthesis that includes both read speech and\nimprovised dialogues rendered in 26 spontaneous expressive styles. We\nillustrate the challenges and potentials of this dataset with an expressive\nresynthesis benchmark where the task is to encode the input in low-bitrate\nunits and resynthesize it in a target voice while preserving content and style.\nWe evaluate resynthesis quality with automatic metrics for different\nself-supervised discrete encoders, and explore tradeoffs between quality,\nbitrate and invariance to speaker and style. All the dataset, evaluation\nmetrics and baseline models are open source",
          "link": "http://arxiv.org/abs/2308.05725",
          "publishedOn": "2023-08-12T00:39:31.237Z",
          "wordCount": null,
          "title": "EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis. (arXiv:2308.05725v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.06601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Siquan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yijiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Leyu Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Ying Gao</a>",
          "description": "The decentralized and privacy-preserving nature of federated learning (FL)\nmakes it vulnerable to backdoor attacks aiming to manipulate the behavior of\nthe resulting model on specific adversary-chosen inputs. However, most existing\ndefenses based on statistical differences take effect only against specific\nattacks, especially when the malicious gradients are similar to benign ones or\nthe data are highly non-independent and identically distributed (non-IID). In\nthis paper, we revisit the distance-based defense methods and discover that i)\nEuclidean distance becomes meaningless in high dimensions and ii) malicious\ngradients with diverse characteristics cannot be identified by a single metric.\nTo this end, we present a simple yet effective defense strategy with\nmulti-metrics and dynamic weighting to identify backdoors adaptively.\nFurthermore, our novel defense has no reliance on predefined assumptions over\nattack settings or data distributions and little impact on benign performance.\nTo evaluate the effectiveness of our approach, we conduct comprehensive\nexperiments on different datasets under various attack settings, where our\nmethod achieves the best defensive performance. For instance, we achieve the\nlowest backdoor accuracy of 3.06% under the difficult Edge-case PGD, showing\nsignificant superiority over previous defenses. The results also demonstrate\nthat our method can be well-adapted to a wide range of non-IID degrees without\nsacrificing the benign performance.",
          "link": "http://arxiv.org/abs/2303.06601",
          "publishedOn": "2023-08-12T00:39:31.236Z",
          "wordCount": null,
          "title": "Multi-metrics adaptively identifies backdoors in Federated learning. (arXiv:2303.06601v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05275",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1\">Pengfei Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guanfeng Liu</a>",
          "description": "In recent years, heterogeneous graph few-shot learning has been proposed to\naddress the label sparsity issue in heterogeneous graphs (HGs), which contain\nvarious types of nodes and edges. The existing methods have achieved good\nperformance by transferring generalized knowledge extracted from rich-labeled\nclasses in source HG(s) to few-labeled classes in a target HG. However, these\nmethods only consider the single-heterogeneity scenario where the source and\ntarget HGs share a fixed set of node/edge types, ignoring the more general\nscenario of cross-heterogeneity, where each HG can have a different and\nnon-fixed set of node/edge types. To this end, we focus on the unexplored\ncross-heterogeneity scenario and propose a novel model for Cross-heterogeneity\nGraph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns\nto capture heterogeneous information and propose a multi-view heterogeneous\ngraph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose\na score module to measure the informativeness of labeled samples and determine\nthe transferability of each source HG. Finally, by integrating MHGN and the\nscore module into a meta-learning mechanism, CGFL can effectively transfer\ngeneralized knowledge to predict new classes with few-labeled data. Extensive\nexperiments on four real-world datasets have demonstrated the superior\nperformance of CGFL over the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2308.05275",
          "publishedOn": "2023-08-12T00:39:31.235Z",
          "wordCount": null,
          "title": "Cross-heterogeneity Graph Few-shot Learning. (arXiv:2308.05275v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jie Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Q/0/1/0/all/0/1\">Qing Ling</a>",
          "description": "This paper studies Byzantine-robust stochastic optimization over a\ndecentralized network, where every agent periodically communicates with its\nneighbors to exchange local models, and then updates its own local model by\nstochastic gradient descent (SGD). The performance of such a method is affected\nby an unknown number of Byzantine agents, which conduct adversarially during\nthe optimization process. To the best of our knowledge, there is no existing\nwork that simultaneously achieves a linear convergence speed and a small\nlearning error. We observe that the learning error is largely dependent on the\nintrinsic stochastic gradient noise. Motivated by this observation, we\nintroduce two variance reduction methods, stochastic average gradient algorithm\n(SAGA) and loopless stochastic variance-reduced gradient (LSVRG), to\nByzantine-robust decentralized stochastic optimization for eliminating the\nnegative effect of the stochastic gradient noise. The two resulting methods,\nBRAVO-SAGA and BRAVO-LSVRG, enjoy both linear convergence speeds and stochastic\ngradient noise-independent learning errors. Such learning errors are optimal\nfor a class of methods based on total variation (TV)-norm regularization and\nstochastic subgradient update. We conduct extensive numerical experiments to\ndemonstrate their effectiveness under various Byzantine attacks.",
          "link": "http://arxiv.org/abs/2308.05292",
          "publishedOn": "2023-08-12T00:39:31.235Z",
          "wordCount": null,
          "title": "Byzantine-Robust Decentralized Stochastic Optimization with Stochastic Gradient Noise-Independent Learning Error. (arXiv:2308.05292v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1\">Vinod Kumar Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiandong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Ping Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molaei_S/0/1/0/all/0/1\">Soheila Molaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>",
          "description": "Hypernetworks, or hypernets in short, are neural networks that generate\nweights for another neural network, known as the target network. They have\nemerged as a powerful deep learning technique that allows for greater\nflexibility, adaptability, dynamism, faster training, information sharing, and\nmodel compression etc. Hypernets have shown promising results in a variety of\ndeep learning problems, including continual learning, causal inference,\ntransfer learning, weight pruning, uncertainty quantification, zero-shot\nlearning, natural language processing, and reinforcement learning etc. Despite\ntheir success across different problem settings, currently, there is no review\navailable to inform the researchers about the developments and to help in\nutilizing hypernets. To fill this gap, we review the progress in hypernets. We\npresent an illustrative example to train deep neural networks using hypernets\nand propose categorizing hypernets based on five design criteria as inputs,\noutputs, variability of inputs and outputs, and architecture of hypernets. We\nalso review applications of hypernets across different deep learning problem\nsettings, followed by a discussion of general scenarios where hypernets can be\neffectively employed. Finally, we discuss the challenges and future directions\nthat remain under-explored in the field of hypernets. We believe that\nhypernetworks have the potential to revolutionize the field of deep learning.\nThey offer a new way to design and train neural networks, and they have the\npotential to improve the performance of deep learning models on a variety of\ntasks. Through this review, we aim to inspire further advancements in deep\nlearning through hypernetworks.",
          "link": "http://arxiv.org/abs/2306.06955",
          "publishedOn": "2023-08-12T00:39:31.153Z",
          "wordCount": null,
          "title": "A Brief Review of Hypernetworks in Deep Learning. (arXiv:2306.06955v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1\">Matthew J. Vowels</a>",
          "description": "Causal inference is a crucial goal of science, enabling researchers to arrive\nat meaningful conclusions regarding the predictions of hypothetical\ninterventions using observational data. Path models, Structural Equation Models\n(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to\nunambiguously specify assumptions regarding the causal structure underlying a\nphenomenon. Unlike DAGs, which make very few assumptions about the functional\nand parametric form, SEM assumes linearity. This can result in functional\nmisspecification which prevents researchers from undertaking reliable effect\nsize estimation. In contrast, we propose Super Learner Equation Modeling, a\npath modeling technique integrating machine learning Super Learner ensembles.\nWe empirically demonstrate its ability to provide consistent and unbiased\nestimates of causal effects, its competitive performance for linear models when\ncompared with SEM, and highlight its superiority over SEM when dealing with\nnon-linear relationships. We provide open-source code, and a tutorial notebook\nwith example usage, accentuating the easy-to-use nature of the method.",
          "link": "http://arxiv.org/abs/2308.04365",
          "publishedOn": "2023-08-12T00:39:31.153Z",
          "wordCount": null,
          "title": "SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_V/0/1/0/all/0/1\">Vladimir G. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aigerman_N/0/1/0/all/0/1\">Noam Aigerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_A/0/1/0/all/0/1\">Alec Jacobson</a>",
          "description": "The recent proliferation of 3D content that can be consumed on hand-held\ndevices necessitates efficient tools for transmitting large geometric data,\ne.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a\nchallenge to storage as well as transmission bandwidth, and level-of-detail\ntechniques are often used to transmit an asset using an appropriate bandwidth\nbudget. It is especially desirable for these methods to transmit data\nprogressively, improving the quality of the geometry with more data. Our key\ninsight is that the geometric details of 3D meshes often exhibit similar local\npatterns even across different shapes, and thus can be effectively represented\nwith a shared learned generative space. We learn this space using a\nsubdivision-based encoder-decoder architecture trained in advance on a large\ncollection of surfaces. We further observe that additional residual features\ncan be transmitted progressively between intermediate levels of subdivision\nthat enable the client to control the tradeoff between bandwidth cost and\nquality of reconstruction, providing a neural progressive mesh representation.\nWe evaluate our method on a diverse set of complex 3D shapes and demonstrate\nthat it outperforms baselines in terms of compression ratio and reconstruction\nquality.",
          "link": "http://arxiv.org/abs/2308.05741",
          "publishedOn": "2023-08-12T00:39:31.038Z",
          "wordCount": null,
          "title": "Neural Progressive Meshes. (arXiv:2308.05741v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.06024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madadi_B/0/1/0/all/0/1\">Bahman Madadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Correia_G/0/1/0/all/0/1\">Goncalo Homem de Almeida Correia</a>",
          "description": "This study proposes a hybrid deep-learning-metaheuristic framework with a\nbi-level architecture for road network design problems (NDPs). We train a graph\nneural network (GNN) to approximate the solution of the user equilibrium (UE)\ntraffic assignment problem and use inferences made by the trained model to\ncalculate fitness function evaluations of a genetic algorithm (GA) to\napproximate solutions for NDPs. Using three test networks, two NDP variants and\nan exact solver as benchmark, we show that on average, our proposed framework\ncan provide solutions within 1.5% gap of the best results in less than 0.5% of\nthe time used by the exact solution procedure. Our framework can be utilized\nwithin an expert system for infrastructure planning to determine the best\ninfrastructure planning and management decisions under different scenarios.\nGiven the flexibility of the framework, it can easily be adapted to many other\ndecision problems that can be modeled as bi-level problems on graphs. Moreover,\nwe foreseen interesting future research directions, thus we also put forward a\nbrief research agenda for this topic. The key observation from our research\nthat can shape future research is that the fitness function evaluation time\nusing the inferences made by the GNN model was in the order of milliseconds,\nwhich points to an opportunity and a need for novel heuristics that 1) can cope\nwell with noisy fitness function values provided by deep learning models, and\n2) can use the significantly enlarged efficiency of the evaluation step to\nexplore the search space effectively (rather than efficiently). This opens a\nnew avenue for a modern class of metaheuristics that are crafted for use with\nAI-powered predictors.",
          "link": "http://arxiv.org/abs/2303.06024",
          "publishedOn": "2023-08-12T00:39:30.955Z",
          "wordCount": null,
          "title": "A hybrid deep-learning-metaheuristic framework for bi-level network design problems. (arXiv:2303.06024v3 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.14961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franco_N/0/1/0/all/0/1\">Nicola Franco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korth_D/0/1/0/all/0/1\">Daniel Korth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenz_J/0/1/0/all/0/1\">Jeanette Miriam Lorenz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roscher_K/0/1/0/all/0/1\">Karsten Roscher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guennemann_S/0/1/0/all/0/1\">Stephan Guennemann</a>",
          "description": "As the use of machine learning continues to expand, the importance of\nensuring its safety cannot be overstated. A key concern in this regard is the\nability to identify whether a given sample is from the training distribution,\nor is an \"Out-Of-Distribution\" (OOD) sample. In addition, adversaries can\nmanipulate OOD samples in ways that lead a classifier to make a confident\nprediction. In this study, we present a novel approach for certifying the\nrobustness of OOD detection within a $\\ell_2$-norm around the input, regardless\nof network architecture and without the need for specific components or\nadditional training. Further, we improve current techniques for detecting\nadversarial attacks on OOD samples, while providing high levels of certified\nand adversarial robustness on in-distribution samples. The average of all OOD\ndetection metrics on CIFAR10/100 shows an increase of $\\sim 13 \\% / 5\\%$\nrelative to previous approaches.",
          "link": "http://arxiv.org/abs/2303.14961",
          "publishedOn": "2023-08-12T00:39:30.900Z",
          "wordCount": null,
          "title": "Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection. (arXiv:2303.14961v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05711",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Marshall Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willes_J/0/1/0/all/0/1\">John Willes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiralerspong_T/0/1/0/all/0/1\">Thomas Jiralerspong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moezzi_M/0/1/0/all/0/1\">Matin Moezzi</a>",
          "description": "Reinforcement learning (RL) is a promising approach for optimizing HVAC\ncontrol. RL offers a framework for improving system performance, reducing\nenergy consumption, and enhancing cost efficiency. We benchmark two popular\nclassical and deep RL methods (Q-Learning and Deep-Q-Networks) across multiple\nHVAC environments and explore the practical consideration of model\nhyper-parameter selection and reward tuning. The findings provide insight for\nconfiguring RL agents in HVAC systems, promoting energy-efficient and\ncost-effective operation.",
          "link": "http://arxiv.org/abs/2308.05711",
          "publishedOn": "2023-08-12T00:39:30.899Z",
          "wordCount": null,
          "title": "A Comparison of Classical and Deep Reinforcement Learning Methods for HVAC Control. (arXiv:2308.05711v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.00790",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Wong_T/0/1/0/all/0/1\">Thomas Wong</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Barahona_M/0/1/0/all/0/1\">Mauricio Barahona</a>",
          "description": "The application of deep learning to non-stationary temporal datasets can lead\nto overfitted models that underperform under regime changes. In this work, we\npropose a modular machine learning pipeline for ranking predictions on temporal\npanel datasets which is robust under regime changes. The modularity of the\npipeline allows the use of different models, including Gradient Boosting\nDecision Trees (GBDTs) and Neural Networks, with and without feature\nengineering. We evaluate our framework on financial data for stock portfolio\nprediction, and find that GBDT models with dropout display high performance,\nrobustness and generalisability with reduced complexity and computational cost.\nWe then demonstrate how online learning techniques, which require no retraining\nof models, can be used post-prediction to enhance the results. First, we show\nthat dynamic feature projection improves robustness by reducing drawdown in\nregime changes. Second, we demonstrate that dynamical model ensembling based on\nselection of models with good recent performance leads to improved Sharpe and\nCalmar ratios of out-of-sample predictions. We also evaluate the robustness of\nour pipeline across different data splits and random seeds with good\nreproducibility.",
          "link": "http://arxiv.org/abs/2301.00790",
          "publishedOn": "2023-08-12T00:39:30.899Z",
          "wordCount": null,
          "title": "Online learning techniques for prediction of temporal tabular datasets with regime changes. (arXiv:2301.00790v4 [q-fin.CP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.09738",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1\">Wu Lin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duruisseaux_V/0/1/0/all/0/1\">Valentin Duruisseaux</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Leok_M/0/1/0/all/0/1\">Melvin Leok</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nielsen_F/0/1/0/all/0/1\">Frank Nielsen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1\">Mark Schmidt</a>",
          "description": "Riemannian submanifold optimization with momentum is computationally\nchallenging because, to ensure that the iterates remain on the submanifold, we\noften need to solve difficult differential equations. Here, we simplify such\ndifficulties for a class of sparse or structured symmetric positive-definite\nmatrices with the affine-invariant metric. We do so by proposing a generalized\nversion of the Riemannian normal coordinates that dynamically orthonormalizes\nthe metric and locally converts the problem into an unconstrained problem in\nthe Euclidean space. We use our approach to simplify existing approaches for\nstructured covariances and develop matrix-inverse-free $2^\\text{nd}$-order\noptimizers for deep learning with low precision by using only matrix\nmultiplications. Code: https://github.com/yorkerlin/StructuredNGD-DL",
          "link": "http://arxiv.org/abs/2302.09738",
          "publishedOn": "2023-08-12T00:39:30.899Z",
          "wordCount": null,
          "title": "Simplifying Momentum-based Positive-definite Submanifold Optimization with Applications to Deep Learning. (arXiv:2302.09738v7 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Weilong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianpu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianwu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhuofeng Zhao</a>",
          "description": "Inter-city highway transportation is significant for urban life. As one of\nthe key functions in intelligent transportation system (ITS), traffic\nevaluation always plays significant role nowadays, and daily traffic flow\nprediction still faces challenges at network-wide toll stations. On the one\nhand, the data imbalance in practice among various locations deteriorates the\nperformance of prediction. On the other hand, complex correlative\nspatio-temporal factors cannot be comprehensively employed in long-term\nduration. In this paper, a prediction method is proposed for daily traffic flow\nin highway domain through spatio-temporal deep learning. In our method, data\nnormalization strategy is used to deal with data imbalance, due to long-tail\ndistribution of traffic flow at network-wide toll stations. And then, based on\ngraph convolutional network, we construct networks in distinct semantics to\ncapture spatio-temporal features. Beside that, meteorology and calendar\nfeatures are used by our model in the full connection stage to extra external\ncharacteristics of traffic flow. By extensive experiments and case studies in\none Chinese provincial highway, our method shows clear improvement in\npredictive accuracy than baselines and practical benefits in business.",
          "link": "http://arxiv.org/abs/2308.05601",
          "publishedOn": "2023-08-12T00:39:30.871Z",
          "wordCount": null,
          "title": "Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction. (arXiv:2308.05601v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xuanhe Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guoliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>",
          "description": "Database administrators (DBAs) play a crucial role in managing, maintaining\nand optimizing a database system to ensure data availability, performance, and\nreliability. However, it is hard and tedious for DBAs to manage a large number\nof database instances (e.g., millions of instances on the cloud databases).\nRecently large language models (LLMs) have shown great potential to understand\nvaluable documents and accordingly generate reasonable answers. Thus, we\npropose D-Bot, a LLM-based database administrator that can continuously acquire\ndatabase maintenance experience from textual sources, and provide reasonable,\nwell-founded, in-time diagnosis and optimization advice for target databases.\nThis paper presents a revolutionary LLM-centric framework for database\nmaintenance, including (i) database maintenance knowledge detection from\ndocuments and tools, (ii) tree of thought reasoning for root cause analysis,\nand (iii) collaborative diagnosis among multiple LLMs. Our preliminary\nexperimental results that D-Bot can efficiently and effectively diagnose the\nroot causes and our code is available at\ngithub.com/TsinghuaDatabaseGroup/DB-GPT.",
          "link": "http://arxiv.org/abs/2308.05481",
          "publishedOn": "2023-08-12T00:39:30.868Z",
          "wordCount": null,
          "title": "LLM As DBA. (arXiv:2308.05481v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yvinec_E/0/1/0/all/0/1\">Edouard Yvinec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dapogny_A/0/1/0/all/0/1\">Arnaud Dapogny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bailly_K/0/1/0/all/0/1\">Kevin Bailly</a>",
          "description": "Deep neural network (DNN) deployment has been confined to larger hardware\ndevices due to their expensive computational requirements. This challenge has\nrecently reached another scale with the emergence of large language models\n(LLMs). In order to reduce both their memory footprint and latency, a promising\ntechnique is quantization. It consists in converting floating point\nrepresentations to low bit-width fixed point representations, usually by\nassuming a uniform mapping onto a regular grid. This process, referred to in\nthe literature as uniform quantization, may however be ill-suited as most DNN\nweights and activations follow a bell-shaped distribution. This is even worse\non LLMs whose weight distributions are known to exhibit large, high impact,\noutlier values. In this work, we propose an improvement over the most commonly\nadopted way to tackle this limitation in deep learning models quantization,\nnamely, non-uniform quantization. NUPES leverages automorphisms to preserve the\nscalar multiplications. Such transformations are derived from power functions.\nHowever, the optimization of the exponent parameter and weight values remains a\nchallenging and novel problem which could not be solved with previous post\ntraining optimization techniques which only learn to round up or down weight\nvalues in order to preserve the predictive function. We circumvent this\nlimitation with a new paradigm: learning new quantized weights over the entire\nquantized space. Similarly, we enable the optimization of the power exponent,\ni.e. the optimization of the quantization operator itself during training by\nalleviating all the numerical instabilities. The resulting predictive function\nis compatible with integer-only low-bit inference. We show the ability of the\nmethod to achieve state-of-the-art compression rates in both, data-free and\ndata-driven configurations.",
          "link": "http://arxiv.org/abs/2308.05600",
          "publishedOn": "2023-08-12T00:39:30.776Z",
          "wordCount": null,
          "title": "NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search. (arXiv:2308.05600v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhiyao Xie</a>",
          "description": "Inspired by the recent success of large language models (LLMs) like ChatGPT,\nresearchers start to explore the adoption of LLMs for agile hardware design,\nsuch as generating design RTL based on natural-language instructions. However,\nin existing works, their target designs are all relatively simple and in a\nsmall scale, and proposed by the authors themselves, making a fair comparison\namong different LLM solutions challenging. In addition, many prior works only\nfocus on the design correctness, without evaluating the design qualities of\ngenerated design RTL. In this work, we propose an open-source benchmark named\nRTLLM, for generating design RTL with natural language instructions. To\nsystematically evaluate the auto-generated design RTL, we summarized three\nprogressive goals, named syntax goal, functionality goal, and design quality\ngoal. This benchmark can automatically provide a quantitative evaluation of any\ngiven LLM-based solution. Furthermore, we propose an easy-to-use yet\nsurprisingly effective prompt engineering technique named self-planning, which\nproves to significantly boost the performance of GPT-3.5 in our proposed\nbenchmark.",
          "link": "http://arxiv.org/abs/2308.05345",
          "publishedOn": "2023-08-12T00:39:30.746Z",
          "wordCount": null,
          "title": "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model. (arXiv:2308.05345v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05451",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1\">Feng Li</a>",
          "description": "With the big popularity and success of Judea Pearl's original causality book,\nthis review covers the main topics updated in the second edition in 2009 and\nillustrates an easy-to-follow causal inference strategy in a forecast scenario.\nIt further discusses some potential benefits and challenges for causal\ninference with time series forecasting when modeling the counterfactuals,\nestimating the uncertainty and incorporating prior knowledge to estimate causal\neffects in different forecasting scenarios.",
          "link": "http://arxiv.org/abs/2308.05451",
          "publishedOn": "2023-08-12T00:39:30.745Z",
          "wordCount": null,
          "title": "A Forecaster's Review of Judea Pearl's Causality: Models, Reasoning and Inference, Second Edition, 2009. (arXiv:2308.05451v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03152",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Xiong_W/0/1/0/all/0/1\">Wei Xiong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Xiang_Y/0/1/0/all/0/1\">Yanfei Xiang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_H/0/1/0/all/0/1\">Hao Wu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhou_S/0/1/0/all/0/1\">Shuyi Zhou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sun_Y/0/1/0/all/0/1\">Yuze Sun</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ma_M/0/1/0/all/0/1\">Muyuan Ma</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huang_X/0/1/0/all/0/1\">Xiaomeng Huang</a>",
          "description": "Ocean modeling is a powerful tool for simulating the physical, chemical, and\nbiological processes of the ocean, which is the foundation for marine science\nresearch and operational oceanography. Modern numerical ocean modeling mainly\nconsists of governing equations and numerical algorithms. Nonlinear\ninstability, computational expense, low reusability efficiency and high\ncoupling costs have gradually become the main bottlenecks for the further\ndevelopment of numerical ocean modeling. Recently, artificial\nintelligence-based modeling in scientific computing has shown revolutionary\npotential for digital twins and scientific simulations, but the bottlenecks of\nnumerical ocean modeling have not been further solved. Here, we present\nAI-GOMS, a large AI-driven global ocean modeling system, for accurate and\nefficient global ocean daily prediction. AI-GOMS consists of a backbone model\nwith the Fourier-based Masked Autoencoder structure for basic ocean variable\nprediction and lightweight fine-tuning models incorporating regional\ndownscaling, wave decoding, and biochemistry coupling modules. AI-GOMS has\nachieved the best performance in 30 days of prediction for the global ocean\nbasic variables with 15 depth layers at 1/4{\\deg} spatial resolution. Beyond\nthe good performance in statistical metrics, AI-GOMS realizes the simulation of\nmesoscale eddies in the Kuroshio region at 1/12{\\deg} spatial resolution and\nocean stratification in the tropical Pacific Ocean. AI-GOMS provides a new\nbackbone-downstream paradigm for Earth system modeling, which makes the system\ntransferable, scalable and reusable.",
          "link": "http://arxiv.org/abs/2308.03152",
          "publishedOn": "2023-08-12T00:39:30.745Z",
          "wordCount": null,
          "title": "AI-GOMS: Large AI-Driven Global Ocean Modeling System. (arXiv:2308.03152v2 [physics.ao-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05281",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zihui Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lingyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hemphill_L/0/1/0/all/0/1\">Libby Hemphill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baecher_G/0/1/0/all/0/1\">Gregory B. Baecher</a>",
          "description": "Effective disaster response is critical for affected communities. Responders\nand decision-makers would benefit from reliable, timely measures of the issues\nimpacting their communities during a disaster, and social media offers a\npotentially rich data source. Social media can reflect public concerns and\ndemands during a disaster, offering valuable insights for decision-makers to\nunderstand evolving situations and optimize resource allocation. We used\nBidirectional Encoder Representations from Transformers (BERT) topic modeling\nto cluster topics from Twitter data. Then, we conducted a temporal-spatial\nanalysis to examine the distribution of these topics across different regions\nduring the 2020 western U.S. wildfire season. Our results show that Twitter\nusers mainly focused on three topics:\"health impact,\" \"damage,\" and\n\"evacuation.\" We used the Susceptible-Infected-Recovered (SIR) theory to\nexplore the magnitude and velocity of topic diffusion on Twitter. The results\ndisplayed a clear relationship between topic trends and wildfire propagation\npatterns. The estimated parameters obtained from the SIR model in selected\ncities revealed that residents exhibited a high level of several concerns\nduring the wildfire. Our study details how the SIR model and topic modeling\nusing social media data can provide decision-makers with a quantitative\napproach to measure disaster response and support their decision-making\nprocesses.",
          "link": "http://arxiv.org/abs/2308.05281",
          "publishedOn": "2023-08-12T00:39:30.682Z",
          "wordCount": null,
          "title": "Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Breuer_A/0/1/0/all/0/1\">Adam Breuer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosravani_N/0/1/0/all/0/1\">Nazanin Khosravani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tingley_M/0/1/0/all/0/1\">Michael Tingley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cottel_B/0/1/0/all/0/1\">Bradford Cottel</a>",
          "description": "In this paper, we describe a new algorithm called Preferential Attachment\nk-class Classifier (PreAttacK) for detecting fake accounts in a social network.\nRecently, several algorithms have obtained high accuracy on this problem.\nHowever, they have done so by relying on information about fake accounts'\nfriendships or the content they share with others--the very things we seek to\nprevent.\n\nPreAttacK represents a significant departure from these approaches. We\nprovide some of the first detailed distributional analyses of how new fake (and\nreal) accounts first attempt to request friends after joining a major network\n(Facebook). We show that even before a new account has made friends or shared\ncontent, these initial friend request behaviors evoke a natural multi-class\nextension of the canonical Preferential Attachment model of social network\ngrowth.\n\nWe use this model to derive a new algorithm, PreAttacK. We prove that in\nrelevant problem instances, PreAttacK near-optimally approximates the posterior\nprobability that a new account is fake under this multi-class Preferential\nAttachment model of new accounts' (not-yet-answered) friend requests. These are\nthe first provable guarantees for fake account detection that apply to new\nusers, and that do not require strong homophily assumptions.\n\nThis principled approach also makes PreAttacK the only algorithm with\nprovable guarantees that obtains state-of-the-art performance on new users on\nthe global Facebook network, where it converges to AUC=0.9 after new users send\n+ receive a total of just 20 not-yet-answered friend requests. For comparison,\nstate-of-the-art benchmarks do not obtain this AUC even after observing\nadditional data on new users' first 100 friend requests. Thus, unlike\nmainstream algorithms, PreAttacK converges before the median new fake account\nhas made a single friendship (accepted friend request) with a human.",
          "link": "http://arxiv.org/abs/2308.05353",
          "publishedOn": "2023-08-12T00:39:30.667Z",
          "wordCount": null,
          "title": "Preemptive Detection of Fake Accounts on Social Networks via Multi-Class Preferential Attachment Classifiers. (arXiv:2308.05353v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05219",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_E/0/1/0/all/0/1\">Elizabeth M. Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castanon_G/0/1/0/all/0/1\">Gregory Castanon</a>",
          "description": "In this paper, we introduce a strategy for identifying textual saliency in\nlarge-scale language models applied to classification tasks. In visual networks\nwhere saliency is more well-studied, saliency is naturally localized through\nthe convolutional layers of the network; however, the same is not true in\nmodern transformer-stack networks used to process natural language. We adapt\ngradient-based saliency methods for these networks, propose a method for\nevaluating the degree of semantic coherence of each layer, and demonstrate\nconsistent improvement over numerous other methods for textual saliency on\nmultiple benchmark classification datasets. Our approach requires no additional\ntraining or access to labelled data, and is comparatively very computationally\nefficient.",
          "link": "http://arxiv.org/abs/2308.05219",
          "publishedOn": "2023-08-12T00:39:30.661Z",
          "wordCount": null,
          "title": "Decoding Layer Saliency in Language Transformers. (arXiv:2308.05219v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maalouf_A/0/1/0/all/0/1\">Alaa Maalouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jadhav_N/0/1/0/all/0/1\">Ninad Jadhav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jatavallabhula_K/0/1/0/all/0/1\">Krishna Murthy Jatavallabhula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chahine_M/0/1/0/all/0/1\">Makram Chahine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_D/0/1/0/all/0/1\">Daniel M.Vogt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_R/0/1/0/all/0/1\">Robert J. Wood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>",
          "description": "Tracking and following objects of interest is critical to several robotics\nuse cases, ranging from industrial automation to logistics and warehousing, to\nhealthcare and security. In this paper, we present a robotic system to detect,\ntrack, and follow any object in real-time. Our approach, dubbed ``follow\nanything'' (FAn), is an open-vocabulary and multimodal model -- it is not\nrestricted to concepts seen at training time and can be applied to novel\nclasses at inference time using text, images, or click queries. Leveraging rich\nvisual descriptors from large-scale pre-trained models (foundation models), FAn\ncan detect and segment objects by matching multimodal queries (text, images,\nclicks) against an input image sequence. These detected and segmented objects\nare tracked across image frames, all while accounting for occlusion and object\nre-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial\nvehicle) and report its ability to seamlessly follow the objects of interest in\na real-time control loop. FAn can be deployed on a laptop with a lightweight\n(6-8 GB) graphics card, achieving a throughput of 6-20 frames per second. To\nenable rapid adoption, deployment, and extensibility, we open-source all our\ncode on our project webpage at https://github.com/alaamaalouf/FollowAnything .\nWe also encourage the reader the watch our 5-minutes explainer video in this\nhttps://www.youtube.com/watch?v=6Mgt3EPytrw .",
          "link": "http://arxiv.org/abs/2308.05737",
          "publishedOn": "2023-08-12T00:39:30.587Z",
          "wordCount": null,
          "title": "Follow Anything: Open-set detection, tracking, and following in real-time. (arXiv:2308.05737v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.08902",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Giuliani_C/0/1/0/all/0/1\">Clemens Giuliani</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Vicentini_F/0/1/0/all/0/1\">Filippo Vicentini</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rossi_R/0/1/0/all/0/1\">Riccardo Rossi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Carleo_G/0/1/0/all/0/1\">Giuseppe Carleo</a>",
          "description": "Neural network approaches to approximate the ground state of quantum\nhamiltonians require the numerical solution of a highly nonlinear optimization\nproblem. We introduce a statistical learning approach that makes the\noptimization trivial by using kernel methods. Our scheme is an approximate\nrealization of the power method, where supervised learning is used to learn the\nnext step of the power iteration. We show that the ground state properties of\narbitrary gapped quantum hamiltonians can be reached with polynomial resources\nunder the assumption that the supervised learning is efficient. Using kernel\nridge regression, we provide numerical evidence that the learning assumption is\nverified by applying our scheme to find the ground states of several\nprototypical interacting many-body quantum systems, both in one and two\ndimensions, showing the flexibility of our approach.",
          "link": "http://arxiv.org/abs/2303.08902",
          "publishedOn": "2023-08-12T00:39:30.586Z",
          "wordCount": null,
          "title": "Learning ground states of gapped quantum Hamiltonians with Kernel Methods. (arXiv:2303.08902v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Juncai He</a>",
          "description": "This paper is devoted to studying the optimal expressive power of ReLU deep\nneural networks (DNNs) and its application in approximation via the Kolmogorov\nSuperposition Theorem. We first constructively prove that any continuous\npiecewise linear functions on $[0,1]$, comprising $O(N^2L)$ segments, can be\nrepresented by ReLU DNNs with $L$ hidden layers and $N$ neurons per layer.\nSubsequently, we demonstrate that this construction is optimal regarding the\nparameter count of the DNNs, achieved through investigating the shattering\ncapacity of ReLU DNNs. Moreover, by invoking the Kolmogorov Superposition\nTheorem, we achieve an enhanced approximation rate for ReLU DNNs of arbitrary\nwidth and depth when dealing with continuous functions in high-dimensional\nspaces.",
          "link": "http://arxiv.org/abs/2308.05509",
          "publishedOn": "2023-08-12T00:39:30.585Z",
          "wordCount": null,
          "title": "On the Optimal Expressive Power of ReLU DNNs and Its Application in Approximation with Kolmogorov Superposition Theorem. (arXiv:2308.05509v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.14679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ceritli_T/0/1/0/all/0/1\">Taha Ceritli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosheh_G/0/1/0/all/0/1\">Ghadeer O. Ghosheh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1\">Vinod Kumar Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tingting Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Creagh_A/0/1/0/all/0/1\">Andrew P. Creagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>",
          "description": "Electronic Health Records (EHRs) contain sensitive patient information, which\npresents privacy concerns when sharing such data. Synthetic data generation is\na promising solution to mitigate these risks, often relying on deep generative\nmodels such as Generative Adversarial Networks (GANs). However, recent studies\nhave shown that diffusion models offer several advantages over GANs, such as\ngeneration of more realistic synthetic data and stable training in generating\ndata modalities, including image, text, and sound. In this work, we investigate\nthe potential of diffusion models for generating realistic mixed-type tabular\nEHRs, comparing TabDDPM model with existing methods on four datasets in terms\nof data quality, utility, privacy, and augmentation. Our experiments\ndemonstrate that TabDDPM outperforms the state-of-the-art models across all\nevaluation metrics, except for privacy, which confirms the trade-off between\nprivacy and utility.",
          "link": "http://arxiv.org/abs/2302.14679",
          "publishedOn": "2023-08-12T00:39:30.585Z",
          "wordCount": null,
          "title": "Synthesizing Mixed-type Electronic Health Records using Diffusion Models. (arXiv:2302.14679v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>",
          "description": "Reinforcement learning (RL) under changing environment models many real-world\napplications via nonstationary Markov Decision Processes (MDPs), and hence\ngains considerable interest. However, theoretical studies on nonstationary MDPs\nin the literature have mainly focused on tabular and linear (mixture) MDPs,\nwhich do not capture the nature of unknown representation in deep RL. In this\npaper, we make the first effort to investigate nonstationary RL under episodic\nlow-rank MDPs, where both transition kernels and rewards may vary over time,\nand the low-rank model contains unknown representation in addition to the\nlinear state embedding function. We first propose a parameter-dependent policy\noptimization algorithm called PORTAL, and further improve PORTAL to its\nparameter-free version of Ada-PORTAL, which is able to tune its\nhyper-parameters adaptively without any prior knowledge of nonstationarity. For\nboth algorithms, we provide upper bounds on the average dynamic suboptimality\ngap, which show that as long as the nonstationarity is not significantly large,\nPORTAL and Ada-PORTAL are sample-efficient and can achieve arbitrarily small\naverage dynamic suboptimality gap with polynomial sample complexity.",
          "link": "http://arxiv.org/abs/2308.05471",
          "publishedOn": "2023-08-12T00:39:30.359Z",
          "wordCount": null,
          "title": "Provably Efficient Algorithm for Nonstationary Low-Rank MDPs. (arXiv:2308.05471v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiageng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Hanchen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jianhua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiazhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khayatkhoei_M/0/1/0/all/0/1\">Mahyar Khayatkhoei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussein_M/0/1/0/all/0/1\">Mohamed E. Hussein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AbdAlmageed_W/0/1/0/all/0/1\">Wael AbdAlmageed</a>",
          "description": "Discovering causal relations among semantic factors is an emergent topic in\nrepresentation learning. Most causal representation learning (CRL) methods are\nfully supervised, which is impractical due to costly labeling. To resolve this\nrestriction, weakly supervised CRL methods were introduced. To evaluate CRL\nperformance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and\nCelebA(SMILE), are utilized. However, existing CRL datasets are limited to\nsimple graphs with few generative factors. Thus we propose two new datasets\nwith a larger number of diverse generative factors and more sophisticated\ncausal graphs. In addition, current real datasets, CelebA(BEARD) and\nCelebA(SMILE), the originally proposed causal graphs are not aligned with the\ndataset distributions. Thus, we propose modifications to them.",
          "link": "http://arxiv.org/abs/2308.05707",
          "publishedOn": "2023-08-12T00:39:30.348Z",
          "wordCount": null,
          "title": "Shadow Datasets, New challenging datasets for Causal Representation Learning. (arXiv:2308.05707v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.12932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yalavarthi_V/0/1/0/all/0/1\">Vijaya Krishna Yalavarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhusudhanan_K/0/1/0/all/0/1\">Kiran Madhusudhanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sholz_R/0/1/0/all/0/1\">Randolf Sholz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nourhan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burchert_J/0/1/0/all/0/1\">Johannes Burchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jawed_S/0/1/0/all/0/1\">Shayan Jawed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Born_S/0/1/0/all/0/1\">Stefan Born</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1\">Lars Schmidt-Thieme</a>",
          "description": "Forecasting irregularly sampled time series with missing values is a crucial\ntask for numerous real-world applications such as healthcare, astronomy, and\nclimate sciences. State-of-the-art approaches to this problem rely on Ordinary\nDifferential Equations (ODEs) which are known to be slow and often require\nadditional features to handle missing values. To address this issue, we propose\na novel model using Graphs for Forecasting Irregularly Sampled Time Series with\nmissing values which we call GraFITi. GraFITi first converts the time series to\na Sparsity Structure Graph which is a sparse bipartite graph, and then\nreformulates the forecasting problem as the edge weight prediction task in the\ngraph. It uses the power of Graph Neural Networks to learn the graph and\npredict the target edge weights. GraFITi has been tested on 3 real-world and 1\nsynthetic irregularly sampled time series dataset with missing values and\ncompared with various state-of-the-art models. The experimental results\ndemonstrate that GraFITi improves the forecasting accuracy by up to 17% and\nreduces the run time up to 5 times compared to the state-of-the-art forecasting\nmodels.",
          "link": "http://arxiv.org/abs/2305.12932",
          "publishedOn": "2023-08-12T00:39:30.144Z",
          "wordCount": null,
          "title": "Forecasting Irregularly Sampled Time Series using Graphs. (arXiv:2305.12932v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagaraj_Y/0/1/0/all/0/1\">Yeshwanth Nagaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1\">Ujjwal Gupta</a>",
          "description": "Code summarization aims to generate concise natural language descriptions for\nsource code. The prevailing approaches adopt transformer-based encoder-decoder\narchitectures, where the Abstract Syntax Tree (AST) of the source code is\nutilized for encoding structural information. However, ASTs are much longer\nthan the corresponding source code, and existing methods ignore this size\nconstraint by directly feeding the entire linearized AST into the encoders.\nThis simplistic approach makes it challenging to extract truly valuable\ndependency relations from the overlong input sequence and leads to significant\ncomputational overhead due to self-attention applied to all nodes in the AST.\n\nTo address this issue effectively and efficiently, we present a model,\nAST-MHSA that uses multi-head attention to extract the important semantic\ninformation from the AST. The model consists of two main components: an encoder\nand a decoder. The encoder takes as input the abstract syntax tree (AST) of the\ncode and generates a sequence of hidden states. The decoder then takes these\nhidden states as input and generates a natural language summary of the code.\n\nThe multi-head attention mechanism allows the model to learn different\nrepresentations of the input code, which can be combined to generate a more\ncomprehensive summary. The model is trained on a dataset of code and summaries,\nand the parameters of the model are optimized to minimize the loss between the\ngenerated summaries and the ground-truth summaries.",
          "link": "http://arxiv.org/abs/2308.05646",
          "publishedOn": "2023-08-12T00:39:29.748Z",
          "wordCount": null,
          "title": "AST-MHSA : Code Summarization using Multi-Head Self-Attention. (arXiv:2308.05646v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lippe_P/0/1/0/all/0/1\">Phillip Lippe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeling_B/0/1/0/all/0/1\">Bastiaan S. Veeling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brandstetter_J/0/1/0/all/0/1\">Johannes Brandstetter</a>",
          "description": "Time-dependent partial differential equations (PDEs) are ubiquitous in\nscience and engineering. Recently, mostly due to the high computational cost of\ntraditional solution techniques, deep neural network based surrogates have\ngained increased interest. The practical utility of such neural PDE solvers\nrelies on their ability to provide accurate, stable predictions over long time\nhorizons, which is a notoriously hard problem. In this work, we present a\nlarge-scale analysis of common temporal rollout strategies, identifying the\nneglect of non-dominant spatial frequency information, often associated with\nhigh frequencies in PDE solutions, as the primary pitfall limiting stable,\naccurate rollout performance. Based on these insights, we draw inspiration from\nrecent advances in diffusion models to introduce PDE-Refiner; a novel model\nclass that enables more accurate modeling of all frequency components via a\nmultistep refinement process. We validate PDE-Refiner on challenging benchmarks\nof complex fluid dynamics, demonstrating stable and accurate rollouts that\nconsistently outperform state-of-the-art models, including neural, numerical,\nand hybrid neural-numerical architectures. We further demonstrate that\nPDE-Refiner greatly enhances data efficiency, since the denoising objective\nimplicitly induces a novel form of spectral data augmentation. Finally,\nPDE-Refiner's connection to diffusion models enables an accurate and efficient\nassessment of the model's predictive uncertainty, allowing us to estimate when\nthe surrogate becomes inaccurate.",
          "link": "http://arxiv.org/abs/2308.05732",
          "publishedOn": "2023-08-12T00:39:29.650Z",
          "wordCount": null,
          "title": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers. (arXiv:2308.05732v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.09807",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kang_M/0/1/0/all/0/1\">Minsung Kang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oh_S/0/1/0/all/0/1\">Sangshin Oh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moon_H/0/1/0/all/0/1\">Hyeongi Moon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_K/0/1/0/all/0/1\">Kyungyun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chon_B/0/1/0/all/0/1\">Ben Sangbae Chon</a>",
          "description": "This paper introduces FALL-E, a foley synthesis system and its\ntraining/inference strategies. The FALL-E model employs a cascaded approach\ncomprising low-resolution spectrogram generation, spectrogram super-resolution,\nand a vocoder. We trained every sound-related model from scratch using our\nextensive datasets, and utilized a pre-trained language model. We conditioned\nthe model with dataset-specific texts, enabling it to learn sound quality and\nrecording environment based on text input. Moreover, we leveraged external\nlanguage models to improve text descriptions of our datasets and performed\nprompt engineering for quality, coherence, and diversity. FALL-E was evaluated\nby an objective measure as well as listening tests in the DCASE 2023 challenge\nTask 7. The submission achieved the second place on average, while achieving\nthe best score for diversity, second place for audio quality, and third place\nfor class fitness.",
          "link": "http://arxiv.org/abs/2306.09807",
          "publishedOn": "2023-08-12T00:39:29.216Z",
          "wordCount": 666,
          "title": "FALL-E: A Foley Sound Synthesis Model and Strategies. (arXiv:2306.09807v2 [eess.AS] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.14408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1\">Eddy Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_A/0/1/0/all/0/1\">Alex Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budhwani_A/0/1/0/all/0/1\">Alikasim Budhwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dempster_R/0/1/0/all/0/1\">Rowan Dempster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Quanquan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Sharman_M/0/1/0/all/0/1\">Mohammad Al-Sharman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rayside_D/0/1/0/all/0/1\">Derek Rayside</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melek_W/0/1/0/all/0/1\">William Melek</a>",
          "description": "When applied to autonomous vehicle (AV) settings, action recognition can\nenhance an environment model's situational awareness. This is especially\nprevalent in scenarios where traditional geometric descriptions and heuristics\nin AVs are insufficient. However, action recognition has traditionally been\nstudied for humans, and its limited adaptability to noisy, un-clipped,\nun-pampered, raw RGB data has limited its application in other fields. To push\nfor the advancement and adoption of action recognition into AVs, this work\nproposes a novel two-stage action recognition system, termed RALACs. RALACs\nformulates the problem of action recognition for road scenes, and bridges the\ngap between it and the established field of human action recognition. This work\nshows how attention layers can be useful for encoding the relations across\nagents, and stresses how such a scheme can be class-agnostic. Furthermore, to\naddress the dynamic nature of agents on the road, RALACs constructs a novel\napproach to adapting Region of Interest (ROI) Alignment to agent tracks for\ndownstream action classification. Finally, our scheme also considers the\nproblem of active agent detection, and utilizes a novel application of fusing\noptical flow maps to discern relevant agents in a road scene. We show that our\nproposed scheme can outperform the baseline on the ICCV2021 Road Challenge\ndataset and by deploying it on a real vehicle platform, we provide preliminary\ninsight to the usefulness of action recognition in decision making.",
          "link": "http://arxiv.org/abs/2209.14408",
          "publishedOn": "2023-08-12T00:39:29.192Z",
          "wordCount": 775,
          "title": "RALACs: Action Recognition in Autonomous Vehicles using Interaction Encoding and Optical Flow. (arXiv:2209.14408v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.13341",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michlo_N/0/1/0/all/0/1\">Nathan Michlo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_R/0/1/0/all/0/1\">Richard Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1\">Steven James</a>",
          "description": "Learning disentangled representations with variational autoencoders (VAEs) is\noften attributed to the regularisation component of the loss. In this work, we\nhighlight the interaction between data and the reconstruction term of the loss\nas the main contributor to disentanglement in VAEs. We show that standard\nbenchmark datasets have unintended correlations between their subjective\nground-truth factors and perceived axes in the data according to typical VAE\nreconstruction losses. Our work exploits this relationship to provide a theory\nfor what constitutes an adversarial dataset under a given reconstruction loss.\nWe verify this by constructing an example dataset that prevents disentanglement\nin state-of-the-art frameworks while maintaining human-intuitive ground-truth\nfactors. Finally, we re-enable disentanglement by designing an example\nreconstruction loss that is once again able to perceive the ground-truth\nfactors. Our findings demonstrate the subjective nature of disentanglement and\nthe importance of considering the interaction between the ground-truth factors,\ndata and notably, the reconstruction loss, which is under-recognised in the\nliterature.",
          "link": "http://arxiv.org/abs/2202.13341",
          "publishedOn": "2023-08-12T00:39:29.185Z",
          "wordCount": 710,
          "title": "Overlooked Implications of the Reconstruction Loss for VAE Disentanglement. (arXiv:2202.13341v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05237",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Innan_N/0/1/0/all/0/1\">Nouhaila Innan</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Khan_M/0/1/0/all/0/1\">Muhammad Al-Zafar Khan</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bennai_M/0/1/0/all/0/1\">Mohamed Bennai</a>",
          "description": "In this research, a comparative study of four Quantum Machine Learning (QML)\nmodels was conducted for fraud detection in finance. We proved that the Quantum\nSupport Vector Classifier model achieved the highest performance, with F1\nscores of 0.98 for fraud and non-fraud classes. Other models like the\nVariational Quantum Classifier, Estimator Quantum Neural Network (QNN), and\nSampler QNN demonstrate promising results, propelling the potential of QML\nclassification for financial applications. While they exhibit certain\nlimitations, the insights attained pave the way for future enhancements and\noptimisation strategies. However, challenges exist, including the need for more\nefficient Quantum algorithms and larger and more complex datasets. The article\nprovides solutions to overcome current limitations and contributes new insights\nto the field of Quantum Machine Learning in fraud detection, with important\nimplications for its future development.",
          "link": "http://arxiv.org/abs/2308.05237",
          "publishedOn": "2023-08-12T00:39:29.162Z",
          "wordCount": 653,
          "title": "Financial Fraud Detection: A Comparative Study of Quantum Machine Learning Models. (arXiv:2308.05237v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jamali_A/0/1/0/all/0/1\">Ali Jamali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Swalpa Kumar Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Danfeng Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atkinson_P/0/1/0/all/0/1\">Peter M Atkinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghamisi_P/0/1/0/all/0/1\">Pedram Ghamisi</a>",
          "description": "Convolutional Neural Networks (CNNs) are models that are utilized extensively\nfor the hierarchical extraction of features. Vision transformers (ViTs),\nthrough the use of a self-attention mechanism, have recently achieved superior\nmodeling of global contextual information compared to CNNs. However, to realize\ntheir image classification strength, ViTs require substantial training\ndatasets. Where the available training data are limited, current advanced\nmulti-layer perceptrons (MLPs) can provide viable alternatives to both deep\nCNNs and ViTs. In this paper, we developed the SGU-MLP, a learning algorithm\nthat effectively uses both MLPs and spatial gating units (SGUs) for precise\nland use land cover (LULC) mapping. Results illustrated the superiority of the\ndeveloped SGU-MLP classification algorithm over several CNN and CNN-ViT-based\nmodels, including HybridSN, ResNet, iFormer, EfficientFormer and CoAtNet. The\nproposed SGU-MLP algorithm was tested through three experiments in Houston,\nUSA, Berlin, Germany and Augsburg, Germany. The SGU-MLP classification model\nwas found to consistently outperform the benchmark CNN and CNN-ViT-based\nalgorithms. For example, for the Houston experiment, SGU-MLP significantly\noutperformed HybridSN, CoAtNet, Efficientformer, iFormer and ResNet by\napproximately 15%, 19%, 20%, 21%, and 25%, respectively, in terms of average\naccuracy. The code will be made publicly available at\nhttps://github.com/aj1365/SGUMLP",
          "link": "http://arxiv.org/abs/2308.05235",
          "publishedOn": "2023-08-12T00:39:29.155Z",
          "wordCount": 718,
          "title": "Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping. (arXiv:2308.05235v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05176",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Talukder_M/0/1/0/all/0/1\">Md. Simul Hasan Talukder</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sulaiman_R/0/1/0/all/0/1\">Rejwan Bin Sulaiman</a>",
          "description": "Epilepsy is a prevalent neurological disorder characterized by recurrent and\nunpredictable seizures, necessitating accurate prediction for effective\nmanagement and patient care. Application of machine learning (ML) on\nelectroencephalogram (EEG) recordings, along with its ability to provide\nvaluable insights into brain activity during seizures, is able to make accurate\nand robust seizure prediction an indispensable component in relevant studies.\nIn this research, we present a comprehensive comparative analysis of five\nmachine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees\n(ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the prediction\nof epileptic seizures using EEG data. The dataset underwent meticulous\npreprocessing, including cleaning, normalization, outlier handling, and\noversampling, ensuring data quality and facilitating accurate model training.\nThese preprocessing techniques played a crucial role in enhancing the models'\nperformance. The results of our analysis demonstrate the performance of each\nmodel in terms of accuracy. The LR classifier achieved an accuracy of 56.95%,\nwhile GB and DT both attained 97.17% accuracy. RT achieved a higher accuracy of\n98.99%, while the ET model exhibited the best performance with an accuracy of\n99.29%. Our findings reveal that the ET model outperformed not only the other\nmodels in the comparative analysis but also surpassed the state-of-the-art\nresults from previous research. The superior performance of the ET model makes\nit a compelling choice for accurate and robust epileptic seizure prediction\nusing EEG data.",
          "link": "http://arxiv.org/abs/2308.05176",
          "publishedOn": "2023-08-12T00:39:29.149Z",
          "wordCount": 771,
          "title": "Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models. (arXiv:2308.05176v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brannvall_R/0/1/0/all/0/1\">Rickard Br&#xe4;nnvall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forsgren_H/0/1/0/all/0/1\">Henrik Forsgren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandin_F/0/1/0/all/0/1\">Fredrik Sandin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>",
          "description": "We replace the multiplication and sigmoid function of the conventional\nrecurrent gate with addition and ReLU activation. This mechanism is designed to\nmaintain long-term memory for sequence processing but at a reduced\ncomputational cost, thereby opening up for more efficient execution or larger\nmodels on restricted hardware. Recurrent Neural Networks (RNNs) with gating\nmechanisms such as LSTM and GRU have been widely successful in learning from\nsequential data due to their ability to capture long-term dependencies.\nConventionally, the update based on current inputs and the previous state\nhistory is each multiplied with dynamic weights and combined to compute the\nnext state. However, multiplication can be computationally expensive,\nespecially for certain hardware architectures or alternative arithmetic systems\nsuch as homomorphic encryption. It is demonstrated that the novel gating\nmechanism can capture long-term dependencies for a standard synthetic sequence\nlearning task while significantly reducing computational costs such that\nexecution time is reduced by half on CPU and by one-third under encryption.\nExperimental results on handwritten text recognition tasks furthermore show\nthat the proposed architecture can be trained to achieve comparable accuracy to\nconventional GRU and LSTM baselines. The gating mechanism introduced in this\npaper may enable privacy-preserving AI applications operating under homomorphic\nencryption by avoiding the multiplication of encrypted variables. It can also\nsupport quantization in (unencrypted) plaintext applications, with the\npotential for substantial performance gains since the addition-based\nformulation can avoid the expansion to double precision often required for\nmultiplication.",
          "link": "http://arxiv.org/abs/2308.05629",
          "publishedOn": "2023-08-12T00:39:29.142Z",
          "wordCount": 734,
          "title": "ReLU and Addition-based Gated RNN. (arXiv:2308.05629v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05133",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Gupta_R/0/1/0/all/0/1\">Rohan Kumar Gupta</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sinha_R/0/1/0/all/0/1\">Rohit Sinha</a>",
          "description": "The primary method for identifying mental disorders automatically has\ntraditionally involved using binary classifiers. These classifiers are trained\nusing behavioral data obtained from an interview setup. In this training\nprocess, data from individuals with the specific disorder under consideration\nare categorized as the positive class, while data from all other participants\nconstitute the negative class. In practice, it is widely recognized that\ncertain mental disorders share similar symptoms, causing the collected\nbehavioral data to encompass a variety of attributes associated with multiple\ndisorders. Consequently, attributes linked to the targeted mental disorder\nmight also be present within the negative class. This data impurity may lead to\nsub-optimal training of the classifier for a mental disorder of interest. In\nthis study, we investigate this hypothesis in the context of major depressive\ndisorder (MDD) and post-traumatic stress disorder detection (PTSD). The results\nshow that upon removal of such data impurity, MDD and PTSD detection\nperformances are significantly improved.",
          "link": "http://arxiv.org/abs/2308.05133",
          "publishedOn": "2023-08-12T00:39:29.116Z",
          "wordCount": 684,
          "title": "Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders. (arXiv:2308.05133v1 [q-bio.NC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shah_H/0/1/0/all/0/1\">Harshit Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_A/0/1/0/all/0/1\">Aravindhan G</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_P/0/1/0/all/0/1\">Pavan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Govidarajulu_Y/0/1/0/all/0/1\">Yuvaraj Govidarajulu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1\">Manojkumar Parmar</a>",
          "description": "A significant number of machine learning models are vulnerable to model\nextraction attacks, which focus on stealing the models by using specially\ncurated queries against the target model. This task is well accomplished by\nusing part of the training data or a surrogate dataset to train a new model\nthat mimics a target model in a white-box environment. In pragmatic situations,\nhowever, the target models are trained on private datasets that are\ninaccessible to the adversary. The data-free model extraction technique\nreplaces this problem when it comes to using queries artificially curated by a\ngenerator similar to that used in Generative Adversarial Nets. We propose for\nthe first time, to the best of our knowledge, an adversary black box attack\nextending to a regression problem for predicting bounding box coordinates in\nobject detection. As part of our study, we found that defining a loss function\nand using a novel generator setup is one of the key aspects in extracting the\ntarget model. We find that the proposed model extraction method achieves\nsignificant results by using reasonable queries. The discovery of this object\ndetection vulnerability will support future prospects for securing such models.",
          "link": "http://arxiv.org/abs/2308.05127",
          "publishedOn": "2023-08-12T00:39:29.110Z",
          "wordCount": 735,
          "title": "Data-Free Model Extraction Attacks in the Context of Object Detection. (arXiv:2308.05127v1 [cs.CR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1\">Qizhang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jiayi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emdad_F/0/1/0/all/0/1\">Forhan Bin Emdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanna_K/0/1/0/all/0/1\">Karim Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhe He</a>",
          "description": "Stroke is a significant cause of mortality and morbidity, necessitating early\npredictive strategies to minimize risks. Traditional methods for evaluating\npatients, such as Acute Physiology and Chronic Health Evaluation (APACHE II,\nIV) and Simplified Acute Physiology Score III (SAPS III), have limited accuracy\nand interpretability. This paper proposes a novel approach: an interpretable,\nattention-based transformer model for early stroke mortality prediction. This\nmodel seeks to address the limitations of previous predictive models, providing\nboth interpretability (providing clear, understandable explanations of the\nmodel) and fidelity (giving a truthful explanation of the model's dynamics from\ninput to output). Furthermore, the study explores and compares fidelity and\ninterpretability scores using Shapley values and attention-based scores to\nimprove model explainability. The research objectives include designing an\ninterpretable attention-based transformer model, evaluating its performance\ncompared to existing models, and providing feature importance derived from the\nmodel.",
          "link": "http://arxiv.org/abs/2308.05110",
          "publishedOn": "2023-08-12T00:39:29.103Z",
          "wordCount": 680,
          "title": "Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke. (arXiv:2308.05110v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lindqvist_B/0/1/0/all/0/1\">Blerta Lindqvist</a>",
          "description": "We examine whether symmetry can be used to defend tree-based ensemble\nclassifiers such as gradient-boosting decision trees (GBDTs) against\nadversarial perturbation attacks. The idea is based on a recent symmetry\ndefense for convolutional neural network classifiers (CNNs) that utilizes CNNs'\nlack of invariance with respect to symmetries. CNNs lack invariance because\nthey can classify a symmetric sample, such as a horizontally flipped image,\ndifferently from the original sample. CNNs' lack of invariance also means that\nCNNs can classify symmetric adversarial samples differently from the incorrect\nclassification of adversarial samples. Using CNNs' lack of invariance, the\nrecent CNN symmetry defense has shown that the classification of symmetric\nadversarial samples reverts to the correct sample classification. In order to\napply the same symmetry defense to GBDTs, we examine GBDT invariance and are\nthe first to show that GBDTs also lack invariance with respect to symmetries.\nWe apply and evaluate the GBDT symmetry defense for nine datasets against six\nperturbation attacks with a threat model that ranges from zero-knowledge to\nperfect-knowledge adversaries. Using the feature inversion symmetry against\nzero-knowledge adversaries, we achieve up to 100% accuracy on adversarial\nsamples even when default and robust classifiers have 0% accuracy. Using the\nfeature inversion and horizontal flip symmetries against perfect-knowledge\nadversaries, we achieve up to over 95% accuracy on adversarial samples for the\nGBDT classifier of the F-MNIST dataset even when default and robust classifiers\nhave 0% accuracy.",
          "link": "http://arxiv.org/abs/2308.05575",
          "publishedOn": "2023-08-12T00:39:29.096Z",
          "wordCount": 725,
          "title": "Symmetry Defense Against XGBoost Adversarial Perturbation Attacks. (arXiv:2308.05575v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quentin_P/0/1/0/all/0/1\">Pajon Quentin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swan_S/0/1/0/all/0/1\">Serre Swan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hugo_W/0/1/0/all/0/1\">Wissocq Hugo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leo_R/0/1/0/all/0/1\">Rabaud L&#xe9;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siba_H/0/1/0/all/0/1\">Haidar Siba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antoun_Y/0/1/0/all/0/1\">Yaacoub Antoun</a>",
          "description": "This paper presents an investigation into machine learning techniques for\nviolence detection in videos and their adaptation to a federated learning\ncontext. The study includes experiments with spatio-temporal features extracted\nfrom benchmark video datasets, comparison of different methods, and proposal of\na modified version of the \"Flow-Gated\" architecture called \"Diff-Gated.\"\nAdditionally, various machine learning techniques, including super-convergence\nand transfer learning, are explored, and a method for adapting centralized\ndatasets to a federated learning context is developed. The research achieves\nbetter accuracy results compared to state-of-the-art models by training the\nbest violence detection model in a federated learning context.",
          "link": "http://arxiv.org/abs/2308.05106",
          "publishedOn": "2023-08-12T00:39:29.091Z",
          "wordCount": 665,
          "title": "Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures. (arXiv:2308.05106v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borrel_Jensen_N/0/1/0/all/0/1\">Nikolas Borrel-Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_S/0/1/0/all/0/1\">Somdatta Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engsig_Karup_A/0/1/0/all/0/1\">Allan P. Engsig-Karup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1\">Cheol-Ho Jeong</a>",
          "description": "We address the challenge of sound propagation simulations in $3$D virtual\nrooms with moving sources, which have applications in virtual/augmented\nreality, game audio, and spatial computing. Solutions to the wave equation can\ndescribe wave phenomena such as diffraction and interference. However,\nsimulating them using conventional numerical discretization methods with\nhundreds of source and receiver positions is intractable, making stimulating a\nsound field with moving sources impractical. To overcome this limitation, we\npropose using deep operator networks to approximate linear wave-equation\noperators. This enables the rapid prediction of sound propagation in realistic\n3D acoustic scenes with moving sources, achieving millisecond-scale\ncomputations. By learning a compact surrogate model, we avoid the offline\ncalculation and storage of impulse responses for all relevant source/listener\npairs. Our experiments, including various complex scene geometries, show good\nagreement with reference solutions, with root mean squared errors ranging from\n0.02 Pa to 0.10 Pa. Notably, our method signifies a paradigm shift as no prior\nmachine learning approach has achieved precise predictions of complete wave\nfields within realistic domains. We anticipate that our findings will drive\nfurther exploration of deep neural operator methods, advancing research in\nimmersive user experiences within virtual environments.",
          "link": "http://arxiv.org/abs/2308.05141",
          "publishedOn": "2023-08-12T00:39:29.070Z",
          "wordCount": 730,
          "title": "Sound propagation in realistic interactive 3D scenes with parameterized sources using deep neural operators. (arXiv:2308.05141v1 [cs.SD])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05118",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Um_D/0/1/0/all/0/1\">Daniel H. Um</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Knowles_D/0/1/0/all/0/1\">David A. Knowles</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kaiser_G/0/1/0/all/0/1\">Gail E. Kaiser</a>",
          "description": "This paper demonstrates the utility of organized numerical representations of\ngenes in research involving flat string gene formats (i.e., FASTA/FASTQ5).\nFASTA/FASTQ files have several current limitations, such as their large file\nsizes, slow processing speeds for mapping and alignment, and contextual\ndependencies. These challenges significantly hinder investigations and tasks\nthat involve finding similar sequences. The solution lies in transforming\nsequences into an alternative representation that facilitates easier clustering\ninto similar groups compared to the raw sequences themselves. By assigning a\nunique vector embedding to each short sequence, it is possible to more\nefficiently cluster and improve upon compression performance for the string\nrepresentations of cDNA libraries. Furthermore, through learning alternative\ncoordinate vector embeddings based on the contexts of codon triplets, we can\ndemonstrate clustering based on amino acid properties. Finally, using this\nsequence embedding method to encode barcodes and cDNA sequences, we can improve\nthe time complexity of the similarity search by coupling vector embeddings with\nan algorithm that determines the proximity of vectors in Euclidean space; this\nallows us to perform sequence similarity searches in a quicker and more modular\nfashion.",
          "link": "http://arxiv.org/abs/2308.05118",
          "publishedOn": "2023-08-12T00:39:29.063Z",
          "wordCount": 730,
          "title": "Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries. (arXiv:2308.05118v1 [q-bio.GN])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05122",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Dvornek_N/0/1/0/all/0/1\">Nicha C. Dvornek</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sullivan_C/0/1/0/all/0/1\">Catherine Sullivan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Duncan_J/0/1/0/all/0/1\">James S. Duncan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gupta_A/0/1/0/all/0/1\">Abha R. Gupta</a>",
          "description": "The multifactorial etiology of autism spectrum disorder (ASD) suggests that\nits study would benefit greatly from multimodal approaches that combine data\nfrom widely varying platforms, e.g., neuroimaging, genetics, and clinical\ncharacterization. Prior neuroimaging-genetic analyses often apply naive feature\nconcatenation approaches in data-driven work or use the findings from one\nmodality to guide posthoc analysis of another, missing the opportunity to\nanalyze the paired multimodal data in a truly unified approach. In this paper,\nwe develop a more integrative model for combining genetic, demographic, and\nneuroimaging data. Inspired by the influence of genotype on phenotype, we\npropose using an attention-based approach where the genetic data guides\nattention to neuroimaging features of importance for model prediction. The\ngenetic data is derived from copy number variation parameters, while the\nneuroimaging data is from functional magnetic resonance imaging. We evaluate\nthe proposed approach on ASD classification and severity prediction tasks,\nusing a sex-balanced dataset of 228 ASD and typically developing subjects in a\n10-fold cross-validation framework. We demonstrate that our attention-based\nmodel combining genetic information, demographic data, and functional magnetic\nresonance imaging results in superior prediction performance compared to other\nmultimodal approaches.",
          "link": "http://arxiv.org/abs/2308.05122",
          "publishedOn": "2023-08-12T00:39:29.056Z",
          "wordCount": 727,
          "title": "Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder. (arXiv:2308.05122v1 [q-bio.QM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05166",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Gupta_N/0/1/0/all/0/1\">Nikhel Gupta</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hayder_Z/0/1/0/all/0/1\">Zeeshan Hayder</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Norris_R/0/1/0/all/0/1\">Ray P. Norris</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Huynh_M/0/1/0/all/0/1\">Minh Huynh</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Petersson_L/0/1/0/all/0/1\">Lars Petersson</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wang_X/0/1/0/all/0/1\">X. Rosalind Wang</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Andernach_H/0/1/0/all/0/1\">Heinz Andernach</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Koribalski_B/0/1/0/all/0/1\">B&#xe4;rbel S. Koribalski</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Yew_M/0/1/0/all/0/1\">Miranda Yew</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Crawford_E/0/1/0/all/0/1\">Evan J. Crawford</a>",
          "description": "The present work discusses the use of a weakly-supervised deep learning\nalgorithm that reduces the cost of labelling pixel-level masks for complex\nradio galaxies with multiple components. The algorithm is trained on weak\nclass-level labels of radio galaxies to get class activation maps (CAMs). The\nCAMs are further refined using an inter-pixel relations network (IRNet) to get\ninstance segmentation masks over radio galaxies and the positions of their\ninfrared hosts. We use data from the Australian Square Kilometre Array\nPathfinder (ASKAP) telescope, specifically the Evolutionary Map of the Universe\n(EMU) Pilot Survey, which covered a sky area of 270 square degrees with an RMS\nsensitivity of 25-35 $\\mu$Jy/beam. We demonstrate that weakly-supervised deep\nlearning algorithms can achieve high accuracy in predicting pixel-level\ninformation, including masks for the extended radio emission encapsulating all\ngalaxy components and the positions of the infrared host galaxies. We evaluate\nthe performance of our method using mean Average Precision (mAP) across\nmultiple classes at a standard intersection over union (IoU) threshold of 0.5.\nWe show that the model achieves a mAP$_{50}$ of 67.5\\% and 76.8\\% for radio\nmasks and infrared host positions, respectively. The network architecture can\nbe found at the following link: https://github.com/Nikhel1/Gal-CAM",
          "link": "http://arxiv.org/abs/2308.05166",
          "publishedOn": "2023-08-12T00:39:29.050Z",
          "wordCount": 773,
          "title": "Deep Learning for Morphological Identification of Extended Radio Galaxies using Weak Labels. (arXiv:2308.05166v1 [astro-ph.IM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05125",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Das_M/0/1/0/all/0/1\">Mamata Das</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+K%2E_S/0/1/0/all/0/1\">Selvakumar K.</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alphonse_P/0/1/0/all/0/1\">P.J.A. Alphonse</a>",
          "description": "The capacity to identify and analyze protein-protein interactions, along with\ntheir internal modular organization, plays a crucial role in comprehending the\nintricate mechanisms underlying biological processes at the molecular level. We\ncan learn a lot about the structure and dynamics of these interactions by using\nnetwork analysis. We can improve our understanding of the biological roots of\ndisease pathogenesis by recognizing network communities. This knowledge, in\nturn, holds significant potential for driving advancements in drug discovery\nand facilitating personalized medicine approaches for disease treatment. In\nthis study, we aimed to uncover the communities within the variant B.1.1.529\n(Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four\nwidely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label\nPropagation algorithm. Each of these algorithms has established prominence in\nthe field and offers unique perspectives on identifying communities within\ncomplex networks. We also compare the networks by the global properties,\nstatistic summary, subgraph count, graphlet and validate by the modulaity. By\nemploying these approaches, we sought to gain deeper insights into the\nstructural organization and interconnections present within the Omicron virus\nnetwork.",
          "link": "http://arxiv.org/abs/2308.05125",
          "publishedOn": "2023-08-12T00:39:29.042Z",
          "wordCount": 713,
          "title": "Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network. (arXiv:2308.05125v1 [q-bio.MN])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05115",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_Z/0/1/0/all/0/1\">Ziyang Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhong_H/0/1/0/all/0/1\">Haitian Zhong</a>",
          "description": "Phosphorylation is central to numerous fundamental cellular processes,\ninfluencing the onset and progression of a variety of diseases. Identification\nof phosphorylation sites is thus an important step for understanding the\nmolecular mechanisms of cells and virus infection, which potentially leads to\nnew therapeutic targets. In this study, we present PTransIPs, a novel deep\nlearning model for the identification of phosphorylation sites. PTransIPs\ntreats amino acids in protein sequences as words in natural language,\nextracting unique encodings based on the types along with position of amino\nacids in the sequence. It also incorporates embeddings from large pre-trained\nprotein models as additional data inputs. PTransIPS is further trained on a\ncombination model of convolutional neural network with residual connections and\nTransformer model equipped with multi-head attention mechanisms. At last, the\nmodel outputs classification results through a fully connected layer. The\nresults of independent testing reveal that PTransIPs outperforms existing\nstate-of-the-art methodologies, achieving AUROCs of 0.9232 and 0.9660 for\nidentifying phosphorylated S/T and Y sites respectively. In addition, ablation\nstudies prove that pretrained model embeddings contribute to the performance of\nPTransIPs. Furthermore, PTransIPs has interpretable amino acid preference,\nvisible training process and shows generalizability on other bioactivity\nclassification tasks. To facilitate usage, our code and data are publicly\naccessible at \\url{https://github.com/StatXzy7/PTransIPs}.",
          "link": "http://arxiv.org/abs/2308.05115",
          "publishedOn": "2023-08-12T00:39:29.014Z",
          "wordCount": 723,
          "title": "PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer. (arXiv:2308.05115v1 [q-bio.QM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05129",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Weng_N/0/1/0/all/0/1\">Nina Weng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bigdeli_S/0/1/0/all/0/1\">Siavash Bigdeli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Petersen_E/0/1/0/all/0/1\">Eike Petersen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feragen_A/0/1/0/all/0/1\">Aasa Feragen</a>",
          "description": "While many studies have assessed the fairness of AI algorithms in the medical\nfield, the causes of differences in prediction performance are often unknown.\nThis lack of knowledge about the causes of bias hampers the efficacy of bias\nmitigation, as evidenced by the fact that simple dataset balancing still often\nperforms best in reducing performance gaps but is unable to resolve all\nperformance differences. In this work, we investigate the causes of gender bias\nin machine learning-based chest X-ray diagnosis. In particular, we explore the\nhypothesis that breast tissue leads to underexposure of the lungs and causes\nlower model performance. Methodologically, we propose a new sampling method\nwhich addresses the highly skewed distribution of recordings per patient in two\nwidely used public datasets, while at the same time reducing the impact of\nlabel errors. Our comprehensive analysis of gender differences across diseases,\ndatasets, and gender representations in the training set shows that dataset\nimbalance is not the sole cause of performance differences. Moreover, relative\ngroup performance differs strongly between datasets, indicating important\ndataset-specific factors influencing male/female group performance. Finally, we\ninvestigate the effect of breast tissue more specifically, by cropping out the\nbreasts from recordings, finding that this does not resolve the observed\nperformance gaps. In conclusion, our results indicate that dataset-specific\nfactors, not fundamental physiological differences, are the main drivers of\nmale--female performance gaps in chest X-ray analyses on widely used NIH and\nCheXpert Dataset.",
          "link": "http://arxiv.org/abs/2308.05129",
          "publishedOn": "2023-08-12T00:39:29.006Z",
          "wordCount": 774,
          "title": "Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?. (arXiv:2308.05129v1 [eess.IV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.05120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Edward Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Han Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_N/0/1/0/all/0/1\">Nam Dinh</a>",
          "description": "In recent years, the field of data-driven neural network-based machine\nlearning (ML) algorithms has grown significantly and spurred research in its\napplicability to instrumentation and control systems. While they are promising\nin operational contexts, the trustworthiness of such algorithms is not\nadequately assessed. Failures of ML-integrated systems are poorly understood;\nthe lack of comprehensive risk modeling can degrade the trustworthiness of\nthese systems. In recent reports by the National Institute for Standards and\nTechnology, trustworthiness in ML is a critical barrier to adoption and will\nplay a vital role in intelligent systems' safe and accountable operation. Thus,\nin this work, we demonstrate a real-time model-agnostic method to evaluate the\nrelative reliability of ML predictions by incorporating out-of-distribution\ndetection on the training dataset. It is well documented that ML algorithms\nexcel at interpolation (or near-interpolation) tasks but significantly degrade\nat extrapolation. This occurs when new samples are \"far\" from training samples.\nThe method, referred to as the Laplacian distributed decay for reliability\n(LADDR), determines the difference between the operational and training\ndatasets, which is used to calculate a prediction's relative reliability. LADDR\nis demonstrated on a feedforward neural network-based model used to predict\nsafety significant factors during different loss-of-flow transients. LADDR is\nintended as a \"data supervisor\" and determines the appropriateness of\nwell-trained ML models in the context of operational conditions. Ultimately,\nLADDR illustrates how training data can be used as evidence to support the\ntrustworthiness of ML predictions when utilized for conventional interpolation\ntasks.",
          "link": "http://arxiv.org/abs/2308.05120",
          "publishedOn": "2023-08-12T00:39:28.993Z",
          "wordCount": 790,
          "title": "Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation & Control Systems. (arXiv:2308.05120v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.03188",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Bond_R/0/1/0/all/0/1\">R. Bailey Bond</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ren_P/0/1/0/all/0/1\">Pu Ren</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hajjar_J/0/1/0/all/0/1\">Jerome F. Hajjar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>",
          "description": "Clustering analysis of sequence data continues to address many applications\nin engineering design, aided with the rapid growth of machine learning in\napplied science. This paper presents an unsupervised machine learning algorithm\nto extract defining characteristics of earthquake ground-motion spectra, also\ncalled latent features, to aid in ground-motion selection (GMS). In this\ncontext, a latent feature is a low-dimensional machine-discovered spectral\ncharacteristic learned through nonlinear relationships of a neural network\nautoencoder. Machine discovered latent features can be combined with\ntraditionally defined intensity measures and clustering can be performed to\nselect a representative subgroup from a large ground-motion suite. The\nobjective of efficient GMS is to choose characteristic records representative\nof what the structure will probabilistically experience in its lifetime. Three\nexamples are presented to validate this approach, including the use of\nsynthetic and field recorded ground-motion datasets. The presented deep\nembedding clustering of ground-motion spectra has three main advantages: 1.\ndefining characteristics the represent the sparse spectral content of\nground-motions are discovered efficiently through training of the autoencoder,\n2. domain knowledge is incorporated into the machine learning framework with\nconditional variables in the deep embedding scheme, and 3. method exhibits\nexcellent performance when compared to a benchmark seismic hazard analysis.",
          "link": "http://arxiv.org/abs/2212.03188",
          "publishedOn": "2023-08-05T00:48:27.439Z",
          "wordCount": 738,
          "title": "An Unsupervised Machine Learning Approach for Ground-Motion Spectra Clustering and Selection. (arXiv:2212.03188v2 [physics.geo-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mayfrank_D/0/1/0/all/0/1\">Daniel Mayfrank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsos_A/0/1/0/all/0/1\">Alexander Mitsos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahmen_M/0/1/0/all/0/1\">Manuel Dahmen</a>",
          "description": "(Economic) nonlinear model predictive control ((e)NMPC) requires dynamic\nsystem models that are sufficiently accurate in all relevant state-space\nregions. These models must also be computationally cheap enough to ensure\nreal-time tractability. Data-driven surrogate models for mechanistic models can\nbe used to reduce the computational burden of (e)NMPC; however, such models are\ntypically trained by system identification for maximum average prediction\naccuracy on simulation samples and perform suboptimally as part of actual\n(e)NMPC. We present a method for end-to-end reinforcement learning of dynamic\nsurrogate models for optimal performance in (e)NMPC applications, resulting in\npredictive controllers that strike a favorable balance between control\nperformance and computational demand. We validate our method on two\napplications derived from an established nonlinear continuous stirred-tank\nreactor model. We compare the controller performance to that of MPCs utilizing\nmodels trained by the prevailing maximum prediction accuracy paradigm, and\nmodel-free neural network controllers trained using reinforcement learning. We\nshow that our method matches the performance of the model-free neural network\ncontrollers while consistently outperforming models derived from system\nidentification. Additionally, we show that the MPC policies can react to\nchanges in the control setting without retraining.",
          "link": "http://arxiv.org/abs/2308.01674",
          "publishedOn": "2023-08-05T00:48:27.433Z",
          "wordCount": 716,
          "title": "End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC. (arXiv:2308.01674v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.15402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quanziang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Renzhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuexiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dong Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1\">Deyu Meng</a>",
          "description": "Continual learning is a promising machine learning paradigm to learn new\ntasks while retaining previously learned knowledge over streaming training\ndata. Till now, rehearsal-based methods, keeping a small part of data from old\ntasks as a memory buffer, have shown good performance in mitigating\ncatastrophic forgetting for previously learned knowledge. However, most of\nthese methods typically treat each new task equally, which may not adequately\nconsider the relationship or similarity between old and new tasks. Furthermore,\nthese methods commonly neglect sample importance in the continual training\nprocess and result in sub-optimal performance on certain tasks. To address this\nchallenging problem, we propose Relational Experience Replay (RER), a bi-level\nlearning framework, to adaptively tune task-wise relationships and sample\nimportance within each task to achieve a better `stability' and `plasticity'\ntrade-off. As such, the proposed method is capable of accumulating new\nknowledge while consolidating previously learned old knowledge during continual\nlearning. Extensive experiments conducted on three publicly available datasets\n(i.e., CIFAR-10, CIFAR-100, and Tiny ImageNet) show that the proposed method\ncan consistently improve the performance of all baselines and surpass current\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2112.15402",
          "publishedOn": "2023-08-05T00:48:27.426Z",
          "wordCount": 744,
          "title": "Relational Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship. (arXiv:2112.15402v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Liang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaofeng Zhu</a>",
          "description": "Unsupervised multiplex graph learning (UMGL) has been shown to achieve\nsignificant effectiveness for different downstream tasks by exploring both\ncomplementary information and consistent information among multiple graphs.\nHowever, previous methods usually overlook the issues in practical\napplications, i.e., the out-of-sample issue and the noise issue. To address the\nabove issues, in this paper, we propose an effective and efficient UMGL method\nto explore both complementary and consistent information. To do this, our\nmethod employs multiple MLP encoders rather than graph convolutional network\n(GCN) to conduct representation learning with two constraints, i.e., preserving\nthe local graph structure among nodes to handle the out-of-sample issue, and\nmaximizing the correlation of multiple node representations to handle the noise\nissue. Comprehensive experiments demonstrate that our proposed method achieves\nsuperior effectiveness and efficiency over the comparison methods and\neffectively tackles those two issues. Code is available at\nhttps://github.com/LarryUESTC/CoCoMG.",
          "link": "http://arxiv.org/abs/2308.01606",
          "publishedOn": "2023-08-05T00:48:27.404Z",
          "wordCount": 664,
          "title": "Unsupervised Multiplex Graph Learning with Complementary and Consistent Information. (arXiv:2308.01606v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Awadalla_A/0/1/0/all/0/1\">Anas Awadalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_I/0/1/0/all/0/1\">Irena Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1\">Josh Gardner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanafy_Y/0/1/0/all/0/1\">Yusuf Hanafy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marathe_K/0/1/0/all/0/1\">Kalyani Marathe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagawa_S/0/1/0/all/0/1\">Shiori Sagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1\">Jenia Jitsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1\">Simon Kornblith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_P/0/1/0/all/0/1\">Pang Wei Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilharco_G/0/1/0/all/0/1\">Gabriel Ilharco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>",
          "description": "We introduce OpenFlamingo, a family of autoregressive vision-language models\nranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce\nan open-source replication of DeepMind's Flamingo models. On seven\nvision-language datasets, OpenFlamingo models average between 80 - 89% of\ncorresponding Flamingo performance. This technical report describes our models,\ntraining data, hyperparameters, and evaluation suite. We share our models and\ncode at https://github.com/mlfoundations/open_flamingo.",
          "link": "http://arxiv.org/abs/2308.01390",
          "publishedOn": "2023-08-05T00:48:27.396Z",
          "wordCount": 690,
          "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models. (arXiv:2308.01390v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.07898",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kawamata_Y/0/1/0/all/0/1\">Yuji Kawamata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Motai_R/0/1/0/all/0/1\">Ryoki Motai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Okada_Y/0/1/0/all/0/1\">Yukihiko Okada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Imakura_A/0/1/0/all/0/1\">Akira Imakura</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sakurai_T/0/1/0/all/0/1\">Tetsuya Sakurai</a>",
          "description": "The development of technologies for causal inference with the privacy\npreservation of distributed data has attracted considerable attention in recent\nyears. To address this issue, we propose a data collaboration quasi-experiment\n(DC-QE) that enables causal inference from distributed data with privacy\npreservation. In our method, first, local parties construct\ndimensionality-reduced intermediate representations from the private data.\nSecond, they share intermediate representations, instead of private data for\nprivacy preservation. Third, propensity scores were estimated from the shared\nintermediate representations. Finally, the treatment effects were estimated\nfrom propensity scores. Our method can reduce both random errors and biases,\nwhereas existing methods can only reduce random errors in the estimation of\ntreatment effects. Through numerical experiments on both artificial and\nreal-world data, we confirmed that our method can lead to better estimation\nresults than individual analyses. Dimensionality-reduction loses some of the\ninformation in the private data and causes performance degradation. However, we\nobserved that in the experiments, sharing intermediate representations with\nmany parties to resolve the lack of subjects and covariates, our method\nimproved performance enough to overcome the degradation caused by\ndimensionality-reduction. With the spread of our method, intermediate\nrepresentations can be published as open data to help researchers find\ncausalities and accumulated as a knowledge base.",
          "link": "http://arxiv.org/abs/2208.07898",
          "publishedOn": "2023-08-05T00:48:27.389Z",
          "wordCount": 718,
          "title": "Collaborative causal inference on distributed data. (arXiv:2208.07898v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2111.12146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_R/0/1/0/all/0/1\">Richa Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phlypo_R/0/1/0/all/0/1\">Ronald Phlypo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saini_R/0/1/0/all/0/1\">Rajkumar Saini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>",
          "description": "Integrating knowledge across different domains is an essential feature of\nhuman learning. Learning paradigms such as transfer learning, meta learning,\nand multi-task learning reflect the human learning process by exploiting the\nprior knowledge for new tasks, encouraging faster learning and good\ngeneralization for new tasks. This article gives a detailed view of these\nlearning paradigms and their comparative analysis. The weakness of one learning\nalgorithm turns out to be a strength of another, and thus merging them is a\nprevalent trait in the literature. There are numerous research papers that\nfocus on each of these learning paradigms separately and provide a\ncomprehensive overview of them. However, this article provides a review of\nresearch studies that combine (two of) these learning algorithms. This survey\ndescribes how these techniques are combined to solve problems in many different\nfields of study, including computer vision, natural language processing,\nhyperspectral imaging, and many more, in supervised setting only. As a result,\nthe global generic learning network an amalgamation of meta learning, transfer\nlearning, and multi-task learning is introduced here, along with some open\nresearch questions and future research directions in the multi-task setting.",
          "link": "http://arxiv.org/abs/2111.12146",
          "publishedOn": "2023-08-05T00:48:27.382Z",
          "wordCount": 803,
          "title": "Sharing to learn and learning to share -- Fitting together Meta-Learning, Multi-Task Learning, and Transfer Learning: A meta review. (arXiv:2111.12146v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.06267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhiqiu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Samuel Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1\">Zhiyi Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1\">Deepak Pathak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>",
          "description": "The ability to quickly learn a new task with minimal instruction - known as\nfew-shot learning - is a central aspect of intelligent agents. Classical\nfew-shot benchmarks make use of few-shot samples from a single modality, but\nsuch samples may not be sufficient to characterize an entire concept class. In\ncontrast, humans use cross-modal information to learn new concepts efficiently.\nIn this work, we demonstrate that one can indeed build a better ${\\bf visual}$\ndog classifier by ${\\bf read}$ing about dogs and ${\\bf listen}$ing to them\nbark. To do so, we exploit the fact that recent multimodal foundation models\nsuch as CLIP are inherently cross-modal, mapping different modalities to the\nsame representation space. Specifically, we propose a simple cross-modal\nadaptation approach that learns from few-shot examples spanning different\nmodalities. By repurposing class names as additional one-shot training samples,\nwe achieve SOTA results with an embarrassingly simple linear classifier for\nvision-language adaptation. Furthermore, we show that our approach can benefit\nexisting methods such as prefix tuning, adapters, and classifier ensembling.\nFinally, to explore other modalities beyond vision and language, we construct\nthe first (to our knowledge) audiovisual few-shot benchmark and use cross-modal\ntraining to improve the performance of both image and audio classification.",
          "link": "http://arxiv.org/abs/2301.06267",
          "publishedOn": "2023-08-05T00:48:27.361Z",
          "wordCount": 770,
          "title": "Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with Multimodal Models. (arXiv:2301.06267v4 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.16149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alromih_A/0/1/0/all/0/1\">Arwa Alromih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gope_P/0/1/0/all/0/1\">Prosanta Gope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikdar_B/0/1/0/all/0/1\">Biplab Sikdar</a>",
          "description": "Energy theft detection (ETD) and energy consumption forecasting (ECF) are two\ninterconnected challenges in smart grid systems. Addressing these issues\ncollectively is crucial for ensuring system security. This paper addresses the\ninterconnected challenges of ETD and ECF in smart grid systems. The proposed\nsolution combines long short-term memory (LSTM) and a denoising diffusion\nprobabilistic model (DDPM) to generate input reconstruction and forecasting. By\nleveraging the reconstruction and forecasting errors, the system identifies\ninstances of energy theft, with the methods based on reconstruction error and\nforecasting error complementing each other in detecting different types of\nattacks. Through extensive experiments on real-world and synthetic datasets,\nthe proposed scheme outperforms baseline methods in ETD and ECF problems. The\nensemble method significantly enhances ETD performance, accurately detecting\nenergy theft attacks that baseline methods fail to detect. The research offers\na comprehensive and effective solution for addressing ETD and ECF challenges,\ndemonstrating promising results and improved security in smart grid systems.",
          "link": "http://arxiv.org/abs/2307.16149",
          "publishedOn": "2023-08-05T00:48:27.355Z",
          "wordCount": 723,
          "title": "An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting in Smart Grid. (arXiv:2307.16149v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nachkov_A/0/1/0/all/0/1\">Asen Nachkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luise_G/0/1/0/all/0/1\">Giulia Luise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valdettaro_F/0/1/0/all/0/1\">Filippo Valdettaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faisal_A/0/1/0/all/0/1\">Aldo Faisal</a>",
          "description": "Efficient exploration in complex environments remains a major challenge for\nreinforcement learning (RL). Compared to previous Thompson sampling-inspired\nmechanisms that enable temporally extended exploration, i.e., deep exploration,\nwe focus on deep exploration in distributional RL. We develop here a general\npurpose approach, Bag of Policies (BoP), that can be built on top of any return\ndistribution estimator by maintaining a population of its copies. BoP consists\nof an ensemble of multiple heads that are updated independently. During\ntraining, each episode is controlled by only one of the heads and the collected\nstate-action pairs are used to update all heads off-policy, leading to distinct\nlearning signals for each head which diversify learning and behaviour. To test\nwhether optimistic ensemble method can improve on distributional RL as did on\nscalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a\npopulation of distributional actor-critics using Bayesian Distributional Policy\nGradients (BDPG). The population thus approximates a posterior distribution of\nreturn distributions along with a posterior distribution of policies. Another\nbenefit of building upon BDPG is that it allows to analyze global posterior\nuncertainty along with local curiosity bonus simultaneously for exploration. As\nBDPG is already an optimistic method, this pairing helps to investigate if\noptimism is accumulatable in distributional RL. Overall BoP results in greater\nrobustness and speed during learning as demonstrated by our experimental\nresults on ALE Atari games.",
          "link": "http://arxiv.org/abs/2308.01759",
          "publishedOn": "2023-08-05T00:48:27.298Z",
          "wordCount": 744,
          "title": "Bag of Policies for Distributional Deep Exploration. (arXiv:2308.01759v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1\">Qianwen Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1\">Hangwei Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yonghui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lizhen Cui</a>",
          "description": "Unsupervised representation learning approaches aim to learn discriminative\nfeature representations from unlabeled data, without the requirement of\nannotating every sample. Enabling unsupervised representation learning is\nextremely crucial for time series data, due to its unique annotation bottleneck\ncaused by its complex characteristics and lack of visual cues compared with\nother data modalities. In recent years, unsupervised representation learning\ntechniques have advanced rapidly in various domains. However, there is a lack\nof systematic analysis of unsupervised representation learning approaches for\ntime series. To fill the gap, we conduct a comprehensive literature review of\nexisting rapidly evolving unsupervised representation learning approaches for\ntime series. Moreover, we also develop a unified and standardized library,\nnamed ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast\nimplementations and unified evaluations on various models. With ULTS, we\nempirically evaluate state-of-the-art approaches, especially the rapidly\nevolving contrastive learning methods, on 9 diverse real-world datasets. We\nfurther discuss practical considerations as well as open research challenges on\nunsupervised representation learning for time series to facilitate future\nresearch in this field.",
          "link": "http://arxiv.org/abs/2308.01578",
          "publishedOn": "2023-08-05T00:48:26.926Z",
          "wordCount": null,
          "title": "Unsupervised Representation Learning for Time Series: A Review. (arXiv:2308.01578v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.08757",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tomasetti_L/0/1/0/all/0/1\">Luca Tomasetti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Engan_K/0/1/0/all/0/1\">Kjersti Engan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hollesli_L/0/1/0/all/0/1\">Liv Jorunn H&#xf8;llesli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurz_K/0/1/0/all/0/1\">Kathinka D&#xe6;hli Kurz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khanmohammadi_M/0/1/0/all/0/1\">Mahdieh Khanmohammadi</a>",
          "description": "Precise and fast prediction methods for ischemic areas comprised of dead\ntissue, core, and salvageable tissue, penumbra, in acute ischemic stroke (AIS)\npatients are of significant clinical interest. They play an essential role in\nimproving diagnosis and treatment planning. Computed Tomography (CT) scan is\none of the primary modalities for early assessment in patients with suspected\nAIS. CT Perfusion (CTP) is often used as a primary assessment to determine\nstroke location, severity, and volume of ischemic lesions. Current automatic\nsegmentation methods for CTP mostly use already processed 3D parametric maps\nconventionally used for clinical interpretation by radiologists as input.\nAlternatively, the raw CTP data is used on a slice-by-slice basis as 2D+time\ninput, where the spatial information over the volume is ignored. In addition,\nthese methods are only interested in segmenting core regions, while predicting\npenumbra can be essential for treatment planning. This paper investigates\ndifferent methods to utilize the entire 4D CTP as input to fully exploit the\nspatio-temporal information, leading us to propose a novel 4D convolution\nlayer. Our comprehensive experiments on a local dataset of 152 patients divided\ninto three groups show that our proposed models generate more precise results\nthan other methods explored. Adopting the proposed 4D mJ-Net, a Dice\nCoefficient of 0.53 and 0.23 is achieved for segmenting penumbra and core\nareas, respectively. The code is available on\nhttps://github.com/Biomedical-Data-Analysis-Laboratory/4D-mJ-Net.git.",
          "link": "http://arxiv.org/abs/2303.08757",
          "publishedOn": "2023-08-05T00:48:26.926Z",
          "wordCount": null,
          "title": "CT Perfusion is All We Need: 4D CNN Segmentation of Penumbra and Core in Patient With Suspected Ischemic Stroke. (arXiv:2303.08757v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08875",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "This paper focusses on the optimal implementation of a Mean Variance\nEstimation network (MVE network) (Nix and Weigend, 1994). This type of network\nis often used as a building block for uncertainty estimation methods in a\nregression setting, for instance Concrete dropout (Gal et al., 2017) and Deep\nEnsembles (Lakshminarayanan et al., 2017). Specifically, an MVE network assumes\nthat the data is produced from a normal distribution with a mean function and\nvariance function. The MVE network outputs a mean and variance estimate and\noptimizes the network parameters by minimizing the negative loglikelihood. In\nour paper, we present two significant insights. Firstly, the convergence\ndifficulties reported in recent work can be relatively easily prevented by\nfollowing the simple yet often overlooked recommendation from the original\nauthors that a warm-up period should be used. During this period, only the mean\nis optimized with a fixed variance. We demonstrate the effectiveness of this\nstep through experimentation, highlighting that it should be standard practice.\nAs a sidenote, we examine whether, after the warm-up, it is beneficial to fix\nthe mean while optimizing the variance or to optimize both simultaneously.\nHere, we do not observe a substantial difference. Secondly, we introduce a\nnovel improvement of the MVE network: separate regularization of the mean and\nthe variance estimate. We demonstrate, both on toy examples and on a number of\nbenchmark UCI regression data sets, that following the original recommendations\nand the novel separate regularization can lead to significant improvements.",
          "link": "http://arxiv.org/abs/2302.08875",
          "publishedOn": "2023-08-05T00:48:26.917Z",
          "wordCount": null,
          "title": "Optimal Training of Mean Variance Estimation Neural Networks. (arXiv:2302.08875v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croitoru_F/0/1/0/all/0/1\">Florinel-Alin Croitoru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hondru_V/0/1/0/all/0/1\">Vlad Hondru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Text-to-image diffusion models such as Stable Diffusion have recently\nattracted the interest of many researchers, and inverting the diffusion process\ncan play an important role in better understanding the generative process and\nhow to engineer prompts in order to obtain the desired images. To this end, we\nintroduce the new task of predicting the text prompt given an image generated\nby a generative diffusion model. We combine a series of white-box and black-box\nmodels (with and without access to the weights of the diffusion network) to\ndeal with the proposed task. We propose a novel learning framework comprising\nof a joint prompt regression and multi-label vocabulary classification\nobjective that generates improved prompts. To further improve our method, we\nemploy a curriculum learning procedure that promotes the learning of\nimage-prompt pairs with lower labeling noise (i.e. that are better aligned),\nand an unsupervised domain-adaptive kernel learning method that uses the\nsimilarities between samples in the source and target domains as extra\nfeatures. We conduct experiments on the DiffusionDB data set, predicting text\nprompts from images generated by Stable Diffusion. Our novel learning framework\nproduces excellent results on the aforementioned task, yielding the highest\ngains when applied on the white-box model. In addition, we make an interesting\ndiscovery: training a diffusion model on the prompt generation task can make\nthe model generate images that are much better aligned with the input prompts,\nwhen the model is directly reused for text-to-image generation.",
          "link": "http://arxiv.org/abs/2308.01472",
          "publishedOn": "2023-08-05T00:48:26.916Z",
          "wordCount": null,
          "title": "Reverse Stable Diffusion: What prompt was used to generate this image?. (arXiv:2308.01472v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukada_Y/0/1/0/all/0/1\">Yuki Tsukada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iiduka_H/0/1/0/all/0/1\">Hideaki Iiduka</a>",
          "description": "Stochastic gradient descent (SGD) is the simplest deep learning optimizer\nwith which to train deep neural networks. While SGD can use various learning\nrates, such as constant or diminishing rates, the previous numerical results\nshowed that SGD performs better than other deep learning optimizers using when\nit uses learning rates given by line search methods. In this paper, we perform\na convergence analysis on SGD with a learning rate given by an Armijo line\nsearch for nonconvex optimization. The analysis indicates that the upper bound\nof the expectation of the squared norm of the full gradient becomes small when\nthe number of steps and the batch size are large. Next, we show that, for SGD\nwith the Armijo-line-search learning rate, the number of steps needed for\nnonconvex optimization is a monotone decreasing convex function of the batch\nsize; that is, the number of steps needed for nonconvex optimization decreases\nas the batch size increases. Furthermore, we show that the stochastic\nfirst-order oracle (SFO) complexity, which is the stochastic gradient\ncomputation cost, is a convex function of the batch size; that is, there exists\na critical batch size that minimizes the SFO complexity. Finally, we provide\nnumerical results that support our theoretical results. The numerical results\nindicate that the number of steps needed for training deep neural networks\ndecreases as the batch size increases and that there exist the critical batch\nsizes that can be estimated from the theoretical results.",
          "link": "http://arxiv.org/abs/2307.13831",
          "publishedOn": "2023-08-05T00:48:26.914Z",
          "wordCount": null,
          "title": "Relationship between Batch Size and Number of Steps Needed for Nonconvex Optimization of Stochastic Gradient Descent using Armijo Line Search. (arXiv:2307.13831v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_W/0/1/0/all/0/1\">Waheed Ul Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Little_M/0/1/0/all/0/1\">Max A. Little</a>",
          "description": "Algorithms for solving the linear classification problem have a long history,\ndating back at least to 1936 with linear discriminant analysis. For linearly\nseparable data, many algorithms can obtain the exact solution to the\ncorresponding 0-1 loss classification problem efficiently, but for data which\nis not linearly separable, it has been shown that this problem, in full\ngenerality, is NP-hard. Alternative approaches all involve approximations of\nsome kind, including the use of surrogates for the 0-1 loss (for example, the\nhinge or logistic loss) or approximate combinatorial search, none of which can\nbe guaranteed to solve the problem exactly. Finding efficient algorithms to\nobtain an exact i.e. globally optimal solution for the 0-1 loss linear\nclassification problem with fixed dimension, remains an open problem. In\nresearch we report here, we detail the rigorous construction of a new\nalgorithm, incremental cell enumeration (ICE), that can solve the 0-1 loss\nclassification problem exactly in polynomial time. We prove correctness using\nconcepts from the theory of hyperplane arrangements and oriented matroids. We\ndemonstrate the effectiveness of this algorithm on synthetic and real-world\ndatasets, showing optimal accuracy both in and out-of-sample, in practical\ncomputational time. We also empirically demonstrate how the use of approximate\nupper bound leads to polynomial time run-time improvements to the algorithm\nwhilst retaining exactness. To our knowledge, this is the first,\nrigorously-proven polynomial time, practical algorithm for this long-standing\nproblem.",
          "link": "http://arxiv.org/abs/2306.12344",
          "publishedOn": "2023-08-05T00:48:26.848Z",
          "wordCount": null,
          "title": "An efficient, provably exact, practical algorithm for the 0-1 loss linear classification problem. (arXiv:2306.12344v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.14563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hiabu_M/0/1/0/all/0/1\">Munir Hiabu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mammen_E/0/1/0/all/0/1\">Enno Mammen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meyer_J/0/1/0/all/0/1\">Joseph T. Meyer</a>",
          "description": "We introduce a novel interpretable tree based algorithm for prediction in a\nregression setting. Our motivation is to estimate the unknown regression\nfunction from a functional decomposition perspective in which the functional\ncomponents correspond to lower order interaction terms. The idea is to modify\nthe random forest algorithm by keeping certain leaves after they are split\ninstead of deleting them. This leads to non-binary trees which we refer to as\nplanted trees. An extension to a forest leads to our random planted forest\nalgorithm. Additionally, the maximum number of covariates which can interact\nwithin a leaf can be bounded. If we set this interaction bound to one, the\nresulting estimator is a sum of one-dimensional functions. In the other extreme\ncase, if we do not set a limit, the resulting estimator and corresponding model\nplace no restrictions on the form of the regression function. In a simulation\nstudy we find encouraging prediction and visualisation properties of our random\nplanted forest method. We also develop theory for an idealized version of\nrandom planted forests in cases where the interaction bound is low. We show\nthat if it is smaller than three, the idealized version achieves asymptotically\noptimal convergence rates up to a logarithmic factor. Code is available on\nGitHub https://github.com/PlantedML/randomPlantedForest.",
          "link": "http://arxiv.org/abs/2012.14563",
          "publishedOn": "2023-08-05T00:48:26.842Z",
          "wordCount": null,
          "title": "Random Planted Forest: a directly interpretable tree ensemble. (arXiv:2012.14563v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Pengcheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jinpu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yulin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Z/0/1/0/all/0/1\">Ziqi Rong</a>",
          "description": "DNA methylation is a crucial regulator of gene transcription and has been\nlinked to various diseases, including autoimmune diseases and cancers. However,\ndiagnostics based on DNA methylation face challenges due to large feature sets\nand small sample sizes, resulting in overfitting and suboptimal performance. To\naddress these issues, we propose MIRACLE, a novel interpretable neural network\nthat leverages autoencoder-based multi-task learning to integrate multiple\ndatasets and jointly identify common patterns in DNA methylation.\n\nMIRACLE's architecture reflects the relationships between methylation sites,\ngenes, and pathways, ensuring biological interpretability and meaningfulness.\nThe network comprises an encoder and a decoder, with a bottleneck layer\nrepresenting pathway information as the basic unit of heredity. Customized\ndefined MaskedLinear Layer is constrained by site-gene-pathway graph adjacency\nmatrix information, which provides explainability and expresses the\nsite-gene-pathway hierarchical structure explicitly. And from the embedding,\nthere are different multi-task classifiers to predict diseases.\n\nTested on six datasets, including rheumatoid arthritis, systemic lupus\nerythematosus, multiple sclerosis, inflammatory bowel disease, psoriasis, and\ntype 1 diabetes, MIRACLE demonstrates robust performance in identifying common\nfunctions of DNA methylation across different phenotypes, with higher accuracy\nin prediction dieseases than baseline methods. By incorporating biological\nprior knowledge, MIRACLE offers a meaningful and interpretable framework for\nDNA methylation data analysis in the context of autoimmune diseases.",
          "link": "http://arxiv.org/abs/2306.13866",
          "publishedOn": "2023-08-05T00:48:26.838Z",
          "wordCount": null,
          "title": "MIRACLE: Multi-task Learning based Interpretable Regulation of Autoimmune Diseases through Common Latent Epigenetics. (arXiv:2306.13866v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pasteris_S/0/1/0/all/0/1\">Stephen Pasteris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hicks_C/0/1/0/all/0/1\">Chris Hicks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mavroudis_V/0/1/0/all/0/1\">Vasilios Mavroudis</a>",
          "description": "In this paper we adapt the nearest neighbour rule to the contextual bandit\nproblem. Our algorithm handles the fully adversarial setting in which no\nassumptions at all are made about the data-generation process. When combined\nwith a sufficiently fast data-structure for (perhaps approximate) adaptive\nnearest neighbour search, such as a navigating net, our algorithm is extremely\nefficient - having a per trial running time polylogarithmic in both the number\nof trials and actions, and taking only quasi-linear space.",
          "link": "http://arxiv.org/abs/2306.13773",
          "publishedOn": "2023-08-05T00:48:26.837Z",
          "wordCount": null,
          "title": "Nearest Neighbour with Bandit Feedback. (arXiv:2306.13773v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1\">Ruyi Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1\">Shijin Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaolin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1\">Yunsi Fei</a>",
          "description": "Graph neural networks (GNNs) have brought superb performance to various\napplications utilizing graph structural data, such as social analysis and fraud\ndetection. The graph links, e.g., social relationships and transaction history,\nare sensitive and valuable information, which raises privacy concerns when\nusing GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel\ngraph poisoning attack that increases the effectiveness of graph link stealing\nby amplifying the link connectivity leakage. To infer node adjacency more\naccurately, we propose an attention mechanism that can be embedded into the\nlink detection network. Our experiments demonstrate that VertexSerum\nsignificantly outperforms the SOTA link inference attack, improving the AUC\nscores by an average of $9.8\\%$ across four real-world datasets and three\ndifferent GNN structures. Furthermore, our experiments reveal the effectiveness\nof VertexSerum in both black-box and online learning settings, further\nvalidating its applicability in real-world scenarios.",
          "link": "http://arxiv.org/abs/2308.01469",
          "publishedOn": "2023-08-05T00:48:26.831Z",
          "wordCount": null,
          "title": "VertexSerum: Poisoning Graph Neural Networks for Link Inference. (arXiv:2308.01469v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01323",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Hu_J/0/1/0/all/0/1\">Jianchang Hu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Szymczak_S/0/1/0/all/0/1\">Silke Szymczak</a>",
          "description": "Gene network information is believed to be beneficial for disease module and\npathway identification, but has not been explicitly utilized in the standard\nrandom forest (RF) algorithm for gene expression data analysis. We investigate\nthe performance of a network-guided RF where the network information is\nsummarized into a sampling probability of predictor variables which is further\nused in the construction of the RF. Our results suggest that network-guided RF\ndoes not provide better disease prediction than the standard RF. In terms of\ndisease gene discovery, if disease genes form module(s), network-guided RF\nidentifies them more accurately. In addition, when disease status is\nindependent from genes in the given network, spurious gene selection results\ncan occur when using network information, especially on hub genes. Our\nempirical analysis on two balanced microarray and RNA-Seq breast cancer\ndatasets from The Cancer Genome Atlas (TCGA) for classification of progesterone\nreceptor (PR) status also demonstrates that network-guided RF can identify\ngenes from PGR-related pathways, which leads to a better connected module of\nidentified genes.",
          "link": "http://arxiv.org/abs/2308.01323",
          "publishedOn": "2023-08-05T00:48:26.827Z",
          "wordCount": null,
          "title": "Evaluation of network-guided random forest for disease gene discovery. (arXiv:2308.01323v1 [q-bio.MN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Haobo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangtai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jianlong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lefei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>",
          "description": "How to enable learnability for new classes while keeping the capability well\non old classes has been a crucial challenge for class incremental learning.\nBeyond the normal case, long-tail class incremental learning and few-shot class\nincremental learning are also proposed to consider the data imbalance and data\nscarcity, respectively, which are common in real-world implementations and\nfurther exacerbate the well-known problem of catastrophic forgetting. Existing\nmethods are specifically proposed for one of the three tasks. In this paper, we\noffer a unified solution to the misalignment dilemma in the three tasks.\nConcretely, we propose neural collapse terminus that is a fixed structure with\nthe maximal equiangular inter-class separation for the whole label space. It\nserves as a consistent target throughout the incremental training to avoid\ndividing the feature space incrementally. For CIL and LTCIL, we further propose\na prototype evolving scheme to drive the backbone features into our neural\ncollapse terminus smoothly. Our method also works for FSCIL with only minor\nadaptations. Theoretical analysis indicates that our method holds the neural\ncollapse optimality in an incremental fashion regardless of data imbalance or\ndata scarcity. We also design a generalized case where we do not know the total\nnumber of classes and whether the data distribution is normal, long-tail, or\nfew-shot for each coming session, to test the generalizability of our method.\nExtensive experiments with multiple datasets are conducted to demonstrate the\neffectiveness of our unified solution to all the three tasks and the\ngeneralized case.",
          "link": "http://arxiv.org/abs/2308.01746",
          "publishedOn": "2023-08-05T00:48:26.823Z",
          "wordCount": null,
          "title": "Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants. (arXiv:2308.01746v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sessa_P/0/1/0/all/0/1\">Pier Giuseppe Sessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laforgue_P/0/1/0/all/0/1\">Pierre Laforgue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>",
          "description": "Multitask learning is a powerful framework that enables one to simultaneously\nlearn multiple related tasks by sharing information between them. Quantifying\nuncertainty in the estimated tasks is of pivotal importance for many downstream\napplications, such as online or active learning. In this work, we provide novel\nmultitask confidence intervals in the challenging agnostic setting, i.e., when\nneither the similarity between tasks nor the tasks' features are available to\nthe learner. The obtained intervals do not require i.i.d. data and can be\ndirectly applied to bound the regret in online learning. Through a refined\nanalysis of the multitask information gain, we obtain new regret guarantees\nthat, depending on a task similarity parameter, can significantly improve over\ntreating tasks independently. We further propose a novel online learning\nalgorithm that achieves such improved regret without knowing this parameter in\nadvance, i.e., automatically adapting to task similarity. As a second key\napplication of our results, we introduce a novel multitask active learning\nsetup where several tasks must be simultaneously optimized, but only one of\nthem can be queried for feedback by the learner at each round. For this\nproblem, we design a no-regret algorithm that uses our confidence intervals to\ndecide which task should be queried. Finally, we empirically validate our\nbounds and algorithms on synthetic and real-world (drug discovery) data.",
          "link": "http://arxiv.org/abs/2308.01744",
          "publishedOn": "2023-08-05T00:48:26.822Z",
          "wordCount": null,
          "title": "Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning. (arXiv:2308.01744v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jianghao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yanru Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xinyi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruiming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>",
          "description": "With the widespread application of personalized online services,\nclick-through rate (CTR) prediction has received more and more attention and\nresearch. The most prominent features of CTR prediction are its multi-field\ncategorical data format, and vast and daily-growing data volume. The large\ncapacity of neural models helps digest such massive amounts of data under the\nsupervised learning paradigm, yet they fail to utilize the substantial data to\nits full potential, since the 1-bit click signal is not sufficient to guide the\nmodel to learn capable representations of features and instances. The\nself-supervised learning paradigm provides a more promising pretrain-finetune\nsolution to better exploit the large amount of user click logs, and learn more\ngeneralized and effective representations. However, self-supervised learning\nfor CTR prediction is still an open question, since current works on this line\nare only preliminary and rudimentary. To this end, we propose a Model-agnostic\npretraining (MAP) framework that applies feature corruption and recovery on\nmulti-field categorical data, and more specifically, we derive two practical\nalgorithms: masked feature prediction (MFP) and replaced feature detection\n(RFD). MFP digs into feature interactions within each instance through masking\nand predicting a small portion of input features, and introduces noise\ncontrastive estimation (NCE) to handle large feature spaces. RFD further turns\nMFP into a binary classification mode through replacing and detecting changes\nin input features, making it even simpler and more effective for CTR\npretraining. Our extensive experiments on two real-world large-scale datasets\n(i.e., Avazu, Criteo) demonstrate the advantages of these two methods on\nseveral strong backbones (e.g., DCNv2, DeepFM), and achieve new\nstate-of-the-art performance in terms of both effectiveness and efficiency for\nCTR prediction.",
          "link": "http://arxiv.org/abs/2308.01737",
          "publishedOn": "2023-08-05T00:48:26.814Z",
          "wordCount": null,
          "title": "MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction. (arXiv:2308.01737v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jiachen Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Peng Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ba_Z/0/1/0/all/0/1\">Zhongjie Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Kui Ren</a>",
          "description": "Diffusion models have emerged as the \\emph{de-facto} technique for image\ngeneration, yet they entail significant computational overhead, hindering the\ntechnique's broader application in the research community. We propose a\nprior-based denoising training framework, the first to incorporate the\npre-train and fine-tune paradigm into the diffusion model training process,\nwhich substantially improves training efficiency and shows potential in\nfacilitating various downstream tasks. Our approach centers on masking a high\nproportion (e.g., up to 90\\%) of the input image and employing masked denoising\nscore matching to denoise the visible areas, thereby guiding the diffusion\nmodel to learn more salient features from training data as prior knowledge. By\nutilizing masked learning in a pre-training stage, we efficiently train the\nViT-based diffusion model on CelebA-HQ $256 \\times 256$ in the pixel space,\nachieving a 4x acceleration and enhancing the quality of generated images\ncompared to denoising diffusion probabilistic model (DDPM). Moreover, our\nmasked pre-training technique can be universally applied to various diffusion\nmodels that directly generate images in the pixel space, aiding in the learning\nof pre-trained models with superior generalizability. For instance, a diffusion\nmodel pre-trained on VGGFace2 attains a 46\\% quality improvement through\nfine-tuning with merely 10\\% data from a different distribution. Moreover, our\nmethod shows the potential to serve as a training paradigm for enhancing the\nprivacy protection capabilities of diffusion models. Our code is available at\n\\url{https://github.com/jiachenlei/maskdm}.",
          "link": "http://arxiv.org/abs/2306.11363",
          "publishedOn": "2023-08-05T00:48:26.813Z",
          "wordCount": null,
          "title": "Masked Diffusion Models Are Fast and Privacy-Aware Learners. (arXiv:2306.11363v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01419",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Pu_X/0/1/0/all/0/1\">Xingyue Pu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Cucuringu_M/0/1/0/all/0/1\">Mihai Cucuringu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Dong_X/0/1/0/all/0/1\">Xiaowen Dong</a>",
          "description": "We present a novel methodology for modeling and forecasting multivariate\nrealized volatilities using customized graph neural networks to incorporate\nspillover effects across stocks. The proposed model offers the benefits of\nincorporating spillover effects from multi-hop neighbors, capturing nonlinear\nrelationships, and flexible training with different loss functions. Our\nempirical findings provide compelling evidence that incorporating spillover\neffects from multi-hop neighbors alone does not yield a clear advantage in\nterms of predictive accuracy. However, modeling nonlinear spillover effects\nenhances the forecasting accuracy of realized volatilities, particularly for\nshort-term horizons of up to one week. Moreover, our results consistently\nindicate that training with the Quasi-likelihood loss leads to substantial\nimprovements in model performance compared to the commonly-used mean squared\nerror. A comprehensive series of empirical evaluations in alternative settings\nconfirm the robustness of our results.",
          "link": "http://arxiv.org/abs/2308.01419",
          "publishedOn": "2023-08-05T00:48:26.803Z",
          "wordCount": null,
          "title": "Graph Neural Networks for Forecasting Multivariate Realized Volatility with Spillover Effects. (arXiv:2308.01419v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.08736",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zhou_M/0/1/0/all/0/1\">Mo Zhou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Han_J/0/1/0/all/0/1\">Jiequn Han</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rachh_M/0/1/0/all/0/1\">Manas Rachh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Borges_C/0/1/0/all/0/1\">Carlos Borges</a>",
          "description": "We consider the inverse acoustic obstacle problem for sound-soft star-shaped\nobstacles in two dimensions wherein the boundary of the obstacle is determined\nfrom measurements of the scattered field at a collection of receivers outside\nthe object. One of the standard approaches for solving this problem is to\nreformulate it as an optimization problem: finding the boundary of the domain\nthat minimizes the $L^2$ distance between computed values of the scattered\nfield and the given measurement data. The optimization problem is\ncomputationally challenging since the local set of convexity shrinks with\nincreasing frequency and results in an increasing number of local minima in the\nvicinity of the true solution. In many practical experimental settings, low\nfrequency measurements are unavailable due to limitations of the experimental\nsetup or the sensors used for measurement. Thus, obtaining a good initial guess\nfor the optimization problem plays a vital role in this environment.\n\nWe present a neural network warm-start approach for solving the inverse\nscattering problem, where an initial guess for the optimization problem is\nobtained using a trained neural network. We demonstrate the effectiveness of\nour method with several numerical examples. For high frequency problems, this\napproach outperforms traditional iterative methods such as Gauss-Newton\ninitialized without any prior (i.e., initialized using a unit circle), or\ninitialized using the solution of a direct method such as the linear sampling\nmethod. The algorithm remains robust to noise in the scattered field\nmeasurements and also converges to the true solution for limited aperture data.\nHowever, the number of training samples required to train the neural network\nscales exponentially in frequency and the complexity of the obstacles\nconsidered. We conclude with a discussion of this phenomenon and potential\ndirections for future research.",
          "link": "http://arxiv.org/abs/2212.08736",
          "publishedOn": "2023-08-05T00:48:26.803Z",
          "wordCount": null,
          "title": "A Neural Network Warm-Start Approach for the Inverse Acoustic Obstacle Scattering Problem. (arXiv:2212.08736v3 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01729",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Duval_F/0/1/0/all/0/1\">Francis Duval</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boucher_J/0/1/0/all/0/1\">Jean-Philippe Boucher</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pigeon_M/0/1/0/all/0/1\">Mathieu Pigeon</a>",
          "description": "We present novel cross-sectional and longitudinal claim count models for\nvehicle insurance built upon the Combined Actuarial Neural Network (CANN)\nframework proposed by Mario W\\\"uthrich and Michael Merz. The CANN approach\ncombines a classical actuarial model, such as a generalized linear model, with\na neural network. This blending of models results in a two-component model\ncomprising a classical regression model and a neural network part. The CANN\nmodel leverages the strengths of both components, providing a solid foundation\nand interpretability from the classical model while harnessing the flexibility\nand capacity to capture intricate relationships and interactions offered by the\nneural network. In our proposed models, we use well-known log-linear claim\ncount regression models for the classical regression part and a multilayer\nperceptron (MLP) for the neural network part. The MLP part is used to process\ntelematics car driving data given as a vector characterizing the driving\nbehavior of each insured driver. In addition to the Poisson and negative\nbinomial distributions for cross-sectional data, we propose a procedure for\ntraining our CANN model with a multivariate negative binomial (MVNB)\nspecification. By doing so, we introduce a longitudinal model that accounts for\nthe dependence between contracts from the same insured. Our results reveal that\nthe CANN models exhibit superior performance compared to log-linear models that\nrely on manually engineered telematics features.",
          "link": "http://arxiv.org/abs/2308.01729",
          "publishedOn": "2023-08-05T00:48:26.802Z",
          "wordCount": null,
          "title": "Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data. (arXiv:2308.01729v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.00605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jureckova_O/0/1/0/all/0/1\">Olha Jure&#x10d;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurecek_M/0/1/0/all/0/1\">Martin Jure&#x10d;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1\">Mark Stamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Troia_F/0/1/0/all/0/1\">Fabio Di Troia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorencz_R/0/1/0/all/0/1\">R&#xf3;bert L&#xf3;rencz</a>",
          "description": "A large amount of new malware is constantly being generated, which must not\nonly be distinguished from benign samples, but also classified into malware\nfamilies. For this purpose, investigating how existing malware families are\ndeveloped and examining emerging families need to be explored. This paper\nfocuses on the online processing of incoming malicious samples to assign them\nto existing families or, in the case of samples from new families, to cluster\nthem. We experimented with seven prevalent malware families from the EMBER\ndataset, four in the training set and three additional new families in the test\nset. Based on the classification score of the multilayer perceptron, we\ndetermined which samples would be classified and which would be clustered into\nnew malware families. We classified 97.21% of streaming data with a balanced\naccuracy of 95.33%. Then, we clustered the remaining data using a\nself-organizing map, achieving a purity from 47.61% for four clusters to 77.68%\nfor ten clusters. These results indicate that our approach has the potential to\nbe applied to the classification and clustering of zero-day malware into\nmalware families.",
          "link": "http://arxiv.org/abs/2305.00605",
          "publishedOn": "2023-08-05T00:48:26.801Z",
          "wordCount": null,
          "title": "Classification and Online Clustering of Zero-Day Malware. (arXiv:2305.00605v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Posch_S/0/1/0/all/0/1\">Stefan Posch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gossnitzer_C/0/1/0/all/0/1\">Clemens G&#xf6;&#xdf;nitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohrhofer_F/0/1/0/all/0/1\">Franz Rohrhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimmer_A/0/1/0/all/0/1\">Andreas Wimmer</a>",
          "description": "The turbulent jet ignition concept using prechambers is a promising solution\nto achieve stable combustion at lean conditions in large gas engines, leading\nto high efficiency at low emission levels. Due to the wide range of design and\noperating parameters for large gas engine prechambers, the preferred method for\nevaluating different designs is computational fluid dynamics (CFD), as testing\nin test bed measurement campaigns is time-consuming and expensive. However, the\nsignificant computational time required for detailed CFD simulations due to the\ncomplexity of solving the underlying physics also limits its applicability. In\noptimization settings similar to the present case, i.e., where the evaluation\nof the objective function(s) is computationally costly, Bayesian optimization\nhas largely replaced classical design-of-experiment. Thus, the present study\ndeals with the computationally efficient Bayesian optimization of large gas\nengine prechambers design using CFD simulation. Reynolds-averaged-Navier-Stokes\nsimulations are used to determine the target values as a function of the\nselected prechamber design parameters. The results indicate that the chosen\nstrategy is effective to find a prechamber design that achieves the desired\ntarget values.",
          "link": "http://arxiv.org/abs/2308.01743",
          "publishedOn": "2023-08-05T00:48:26.798Z",
          "wordCount": null,
          "title": "Finding the Optimum Design of Large Gas Engines Prechambers Using CFD and Bayesian Optimization. (arXiv:2308.01743v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agro_B/0/1/0/all/0/1\">Ben Agro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sykora_Q/0/1/0/all/0/1\">Quinlan Sykora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_S/0/1/0/all/0/1\">Sergio Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1\">Raquel Urtasun</a>",
          "description": "A self-driving vehicle (SDV) must be able to perceive its surroundings and\npredict the future behavior of other traffic participants. Existing works\neither perform object detection followed by trajectory forecasting of the\ndetected objects, or predict dense occupancy and flow grids for the whole\nscene. The former poses a safety concern as the number of detections needs to\nbe kept low for efficiency reasons, sacrificing object recall. The latter is\ncomputationally expensive due to the high-dimensionality of the output grid,\nand suffers from the limited receptive field inherent to fully convolutional\nnetworks. Furthermore, both approaches employ many computational resources\npredicting areas or objects that might never be queried by the motion planner.\nThis motivates our unified approach to perception and future prediction that\nimplicitly represents occupancy and flow over time with a single neural\nnetwork. Our method avoids unnecessary computation, as it can be directly\nqueried by the motion planner at continuous spatio-temporal locations.\nMoreover, we design an architecture that overcomes the limited receptive field\nof previous explicit occupancy prediction methods by adding an efficient yet\neffective global attention mechanism. Through extensive experiments in both\nurban and highway settings, we demonstrate that our implicit model outperforms\nthe current state-of-the-art. For more information, visit the project website:\nhttps://waabi.ai/research/implicito.",
          "link": "http://arxiv.org/abs/2308.01471",
          "publishedOn": "2023-08-05T00:48:26.797Z",
          "wordCount": null,
          "title": "Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving. (arXiv:2308.01471v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10903",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "With the rise of the popularity and usage of neural networks, trustworthy\nuncertainty estimation is becoming increasingly essential. One of the most\nprominent uncertainty estimation methods is Deep Ensembles (Lakshminarayanan et\nal., 2017) . A classical parametric model has uncertainty in the parameters due\nto the fact that the data on which the model is build is a random sample. A\nmodern neural network has an additional uncertainty component since the\noptimization of the network is random. Lakshminarayanan et al. (2017) noted\nthat Deep Ensembles do not incorporate the classical uncertainty induced by the\neffect of finite data. In this paper, we present a computationally cheap\nextension of Deep Ensembles for the regression setting, called Bootstrapped\nDeep Ensembles, that explicitly takes this classical effect of finite data into\naccount using a modified version of the parametric bootstrap. We demonstrate\nthrough an experimental study that our method significantly improves upon\nstandard Deep Ensembles",
          "link": "http://arxiv.org/abs/2202.10903",
          "publishedOn": "2023-08-05T00:48:26.793Z",
          "wordCount": null,
          "title": "Confident Neural Network Regression with Bootstrapped Deep Ensembles. (arXiv:2202.10903v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01362",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Laurie_M/0/1/0/all/0/1\">Mark Laurie</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lu_J/0/1/0/all/0/1\">James Lu</a>",
          "description": "While tumor dynamic modeling has been widely applied to support the\ndevelopment of oncology drugs, there remains a need to increase predictivity,\nenable personalized therapy, and improve decision-making. We propose the use of\nTumor Dynamic Neural-ODE (TDNODE) as a pharmacology-informed neural network to\nenable model discovery from longitudinal tumor size data. We show that TDNODE\novercomes a key limitation of existing models in its ability to make unbiased\npredictions from truncated data. The encoder-decoder architecture is designed\nto express an underlying dynamical law which possesses the fundamental property\nof generalized homogeneity with respect to time. Thus, the modeling formalism\nenables the encoder output to be interpreted as kinetic rate metrics, with\ninverse time as the physical unit. We show that the generated metrics can be\nused to predict patients' overall survival (OS) with high accuracy. The\nproposed modeling formalism provides a principled way to integrate multimodal\ndynamical datasets in oncology disease modeling.",
          "link": "http://arxiv.org/abs/2308.01362",
          "publishedOn": "2023-08-05T00:48:26.791Z",
          "wordCount": null,
          "title": "Explainable Deep Learning for Tumor Dynamic Modeling and Overall Survival Prediction using Neural-ODE. (arXiv:2308.01362v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07901",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ott_F/0/1/0/all/0/1\">Felix Ott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heublein_L/0/1/0/all/0/1\">Lucas Heublein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutschler_C/0/1/0/all/0/1\">Christopher Mutschler</a>",
          "description": "Cross-modal representation learning learns a shared embedding between two or\nmore modalities to improve performance in a given task compared to using only\none of the modalities. Cross-modal representation learning from different data\ntypes -- such as images and time-series data (e.g., audio or text data) --\nrequires a deep metric learning loss that minimizes the distance between the\nmodality embeddings. In this paper, we propose to use the contrastive or\ntriplet loss, which uses positive and negative identities to create sample\npairs with different labels, for cross-modal representation learning between\nimage and time-series modalities (CMR-IS). By adapting the triplet loss for\ncross-modal representation learning, higher accuracy in the main (time-series\nclassification) task can be achieved by exploiting additional information of\nthe auxiliary (image classification) task. We present a triplet loss with a\ndynamic margin for single label and sequence-to-sequence classification tasks.\nWe perform extensive evaluations on synthetic image and time-series data, and\non data for offline handwriting recognition (HWR) and on online HWR from\nsensor-enhanced pens for classifying written words. Our experiments show an\nimproved classification accuracy, faster convergence, and better\ngeneralizability due to an improved cross-modal representation. Furthermore,\nthe more suitable generalizability leads to a better adaptability between\nwriters for online HWR.",
          "link": "http://arxiv.org/abs/2202.07901",
          "publishedOn": "2023-08-05T00:48:26.789Z",
          "wordCount": null,
          "title": "Auxiliary Cross-Modal Representation Learning with Triplet Loss Functions for Online Handwriting Recognition. (arXiv:2202.07901v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.10406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhuliawala_S/0/1/0/all/0/1\">Shehzaad Dhuliawala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1\">Carl Allen</a>",
          "description": "We present a latent variable generalisation of neural network softmax\nclassification trained with cross-entropy loss, referred to as variational\nclassification (VC). Our approach offers a novel probabilistic perspective on\nthe highly familiar softmax classification model, to which it relates similarly\nto how variational and traditional autoencoders relate. We derive a training\nobjective based on the evidence lower bound (ELBO) that is non-trivial to\noptimize, and therefore propose an adversarial approach to maximise it. We show\nthat VC addresses an inherent inconsistency within softmax classification,\nwhilst also allowing more flexible choices of prior distributions in the latent\nspace in place of implicit assumptions revealed within off-the-shelf softmax\nclassifiers. Empirical evaluation on image and text classification datasets\ndemonstrates that variational classification maintains prediction accuracy\nwhile improving other desirable properties such as calibration and adversarial\nrobustness, particularly under distribution shift and low data settings.",
          "link": "http://arxiv.org/abs/2305.10406",
          "publishedOn": "2023-08-05T00:48:26.786Z",
          "wordCount": null,
          "title": "Variational Classification. (arXiv:2305.10406v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leluc_R/0/1/0/all/0/1\">R&#xe9;mi Leluc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadoche_E/0/1/0/all/0/1\">Elie Kadoche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertoncello_A/0/1/0/all/0/1\">Antoine Bertoncello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gourvenec_S/0/1/0/all/0/1\">S&#xe9;bastien Gourv&#xe9;nec</a>",
          "description": "Maintaining a balance between the supply and demand of products by optimizing\nreplenishment decisions is one of the most important challenges in the supply\nchain industry. This paper presents a novel reinforcement learning framework\ncalled MARLIM, to address the inventory management problem for a single-echelon\nmulti-products supply chain with stochastic demands and lead-times. Within this\ncontext, controllers are developed through single or multiple agents in a\ncooperative setting. Numerical experiments on real data demonstrate the\nbenefits of reinforcement learning methods over traditional baselines.",
          "link": "http://arxiv.org/abs/2308.01649",
          "publishedOn": "2023-08-05T00:48:26.784Z",
          "wordCount": null,
          "title": "MARLIM: Multi-Agent Reinforcement Learning for Inventory Management. (arXiv:2308.01649v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01789",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Turati_G/0/1/0/all/0/1\">Gloria Turati</a> (1), <a href=\"http://arxiv.org/find/quant-ph/1/au:+Dacrema_M/0/1/0/all/0/1\">Maurizio Ferrari Dacrema</a> (1), <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cremonesi_P/0/1/0/all/0/1\">Paolo Cremonesi</a> (1) ((1) Politecnico di Milano)",
          "description": "In recent years, Variational Quantum Algorithms (VQAs) have emerged as a\npromising approach for solving optimization problems on quantum computers in\nthe NISQ era. However, one limitation of VQAs is their reliance on\nfixed-structure circuits, which may not be taylored for specific problems or\nhardware configurations. A leading strategy to address this issue are\nAdaptative VQAs, which dynamically modify the circuit structure by adding and\nremoving gates, and optimize their parameters during the training. Several\nAdaptative VQAs, based on heuristics such as circuit shallowness, entanglement\ncapability and hardware compatibility, have already been proposed in the\nliterature, but there is still lack of a systematic comparison between the\ndifferent methods. In this paper, we aim to fill this gap by analyzing three\nAdaptative VQAs: Evolutionary Variational Quantum Eigensolver (EVQE), Variable\nAnsatz (VAns), already proposed in the literature, and Random Adapt-VQE\n(RA-VQE), a random approach we introduce as a baseline. In order to compare\nthese algorithms to traditional VQAs, we also include the Quantum Approximate\nOptimization Algorithm (QAOA) in our analysis. We apply these algorithms to\nQUBO problems and study their performance by examining the quality of the\nsolutions found and the computational times required. Additionally, we\ninvestigate how the choice of the hyperparameters can impact the overall\nperformance of the algorithms, highlighting the importance of selecting an\nappropriate methodology for hyperparameter tuning. Our analysis sets benchmarks\nfor Adaptative VQAs designed for near-term quantum devices and provides\nvaluable insights to guide future research in this area.",
          "link": "http://arxiv.org/abs/2308.01789",
          "publishedOn": "2023-08-05T00:48:26.784Z",
          "wordCount": null,
          "title": "Benchmarking Adaptative Variational Quantum Algorithms on QUBO Instances. (arXiv:2308.01789v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiawei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1\">Changkun Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1\">Ruikai Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>",
          "description": "For safety-related applications, it is crucial to produce trustworthy deep\nneural networks whose prediction is associated with confidence that can\nrepresent the likelihood of correctness for subsequent decision-making.\nExisting dense binary classification models are prone to being over-confident.\nTo improve model calibration, we propose Adaptive Stochastic Label Perturbation\n(ASLP) which learns a unique label perturbation level for each training image.\nASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss,\nwhich unifies label perturbation processes including stochastic approaches\n(like DisturbLabel), and label smoothing, to correct calibration while\nmaintaining classification rates. ASLP follows Maximum Entropy Inference of\nclassic statistical mechanics to maximise prediction entropy with respect to\nmissing information. It performs this while: (1) preserving classification\naccuracy on known data as a conservative solution, or (2) specifically improves\nmodel calibration degree by minimising the gap between the prediction accuracy\nand expected confidence of the target training label. Extensive results\ndemonstrate that ASLP can significantly improve calibration degrees of dense\nbinary classification models on both in-distribution and out-of-distribution\ndata. The code is available on https://github.com/Carlisle-Liu/ASLP.",
          "link": "http://arxiv.org/abs/2307.13539",
          "publishedOn": "2023-08-05T00:48:26.783Z",
          "wordCount": null,
          "title": "Model Calibration in Dense Classification with Adaptive Label Perturbation. (arXiv:2307.13539v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yilun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>",
          "description": "Text-to-image generative models have enabled high-resolution image synthesis\nacross different domains, but require users to specify the content they wish to\ngenerate. In this paper, we consider the inverse problem -- given a collection\nof different images, can we discover the generative concepts that represent\neach image? We present an unsupervised approach to discover generative concepts\nfrom a collection of images, disentangling different art styles in paintings,\nobjects, and lighting from kitchen scenes, and discovering image classes given\nImageNet images. We show how such generative concepts can accurately represent\nthe content of images, be recombined and composed to generate new artistic and\nhybrid images, and be further used as a representation for downstream\nclassification tasks.",
          "link": "http://arxiv.org/abs/2306.05357",
          "publishedOn": "2023-08-05T00:48:26.781Z",
          "wordCount": null,
          "title": "Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models. (arXiv:2306.05357v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.16680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1\">Mingyuan Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jun Huang</a>",
          "description": "Diffusion models and large language models have emerged as leading-edge\ngenerative models and have sparked a revolutionary impact on various aspects of\nhuman life. However, the practical implementation of these models has also\nexposed inherent risks, highlighting their dual nature and raising concerns\nregarding their trustworthiness. Despite the abundance of literature on this\nsubject, a comprehensive survey specifically delving into the intersection of\nlarge-scale generative models and their trustworthiness remains largely absent.\nTo bridge this gap, This paper investigates both the long-standing and emerging\nthreats associated with these models across four fundamental dimensions:\nprivacy, security, fairness, and responsibility. In this way, we construct an\nextensive map outlining the trustworthiness of these models, while also\nproviding practical recommendations and identifying future directions. These\nefforts are crucial for promoting the trustworthy deployment of these models,\nultimately benefiting society as a whole.",
          "link": "http://arxiv.org/abs/2307.16680",
          "publishedOn": "2023-08-05T00:48:26.781Z",
          "wordCount": null,
          "title": "On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey. (arXiv:2307.16680v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.07944",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cheng_H/0/1/0/all/0/1\">Huqiang Cheng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Liao_X/0/1/0/all/0/1\">Xiaofeng Liao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_H/0/1/0/all/0/1\">Huaqing Li</a>",
          "description": "We deal with a general distributed constrained online learning problem with\nprivacy over time-varying networks, where a class of nondecomposable objectives\nare considered. Under this setting, each node only controls a part of the\nglobal decision, and the goal of all nodes is to collaboratively minimize the\nglobal cost over a time horizon $T$ while guarantees the security of the\ntransmitted information. For such problems, we first design a novel generic\nalgorithm framework, named as DPSDA, of differentially private distributed\nonline learning using the Laplace mechanism and the stochastic variants of dual\naveraging method. Note that in the dual updates, all nodes of DPSDA employ the\nnoise-corrupted gradients for more generality. Then, we propose two algorithms,\nnamed as DPSDA-C and DPSDA-PS, under this framework. In DPSDA-C, the nodes\nimplement a circulation-based communication in the primal updates so as to\nalleviate the disagreements over time-varying undirected networks. In addition,\nfor the extension to time-varying directed ones, the nodes implement the\nbroadcast-based push-sum dynamics in DPSDA-PS, which can achieve average\nconsensus over arbitrary directed networks. Theoretical results show that both\nalgorithms attain an expected regret upper bound in $\\mathcal{O}( \\sqrt{T} )$\nwhen the objective function is convex, which matches the best utility\nachievable by cutting-edge algorithms. Finally, numerical experiment results on\nboth synthetic and real-world datasets verify the effectiveness of our\nalgorithms.",
          "link": "http://arxiv.org/abs/2206.07944",
          "publishedOn": "2023-08-05T00:48:26.780Z",
          "wordCount": null,
          "title": "Distributed Online Private Learning of Convex Nondecomposable Objectives. (arXiv:2206.07944v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12130",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chen_S/0/1/0/all/0/1\">Shengyu Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bao_T/0/1/0/all/0/1\">Tianshu Bao</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Givi_P/0/1/0/all/0/1\">Peyman Givi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zheng_C/0/1/0/all/0/1\">Can Zheng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jia_X/0/1/0/all/0/1\">Xiaowei Jia</a>",
          "description": "Simulating turbulence is critical for many societally important applications\nin aerospace engineering, environmental science, the energy industry, and\nbiomedicine. Large eddy simulation (LES) has been widely used as an alternative\nto direct numerical simulation (DNS) for simulating turbulent flows due to its\nreduced computational cost. However, LES is unable to capture all of the scales\nof turbulent transport accurately. Reconstructing DNS from low-resolution LES\nis critical for many scientific and engineering disciplines, but it poses many\nchallenges to existing super-resolution methods due to the spatio-temporal\ncomplexity of turbulent flows. In this work, we propose a new physics-guided\nneural network for reconstructing the sequential DNS from low-resolution LES\ndata. The proposed method leverages the partial differential equation that\nunderlies the flow dynamics in the design of spatio-temporal model\narchitecture. A degradation-based refinement method is also developed to\nenforce physical constraints and further reduce the accumulated reconstruction\nerrors over long periods. The results on two different types of turbulent flow\ndata confirm the superiority of the proposed method in reconstructing the\nhigh-resolution DNS data and preserving the physical characteristics of flow\ntransport.",
          "link": "http://arxiv.org/abs/2304.12130",
          "publishedOn": "2023-08-05T00:48:26.779Z",
          "wordCount": null,
          "title": "Reconstructing Turbulent Flows Using Physics-Aware Spatio-Temporal Dynamics and Test-Time Refinement. (arXiv:2304.12130v2 [physics.flu-dyn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12729",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Darya_A/0/1/0/all/0/1\">Abdollah Masoud Darya</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Fernini_I/0/1/0/all/0/1\">Ilias Fernini</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vellasco_M/0/1/0/all/0/1\">Marley Vellasco</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hussain_A/0/1/0/all/0/1\">Abir Hussain</a>",
          "description": "The field of radio astronomy is witnessing a boom in the amount of data\nproduced per day due to newly commissioned radio telescopes. One of the most\ncrucial problems in this field is the automatic classification of extragalactic\nradio sources based on their morphologies. Most recent contributions in the\nfield of morphological classification of extragalactic radio sources have\nproposed classifiers based on convolutional neural networks. Alternatively,\nthis work proposes gradient boosting machine learning methods accompanied by\nprincipal component analysis as data-efficient alternatives to convolutional\nneural networks. Recent findings have shown the efficacy of gradient boosting\nmethods in outperforming deep learning methods for classification problems with\ntabular data. The gradient boosting methods considered in this work are based\non the XGBoost, LightGBM, and CatBoost implementations. This work also studies\nthe effect of dataset size on classifier performance. A three-class\nclassification problem is considered in this work based on the three main\nFanaroff-Riley classes: class 0, class I, and class II, using radio sources\nfrom the Best-Heckman sample. All three proposed gradient boosting methods\noutperformed a state-of-the-art convolutional neural networks-based classifier\nusing less than a quarter of the number of images, with CatBoost having the\nhighest accuracy. This was mainly due to the superior accuracy of gradient\nboosting methods in classifying Fanaroff-Riley class II sources, with\n3$\\unicode{x2013}$4% higher recall.",
          "link": "http://arxiv.org/abs/2304.12729",
          "publishedOn": "2023-08-05T00:48:26.778Z",
          "wordCount": null,
          "title": "Morphological Classification of Extragalactic Radio Sources Using Gradient Boosting Methods. (arXiv:2304.12729v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tajidini_F/0/1/0/all/0/1\">Farzaneh Tajidini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kheiri_M/0/1/0/all/0/1\">Mohammad-Javad Kheiri</a>",
          "description": "Computer-aided diagnosis (CAD), a vibrant medical imaging research field, is\nexpanding quickly. Because errors in medical diagnostic systems might lead to\nseriously misleading medical treatments, major efforts have been made in recent\nyears to improve computer-aided diagnostics applications. The use of machine\nlearning in computer-aided diagnosis is crucial. A simple equation may result\nin a false indication of items like organs. Therefore, learning from examples\nis a vital component of pattern recognition. Pattern recognition and machine\nlearning in the biomedical area promise to increase the precision of disease\ndetection and diagnosis. They also support the decision-making process's\nobjectivity. Machine learning provides a practical method for creating elegant\nand autonomous algorithms to analyze high-dimensional and multimodal\nbio-medical data. This review article examines machine-learning algorithms for\ndetecting diseases, including hepatitis, diabetes, liver disease, dengue fever,\nand heart disease. It draws attention to the collection of machine learning\ntechniques and algorithms employed in studying conditions and the ensuing\ndecision-making process.",
          "link": "http://arxiv.org/abs/2308.01319",
          "publishedOn": "2023-08-05T00:48:26.777Z",
          "wordCount": null,
          "title": "Recent advancement in Disease Diagnostic using machine learning: Systematic survey of decades, comparisons, and challenges. (arXiv:2308.01319v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.10112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_D/0/1/0/all/0/1\">Di Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_J/0/1/0/all/0/1\">Jingping Bi</a>",
          "description": "Temporal data, representing chronological observations of complex systems,\nhas always been a typical data structure that can be widely generated by many\ndomains, such as industry, medicine and finance. Analyzing this type of data is\nextremely valuable for various applications. Thus, different temporal data\nanalysis tasks, eg, classification, clustering and prediction, have been\nproposed in the past decades. Among them, causal discovery, learning the causal\nrelations from temporal data, is considered an interesting yet critical task\nand has attracted much research attention. Existing causal discovery works can\nbe divided into two highly correlated categories according to whether the\ntemporal data is calibrated, ie, multivariate time series causal discovery, and\nevent sequence causal discovery. However, most previous surveys are only\nfocused on the time series causal discovery and ignore the second category. In\nthis paper, we specify the correlation between the two categories and provide a\nsystematical overview of existing solutions. Furthermore, we provide public\ndatasets, evaluation metrics and new perspectives for temporal data causal\ndiscovery.",
          "link": "http://arxiv.org/abs/2303.10112",
          "publishedOn": "2023-08-05T00:48:26.777Z",
          "wordCount": null,
          "title": "Causal Discovery from Temporal Data: An Overview and New Perspectives. (arXiv:2303.10112v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dvorkin_V/0/1/0/all/0/1\">Vladimir Dvorkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1\">Ferdinando Fioretto</a>",
          "description": "While deep learning gradually penetrates operational planning, its inherent\nprediction errors may significantly affect electricity prices. This letter\nexamines how prediction errors propagate into electricity prices, revealing\nnotable pricing errors and their spatial disparity in congested power systems.\nTo improve fairness, we propose to embed electricity market-clearing\noptimization as a deep learning layer. Differentiating through this layer\nallows for balancing between prediction and pricing errors, as oppose to\nminimizing prediction errors alone. This layer implicitly optimizes fairness\nand controls the spatial distribution of price errors across the system. We\nshowcase the price-aware deep learning in the nexus of wind power forecasting\nand short-term electricity market clearing.",
          "link": "http://arxiv.org/abs/2308.01436",
          "publishedOn": "2023-08-05T00:48:26.759Z",
          "wordCount": null,
          "title": "Price-Aware Deep Learning for Electricity Markets. (arXiv:2308.01436v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.11233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoxing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xiangxiang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yuda Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhexi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>",
          "description": "Albeit being a prevalent architecture searching approach, differentiable\narchitecture search (DARTS) is largely hindered by its substantial memory cost\nsince the entire supernet resides in the memory. This is where the single-path\nDARTS comes in, which only chooses a single-path submodel at each step. While\nbeing memory-friendly, it also comes with low computational costs. Nonetheless,\nwe discover a critical issue of single-path DARTS that has not been primarily\nnoticed. Namely, it also suffers from severe performance collapse since too\nmany parameter-free operations like skip connections are derived, just like\nDARTS does. In this paper, we propose a new algorithm called RObustifying\nMemory-Efficient NAS (ROME) to give a cure. First, we disentangle the topology\nsearch from the operation search to make searching and evaluation consistent.\nWe then adopt Gumbel-Top2 reparameterization and gradient accumulation to\nrobustify the unwieldy bi-level optimization. We verify ROME extensively across\n15 benchmarks to demonstrate its effectiveness and robustness.",
          "link": "http://arxiv.org/abs/2011.11233",
          "publishedOn": "2023-08-05T00:48:26.757Z",
          "wordCount": null,
          "title": "ROME: Robustifying Memory-Efficient NAS via Topology Disentanglement and Gradient Accumulation. (arXiv:2011.11233v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.09048",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Rolle_A/0/1/0/all/0/1\">Alexander Rolle</a>, <a href=\"http://arxiv.org/find/math/1/au:+Scoccola_L/0/1/0/all/0/1\">Luis Scoccola</a>",
          "description": "We consider the degree-Rips construction from topological data analysis,\nwhich provides a density-sensitive, multiparameter hierarchical clustering\nalgorithm. We analyze its stability to perturbations of the input data using\nthe correspondence-interleaving distance, a metric for hierarchical clusterings\nthat we introduce. Taking certain one-parameter slices of degree-Rips recovers\nwell-known methods for density-based clustering, but we show that these methods\nare unstable. However, we prove that degree-Rips, as a multiparameter object,\nis stable, and we propose an alternative approach for taking slices of\ndegree-Rips, which yields a one-parameter hierarchical clustering algorithm\nwith better stability properties. We prove that this algorithm is consistent,\nusing the correspondence-interleaving distance. We provide an algorithm for\nextracting a single clustering from one-parameter hierarchical clusterings,\nwhich is stable with respect to the correspondence-interleaving distance. And,\nwe integrate these methods into a pipeline for density-based clustering, which\nwe call Persistable. Adapting tools from multiparameter persistent homology, we\npropose visualization tools that guide the selection of all parameters of the\npipeline. We demonstrate Persistable on benchmark datasets, showing that it\nidentifies multi-scale cluster structure in data.",
          "link": "http://arxiv.org/abs/2005.09048",
          "publishedOn": "2023-08-05T00:48:26.750Z",
          "wordCount": null,
          "title": "Stable and consistent density-based clustering via multiparameter persistence. (arXiv:2005.09048v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.13619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "As one of the most pervasive applications of machine learning, recommender\nsystems are playing an important role on assisting human decision making. The\nsatisfaction of users and the interests of platforms are closely related to the\nquality of the generated recommendation results. However, as a highly\ndata-driven system, recommender system could be affected by data or algorithmic\nbias and thus generate unfair results, which could weaken the reliance of the\nsystems. As a result, it is crucial to address the potential unfairness\nproblems in recommendation settings. Recently, there has been growing attention\non fairness considerations in recommender systems with more and more literature\non approaches to promote fairness in recommendation. However, the studies are\nrather fragmented and lack a systematic organization, thus making it difficult\nto penetrate for new researchers to the domain. This motivates us to provide a\nsystematic survey of existing works on fairness in recommendation. This survey\nfocuses on the foundations for fairness in recommendation literature. It first\npresents a brief introduction about fairness in basic machine learning tasks\nsuch as classification and ranking in order to provide a general overview of\nfairness research, as well as introduce the more complex situations and\nchallenges that need to be considered when studying fairness in recommender\nsystems. After that, the survey will introduce fairness in recommendation with\na focus on the taxonomies of current fairness definitions, the typical\ntechniques for improving fairness, as well as the datasets for fairness studies\nin recommendation. The survey also talks about the challenges and opportunities\nin fairness research with the hope of promoting the fair recommendation\nresearch area and beyond.",
          "link": "http://arxiv.org/abs/2205.13619",
          "publishedOn": "2023-08-05T00:48:26.750Z",
          "wordCount": null,
          "title": "Fairness in Recommendation: Foundations, Methods and Applications. (arXiv:2205.13619v6 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xiangxu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chuhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianing Chen</a>",
          "description": "Recently, significant advancements have been made in time-series forecasting\nresearch, with an increasing focus on analyzing the nature of time-series data,\ne.g, channel-independence (CI) and channel-dependence (CD), rather than solely\nfocusing on designing sophisticated forecasting models. However, current\nresearch has primarily focused on either CI or CD in isolation, and the\nchallenge of effectively combining these two opposing properties to achieve a\nsynergistic effect remains an unresolved issue. In this paper, we carefully\nexamine the opposing properties of CI and CD, and raise a practical question\nthat has not been effectively answered, e.g.,\"How to effectively mix the CI and\nCD properties of time series to achieve better predictive performance?\" To\nanswer this question, we propose Mlinear (MIX-Linear), a simple yet effective\nmethod based mainly on linear layers. The design philosophy of Mlinear mainly\nincludes two aspects:(1) dynamically tuning the CI and CD properties based on\nthe time semantics of different input time series, and (2) providing deep\nsupervision to adjust the individual performance of the \"CI predictor\" and \"CD\npredictor\". In addition, empirically, we introduce a new loss function that\nsignificantly outperforms the widely used mean squared error (MSE) on multiple\ndatasets. Experiments on time-series datasets covering multiple fields and\nwidely used have demonstrated the superiority of our method over PatchTST which\nis the lateset Transformer-based method in terms of the MSE and MAE metrics on\n7 datasets with identical sequence inputs (336 or 512). Specifically, our\nmethod significantly outperforms PatchTST with a ratio of 21:3 at 336 sequence\nlength input and 29:10 at 512 sequence length input. Additionally, our approach\nhas a 10 $\\times$ efficiency advantage at the unit level, taking into account\nboth training and inference times.",
          "link": "http://arxiv.org/abs/2305.04800",
          "publishedOn": "2023-08-05T00:48:26.747Z",
          "wordCount": null,
          "title": "Mlinear: Rethink the Linear Model for Time-series Forecasting. (arXiv:2305.04800v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01562",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pervej_M/0/1/0/all/0/1\">Md Ferdous Pervej</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_R/0/1/0/all/0/1\">Richeng Jin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dai_H/0/1/0/all/0/1\">Huaiyu Dai</a>",
          "description": "While a practical wireless network has many tiers where end users do not\ndirectly communicate with the central server, the users' devices have limited\ncomputation and battery powers, and the serving base station (BS) has a fixed\nbandwidth. Owing to these practical constraints and system models, this paper\nleverages model pruning and proposes a pruning-enabled hierarchical federated\nlearning (PHFL) in heterogeneous networks (HetNets). We first derive an upper\nbound of the convergence rate that clearly demonstrates the impact of the model\npruning and wireless communications between the clients and the associated BS.\nThen we jointly optimize the model pruning ratio, central processing unit (CPU)\nfrequency and transmission power of the clients in order to minimize the\ncontrollable terms of the convergence bound under strict delay and energy\nconstraints. However, since the original problem is not convex, we perform\nsuccessive convex approximation (SCA) and jointly optimize the parameters for\nthe relaxed convex problem. Through extensive simulation, we validate the\neffectiveness of our proposed PHFL algorithm in terms of test accuracy, wall\nclock time, energy consumption and bandwidth requirement.",
          "link": "http://arxiv.org/abs/2308.01562",
          "publishedOn": "2023-08-05T00:48:26.745Z",
          "wordCount": null,
          "title": "Hierarchical Federated Learning in Wireless Networks: Pruning Tackles Bandwidth Scarcity and System Heterogeneity. (arXiv:2308.01562v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01433",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Romero_N/0/1/0/all/0/1\">Noemi Maritza L. Romero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vasconcellos_R/0/1/0/all/0/1\">Ricco Vasconcellos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mendoza_M/0/1/0/all/0/1\">Mariana R. Mendoza</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Comba_J/0/1/0/all/0/1\">Jo&#xe3;o L. D. Comba</a>",
          "description": "The COVID-19 pandemic presented numerous challenges to healthcare systems\nworldwide. Given that lung infections are prevalent among COVID-19 patients,\nchest Computer Tomography (CT) scans have frequently been utilized as an\nalternative method for identifying COVID-19 conditions and various other types\nof pulmonary diseases. Deep learning architectures have emerged to automate the\nidentification of pulmonary disease types by leveraging CT scan slices as\ninputs for classification models. This paper introduces COVID-VR, a novel\napproach for classifying pulmonary diseases based on volume rendering images of\nthe lungs captured from multiple angles, thereby providing a comprehensive view\nof the entire lung in each image. To assess the effectiveness of our proposal,\nwe compared it against competing strategies utilizing both private data\nobtained from partner hospitals and a publicly available dataset. The results\ndemonstrate that our approach effectively identifies pulmonary lesions and\nperforms competitively when compared to slice-based methods.",
          "link": "http://arxiv.org/abs/2308.01433",
          "publishedOn": "2023-08-05T00:48:26.742Z",
          "wordCount": null,
          "title": "COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography. (arXiv:2308.01433v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaur_V/0/1/0/all/0/1\">Vedant Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saunshi_N/0/1/0/all/0/1\">Nikunj Saunshi</a>",
          "description": "Large language models (LLMs) have revolutionized NLP by solving downstream\ntasks with little to no labeled data. Despite their versatile abilities, the\nlarger question of their ability to reason remains ill-understood. This paper\naddresses reasoning in math word problems (MWPs) by studying symbolic versions\nof the numeric problems, since a symbolic expression is a \"concise explanation\"\nof the numeric answer. We create and use a symbolic version of the SVAMP\ndataset and find that GPT-3's davinci-002 model also has good zero-shot\naccuracy on symbolic MWPs. To evaluate the faithfulness of the model's\nreasoning, we go beyond accuracy and additionally evaluate the alignment\nbetween the final answer and the outputted reasoning, which correspond to\nnumeric and symbolic answers respectively for MWPs. We explore a self-prompting\napproach to encourage the symbolic reasoning to align with the numeric answer,\nthus equipping the LLM with the ability to provide a concise and verifiable\nreasoning and making it more interpretable. Surprisingly, self-prompting also\nimproves the symbolic accuracy to be higher than both the numeric and symbolic\naccuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be\nreleased for future research on symbolic math problems.",
          "link": "http://arxiv.org/abs/2308.01906",
          "publishedOn": "2023-08-05T00:48:26.741Z",
          "wordCount": null,
          "title": "Reasoning in Large Language Models Through Symbolic Math Word Problems. (arXiv:2308.01906v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenhao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yulong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Run Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Liming Fang</a>",
          "description": "Adversarial training (AT) is widely considered the state-of-the-art technique\nfor improving the robustness of deep neural networks (DNNs) against adversarial\nexamples (AE). Nevertheless, recent studies have revealed that adversarially\ntrained models are prone to unfairness problems, restricting their\napplicability. In this paper, we empirically observe that this limitation may\nbe attributed to serious adversarial confidence overfitting, i.e., certain\nadversarial examples with overconfidence. To alleviate this problem, we propose\nHAM, a straightforward yet effective framework via adaptive Hard Adversarial\nexample Mining.HAM concentrates on mining hard adversarial examples while\ndiscarding the easy ones in an adaptive fashion. Specifically, HAM identifies\nhard AEs in terms of their step sizes needed to cross the decision boundary\nwhen calculating loss value. Besides, an early-dropping mechanism is\nincorporated to discard the easy examples at the initial stages of AE\ngeneration, resulting in efficient AT. Extensive experimental results on\nCIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant\nimprovement in robust fairness while reducing computational cost compared to\nseveral state-of-the-art adversarial training methods. The code will be made\npublicly available.",
          "link": "http://arxiv.org/abs/2308.01823",
          "publishedOn": "2023-08-05T00:48:26.740Z",
          "wordCount": null,
          "title": "Hard Adversarial Example Mining for Improving Robust Fairness. (arXiv:2308.01823v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhewei Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aminabadi_R/0/1/0/all/0/1\">Reza Yazdani Aminabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruwase_O/0/1/0/all/0/1\">Olatunji Ruwase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajbhandari_S/0/1/0/all/0/1\">Samyam Rajbhandari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awan_A/0/1/0/all/0/1\">Ammar Ahmad Awan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasley_J/0/1/0/all/0/1\">Jeff Rasley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Conglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1\">Connor Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhongzhu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyatt_M/0/1/0/all/0/1\">Michael Wyatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Molly Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurilenko_L/0/1/0/all/0/1\">Lev Kurilenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1\">Heyang Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_M/0/1/0/all/0/1\">Masahiro Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_S/0/1/0/all/0/1\">Shuai Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuaiwen Leon Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>",
          "description": "ChatGPT-like models have revolutionized various applications in artificial\nintelligence, from summarization and coding to translation, matching or even\nsurpassing human performance. However, the current landscape lacks an\naccessible, efficient, and cost-effective end-to-end RLHF (Reinforcement\nLearning with Human Feedback) training pipeline for these powerful models,\nparticularly when training at the scale of billions of parameters. This paper\nintroduces DeepSpeed-Chat, a novel system that democratizes RLHF training,\nmaking it accessible to the AI community. DeepSpeed-Chat offers three key\ncapabilities: an easy-to-use training and inference experience for ChatGPT-like\nmodels, a DeepSpeed-RLHF pipeline that replicates the training pipeline from\nInstructGPT, and a robust DeepSpeed-RLHF system that combines various\noptimizations for training and inference in a unified way. The system delivers\nunparalleled efficiency and scalability, enabling training of models with\nhundreds of billions of parameters in record time and at a fraction of the\ncost. With this development, DeepSpeed-Chat paves the way for broader access to\nadvanced RLHF training, even for data scientists with limited resources,\nthereby fostering innovation and further development in the field of AI.",
          "link": "http://arxiv.org/abs/2308.01320",
          "publishedOn": "2023-08-05T00:48:26.738Z",
          "wordCount": null,
          "title": "DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales. (arXiv:2308.01320v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shokrollahi1_Y/0/1/0/all/0/1\">Yasin Shokrollahi1</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong1_P/0/1/0/all/0/1\">Pengfei Dong1</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1\">Linxia Gu</a>",
          "description": "This study investigated the potential of end-to-end deep learning tools as a\nmore effective substitute for FEM in predicting stress-strain fields within 2D\ncross sections of arterial wall. We first proposed a U-Net based fully\nconvolutional neural network (CNN) to predict the von Mises stress and strain\ndistribution based on the spatial arrangement of calcification within arterial\nwall cross-sections. Further, we developed a conditional generative adversarial\nnetwork (cGAN) to enhance, particularly from the perceptual perspective, the\nprediction accuracy of stress and strain field maps for arterial walls with\nvarious calcification quantities and spatial configurations. On top of U-Net\nand cGAN, we also proposed their ensemble approaches, respectively, to further\nimprove the prediction accuracy of field maps. Our dataset, consisting of input\nand output images, was generated by implementing boundary conditions and\nextracting stress-strain field maps. The trained U-Net models can accurately\npredict von Mises stress and strain fields, with structural similarity index\nscores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for\nstress and strain, respectively, on a reserved test set. Meanwhile, the cGAN\nmodels in a combination of ensemble and transfer learning techniques\ndemonstrate high accuracy in predicting von Mises stress and strain fields, as\nevidenced by SSIM scores of 0.890 for stress and 0.803 for strain.\nAdditionally, mean squared errors of 0.008 for stress and 0.017 for strain\nfurther support the model's performance on a designated test set. Overall, this\nstudy developed a surrogate model for finite element analysis, which can\naccurately and efficiently predict stress-strain fields of arterial walls\nregardless of complex geometries and boundary conditions.",
          "link": "http://arxiv.org/abs/2308.01771",
          "publishedOn": "2023-08-05T00:48:26.734Z",
          "wordCount": null,
          "title": "Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment. (arXiv:2308.01771v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.02144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1\">Pablo Barcel&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duarte_M/0/1/0/all/0/1\">Mauricio Duarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rojas_C/0/1/0/all/0/1\">Crist&#xf3;bal Rojas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steifer_T/0/1/0/all/0/1\">Tomasz Steifer</a>",
          "description": "In peer review systems, reviewers are often asked to evaluate various\nfeatures of submissions, such as technical quality or novelty. A score is given\nto each of the predefined features and based on these the reviewer has to\nprovide an overall quantitative recommendation. It may be assumed that each\nreviewer has her own mapping from the set of features to a recommendation, and\nthat different reviewers have different mappings in mind. This introduces an\nelement of arbitrariness known as commensuration bias. In this paper we discuss\na framework, introduced by Noothigattu, Shah and Procaccia, and then applied by\nthe organizers of the AAAI 2022 conference. Noothigattu, Shah and Procaccia\nproposed to aggregate reviewer's mapping by minimizing certain loss functions,\nand studied axiomatic properties of this approach, in the sense of social\nchoice theory. We challenge several of the results and assumptions used in\ntheir work and report a number of negative results. On the one hand, we study a\ntrade-off between some of the axioms proposed and the ability of the method to\nproperly capture agreements of the majority of reviewers. On the other hand, we\nshow that dropping a certain unrealistic assumption has dramatic effects,\nincluding causing the method to be discontinuous.",
          "link": "http://arxiv.org/abs/2211.02144",
          "publishedOn": "2023-08-05T00:48:26.733Z",
          "wordCount": null,
          "title": "No Agreement Without Loss: Learning and Social Choice in Peer Review. (arXiv:2211.02144v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianning Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junda Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaofeng Zhang</a>",
          "description": "At the beginning era of large language model, it is quite critical to\ngenerate a high-quality financial dataset to fine-tune a large language model\nfor financial related tasks. Thus, this paper presents a carefully designed\ndata creation pipeline for this purpose. Particularly, we initiate a dialogue\nbetween an AI investor and financial expert using ChatGPT and incorporate the\nfeedback of human financial experts, leading to the refinement of the dataset.\nThis pipeline yielded a robust instruction tuning dataset comprised of 103k\nmulti-turn chats. Extensive experiments have been conducted on this dataset to\nevaluate the model's performance by adopting an external GPT-4 as the judge.\nThe promising experimental results verify that our approach led to significant\nadvancements in generating accurate, relevant, and financial-style responses\nfrom AI models, and thus providing a powerful tool for applications within the\nfinancial sector.",
          "link": "http://arxiv.org/abs/2308.01415",
          "publishedOn": "2023-08-05T00:48:26.732Z",
          "wordCount": null,
          "title": "An Effective Data Creation Pipeline to Generate High-quality Financial Instruction Data for Large Language Model. (arXiv:2308.01415v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1\">Lu Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaoshuang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Heng Tao Shen</a>",
          "description": "The presence of label noise in the training data has a profound impact on the\ngeneralization of deep neural networks (DNNs). In this study, we introduce and\ntheoretically demonstrate a simple feature noise method, which directly adds\nnoise to the features of training data, can enhance the generalization of DNNs\nunder label noise. Specifically, we conduct theoretical analyses to reveal that\nlabel noise leads to weakened DNN generalization by loosening the PAC-Bayes\ngeneralization bound, and feature noise results in better DNN generalization by\nimposing an upper bound on the mutual information between the model weights and\nthe features, which constrains the PAC-Bayes generalization bound. Furthermore,\nto ensure effective generalization of DNNs in the presence of label noise, we\nconduct application analyses to identify the optimal types and levels of\nfeature noise to add for obtaining desirable label noise generalization.\nFinally, extensive experimental results on several popular datasets demonstrate\nthe feature noise method can significantly enhance the label noise\ngeneralization of the state-of-the-art label noise method.",
          "link": "http://arxiv.org/abs/2308.01609",
          "publishedOn": "2023-08-05T00:48:26.731Z",
          "wordCount": null,
          "title": "Feature Noise Boosts DNN Generalization under Label Noise. (arXiv:2308.01609v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Ke Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yusong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haohe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nezhurina_M/0/1/0/all/0/1\">Marianna Nezhurina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubnov_S/0/1/0/all/0/1\">Shlomo Dubnov</a>",
          "description": "Diffusion models have shown promising results in cross-modal generation\ntasks, including text-to-image and text-to-audio generation. However,\ngenerating music, as a special type of audio, presents unique challenges due to\nlimited availability of music data and sensitive issues related to copyright\nand plagiarism. In this paper, to tackle these challenges, we first construct a\nstate-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion\nand AudioLDM architectures to the music domain. We achieve this by retraining\nthe contrastive language-audio pretraining model (CLAP) and the Hifi-GAN\nvocoder, as components of MusicLDM, on a collection of music data samples.\nThen, to address the limitations of training data and to avoid plagiarism, we\nleverage a beat tracking model and propose two different mixup strategies for\ndata augmentation: beat-synchronous audio mixup and beat-synchronous latent\nmixup, which recombine training audio directly or via a latent embeddings\nspace, respectively. Such mixup strategies encourage the model to interpolate\nbetween musical training samples and generate new music within the convex hull\nof the training data, making the generated music more diverse while still\nstaying faithful to the corresponding style. In addition to popular evaluation\nmetrics, we design several new evaluation metrics based on CLAP score to\ndemonstrate that our proposed MusicLDM and beat-synchronous mixup strategies\nimprove both the quality and novelty of generated music, as well as the\ncorrespondence between input text and generated music.",
          "link": "http://arxiv.org/abs/2308.01546",
          "publishedOn": "2023-08-05T00:48:26.725Z",
          "wordCount": null,
          "title": "MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies. (arXiv:2308.01546v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Badrinath_C/0/1/0/all/0/1\">Charumathi Badrinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Weiwei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "A common way to explore text corpora is through low-dimensional projections\nof the documents, where one hopes that thematically similar documents will be\nclustered together in the projected space. However, popular algorithms for\ndimensionality reduction of text corpora, like Latent Dirichlet Allocation\n(LDA), often produce projections that do not capture human notions of document\nsimilarity. We propose a semi-supervised human-in-the-loop LDA-based method for\nlearning topics that preserve semantically meaningful relationships between\ndocuments in low-dimensional projections. On synthetic corpora, our method\nyields more interpretable projections than baseline methods with only a\nfraction of labels provided. On a real corpus, we obtain qualitatively similar\nresults.",
          "link": "http://arxiv.org/abs/2308.01420",
          "publishedOn": "2023-08-05T00:48:26.716Z",
          "wordCount": null,
          "title": "SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text. (arXiv:2308.01420v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xinglong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponce_J/0/1/0/all/0/1\">Jean Ponce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiong Wang</a>",
          "description": "Depth completion, which aims to generate high-quality dense depth maps from\nsparse depth maps, has attracted increasing attention in recent years. Previous\nwork usually employs RGB images as guidance, and introduces iterative spatial\npropagation to refine estimated coarse depth maps. However, most of the\npropagation refinement methods require several iterations and suffer from a\nfixed receptive field, which may contain irrelevant and useless information\nwith very sparse input. In this paper, we address these two challenges\nsimultaneously by revisiting the idea of deformable convolution. We propose an\neffective architecture that leverages deformable kernel convolution as a\nsingle-pass refinement module, and empirically demonstrate its superiority. To\nbetter understand the function of deformable convolution and exploit it for\ndepth completion, we further systematically investigate a variety of\nrepresentative strategies. Our study reveals that, different from prior work,\ndeformable convolution needs to be applied on an estimated depth map with a\nrelatively high density for better performance. We evaluate our model on the\nlarge-scale KITTI dataset and achieve state-of-the-art level performance in\nboth accuracy and inference speed. Our code is available at\nhttps://github.com/AlexSunNik/ReDC.",
          "link": "http://arxiv.org/abs/2308.01905",
          "publishedOn": "2023-08-05T00:48:26.712Z",
          "wordCount": null,
          "title": "Revisiting Deformable Convolution for Depth Completion. (arXiv:2308.01905v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.10276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1\">Ruixuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yiwen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Runze Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>",
          "description": "Learning with Noisy Labels (LNL) has become an appealing topic, as\nimperfectly annotated data are relatively cheaper to obtain. Recent\nstate-of-the-art approaches employ specific selection mechanisms to separate\nclean and noisy samples and then apply Semi-Supervised Learning (SSL)\ntechniques for improved performance. However, the selection step mostly\nprovides a medium-sized and decent-enough clean subset, which overlooks a rich\nset of clean samples. To fulfill this, we propose a novel LNL framework ProMix\nthat attempts to maximize the utility of clean samples for boosted performance.\nKey to our method, we propose a matched high confidence selection technique\nthat selects those examples with high confidence scores and matched predictions\nwith given labels to dynamically expand a base clean sample set. To overcome\nthe potential side effect of excessive clean set selection procedure, we\nfurther devise a novel SSL framework that is able to train balanced and\nunbiased classifiers on the separated clean and noisy samples. Extensive\nexperiments demonstrate that ProMix significantly advances the current\nstate-of-the-art results on multiple benchmarks with different types and levels\nof noise. It achieves an average improvement of 2.48\\% on the CIFAR-N dataset.\nThe code is available at https://github.com/Justherozen/ProMix",
          "link": "http://arxiv.org/abs/2207.10276",
          "publishedOn": "2023-08-05T00:48:26.711Z",
          "wordCount": null,
          "title": "ProMix: Combating Label Noise via Maximizing Clean Sample Utility. (arXiv:2207.10276v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borile_C/0/1/0/all/0/1\">Claudio Borile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perotti_A/0/1/0/all/0/1\">Alan Perotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panisson_A/0/1/0/all/0/1\">Andr&#xe9; Panisson</a>",
          "description": "Graph Machine Learning (GML) has numerous applications, such as node/graph\nclassification and link prediction, in real-world domains. Providing\nhuman-understandable explanations for GML models is a challenging yet\nfundamental task to foster their adoption, but validating explanations for link\nprediction models has received little attention. In this paper, we provide\nquantitative metrics to assess the quality of link prediction explanations,\nwith or without ground-truth. State-of-the-art explainability methods for Graph\nNeural Networks are evaluated using these metrics. We discuss how underlying\nassumptions and technical details specific to the link prediction task, such as\nthe choice of distance between node embeddings, can influence the quality of\nthe explanations.",
          "link": "http://arxiv.org/abs/2308.01682",
          "publishedOn": "2023-08-05T00:48:26.710Z",
          "wordCount": null,
          "title": "Evaluating Link Prediction Explanations for Graph Neural Networks. (arXiv:2308.01682v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1\">Minh Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marshall_K/0/1/0/all/0/1\">Kelly O. Marshall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1\">Chinmay Hegde</a>",
          "description": "Text-to-image generative models can produce photo-realistic images for an\nextremely broad range of concepts, and their usage has proliferated widely\namong the general public. On the flip side, these models have numerous\ndrawbacks, including their potential to generate images featuring sexually\nexplicit content, mirror artistic styles without permission, or even\nhallucinate (or deepfake) the likenesses of celebrities. Consequently, various\nmethods have been proposed in order to \"erase\" sensitive concepts from\ntext-to-image models. In this work, we examine five recently proposed concept\nerasure methods, and show that targeted concepts are not fully excised from any\nof these methods. Specifically, we leverage the existence of special learned\nword embeddings that can retrieve \"erased\" concepts from the sanitized models\nwith no alterations to their weights. Our results highlight the brittleness of\npost hoc concept erasure methods, and call into question their use in the\nalgorithmic toolkit for AI safety.",
          "link": "http://arxiv.org/abs/2308.01508",
          "publishedOn": "2023-08-05T00:48:26.704Z",
          "wordCount": null,
          "title": "Circumventing Concept Erasure Methods For Text-to-Image Generative Models. (arXiv:2308.01508v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sakhi_O/0/1/0/all/0/1\">Otmane Sakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohde_D/0/1/0/all/0/1\">David Rohde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chopin_N/0/1/0/all/0/1\">Nicolas Chopin</a>",
          "description": "An increasingly important building block of large scale machine learning\nsystems is based on returning slates; an ordered lists of items given a query.\nApplications of this technology include: search, information retrieval and\nrecommender systems. When the action space is large, decision systems are\nrestricted to a particular structure to complete online queries quickly. This\npaper addresses the optimization of these large scale decision systems given an\narbitrary reward function. We cast this learning problem in a policy\noptimization framework and propose a new class of policies, born from a novel\nrelaxation of decision functions. This results in a simple, yet efficient\nlearning algorithm that scales to massive action spaces. We compare our method\nto the commonly adopted Plackett-Luce policy class and demonstrate the\neffectiveness of our approach on problems with action space sizes in the order\nof millions.",
          "link": "http://arxiv.org/abs/2308.01566",
          "publishedOn": "2023-08-05T00:48:26.703Z",
          "wordCount": null,
          "title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce. (arXiv:2308.01566v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagner_L/0/1/0/all/0/1\">Laurin Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zusag_M/0/1/0/all/0/1\">Mario Zusag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bloder_T/0/1/0/all/0/1\">Theresa Bloder</a>",
          "description": "This paper presents a fully automated approach for identifying speech\nanomalies from voice recordings to aid in the assessment of speech impairments.\nBy combining Connectionist Temporal Classification (CTC) and\nencoder-decoder-based automatic speech recognition models, we generate rich\nacoustic and clean transcripts. We then apply several natural language\nprocessing methods to extract features from these transcripts to produce\nprototypes of healthy speech. Basic distance measures from these prototypes\nserve as input features for standard machine learning classifiers, yielding\nhuman-level accuracy for the distinction between recordings of people with\naphasia and a healthy control group. Furthermore, the most frequently occurring\naphasia types can be distinguished with 90% accuracy. The pipeline is directly\napplicable to other diseases and languages, showing promise for robustly\nextracting diagnostic speech biomarkers.",
          "link": "http://arxiv.org/abs/2308.01327",
          "publishedOn": "2023-08-05T00:48:26.701Z",
          "wordCount": null,
          "title": "Careful Whisper -- leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification. (arXiv:2308.01327v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_M/0/1/0/all/0/1\">Minhao Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhongxue Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yutong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_D/0/1/0/all/0/1\">Dongyan Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1\">Chun Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1\">Siyang Leng</a>",
          "description": "Graph and hypergraph representation learning has attracted increasing\nattention from various research fields. Despite the decent performance and\nfruitful applications of Graph Neural Networks (GNNs), Hypergraph Neural\nNetworks (HGNNs), and their well-designed variants, on some commonly used\nbenchmark graphs and hypergraphs, they are outperformed by even a simple\nMulti-Layer Perceptron. This observation motivates a reexamination of the\ndesign paradigm of the current GNNs and HGNNs and poses challenges of\nextracting graph features effectively. In this work, a universal feature\nencoder for both graph and hypergraph representation learning is designed,\ncalled UniG-Encoder. The architecture starts with a forward transformation of\nthe topological relationships of connected nodes into edge or hyperedge\nfeatures via a normalized projection matrix. The resulting edge/hyperedge\nfeatures, together with the original node features, are fed into a neural\nnetwork. The encoded node embeddings are then derived from the reversed\ntransformation, described by the transpose of the projection matrix, of the\nnetwork's output, which can be further used for tasks such as node\nclassification. The proposed architecture, in contrast to the traditional\nspectral-based and/or message passing approaches, simultaneously and\ncomprehensively exploits the node features and graph/hypergraph topologies in\nan efficient and unified manner, covering both heterophilic and homophilic\ngraphs. The designed projection matrix, encoding the graph features, is\nintuitive and interpretable. Extensive experiments are conducted and\ndemonstrate the superior performance of the proposed framework on twelve\nrepresentative hypergraph datasets and six real-world graph datasets, compared\nto the state-of-the-art methods. Our implementation is available online at\nhttps://github.com/MinhZou/UniG-Encoder.",
          "link": "http://arxiv.org/abs/2308.01650",
          "publishedOn": "2023-08-05T00:48:26.695Z",
          "wordCount": null,
          "title": "UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node Classification. (arXiv:2308.01650v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.11435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yuwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochiai_H/0/1/0/all/0/1\">Hideya Ochiai</a>",
          "description": "Visual Question Answering (VQA) based on multi-modal data facilitates\nreal-life applications such as home robots and medical diagnoses. One\nsignificant challenge is to devise a robust decentralized learning framework\nfor various client models where centralized data collection is refrained due to\nconfidentiality concerns. This work aims to tackle privacy-preserving VQA by\ndecoupling a multi-modal model into representation modules and a contrastive\nmodule and leveraging inter-module gradients sharing and inter-client weight\nsharing. To this end, we propose Bidirectional Contrastive Split Learning\n(BiCSL) to train a global multi-modal model on the entire data distribution of\ndecentralized clients. We employ the contrastive loss that enables a more\nefficient self-supervised learning of decentralized modules. Comprehensive\nexperiments are conducted on the VQA-v2 dataset based on five SOTA VQA models,\ndemonstrating the effectiveness of the proposed method. Furthermore, we inspect\nBiCSL's robustness against a dual-key backdoor attack on VQA. Consequently,\nBiCSL shows much better robustness to the multi-modal adversarial attack\ncompared to the centralized learning method, which provides a promising\napproach to decentralized multi-modal learning.",
          "link": "http://arxiv.org/abs/2208.11435",
          "publishedOn": "2023-08-05T00:48:26.687Z",
          "wordCount": null,
          "title": "Bidirectional Contrastive Split Learning for Visual Question Answering. (arXiv:2208.11435v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhaumik_D/0/1/0/all/0/1\">Debosmita Bhaumik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannakakis_G/0/1/0/all/0/1\">Georgios N. Yannakakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1\">Ahmed Khalifa</a>",
          "description": "We explore AI-powered upscaling as a design assistance tool in the context of\ncreating 2D game levels. Deep neural networks are used to upscale artificially\ndownscaled patches of levels from the puzzle platformer game Lode Runner. The\ntrained networks are incorporated into a web-based editor, where the user can\ncreate and edit levels at three different levels of resolution: 4x4, 8x8, and\n16x16. An edit at any resolution instantly transfers to the other resolutions.\nAs upscaling requires inventing features that might not be present at lower\nresolutions, we train neural networks to reproduce these features. We introduce\na neural network architecture that is capable of not only learning upscaling\nbut also giving higher priority to less frequent tiles. To investigate the\npotential of this tool and guide further development, we conduct a qualitative\nstudy with 3 designers to understand how they use it. Designers enjoyed\nco-designing with the tool, liked its underlying concept, and provided feedback\nfor further improvement.",
          "link": "http://arxiv.org/abs/2308.01543",
          "publishedOn": "2023-08-05T00:48:26.686Z",
          "wordCount": null,
          "title": "Lode Enhancer: Level Co-creation Through Scaling. (arXiv:2308.01543v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Motogna_A/0/1/0/all/0/1\">Alexandru Motogna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groza_A/0/1/0/all/0/1\">Adrian Groza</a>",
          "description": "An attractive book cover is important for the success of a book. In this\npaper, we apply Generative Adversarial Networks (GANs) to the book covers\ndomain, using different methods for training in order to obtain better\ngenerated images. We interleave GANs with knowledge graphs to alter the input\ntitle to obtain multiple possible options for any given title, which are then\nused as an augmented input to the generator. Finally, we use the discriminator\nobtained during the training phase to select the best images generated with new\ntitles. Our method performed better at generating book covers than previous\nattempts, and the knowledge graph gives better options to the book author or\neditor compared to using GANs alone.",
          "link": "http://arxiv.org/abs/2308.01626",
          "publishedOn": "2023-08-05T00:48:26.682Z",
          "wordCount": null,
          "title": "Interleaving GANs with knowledge graphs to support design creativity for book covers. (arXiv:2308.01626v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yuzhe Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Binghao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyk_K/0/1/0/all/0/1\">Karl Van Wyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_Y/0/1/0/all/0/1\">Yu-Wei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1\">Dieter Fox</a>",
          "description": "Vision-based teleoperation offers the possibility to endow robots with\nhuman-level intelligence to physically interact with the environment, while\nonly requiring low-cost camera sensors. However, current vision-based\nteleoperation systems are designed and engineered towards a particular robot\nmodel and deploy environment, which scales poorly as the pool of the robot\nmodels expands and the variety of the operating environment increases. In this\npaper, we propose AnyTeleop, a unified and general teleoperation system to\nsupport multiple different arms, hands, realities, and camera configurations\nwithin a single system. Although being designed to provide great flexibility to\nthe choice of simulators and real hardware, our system can still achieve great\nperformance. For real-world experiments, AnyTeleop can outperform a previous\nsystem that was designed for a specific robot hardware with a higher success\nrate, using the same robot. For teleoperation in simulation, AnyTeleop leads to\nbetter imitation learning performance, compared with a previous system that is\nparticularly designed for that simulator. Project page: this http URL",
          "link": "http://arxiv.org/abs/2307.04577",
          "publishedOn": "2023-08-05T00:48:26.680Z",
          "wordCount": null,
          "title": "AnyTeleop: A General Vision-Based Dexterous Robot Arm-Hand Teleoperation System. (arXiv:2307.04577v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1\">Chin-Chia Michael Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yujie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huiyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>",
          "description": "Embedding learning transforms discrete data entities into continuous\nnumerical representations, encoding features/properties of the entities.\nDespite the outstanding performance reported from different embedding learning\nalgorithms, few efforts were devoted to structurally interpreting how features\nare encoded in the learned embedding space. This work proposes EmbeddingTree, a\nhierarchical embedding exploration algorithm that relates the semantics of\nentity features with the less-interpretable embedding vectors. An interactive\nvisualization tool is also developed based on EmbeddingTree to explore\nhigh-dimensional embeddings. The tool helps users discover nuance features of\ndata entities, perform feature denoising/injecting in embedding training, and\ngenerate embeddings for unseen entities. We demonstrate the efficacy of\nEmbeddingTree and our visualization tool through embeddings generated for\nindustry-scale merchant data and the public 30Music listening/playlists\ndataset.",
          "link": "http://arxiv.org/abs/2308.01329",
          "publishedOn": "2023-08-05T00:48:26.679Z",
          "wordCount": null,
          "title": "EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding. (arXiv:2308.01329v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chao_P/0/1/0/all/0/1\">Patrick Chao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Distribution shifts are a serious concern in modern statistical learning as\nthey can systematically change the properties of the data away from the truth.\nWe focus on Wasserstein distribution shifts, where every data point may undergo\na slight perturbation, as opposed to the Huber contamination model where a\nfraction of observations are outliers. We formulate and study shifts beyond\nindependent perturbations, exploring Joint Distribution Shifts, where the\nper-observation perturbations can be coordinated. We analyze several important\nstatistical problems, including location estimation, linear regression, and\nnon-parametric density estimation. Under a squared loss for mean estimation and\nprediction error in linear regression, we find the exact minimax risk, a least\nfavorable perturbation, and show that the sample mean and least squares\nestimators are respectively optimal. This holds for both independent and joint\nshifts, but the least favorable perturbations and minimax risks differ. For\nother problems, we provide nearly optimal estimators and precise finite-sample\nbounds. We also introduce several tools for bounding the minimax risk under\ndistribution shift, such as a smoothing technique for location families, and\ngeneralizations of classical tools including least favorable sequences of\npriors, the modulus of continuity, Le Cam's, Fano's, and Assouad's methods.",
          "link": "http://arxiv.org/abs/2308.01853",
          "publishedOn": "2023-08-05T00:48:26.678Z",
          "wordCount": null,
          "title": "Statistical Estimation Under Distribution Shift: Wasserstein Perturbations and Minimax Theory. (arXiv:2308.01853v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.08904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1\">Maurice Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaojun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlas_B/0/1/0/all/0/1\">Bojan Karla&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Recent studies have shown that deep neural networks (DNNs) are vulnerable to\nadversarial attacks, including evasion and backdoor (poisoning) attacks. On the\ndefense side, there have been intensive efforts on improving both empirical and\nprovable robustness against evasion attacks; however, the provable robustness\nagainst backdoor attacks still remains largely unexplored. In this paper, we\nfocus on certifying the machine learning model robustness against general\nthreat models, especially backdoor attacks. We first provide a unified\nframework via randomized smoothing techniques and show how it can be\ninstantiated to certify the robustness against both evasion and backdoor\nattacks. We then propose the first robust training process, RAB, to smooth the\ntrained model and certify its robustness against backdoor attacks. We prove the\nrobustness bound for machine learning models trained with RAB and prove that\nour robustness bound is tight. In addition, we theoretically show that it is\npossible to train the robust smoothed models efficiently for simple models such\nas K-nearest neighbor classifiers, and we propose an exact smooth-training\nalgorithm that eliminates the need to sample from a noise distribution for such\nmodels. Empirically, we conduct comprehensive experiments for different machine\nlearning (ML) models such as DNNs, support vector machines, and K-NN models on\nMNIST, CIFAR-10, and ImageNette datasets and provide the first benchmark for\ncertified robustness against backdoor attacks. In addition, we evaluate K-NN\nmodels on a spambase tabular dataset to demonstrate the advantages of the\nproposed exact algorithm. Both the theoretic analysis and the comprehensive\nevaluation on diverse ML models and datasets shed light on further robust\nlearning strategies against general training time attacks.",
          "link": "http://arxiv.org/abs/2003.08904",
          "publishedOn": "2023-08-05T00:48:26.677Z",
          "wordCount": null,
          "title": "RAB: Provable Robustness Against Backdoor Attacks. (arXiv:2003.08904v8 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1\">Hang Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1\">Bing Bai</a>",
          "description": "This paper introduces a new Convolutional Neural Network (ConvNet)\narchitecture inspired by a class of partial differential equations (PDEs)\ncalled quasi-linear hyperbolic systems. With comparable performance on image\nclassification task, it allows for the modification of the weights via a\ncontinuous group of symmetry. This is a significant shift from traditional\nmodels where the architecture and weights are essentially fixed. We wish to\npromote the (internal) symmetry as a new desirable property for a neural\nnetwork, and to draw attention to the PDE perspective in analyzing and\ninterpreting ConvNets in the broader Deep Learning community.",
          "link": "http://arxiv.org/abs/2308.01621",
          "publishedOn": "2023-08-05T00:48:26.672Z",
          "wordCount": null,
          "title": "A Novel Convolutional Neural Network Architecture with a Continuous Symmetry. (arXiv:2308.01621v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cindy Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "In recent years, multiple notions of algorithmic fairness have arisen. One\nsuch notion is individual fairness (IF), which requires that individuals who\nare similar receive similar treatment. In parallel, matrix estimation (ME) has\nemerged as a natural paradigm for handling noisy data with missing values. In\nthis work, we connect the two concepts. We show that pre-processing data using\nME can improve an algorithm's IF without sacrificing performance. Specifically,\nwe show that using a popular ME method known as singular value thresholding\n(SVT) to pre-process the data provides a strong IF guarantee under appropriate\nconditions. We then show that, under analogous conditions, SVT pre-processing\nalso yields estimates that are consistent and approximately minimax optimal. As\nsuch, the ME pre-processing step does not, under the stated conditions,\nincrease the prediction error of the base algorithm, i.e., does not impose a\nfairness-performance trade-off. We verify these results on synthetic and real\ndata.",
          "link": "http://arxiv.org/abs/2302.02096",
          "publishedOn": "2023-08-05T00:48:26.667Z",
          "wordCount": null,
          "title": "Matrix Estimation for Individual Fairness. (arXiv:2302.02096v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jialiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhiyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaodong Shi</a>",
          "description": "Preprints play an increasingly critical role in academic communities. There\nare many reasons driving researchers to post their manuscripts to preprint\nservers before formal submission to journals or conferences, but the use of\npreprints has also sparked considerable controversy, especially surrounding the\nclaim of priority. In this paper, a case study of computer science preprints\nsubmitted to arXiv from 2008 to 2017 is conducted to quantify how many\npreprints have eventually been printed in peer-reviewed venues. Among those\npublished manuscripts, some are published under different titles and without an\nupdate to their preprints on arXiv. In the case of these manuscripts, the\ntraditional fuzzy matching method is incapable of mapping the preprint to the\nfinal published version. In view of this issue, we introduce a semantics-based\nmapping method with the employment of Bidirectional Encoder Representations\nfrom Transformers (BERT). With this new mapping method and a plurality of data\nsources, we find that 66% of all sampled preprints are published under\nunchanged titles and 11% are published under different titles and with other\nmodifications. A further analysis was then performed to investigate why these\npreprints but not others were accepted for publication. Our comparison reveals\nthat in the field of computer science, published preprints feature adequate\nrevisions, multiple authorship, detailed abstract and introduction, extensive\nand authoritative references and available source code.",
          "link": "http://arxiv.org/abs/2308.01899",
          "publishedOn": "2023-08-05T00:48:26.666Z",
          "wordCount": null,
          "title": "How many preprints have actually been printed and why: a case study of computer science preprints on arXiv. (arXiv:2308.01899v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Greg Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Littwin_E/0/1/0/all/0/1\">Etai Littwin</a>",
          "description": "Going beyond stochastic gradient descent (SGD), what new phenomena emerge in\nwide neural networks trained by adaptive optimizers like Adam? Here we show:\nThe same dichotomy between feature learning and kernel behaviors (as in SGD)\nholds for general optimizers as well, including Adam -- albeit with a nonlinear\nnotion of \"kernel.\" We derive the corresponding \"neural tangent\" and \"maximal\nupdate\" limits for any architecture. Two foundational advances underlie the\nabove results: 1) A new Tensor Program language, NEXORT, that can express how\nadaptive optimizers process gradients into updates. 2) The introduction of\nbra-ket notation to drastically simplify expressions and calculations in Tensor\nPrograms. This work summarizes and generalizes all previous results in the\nTensor Programs series of papers.",
          "link": "http://arxiv.org/abs/2308.01814",
          "publishedOn": "2023-08-05T00:48:26.662Z",
          "wordCount": null,
          "title": "Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit. (arXiv:2308.01814v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.03110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emukpere_D/0/1/0/all/0/1\">David Emukpere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1\">Xavier Alameda-Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reinke_C/0/1/0/all/0/1\">Chris Reinke</a>",
          "description": "A longstanding goal in reinforcement learning is to build intelligent agents\nthat show fast learning and a flexible transfer of skills akin to humans and\nanimals. This paper investigates the integration of two frameworks for tackling\nthose goals: episodic control and successor features. Episodic control is a\ncognitively inspired approach relying on episodic memory, an instance-based\nmemory model of an agent's experiences. Meanwhile, successor features and\ngeneralized policy improvement (SF&GPI) is a meta and transfer learning\nframework allowing to learn policies for tasks that can be efficiently reused\nfor later tasks which have a different reward function. Individually, these two\ntechniques have shown impressive results in vastly improving sample efficiency\nand the elegant reuse of previously learned policies. Thus, we outline a\ncombination of both approaches in a single reinforcement learning framework and\nempirically illustrate its benefits.",
          "link": "http://arxiv.org/abs/2111.03110",
          "publishedOn": "2023-08-05T00:48:26.661Z",
          "wordCount": null,
          "title": "Successor Feature Neural Episodic Control. (arXiv:2111.03110v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.03606",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tyralis_H/0/1/0/all/0/1\">Hristos Tyralis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Papacharalampous_G/0/1/0/all/0/1\">Georgia Papacharalampous</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doulamis_N/0/1/0/all/0/1\">Nikolaos Doulamis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doulamis_A/0/1/0/all/0/1\">Anastasios Doulamis</a>",
          "description": "Knowing the actual precipitation in space and time is critical in\nhydrological modelling applications, yet the spatial coverage with rain gauge\nstations is limited due to economic constraints. Gridded satellite\nprecipitation datasets offer an alternative option for estimating the actual\nprecipitation by covering uniformly large areas, albeit related estimates are\nnot accurate. To improve precipitation estimates, machine learning is applied\nto merge rain gauge-based measurements and gridded satellite precipitation\nproducts. In this context, observed precipitation plays the role of the\ndependent variable, while satellite data play the role of predictor variables.\nRandom forests is the dominant machine learning algorithm in relevant\napplications. In those spatial predictions settings, point predictions (mostly\nthe mean or the median of the conditional distribution) of the dependent\nvariable are issued. The aim of the manuscript is to solve the problem of\nprobabilistic prediction of precipitation with an emphasis on extreme quantiles\nin spatial interpolation settings. Here we propose, issuing probabilistic\nspatial predictions of precipitation using Light Gradient Boosting Machine\n(LightGBM). LightGBM is a boosting algorithm, highlighted by prize-winning\nentries in prediction and forecasting competitions. To assess LightGBM, we\ncontribute a large-scale application that includes merging daily precipitation\nmeasurements in contiguous US with PERSIANN and GPM-IMERG satellite\nprecipitation data. We focus on extreme quantiles of the probability\ndistribution of the dependent variable, where LightGBM outperforms quantile\nregression forests (QRF, a variant of random forests) in terms of quantile\nscore at extreme quantiles. Our study offers understanding of probabilistic\npredictions in spatial settings using machine learning.",
          "link": "http://arxiv.org/abs/2302.03606",
          "publishedOn": "2023-08-05T00:48:26.660Z",
          "wordCount": null,
          "title": "Merging satellite and gauge-measured precipitation using LightGBM with an emphasis on extreme quantiles. (arXiv:2302.03606v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Battiloro_C/0/1/0/all/0/1\">Claudio Battiloro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spinelli_I/0/1/0/all/0/1\">Indro Spinelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telyatnikov_L/0/1/0/all/0/1\">Lev Telyatnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1\">Simone Scardapane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzo_P/0/1/0/all/0/1\">Paolo Di Lorenzo</a>",
          "description": "Latent Graph Inference (LGI) relaxed the reliance of Graph Neural Networks\n(GNNs) on a given graph topology by dynamically learning it. However, most of\nLGI methods assume to have a (noisy, incomplete, improvable, ...) input graph\nto rewire and can solely learn regular graph topologies. In the wake of the\nsuccess of Topological Deep Learning (TDL), we study Latent Topology Inference\n(LTI) for learning higher-order cell complexes (with sparse and not regular\ntopology) describing multi-way interactions between data points. To this aim,\nwe introduce the Differentiable Cell Complex Module (DCM), a novel learnable\nfunction that computes cell probabilities in the complex to improve the\ndownstream task. We show how to integrate DCM with cell complex message passing\nnetworks layers and train it in a end-to-end fashion, thanks to a two-step\ninference procedure that avoids an exhaustive search across all possible cells\nin the input, thus maintaining scalability. Our model is tested on several\nhomophilic and heterophilic graph datasets and it is shown to outperform other\nstate-of-the-art techniques, offering significant improvements especially in\ncases where an input graph is not provided.",
          "link": "http://arxiv.org/abs/2305.16174",
          "publishedOn": "2023-08-05T00:48:26.656Z",
          "wordCount": null,
          "title": "From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module. (arXiv:2305.16174v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01445",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Torzoni_M/0/1/0/all/0/1\">Matteo Torzoni</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tezzele_M/0/1/0/all/0/1\">Marco Tezzele</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mariani_S/0/1/0/all/0/1\">Stefano Mariani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Manzoni_A/0/1/0/all/0/1\">Andrea Manzoni</a>, <a href=\"http://arxiv.org/find/math/1/au:+Willcox_K/0/1/0/all/0/1\">Karen E. Willcox</a>",
          "description": "The digital twin concept represents an appealing opportunity to advance\ncondition-based and predictive maintenance paradigms for civil engineering\nsystems, thus allowing reduced lifecycle costs, increased system safety, and\nincreased system availability. This work proposes a predictive digital twin\napproach to the health monitoring, maintenance, and management planning of\ncivil engineering structures. The asset-twin coupled dynamical system is\nencoded employing a probabilistic graphical model, which allows all relevant\nsources of uncertainty to be taken into account. In particular, the\ntime-repeating observations-to-decisions flow is modeled using a dynamic\nBayesian network. Real-time structural health diagnostics are provided by\nassimilating sensed data with deep learning models. The digital twin state is\ncontinually updated in a sequential Bayesian inference fashion. This is then\nexploited to inform the optimal planning of maintenance and management actions\nwithin a dynamic decision-making framework. A preliminary offline phase\ninvolves the population of training datasets through a reduced-order numerical\nmodel and the computation of a health-dependent control policy. The strategy is\nassessed on two synthetic case studies, involving a cantilever beam and a\nrailway bridge, demonstrating the dynamic decision-making capabilities of\nhealth-aware digital twins.",
          "link": "http://arxiv.org/abs/2308.01445",
          "publishedOn": "2023-08-05T00:48:26.652Z",
          "wordCount": null,
          "title": "A digital twin framework for civil engineering structures. (arXiv:2308.01445v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Po-Lin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Cheng-Shang Chang</a>",
          "description": "This research paper delves into the integration of OpenAI's ChatGPT into\nembodied agent systems, evaluating its influence on interactive decision-making\nbenchmark. Drawing a parallel to the concept of people assuming roles according\nto their unique strengths, we introduce InterAct. In this approach, we feed\nChatGPT with varied prompts, assigning it a numerous roles like a checker and a\nsorter, then integrating them with the original language model. Our research\nshows a remarkable success rate of 98% in AlfWorld, which consists of 6\ndifferent tasks in a simulated household environment, emphasizing the\nsignificance of proficient prompt engineering. The results highlight ChatGPT's\ncompetence in comprehending and performing intricate tasks effectively in\nreal-world settings, thus paving the way for further advancements in task\nplanning.",
          "link": "http://arxiv.org/abs/2308.01552",
          "publishedOn": "2023-08-05T00:48:26.641Z",
          "wordCount": null,
          "title": "InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent. (arXiv:2308.01552v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galatzer_Levy_I/0/1/0/all/0/1\">Isaac R. Galatzer-Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDuff_D/0/1/0/all/0/1\">Daniel McDuff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_V/0/1/0/all/0/1\">Vivek Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karthikesalingam_A/0/1/0/all/0/1\">Alan Karthikesalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malgaroli_M/0/1/0/all/0/1\">Matteo Malgaroli</a>",
          "description": "The current work investigates the capability of Large language models (LLMs)\nthat are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2)\nto predict psychiatric functioning from patient interviews and clinical\ndescriptions without being trained to do so. To assess this, n = 145 depression\nand n =115 PTSD assessments and n = 46 clinical case studies across high\nprevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma\nand stress, Addictive disorders) were analyzed using prompts to extract\nestimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is\ncapable of assessing psychiatric functioning across a range of psychiatric\nconditions with the strongest performance being the prediction of depression\nscores based on standardized assessments (Accuracy range= 0.80 - 0.84) which\nwere statistically indistinguishable from human clinical raters t(1,144) =\n1.20; p = 0.23. Results show the potential for general clinical language models\nto flexibly predict psychiatric risk based on free descriptions of functioning\nfrom both patients and clinicians.",
          "link": "http://arxiv.org/abs/2308.01834",
          "publishedOn": "2023-08-05T00:48:26.641Z",
          "wordCount": null,
          "title": "The Capability of Large Language Models to Measure Psychiatric Functioning. (arXiv:2308.01834v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01602",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Franco_N/0/1/0/all/0/1\">Nicola Rares Franco</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fresca_S/0/1/0/all/0/1\">Stefania Fresca</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tombari_F/0/1/0/all/0/1\">Filippo Tombari</a>, <a href=\"http://arxiv.org/find/math/1/au:+Manzoni_A/0/1/0/all/0/1\">Andrea Manzoni</a>",
          "description": "Mesh-based simulations play a key role when modeling complex physical systems\nthat, in many disciplines across science and engineering, require the solution\nof parametrized time-dependent nonlinear partial differential equations (PDEs).\nIn this context, full order models (FOMs), such as those relying on the finite\nelement method, can reach high levels of accuracy, however often yielding\nintensive simulations to run. For this reason, surrogate models are developed\nto replace computationally expensive solvers with more efficient ones, which\ncan strike favorable trade-offs between accuracy and efficiency. This work\nexplores the potential usage of graph neural networks (GNNs) for the simulation\nof time-dependent PDEs in the presence of geometrical variability. In\nparticular, we propose a systematic strategy to build surrogate models based on\na data-driven time-stepping scheme where a GNN architecture is used to\nefficiently evolve the system. With respect to the majority of surrogate\nmodels, the proposed approach stands out for its ability of tackling problems\nwith parameter dependent spatial domains, while simultaneously generalizing to\ndifferent geometries and mesh resolutions. We assess the effectiveness of the\nproposed approach through a series of numerical experiments, involving both\ntwo- and three-dimensional problems, showing that GNNs can provide a valid\nalternative to traditional surrogate models in terms of computational\nefficiency and generalization to new scenarios. We also assess, from a\nnumerical standpoint, the importance of using GNNs, rather than classical dense\ndeep neural networks, for the proposed framework.",
          "link": "http://arxiv.org/abs/2308.01602",
          "publishedOn": "2023-08-05T00:48:26.622Z",
          "wordCount": null,
          "title": "Deep Learning-based surrogate models for parametrized PDEs: handling geometric variability through graph neural networks. (arXiv:2308.01602v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+geng_Z/0/1/0/all/0/1\">Zhiqiang Kou jing wang yuheng jia xin geng</a>",
          "description": "Label Distribution Learning (LDL) is a novel machine learning paradigm that\nassigns label distribution to each instance. Many LDL methods proposed to\nleverage label correlation in the learning process to solve the\nexponential-sized output space; among these, many exploited the low-rank\nstructure of label distribution to capture label correlation. However, recent\nstudies disclosed that label distribution matrices are typically full-rank,\nposing challenges to those works exploiting low-rank label correlation. Note\nthat multi-label is generally low-rank; low-rank label correlation is widely\nadopted in multi-label learning (MLL) literature. Inspired by that, we\nintroduce an auxiliary MLL process in LDL and capture low-rank label\ncorrelation on that MLL rather than LDL. In such a way, low-rank label\ncorrelation is appropriately exploited in our LDL methods. We conduct\ncomprehensive experiments and demonstrate that our methods are superior to\nexisting LDL methods. Besides, the ablation studies justify the advantages of\nexploiting low-rank label correlation in the auxiliary MLL.",
          "link": "http://arxiv.org/abs/2308.01742",
          "publishedOn": "2023-08-05T00:48:26.617Z",
          "wordCount": null,
          "title": "Exploiting Multi-Label Correlation in Label Distribution Learning. (arXiv:2308.01742v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01481",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Roy_A/0/1/0/all/0/1\">Abhishek Roy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Krishnakumar Balasubramanian</a>",
          "description": "We study the online overlapping batch-means covariance estimator for\nStochastic Gradient Descent (SGD) under Markovian sampling. We show that the\nconvergence rates of the covariance estimator are\n$O\\big(\\sqrt{d}\\,n^{-1/8}(\\log n)^{1/4}\\big)$ and\n$O\\big(\\sqrt{d}\\,n^{-1/8}\\big)$ under state-dependent and state-independent\nMarkovian sampling, respectively, with $d$ representing dimensionality and $n$\ndenoting the number of observations or SGD iterations. Remarkably, these rates\nmatch the best-known convergence rate previously established for the\nindependent and identically distributed ($\\iid$) case by \\cite{zhu2021online},\nup to logarithmic factors. Our analysis overcomes significant challenges that\narise due to Markovian sampling, leading to the introduction of additional\nerror terms and complex dependencies between the blocks of the batch-means\ncovariance estimator. Moreover, we establish the convergence rate for the first\nfour moments of the $\\ell_2$ norm of the error of SGD dynamics under\nstate-dependent Markovian data, which holds potential interest as an\nindependent result. To validate our theoretical findings, we provide numerical\nillustrations to derive confidence intervals for SGD when training linear and\nlogistic regression models under Markovian sampling. Additionally, we apply our\napproach to tackle the intriguing problem of strategic classification with\nlogistic regression, where adversaries can adaptively modify features during\nthe training process to increase their chances of being classified in a\nspecific target class.",
          "link": "http://arxiv.org/abs/2308.01481",
          "publishedOn": "2023-08-05T00:48:26.610Z",
          "wordCount": null,
          "title": "Online covariance estimation for stochastic gradient descent under Markovian sampling. (arXiv:2308.01481v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01677",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Garber_D/0/1/0/all/0/1\">Dan Garber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kaplan_A/0/1/0/all/0/1\">Atara Kaplan</a>",
          "description": "We consider convex relaxations for recovering low-rank tensors based on\nconstrained minimization over a ball induced by the tensor nuclear norm,\nrecently introduced in \\cite{tensor_tSVD}. We build on a recent line of results\nthat considered convex relaxations for the recovery of low-rank matrices and\nestablished that under a strict complementarity condition (SC), both the\nconvergence rate and per-iteration runtime of standard gradient methods may\nimprove dramatically. We develop the appropriate strict complementarity\ncondition for the tensor nuclear norm ball and obtain the following main\nresults under this condition: 1. When the objective to minimize is of the form\n$f(\\mX)=g(\\mA\\mX)+\\langle{\\mC,\\mX}\\rangle$ , where $g$ is strongly convex and\n$\\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds,\nwhich implies linear convergence rates for standard projected gradient methods,\ndespite the fact that $f$ need not be strongly convex. 2. For a smooth\nobjective function, when initialized in certain proximity of an optimal\nsolution which satisfies SC, standard projected gradient methods only require\nSVD computations (for projecting onto the tensor nuclear norm ball) of rank\nthat matches the tubal rank of the optimal solution. In particular, when the\ntubal rank is constant, this implies nearly linear (in the size of the tensor)\nruntime per iteration, as opposed to super linear without further assumptions.\n3. For a nonsmooth objective function which admits a popular smooth\nsaddle-point formulation, we derive similar results to the latter for the well\nknown extragradient method. An additional contribution which may be of\nindependent interest, is the rigorous extension of many basic results regarding\ntensors of arbitrary order, which were previously obtained only for third-order\ntensors.",
          "link": "http://arxiv.org/abs/2308.01677",
          "publishedOn": "2023-08-05T00:48:26.604Z",
          "wordCount": null,
          "title": "Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity. (arXiv:2308.01677v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Philippenko_C/0/1/0/all/0/1\">Constantin Philippenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieuleveut_A/0/1/0/all/0/1\">Aymeric Dieuleveut</a>",
          "description": "In this paper, we investigate the impact of compression on stochastic\ngradient algorithms for machine learning, a technique widely used in\ndistributed and federated learning. We underline differences in terms of\nconvergence rates between several unbiased compression operators, that all\nsatisfy the same condition on their variance, thus going beyond the classical\nworst-case analysis. To do so, we focus on the case of least-squares regression\n(LSR) and analyze a general stochastic approximation algorithm for minimizing\nquadratic functions relying on a random field. We consider weak assumptions on\nthe random field, tailored to the analysis (specifically, expected H\\\"older\nregularity), and on the noise covariance, enabling the analysis of various\nrandomizing mechanisms, including compression. We then extend our results to\nthe case of federated learning.\n\nMore formally, we highlight the impact on the convergence of the covariance\n$\\mathfrak{C}_{\\mathrm{ania}}$ of the additive noise induced by the algorithm.\nWe demonstrate despite the non-regularity of the stochastic field, that the\nlimit variance term scales with $\\mathrm{Tr}(\\mathfrak{C}_{\\mathrm{ania}}\nH^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the\nnumber of iterations) generalizing the rate for the vanilla LSR case where it\nis $\\sigma^2 \\mathrm{Tr}(H H^{-1}) / K = \\sigma^2 d / K$ (Bach and Moulines,\n2013). Then, we analyze the dependency of $\\mathfrak{C}_{\\mathrm{ania}}$ on the\ncompression strategy and ultimately its impact on convergence, first in the\ncentralized case, then in two heterogeneous FL frameworks.",
          "link": "http://arxiv.org/abs/2308.01358",
          "publishedOn": "2023-08-05T00:48:26.599Z",
          "wordCount": null,
          "title": "Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning. (arXiv:2308.01358v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.14720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Read_J/0/1/0/all/0/1\">Jesse Read</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zliobaite_I/0/1/0/all/0/1\">Indr&#x117; &#x17d;liobait&#x117;</a>",
          "description": "The literature on machine learning in the context of data streams is vast and\ngrowing. However, many of the defining assumptions regarding data-stream\nlearning tasks are too strong to hold in practice, or are even contradictory\nsuch that they cannot be met in the contexts of supervised learning. Algorithms\nare chosen and designed based on criteria which are often not clearly stated,\nfor problem settings not clearly defined, tested in unrealistic settings,\nand/or in isolation from related approaches in the wider literature. This puts\ninto question the potential for real-world impact of many approaches conceived\nin such contexts, and risks propagating a misguided research focus. We propose\nto tackle these issues by reformulating the fundamental definitions and\nsettings of supervised data-stream learning with regard to contemporary\nconsiderations of concept drift and temporal dependence; and we take a fresh\nlook at what constitutes a supervised data-stream learning task, and a\nreconsideration of algorithms that may be applied to tackle such tasks. Through\nand in reflection of this formulation and overview, helped by an informal\nsurvey of industrial players dealing with real-world data streams, we provide\nrecommendations. Our main emphasis is that learning from data streams does not\nimpose a single-pass or online-learning approach, or any particular learning\nregime; and any constraints on memory and time are not specific to streaming.\nMeanwhile, there exist established techniques for dealing with temporal\ndependence and concept drift, in other areas of the literature. For the data\nstreams community, we thus encourage a shift in research focus, from dealing\nwith often-artificial constraints and assumptions on the learning mode, to\nissues such as robustness, privacy, and interpretability which are increasingly\nrelevant to learning in data streams in academic and industrial settings.",
          "link": "http://arxiv.org/abs/2212.14720",
          "publishedOn": "2023-08-05T00:48:26.592Z",
          "wordCount": null,
          "title": "Learning from Data Streams: An Overview and Update. (arXiv:2212.14720v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manohara_M/0/1/0/all/0/1\">Manasa Manohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dayal_S/0/1/0/all/0/1\">Sankalp Dayal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afzal_T/0/1/0/all/0/1\">Tarqi Afzal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_R/0/1/0/all/0/1\">Rahul Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1\">Kahkuen Fu</a>",
          "description": "Despite the proliferation of diverse hardware accelerators (e.g., NPU, TPU,\nDPU), deploying deep learning models on edge devices with fixed-point hardware\nis still challenging due to complex model quantization and conversion. Existing\nmodel quantization frameworks like Tensorflow QAT [1], TFLite PTQ [2], and\nQualcomm AIMET [3] supports only a limited set of quantization schemes (e.g.,\nonly asymmetric per-tensor quantization in TF1.x QAT [4]). Accordingly, deep\nlearning models cannot be easily quantized for diverse fixed-point hardwares,\nmainly due to slightly different quantization requirements. In this paper, we\nenvision a new type of model quantization approach called MRQ (model\nre-quantization), which takes existing quantized models and quickly transforms\nthe models to meet different quantization requirements (e.g., asymmetric ->\nsymmetric, non-power-of-2 scale -> power-of-2 scale). Re-quantization is much\nsimpler than quantizing from scratch because it avoids costly re-training and\nprovides support for multiple quantization schemes simultaneously. To minimize\nre-quantization error, we developed a new set of re-quantization algorithms\nincluding weight correction and rounding error folding. We have demonstrated\nthat MobileNetV2 QAT model [7] can be quickly re-quantized into two different\nquantization schemes (i.e., symmetric and symmetric+power-of-2 scale) with less\nthan 0.64 units of accuracy loss. We believe our work is the first to leverage\nthis concept of re-quantization for model quantization and models obtained from\nthe re-quantization process have been successfully deployed on NNA in the Echo\nShow devices.",
          "link": "http://arxiv.org/abs/2308.01867",
          "publishedOn": "2023-08-05T00:48:26.580Z",
          "wordCount": null,
          "title": "MRQ:Support Multiple Quantization Schemes through Model Re-Quantization. (arXiv:2308.01867v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiser_S/0/1/0/all/0/1\">Shawn L. Kiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guskov_M/0/1/0/all/0/1\">Mikhail Guskov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rebillat_M/0/1/0/all/0/1\">Marc R&#xe9;billat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranc_N/0/1/0/all/0/1\">Nicolas Ranc</a>",
          "description": "Identification of nonlinear dynamical systems has been popularized by sparse\nidentification of the nonlinear dynamics (SINDy) via the sequentially\nthresholded least squares (STLS) algorithm. Many extensions SINDy have emerged\nin the literature to deal with experimental data which are finite in length and\nnoisy. Recently, the computationally intensive method of ensembling\nbootstrapped SINDy models (E-SINDy) was proposed for model identification,\nhandling finite, highly noisy data. While the extensions of SINDy are numerous,\ntheir sparsity-promoting estimators occasionally provide sparse approximations\nof the dynamics as opposed to exact recovery. Furthermore, these estimators\nsuffer under multicollinearity, e.g. the irrepresentable condition for the\nLasso. In this paper, we demonstrate that the Trimmed Lasso for robust\nidentification of models (TRIM) can provide exact recovery under more severe\nnoise, finite data, and multicollinearity as opposed to E-SINDy. Additionally,\nthe computational cost of TRIM is asymptotically equal to STLS since the\nsparsity parameter of the TRIM can be solved efficiently by convex solvers. We\ncompare these methodologies on challenging nonlinear systems, specifically the\nLorenz 63 system, the Bouc Wen oscillator from the nonlinear dynamics benchmark\nof No\\\"el and Schoukens, 2016, and a time delay system describing tool cutting\ndynamics. This study emphasizes the comparisons between STLS, reweighted\n$\\ell_1$ minimization, and Trimmed Lasso in identification with respect to\nproblems faced by practitioners: the problem of finite and noisy data, the\nperformance of the sparse regression of when the library grows in dimension\n(multicollinearity), and automatic methods for choice of regularization\nparameters.",
          "link": "http://arxiv.org/abs/2308.01891",
          "publishedOn": "2023-08-05T00:48:26.575Z",
          "wordCount": null,
          "title": "Exact identification of nonlinear dynamical systems by Trimmed Lasso. (arXiv:2308.01891v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01868",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Gonzalez_Abad_J/0/1/0/all/0/1\">Jose Gonz&#xe1;lez-Abad</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hernandez_Garcia_A/0/1/0/all/0/1\">&#xc1;lex Hern&#xe1;ndez-Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Harder_P/0/1/0/all/0/1\">Paula Harder</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rolnick_D/0/1/0/all/0/1\">David Rolnick</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gutierrez_J/0/1/0/all/0/1\">Jos&#xe9; Manuel Guti&#xe9;rrez</a>",
          "description": "Global Climate Models (GCMs) are the primary tool to simulate climate\nevolution and assess the impacts of climate change. However, they often operate\nat a coarse spatial resolution that limits their accuracy in reproducing\nlocal-scale phenomena. Statistical downscaling methods leveraging deep learning\noffer a solution to this problem by approximating local-scale climate fields\nfrom coarse variables, thus enabling regional GCM projections. Typically,\nclimate fields of different variables of interest are downscaled independently,\nresulting in violations of fundamental physical properties across\ninterconnected variables. This study investigates the scope of this problem\nand, through an application on temperature, lays the foundation for a framework\nintroducing multi-variable hard constraints that guarantees physical\nrelationships between groups of downscaled climate variables.",
          "link": "http://arxiv.org/abs/2308.01868",
          "publishedOn": "2023-08-05T00:48:26.568Z",
          "wordCount": null,
          "title": "Multi-variable Hard Physical Constraints for Climate Model Downscaling. (arXiv:2308.01868v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+OGara_A/0/1/0/all/0/1\">Aidan O&#x27;Gara</a>",
          "description": "Are current language models capable of deception and lie detection? We study\nthis question by introducing a text-based game called $\\textit{Hoodwinked}$,\ninspired by $\\textit{Mafia}$ and $\\textit{Among Us}$. Players are locked in a\nhouse and must find a key to escape, but one player is tasked with killing the\nothers. Each time a murder is committed, the surviving players have a natural\nlanguage discussion then vote to banish one player from the game. We conduct\nexperiments with agents controlled by GPT-3, GPT-3.5, and GPT-4 and find\nevidence of deception and lie detection capabilities. The killer often denies\ntheir crime and accuses others, leading to measurable effects on voting\noutcomes. More advanced models are more effective killers, outperforming\nsmaller models in 18 of 24 pairwise comparisons. Secondary metrics provide\nevidence that this improvement is not mediated by different actions, but rather\nby stronger deception capabilities during discussions. Overall, we find\nsubstantial evidence that current language models are capable of deception. To\nbetter evaluate the ability of AI agents to deceive humans, we make this game\npublicly available at https://hoodwinked.ai/ .",
          "link": "http://arxiv.org/abs/2308.01404",
          "publishedOn": "2023-08-05T00:48:26.557Z",
          "wordCount": null,
          "title": "Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models. (arXiv:2308.01404v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadshirazi_A/0/1/0/all/0/1\">Ahmad Mohammadshirazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadafian_A/0/1/0/all/0/1\">Aida Nadafian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_A/0/1/0/all/0/1\">Amin Karimi Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafiei_M/0/1/0/all/0/1\">Mohammad H. Rafiei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramnath_R/0/1/0/all/0/1\">Rajiv Ramnath</a>",
          "description": "Cost-effective sensors are capable of real-time capturing a variety of air\nquality-related modalities from different pollutant concentrations to\nindoor/outdoor humidity and temperature. Machine learning (ML) models are\ncapable of performing air-quality \"ahead-of-time\" approximations. Undoubtedly,\naccurate indoor air quality approximation significantly helps provide a healthy\nindoor environment, optimize associated energy consumption, and offer human\ncomfort. However, it is crucial to design an ML architecture to capture the\ndomain knowledge, so-called problem physics. In this study, we propose six\nnovel physics-based ML models for accurate indoor pollutant concentration\napproximations. The proposed models include an adroit combination of\nstate-space concepts in physics, Gated Recurrent Units, and Decomposition\ntechniques. The proposed models were illustrated using data collected from five\noffices in a commercial building in California. The proposed models are shown\nto be less complex, computationally more efficient, and more accurate than\nsimilar state-of-the-art transformer-based models. The superiority of the\nproposed models is due to their relatively light architecture (computational\nefficiency) and, more importantly, their ability to capture the underlying\nhighly nonlinear patterns embedded in the often contaminated sensor-collected\nindoor air quality temporal data.",
          "link": "http://arxiv.org/abs/2308.01438",
          "publishedOn": "2023-08-05T00:48:26.550Z",
          "wordCount": null,
          "title": "Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations. (arXiv:2308.01438v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_M/0/1/0/all/0/1\">Myeongjin Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yong-Hoon Choi</a>",
          "description": "The diffusion model is capable of generating high-quality data through a\nprobabilistic approach. However, it suffers from the drawback of slow\ngeneration speed due to the requirement of a large number of time steps. To\naddress this limitation, recent models such as denoising diffusion implicit\nmodels (DDIM) focus on generating samples without directly modeling the\nprobability distribution, while models like denoising diffusion generative\nadversarial networks (GAN) combine diffusion processes with GANs. In the field\nof speech synthesis, a recent diffusion speech synthesis model called\nDiffGAN-TTS, utilizing the structure of GANs, has been introduced and\ndemonstrates superior performance in both speech quality and generation speed.\nIn this paper, to further enhance the performance of DiffGAN-TTS, we propose a\nspeech synthesis model with two discriminators: a diffusion discriminator for\nlearning the distribution of the reverse process and a spectrogram\ndiscriminator for learning the distribution of the generated data. Objective\nmetrics such as structural similarity index measure (SSIM), mel-cepstral\ndistortion (MCD), F0 root mean squared error (F0 RMSE), short-time objective\nintelligibility (STOI), perceptual evaluation of speech quality (PESQ), as well\nas subjective metrics like mean opinion score (MOS), are used to evaluate the\nperformance of the proposed model. The evaluation results show that the\nproposed model outperforms recent state-of-the-art models such as FastSpeech2\nand DiffGAN-TTS in various metrics. Our implementation and audio samples are\nlocated on GitHub.",
          "link": "http://arxiv.org/abs/2308.01573",
          "publishedOn": "2023-08-05T00:48:26.540Z",
          "wordCount": null,
          "title": "Adversarial Training of Denoising Diffusion Model Using Dual Discriminators for High-Fidelity Multi-Speaker TTS. (arXiv:2308.01573v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.04934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jinghan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiancheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gaowen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Pranay Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "In response to recent data regulation requirements, machine unlearning (MU)\nhas emerged as a critical process to remove the influence of specific examples\nfrom a given model. Although exact unlearning can be achieved through complete\nmodel retraining using the remaining dataset, the associated computational\ncosts have driven the development of efficient, approximate unlearning\ntechniques. Moving beyond data-centric MU approaches, our study introduces a\nnovel model-based perspective: model sparsification via weight pruning, which\nis capable of reducing the gap between exact unlearning and approximate\nunlearning. We show in both theory and practice that model sparsity can boost\nthe multi-criteria unlearning performance of an approximate unlearner, closing\nthe approximation gap, while continuing to be efficient. This leads to a new MU\nparadigm, termed prune first, then unlearn, which infuses a sparse model prior\ninto the unlearning process. Building on this insight, we also develop a\nsparsity-aware unlearning method that utilizes sparsity regularization to\nenhance the training process of approximate unlearning. Extensive experiments\nshow that our proposals consistently benefit MU in various unlearning\nscenarios. A notable highlight is the 77% unlearning efficacy gain of\nfine-tuning (one of the simplest unlearning methods) when using sparsity-aware\nunlearning. Furthermore, we demonstrate the practical impact of our proposed MU\nmethods in addressing other machine learning challenges, such as defending\nagainst backdoor attacks and enhancing transfer learning. Codes are available\nat https://github.com/OPTML-Group/Unlearn-Sparse.",
          "link": "http://arxiv.org/abs/2304.04934",
          "publishedOn": "2023-08-05T00:48:26.522Z",
          "wordCount": null,
          "title": "Model Sparsity Can Simplify Machine Unlearning. (arXiv:2304.04934v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bonetta_G/0/1/0/all/0/1\">Giovanni Bonetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zago_D/0/1/0/all/0/1\">Davide Zago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cancelliere_R/0/1/0/all/0/1\">Rossella Cancelliere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosso_A/0/1/0/all/0/1\">Andrea Grosso</a>",
          "description": "Job scheduling is a well-known Combinatorial Optimization problem with\nendless applications. Well planned schedules bring many benefits in the context\nof automated systems: among others, they limit production costs and waste.\nNevertheless, the NP-hardness of this problem makes it essential to use\nheuristics whose design is difficult, requires specialized knowledge and often\nproduces methods tailored to the specific task. This paper presents an original\nend-to-end Deep Reinforcement Learning approach to scheduling that\nautomatically learns dispatching rules. Our technique is inspired by natural\nlanguage encoder-decoder models for sequence processing and has never been\nused, to the best of our knowledge, for scheduling purposes. We applied and\ntested our method in particular to some benchmark instances of Job Shop\nProblem, but this technique is general enough to be potentially used to tackle\nother different optimal job scheduling tasks with minimal intervention. Results\ndemonstrate that we outperform many classical approaches exploiting priority\ndispatching rules and show competitive results on state-of-the-art Deep\nReinforcement Learning ones.",
          "link": "http://arxiv.org/abs/2308.01797",
          "publishedOn": "2023-08-05T00:48:26.507Z",
          "wordCount": null,
          "title": "Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach. (arXiv:2308.01797v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_J/0/1/0/all/0/1\">Joao Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_A/0/1/0/all/0/1\">An T. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baierl_M/0/1/0/all/0/1\">Mark Baierl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koert_D/0/1/0/all/0/1\">Dorothea Koert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>",
          "description": "Learning priors on trajectory distributions can help accelerate robot motion\nplanning optimization. Given previously successful plans, learning trajectory\ngenerative models as priors for a new planning problem is highly desirable.\nPrior works propose several ways on utilizing this prior to bootstrapping the\nmotion planning problem. Either sampling the prior for initializations or using\nthe prior distribution in a maximum-a-posterior formulation for trajectory\noptimization. In this work, we propose learning diffusion models as priors. We\nthen can sample directly from the posterior trajectory distribution conditioned\non task goals, by leveraging the inverse denoising process of diffusion models.\nFurthermore, diffusion has been recently shown to effectively encode data\nmultimodality in high-dimensional settings, which is particularly well-suited\nfor large trajectory dataset. To demonstrate our method efficacy, we compare\nour proposed method - Motion Planning Diffusion - against several baselines in\nsimulated planar robot and 7-dof robot arm manipulator environments. To assess\nthe generalization capabilities of our method, we test it in environments with\npreviously unseen obstacles. Our experiments show that diffusion models are\nstrong priors to encode high-dimensional trajectory distributions of robot\nmotions.",
          "link": "http://arxiv.org/abs/2308.01557",
          "publishedOn": "2023-08-05T00:48:26.488Z",
          "wordCount": null,
          "title": "Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models. (arXiv:2308.01557v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01835",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tamas_A/0/1/0/all/0/1\">Ambrus Tam&#xe1;s</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Csaji_B/0/1/0/all/0/1\">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>",
          "description": "One of the key objects of binary classification is the regression function,\ni.e., the conditional expectation of the class labels given the inputs. With\nthe regression function not only a Bayes optimal classifier can be defined, but\nit also encodes the corresponding misclassification probabilities. The paper\npresents a resampling framework to construct exact, distribution-free and\nnon-asymptotically guaranteed confidence regions for the true regression\nfunction for any user-chosen confidence level. Then, specific algorithms are\nsuggested to demonstrate the framework. It is proved that the constructed\nconfidence regions are strongly consistent, that is, any false model is\nexcluded in the long run with probability one. The exclusion is quantified with\nprobably approximately correct type bounds, as well. Finally, the algorithms\nare validated via numerical experiments, and the methods are compared to\napproximate asymptotic confidence ellipsoids.",
          "link": "http://arxiv.org/abs/2308.01835",
          "publishedOn": "2023-08-05T00:48:26.474Z",
          "wordCount": null,
          "title": "Distribution-Free Inference for the Regression Function of Binary Classification. (arXiv:2308.01835v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Puning Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Lifeng Lai</a>",
          "description": "$Q$ learning is a popular model free reinforcement learning method. Most of\nexisting works focus on analyzing $Q$ learning for finite state and action\nspaces. If the state space is continuous, then the original $Q$ learning method\ncan not be directly used. A modification of the original $Q$ learning method\nwas proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest\nneighbors. Such modification makes $Q$ learning suitable for continuous state\nspace. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$\nfunction is $\\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower\nbound $\\tilde{\\Omega}(T^{-1/(d+2)})$, indicating that this method is not\nefficient. This paper proposes two new $Q$ learning methods to bridge the gap\nof convergence rates in (Shah and Xie, 2018), with one of them being offline,\nwhile the other is online. Despite that we still use nearest neighbor approach\nto estimate $Q$ function, the algorithms are crucially different from (Shah and\nXie, 2018). In particular, we replace the kernel nearest neighbor in\ndiscretized region with a direct nearest neighbor approach. Consequently, our\napproach significantly improves the convergence rate. Moreover, the time\ncomplexity is also significantly improved in high dimensional state spaces. Our\nanalysis shows that both offline and online methods are minimax rate optimal.",
          "link": "http://arxiv.org/abs/2308.01490",
          "publishedOn": "2023-08-05T00:48:26.460Z",
          "wordCount": null,
          "title": "Minimax Optimal $Q$ Learning with Nearest Neighbors. (arXiv:2308.01490v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_S/0/1/0/all/0/1\">Sanghyeon Na</a>",
          "description": "Face swapping is a task that changes a facial identity of a given image to\nthat of another person. In this work, we propose a novel face-swapping\nframework called Megapixel Facial Identity Manipulation (MFIM). The\nface-swapping model should achieve two goals. First, it should be able to\ngenerate a high-quality image. We argue that a model which is proficient in\ngenerating a megapixel image can achieve this goal. However, generating a\nmegapixel image is generally difficult without careful model design. Therefore,\nour model exploits pretrained StyleGAN in the manner of GAN-inversion to\neffectively generate a megapixel image. Second, it should be able to\neffectively transform the identity of a given image. Specifically, it should be\nable to actively transform ID attributes (e.g., face shape and eyes) of a given\nimage into those of another person, while preserving ID-irrelevant attributes\n(e.g., pose and expression). To achieve this goal, we exploit 3DMM that can\ncapture various facial attributes. Specifically, we explicitly supervise our\nmodel to generate a face-swapped image with the desirable attributes using\n3DMM. We show that our model achieves state-of-the-art performance through\nextensive experiments. Furthermore, we propose a new operation called ID\nmixing, which creates a new identity by semantically mixing the identities of\nseveral people. It allows the user to customize the new identity.",
          "link": "http://arxiv.org/abs/2308.01536",
          "publishedOn": "2023-08-05T00:48:26.454Z",
          "wordCount": null,
          "title": "MFIM: Megapixel Facial Identity Manipulation. (arXiv:2308.01536v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agliari_E/0/1/0/all/0/1\">Elena Agliari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aquaro_M/0/1/0/all/0/1\">Miriam Aquaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alemanno_F/0/1/0/all/0/1\">Francesco Alemanno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fachechi_A/0/1/0/all/0/1\">Alberto Fachechi</a>",
          "description": "In this work we approach attractor neural networks from a machine learning\nperspective: we look for optimal network parameters by applying a gradient\ndescent over a regularized loss function. Within this framework, the optimal\nneuron-interaction matrices turn out to be a class of matrices which correspond\nto Hebbian kernels revised by iteratively applying some unlearning protocols.\nRemarkably, the number of unlearning steps is proved to be related to the\nregularization hyperparameters of the loss function and to the training time.\nThus, we can design strategies to avoid overfitting that are formulated in\nterms of the algebraic properties of the interaction matrix, or, equivalently,\nin terms of regularization tuning and early-stopping strategies. The\ngeneralization capabilities of these attractor networks are also investigated:\nanalytical results are obtained for random synthetic datasets, next, the\nemerging picture is corroborated by numerical experiments that highlight the\nexistence of several regimes (i.e., overfitting, failure and success) as the\ndataset parameters are varied.",
          "link": "http://arxiv.org/abs/2308.01421",
          "publishedOn": "2023-08-05T00:48:26.249Z",
          "wordCount": null,
          "title": "Regularization, early-stopping and dreaming: a Hopfield-like setup to address generalization and overfitting. (arXiv:2308.01421v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.04370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_K/0/1/0/all/0/1\">Kai Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jianchao Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Human intelligence excels at combining basic skills to solve complex tasks.\nThis capability is vital for Artificial Intelligence (AI) and should be\nembedded in comprehensive intelligent models, enabling them to harness expert\nmodels for complex task-solving towards Artificial General Intelligence (AGI).\nLarge Language Models (LLMs) show promising learning and reasoning abilities,\nand can effectively use external models, tools or APIs to tackle complex\nproblems. In this work, we introduce OpenAGI, an open-source AGI research\nplatform designed for multi-step, real-world tasks. Specifically, OpenAGI uses\na dual strategy, integrating standard benchmark tasks for benchmarking and\nevaluation, and open-ended tasks including more expandable models, tools or\nAPIs for creative problem-solving. Tasks are presented as natural language\nqueries to the LLM, which then selects and executes appropriate models. We also\npropose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses\ntask results to improve the LLM's ability, which creates a self-improving AI\nfeedback loop. While we acknowledge that AGI is a broad and multifaceted\nresearch challenge with no singularly defined solution path, the integration of\nLLMs with domain-specific expert models, inspired by mirroring the blend of\ngeneral and specialized intelligence in humans, offers a promising approach\ntowards AGI. We are open-sourcing the OpenAGI project's code, dataset,\nbenchmarks, evaluation methods, and demo to foster community involvement in AGI\nadvancement: https://github.com/agiresearch/OpenAGI.",
          "link": "http://arxiv.org/abs/2304.04370",
          "publishedOn": "2023-08-05T00:48:26.047Z",
          "wordCount": 773,
          "title": "OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v5 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tabellion_E/0/1/0/all/0/1\">Eric Tabellion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnad_N/0/1/0/all/0/1\">Nikhil Karnad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaser_N/0/1/0/all/0/1\">Noa Glaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_B/0/1/0/all/0/1\">Ben Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David E. Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1\">Yael Pritch</a>",
          "description": "Long exposure photography produces stunning imagery, representing moving\nelements in a scene with motion-blur. It is generally employed in two\nmodalities, producing either a foreground or a background blur effect.\nForeground blur images are traditionally captured on a tripod-mounted camera\nand portray blurred moving foreground elements, such as silky water or light\ntrails, over a perfectly sharp background landscape. Background blur images,\nalso called panning photography, are captured while the camera is tracking a\nmoving subject, to produce an image of a sharp subject over a background\nblurred by relative motion. Both techniques are notoriously challenging and\nrequire additional equipment and advanced skills. In this paper, we describe a\ncomputational burst photography system that operates in a hand-held smartphone\ncamera app, and achieves these effects fully automatically, at the tap of the\nshutter button. Our approach first detects and segments the salient subject. We\ntrack the scene motion over multiple frames and align the images in order to\npreserve desired sharpness and to produce aesthetically pleasing motion\nstreaks. We capture an under-exposed burst and select the subset of input\nframes that will produce blur trails of controlled length, regardless of scene\nor camera motion velocity. We predict inter-frame motion and synthesize\nmotion-blur to fill the temporal gaps between the input frames. Finally, we\ncomposite the blurred image with the sharp regular exposure to protect the\nsharpness of faces or areas of the scene that are barely moving, and produce a\nfinal high resolution and high dynamic range (HDR) photograph. Our system\ndemocratizes a capability previously reserved to professionals, and makes this\ncreative style accessible to most casual photographers.\n\nMore information and supplementary material can be found on our project\nwebpage: https://motion-mode.github.io/",
          "link": "http://arxiv.org/abs/2308.01379",
          "publishedOn": "2023-08-05T00:48:25.989Z",
          "wordCount": 815,
          "title": "Computational Long Exposure Mobile Photography. (arXiv:2308.01379v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.10741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yang Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kargarandehkordi_A/0/1/0/all/0/1\">Ali Kargarandehkordi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutlu_O/0/1/0/all/0/1\">Onur Cezmi Mutlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surabhi_S/0/1/0/all/0/1\">Saimourya Surabhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honarmand_M/0/1/0/all/0/1\">Mohammadmahdi Honarmand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wall_D/0/1/0/all/0/1\">Dennis Paul Wall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1\">Peter Washington</a>",
          "description": "Emotions play an essential role in human communication. Developing computer\nvision models for automatic recognition of emotion expression can aid in a\nvariety of domains, including robotics, digital behavioral healthcare, and\nmedia analytics. There are three types of emotional representations which are\ntraditionally modeled in affective computing research: Action Units, Valence\nArousal (VA), and Categorical Emotions. As part of an effort to move beyond\nthese representations towards more fine-grained labels, we describe our\nsubmission to the newly introduced Emotional Reaction Intensity (ERI)\nEstimation challenge in the 5th competition for Affective Behavior Analysis\nin-the-Wild (ABAW). We developed four deep neural networks trained in the\nvisual domain and a multimodal model trained with both visual and audio\nfeatures to predict emotion reaction intensity. Our best performing model on\nthe Hume-Reaction dataset achieved an average Pearson correlation coefficient\nof 0.4080 on the test set using a pre-trained ResNet50 model. This work\nprovides a first step towards the development of production-grade models which\npredict emotion reaction intensities rather than discrete emotion categories.",
          "link": "http://arxiv.org/abs/2303.10741",
          "publishedOn": "2023-08-05T00:48:25.982Z",
          "wordCount": 704,
          "title": "Computer Vision Estimation of Emotion Reaction Intensity in the Wild. (arXiv:2303.10741v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tothova_K/0/1/0/all/0/1\">Katar&#xed;na T&#xf3;thov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladicky_L/0/1/0/all/0/1\">&#x13d;ubor Ladick&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thul_D/0/1/0/all/0/1\">Daniel Thul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1\">Ender Konukoglu</a>",
          "description": "Predictive variability due to data ambiguities has typically been addressed\nvia construction of dedicated models with built-in probabilistic capabilities\nthat are trained to predict uncertainty estimates as variables of interest.\nThese approaches require distinct architectural components and training\nmechanisms, may include restrictive assumptions and exhibit overconfidence,\ni.e., high confidence in imprecise predictions. In this work, we propose a\npost-hoc sampling strategy for estimating predictive uncertainty accounting for\ndata ambiguity. The method can generate different plausible outputs for a given\ninput and does not assume parametric forms of predictive distributions. It is\narchitecture agnostic and can be applied to any feed-forward deterministic\nnetwork without changes to the architecture or training procedure. Experiments\non regression tasks on imaging and non-imaging input data show the method's\nability to generate diverse and multi-modal predictive distributions, and a\ndesirable correlation of the estimated uncertainty with the prediction error.",
          "link": "http://arxiv.org/abs/2308.01731",
          "publishedOn": "2023-08-05T00:48:25.976Z",
          "wordCount": 673,
          "title": "Quantification of Predictive Uncertainty via Inference-Time Sampling. (arXiv:2308.01731v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sa_J/0/1/0/all/0/1\">Jader Martins Camboim de S&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanches_M/0/1/0/all/0/1\">Matheus Ferraroni Sanches</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souza_R/0/1/0/all/0/1\">Rafael Roque de Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_J/0/1/0/all/0/1\">J&#xfa;lio Cesar dos Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villas_L/0/1/0/all/0/1\">Leandro Aparecido Villas</a>",
          "description": "Fine-tuning language models in a downstream task is the standard approach for\nmany state-of-the-art methodologies in the field of NLP. However, when the\ndistribution between the source task and target task drifts, \\textit{e.g.},\nconversational environments, these gains tend to be diminished. This article\nproposes a sequence of pre-training steps (a curriculum) guided by \"data\nhacking\" and grammar analysis that allows further gradual adaptation between\npre-training distributions. In our experiments, we acquire a considerable\nimprovement from our method compared to other known pre-training approaches for\nthe MultiWoZ task.",
          "link": "http://arxiv.org/abs/2308.01849",
          "publishedOn": "2023-08-05T00:48:25.970Z",
          "wordCount": 599,
          "title": "Curricular Transfer Learning for Sentence Encoded Tasks. (arXiv:2308.01849v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.00788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khanduri_P/0/1/0/all/0/1\">Prashant Khanduri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsaknakis_I/0/1/0/all/0/1\">Ioannis Tsaknakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Mingyi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "Recently, bi-level optimization (BLO) has taken center stage in some very\nexciting developments in the area of signal processing (SP) and machine\nlearning (ML). Roughly speaking, BLO is a classical optimization problem that\ninvolves two levels of hierarchy (i.e., upper and lower levels), wherein\nobtaining the solution to the upper-level problem requires solving the\nlower-level one. BLO has become popular largely because it is powerful in\nmodeling problems in SP and ML, among others, that involve optimizing nested\nobjective functions. Prominent applications of BLO range from resource\nallocation for wireless systems to adversarial machine learning. In this work,\nwe focus on a class of tractable BLO problems that often appear in SP and ML\napplications. We provide an overview of some basic concepts of this class of\nBLO problems, such as their optimality conditions, standard algorithms\n(including their optimization principles and practical implementations), as\nwell as how they can be leveraged to obtain state-of-the-art results for a\nnumber of key SP and ML applications. Further, we discuss some recent advances\nin BLO theory, its implications for applications, and point out some\nlimitations of the state-of-the-art that require significant future research\nefforts. Overall, we hope that this article can serve to accelerate the\nadoption of BLO as a generic tool to model, analyze, and innovate on a wide\narray of emerging SP and ML applications.",
          "link": "http://arxiv.org/abs/2308.00788",
          "publishedOn": "2023-08-05T00:48:25.938Z",
          "wordCount": 777,
          "title": "An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning. (arXiv:2308.00788v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.13495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinyao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Shengdong Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianrui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_F/0/1/0/all/0/1\">Fei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yan Yang</a>",
          "description": "With the advent of the big data era, the data quality problem is becoming\nmore critical. Among many factors, data with missing values is one primary\nissue, and thus developing effective imputation models is a key topic in the\nresearch community. Recently, a major research direction is to employ neural\nnetwork models such as self-organizing mappings or automatic encoders for\nfilling missing values. However, these classical methods can hardly discover\ninterrelated features and common features simultaneously among data attributes.\nEspecially, it is a very typical problem for classical autoencoders that they\noften learn invalid constant mappings, which dramatically hurts the filling\nperformance. To solve the above-mentioned problems, we propose a\nmissing-value-filling model based on a feature-fusion-enhanced autoencoder. We\nfirst incorporate into an autoencoder a hidden layer that consists of\nde-tracking neurons and radial basis function neurons, which can enhance the\nability of learning interrelated features and common features. Besides, we\ndevelop a missing value filling strategy based on dynamic clustering that is\nincorporated into an iterative optimization process. This design can enhance\nthe multi-dimensional feature fusion ability and thus improves the dynamic\ncollaborative missing-value-filling performance. The effectiveness of the\nproposed model is validated by extensive experiments compared to a variety of\nbaseline methods on thirteen data sets.",
          "link": "http://arxiv.org/abs/2208.13495",
          "publishedOn": "2023-08-05T00:48:25.931Z",
          "wordCount": 741,
          "title": "A Missing Value Filling Model Based on Feature Fusion Enhanced Autoencoder. (arXiv:2208.13495v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.11883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Journe_A/0/1/0/all/0/1\">Adrien Journ&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_H/0/1/0/all/0/1\">Hector Garcia Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qinghai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraitis_T/0/1/0/all/0/1\">Timoleon Moraitis</a>",
          "description": "Recent approximations to backpropagation (BP) have mitigated many of BP's\ncomputational inefficiencies and incompatibilities with biology, but important\nlimitations still remain. Moreover, the approximations significantly decrease\naccuracy in benchmarks, suggesting that an entirely different approach may be\nmore fruitful. Here, grounded on recent theory for Hebbian learning in soft\nwinner-take-all networks, we present multilayer SoftHebb, i.e. an algorithm\nthat trains deep neural networks, without any feedback, target, or error\nsignals. As a result, it achieves efficiency by avoiding weight transport,\nnon-local plasticity, time-locking of layer updates, iterative equilibria, and\n(self-) supervisory or other feedback signals -- which were necessary in other\napproaches. Its increased efficiency and biological compatibility do not trade\noff accuracy compared to state-of-the-art bio-plausible learning, but rather\nimprove it. With up to five hidden layers and an added linear classifier,\naccuracies on MNIST, CIFAR-10, STL-10, and ImageNet, respectively reach 99.4%,\n80.3%, 76.2%, and 27.3%. In conclusion, SoftHebb shows with a radically\ndifferent approach from BP that Deep Learning over few layers may be plausible\nin the brain and increases the accuracy of bio-plausible machine learning. Code\nis available at https://github.com/NeuromorphicComputing/SoftHebb.",
          "link": "http://arxiv.org/abs/2209.11883",
          "publishedOn": "2023-08-05T00:48:25.924Z",
          "wordCount": 728,
          "title": "Hebbian Deep Learning Without Feedback. (arXiv:2209.11883v2 [cs.NE] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mercier_A/0/1/0/all/0/1\">Antoine Mercier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erasmus_R/0/1/0/all/0/1\">Ruan Erasmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savani_Y/0/1/0/all/0/1\">Yashesh Savani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_M/0/1/0/all/0/1\">Manik Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1\">Fatih Porikli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_G/0/1/0/all/0/1\">Guillaume Berger</a>",
          "description": "Real-time rendering for video games has become increasingly challenging due\nto the need for higher resolutions, framerates and photorealism. Supersampling\nhas emerged as an effective solution to address this challenge. Our work\nintroduces a novel neural algorithm for supersampling rendered content that is\n4 times more efficient than existing methods while maintaining the same level\nof accuracy. Additionally, we introduce a new dataset which provides auxiliary\nmodalities such as motion vectors and depth generated using graphics rendering\nfeatures like viewport jittering and mipmap biasing at different resolutions.\nWe believe that this dataset fills a gap in the current dataset landscape and\ncan serve as a valuable resource to help measure progress in the field and\nadvance the state-of-the-art in super-resolution techniques for gaming content.",
          "link": "http://arxiv.org/abs/2308.01483",
          "publishedOn": "2023-08-05T00:48:25.917Z",
          "wordCount": 658,
          "title": "Efficient neural supersampling on a novel gaming dataset. (arXiv:2308.01483v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.11429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Streeter_M/0/1/0/all/0/1\">Matthew Streeter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dillon_J/0/1/0/all/0/1\">Joshua V. Dillon</a>",
          "description": "We present a new algorithm for automatically bounding the Taylor remainder\nseries. In the special case of a scalar function $f: \\mathbb{R} \\to\n\\mathbb{R}$, our algorithm takes as input a reference point $x_0$, trust region\n$[a, b]$, and integer $k \\ge 1$, and returns an interval $I$ such that $f(x) -\n\\sum_{i=0}^{k-1} \\frac {1} {i!} f^{(i)}(x_0) (x - x_0)^i \\in I (x - x_0)^k$ for\nall $x \\in [a, b]$. As in automatic differentiation, the function $f$ is\nprovided to the algorithm in symbolic form, and must be composed of known\natomic functions.\n\nAt a high level, our algorithm has two steps. First, for a variety of\ncommonly-used elementary functions (e.g., $\\exp$, $\\log$), we use\nrecently-developed theory to derive sharp polynomial upper and lower bounds on\nthe Taylor remainder series. We then recursively combine the bounds for the\nelementary functions using an interval arithmetic variant of Taylor-mode\nautomatic differentiation. Our algorithm can make efficient use of machine\nlearning hardware accelerators, and we provide an open source implementation in\nJAX.\n\nWe then turn our attention to applications. Most notably, in a companion\npaper we use our new machinery to create the first universal\nmajorization-minimization optimization algorithms: algorithms that iteratively\nminimize an arbitrary loss using a majorizer that is derived automatically,\nrather than by hand. We also show that our automatically-derived bounds can be\nused for verified global optimization and numerical integration, and to prove\nsharper versions of Jensen's inequality.",
          "link": "http://arxiv.org/abs/2212.11429",
          "publishedOn": "2023-08-05T00:48:25.889Z",
          "wordCount": 800,
          "title": "Automatically Bounding the Taylor Remainder Series: Tighter Bounds and New Applications. (arXiv:2212.11429v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gannamaneni_S/0/1/0/all/0/1\">Sujan Sai Gannamaneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mock_M/0/1/0/all/0/1\">Michael Mock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1\">Maram Akila</a>",
          "description": "With the advancement of DNNs into safety-critical applications, testing\napproaches for such models have gained more attention. A current direction is\nthe search for and identification of systematic weaknesses that put safety\nassumptions based on average performance values at risk. Such weaknesses can\ntake on the form of (semantically coherent) subsets or areas in the input space\nwhere a DNN performs systematically worse than its expected average. However,\nit is non-trivial to attribute the reason for such observed low performances to\nthe specific semantic features that describe the subset. For instance,\ninhomogeneities within the data w.r.t. other (non-considered) attributes might\ndistort results. However, taking into account all (available) attributes and\ntheir interaction is often computationally highly expensive. Inspired by\ncounterfactual explanations, we propose an effective and computationally cheap\nalgorithm to validate the semantic attribution of existing subsets, i.e., to\ncheck whether the identified attribute is likely to have caused the degraded\nperformance. We demonstrate this approach on an example from the autonomous\ndriving domain using highly annotated simulated data, where we show for a\nsemantic segmentation model that (i) performance differences among the\ndifferent pedestrian assets exist, but (ii) only in some cases is the asset\ntype itself the reason for this reduction in the performance.",
          "link": "http://arxiv.org/abs/2308.01614",
          "publishedOn": "2023-08-05T00:48:25.882Z",
          "wordCount": 722,
          "title": "Assessing Systematic Weaknesses of DNNs using Counterfactuals. (arXiv:2308.01614v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yeonghun Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jihan Kim</a>",
          "description": "ChatMOF is an autonomous Artificial Intelligence (AI) system that is built to\npredict and generate of metal-organic frameworks (MOFs). By leveraging a\nlarge-scale language model (gpt-3.5-turbo), ChatMOF extracts key details from\ntextual inputs and delivers appropriate responses, thus eliminating the\nnecessity for rigid structured queries. The system is comprised of three core\ncomponents (i.e. an agent, a toolkit, and an evaluator) and it forms a robust\npipeline that manages a variety of tasks, including data retrieval, property\nprediction, and structure generation. The study further explores the merits and\nconstraints of using large language models (LLMs) AI system in material\nsciences using and showcases its transformative potential for future\nadvancements.",
          "link": "http://arxiv.org/abs/2308.01423",
          "publishedOn": "2023-08-05T00:48:25.875Z",
          "wordCount": 625,
          "title": "ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks. (arXiv:2308.01423v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jessy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yuqing Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1\">Olivia Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafner_D/0/1/0/all/0/1\">Danijar Hafner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca Dragan</a>",
          "description": "To interact with humans in the world, agents need to understand the diverse\ntypes of language that people use, relate them to the visual world, and act\nbased on them. While current agents learn to execute simple language\ninstructions from task rewards, we aim to build agents that leverage diverse\nlanguage that conveys general knowledge, describes the state of the world,\nprovides interactive feedback, and more. Our key idea is that language helps\nagents predict the future: what will be observed, how the world will behave,\nand which situations will be rewarded. This perspective unifies language\nunderstanding with future prediction as a powerful self-supervised learning\nobjective. We present Dynalang, an agent that learns a multimodal world model\nthat predicts future text and image representations and learns to act from\nimagined model rollouts. Unlike traditional agents that use language only to\npredict actions, Dynalang acquires rich language understanding by using past\nlanguage also to predict future language, video, and rewards. In addition to\nlearning from online interaction in an environment, Dynalang can be pretrained\non datasets of text, video, or both without actions or rewards. From using\nlanguage hints in grid worlds to navigating photorealistic scans of homes,\nDynalang utilizes diverse types of language to improve task performance,\nincluding environment descriptions, game rules, and instructions.",
          "link": "http://arxiv.org/abs/2308.01399",
          "publishedOn": "2023-08-05T00:48:25.869Z",
          "wordCount": 725,
          "title": "Learning to Model the World with Language. (arXiv:2308.01399v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Ping Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Ximeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1\">Stan Sclaroff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "Multi-label image recognition in the low-label regime is a task of great\nchallenge and practical significance. Previous works have focused on learning\nthe alignment between textual and visual spaces to compensate for limited image\nlabels, yet may suffer from reduced accuracy due to the scarcity of\nhigh-quality multi-label annotations. In this research, we leverage the\npowerful alignment between textual and visual features pretrained with millions\nof auxiliary image-text pairs. We introduce an efficient and effective\nframework called Evidence-guided Dual Context Optimization (DualCoOp++), which\nserves as a unified approach for addressing partial-label and zero-shot\nmulti-label recognition. In DualCoOp++ we separately encode evidential,\npositive, and negative contexts for target classes as parametric components of\nthe linguistic input (i.e., prompts). The evidential context aims to discover\nall the related visual content for the target class, and serves as guidance to\naggregate positive and negative contexts from the spatial domain of the image,\nenabling better distinguishment between similar categories. Additionally, we\nintroduce a Winner-Take-All module that promotes inter-class interaction during\ntraining, while avoiding the need for extra parameters and costs. As DualCoOp++\nimposes minimal additional learnable overhead on the pretrained vision-language\nframework, it enables rapid adaptation to multi-label recognition tasks with\nlimited annotations and even unseen classes. Experiments on standard\nmulti-label recognition benchmarks across two challenging low-label settings\ndemonstrate the superior performance of our approach compared to\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2308.01890",
          "publishedOn": "2023-08-05T00:48:25.851Z",
          "wordCount": 775,
          "title": "DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations. (arXiv:2308.01890v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01389",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_J/0/1/0/all/0/1\">Jumman Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momtaz_M/0/1/0/all/0/1\">Maliha Momtaz</a>",
          "description": "Nowadays, autonomous cars are gaining traction due to their numerous\npotential applications on battlefields and in resolving a variety of other\nreal-world challenges. The main goal of our project is to build an autonomous\nsystem using DeepRacer which will follow a specific person (for our project, a\nsoldier) when they will be moving in any direction. Two main components to\naccomplish this project is an optimized Single-Shot Multibox Detection (SSD)\nobject detection model and a Reinforcement Learning (RL) model. We accomplished\nthe task using SSD Lite instead of SSD and at the end, compared the results\namong SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental\nresults show that SSD Lite gives better performance among these three\ntechniques and exhibits a considerable boost in inference speed (~2-3 times)\nwithout compromising accuracy.",
          "link": "http://arxiv.org/abs/2308.01389",
          "publishedOn": "2023-08-05T00:48:25.846Z",
          "wordCount": 642,
          "title": "Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning. (arXiv:2308.01389v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brignac_D/0/1/0/all/0/1\">Daniel Brignac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lobo_N/0/1/0/all/0/1\">Niels Lobo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahalanobis_A/0/1/0/all/0/1\">Abhijit Mahalanobis</a>",
          "description": "Continual learning seeks to enable deep learners to train on a series of\ntasks of unknown length without suffering from the catastrophic forgetting of\nprevious tasks. One effective solution is replay, which involves storing few\nprevious experiences in memory and replaying them when learning the current\ntask. However, there is still room for improvement when it comes to selecting\nthe most informative samples for storage and determining the optimal number of\nsamples to be stored. This study aims to address these issues with a novel\ncomparison of the commonly used reservoir sampling to various alternative\npopulation strategies and providing a novel detailed analysis of how to find\nthe optimal number of stored samples.",
          "link": "http://arxiv.org/abs/2308.01895",
          "publishedOn": "2023-08-05T00:48:25.840Z",
          "wordCount": 632,
          "title": "Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning. (arXiv:2308.01895v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jong Moon Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fink_O/0/1/0/all/0/1\">Olga Fink</a>",
          "description": "Extensive research has been conducted on fault diagnosis of planetary\ngearboxes using vibration signals and deep learning (DL) approaches. However,\nDL-based methods are susceptible to the domain shift problem caused by varying\noperating conditions of the gearbox. Although domain adaptation and data\nsynthesis methods have been proposed to overcome such domain shifts, they are\noften not directly applicable in real-world situations where only healthy data\nis available in the target domain. To tackle the challenge of extreme domain\nshift scenarios where only healthy data is available in the target domain, this\npaper proposes two novel domain knowledge-informed data synthesis methods\nutilizing the health data map (HDMap). The two proposed approaches are referred\nto as scaled CutPaste and FaultPaste. The HDMap is used to physically represent\nthe vibration signal of the planetary gearbox as an image-like matrix, allowing\nfor visualization of fault-related features. CutPaste and FaultPaste are then\napplied to generate faulty samples based on the healthy data in the target\ndomain, using domain knowledge and fault signatures extracted from the source\ndomain, respectively. In addition to generating realistic faults, the proposed\nmethods introduce scaling of fault signatures for controlled synthesis of\nfaults with various severity levels. A case study is conducted on a planetary\ngearbox testbed to evaluate the proposed approaches. The results show that the\nproposed methods are capable of accurately diagnosing faults, even in cases of\nextreme domain shift, and can estimate the severity of faults that have not\nbeen previously observed in the target domain.",
          "link": "http://arxiv.org/abs/2305.19569",
          "publishedOn": "2023-08-05T00:48:25.834Z",
          "wordCount": 840,
          "title": "Domain knowledge-informed Synthetic fault sample generation with Health Data Map for cross-domain Planetary Gearbox Fault Diagnosis. (arXiv:2305.19569v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01475",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Allen_G/0/1/0/all/0/1\">Genevera I. Allen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gan_L/0/1/0/all/0/1\">Luqin Gan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_L/0/1/0/all/0/1\">Lili Zheng</a>",
          "description": "New technologies have led to vast troves of large and complex datasets across\nmany scientific domains and industries. People routinely use machine learning\ntechniques to not only process, visualize, and make predictions from this big\ndata, but also to make data-driven discoveries. These discoveries are often\nmade using Interpretable Machine Learning, or machine learning models and\ntechniques that yield human understandable insights. In this paper, we discuss\nand review the field of interpretable machine learning, focusing especially on\nthe techniques as they are often employed to generate new knowledge or make\ndiscoveries from large data sets. We outline the types of discoveries that can\nbe made using Interpretable Machine Learning in both supervised and\nunsupervised settings. Additionally, we focus on the grand challenge of how to\nvalidate these discoveries in a data-driven manner, which promotes trust in\nmachine learning systems and reproducibility in science. We discuss validation\nfrom both a practical perspective, reviewing approaches based on data-splitting\nand stability, as well as from a theoretical perspective, reviewing statistical\nresults on model selection consistency and uncertainty quantification via\nstatistical inference. Finally, we conclude by highlighting open challenges in\nusing interpretable machine learning techniques to make discoveries, including\ngaps between theory and practice for validating data-driven-discoveries.",
          "link": "http://arxiv.org/abs/2308.01475",
          "publishedOn": "2023-08-05T00:48:25.826Z",
          "wordCount": 709,
          "title": "Interpretable Machine Learning for Discovery: Statistical Challenges \\& Opportunities. (arXiv:2308.01475v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eykholt_K/0/1/0/all/0/1\">Kevin Eykholt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Taesung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schales_D/0/1/0/all/0/1\">Douglas Schales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jiyong Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1\">Ian Molloy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zorin_M/0/1/0/all/0/1\">Masha Zorin</a>",
          "description": "Machine learning models are known to be vulnerable to adversarial evasion\nattacks as illustrated by image classification models. Thoroughly understanding\nsuch attacks is critical in order to ensure the safety and robustness of\ncritical AI tasks. However, most evasion attacks are difficult to deploy\nagainst a majority of AI systems because they have focused on image domain with\nonly few constraints. An image is composed of homogeneous, numerical,\ncontinuous, and independent features, unlike many other input types to AI\nsystems used in practice. Furthermore, some input types include additional\nsemantic and functional constraints that must be observed to generate realistic\nadversarial inputs. In this work, we propose a new framework to enable the\ngeneration of adversarial inputs irrespective of the input type and task\ndomain. Given an input and a set of pre-defined input transformations, our\nframework discovers a sequence of transformations that result in a semantically\ncorrect and functional adversarial input. We demonstrate the generality of our\napproach on several diverse machine learning tasks with various input\nrepresentations. We also show the importance of generating adversarial examples\nas they enable the deployment of mitigation techniques.",
          "link": "http://arxiv.org/abs/2308.01840",
          "publishedOn": "2023-08-05T00:48:25.816Z",
          "wordCount": 701,
          "title": "URET: Universal Robustness Evaluation Toolkit (for Evasion). (arXiv:2308.01840v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2106.03395",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "As neural networks become more popular, the need for accompanying uncertainty\nestimates increases. There are currently two main approaches to test the\nquality of these estimates. Most methods output a density. They can be compared\nby evaluating their loglikelihood on a test set. Other methods output a\nprediction interval directly. These methods are often tested by examining the\nfraction of test points that fall inside the corresponding prediction\nintervals. Intuitively both approaches seem logical. However, we demonstrate\nthrough both theoretical arguments and simulations that both ways of evaluating\nthe quality of uncertainty estimates have serious flaws. Firstly, both\napproaches cannot disentangle the separate components that jointly create the\npredictive uncertainty, making it difficult to evaluate the quality of the\nestimates of these components. Secondly, a better loglikelihood does not\nguarantee better prediction intervals, which is what the methods are often used\nfor in practice. Moreover, the current approach to test prediction intervals\ndirectly has additional flaws. We show why it is fundamentally flawed to test a\nprediction or confidence interval on a single test set. At best, marginal\ncoverage is measured, implicitly averaging out overconfident and underconfident\npredictions. A much more desirable property is pointwise coverage, requiring\nthe correct coverage for each prediction. We demonstrate through practical\nexamples that these effects can result in favoring a method, based on the\npredictive uncertainty, that has undesirable behaviour of the confidence or\nprediction intervals. Finally, we propose a simulation-based testing approach\nthat addresses these problems while still allowing easy comparison between\ndifferent methods.",
          "link": "http://arxiv.org/abs/2106.03395",
          "publishedOn": "2023-08-05T00:48:25.798Z",
          "wordCount": 778,
          "title": "How to Evaluate Uncertainty Estimates in Machine Learning for Regression?. (arXiv:2106.03395v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.02060",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stone_I/0/1/0/all/0/1\">Iris R. Stone</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sagiv_Y/0/1/0/all/0/1\">Yotam Sagiv</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_I/0/1/0/all/0/1\">Il Memming Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillow_J/0/1/0/all/0/1\">Jonathan W. Pillow</a>",
          "description": "Latent linear dynamical systems with Bernoulli observations provide a\npowerful modeling framework for identifying the temporal dynamics underlying\nbinary time series data, which arise in a variety of contexts such as binary\ndecision-making and discrete stochastic processes (e.g., binned neural spike\ntrains). Here we develop a spectral learning method for fast, efficient fitting\nof probit-Bernoulli latent linear dynamical system (LDS) models. Our approach\nextends traditional subspace identification methods to the Bernoulli setting\nvia a transformation of the first and second sample moments. This results in a\nrobust, fixed-cost estimator that avoids the hazards of local optima and the\nlong computation time of iterative fitting procedures like the\nexpectation-maximization (EM) algorithm. In regimes where data is limited or\nassumptions about the statistical structure of the data are not met, we\ndemonstrate that the spectral estimate provides a good initialization for\nLaplace-EM fitting. Finally, we show that the estimator provides substantial\nbenefits to real world settings by analyzing data from mice performing a\nsensory decision-making task.",
          "link": "http://arxiv.org/abs/2303.02060",
          "publishedOn": "2023-07-29T00:48:57.654Z",
          "wordCount": null,
          "title": "Spectral learning of Bernoulli linear dynamical systems models. (arXiv:2303.02060v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.13381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yingtian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vikas Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1\">Sarthak Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wai Hoh Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1\">Juho Kannala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solin_A/0/1/0/all/0/1\">Arno Solin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>",
          "description": "Mixup is a popular data augmentation technique for training deep neural\nnetworks where additional samples are generated by linearly interpolating pairs\nof inputs and their labels. This technique is known to improve the\ngeneralization performance in many learning paradigms and applications. In this\nwork, we first analyze Mixup and show that it implicitly regularizes infinitely\nmany directional derivatives of all orders. Based on this new insight, we\npropose an improved version of Mixup, theoretically justified to deliver better\ngeneralization performance than the vanilla Mixup. To demonstrate the\neffectiveness of the proposed method, we conduct experiments across various\ndomains such as images, tabular data, speech, and graphs. Our results show that\nthe proposed method improves Mixup across multiple datasets using a variety of\narchitectures, for instance, exhibiting an improvement over Mixup by 0.8% in\nImageNet top-1 accuracy.",
          "link": "http://arxiv.org/abs/2212.13381",
          "publishedOn": "2023-07-29T00:48:57.653Z",
          "wordCount": null,
          "title": "MixupE: Understanding and Improving Mixup from Directional Derivative Perspective. (arXiv:2212.13381v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkataramanan_A/0/1/0/all/0/1\">Aishwarya Venkataramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benbihi_A/0/1/0/all/0/1\">Assia Benbihi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laviale_M/0/1/0/all/0/1\">Martin Laviale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pradalier_C/0/1/0/all/0/1\">Cedric Pradalier</a>",
          "description": "Recent works show that the data distribution in a network's latent space is\nuseful for estimating classification uncertainty and detecting\nOut-of-distribution (OOD) samples. To obtain a well-regularized latent space\nthat is conducive for uncertainty estimation, existing methods bring in\nsignificant changes to model architectures and training procedures. In this\npaper, we present a lightweight, fast, and high-performance regularization\nmethod for Mahalanobis distance-based uncertainty prediction, and that requires\nminimal changes to the network's architecture. To derive Gaussian latent\nrepresentation favourable for Mahalanobis Distance calculation, we introduce a\nself-supervised representation learning method that separates in-class\nrepresentations into multiple Gaussians. Classes with non-Gaussian\nrepresentations are automatically identified and dynamically clustered into\nmultiple new classes that are approximately Gaussian. Evaluation on standard\nOOD benchmarks shows that our method achieves state-of-the-art results on OOD\ndetection with minimal inference time, and is very competitive on predictive\nprobability calibration. Finally, we show the applicability of our method to a\nreal-life computer vision use case on microorganism classification.",
          "link": "http://arxiv.org/abs/2305.13849",
          "publishedOn": "2023-07-29T00:48:57.653Z",
          "wordCount": null,
          "title": "Gaussian Latent Representations for Uncertainty Estimation using Mahalanobis Distance in Deep Classifiers. (arXiv:2305.13849v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.10045",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lin_Y/0/1/0/all/0/1\">Yuchao Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yan_K/0/1/0/all/0/1\">Keqiang Yan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Luo_Y/0/1/0/all/0/1\">Youzhi Luo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Qian_X/0/1/0/all/0/1\">Xiaoning Qian</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>",
          "description": "We study property prediction for crystal materials. A crystal structure\nconsists of a minimal unit cell that is repeated infinitely in 3D space. How to\naccurately represent such repetitive structures in machine learning models\nremains unresolved. Current methods construct graphs by establishing edges only\nbetween nearby nodes, thereby failing to faithfully capture infinite repeating\npatterns and distant interatomic interactions. In this work, we propose several\ninnovations to overcome these limitations. First, we propose to model\nphysics-principled interatomic potentials directly instead of only using\ndistances as in many existing methods. These potentials include the Coulomb\npotential, London dispersion potential, and Pauli repulsion potential. Second,\nwe model the complete set of potentials among all atoms, instead of only\nbetween nearby atoms as in existing methods. This is enabled by our\napproximations of infinite potential summations with provable error bounds. We\nfurther develop efficient algorithms to compute the approximations. Finally, we\npropose to incorporate our computations of complete interatomic potentials into\nmessage passing neural networks for representation learning. We perform\nexperiments on the JARVIS and Materials Project benchmarks for evaluation.\nResults show that the use of interatomic potentials and complete interatomic\npotentials leads to consistent performance improvements with reasonable\ncomputational costs. Our code is publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS/tree/main/OpenMat/PotNet).",
          "link": "http://arxiv.org/abs/2306.10045",
          "publishedOn": "2023-07-29T00:48:57.653Z",
          "wordCount": null,
          "title": "Efficient Approximations of Complete Interatomic Potentials for Crystal Property Prediction. (arXiv:2306.10045v7 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianing Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yilin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wei Zeng</a>",
          "description": "Deep learning (DL) approaches are being increasingly used for time-series\nforecasting, with many efforts devoted to designing complex DL models. Recent\nstudies have shown that the DL success is often attributed to effective data\nrepresentations, fostering the fields of feature engineering and representation\nlearning. However, automated approaches for feature learning are typically\nlimited with respect to incorporating prior knowledge, identifying interactions\namong variables, and choosing evaluation metrics to ensure that the models are\nreliable. To improve on these limitations, this paper contributes a novel\nvisual analytics framework, namely TimeTuner, designed to help analysts\nunderstand how model behaviors are associated with localized correlations,\nstationarity, and granularity of time-series representations. The system mainly\nconsists of the following two-stage technique: We first leverage counterfactual\nexplanations to connect the relationships among time-series representations,\nmultivariate features and model predictions. Next, we design multiple\ncoordinated views including a partition-based correlation matrix and juxtaposed\nbivariate stripes, and provide a set of interactions that allow users to step\ninto the transformation selection process, navigate through the feature space,\nand reason the model performance. We instantiate TimeTuner with two\ntransformation methods of smoothing and sampling, and demonstrate its\napplicability on real-world time-series forecasting of univariate sunspots and\nmultivariate air pollutants. Feedback from domain experts indicates that our\nsystem can help characterize time-series representations and guide the feature\nengineering processes.",
          "link": "http://arxiv.org/abs/2307.09916",
          "publishedOn": "2023-07-29T00:48:57.652Z",
          "wordCount": null,
          "title": "TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations. (arXiv:2307.09916v3 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaixin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yabin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_C/0/1/0/all/0/1\">Chang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Donghua Yang</a>",
          "description": "Learned cardinality estimation methods have achieved high precision compared\nto traditional methods. Among learned methods, query-driven approaches face the\ndata and workload drift problem for a long time. Although both query-driven and\nhybrid methods are proposed to avoid this problem, even the state-of-art of\nthem suffer from high training and estimation costs, limited scalability,\ninstability, and long-tailed distribution problem on high cardinality and high\ndimensional tables, which seriously affects the practical application of\nlearned cardinality estimators. In this paper, we prove that most of these\nproblems are directly caused by the widely used progressive sampling. We solve\nthis problem by introducing predicates into the autoregressive model and\npropose Duet, a stable, efficient, and scalable hybrid method to estimate\ncardinality directly without sampling or any non-differentiable process, which\ncan not only reduces the inference complexity from $O(n)$ to $O(1)$ compared to\nNaru and UAE but also achieve higher accuracy on high cardinality and high\ndimensional tables. Experimental results show that Duet can achieve all the\ndesign goals above and be much more practical and even has a lower inference\ncost on CPU than that of most learned methods on GPU.",
          "link": "http://arxiv.org/abs/2307.13494",
          "publishedOn": "2023-07-29T00:48:57.652Z",
          "wordCount": null,
          "title": "Duet: efficient and scalable hybriD neUral rElation undersTanding. (arXiv:2307.13494v3 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brahman_F/0/1/0/all/0/1\">Faeze Brahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena D. Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lorraine Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arai_H/0/1/0/all/0/1\">Hirona J. Arai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanyal_S/0/1/0/all/0/1\">Soumya Sanyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaguchi_K/0/1/0/all/0/1\">Keisuke Sakaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "Procedural planning, which entails decomposing a high-level goal into a\nsequence of temporally ordered steps, is an important yet intricate task for\nmachines. It involves integrating common-sense knowledge to reason about\ncomplex contextualized situations that are often counterfactual, e.g.\n\"scheduling a doctor's appointment without a phone\". While current approaches\nshow encouraging results using large language models (LLMs), they are hindered\nby drawbacks such as costly API calls and reproducibility issues. In this\npaper, we advocate planning using smaller language models. We present PlaSma, a\nnovel two-pronged approach to endow small language models with procedural\nknowledge and (counterfactual) planning capabilities. More concretely, we\ndevelop symbolic procedural knowledge distillation to enhance the implicit\nknowledge in small language models and an inference-time algorithm to\nfacilitate more structured and accurate reasoning. In addition, we introduce a\nnovel task, Counterfactual Planning, that requires a revision of a plan to cope\nwith a counterfactual situation. In both the original and counterfactual\nsetting, we show that orders-of-magnitude smaller models (770M-11B parameters)\ncan compete and often surpass their larger teacher models' capabilities.",
          "link": "http://arxiv.org/abs/2305.19472",
          "publishedOn": "2023-07-29T00:48:57.651Z",
          "wordCount": null,
          "title": "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning. (arXiv:2305.19472v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Close_G/0/1/0/all/0/1\">George Close</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goetze_S/0/1/0/all/0/1\">Stefan Goetze</a>",
          "description": "Self-supervised speech representations (SSSRs) have been successfully applied\nto a number of speech-processing tasks, e.g. as feature extractor for speech\nquality (SQ) prediction, which is, in turn, relevant for assessment and\ntraining speech enhancement systems for users with normal or impaired hearing.\nHowever, exact knowledge of why and how quality-related information is encoded\nwell in such representations remains poorly understood. In this work,\ntechniques for non-intrusive prediction of SQ ratings are extended to the\nprediction of intelligibility for hearing-impaired users. It is found that\nself-supervised representations are useful as input features to non-intrusive\nprediction models, achieving competitive performance to more complex systems. A\ndetailed analysis of the performance depending on Clarity Prediction Challenge\n1 listeners and enhancement systems indicates that more data might be needed to\nallow generalisation to unknown systems and (hearing-impaired) individuals",
          "link": "http://arxiv.org/abs/2307.13423",
          "publishedOn": "2023-07-29T00:48:57.651Z",
          "wordCount": null,
          "title": "Non Intrusive Intelligibility Predictor for Hearing Impaired Individuals using Self Supervised Speech Representations. (arXiv:2307.13423v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frick_R/0/1/0/all/0/1\">Raphael Frick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_I/0/1/0/all/0/1\">Inna Vogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jeong-Eun Choi</a>",
          "description": "This paper describes the second-placed approach developed by the Fraunhofer\nSIT team in the CLEF-2023 CheckThat! lab Task 1B for English. Given a text\nsnippet from a political debate, the aim of this task is to determine whether\nit should be assessed for check-worthiness. Detecting check-worthy statements\naims to facilitate manual fact-checking efforts by prioritizing the claims that\nfact-checkers should consider first. It can also be considered as primary step\nof a fact-checking system. Our best-performing method took advantage of an\nensemble classification scheme centered on Model Souping. When applied to the\nEnglish data set, our submitted model achieved an overall F1 score of 0.878 and\nwas ranked as the second-best model in the competition.",
          "link": "http://arxiv.org/abs/2307.02377",
          "publishedOn": "2023-07-29T00:48:57.582Z",
          "wordCount": null,
          "title": "Fraunhofer SIT at CheckThat! 2023: Tackling Classification Uncertainty Using Model Souping on the Example of Check-Worthiness Classification. (arXiv:2307.02377v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anpei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zexiang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xinyue Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Andreas Geiger</a>",
          "description": "We present Factor Fields, a novel framework for modeling and representing\nsignals. Factor Fields decomposes a signal into a product of factors, each\nrepresented by a classical or neural field representation which operates on\ntransformed input coordinates. This decomposition results in a unified\nframework that accommodates several recent signal representations including\nNeRF, Plenoxels, EG3D, Instant-NGP, and TensoRF. Additionally, our framework\nallows for the creation of powerful new signal representations, such as the\n\"Dictionary Field\" (DiF) which is a second contribution of this paper. Our\nexperiments show that DiF leads to improvements in approximation quality,\ncompactness, and training time when compared to previous fast reconstruction\nmethods. Experimentally, our representation achieves better image approximation\nquality on 2D image regression tasks, higher geometric quality when\nreconstructing 3D signed distance fields, and higher compactness for radiance\nfield reconstruction tasks. Furthermore, DiF enables generalization to unseen\nimages/3D scenes by sharing bases across signals during training which greatly\nbenefits use cases such as image regression from sparse observations and\nfew-shot radiance field reconstruction.",
          "link": "http://arxiv.org/abs/2302.01226",
          "publishedOn": "2023-07-29T00:48:57.581Z",
          "wordCount": null,
          "title": "Factor Fields: A Unified Framework for Neural Fields and Beyond. (arXiv:2302.01226v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frick_R/0/1/0/all/0/1\">Raphael Frick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_I/0/1/0/all/0/1\">Inna Vogel</a>",
          "description": "The option of sharing images, videos and audio files on social media opens up\nnew possibilities for distinguishing between false information and fake news on\nthe Internet. Due to the vast amount of data shared every second on social\nmedia, not all data can be verified by a computer or a human expert. Here, a\ncheck-worthiness analysis can be used as a first step in the fact-checking\npipeline and as a filtering mechanism to improve efficiency. This paper\nproposes a novel way of detecting the check-worthiness in multi-modal tweets.\nIt takes advantage of two classifiers, each trained on a single modality. For\nimage data, extracting the embedded text with an OCR analysis has shown to\nperform best. By combining the two classifiers, the proposed solution was able\nto place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297\nachieved on the private test set.",
          "link": "http://arxiv.org/abs/2307.00610",
          "publishedOn": "2023-07-29T00:48:57.581Z",
          "wordCount": null,
          "title": "Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to Estimate the Check-Worthiness of Multi-Modal Tweets. (arXiv:2307.00610v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03811",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Sharma_V/0/1/0/all/0/1\">Vidushi Sharma</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Giammona_M/0/1/0/all/0/1\">Maxwell Giammona</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zubarev_D/0/1/0/all/0/1\">Dmitry Zubarev</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tek_A/0/1/0/all/0/1\">Andy Tek</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Nugyuen_K/0/1/0/all/0/1\">Khanh Nugyuen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sundberg_L/0/1/0/all/0/1\">Linda Sundberg</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Congiu_D/0/1/0/all/0/1\">Daniele Congiu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+La_Y/0/1/0/all/0/1\">Young-Hye La</a>",
          "description": "Advanced computational methods are being actively sought for addressing the\nchallenges associated with discovery and development of new combinatorial\nmaterial such as formulations. A widely adopted approach involves domain\ninformed high-throughput screening of individual components that can be\ncombined into a formulation. This manages to accelerate the discovery of new\ncompounds for a target application but still leave the process of identifying\nthe right 'formulation' from the shortlisted chemical space largely a\nlaboratory experiment-driven process. We report a deep learning model,\nFormulation Graph Convolution Network (F-GCN), that can map\nstructure-composition relationship of the individual components to the property\nof liquid formulation as whole. Multiple GCNs are assembled in parallel that\nfeaturize formulation constituents domain-intuitively on the fly. The resulting\nmolecular descriptors are scaled based on respective constituent's molar\npercentage in the formulation, followed by formalizing into a combined\ndescriptor that represents a complete formulation to an external learning\narchitecture. The use case of proposed formulation learning model is\ndemonstrated for battery electrolytes by training and testing it on two\nexemplary datasets representing electrolyte formulations vs battery performance\n-- one dataset is sourced from literature about Li/Cu half-cells, while the\nother is obtained by lab-experiments related to lithium-iodide full-cell\nchemistry. The model is shown to predict the performance metrics like Coulombic\nEfficiency (CE) and specific capacity of new electrolyte formulations with\nlowest reported errors. The best performing F-GCN model uses molecular\ndescriptors derived from molecular graphs that are informed with HOMO-LUMO and\nelectric moment properties of the molecules using a knowledge transfer\ntechnique.",
          "link": "http://arxiv.org/abs/2307.03811",
          "publishedOn": "2023-07-29T00:48:57.581Z",
          "wordCount": null,
          "title": "Formulation Graphs for Mapping Structure-Composition of Battery Electrolytes to Device Performance. (arXiv:2307.03811v2 [cond-mat.mtrl-sci] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.09246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dostal_L/0/1/0/all/0/1\">Leo Dostal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bespalko_A/0/1/0/all/0/1\">Alexej Bespalko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duecker_D/0/1/0/all/0/1\">Daniel A. Duecker</a>",
          "description": "We present computational and experimental results on how artificial\nintelligence (AI) learns to control an Acrobot using reinforcement learning\n(RL). Thereby the experimental setup is designed as an embedded system, which\nis of interest for robotics and energy harvesting applications. Specifically,\nwe study the control of angular velocity of the Acrobot, as well as control of\nits total energy, which is the sum of the kinetic and the potential energy. By\nthis means the RL algorithm is designed to drive the angular velocity or the\nenergy of the first pendulum of the Acrobot towards a desired value. With this,\nlibration or full rotation of the unactuated pendulum of the Acrobot is\nachieved. Moreover, investigations of the Acrobot control are carried out,\nwhich lead to insights about the influence of the state space discretization,\nthe episode length, the action space or the mass of the driven pendulum on the\nRL control. By further numerous simulations and experiments the effects of\nparameter variations are evaluated.",
          "link": "http://arxiv.org/abs/2011.09246",
          "publishedOn": "2023-07-29T00:48:57.580Z",
          "wordCount": null,
          "title": "Experimental Study on Reinforcement Learning-based Control of an Acrobot. (arXiv:2011.09246v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujii_S/0/1/0/all/0/1\">Satoru Fujii</a>",
          "description": "Many properties in the real world, such as desirability or strength in\ncompetitive environment, can't be directly observed, which makes them difficult\nto evaluate. To deal with this challenging problem, prior works have primarily\nfocused on estimating those properties of known items, especially the strength\nof sports players, only of those who appears in paired comparison dataset. In\nthis paper, we introduce Deep Bradley-Terry Rating (DBTR), a novel ML framework\nto evaluate any properties of unknown items, not necessarily present in the\ntraining data. Our method seamlessly integrates traditional Bradley-Terry model\nwith a neural network structure. We also generalizes this architecture further\nfor asymmetric environment with unfairness, which is much more common in real\nworld settings. In our experimental analysis, DBTR successfully learned desired\nquantification of those properties.",
          "link": "http://arxiv.org/abs/2307.13709",
          "publishedOn": "2023-07-29T00:48:57.580Z",
          "wordCount": null,
          "title": "Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items. (arXiv:2307.13709v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.01462",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Koutny_D/0/1/0/all/0/1\">Dominik Koutn&#xfd;</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gines_L/0/1/0/all/0/1\">Laia Gin&#xe9;s</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Moczala_Dusanowska_M/0/1/0/all/0/1\">Magdalena Mocza&#x142;a-Dusanowska</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Hofling_S/0/1/0/all/0/1\">Sven H&#xf6;fling</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Schneider_C/0/1/0/all/0/1\">Christian Schneider</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Predojevic_A/0/1/0/all/0/1\">Ana Predojevi&#x107;</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jezek_M/0/1/0/all/0/1\">Miroslav Je&#x17e;ek</a>",
          "description": "The quantification of the entanglement present in a physical system is of\npara\\-mount importance for fundamental research and many cutting-edge\napplications. Currently, achieving this goal requires either a priori knowledge\non the system or very demanding experimental procedures such as full state\ntomography or collective measurements. Here, we demonstrate that by employing\nneural networks we can quantify the degree of entanglement without needing to\nknow the full description of the quantum state. Our method allows for direct\nquantification of the quantum correlations using an incomplete set of local\nmeasurements. Despite using undersampled measurements, we achieve a\nquantification error of up to an order of magnitude lower than the\nstate-of-the-art quantum tomography. Furthermore, we achieve this result\nemploying networks trained using exclusively simulated data. Finally, we derive\na method based on a convolutional network input that can accept data from\nvarious measurement scenarios and perform, to some extent, independently of the\nmeasurement device.",
          "link": "http://arxiv.org/abs/2205.01462",
          "publishedOn": "2023-07-29T00:48:57.580Z",
          "wordCount": null,
          "title": "Deep learning of quantum entanglement from incomplete measurements. (arXiv:2205.01462v6 [quant-ph] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.10291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Derezinski_M/0/1/0/all/0/1\">Micha&#x142; Derezi&#x144;ski</a>",
          "description": "Algorithmic Gaussianization is a phenomenon that can arise when using\nrandomized sketching or sampling methods to produce smaller representations of\nlarge datasets: For certain tasks, these sketched representations have been\nobserved to exhibit many robust performance characteristics that are known to\noccur when a data sample comes from a sub-gaussian random design, which is a\npowerful statistical model of data distributions. However, this phenomenon has\nonly been studied for specific tasks and metrics, or by relying on\ncomputationally expensive methods. We address this by providing an algorithmic\nframework for gaussianizing data distributions via averaging, proving that it\nis possible to efficiently construct data sketches that are nearly\nindistinguishable (in terms of total variation distance) from sub-gaussian\nrandom designs. In particular, relying on a recently introduced sketching\ntechnique called Leverage Score Sparsified (LESS) embeddings, we show that one\ncan construct an $n\\times d$ sketch of an $N\\times d$ matrix $A$, where $n\\ll\nN$, that is nearly indistinguishable from a sub-gaussian design, in time\n$O(\\text{nnz}(A)\\log N + nd^2)$, where $\\text{nnz}(A)$ is the number of\nnon-zero entries in $A$. As a consequence, strong statistical guarantees and\nprecise asymptotics available for the estimators produced from sub-gaussian\ndesigns (e.g., for least squares and Lasso regression, covariance estimation,\nlow-rank approximation, etc.) can be straightforwardly adapted to our sketching\nframework. We illustrate this with a new approximation guarantee for sketched\nleast squares, among other examples.",
          "link": "http://arxiv.org/abs/2206.10291",
          "publishedOn": "2023-07-29T00:48:57.579Z",
          "wordCount": null,
          "title": "Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs. (arXiv:2206.10291v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Helwig_J/0/1/0/all/0/1\">Jacob Helwig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Cong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtin_J/0/1/0/all/0/1\">Jerry Kurtin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>",
          "description": "We consider solving partial differential equations (PDEs) with Fourier neural\noperators (FNOs), which operate in the frequency domain. Since the laws of\nphysics do not depend on the coordinate system used to describe them, it is\ndesirable to encode such symmetries in the neural operator architecture for\nbetter performance and easier learning. While encoding symmetries in the\nphysical domain using group theory has been studied extensively, how to capture\nsymmetries in the frequency domain is under-explored. In this work, we extend\ngroup convolutions to the frequency domain and design Fourier layers that are\nequivariant to rotations, translations, and reflections by leveraging the\nequivariance property of the Fourier transform. The resulting $G$-FNO\narchitecture generalizes well across input resolutions and performs well in\nsettings with varying levels of symmetry. Our code is publicly available as\npart of the AIRS library (https://github.com/divelab/AIRS).",
          "link": "http://arxiv.org/abs/2306.05697",
          "publishedOn": "2023-07-29T00:48:57.579Z",
          "wordCount": null,
          "title": "Group Equivariant Fourier Neural Operators for Partial Differential Equations. (arXiv:2306.05697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.01669",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yangyang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingqiao Liu</a>",
          "description": "Self-supervised learning (SSL) strategies have demonstrated remarkable\nperformance in various recognition tasks. However, both our preliminary\ninvestigation and recent studies suggest that they may be less effective in\nlearning representations for fine-grained visual recognition (FGVR) since many\nfeatures helpful for optimizing SSL objectives are not suitable for\ncharacterizing the subtle differences in FGVR. To overcome this issue, we\npropose learning an additional screening mechanism to identify discriminative\nclues commonly seen across instances and classes, dubbed as common rationales\nin this paper. Intuitively, common rationales tend to correspond to the\ndiscriminative patterns from the key parts of foreground objects. We show that\na common rationale detector can be learned by simply exploiting the GradCAM\ninduced from the SSL objective without using any pre-trained object parts or\nsaliency detectors, making it seamlessly to be integrated with the existing SSL\nprocess. Specifically, we fit the GradCAM with a branch with limited fitting\ncapacity, which allows the branch to capture the common rationales and discard\nthe less common discriminative patterns. At the test stage, the branch\ngenerates a set of spatial weights to selectively aggregate features\nrepresenting an instance. Extensive experimental results on four visual tasks\ndemonstrate that the proposed method can lead to a significant improvement in\ndifferent evaluation settings.",
          "link": "http://arxiv.org/abs/2303.01669",
          "publishedOn": "2023-07-29T00:48:57.578Z",
          "wordCount": null,
          "title": "Learning Common Rationale to Improve Self-Supervised Representation for Fine-Grained Visual Recognition Problems. (arXiv:2303.01669v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.08944",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ohayon_G/0/1/0/all/0/1\">Guy Ohayon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adrai_T/0/1/0/all/0/1\">Theo Adrai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Elad_M/0/1/0/all/0/1\">Michael Elad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Michaeli_T/0/1/0/all/0/1\">Tomer Michaeli</a>",
          "description": "Stochastic restoration algorithms allow to explore the space of solutions\nthat correspond to the degraded input. In this paper we reveal additional\nfundamental advantages of stochastic methods over deterministic ones, which\nfurther motivate their use. First, we prove that any restoration algorithm that\nattains perfect perceptual quality and whose outputs are consistent with the\ninput must be a posterior sampler, and is thus required to be stochastic.\nSecond, we illustrate that while deterministic restoration algorithms may\nattain high perceptual quality, this can be achieved only by filling up the\nspace of all possible source images using an extremely sensitive mapping, which\nmakes them highly vulnerable to adversarial attacks. Indeed, we show that\nenforcing deterministic models to be robust to such attacks profoundly hinders\ntheir perceptual quality, while robustifying stochastic models hardly\ninfluences their perceptual quality, and improves their output variability.\nThese findings provide a motivation to foster progress in stochastic\nrestoration methods, paving the way to better recovery algorithms.",
          "link": "http://arxiv.org/abs/2211.08944",
          "publishedOn": "2023-07-29T00:48:57.577Z",
          "wordCount": null,
          "title": "Reasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality. (arXiv:2211.08944v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_A/0/1/0/all/0/1\">Agnimitra Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1\">Sudeepta Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Adway Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_S/0/1/0/all/0/1\">S. Ilgin Guler</a>",
          "description": "Deep-learning models for traffic data prediction can have superior\nperformance in modeling complex functions using a multi-layer architecture.\nHowever, a major drawback of these approaches is that most of these approaches\ndo not offer forecasts with uncertainty estimates, which are essential for\ntraffic operations and control. Without uncertainty estimates, it is difficult\nto place any level of trust to the model predictions, and operational\nstrategies relying on overconfident predictions can lead to worsening traffic\nconditions. In this study, we propose a Bayesian recurrent neural network\nframework for uncertainty quantification in traffic prediction with higher\ngeneralizability by introducing spectral normalization to its hidden layers. In\nour paper, we have shown that normalization alters the training process of deep\nneural networks by controlling the model's complexity and reducing the risk of\noverfitting to the training data. This, in turn, helps improve the\ngeneralization performance of the model on out-of-distribution datasets.\nResults demonstrate that spectral normalization improves uncertainty estimates\nand significantly outperforms both the layer normalization and model without\nnormalization in single-step prediction horizons. This improved performance can\nbe attributed to the ability of spectral normalization to better localize the\nfeature space of the data under perturbations. Our findings are especially\nrelevant to traffic management applications, where predicting traffic\nconditions across multiple locations is the goal, but the availability of\ntraining data from multiple locations is limited. Spectral normalization,\ntherefore, provides a more generalizable approach that can effectively capture\nthe underlying patterns in traffic data without requiring location-specific\nmodels.",
          "link": "http://arxiv.org/abs/2307.05946",
          "publishedOn": "2023-07-29T00:48:57.577Z",
          "wordCount": null,
          "title": "A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models. (arXiv:2307.05946v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.00052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_C/0/1/0/all/0/1\">Ching-Yun Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>",
          "description": "One powerful paradigm in visual navigation is to predict actions from\nobservations directly. Training such an end-to-end system allows\nrepresentations useful for downstream tasks to emerge automatically. However,\nthe lack of inductive bias makes this system data inefficient. We hypothesize a\nsufficient representation of the current view and the goal view for a\nnavigation policy can be learned by predicting the location and size of a crop\nof the current view that corresponds to the goal. We further show that training\nsuch random crop prediction in a self-supervised fashion purely on synthetic\nnoise images transfers well to natural home images. The learned representation\ncan then be bootstrapped to learn a navigation policy efficiently with little\ninteraction data. The code is available at https://yanweiw.github.io/noise2ptz",
          "link": "http://arxiv.org/abs/2207.00052",
          "publishedOn": "2023-07-29T00:48:57.576Z",
          "wordCount": null,
          "title": "Visual Pre-training for Navigation: What Can We Learn from Noise?. (arXiv:2207.00052v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rousseau_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my Rousseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaka_C/0/1/0/all/0/1\">Christian Alaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Covili_E/0/1/0/all/0/1\">Emma Covili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayard_H/0/1/0/all/0/1\">Hippolyte Mayard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misrachi_L/0/1/0/all/0/1\">Laura Misrachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Au_W/0/1/0/all/0/1\">Willy Au</a>",
          "description": "Medical radiography segmentation, and specifically dental radiography, is\nhighly limited by the cost of labeling which requires specific expertise and\nlabor-intensive annotations. In this work, we propose a straightforward\npre-training method for semantic segmentation leveraging Denoising Diffusion\nProbabilistic Models (DDPM), which have shown impressive results for generative\nmodeling. Our straightforward approach achieves remarkable performance in terms\nof label efficiency and does not require architectural modifications between\npre-training and downstream tasks. We propose to first pre-train a Unet by\nexploiting the DDPM training objective, and then fine-tune the resulting model\non a segmentation task. Our experimental results on the segmentation of dental\nradiographs demonstrate that the proposed method is competitive with\nstate-of-the-art pre-training methods.",
          "link": "http://arxiv.org/abs/2307.14066",
          "publishedOn": "2023-07-29T00:48:57.576Z",
          "wordCount": null,
          "title": "Pre-Training with Diffusion models for Dental Radiography segmentation. (arXiv:2307.14066v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.13624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiashuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zheyan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Renzhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>",
          "description": "Traditional machine learning paradigms are based on the assumption that both\ntraining and test data follow the same statistical pattern, which is\nmathematically referred to as Independent and Identically Distributed\n($i.i.d.$). However, in real-world applications, this $i.i.d.$ assumption often\nfails to hold due to unforeseen distributional shifts, leading to considerable\ndegradation in model performance upon deployment. This observed discrepancy\nindicates the significance of investigating the Out-of-Distribution (OOD)\ngeneralization problem. OOD generalization is an emerging topic of machine\nlearning research that focuses on complex scenarios wherein the distributions\nof the test data differ from those of the training data. This paper represents\nthe first comprehensive, systematic review of OOD generalization, encompassing\na spectrum of aspects from problem definition, methodological development, and\nevaluation procedures, to the implications and future directions of the field.\nOur discussion begins with a precise, formal characterization of the OOD\ngeneralization problem. Following that, we categorize existing methodologies\ninto three segments: unsupervised representation learning, supervised model\nlearning, and optimization, according to their positions within the overarching\nlearning process. We provide an in-depth discussion on representative\nmethodologies for each category, further elucidating the theoretical links\nbetween them. Subsequently, we outline the prevailing benchmark datasets\nemployed in OOD generalization studies. To conclude, we overview the existing\nbody of work in this domain and suggest potential avenues for future research\non OOD generalization. A summary of the OOD generalization methodologies\nsurveyed in this paper can be accessed at\nthis http URL",
          "link": "http://arxiv.org/abs/2108.13624",
          "publishedOn": "2023-07-29T00:48:57.575Z",
          "wordCount": null,
          "title": "Towards Out-Of-Distribution Generalization: A Survey. (arXiv:2108.13624v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Malinovskaya_A/0/1/0/all/0/1\">Anna Malinovskaya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Otto_P/0/1/0/all/0/1\">Philipp Otto</a>",
          "description": "The rapid advancement of models based on artificial intelligence demands\ninnovative monitoring techniques which can operate in real time with low\ncomputational costs. In machine learning, especially if we consider artificial\nneural networks (ANNs), the models are often trained in a supervised manner.\nConsequently, the learned relationship between the input and the output must\nremain valid during the model's deployment. If this stationarity assumption\nholds, we can conclude that the ANN provides accurate predictions. Otherwise,\nthe retraining or rebuilding of the model is required. We propose considering\nthe latent feature representation of the data (called \"embedding\") generated by\nthe ANN to determine the time when the data stream starts being nonstationary.\nIn particular, we monitor embeddings by applying multivariate control charts\nbased on the data depth calculation and normalized ranks. The performance of\nthe introduced method is compared with benchmark approaches for various ANN\narchitectures and different underlying data formats.",
          "link": "http://arxiv.org/abs/2209.07436",
          "publishedOn": "2023-07-29T00:48:57.571Z",
          "wordCount": null,
          "title": "Statistical process monitoring of artificial neural networks. (arXiv:2209.07436v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Mingquan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junze Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lichen Zhang</a>",
          "description": "Weighted low rank approximation is a fundamental problem in numerical linear\nalgebra, and it has many applications in machine learning. Given a matrix $M\n\\in \\mathbb{R}^{n \\times n}$, a weight matrix $W \\in \\mathbb{R}_{\\geq 0}^{n\n\\times n}$, a parameter $k$, the goal is to output two matrices $U, V \\in\n\\mathbb{R}^{n \\times k}$ such that $\\| W \\circ (M - U V^\\top) \\|_F$ is\nminimized, where $\\circ$ denotes the Hadamard product. Such a problem is known\nto be NP-hard and even hard to approximate assuming Exponential Time Hypothesis\n[GG11, RSW16]. Meanwhile, alternating minimization is a good heuristic solution\nfor approximating weighted low rank approximation. The work [LLR16] shows that,\nunder mild assumptions, alternating minimization does provide provable\nguarantees. In this work, we develop an efficient and robust framework for\nalternating minimization. For weighted low rank approximation, this improves\nthe runtime of [LLR16] from $n^2 k^2$ to $n^2k$. At the heart of our work\nframework is a high-accuracy multiple response regression solver together with\na robust analysis of alternating minimization.",
          "link": "http://arxiv.org/abs/2306.04169",
          "publishedOn": "2023-07-29T00:48:57.571Z",
          "wordCount": null,
          "title": "Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation. (arXiv:2306.04169v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Erp_B/0/1/0/all/0/1\">Bart van Erp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nuijten_W/0/1/0/all/0/1\">Wouter W. L. Nuijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laar_T/0/1/0/all/0/1\">Thijs van de Laar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_B/0/1/0/all/0/1\">Bert de Vries</a>",
          "description": "Bayesian state and parameter estimation have been automated effectively in a\nvariety of probabilistic programming languages. The process of model comparison\non the other hand, which still requires error-prone and time-consuming manual\nderivations, is often overlooked despite its importance. This paper efficiently\nautomates Bayesian model averaging, selection, and combination by message\npassing on a Forney-style factor graph with a custom mixture node. Parameter\nand state inference, and model comparison can then be executed simultaneously\nusing message passing with scale factors. This approach shortens the model\ndesign cycle and allows for the straightforward extension to hierarchical and\ntemporal model priors to accommodate for modeling complicated time-varying\nprocesses.",
          "link": "http://arxiv.org/abs/2306.05965",
          "publishedOn": "2023-07-29T00:48:57.570Z",
          "wordCount": null,
          "title": "Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tee_J/0/1/0/all/0/1\">Jia Yu Tee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candido_O/0/1/0/all/0/1\">Oliver De Candido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Utschick_W/0/1/0/all/0/1\">Wolfgang Utschick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_P/0/1/0/all/0/1\">Philipp Geiger</a>",
          "description": "Towards safe autonomous driving (AD), we consider the problem of learning\nmodels that accurately capture the diversity and tail quantiles of human driver\nbehavior probability distributions, in interaction with an AD vehicle. Such\nmodels, which predict drivers' continuous actions from their states, are\nparticularly relevant for closing the gap between AD agent simulations and\nreality. To this end, we adapt two flexible quantile learning frameworks for\nthis setting that avoid strong distributional assumptions: (1) quantile\nregression (based on the titled absolute loss), and (2) autoregressive quantile\nflows (a version of normalizing flows). Training happens in a behavior\ncloning-fashion. We use the highD dataset consisting of driver trajectories on\nseveral highways. We evaluate our approach in a one-step acceleration\nprediction task, and in multi-step driver simulation rollouts. We report\nquantitative results using the tilted absolute loss as metric, give qualitative\nexamples showing that realistic extremal behavior can be learned, and discuss\nthe main insights.",
          "link": "http://arxiv.org/abs/2305.13106",
          "publishedOn": "2023-07-29T00:48:57.569Z",
          "wordCount": null,
          "title": "On Learning the Tail Quantiles of Driving Behavior Distributions via Quantile Regression and Flows. (arXiv:2305.13106v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.11892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blum_A/0/1/0/all/0/1\">Avrim Blum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okoroafor_P/0/1/0/all/0/1\">Princewill Okoroafor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aadirupa Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stangl_K/0/1/0/all/0/1\">Kevin Stangl</a>",
          "description": "We consider the vulnerability of fairness-constrained learning to small\namounts of malicious noise in the training data. Konstantinov and Lampert\n(2021) initiated the study of this question and presented negative results\nshowing there exist data distributions where for several fairness constraints,\nany proper learner will exhibit high vulnerability when group sizes are\nimbalanced. Here, we present a more optimistic view, showing that if we allow\nrandomized classifiers, then the landscape is much more nuanced. For example,\nfor Demographic Parity we show we can incur only a $\\Theta(\\alpha)$ loss in\naccuracy, where $\\alpha$ is the malicious noise rate, matching the best\npossible even without fairness constraints. For Equal Opportunity, we show we\ncan incur an $O(\\sqrt{\\alpha})$ loss, and give a matching\n$\\Omega(\\sqrt{\\alpha})$lower bound. In contrast, Konstantinov and Lampert\n(2021) showed for proper learners the loss in accuracy for both notions is\n$\\Omega(1)$. The key technical novelty of our work is how randomization can\nbypass simple \"tricks\" an adversary can use to amplify his power. We also\nconsider additional fairness notions including Equalized Odds and Calibration.\nFor these fairness notions, the excess accuracy clusters into three natural\nregimes $O(\\alpha)$,$O(\\sqrt{\\alpha})$ and $O(1)$. These results provide a more\nfine-grained view of the sensitivity of fairness-constrained learning to\nadversarial noise in training data.",
          "link": "http://arxiv.org/abs/2307.11892",
          "publishedOn": "2023-07-29T00:48:57.569Z",
          "wordCount": null,
          "title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise. (arXiv:2307.11892v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14938",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jafarpour_S/0/1/0/all/0/1\">Saber Jafarpour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harapanahalli_A/0/1/0/all/0/1\">Akash Harapanahalli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Coogan_S/0/1/0/all/0/1\">Samuel Coogan</a>",
          "description": "In this paper, we propose a computationally efficient framework for interval\nreachability of neural network controlled systems. Our approach builds upon\ninclusion functions for the neural network controller and the open-loop system.\nWe observe that many state-of-the-art neural network verifiers can produce\ninclusion functions for neural networks. We introduce and analyze a new class\nof inclusion functions for the open-loop dynamics based on bounds of the\nfunction Jacobian that is particularly suitable for capturing the interactions\nbetween systems and neural network controllers. Next, for any dynamical system,\nwe use inclusion functions to construct an embedding system with twice the\nnumber of states as the original system. We show that a single trajectory of\nthis embedding system provides hyper-rectangular over-approximations of\nreachable sets. We then propose two approaches for constructing a closed-loop\nembedding system for a neural network controlled dynamical system that accounts\nfor the interaction between the system and the controller in different ways.\nThe interconnection-based approach accounts for the worst-case evolution of\neach coordinate separately by substituting the neural network inclusion\nfunction into the open-loop embedding system. The interaction-based approach\nuses the newly introduced class of Jacobian-based inclusion functions to fully\ncapture first-order interactions between the system and the controller.\nFinally, we implement our approach in a Python framework called\n\\texttt{ReachMM} and show that on several existing benchmarks, our methods\noutperform the existing approaches in the literature. We also demonstrate the\nscalability of our method on a vehicle platooning example with up to $200$\nstates.",
          "link": "http://arxiv.org/abs/2307.14938",
          "publishedOn": "2023-07-29T00:48:57.568Z",
          "wordCount": null,
          "title": "Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops. (arXiv:2307.14938v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.10825",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1\">Jiajin Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1\">Linglingzhi Zhu</a>, <a href=\"http://arxiv.org/find/math/1/au:+So_A/0/1/0/all/0/1\">Anthony Man-Cho So</a>",
          "description": "Nonconvex-nonconcave minimax optimization has gained widespread interest over\nthe last decade. However, most existing works focus on variants of gradient\ndescent-ascent (GDA) algorithms, which are only applicable to smooth\nnonconvex-concave settings. To address this limitation, we propose a novel\nalgorithm named smoothed proximal linear descent-ascent (smoothed PLDA), which\ncan effectively handle a broad range of structured nonsmooth\nnonconvex-nonconcave minimax problems. Specifically, we consider the setting\nwhere the primal function has a nonsmooth composite structure and the dual\nfunction possesses the Kurdyka-Lojasiewicz (KL) property with exponent $\\theta\n\\in [0,1)$. We introduce a novel convergence analysis framework for smoothed\nPLDA, the key components of which are our newly developed nonsmooth primal\nerror bound and dual error bound. Using this framework, we show that smoothed\nPLDA can find both $\\epsilon$-game-stationary points and\n$\\epsilon$-optimization-stationary points of the problems of interest in\n$\\mathcal{O}(\\epsilon^{-2\\max\\{2\\theta,1\\}})$ iterations. Furthermore, when\n$\\theta \\in [0,\\frac{1}{2}]$, smoothed PLDA achieves the optimal iteration\ncomplexity of $\\mathcal{O}(\\epsilon^{-2})$. To further demonstrate the\neffectiveness and wide applicability of our analysis framework, we show that\ncertain max-structured problem possesses the KL property with exponent\n$\\theta=0$ under mild assumptions. As a by-product, we establish\nalgorithm-independent quantitative relationships among various stationarity\nconcepts, which may be of independent interest.",
          "link": "http://arxiv.org/abs/2209.10825",
          "publishedOn": "2023-07-29T00:48:57.568Z",
          "wordCount": null,
          "title": "Nonsmooth Nonconvex-Nonconcave Minimax Optimization: Primal-Dual Balancing and Iteration Complexity Analysis. (arXiv:2209.10825v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kakaiya_R/0/1/0/all/0/1\">Ravi Kakaiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathish_R/0/1/0/all/0/1\">Rakshith Sathish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethuraman_R/0/1/0/all/0/1\">Ramanathan Sethuraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheet_D/0/1/0/all/0/1\">Debdoot Sheet</a>",
          "description": "Autonomous vehicles and Advanced Driving Assistance Systems (ADAS) have the\npotential to radically change the way we travel. Many such vehicles currently\nrely on segmentation and object detection algorithms to detect and track\nobjects around its surrounding. The data collected from the vehicles are often\nsent to cloud servers to facilitate continual/life-long learning of these\nalgorithms. Considering the bandwidth constraints, the data is compressed\nbefore sending it to servers, where it is typically decompressed for training\nand analysis. In this work, we propose the use of a learning-based compression\nCodec to reduce the overhead in latency incurred for the decompression\noperation in the standard pipeline. We demonstrate that the learned compressed\nrepresentation can also be used to perform tasks like semantic segmentation in\naddition to decompression to obtain the images. We experimentally validate the\nproposed pipeline on the Cityscapes dataset, where we achieve a compression\nfactor up to $66 \\times$ while preserving the information required to perform\nsegmentation with a dice coefficient of $0.84$ as compared to $0.88$ achieved\nusing decompressed images while reducing the overall compute by $11\\%$.",
          "link": "http://arxiv.org/abs/2307.01524",
          "publishedOn": "2023-07-29T00:48:57.567Z",
          "wordCount": null,
          "title": "Exploiting Richness of Learned Compressed Representation of Images for Semantic Segmentation. (arXiv:2307.01524v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.03124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Surasinghe_S/0/1/0/all/0/1\">Sudam Surasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fish_J/0/1/0/all/0/1\">Jeremie Fish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollt_E/0/1/0/all/0/1\">Erik M. Bollt</a>",
          "description": "Inference of transfer operators from data is often formulated as a classical\nproblem that hinges on the Ulam method. The conventional description, known as\nthe Ulam-Galerkin method, involves projecting onto basis functions represented\nas characteristic functions supported over a fine grid of rectangles. From this\nperspective, the Ulam-Galerkin approach can be interpreted as density\nestimation using the histogram method. In this study, we recast the problem\nwithin the framework of statistical density estimation. This alternative\nperspective allows for an explicit and rigorous analysis of bias and variance,\nthereby facilitating a discussion on the mean square error. Through\ncomprehensive examples utilizing the logistic map and a Markov map, we\ndemonstrate the validity and effectiveness of this approach in estimating the\neigenvectors of the Frobenius-Perron operator. We compare the performance of\nHistogram Density Estimation(HDE) and Kernel Density Estimation(KDE) methods\nand find that KDE generally outperforms HDE in terms of accuracy. However, it\nis important to note that KDE exhibits limitations around boundary points and\njumps. Based on our research findings, we suggest the possibility of\nincorporating other density estimation methods into this field and propose\nfuture investigations into the application of KDE-based estimation for\nhigh-dimensional maps. These findings provide valuable insights for researchers\nand practitioners working on estimating the Frobenius-Perron operator and\nhighlight the potential of density estimation techniques in this area of study.\n\nKeywords: Transfer Operators; Frobenius-Perron operator; probability density\nestimation; Ulam-Galerkin method; Kernel Density Estimation; Histogram Density\nEstimation.",
          "link": "http://arxiv.org/abs/2210.03124",
          "publishedOn": "2023-07-29T00:48:57.563Z",
          "wordCount": null,
          "title": "Learning Transfer Operators by Kernel Density Estimation. (arXiv:2210.03124v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.07959",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Thaler_S/0/1/0/all/0/1\">Stephan Thaler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Doehner_G/0/1/0/all/0/1\">Gregor Doehner</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zavadlav_J/0/1/0/all/0/1\">Julija Zavadlav</a>",
          "description": "Neural network (NN) potentials promise highly accurate molecular dynamics\n(MD) simulations within the computational complexity of classical MD force\nfields. However, when applied outside their training domain, NN potential\npredictions can be inaccurate, increasing the need for Uncertainty\nQuantification (UQ). Bayesian modeling provides the mathematical framework for\nUQ, but classical Bayesian methods based on Markov chain Monte Carlo (MCMC) are\ncomputationally intractable for NN potentials. By training graph NN potentials\nfor coarse-grained systems of liquid water and alanine dipeptide, we\ndemonstrate here that scalable Bayesian UQ via stochastic gradient MCMC\n(SG-MCMC) yields reliable uncertainty estimates for MD observables. We show\nthat cold posteriors can reduce the required training data size and that for\nreliable UQ, multiple Markov chains are needed. Additionally, we find that\nSG-MCMC and the Deep Ensemble method achieve comparable results, despite\nshorter training and less hyperparameter tuning of the latter. We show that\nboth methods can capture aleatoric and epistemic uncertainty reliably, but not\nsystematic uncertainty, which needs to be minimized by adequate modeling to\nobtain accurate credible intervals for MD observables. Our results represent a\nstep towards accurate UQ that is of vital importance for trustworthy NN\npotential-based MD simulations required for decision-making in practice.",
          "link": "http://arxiv.org/abs/2212.07959",
          "publishedOn": "2023-07-29T00:48:57.557Z",
          "wordCount": null,
          "title": "Scalable Bayesian Uncertainty Quantification for Neural Network Potentials: Promise and Pitfalls. (arXiv:2212.07959v2 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.13037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Van-Duc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_C/0/1/0/all/0/1\">Cuong-Tien Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wen-Syan Li</a>",
          "description": "An end-to-end machine learning (ML) lifecycle consists of many iterative\nprocesses, from data preparation and ML model design to model training and then\ndeploying the trained model for inference. When building an end-to-end\nlifecycle for an ML problem, many ML pipelines must be designed and executed\nthat produce a huge number of lifecycle versions. Therefore, this paper\nintroduces VeML, a Version management system dedicated to end-to-end ML\nLifecycle. Our system tackles several crucial problems that other systems have\nnot solved. First, we address the high cost of building an ML lifecycle,\nespecially for large-scale and high-dimensional dataset. We solve this problem\nby proposing to transfer the lifecycle of similar datasets managed in our\nsystem to the new training data. We design an algorithm based on the core set\nto compute similarity for large-scale, high-dimensional data efficiently.\nAnother critical issue is the model accuracy degradation by the difference\nbetween training data and testing data during the ML lifetime, which leads to\nlifecycle rebuild. Our system helps to detect this mismatch without getting\nlabeled data from testing data and rebuild the ML lifecycle for a new data\nversion. To demonstrate our contributions, we conduct experiments on\nreal-world, large-scale datasets of driving images and spatiotemporal sensor\ndata and show promising results.",
          "link": "http://arxiv.org/abs/2304.13037",
          "publishedOn": "2023-07-29T00:48:57.557Z",
          "wordCount": null,
          "title": "VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data. (arXiv:2304.13037v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.08890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_T/0/1/0/all/0/1\">Tianxiang Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuanpeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>",
          "description": "Fuzzy time series forecasting (FTSF) is a typical forecasting method with\nwide application. Traditional FTSF is regarded as an expert system which leads\nto loss of the ability to recognize undefined features. The mentioned is the\nmain reason for poor forecasting with FTSF. To solve the problem, the proposed\nmodel Differential Fuzzy Convolutional Neural Network (DFCNN) utilizes a\nconvolution neural network to re-implement FTSF with learnable ability. DFCNN\nis capable of recognizing potential information and improving forecasting\naccuracy. Thanks to the learnable ability of the neural network, the length of\nfuzzy rules established in FTSF is expended to an arbitrary length that the\nexpert is not able to handle by the expert system. At the same time, FTSF\nusually cannot achieve satisfactory performance of non-stationary time series\ndue to the trend of non-stationary time series. The trend of non-stationary\ntime series causes the fuzzy set established by FTSF to be invalid and causes\nthe forecasting to fail. DFCNN utilizes the Difference algorithm to weaken the\nnon-stationary of time series so that DFCNN can forecast the non-stationary\ntime series with a low error that FTSF cannot forecast in satisfactory\nperformance. After the mass of experiments, DFCNN has an excellent prediction\neffect, which is ahead of the existing FTSF and common time series forecasting\nalgorithms. Finally, DFCNN provides further ideas for improving FTSF and holds\ncontinued research value.",
          "link": "http://arxiv.org/abs/2305.08890",
          "publishedOn": "2023-07-29T00:48:57.557Z",
          "wordCount": null,
          "title": "Differential Convolutional Fuzzy Time Series Forecasting. (arXiv:2305.08890v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15010",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Wang_X/0/1/0/all/0/1\">Xiangzun Wang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Cichos_F/0/1/0/all/0/1\">Frank Cichos</a>",
          "description": "The processing of information is an indispensable property of living systems\nrealized by networks of active processes with enormous complexity. They have\ninspired many variants of modern machine learning one of them being reservoir\ncomputing, in which stimulating a network of nodes with fading memory enables\ncomputations and complex predictions. Reservoirs are implemented on computer\nhardware, but also on unconventional physical substrates such as mechanical\noscillators, spins, or bacteria often summarized as physical reservoir\ncomputing. Here we demonstrate physical reservoir computing with a synthetic\nactive microparticle system that self-organizes from an active and passive\ncomponent into inherently noisy nonlinear dynamical units. The\nself-organization and dynamical response of the unit is the result of a delayed\npropulsion of the microswimmer to a passive target. A reservoir of such units\nwith a self-coupling via the delayed response can perform predictive tasks\ndespite the strong noise resulting from Brownian motion of the microswimmers.\nTo achieve efficient noise suppression, we introduce a special architecture\nthat uses historical reservoir states for output. Our results pave the way for\nthe study of information processing in synthetic self-organized active particle\nsystems.",
          "link": "http://arxiv.org/abs/2307.15010",
          "publishedOn": "2023-07-29T00:48:57.556Z",
          "wordCount": null,
          "title": "Harnessing Synthetic Active Particles for Physical Reservoir Computing. (arXiv:2307.15010v1 [cond-mat.soft])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.00570",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_B/0/1/0/all/0/1\">Bo Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_H/0/1/0/all/0/1\">Huidong Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qiong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xiongchao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_X/0/1/0/all/0/1\">Xueqi Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_Z/0/1/0/all/0/1\">Zhicheng Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1\">S. Kevin Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_B/0/1/0/all/0/1\">Biao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rominger_A/0/1/0/all/0/1\">Axel Rominger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_K/0/1/0/all/0/1\">Kuangyu Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duncan_J/0/1/0/all/0/1\">James S. Duncan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chi Liu</a>",
          "description": "Low-count PET is an efficient way to reduce radiation exposure and\nacquisition time, but the reconstructed images often suffer from low\nsignal-to-noise ratio (SNR), thus affecting diagnosis and other downstream\ntasks. Recent advances in deep learning have shown great potential in improving\nlow-count PET image quality, but acquiring a large, centralized, and diverse\ndataset from multiple institutions for training a robust model is difficult due\nto privacy and security concerns of patient data. Moreover, low-count PET data\nat different institutions may have different data distribution, thus requiring\npersonalized models. While previous federated learning (FL) algorithms enable\nmulti-institution collaborative training without the need of aggregating local\ndata, addressing the large domain shift in the application of\nmulti-institutional low-count PET denoising remains a challenge and is still\nhighly under-explored. In this work, we propose FedFTN, a personalized\nfederated learning strategy that addresses these challenges. FedFTN uses a\nlocal deep feature transformation network (FTN) to modulate the feature outputs\nof a globally shared denoising network, enabling personalized low-count PET\ndenoising for each institution. During the federated learning process, only the\ndenoising network's weights are communicated and aggregated, while the FTN\nremains at the local institutions for feature transformation. We evaluated our\nmethod using a large-scale dataset of multi-institutional low-count PET imaging\ndata from three medical centers located across three continents, and showed\nthat FedFTN provides high-quality low-count PET images, outperforming previous\nbaseline FL reconstruction methods across all low-count levels at all three\ninstitutions.",
          "link": "http://arxiv.org/abs/2304.00570",
          "publishedOn": "2023-07-29T00:48:57.556Z",
          "wordCount": null,
          "title": "FedFTN: Personalized Federated Learning with Deep Feature Transformation Network for Multi-institutional Low-count PET Denoising. (arXiv:2304.00570v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.01913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marty_T/0/1/0/all/0/1\">Tom Marty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francois_T/0/1/0/all/0/1\">Tristan Fran&#xe7;ois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tessier_P/0/1/0/all/0/1\">Pierre Tessier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gauthier_L/0/1/0/all/0/1\">Louis Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rousseau_L/0/1/0/all/0/1\">Louis-Martin Rousseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cappart_Q/0/1/0/all/0/1\">Quentin Cappart</a>",
          "description": "Constraint programming is known for being an efficient approach for solving\ncombinatorial problems. Important design choices in a solver are the branching\nheuristics, which are designed to lead the search to the best solutions in a\nminimum amount of time. However, developing these heuristics is a\ntime-consuming process that requires problem-specific expertise. This\nobservation has motivated many efforts to use machine learning to automatically\nlearn efficient heuristics without expert intervention. To the best of our\nknowledge, it is still an open research question. Although several generic\nvariable-selection heuristics are available in the literature, the options for\na generic value-selection heuristic are more scarce. In this paper, we propose\nto tackle this issue by introducing a generic learning procedure that can be\nused to obtain a value-selection heuristic inside a constraint programming\nsolver. This has been achieved thanks to the combination of a deep Q-learning\nalgorithm, a tailored reward signal, and a heterogeneous graph neural network\narchitecture. Experiments on graph coloring, maximum independent set, and\nmaximum cut problems show that our framework is able to find better solutions\nclose to optimality without requiring a large amounts of backtracks while being\ngeneric.",
          "link": "http://arxiv.org/abs/2301.01913",
          "publishedOn": "2023-07-29T00:48:57.555Z",
          "wordCount": null,
          "title": "Learning a Generic Value-Selection Heuristic Inside a Constraint Programming Solver. (arXiv:2301.01913v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1\">Leonardo Cotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1\">Beatrice Bevilacqua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nesreen Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>",
          "description": "Existing causal models for link prediction assume an underlying set of\ninherent node factors -- an innate characteristic defined at the node's birth\n-- that governs the causal evolution of links in the graph. In some causal\ntasks, however, link formation is path-dependent: The outcome of link\ninterventions depends on existing links. Unfortunately, these existing causal\nmethods are not designed for path-dependent link formation, as the cascading\nfunctional dependencies between links (arising from path dependence) are either\nunidentifiable or require an impractical number of control variables. To\novercome this, we develop the first causal model capable of dealing with path\ndependencies in link prediction. In this work we introduce the concept of\ncausal lifting, an invariance in causal models of independent interest that, on\ngraphs, allows the identification of causal link prediction queries using\nlimited interventional data. Further, we show how structural pairwise\nembeddings exhibit lower bias and correctly represent the task's causal\nstructure, as opposed to existing node embeddings, e.g., graph neural network\nnode embeddings and matrix factorization. Finally, we validate our theoretical\nfindings on three scenarios for causal link prediction tasks: knowledge base\ncompletion, covariance matrix estimation and consumer-product recommendations.",
          "link": "http://arxiv.org/abs/2302.01198",
          "publishedOn": "2023-07-29T00:48:57.555Z",
          "wordCount": null,
          "title": "Causal Lifting and Link Prediction. (arXiv:2302.01198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08720",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Annau_N/0/1/0/all/0/1\">Nicolaas J. Annau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cannon_A/0/1/0/all/0/1\">Alex J. Cannon</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Monahan_A/0/1/0/all/0/1\">Adam H. Monahan</a>",
          "description": "This paper explores the application of emerging machine learning methods from\nimage super-resolution (SR) to the task of statistical downscaling. We\nspecifically focus on convolutional neural network-based Generative Adversarial\nNetworks (GANs). Our GANs are conditioned on low-resolution (LR) inputs to\ngenerate high-resolution (HR) surface winds emulating Weather Research and\nForecasting (WRF) model simulations over North America. Unlike traditional SR\nmodels, where LR inputs are idealized coarsened versions of the HR images, WRF\nemulation involves using non-idealized LR and HR pairs resulting in\nshared-scale mismatches due to internal variability. Our study builds upon\ncurrent SR-based statistical downscaling by experimenting with a novel\nfrequency-separation (FS) approach from the computer vision field. To assess\nthe skill of SR models, we carefully select evaluation metrics, and focus on\nperformance measures based on spatial power spectra. Our analyses reveal how\nGAN configurations influence spatial structures in the generated fields,\nparticularly biases in spatial variability spectra. Using power spectra to\nevaluate the FS experiments reveals that successful applications of FS in\ncomputer vision do not translate to climate fields. However, the FS experiments\ndemonstrate the sensitivity of power spectra to a commonly used GAN-based SR\nobjective function, which helps interpret and understand its role in\ndetermining spatial structures. This result motivates the development of a\nnovel partial frequency-separation scheme as a promising configuration option.\nWe also quantify the influence on GAN performance of non-idealized LR fields\nresulting from internal variability. Furthermore, we conduct a spectra-based\nfeature-importance experiment allowing us to explore the dependence of the\nspatial structure of generated fields on different physically relevant LR\ncovariates.",
          "link": "http://arxiv.org/abs/2302.08720",
          "publishedOn": "2023-07-29T00:48:57.554Z",
          "wordCount": null,
          "title": "Algorithmic Hallucinations of Near-Surface Winds: Statistical Downscaling with Generative Adversarial Networks to Convection-Permitting Scales. (arXiv:2302.08720v2 [physics.ao-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.12672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bogdanov_E/0/1/0/all/0/1\">Eli Bogdanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_I/0/1/0/all/0/1\">Izack Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_A/0/1/0/all/0/1\">Avigdor Gal</a>",
          "description": "In this work we propose an algorithm for trace recovery from stochastically\nknown logs, a setting that is becoming more common with the increasing number\nof sensors and predictive models that generate uncertain data. The suggested\napproach calculates the conformance between a process model and a\nstochastically known trace and recovers the best alignment within this\nstochastic trace as the true trace. The paper offers an analysis of the impact\nof various cost models on trace recovery accuracy and makes use of a product\nmulti-graph to compare alternative trace recovery options. The average accuracy\nof our approach, evaluated using two publicly available datasets, is\nimpressive, with an average recovery accuracy score of 90-97%, significantly\nimproving a common heuristic that chooses the most likely value for each\nuncertain activity. We believe that the effectiveness of the proposed algorithm\nin recovering correct traces from stochastically known logs may be a powerful\naid for developing credible decision-making tools in uncertain settings.",
          "link": "http://arxiv.org/abs/2206.12672",
          "publishedOn": "2023-07-29T00:48:57.552Z",
          "wordCount": null,
          "title": "Trace Recovery from Stochastically Known Logs. (arXiv:2206.12672v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_N/0/1/0/all/0/1\">Naoya Hasegawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>",
          "description": "Recognition problems in long-tailed data, where the sample size per class is\nheavily skewed, have recently gained importance because the distribution of the\nsample size per class in a dataset is generally exponential unless the sample\nsize is intentionally adjusted. Various approaches have been devised to address\nthese problems. Recently, weight balancing, which combines well-known classical\nregularization techniques with two-stage training, has been proposed. Despite\nits simplicity, it is known for its high performance against existing methods\ndevised in various ways. However, there is a lack of understanding as to why\nthis approach is effective for long-tailed data. In this study, we analyze the\nmethod focusing on neural collapse and cone effect at each training stage and\nfind that it can be decomposed into the increase in Fisher's discriminant ratio\nof the feature extractor caused by weight decay and cross entropy loss and\nimplicit logit adjustment caused by weight decay and class-balanced loss. Our\nanalysis shows that the training method can be further simplified by reducing\nthe number of training stages to one while increasing accuracy.",
          "link": "http://arxiv.org/abs/2305.16573",
          "publishedOn": "2023-07-29T00:48:57.551Z",
          "wordCount": null,
          "title": "Exploring Weight Balancing on Long-Tailed Recognition Problem. (arXiv:2305.16573v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khormali_A/0/1/0/all/0/1\">Aminollah Khormali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jiann-Shiun Yuan</a>",
          "description": "Deepfake detection methods have shown promising results in recognizing\nforgeries within a given dataset, where training and testing take place on the\nin-distribution dataset. However, their performance deteriorates significantly\nwhen presented with unseen samples. As a result, a reliable deepfake detection\nsystem must remain impartial to forgery types, appearance, and quality for\nguaranteed generalizable detection performance. Despite various attempts to\nenhance cross-dataset generalization, the problem remains challenging,\nparticularly when testing against common post-processing perturbations, such as\nvideo compression or blur. Hence, this study introduces a deepfake detection\nframework, leveraging a self-supervised pre-training model that delivers\nexceptional generalization ability, withstanding common corruptions and\nenabling feature explainability. The framework comprises three key components:\na feature extractor based on vision Transformer architecture that is\npre-trained via self-supervised contrastive learning methodology, a graph\nconvolution network coupled with a Transformer discriminator, and a graph\nTransformer relevancy map that provides a better understanding of manipulated\nregions and further explains the model's decision. To assess the effectiveness\nof the proposed framework, several challenging experiments are conducted,\nincluding in-data distribution performance, cross-dataset, cross-manipulation\ngeneralization, and robustness against common post-production perturbations.\nThe results achieved demonstrate the remarkable effectiveness of the proposed\ndeepfake detection framework, surpassing the current state-of-the-art\napproaches.",
          "link": "http://arxiv.org/abs/2307.15019",
          "publishedOn": "2023-07-29T00:48:57.547Z",
          "wordCount": null,
          "title": "Self-Supervised Graph Transformer for Deepfake Detection. (arXiv:2307.15019v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Colin White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_R/0/1/0/all/0/1\">Renbo Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1\">Jean Kossaifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1\">Gennady Pekhimenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "The Fourier neural operator (FNO) is a powerful technique for learning\nsurrogate maps for partial differential equation (PDE) solution operators. For\nmany real-world applications, which often require high-resolution data points,\ntraining time and memory usage are significant bottlenecks. While there are\nmixed-precision training techniques for standard neural networks, those work\nfor real-valued datatypes on finite dimensions and therefore cannot be directly\napplied to FNO, which crucially operates in the (complex-valued) Fourier domain\nand in function spaces. On the other hand, since the Fourier transform is\nalready an approximation (due to discretization error), we do not need to\nperform the operation at full precision. In this work, we (i) profile memory\nand runtime for FNO with full and mixed-precision training, (ii) conduct a\nstudy on the numerical stability of mixed-precision training of FNO, and (iii)\ndevise a training routine which substantially decreases training time and\nmemory usage (up to 34%), with little or no reduction in accuracy, on the\nNavier-Stokes and Darcy flow equations. Combined with the recently proposed\ntensorized FNO (Kossaifi et al., 2023), the resulting model has far better\nperformance while also being significantly faster than the original FNO.",
          "link": "http://arxiv.org/abs/2307.15034",
          "publishedOn": "2023-07-29T00:48:57.547Z",
          "wordCount": null,
          "title": "Speeding up Fourier Neural Operators via Mixed Precision. (arXiv:2307.15034v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.08411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kandpal_N/0/1/0/all/0/1\">Nikhil Kandpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Haikang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>",
          "description": "The Internet contains a wealth of knowledge -- from the birthdays of\nhistorical figures to tutorials on how to code -- all of which may be learned\nby language models. However, while certain pieces of information are ubiquitous\non the web, others appear extremely rarely. In this paper, we study the\nrelationship between the knowledge memorized by large language models and the\ninformation in pre-training datasets scraped from the web. In particular, we\nshow that a language model's ability to answer a fact-based question relates to\nhow many documents associated with that question were seen during pre-training.\nWe identify these relevant documents by entity linking pre-training datasets\nand counting documents that contain the same entities as a given\nquestion-answer pair. Our results demonstrate strong correlational and causal\nrelationships between accuracy and relevant document count for numerous\nquestion answering datasets (e.g., TriviaQA), pre-training corpora (e.g.,\nROOTS), and model sizes (e.g., 176B parameters). Moreover, while larger models\nare better at learning long-tail knowledge, we estimate that today's models\nmust be scaled by many orders of magnitude to reach competitive QA performance\non questions with little support in the pre-training data. Finally, we show\nthat retrieval-augmentation can reduce the dependence on relevant pre-training\ninformation, presenting a promising approach for capturing the long-tail.",
          "link": "http://arxiv.org/abs/2211.08411",
          "publishedOn": "2023-07-29T00:48:57.546Z",
          "wordCount": null,
          "title": "Large Language Models Struggle to Learn Long-Tail Knowledge. (arXiv:2211.08411v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.12481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_Z/0/1/0/all/0/1\">Zulqarnain Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1\">Davin Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masoomi_A/0/1/0/all/0/1\">Aria Masoomi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bone_J/0/1/0/all/0/1\">Joshua Bone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1\">Jennifer Dy</a>",
          "description": "Machine learning methods have significantly improved in their predictive\ncapabilities, but at the same time they are becoming more complex and less\ntransparent. As a result, explainers are often relied on to provide\ninterpretability to these black-box prediction models. As crucial diagnostics\ntools, it is important that these explainers themselves are robust. In this\npaper we focus on one particular aspect of robustness, namely that an explainer\nshould give similar explanations for similar data inputs. We formalize this\nnotion by introducing and defining explainer astuteness, analogous to\nastuteness of prediction functions. Our formalism allows us to connect\nexplainer robustness to the predictor's probabilistic Lipschitzness, which\ncaptures the probability of local smoothness of a function. We provide lower\nbound guarantees on the astuteness of a variety of explainers (e.g., SHAP,\nRISE, CXPlain) given the Lipschitzness of the prediction function. These\ntheoretical results imply that locally smooth prediction functions lend\nthemselves to locally robust explanations. We evaluate these results\nempirically on simulated as well as real datasets.",
          "link": "http://arxiv.org/abs/2206.12481",
          "publishedOn": "2023-07-29T00:48:57.545Z",
          "wordCount": null,
          "title": "Analyzing Explainer Robustness via Lipschitzness of Prediction Functions. (arXiv:2206.12481v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.09924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hecking_T/0/1/0/all/0/1\">Tobias Hecking</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muthukrishnan_S/0/1/0/all/0/1\">Swathy Muthukrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinert_A/0/1/0/all/0/1\">Alexander Weinert</a>",
          "description": "Solving parity games is a major building block for numerous applications in\nreactive program verification and synthesis. While they can be solved\nefficiently in practice, no known approach has a polynomial worst-case runtime\ncomplexity. We present a incomplete polynomial-time approach to determining the\nwinning regions of parity games via graph neural networks.\n\nOur evaluation on 900 randomly generated parity games shows that this\napproach is effective and efficient in practice. It correctly determines the\nwinning regions of $\\sim$60\\% of the games in our data set and only incurs\nminor errors in the remaining ones. We believe that this approach can be\nextended to efficiently solve parity games as well.",
          "link": "http://arxiv.org/abs/2210.09924",
          "publishedOn": "2023-07-29T00:48:57.545Z",
          "wordCount": null,
          "title": "Predicting Winning Regions in Parity Games via Graph Neural Networks (Extended Abstract). (arXiv:2210.09924v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+So_J/0/1/0/all/0/1\">Jinhyun So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_R/0/1/0/all/0/1\">Ramy E. Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_B/0/1/0/all/0/1\">Basak Guler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>",
          "description": "Secure aggregation is a critical component in federated learning (FL), which\nenables the server to learn the aggregate model of the users without observing\ntheir local models. Conventionally, secure aggregation algorithms focus only on\nensuring the privacy of individual users in a single training round. We contend\nthat such designs can lead to significant privacy leakages over multiple\ntraining rounds, due to partial user selection/participation at each round of\nFL. In fact, we show that the conventional random user selection strategies in\nFL lead to leaking users' individual models within number of rounds that is\nlinear in the number of users. To address this challenge, we introduce a secure\naggregation framework, Multi-RoundSecAgg, with multi-round privacy guarantees.\nIn particular, we introduce a new metric to quantify the privacy guarantees of\nFL over multiple training rounds, and develop a structured user selection\nstrategy that guarantees the long-term privacy of each user (over any number of\ntraining rounds). Our framework also carefully accounts for the fairness and\nthe average number of participating users at each round. Our experiments on\nMNIST and CIFAR-10 datasets in the IID and the non-IID settings demonstrate the\nperformance improvement over the baselines, both in terms of privacy protection\nand test accuracy.",
          "link": "http://arxiv.org/abs/2106.03328",
          "publishedOn": "2023-07-29T00:48:57.544Z",
          "wordCount": null,
          "title": "Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning. (arXiv:2106.03328v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.14704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Prompt learning approaches have made waves in natural language processing by\ninducing better few-shot performance while they still follow a parametric-based\nlearning paradigm; the oblivion and rote memorization problems in learning may\nencounter unstable generalization issues. Specifically, vanilla prompt learning\nmay struggle to utilize atypical instances by rote during fully-supervised\ntraining or overfit shallow patterns with low-shot data. To alleviate such\nlimitations, we develop RetroPrompt with the motivation of decoupling knowledge\nfrom memorization to help the model strike a balance between generalization and\nmemorization. In contrast with vanilla prompt learning, RetroPrompt constructs\nan open-book knowledge-store from training instances and implements a retrieval\nmechanism during the process of input, training and inference, thus equipping\nthe model with the ability to retrieve related contexts from the training\ncorpus as cues for enhancement. Extensive experiments demonstrate that\nRetroPrompt can obtain better performance in both few-shot and zero-shot\nsettings. Besides, we further illustrate that our proposed RetroPrompt can\nyield better generalization abilities with new datasets. Detailed analysis of\nmemorization indeed reveals RetroPrompt can reduce the reliance of language\nmodels on memorization; thus, improving generalization for downstream tasks.\nCode is available in\nhttps://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt.",
          "link": "http://arxiv.org/abs/2205.14704",
          "publishedOn": "2023-07-29T00:48:57.544Z",
          "wordCount": null,
          "title": "Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning. (arXiv:2205.14704v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.01555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eldele_E/0/1/0/all/0/1\">Emadeldeen Eldele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragab_M/0/1/0/all/0/1\">Mohamed Ragab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhenghua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Min Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1\">Chee-Keong Kwoh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoli Li</a>",
          "description": "Unsupervised Domain Adaptation (UDA) has emerged as a powerful solution for\nthe domain shift problem via transferring the knowledge from a labeled source\ndomain to a shifted unlabeled target domain. Despite the prevalence of UDA for\nvisual applications, it remains relatively less explored for time-series\napplications. In this work, we propose a novel lightweight contrastive domain\nadaptation framework called CoTMix for time-series data. Unlike existing\napproaches that either use statistical distances or adversarial techniques, we\nleverage contrastive learning solely to mitigate the distribution shift across\nthe different domains. Specifically, we propose a novel temporal mixup strategy\nto generate two intermediate augmented views for the source and target domains.\nSubsequently, we leverage contrastive learning to maximize the similarity\nbetween each domain and its corresponding augmented view. The generated views\nconsider the temporal dynamics of time-series data during the adaptation\nprocess while inheriting the semantics among the two domains. Hence, we\ngradually push both domains towards a common intermediate space, mitigating the\ndistribution shift across them. Extensive experiments conducted on five\nreal-world time-series datasets show that our approach can significantly\noutperform all state-of-the-art UDA methods. The implementation code of CoTMix\nis available at\n\\href{https://github.com/emadeldeen24/CoTMix}{github.com/emadeldeen24/CoTMix}.",
          "link": "http://arxiv.org/abs/2212.01555",
          "publishedOn": "2023-07-29T00:48:57.544Z",
          "wordCount": null,
          "title": "Contrastive Domain Adaptation for Time-Series via Temporal Mixup. (arXiv:2212.01555v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dambra_S/0/1/0/all/0/1\">Savino Dambra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yufei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aonzo_S/0/1/0/all/0/1\">Simone Aonzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotzias_P/0/1/0/all/0/1\">Platon Kotzias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitale_A/0/1/0/all/0/1\">Antonino Vitale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caballero_J/0/1/0/all/0/1\">Juan Caballero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balzarotti_D/0/1/0/all/0/1\">Davide Balzarotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilge_L/0/1/0/all/0/1\">Leyla Bilge</a>",
          "description": "Many studies have proposed machine-learning (ML) models for malware detection\nand classification, reporting an almost-perfect performance. However, they\nassemble ground-truth in different ways, use diverse static- and\ndynamic-analysis techniques for feature extraction, and even differ on what\nthey consider a malware family. As a consequence, our community still lacks an\nunderstanding of malware classification results: whether they are tied to the\nnature and distribution of the collected dataset, to what extent the number of\nfamilies and samples in the training dataset influence performance, and how\nwell static and dynamic features complement each other.\n\nThis work sheds light on those open questions. by investigating the key\nfactors influencing ML-based malware detection and classification. For this, we\ncollect the largest balanced malware dataset so far with 67K samples from 670\nfamilies (100 samples each), and train state-of-the-art models for malware\ndetection and family classification using our dataset. Our results reveal that\nstatic features perform better than dynamic features, and that combining both\nonly provides marginal improvement over static features. We discover no\ncorrelation between packing and classification accuracy, and that missing\nbehaviors in dynamically-extracted features highly penalize their performance.\nWe also demonstrate how a larger number of families to classify make the\nclassification harder, while a higher number of samples per family increases\naccuracy. Finally, we find that models trained on a uniform distribution of\nsamples per family better generalize on unseen data.",
          "link": "http://arxiv.org/abs/2307.14657",
          "publishedOn": "2023-07-29T00:48:57.543Z",
          "wordCount": null,
          "title": "Decoding the Secrets of Machine Learning in Malware Classification: A Deep Dive into Datasets, Feature Extraction, and Model Performance. (arXiv:2307.14657v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14970",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Sturm_D/0/1/0/all/0/1\">Dominik Sturm</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Maddu_S/0/1/0/all/0/1\">Suryanarayana Maddu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sbalzarini_I/0/1/0/all/0/1\">Ivo F. Sbalzarini</a>",
          "description": "We use a combination of unsupervised clustering and sparsity-promoting\ninference algorithms to learn locally dominant force balances that explain\nmacroscopic pattern formation in self-organized active particle systems. The\nself-organized emergence of macroscopic patterns from microscopic interactions\nbetween self-propelled particles can be widely observed nature. Although\nhydrodynamic theories help us better understand the physical basis of this\nphenomenon, identifying a sufficient set of local interactions that shape,\nregulate, and sustain self-organized structures in active particle systems\nremains challenging. We investigate a classic hydrodynamic model of\nself-propelled particles that produces a wide variety of patterns, like asters\nand moving density bands. Our data-driven analysis shows that propagating bands\nare formed by local alignment interactions driven by density gradients, while\nsteady-state asters are shaped by a mechanism of splay-induced negative\ncompressibility arising from strong particle interactions. Our method also\nreveals analogous physical principles of pattern formation in a system where\nthe speed of the particle is influenced by local density. This demonstrates the\nability of our method to reveal physical commonalities across models. The\nphysical mechanisms inferred from the data are in excellent agreement with\nanalytical scaling arguments and experimental observations.",
          "link": "http://arxiv.org/abs/2307.14970",
          "publishedOn": "2023-07-29T00:48:57.543Z",
          "wordCount": null,
          "title": "Learning locally dominant force balances in active particle systems. (arXiv:2307.14970v1 [cond-mat.soft])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.00695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyang R. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1\">Gregory Valiant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>",
          "description": "Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations that preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations that mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms random sampling methods by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2005.00695",
          "publishedOn": "2023-07-29T00:48:57.543Z",
          "wordCount": null,
          "title": "On the Generalization Effects of Linear Transformations in Data Augmentation. (arXiv:2005.00695v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeunen_O/0/1/0/all/0/1\">Olivier Jeunen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potapov_I/0/1/0/all/0/1\">Ivan Potapov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ustimenko_A/0/1/0/all/0/1\">Aleksei Ustimenko</a>",
          "description": "Approaches to recommendation are typically evaluated in one of two ways: (1)\nvia a (simulated) online experiment, often seen as the gold standard, or (2)\nvia some offline evaluation procedure, where the goal is to approximate the\noutcome of an online experiment. Several offline evaluation metrics have been\nadopted in the literature, inspired by ranking metrics prevalent in the field\nof Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one\nsuch metric that has seen widespread adoption in empirical studies, and higher\n(n)DCG values have been used to present new methods as the state-of-the-art in\ntop-$n$ recommendation for many years.\n\nOur work takes a critical look at this approach, and investigates when we can\nexpect such metrics to approximate the gold standard outcome of an online\nexperiment. We formally present the assumptions that are necessary to consider\nDCG an unbiased estimator of online reward and provide a derivation for this\nmetric from first principles, highlighting where we deviate from its\ntraditional uses in IR. Importantly, we show that normalising the metric\nrenders it inconsistent, in that even when DCG is unbiased, ranking competing\nmethods by their normalised DCG can invert their relative order. Through a\ncorrelation analysis between off- and on-line experiments conducted on a\nlarge-scale recommendation platform, we show that our unbiased DCG estimates\nstrongly correlate with online reward, even when some of the metric's inherent\nassumptions are violated. This statement no longer holds for its normalised\nvariant, suggesting that nDCG's practical utility may be limited.",
          "link": "http://arxiv.org/abs/2307.15053",
          "publishedOn": "2023-07-29T00:48:57.542Z",
          "wordCount": null,
          "title": "On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation. (arXiv:2307.15053v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02626",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bena_G/0/1/0/all/0/1\">Gabriel B&#xe9;na</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Goodman_D/0/1/0/all/0/1\">Dan F. M. Goodman</a>",
          "description": "It has long been believed that the brain is highly modular both in terms of\nstructure and function, although recent evidence has led some to question the\nextent of both types of modularity. We used artificial neural networks to test\nthe hypothesis that structural modularity is sufficient to guarantee functional\nspecialization, and find that in general, this doesn't necessarily hold except\nat extreme levels. We then systematically tested which features of the\nenvironment and network do lead to the emergence of specialization. We used a\nsimple toy environment, task and network, allowing us precise control, and show\nthat in this setup, several distinct measures of specialization give\nqualitatively similar results. We further find that (1) specialization can only\nemerge in environments where features of that environment are meaningfully\nseparable, (2) specialization preferentially emerges when the network is\nstrongly resource-constrained, and (3) these findings are qualitatively similar\nacross different network architectures, but the quantitative relationships\ndepends on the architecture type. Finally, we show that functional\nspecialization varies dynamically across time, and demonstrate that these\ndynamics depend on both the timing and bandwidth of information flow in the\nnetwork. We conclude that a static notion of specialization, based on\nstructural modularity, is likely too simple a framework for understanding\nintelligent systems in situations of real-world complexity. We propose that\nthoroughly stress testing candidate definitions of functional modularity in\nsimplified scenarios before extending to more complex data, network models and\nelectrophysiological recordings is likely to be a fruitful approach.",
          "link": "http://arxiv.org/abs/2106.02626",
          "publishedOn": "2023-07-29T00:48:57.542Z",
          "wordCount": null,
          "title": "Dynamics of specialization in neural modules under resource constraints. (arXiv:2106.02626v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.11838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1\">Alessandro Abate</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Almulla_Y/0/1/0/all/0/1\">Yousif Almulla</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Fox_J/0/1/0/all/0/1\">James Fox</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hyland_D/0/1/0/all/0/1\">David Hyland</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wooldridge_M/0/1/0/all/0/1\">Michael Wooldridge</a> (1) ((1) University of Oxford)",
          "description": "Training reinforcement learning (RL) agents using scalar reward signals is\noften infeasible when an environment has sparse and non-Markovian rewards.\nMoreover, handcrafting these reward functions before training is prone to\nmisspecification, especially when the environment's dynamics are only partially\nknown. This paper proposes a novel pipeline for learning non-Markovian task\nspecifications as succinct finite-state `task automata' from episodes of agent\nexperience within unknown environments. We leverage two key algorithmic\ninsights. First, we learn a product MDP, a model composed of the\nspecification's automaton and the environment's MDP (both initially unknown),\nby treating the product MDP as a partially observable MDP and using the\nwell-known Baum-Welch algorithm for learning hidden Markov models. Second, we\npropose a novel method for distilling the task automaton (assumed to be a\ndeterministic finite automaton) from the learnt product MDP. Our learnt task\nautomaton enables the decomposition of a task into its constituent sub-tasks,\nwhich improves the rate at which an RL agent can later synthesise an optimal\npolicy. It also provides an interpretable encoding of high-level environmental\nand task features, so a human can readily verify that the agent has learnt\ncoherent tasks with no misspecifications. In addition, we take steps towards\nensuring that the learnt automaton is environment-agnostic, making it\nwell-suited for use in transfer learning. Finally, we provide experimental\nresults compared with two baselines to illustrate our algorithm's performance\nin different environments and tasks.",
          "link": "http://arxiv.org/abs/2208.11838",
          "publishedOn": "2023-07-29T00:48:57.542Z",
          "wordCount": null,
          "title": "Learning Task Automata for Reinforcement Learning using Hidden Markov Models. (arXiv:2208.11838v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+R_A/0/1/0/all/0/1\">Amarnath R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_V/0/1/0/all/0/1\">Vinay Kumar V</a>",
          "description": "Recognizing handwritten digits is a challenging task primarily due to the\ndiversity of writing styles and the presence of noisy images. The widely used\nMNIST dataset, which is commonly employed as a benchmark for this task,\nincludes distorted digits with irregular shapes, incomplete strokes, and\nvarying skew in both the training and testing datasets. Consequently, these\nfactors contribute to reduced accuracy in digit recognition. To overcome this\nchallenge, we propose a two-stage deep learning approach. In the first stage,\nwe create a simple neural network to identify distorted digits within the\ntraining set. This model serves to detect and filter out such distorted and\nambiguous images. In the second stage, we exclude these identified images from\nthe training dataset and proceed to retrain the model using the filtered\ndataset. This process aims to improve the classification accuracy and\nconfidence levels while mitigating issues of underfitting and overfitting. Our\nexperimental results demonstrate the effectiveness of the proposed approach,\nachieving an accuracy rate of over 99.5% on the testing dataset. This\nsignificant improvement showcases the potential of our method in enhancing\ndigit classification accuracy. In our future work, we intend to explore the\nscalability of this approach and investigate techniques to further enhance\naccuracy by reducing the size of the training data.",
          "link": "http://arxiv.org/abs/2307.14343",
          "publishedOn": "2023-07-29T00:48:57.541Z",
          "wordCount": null,
          "title": "Pruning Distorted Images in MNIST Handwritten Digits. (arXiv:2307.14343v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cobb_O/0/1/0/all/0/1\">Oliver Cobb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Looveren_A/0/1/0/all/0/1\">Arnaud Van Looveren</a>",
          "description": "There is a growing awareness of the harmful effects of distribution shift on\nthe performance of deployed machine learning models. Consequently, there is a\ngrowing interest in detecting these shifts before associated costs have time to\naccumulate. However, desiderata of crucial importance to the practicable\ndeployment of sequential shift detectors are typically overlooked by existing\nworks, precluding their widespread adoption. We identify three such desiderata,\nhighlight existing works relevant to their satisfaction, and recommend\nimpactful directions for future research.",
          "link": "http://arxiv.org/abs/2307.14758",
          "publishedOn": "2023-07-29T00:48:57.541Z",
          "wordCount": null,
          "title": "Towards Practicable Sequential Shift Detectors. (arXiv:2307.14758v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yeye He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Cong Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauduri_S/0/1/0/all/0/1\">Surajit Chauduri</a>",
          "description": "Relational tables, where each row corresponds to an entity and each column\ncorresponds to an attribute, have been the standard for tables in relational\ndatabases. However, such a standard cannot be taken for granted when dealing\nwith tables \"in the wild\". Our survey of real spreadsheet-tables and web-tables\nshows that over 30% of such tables do not conform to the relational standard,\nfor which complex table-restructuring transformations are needed before these\ntables can be queried easily using SQL-based analytics tools. Unfortunately,\nthe required transformations are non-trivial to program, which has become a\nsubstantial pain point for technical and non-technical users alike, as\nevidenced by large numbers of forum questions in places like StackOverflow and\nExcel/Tableau forums.\n\nWe develop an Auto-Tables system that can automatically synthesize pipelines\nwith multi-step transformations (in Python or other languages), to transform\nnon-relational tables into standard relational forms for downstream analytics,\nobviating the need for users to manually program transformations. We compile an\nextensive benchmark for this new task, by collecting 194 real test cases from\nuser spreadsheets and online forums. Our evaluation suggests that Auto-Tables\ncan successfully synthesize transformations for over 70% of test cases at\ninteractive speeds, without requiring any input from users, making this an\neffective tool for both technical and non-technical users to prepare data for\nanalytics.",
          "link": "http://arxiv.org/abs/2307.14565",
          "publishedOn": "2023-07-29T00:48:57.540Z",
          "wordCount": null,
          "title": "Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize Tables without Using Examples. (arXiv:2307.14565v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14653",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1\">Inbar Seroussi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alemi_A/0/1/0/all/0/1\">Alexander A. Alemi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Helias_M/0/1/0/all/0/1\">Moritz Helias</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1\">Zohar Ringel</a>",
          "description": "State-of-the-art neural networks require extreme computational power to\ntrain. It is therefore natural to wonder whether they are optimally trained.\nHere we apply a recent advancement in stochastic thermodynamics which allows\nbounding the speed at which one can go from the initial weight distribution to\nthe final distribution of the fully trained network, based on the ratio of\ntheir Wasserstein-2 distance and the entropy production rate of the dynamical\nprocess connecting them. Considering both gradient-flow and Langevin training\ndynamics, we provide analytical expressions for these speed limits for linear\nand linearizable neural networks e.g. Neural Tangent Kernel (NTK). Remarkably,\ngiven some plausible scaling assumptions on the NTK spectra and spectral\ndecomposition of the labels -- learning is optimal in a scaling sense. Our\nresults are consistent with small-scale experiments with Convolutional Neural\nNetworks (CNNs) and Fully Connected Neural networks (FCNs) on CIFAR-10, showing\na short highly non-optimal regime followed by a longer optimal regime.",
          "link": "http://arxiv.org/abs/2307.14653",
          "publishedOn": "2023-07-29T00:48:57.500Z",
          "wordCount": null,
          "title": "Speed Limits for Deep Learning. (arXiv:2307.14653v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oesterling_A/0/1/0/all/0/1\">Alex Oesterling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaqi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Hima Lakkaraju</a>",
          "description": "As public consciousness regarding the collection and use of personal\ninformation by corporations grows, it is of increasing importance that\nconsumers be active participants in the curation of corporate datasets. In\nlight of this, data governance frameworks such as the General Data Protection\nRegulation (GDPR) have outlined the right to be forgotten as a key principle\nallowing individuals to request that their personal data be deleted from the\ndatabases and models used by organizations. To achieve forgetting in practice,\nseveral machine unlearning methods have been proposed to address the\ncomputational inefficiencies of retraining a model from scratch with each\nunlearning request. While efficient online alternatives to retraining, it is\nunclear how these methods impact other properties critical to real-world\napplications, such as fairness. In this work, we propose the first fair machine\nunlearning method that can provably and efficiently unlearn data instances\nwhile preserving group fairness. We derive theoretical results which\ndemonstrate that our method can provably unlearn data instances while\nmaintaining fairness objectives. Extensive experimentation with real-world\ndatasets highlight the efficacy of our method at unlearning data instances\nwhile preserving fairness.",
          "link": "http://arxiv.org/abs/2307.14754",
          "publishedOn": "2023-07-29T00:48:57.500Z",
          "wordCount": null,
          "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities. (arXiv:2307.14754v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15045",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Momeni_S/0/1/0/all/0/1\">Saleh Momeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+BabaAli_B/0/1/0/all/0/1\">Bagher BabaAli</a>",
          "description": "Handwriting recognition is a challenging and critical problem in the fields\nof pattern recognition and machine learning, with applications spanning a wide\nrange of domains. In this paper, we focus on the specific issue of recognizing\noffline Arabic handwritten text. Existing approaches typically utilize a\ncombination of convolutional neural networks for image feature extraction and\nrecurrent neural networks for temporal modeling, with connectionist temporal\nclassification used for text generation. However, these methods suffer from a\nlack of parallelization due to the sequential nature of recurrent neural\nnetworks. Furthermore, these models cannot account for linguistic rules,\nnecessitating the use of an external language model in the post-processing\nstage to boost accuracy. To overcome these issues, we introduce two alternative\narchitectures, namely the Transformer Transducer and the standard\nsequence-to-sequence Transformer, and compare their performance in terms of\naccuracy and speed. Our approach can model language dependencies and relies\nonly on the attention mechanism, thereby making it more parallelizable and less\ncomplex. We employ pre-trained Transformers for both image understanding and\nlanguage modeling. Our evaluation on the Arabic KHATT dataset demonstrates that\nour proposed method outperforms the current state-of-the-art approaches for\nrecognizing offline Arabic handwritten text.",
          "link": "http://arxiv.org/abs/2307.15045",
          "publishedOn": "2023-07-29T00:48:57.500Z",
          "wordCount": null,
          "title": "A Transformer-based Approach for Arabic Offline Handwritten Text Recognition. (arXiv:2307.15045v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nancy Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosma_C/0/1/0/all/0/1\">Chrysoula Kosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>",
          "description": "Time series forecasting lies at the core of important real-world applications\nin many fields of science and engineering. The abundance of large time series\ndatasets that consist of complex patterns and long-term dependencies has led to\nthe development of various neural network architectures. Graph neural network\napproaches, which jointly learn a graph structure based on the correlation of\nraw values of multivariate time series while forecasting, have recently seen\ngreat success. However, such solutions are often costly to train and difficult\nto scale. In this paper, we propose TimeGNN, a method that learns dynamic\ntemporal graph representations that can capture the evolution of inter-series\npatterns along with the correlations of multiple series. TimeGNN achieves\ninference times 4 to 80 times faster than other state-of-the-art graph-based\nmethods while achieving comparable forecasting performance",
          "link": "http://arxiv.org/abs/2307.14680",
          "publishedOn": "2023-07-29T00:48:57.499Z",
          "wordCount": null,
          "title": "TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting. (arXiv:2307.14680v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14783",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sulun_S/0/1/0/all/0/1\">Serkan Sulun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oliveira_P/0/1/0/all/0/1\">Pedro Oliveira</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Viana_P/0/1/0/all/0/1\">Paula Viana</a>",
          "description": "We present a new large-scale emotion-labeled symbolic music dataset\nconsisting of 12k MIDI songs. To create this dataset, we first trained emotion\nclassification models on the GoEmotions dataset, achieving state-of-the-art\nresults with a model half the size of the baseline. We then applied these\nmodels to lyrics from two large-scale MIDI datasets. Our dataset covers a wide\nrange of fine-grained emotions, providing a valuable resource to explore the\nconnection between music and emotions and, especially, to develop models that\ncan generate music based on specific emotions. Our code for inference, trained\nmodels, and datasets are available online.",
          "link": "http://arxiv.org/abs/2307.14783",
          "publishedOn": "2023-07-29T00:48:57.499Z",
          "wordCount": null,
          "title": "Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset. (arXiv:2307.14783v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.11264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feihu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>",
          "description": "In the paper, we propose an effective and efficient Compositional Federated\nLearning (ComFedL) algorithm for solving a new compositional Federated Learning\n(FL) framework, which frequently appears in many data mining and machine\nlearning problems with a hierarchical structure such as distributionally robust\nFL and model-agnostic meta learning (MAML). Moreover, we study the convergence\nanalysis of our ComFedL algorithm under some mild conditions, and prove that it\nachieves a convergence rate of $O(\\frac{1}{\\sqrt{T}})$, where $T$ denotes the\nnumber of iteration. To the best of our knowledge, our new Compositional FL\nframework is the first work to bridge federated learning with composition\nstochastic optimization. In particular, we first transform the distributionally\nrobust FL (i.e., a minimax optimization problem) into a simple composition\noptimization problem by using KL divergence regularization. At the same time,\nwe also first transform the distribution-agnostic MAML problem (i.e., a minimax\noptimization problem) into a simple yet effective composition optimization\nproblem. Finally, we apply two popular machine learning tasks, i.e.,\ndistributionally robust FL and MAML to demonstrate the effectiveness of our\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.11264",
          "publishedOn": "2023-07-29T00:48:57.499Z",
          "wordCount": null,
          "title": "Compositional federated learning: Applications in distributionally robust averaging and meta learning. (arXiv:2106.11264v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jing Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_T/0/1/0/all/0/1\">Tianqi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>",
          "description": "Non-intrusive load monitoring (NILM) identifies the status and power\nconsumption of various household appliances by disaggregating the total power\nusage signal of an entire house. Efficient and accurate load monitoring\nfacilitates user profile establishment, intelligent household energy\nmanagement, and peak load shifting. This is beneficial for both the end-users\nand utilities by improving the overall efficiency of a power distribution\nnetwork. Existing approaches mainly focus on developing an individual model for\neach appliance. Those approaches typically rely on a large amount of\nhousehold-labeled data which is hard to collect. In this paper, we propose a\nmulti-appliance-task framework with a training-efficient sample augmentation\n(SA) scheme that boosts the disaggregation performance with limited labeled\ndata. For each appliance, we develop a shared-hierarchical split structure for\nits regression and classification tasks. In addition, we also propose a\ntwo-dimensional attention mechanism in order to capture spatio-temporal\ncorrelations among all appliances. With only one-day training data and limited\nappliance operation profiles, the proposed SA algorithm can achieve comparable\ntest performance to the case of training with the full dataset. Finally,\nsimulation results show that our proposed approach features a significantly\nimproved performance over many baseline models. The relative errors can be\nreduced by more than 50\\% on average. The codes of this work are available at\nhttps://github.com/jxiong22/MATNilm",
          "link": "http://arxiv.org/abs/2307.14778",
          "publishedOn": "2023-07-29T00:48:57.498Z",
          "wordCount": null,
          "title": "MATNilm: Multi-appliance-task Non-intrusive Load Monitoring with Limited Labeled Data. (arXiv:2307.14778v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilm_T/0/1/0/all/0/1\">Timo Wilm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Normann_P/0/1/0/all/0/1\">Philipp Normann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baumeister_S/0/1/0/all/0/1\">Sophie Baumeister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobow_P/0/1/0/all/0/1\">Paul-Vincent Kobow</a>",
          "description": "This work introduces TRON, a scalable session-based Transformer Recommender\nusing Optimized Negative-sampling. Motivated by the scalability and performance\nlimitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates\ntop-k negative sampling and listwise loss functions to enhance its\nrecommendation accuracy. Evaluations on relevant large-scale e-commerce\ndatasets show that TRON improves upon the recommendation quality of current\nmethods while maintaining training speeds similar to SASRec. A live A/B test\nyielded an 18.14% increase in click-through rate over SASRec, highlighting the\npotential of TRON in practical settings. For further research, we provide\naccess to our source code at https://github.com/otto-de/TRON and an anonymized\ndataset at https://github.com/otto-de/recsys-dataset.",
          "link": "http://arxiv.org/abs/2307.14906",
          "publishedOn": "2023-07-29T00:48:57.498Z",
          "wordCount": null,
          "title": "Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions. (arXiv:2307.14906v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cannizzaro_R/0/1/0/all/0/1\">Ricardo Cannizzaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunze_L/0/1/0/all/0/1\">Lars Kunze</a>",
          "description": "Robots operating in real-world environments must reason about possible\noutcomes of stochastic actions and make decisions based on partial observations\nof the true world state. A major challenge for making accurate and robust\naction predictions is the problem of confounding, which if left untreated can\nlead to prediction errors. The partially observable Markov decision process\n(POMDP) is a widely-used framework to model these stochastic and\npartially-observable decision-making problems. However, due to a lack of\nexplicit causal semantics, POMDP planning methods are prone to confounding bias\nand thus in the presence of unobserved confounders may produce underperforming\npolicies. This paper presents a novel causally-informed extension of \"anytime\nregularized determinized sparse partially observable tree\" (AR-DESPOT), a\nmodern anytime online POMDP planner, using causal modelling and inference to\neliminate errors caused by unmeasured confounder variables. We further propose\na method to learn offline the partial parameterisation of the causal model for\nplanning, from ground truth model data. We evaluate our methods on a toy\nproblem with an unobserved confounder and show that the learned causal model is\nhighly accurate, while our planning method is more robust to confounding and\nproduces overall higher performing policies than AR-DESPOT.",
          "link": "http://arxiv.org/abs/2304.06848",
          "publishedOn": "2023-07-29T00:48:57.497Z",
          "wordCount": null,
          "title": "CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in Confounded Environments. (arXiv:2304.06848v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xumin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1\">Yongming Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>",
          "description": "With the overwhelming trend of mask image modeling led by MAE, generative\npre-training has shown a remarkable potential to boost the performance of\nfundamental models in 2D vision. However, in 3D vision, the over-reliance on\nTransformer-based backbones and the unordered nature of point clouds have\nrestricted the further development of generative pre-training. In this paper,\nwe propose a novel 3D-to-2D generative pre-training method that is adaptable to\nany point cloud model. We propose to generate view images from different\ninstructed poses via the cross-attention mechanism as the pre-training scheme.\nGenerating view images has more precise supervision than its point cloud\ncounterpart, thus assisting 3D backbones to have a finer comprehension of the\ngeometrical structure and stereoscopic relations of the point cloud.\nExperimental results have proved the superiority of our proposed 3D-to-2D\ngenerative pre-training over previous pre-training methods. Our method is also\neffective in boosting the performance of architecture-oriented approaches,\nachieving state-of-the-art performance when fine-tuning on ScanObjectNN\nclassification and ShapeNetPart segmentation tasks. Code is available at\nhttps://github.com/wangzy22/TAP.",
          "link": "http://arxiv.org/abs/2307.14971",
          "publishedOn": "2023-07-29T00:48:57.486Z",
          "wordCount": null,
          "title": "Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models. (arXiv:2307.14971v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coelho_C/0/1/0/all/0/1\">C. Coelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_M/0/1/0/all/0/1\">M. Fernanda P. Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferras_L/0/1/0/all/0/1\">L. L. Ferr&#xe1;s</a>",
          "description": "The continuous dynamics of natural systems has been effectively modelled\nusing Neural Ordinary Differential Equations (Neural ODEs). However, for\naccurate and meaningful predictions, it is crucial that the models follow the\nunderlying rules or laws that govern these systems. In this work, we propose a\nself-adaptive penalty algorithm for Neural ODEs to enable modelling of\nconstrained natural systems. The proposed self-adaptive penalty function can\ndynamically adjust the penalty parameters. The explicit introduction of prior\nknowledge helps to increase the interpretability of Neural ODE -based models.\nWe validate the proposed approach by modelling three natural systems with prior\nknowledge constraints: population growth, chemical reaction evolution, and\ndamped harmonic oscillator motion. The numerical experiments and a comparison\nwith other penalty Neural ODE approaches and \\emph{vanilla} Neural ODE,\ndemonstrate the effectiveness of the proposed self-adaptive penalty algorithm\nfor Neural ODEs in modelling constrained natural systems. Moreover, the\nself-adaptive penalty approach provides more accurate and robust models with\nreliable and meaningful predictions.",
          "link": "http://arxiv.org/abs/2307.14940",
          "publishedOn": "2023-07-29T00:48:57.485Z",
          "wordCount": null,
          "title": "A Self-Adaptive Penalty Method for Integrating Prior Knowledge Constraints into Neural ODEs. (arXiv:2307.14940v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims\nto mitigate data distribution shifts when transferring knowledge from multiple\nlabeled source domains to an unlabeled target domain. We propose a novel MSDA\nframework based on dictionary learning and optimal transport. We interpret each\ndomain in MSDA as an empirical distribution. As such, we express each domain as\na Wasserstein barycenter of dictionary atoms, which are empirical\ndistributions. We propose a novel algorithm, DaDiL, for learning via\nmini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.\nBased on our dictionary, we propose two novel methods for MSDA: DaDil-R, based\non the reconstruction of labeled samples in the target domain, and DaDiL-E,\nbased on the ensembling of classifiers learned on atom distributions. We\nevaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU,\nwhere we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in\nclassification performance. Finally, we show that interpolations in the\nWasserstein hull of learned atoms provide data that can generalize to the\ntarget domain.",
          "link": "http://arxiv.org/abs/2307.14953",
          "publishedOn": "2023-07-29T00:48:57.485Z",
          "wordCount": null,
          "title": "Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dubinin_I/0/1/0/all/0/1\">Igor Dubinin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Effenberger_F/0/1/0/all/0/1\">Felix Effenberger</a>",
          "description": "Residual connections have been proposed as architecture-based inductive bias\nto mitigate the problem of exploding and vanishing gradients and increase task\nperformance in both feed-forward and recurrent networks (RNNs) when trained\nwith the backpropagation algorithm. Yet, little is known about how residual\nconnections in RNNs influence their dynamics and fading memory properties.\nHere, we introduce weakly coupled residual recurrent networks (WCRNNs) in which\nresidual connections result in well-defined Lyapunov exponents and allow for\nstudying properties of fading memory. We investigate how the residual\nconnections of WCRNNs influence their performance, network dynamics, and memory\nproperties on a set of benchmark tasks. We show that several distinct forms of\nresidual connections yield effective inductive biases that result in increased\nnetwork expressivity. In particular, residual connections that (i) result in\nnetwork dynamics at the proximity of the edge of chaos, (ii) allow networks to\ncapitalize on characteristic spectral properties of the data, and (iii) result\nin heterogeneous memory properties are shown to increase practical\nexpressivity. In addition, we demonstrate how our results can be extended to\nnon-linear residuals and introduce a weakly coupled residual initialization\nscheme that can be used for Elman RNNs",
          "link": "http://arxiv.org/abs/2307.14823",
          "publishedOn": "2023-07-29T00:48:57.484Z",
          "wordCount": null,
          "title": "Fading memory as inductive bias in residual recurrent networks. (arXiv:2307.14823v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1\">Bo Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Taihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_D/0/1/0/all/0/1\">Daoguang Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_B/0/1/0/all/0/1\">Bing Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_A/0/1/0/all/0/1\">An Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Muhan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Ailun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jichuan Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jingyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuenan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianxiang Wang</a>",
          "description": "Large Language Models for Code (Code LLM) are flourishing. New and powerful\nmodels are released on a weekly basis, demonstrating remarkable performance on\nthe code generation task. Various approaches have been proposed to boost the\ncode generation performance of pre-trained Code LLMs, such as supervised\nfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we\npropose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework,\nwhich can effectively and efficiently boost pre-trained large language models\nfor code generation. Under this framework, we present PanGu-Coder2, which\nachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through\nan extensive evaluation on CoderEval and LeetCode benchmarks, we show that\nPanGu-Coder2 consistently outperforms all previous Code LLMs.",
          "link": "http://arxiv.org/abs/2307.14936",
          "publishedOn": "2023-07-29T00:48:57.483Z",
          "wordCount": null,
          "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback. (arXiv:2307.14936v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuejun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bettaieb_S/0/1/0/all/0/1\">Seifeddine Bettaieb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1\">Qiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Traon_Y/0/1/0/all/0/1\">Yves Le Traon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1\">Qiang Tang</a>",
          "description": "Representing source code in a generic input format is crucial to automate\nsoftware engineering tasks, e.g., applying machine learning algorithms to\nextract information. Visualizing code representations can further enable human\nexperts to gain an intuitive insight into the code. Unfortunately, as of today,\nthere is no universal tool that can simultaneously visualise different types of\ncode representations. In this paper, we introduce a tool, CodeLens, which\nprovides a visual interaction environment that supports various representation\nmethods and helps developers understand and explore them. CodeLens is designed\nto support multiple programming languages, such as Java, Python, and\nJavaScript, and four types of code representations, including sequence of\ntokens, abstract syntax tree (AST), data flow graph (DFG), and control flow\ngraph (CFG). By using CodeLens, developers can quickly visualize the specific\ncode representation and also obtain the represented inputs for models of code.\nThe Web-based interface of CodeLens is available at this http URL\nThe demonstration video can be found at this http URL",
          "link": "http://arxiv.org/abs/2307.14902",
          "publishedOn": "2023-07-29T00:48:57.482Z",
          "wordCount": null,
          "title": "CodeLens: An Interactive Tool for Visualizing Code Representations. (arXiv:2307.14902v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhalla_U/0/1/0/all/0/1\">Usha Bhalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_S/0/1/0/all/0/1\">Suraj Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "With the increased deployment of machine learning models in various\nreal-world applications, researchers and practitioners alike have emphasized\nthe need for explanations of model behaviour. To this end, two broad strategies\nhave been outlined in prior literature to explain models. Post hoc explanation\nmethods explain the behaviour of complex black-box models by highlighting\nfeatures that are critical to model predictions; however, prior work has shown\nthat these explanations may not be faithful, and even more concerning is our\ninability to verify them. Specifically, it is nontrivial to evaluate if a given\nattribution is correct with respect to the underlying model. Inherently\ninterpretable models, on the other hand, circumvent these issues by explicitly\nencoding explanations into model architecture, meaning their explanations are\nnaturally faithful and verifiable, but they often exhibit poor predictive\nperformance due to their limited expressive power. In this work, we aim to\nbridge the gap between the aforementioned strategies by proposing Verifiability\nTuning (VerT), a method that transforms black-box models into models that\nnaturally yield faithful and verifiable feature attributions. We begin by\nintroducing a formal theoretical framework to understand verifiability and show\nthat attributions produced by standard models cannot be verified. We then\nleverage this framework to propose a method to build verifiable models and\nfeature attributions out of fully trained black-box models. Finally, we perform\nextensive experiments on semi-synthetic and real-world datasets, and show that\nVerT produces models that (1) yield explanations that are correct and\nverifiable and (2) are faithful to the original black-box models they are meant\nto explain.",
          "link": "http://arxiv.org/abs/2307.15007",
          "publishedOn": "2023-07-29T00:48:57.482Z",
          "wordCount": null,
          "title": "Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability. (arXiv:2307.15007v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13813",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Busbridge_D/0/1/0/all/0/1\">Dan Busbridge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramapuram_J/0/1/0/all/0/1\">Jason Ramapuram</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1\">Pierre Ablin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dhekane_E/0/1/0/all/0/1\">Eeshan Gunesh Dhekane</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suau_X/0/1/0/all/0/1\">Xavier Suau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_R/0/1/0/all/0/1\">Russ Webb</a>",
          "description": "Preserving training dynamics across batch sizes is an important tool for\npractical machine learning as it enables the trade-off between batch size and\nwall-clock time. This trade-off is typically enabled by a scaling rule, for\nexample, in stochastic gradient descent, one should scale the learning rate\nlinearly with the batch size. Another important tool for practical machine\nlearning is the model Exponential Moving Average (EMA), which is a model copy\nthat does not receive gradient information, but instead follows its target\nmodel with some momentum. This model EMA can improve the robustness and\ngeneralization properties of supervised learning, stabilize pseudo-labeling,\nand provide a learning signal for Self-Supervised Learning (SSL). Prior works\nhave treated the model EMA separately from optimization, leading to different\ntraining dynamics across batch sizes and lower model performance. In this work,\nwe provide a scaling rule for optimization in the presence of model EMAs and\ndemonstrate its validity across a range of architectures, optimizers, and data\nmodalities. We also show the rule's validity where the model EMA contributes to\nthe optimization of the target model, enabling us to train EMA-based\npseudo-labeling and SSL methods at small and large batch sizes. For SSL, we\nenable training of BYOL up to batch size 24,576 without sacrificing\nperformance, optimally a 6$\\times$ wall-clock time reduction.",
          "link": "http://arxiv.org/abs/2307.13813",
          "publishedOn": "2023-07-29T00:48:57.481Z",
          "wordCount": null,
          "title": "How to Scale Your EMA. (arXiv:2307.13813v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Talwar_K/0/1/0/all/0/1\">Kunal Talwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMillan_A/0/1/0/all/0/1\">Audra McMillan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jina_V/0/1/0/all/0/1\">Vojta Jina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_V/0/1/0/all/0/1\">Vitaly Feldman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basile_B/0/1/0/all/0/1\">Bailey Basile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahill_A/0/1/0/all/0/1\">Aine Cahill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_Y/0/1/0/all/0/1\">Yi Sheng Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzidakis_M/0/1/0/all/0/1\">Mike Chatzidakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junye Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chick_O/0/1/0/all/0/1\">Oliver Chick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitnis_M/0/1/0/all/0/1\">Mona Chitnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganta_S/0/1/0/all/0/1\">Suman Ganta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goren_Y/0/1/0/all/0/1\">Yusuf Goren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granqvist_F/0/1/0/all/0/1\">Filip Granqvist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kristine Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_F/0/1/0/all/0/1\">Frederic Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javidbakht_O/0/1/0/all/0/1\">Omid Javidbakht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Albert Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Low_R/0/1/0/all/0/1\">Richard Low</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mascenik_D/0/1/0/all/0/1\">Dan Mascenik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_S/0/1/0/all/0/1\">Steve Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">David Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_W/0/1/0/all/0/1\">Wonhee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parsa_G/0/1/0/all/0/1\">Gianni Parsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauly_T/0/1/0/all/0/1\">Tommy Pauly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priebe_C/0/1/0/all/0/1\">Christian Priebe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rishi_R/0/1/0/all/0/1\">Rehan Rishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rothblum_G/0/1/0/all/0/1\">Guy Rothblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaria_M/0/1/0/all/0/1\">Michael Scaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linmao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Congzheng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarbe_K/0/1/0/all/0/1\">Karl Tarbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_S/0/1/0/all/0/1\">Sebastian Vogt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winstrom_L/0/1/0/all/0/1\">Luke Winstrom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shundong Zhou</a>",
          "description": "We revisit the problem of designing scalable protocols for private statistics\nand private federated learning when each device holds its private data. Our\nfirst contribution is to propose a simple primitive that allows for efficient\nimplementation of several commonly used algorithms, and allows for privacy\naccounting that is close to that in the central setting without requiring the\nstrong trust assumptions it entails. Second, we propose a system architecture\nthat implements this primitive and perform a security analysis of the proposed\nsystem.",
          "link": "http://arxiv.org/abs/2307.15017",
          "publishedOn": "2023-07-29T00:48:57.468Z",
          "wordCount": null,
          "title": "Samplable Anonymous Aggregation for Private Federated Data Analysis. (arXiv:2307.15017v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14588",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_L/0/1/0/all/0/1\">Liang Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Mingxiao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_Y/0/1/0/all/0/1\">Yi Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shao_P/0/1/0/all/0/1\">Pengfei Shao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_S/0/1/0/all/0/1\">Shuwei Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yao_P/0/1/0/all/0/1\">Peng Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_R/0/1/0/all/0/1\">Ronald X.Xu</a>",
          "description": "The UNet architecture, based on Convolutional Neural Networks (CNN), has\ndemonstrated its remarkable performance in medical image analysis. However, it\nfaces challenges in capturing long-range dependencies due to the limited\nreceptive fields and inherent bias of convolutional operations. Recently,\nnumerous transformer-based techniques have been incorporated into the UNet\narchitecture to overcome this limitation by effectively capturing global\nfeature correlations. However, the integration of the Transformer modules may\nresult in the loss of local contextual information during the global feature\nfusion process. To overcome these challenges, we propose a 2D medical image\nsegmentation model called Multi-scale Cross Perceptron Attention Network\n(MCPA). The MCPA consists of three main components: an encoder, a decoder, and\na Cross Perceptron. The Cross Perceptron first captures the local correlations\nusing multiple Multi-scale Cross Perceptron modules, facilitating the fusion of\nfeatures across scales. The resulting multi-scale feature vectors are then\nspatially unfolded, concatenated, and fed through a Global Perceptron module to\nmodel global dependencies. Furthermore, we introduce a Progressive Dual-branch\nStructure to address the semantic segmentation of the image involving finer\ntissue structures. This structure gradually shifts the segmentation focus of\nMCPA network training from large-scale structural features to more\nsophisticated pixel-level features. We evaluate our proposed MCPA model on\nseveral publicly available medical image datasets from different tasks and\ndevices, including the open large-scale dataset of CT (Synapse), MRI (ACDC),\nfundus camera (DRIVE, CHASE_DB1, HRF), and OCTA (ROSE). The experimental\nresults show that our MCPA model achieves state-of-the-art performance. The\ncode is available at\nhttps://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation.",
          "link": "http://arxiv.org/abs/2307.14588",
          "publishedOn": "2023-07-29T00:48:57.467Z",
          "wordCount": null,
          "title": "MCPA: Multi-scale Cross Perceptron Attention Network for 2D Medical Image Segmentation. (arXiv:2307.14588v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yixian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_K/0/1/0/all/0/1\">Kun Zhan</a>",
          "description": "Augmentation techniques and sampling strategies are crucial in contrastive\nlearning, but in most existing works, augmentation techniques require careful\ndesign, and their sampling strategies can only capture a small amount of\nintrinsic supervision information. Additionally, the existing methods require\ncomplex designs to obtain two different representations of the data. To\novercome these limitations, we propose a novel framework called the\nSelf-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two\nmain components: the Attentional Module (AttM) and the Diffusion Module (DiFM).\nAttM aggregates higher-order structure and feature information to get an\nexcellent embedding, while DiFM balances the state of each node in the graph\nthrough Laplacian diffusion learning and allows the cooperative evolution of\nadjacency and feature information in the graph. Unlike existing methodologies,\nSCGDN is an augmentation-free approach that avoids \"sampling bias\" and semantic\ndrift, without the need for pre-training. We conduct a high-quality sampling of\nsamples based on structure and feature information. If two nodes are neighbors,\nthey are considered positive samples of each other. If two disconnected nodes\nare also unrelated on $k$NN graph, they are considered negative samples for\neach other. The contrastive objective reasonably uses our proposed sampling\nstrategies, and the redundancy reduction term minimizes redundant information\nin the embedding and can well retain more discriminative information. In this\nnovel framework, the graph self-contrastive learning paradigm gives expression\nto a powerful force. SCGDN effectively balances between preserving high-order\nstructure information and avoiding overfitting. The results manifest that SCGDN\ncan consistently generate outperformance over both the contrastive methods and\nthe classical methods.",
          "link": "http://arxiv.org/abs/2307.14613",
          "publishedOn": "2023-07-29T00:48:57.467Z",
          "wordCount": null,
          "title": "Self-Contrastive Graph Diffusion Network. (arXiv:2307.14613v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garrigos_G/0/1/0/all/0/1\">Guillaume Garrigos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gower_R/0/1/0/all/0/1\">Robert M. Gower</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaipp_F/0/1/0/all/0/1\">Fabian Schaipp</a>",
          "description": "Here we develop variants of SGD (stochastic gradient descent) with an\nadaptive step size that make use of the sampled loss values. In particular, we\nfocus on solving a finite sum-of-terms problem, also known as empirical risk\nminimization. We first detail an idealized adaptive method called\n$\\texttt{SPS}_+$ that makes use of the sampled loss values and assumes\nknowledge of the sampled loss at optimality. This $\\texttt{SPS}_+$ is a minor\nmodification of the SPS (Stochastic Polyak Stepsize) method, where the step\nsize is enforced to be positive. We then show that $\\texttt{SPS}_+$ achieves\nthe best known rates of convergence for SGD in the Lipschitz non-smooth. We\nthen move onto to develop $\\texttt{FUVAL}$, a variant of $\\texttt{SPS}_+$ where\nthe loss values at optimality are gradually learned, as opposed to being given.\nWe give three viewpoints of $\\texttt{FUVAL}$, as a projection based method, as\na variant of the prox-linear method, and then as a particular online SGD\nmethod. We then present a convergence analysis of $\\texttt{FUVAL}$ and\nexperimental results. The shortcomings of our work is that the convergence\nanalysis of $\\texttt{FUVAL}$ shows no advantage over SGD. Another shortcomming\nis that currently only the full batch version of $\\texttt{FUVAL}$ shows a minor\nadvantages of GD (Gradient Descent) in terms of sensitivity to the step size.\nThe stochastic version shows no clear advantage over SGD. We conjecture that\nlarge mini-batches are required to make $\\texttt{FUVAL}$ competitive.\n\nCurrently the new $\\texttt{FUVAL}$ method studied in this paper does not\noffer any clear theoretical or practical advantage. We have chosen to make this\ndraft available online nonetheless because of some of the analysis techniques\nwe use, such as the non-smooth analysis of $\\texttt{SPS}_+$, and also to show\nan apparently interesting approach that currently does not work.",
          "link": "http://arxiv.org/abs/2307.14528",
          "publishedOn": "2023-07-29T00:48:57.466Z",
          "wordCount": null,
          "title": "Function Value Learning: Adaptive Learning Rates Based on the Polyak Stepsize and Function Splitting in ERM. (arXiv:2307.14528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>",
          "description": "Large language models (LLMs) are now highly capable at a diverse range of\ntasks. This paper studies whether or not GPT-4, one such LLM, is capable of\nassisting researchers in the field of adversarial machine learning. As a case\nstudy, we evaluate the robustness of AI-Guardian, a recent defense to\nadversarial examples published at IEEE S&P 2023, a top computer security\nconference. We completely break this defense: the proposed scheme does not\nincrease robustness compared to an undefended baseline.\n\nWe write none of the code to attack this model, and instead prompt GPT-4 to\nimplement all attack algorithms following our instructions and guidance. This\nprocess was surprisingly effective and efficient, with the language model at\ntimes producing code from ambiguous instructions faster than the author of this\npaper could have done. We conclude by discussing (1) the warning signs present\nin the evaluation that suggested to us AI-Guardian would be broken, and (2) our\nexperience with designing attacks and performing novel research using the most\nrecent advances in language modeling.",
          "link": "http://arxiv.org/abs/2307.15008",
          "publishedOn": "2023-07-29T00:48:57.465Z",
          "wordCount": null,
          "title": "A LLM Assisted Exploitation of AI-Guardian. (arXiv:2307.15008v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Morovati_M/0/1/0/all/0/1\">Mohammad Mehdi Morovati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1\">Amin Nikanjam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tambon_F/0/1/0/all/0/1\">Florian Tambon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Z/0/1/0/all/0/1\">Zhen Ming</a> (Jack) <a href=\"http://arxiv.org/find/cs/1/au:+Jiang/0/1/0/all/0/1\">Jiang</a>",
          "description": "Rapid growth of applying Machine Learning (ML) in different domains,\nespecially in safety-critical areas, increases the need for reliable ML\ncomponents, i.e., a software component operating based on ML. Understanding the\nbugs characteristics and maintenance challenges in ML-based systems can help\ndevelopers of these systems to identify where to focus maintenance and testing\nefforts, by giving insights into the most error-prone components, most common\nbugs, etc. In this paper, we investigate the characteristics of bugs in\nML-based software systems and the difference between ML and non-ML bugs from\nthe maintenance viewpoint. We extracted 447,948 GitHub repositories that used\none of the three most popular ML frameworks, i.e., TensorFlow, Keras, and\nPyTorch. After multiple filtering steps, we select the top 300 repositories\nwith the highest number of closed issues. We manually investigate the extracted\nrepositories to exclude non-ML-based systems. Our investigation involved a\nmanual inspection of 386 sampled reported issues in the identified ML-based\nsystems to indicate whether they affect ML components or not. Our analysis\nshows that nearly half of the real issues reported in ML-based systems are ML\nbugs, indicating that ML components are more error-prone than non-ML\ncomponents. Next, we thoroughly examined 109 identified ML bugs to identify\ntheir root causes, symptoms, and calculate their required fixing time. The\nresults also revealed that ML bugs have significantly different characteristics\ncompared to non-ML bugs, in terms of the complexity of bug-fixing (number of\ncommits, changed files, and changed lines of code). Based on our results,\nfixing ML bugs are more costly and ML components are more error-prone, compared\nto non-ML bugs and non-ML components respectively. Hence, paying a significant\nattention to the reliability of the ML components is crucial in ML-based\nsystems.",
          "link": "http://arxiv.org/abs/2307.14512",
          "publishedOn": "2023-07-29T00:48:57.464Z",
          "wordCount": null,
          "title": "Bug Characterization in Machine Learning-based Systems. (arXiv:2307.14512v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14643",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nie_H/0/1/0/all/0/1\">Haitao Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1\">Bin Xie</a>",
          "description": "How to accurately measure the relevance and redundancy of features is an\nage-old challenge in the field of feature selection. However, existing\nfilter-based feature selection methods cannot directly measure redundancy for\ncontinuous data. In addition, most methods rely on manually specifying the\nnumber of features, which may introduce errors in the absence of expert\nknowledge. In this paper, we propose a non-parametric feature selection\nalgorithm based on maximum inter-class variation and minimum redundancy,\nabbreviated as MVMR-FS. We first introduce supervised and unsupervised kernel\ndensity estimation on the features to capture their similarities and\ndifferences in inter-class and overall distributions. Subsequently, we present\nthe criteria for maximum inter-class variation and minimum redundancy (MVMR),\nwherein the inter-class probability distributions are employed to reflect\nfeature relevance and the distances between overall probability distributions\nare used to quantify redundancy. Finally, we employ an AGA to search for the\nfeature subset that minimizes the MVMR. Compared with ten state-of-the-art\nmethods, MVMR-FS achieves the highest average accuracy and improves the\naccuracy by 5% to 11%.",
          "link": "http://arxiv.org/abs/2307.14643",
          "publishedOn": "2023-07-29T00:48:57.464Z",
          "wordCount": null,
          "title": "MVMR-FS : Non-parametric feature selection algorithm based on Maximum inter-class Variation and Minimum Redundancy. (arXiv:2307.14643v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_P/0/1/0/all/0/1\">Prajit Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_A/0/1/0/all/0/1\">Anant Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rana_P/0/1/0/all/0/1\">Prashant Singh Rana</a>",
          "description": "Armoured vehicles are specialized and complex pieces of machinery designed to\noperate in high-stress environments, often in combat or tactical situations.\nThis study proposes a predictive maintenance-based ensemble system that aids in\npredicting potential maintenance needs based on sensor data collected from\nthese vehicles. The proposed model's architecture involves various models such\nas Light Gradient Boosting, Random Forest, Decision Tree, Extra Tree Classifier\nand Gradient Boosting to predict the maintenance requirements of the vehicles\naccurately. In addition, K-fold cross validation, along with TOPSIS analysis,\nis employed to evaluate the proposed ensemble model's stability. The results\nindicate that the proposed system achieves an accuracy of 98.93%, precision of\n99.80% and recall of 99.03%. The algorithm can effectively predict maintenance\nneeds, thereby reducing vehicle downtime and improving operational efficiency.\nThrough comparisons between various algorithms and the suggested ensemble, this\nstudy highlights the potential of machine learning-based predictive maintenance\nsolutions.",
          "link": "http://arxiv.org/abs/2307.14453",
          "publishedOn": "2023-07-29T00:48:57.463Z",
          "wordCount": null,
          "title": "Predictive Maintenance of Armoured Vehicles using Machine Learning Approaches. (arXiv:2307.14453v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manzini_T/0/1/0/all/0/1\">Thomas Manzini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_R/0/1/0/all/0/1\">Robin Murphy</a>",
          "description": "This paper details the challenges in applying two computer vision systems, an\nEfficientDET supervised learning model and the unsupervised RX spectral\nclassifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and\nrescue (WSAR) effort in Japan and identifies 3 directions for future research.\nThere have been at least 19 proposed approaches and 3 datasets aimed at\nlocating missing persons in drone imagery, but only 3 approaches (2\nunsupervised and 1 of an unknown structure) are referenced in the literature as\nhaving been used in an actual WSAR operation. Of these proposed approaches, the\nEfficientDET architecture and the unsupervised spectral RX classifier were\nselected as the most appropriate for this setting. The EfficientDET model was\napplied to the HERIDAL dataset and despite achieving performance that is\nstatistically equivalent to the state-of-the-art, the model fails to translate\nto the real world in terms of false positives (e.g., identifying tree limbs and\nrocks as people), and false negatives (e.g., failing to identify members of the\nsearch team). The poor results in practice for algorithms that showed good\nresults on datasets suggest 3 areas of future research: more realistic datasets\nfor wilderness SAR, computer vision models that are capable of seamlessly\nhandling the variety of imagery that can be collected during actual WSAR\noperations, and better alignment on performance measures.",
          "link": "http://arxiv.org/abs/2307.14527",
          "publishedOn": "2023-07-29T00:48:57.463Z",
          "wordCount": null,
          "title": "Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad. (arXiv:2307.14527v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrate_C/0/1/0/all/0/1\">Carlo Abrate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preti_G/0/1/0/all/0/1\">Giulia Preti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1\">Francesco Bonchi</a>",
          "description": "Counterfactual examples have emerged as an effective approach to produce\nsimple and understandable post-hoc explanations. In the context of graph\nclassification, previous work has focused on generating counterfactual\nexplanations by manipulating the most elementary units of a graph, i.e.,\nremoving an existing edge, or adding a non-existing one. In this paper, we\nclaim that such language of explanation might be too fine-grained, and turn our\nattention to some of the main characterizing features of real-world complex\nnetworks, such as the tendency to close triangles, the existence of recurring\nmotifs, and the organization into dense modules. We thus define a general\ndensity-based counterfactual search framework to generate instance-level\ncounterfactual explanations for graph classifiers, which can be instantiated\nwith different notions of dense substructures. In particular, we show two\nspecific instantiations of this general framework: a method that searches for\ncounterfactual graphs by opening or closing triangles, and a method driven by\nmaximal cliques. We also discuss how the general method can be instantiated to\nexploit any other notion of dense substructures, including, for instance, a\ngiven taxonomy of nodes. We evaluate the effectiveness of our approaches in 7\nbrain network datasets and compare the counterfactual statements generated\naccording to several widely-used metrics. Results confirm that adopting a\nsemantic-relevant unit of change like density is essential to define versatile\nand interpretable counterfactual explanation methods.",
          "link": "http://arxiv.org/abs/2307.14849",
          "publishedOn": "2023-07-29T00:48:57.462Z",
          "wordCount": null,
          "title": "Counterfactual Explanations for Graph Classification Through the Lenses of Density. (arXiv:2307.14849v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14642",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_K/0/1/0/all/0/1\">Kyurae Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yian Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "We prove that black-box variational inference (BBVI) with control variates,\nparticularly the sticking-the-landing (STL) estimator, converges at a geometric\n(traditionally called \"linear\") rate under perfect variational family\nspecification. In particular, we prove a quadratic bound on the gradient\nvariance of the STL estimator, one which encompasses misspecified variational\nfamilies. Combined with previous works on the quadratic variance condition,\nthis directly implies convergence of BBVI with the use of projected stochastic\ngradient descent. We also improve existing analysis on the regular closed-form\nentropy gradient estimators, which enables comparison against the STL estimator\nand provides explicit non-asymptotic complexity guarantees for both.",
          "link": "http://arxiv.org/abs/2307.14642",
          "publishedOn": "2023-07-29T00:48:57.461Z",
          "wordCount": null,
          "title": "Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.10473",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhihong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Just_H/0/1/0/all/0/1\">Hoang Anh Just</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xiangyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "Data valuation -- quantifying the contribution of individual data sources to\ncertain predictive behaviors of a model -- is of great importance to enhancing\nthe transparency of machine learning and designing incentive systems for data\nsharing. Existing work has focused on evaluating data sources with the shared\nfeature or sample space. How to valuate fragmented data sources of which each\nonly contains partial features and samples remains an open question. We start\nby presenting a method to calculate the counterfactual of removing a fragment\nfrom the aggregated data matrix. Based on the counterfactual calculation, we\nfurther propose 2D-Shapley, a theoretical framework for fragmented data\nvaluation that uniquely satisfies some appealing axioms in the fragmented data\ncontext. 2D-Shapley empowers a range of new use cases, such as selecting useful\ndata fragments, providing interpretation for sample-wise data values, and\nfine-grained data issue diagnosis.",
          "link": "http://arxiv.org/abs/2306.10473",
          "publishedOn": "2023-07-29T00:48:57.461Z",
          "wordCount": null,
          "title": "2D-Shapley: A Framework for Fragmented Data Valuation. (arXiv:2306.10473v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1\">Haotong Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Ge-Peng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Deng-Ping Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in\nthe field of conversational AI. Notably, Bard has recently been updated to\nhandle visual inputs alongside text prompts during conversations. Given Bard's\nimpressive track record in handling textual inputs, we explore its capabilities\nin understanding and interpreting visual data (images) conditioned by text\nquestions. This exploration holds the potential to unveil new insights and\nchallenges for Bard and other forthcoming multi-modal Generative models,\nespecially in addressing complex computer vision problems that demand accurate\nvisual and language understanding. Specifically, in this study, we focus on 15\ndiverse task scenarios encompassing regular, camouflaged, medical, under-water\nand remote sensing data to comprehensively evaluate Bard's performance. Our\nprimary finding indicates that Bard still struggles in these vision scenarios,\nhighlighting the significant gap in vision-based understanding that needs to be\nbridged in future developments. We expect that this empirical study will prove\nvaluable in advancing future models, leading to enhanced capabilities in\ncomprehending and interpreting fine-grained visual data. Our project is\nreleased on https://github.com/htqin/GoogleBard-VisUnderstand",
          "link": "http://arxiv.org/abs/2307.15016",
          "publishedOn": "2023-07-29T00:48:57.460Z",
          "wordCount": null,
          "title": "How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges. (arXiv:2307.15016v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeung_C/0/1/0/all/0/1\">Calvin C. K. Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujii_K/0/1/0/all/0/1\">Keisuke Fujii</a>",
          "description": "Complex interactions between two opposing agents frequently occur in domains\nof machine learning, game theory, and other application domains. Quantitatively\nanalyzing the strategies involved can provide an objective basis for\ndecision-making. One such critical scenario is shot-taking in football, where\ndecisions, such as whether the attacker should shoot or pass the ball and\nwhether the defender should attempt to block the shot, play a crucial role in\nthe outcome of the game. However, there are currently no effective data-driven\nand/or theory-based approaches to analyzing such situations. To address this\nissue, we proposed a novel framework to analyze such scenarios based on game\ntheory, where we estimate the expected payoff with machine learning (ML)\nmodels, and additional features for ML models were extracted with a\ntheory-based shot block model. Conventionally, successes or failures (1 or 0)\nare used as payoffs, while a success shot (goal) is extremely rare in football.\nTherefore, we proposed the Expected Probability of Shot On Target (xSOT) metric\nto evaluate players' actions even if the shot results in no goal; this allows\nfor effective differentiation and comparison between different shots and even\nenables counterfactual shot situation analysis. In our experiments, we have\nvalidated the framework by comparing it with baseline and ablated models.\nFurthermore, we have observed a high correlation between the xSOT and existing\nmetrics. This alignment of information suggests that xSOT provides valuable\ninsights. Lastly, as an illustration, we studied optimal strategies in the\nWorld Cup 2022 and analyzed a shot situation in EURO 2020.",
          "link": "http://arxiv.org/abs/2307.14732",
          "publishedOn": "2023-07-29T00:48:57.459Z",
          "wordCount": null,
          "title": "A Strategic Framework for Optimal Decisions in Football 1-vs-1 Shot-Taking Situations: An Integrated Approach of Machine Learning, Theory-Based Modeling, and Game Theory. (arXiv:2307.14732v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14857",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Heyder_F/0/1/0/all/0/1\">Florian Heyder</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mellado_J/0/1/0/all/0/1\">Juan Pedro Mellado</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schumacher_J/0/1/0/all/0/1\">J&#xf6;rg Schumacher</a>",
          "description": "Turbulence parametrizations will remain a necessary building block in\nkilometer-scale Earth system models. In convective boundary layers, where the\nmean vertical gradients of conserved properties such as potential temperature\nand moisture are approximately zero, the standard ansatz which relates\nturbulent fluxes to mean vertical gradients via an eddy diffusivity has to be\nextended by mass flux parametrizations for the typically asymmetric up- and\ndowndrafts in the atmospheric boundary layer. In this work, we present a\nparametrization for a dry convective boundary layer based on a generative\nadversarial network. The model incorporates the physics of self-similar layer\ngrowth following from the classical mixed layer theory by Deardorff. This\nenhances the training data base of the generative machine learning algorithm\nand thus significantly improves the predicted statistics of the synthetically\ngenerated turbulence fields at different heights inside the boundary layer. The\nalgorithm training is based on fully three-dimensional direct numerical\nsimulation data. Differently to stochastic parametrizations, our model is able\nto predict the highly non-Gaussian transient statistics of buoyancy\nfluctuations, vertical velocity, and buoyancy flux at different heights thus\nalso capturing the fastest thermals penetrating into the stabilized top region.\nThe results of our generative algorithm agree with standard two-equation or\nmulti-plume stochastic mass-flux schemes. The present parametrization provides\nadditionally the granule-type horizontal organization of the turbulent\nconvection which cannot be obtained in any of the other model closures. Our\nwork paves the way to efficient data-driven convective parametrizations in\nother natural flows, such as moist convection, upper ocean mixing, or\nconvection in stellar interiors.",
          "link": "http://arxiv.org/abs/2307.14857",
          "publishedOn": "2023-07-29T00:48:57.459Z",
          "wordCount": null,
          "title": "Generative convective parametrization of dry atmospheric boundary layer. (arXiv:2307.14857v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Stephen Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anokhin_I/0/1/0/all/0/1\">Ivan Anokhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krueger_D/0/1/0/all/0/1\">David Krueger</a>",
          "description": "We propose the Thinker algorithm, a novel approach that enables reinforcement\nlearning agents to autonomously interact with and utilize a learned world\nmodel. The Thinker algorithm wraps the environment with a world model and\nintroduces new actions designed for interacting with the world model. These\nmodel-interaction actions enable agents to perform planning by proposing\nalternative plans to the world model before selecting a final action to execute\nin the environment. This approach eliminates the need for hand-crafted planning\nalgorithms by enabling the agent to learn how to plan autonomously and allows\nfor easy interpretation of the agent's plan with visualization. We demonstrate\nthe algorithm's effectiveness through experimental results in the game of\nSokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves\nstate-of-the-art performance and competitive results, respectively.\nVisualizations of agents trained with the Thinker algorithm demonstrate that\nthey have learned to plan effectively with the world model to select better\nactions. The algorithm's generality opens a new research direction on how a\nworld model can be used in reinforcement learning and how planning can be\nseamlessly integrated into an agent's decision-making process.",
          "link": "http://arxiv.org/abs/2307.14993",
          "publishedOn": "2023-07-29T00:48:57.458Z",
          "wordCount": null,
          "title": "Thinker: Learning to Plan and Act. (arXiv:2307.14993v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassan_S/0/1/0/all/0/1\">Sheikh Md Shakeel Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feeney_A/0/1/0/all/0/1\">Arthur Feeney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhruv_A/0/1/0/all/0/1\">Akash Dhruv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jihoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_Y/0/1/0/all/0/1\">Youngjoon Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1\">Jaiyoung Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Won_Y/0/1/0/all/0/1\">Yoonjin Won</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandramowlishwaran_A/0/1/0/all/0/1\">Aparna Chandramowlishwaran</a>",
          "description": "In the field of phase change phenomena, the lack of accessible and diverse\ndatasets suitable for machine learning (ML) training poses a significant\nchallenge. Existing experimental datasets are often restricted, with limited\navailability and sparse ground truth data, impeding our understanding of this\ncomplex multi-physics phenomena. To bridge this gap, we present the BubbleML\nDataset(https://github.com/HPCForge/BubbleML) which leverages physics-driven\nsimulations to provide accurate ground truth information for various boiling\nscenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled\nboiling. This extensive dataset covers a wide range of parameters, including\nvarying gravity conditions, flow rates, sub-cooling levels, and wall superheat,\ncomprising 51 simulations. BubbleML is validated against experimental\nobservations and trends, establishing it as an invaluable resource for ML\nresearch. Furthermore, we showcase its potential to facilitate exploration of\ndiverse downstream tasks by introducing two benchmarks: (a) optical flow\nanalysis to capture bubble dynamics, and (b) operator networks for learning\ntemperature dynamics. The BubbleML dataset and its benchmarks serve as a\ncatalyst for advancements in ML-driven research on multi-physics phase change\nphenomena, enabling the development and comparison of state-of-the-art\ntechniques and models.",
          "link": "http://arxiv.org/abs/2307.14623",
          "publishedOn": "2023-07-29T00:48:57.457Z",
          "wordCount": null,
          "title": "BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning. (arXiv:2307.14623v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Williams_W/0/1/0/all/0/1\">Warren R. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glandon_S/0/1/0/all/0/1\">S. Ross Glandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_L/0/1/0/all/0/1\">Luke L. Morris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jing-Ru C. Cheng</a>",
          "description": "Performance Benchmarking of HPC systems is an ongoing effort that seeks to\nprovide information that will allow for increased performance and improve the\njob schedulers that manage these systems. We develop a benchmarking tool that\nutilizes machine learning models and gathers performance data on\nGPU-accelerated nodes while they perform material segmentation analysis. The\nbenchmark uses a ML model that has been converted from Caffe to PyTorch using\nthe MMdnn toolkit and the MINC-2500 dataset. Performance data is gathered on\ntwo ERDC DSRC systems, Onyx and Vulcanite. The data reveals that while\nVulcanite has faster model times in a large number of benchmarks, and it is\nalso more subject to some environmental factors that can cause performances\nslower than Onyx. In contrast the model times from Onyx are consistent across\nbenchmarks.",
          "link": "http://arxiv.org/abs/2307.14921",
          "publishedOn": "2023-07-29T00:48:57.457Z",
          "wordCount": null,
          "title": "Benchmarking Performance of Deep Learning Model for Material Segmentation on Two HPC Systems. (arXiv:2307.14921v1 [cs.PF])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cosenza_E/0/1/0/all/0/1\">Emanuele Cosenza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valenti_A/0/1/0/all/0/1\">Andrea Valenti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1\">Davide Bacciu</a>",
          "description": "Graphs can be leveraged to model polyphonic multitrack symbolic music, where\nnotes, chords and entire sections may be linked at different levels of the\nmusical hierarchy by tonal and rhythmic relationships. Nonetheless, there is a\nlack of works that consider graph representations in the context of deep\nlearning systems for music generation. This paper bridges this gap by\nintroducing a novel graph representation for music and a deep Variational\nAutoencoder that generates the structure and the content of musical graphs\nseparately, one after the other, with a hierarchical architecture that matches\nthe structural priors of music. By separating the structure and content of\nmusical graphs, it is possible to condition generation by specifying which\ninstruments are played at certain times. This opens the door to a new form of\nhuman-computer interaction in the context of music co-creation. After training\nthe model on existing MIDI datasets, the experiments show that the model is\nable to generate appealing short and long musical sequences and to\nrealistically interpolate between them, producing music that is tonally and\nrhythmically consistent. Finally, the visualization of the embeddings shows\nthat the model is able to organize its latent space in accordance with known\nmusical concepts.",
          "link": "http://arxiv.org/abs/2307.14928",
          "publishedOn": "2023-07-29T00:48:57.456Z",
          "wordCount": null,
          "title": "Graph-based Polyphonic Multitrack Music Generation. (arXiv:2307.14928v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elbatel_M/0/1/0/all/0/1\">Marawan Elbatel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hualiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marti_R/0/1/0/all/0/1\">Robert Mart&#xed;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaomeng Li</a>",
          "description": "In the medical field, federated learning commonly deals with highly\nimbalanced datasets, including skin lesions and gastrointestinal images.\nExisting federated methods under highly imbalanced datasets primarily focus on\noptimizing a global model without incorporating the intra-class variations that\ncan arise in medical imaging due to different populations, findings, and\nscanners. In this paper, we study the inter-client intra-class variations with\npublicly available self-supervised auxiliary networks. Specifically, we find\nthat employing a shared auxiliary pre-trained model, like MoCo-V2, locally on\nevery client yields consistent divergence measurements. Based on these\nfindings, we derive a dynamic balanced model aggregation via self-supervised\npriors (MAS) to guide the global model optimization. Fed-MAS can be utilized\nwith different local learning methods for effective model aggregation toward a\nhighly robust and unbiased global model. Our code is available at\n\\url{https://github.com/xmed-lab/Fed-MAS}.",
          "link": "http://arxiv.org/abs/2307.14959",
          "publishedOn": "2023-07-29T00:48:57.455Z",
          "wordCount": null,
          "title": "Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification. (arXiv:2307.14959v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14459",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Viszlai_J/0/1/0/all/0/1\">Joshua Viszlai</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tomesh_T/0/1/0/all/0/1\">Teague Tomesh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gokhale_P/0/1/0/all/0/1\">Pranav Gokhale</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Anschuetz_E/0/1/0/all/0/1\">Eric Anschuetz</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chong_F/0/1/0/all/0/1\">Frederic T. Chong</a>",
          "description": "Recent work has proposed and explored using coreset techniques for quantum\nalgorithms that operate on classical data sets to accelerate the applicability\nof these algorithms on near-term quantum devices. We apply these ideas to\nQuantum Boltzmann Machines (QBM) where gradient-based steps which require Gibbs\nstate sampling are the main computational bottleneck during training. By using\na coreset in place of the full data set, we try to minimize the number of steps\nneeded and accelerate the overall training time. In a regime where\ncomputational time on quantum computers is a precious resource, we propose this\nmight lead to substantial practical savings. We evaluate this approach on 6x6\nbinary images from an augmented bars and stripes data set using a QBM with 36\nvisible units and 8 hidden units. Using an Inception score inspired metric, we\ncompare QBM training times with and without using coresets.",
          "link": "http://arxiv.org/abs/2307.14459",
          "publishedOn": "2023-07-29T00:48:57.423Z",
          "wordCount": null,
          "title": "Training Quantum Boltzmann Machines with Coresets. (arXiv:2307.14459v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14654",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Reddy_P/0/1/0/all/0/1\">P. Jyoteeshkumar Reddy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chinta_S/0/1/0/all/0/1\">Sandeep Chinta</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Matear_R/0/1/0/all/0/1\">Richard Matear</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Taylor_J/0/1/0/all/0/1\">John Taylor</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Baki_H/0/1/0/all/0/1\">Harish Baki</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Thatcher_M/0/1/0/all/0/1\">Marcus Thatcher</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kala_J/0/1/0/all/0/1\">Jatin Kala</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sharples_J/0/1/0/all/0/1\">Jason Sharples</a>",
          "description": "Heatwaves and bushfires cause substantial impacts on society and ecosystems\nacross the globe. Accurate information of heat extremes is needed to support\nthe development of actionable mitigation and adaptation strategies. Regional\nclimate models are commonly used to better understand the dynamics of these\nevents. These models have very large input parameter sets, and the parameters\nwithin the physics schemes substantially influence the model's performance.\nHowever, parameter sensitivity analysis (SA) of regional models for heat\nextremes is largely unexplored. Here, we focus on the southeast Australian\nregion, one of the global hotspots of heat extremes. In southeast Australia\nWeather Research and Forecasting (WRF) model is the widely used regional model\nto simulate extreme weather events across the region. Hence in this study, we\nfocus on the sensitivity of WRF model parameters to surface meteorological\nvariables such as temperature, relative humidity, and wind speed during two\nextreme heat events over southeast Australia. Due to the presence of multiple\nparameters and their complex relationship with output variables, a machine\nlearning (ML) surrogate-based global sensitivity analysis method is considered\nfor the SA. The ML surrogate-based Sobol SA is used to identify the sensitivity\nof 24 adjustable parameters in seven different physics schemes of the WRF\nmodel. Results show that out of these 24, only three parameters, namely the\nscattering tuning parameter, multiplier of saturated soil water content, and\nprofile shape exponent in the momentum diffusivity coefficient, are important\nfor the considered meteorological variables. These SA results are consistent\nfor the two different extreme heat events. Further, we investigated the\nphysical significance of sensitive parameters. This study's results will help\nin further optimising WRF parameters to improve model simulation.",
          "link": "http://arxiv.org/abs/2307.14654",
          "publishedOn": "2023-07-29T00:48:57.423Z",
          "wordCount": null,
          "title": "Machine Learning based Parameter Sensitivity of Regional Climate Models -- A Case Study of the WRF Model for Heat Extremes over Southeast Australia. (arXiv:2307.14654v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gijon_A/0/1/0/all/0/1\">Alfonso Gij&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujana_Goitia_A/0/1/0/all/0/1\">Ainhoa Pujana-Goitia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perea_E/0/1/0/all/0/1\">Eugenio Perea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_Solana_M/0/1/0/all/0/1\">Miguel Molina-Solana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Romero_J/0/1/0/all/0/1\">Juan G&#xf3;mez-Romero</a>",
          "description": "The ever-growing use of wind energy makes necessary the optimization of\nturbine operations through pitch angle controllers and their maintenance with\nearly fault detection. It is crucial to have accurate and robust models\nimitating the behavior of wind turbines, especially to predict the generated\npower as a function of the wind speed. Existing empirical and physics-based\nmodels have limitations in capturing the complex relations between the input\nvariables and the power, aggravated by wind variability. Data-driven methods\noffer new opportunities to enhance wind turbine modeling of large datasets by\nimproving accuracy and efficiency. In this study, we used physics-informed\nneural networks to reproduce historical data coming from 4 turbines in a wind\nfarm, while imposing certain physical constraints to the model. The developed\nmodels for regression of the power, torque, and power coefficient as output\nvariables showed great accuracy for both real data and physical equations\ngoverning the system. Lastly, introducing an efficient evidential layer\nprovided uncertainty estimations of the predictions, proved to be consistent\nwith the absolute error, and made possible the definition of a confidence\ninterval in the power curve.",
          "link": "http://arxiv.org/abs/2307.14675",
          "publishedOn": "2023-07-29T00:48:57.423Z",
          "wordCount": null,
          "title": "Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification. (arXiv:2307.14675v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaluza_D/0/1/0/all/0/1\">Daniel Ka&#x142;u&#x17c;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janusz_A/0/1/0/all/0/1\">Andrzej Janusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Dominik &#x15a;l&#x119;zak</a>",
          "description": "Supervised classification algorithms are used to solve a growing number of\nreal-life problems around the globe. Their performance is strictly connected\nwith the quality of labels used in training. Unfortunately, acquiring\ngood-quality annotations for many tasks is infeasible or too expensive to be\ndone in practice. To tackle this challenge, active learning algorithms are\ncommonly employed to select only the most relevant data for labeling. However,\nthis is possible only when the quality and quantity of labels acquired from\nexperts are sufficient. Unfortunately, in many applications, a trade-off\nbetween annotating individual samples by multiple annotators to increase label\nquality vs. annotating new samples to increase the total number of labeled\ninstances is necessary. In this paper, we address the issue of faulty data\nannotations in the context of active learning. In particular, we propose two\nnovel annotation unification algorithms that utilize unlabeled parts of the\nsample space. The proposed methods require little to no intersection between\nsamples annotated by different experts. Our experiments on four public datasets\nindicate the robustness and superiority of the proposed methods in both, the\nestimation of the annotator's reliability, and the assignment of actual labels,\nagainst the state-of-the-art algorithms and the simple majority voting.",
          "link": "http://arxiv.org/abs/2307.14380",
          "publishedOn": "2023-07-29T00:48:57.422Z",
          "wordCount": null,
          "title": "Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations. (arXiv:2307.14380v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zezhi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuchen Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_G/0/1/0/all/0/1\">Guangyin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yongjun Xu</a>",
          "description": "Traffic forecasting, which aims to predict traffic conditions based on\nhistorical observations, has been an enduring research topic and is widely\nrecognized as an essential component of intelligent transportation. Recent\nproposals on Spatial-Temporal Graph Neural Networks (STGNNs) have made\nsignificant progress by combining sequential models with graph convolution\nnetworks. However, due to high complexity issues, STGNNs only focus on\nshort-term traffic forecasting, e.g., 1-hour forecasting, while ignoring more\npractical long-term forecasting. In this paper, we make the first attempt to\nexplore long-term traffic forecasting, e.g., 1-day forecasting. To this end, we\nfirst reveal its unique challenges in exploiting multi-scale representations.\nThen, we propose a novel Hierarchical U-net TransFormer (HUTFormer) to address\nthe issues of long-term traffic forecasting. HUTFormer consists of a\nhierarchical encoder and decoder to jointly generate and utilize multi-scale\nrepresentations of traffic data. Specifically, for the encoder, we propose\nwindow self-attention and segment merging to extract multi-scale\nrepresentations from long-term traffic data. For the decoder, we design a\ncross-scale attention mechanism to effectively incorporate multi-scale\nrepresentations. In addition, HUTFormer employs an efficient input embedding\nstrategy to address the complexity issues. Extensive experiments on four\ntraffic datasets show that the proposed HUTFormer significantly outperforms\nstate-of-the-art traffic forecasting and long time series forecasting\nbaselines.",
          "link": "http://arxiv.org/abs/2307.14596",
          "publishedOn": "2023-07-29T00:48:57.422Z",
          "wordCount": null,
          "title": "HUTFormer: Hierarchical U-Net Transformer for Long-Term Traffic Forecasting. (arXiv:2307.14596v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chennu_S/0/1/0/all/0/1\">Srivas Chennu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maher_A/0/1/0/all/0/1\">Andrew Maher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pangerl_C/0/1/0/all/0/1\">Christian Pangerl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabanantham_S/0/1/0/all/0/1\">Subash Prabanantham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_J/0/1/0/all/0/1\">Jae Hyeon Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1\">Jamie Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_B/0/1/0/all/0/1\">Bud Goswami</a>",
          "description": "AB testing aids business operators with their decision making, and is\nconsidered the gold standard method for learning from data to improve digital\nuser experiences. However, there is usually a gap between the requirements of\npractitioners, and the constraints imposed by the statistical hypothesis\ntesting methodologies commonly used for analysis of AB tests. These include the\nlack of statistical power in multivariate designs with many factors,\ncorrelations between these factors, the need of sequential testing for early\nstopping, and the inability to pool knowledge from past tests. Here, we propose\na solution that applies hierarchical Bayesian estimation to address the above\nlimitations. In comparison to current sequential AB testing methodology, we\nincrease statistical power by exploiting correlations between factors, enabling\nsequential testing and progressive early stopping, without incurring excessive\nfalse positive risk. We also demonstrate how this methodology can be extended\nto enable the extraction of composite global learnings from past AB tests, to\naccelerate future tests. We underpin our work with a solid theoretical\nframework that articulates the value of hierarchical estimation. We demonstrate\nits utility using both numerical simulations and a large set of real-world AB\ntests. Together, these results highlight the practical value of our approach\nfor statistical inference in the technology industry.",
          "link": "http://arxiv.org/abs/2307.14628",
          "publishedOn": "2023-07-29T00:48:57.422Z",
          "wordCount": null,
          "title": "Rapid and Scalable Bayesian AB Testing. (arXiv:2307.14628v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Sen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Weishen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>",
          "description": "Algorithmic fairness has been a serious concern and received lots of interest\nin machine learning community. In this paper, we focus on the bipartite ranking\nscenario, where the instances come from either the positive or negative class\nand the goal is to learn a ranking function that ranks positive instances\nhigher than negative ones. While there could be a trade-off between fairness\nand performance, we propose a model agnostic post-processing framework xOrder\nfor achieving fairness in bipartite ranking and maintaining the algorithm\nclassification performance. In particular, we optimize a weighted sum of the\nutility as identifying an optimal warping path across different protected\ngroups and solve it through a dynamic programming process. xOrder is compatible\nwith various classification models and ranking fairness metrics, including\nsupervised and unsupervised fairness metrics. In addition to binary groups,\nxOrder can be applied to multiple protected groups. We evaluate our proposed\nalgorithm on four benchmark data sets and two real-world patient electronic\nhealth record repositories. xOrder consistently achieves a better balance\nbetween the algorithm utility and ranking fairness on a variety of datasets\nwith different metrics. From the visualization of the calibrated ranking\nscores, xOrder mitigates the score distribution shifts of different groups\ncompared with baselines. Moreover, additional analytical results verify that\nxOrder achieves a robust performance when faced with fewer samples and a bigger\ndifference between training and testing ranking score distributions.",
          "link": "http://arxiv.org/abs/2307.14668",
          "publishedOn": "2023-07-29T00:48:57.421Z",
          "wordCount": null,
          "title": "Bipartite Ranking Fairness through a Model Agnostic Ordering Adjustment. (arXiv:2307.14668v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bralios_D/0/1/0/all/0/1\">Dimitrios Bralios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1\">Efthymios Tzinis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smaragdis_P/0/1/0/all/0/1\">Paris Smaragdis</a>",
          "description": "Recent approaches in source separation leverage semantic information about\ntheir input mixtures and constituent sources that when used in conditional\nseparation models can achieve impressive performance. Most approaches along\nthese lines have focused on simple descriptions, which are not always useful\nfor varying types of input mixtures. In this work, we present an approach in\nwhich a model, given an input mixture and partial semantic information about a\ntarget source, is trained to extract additional semantic data. We then leverage\nthis pre-trained model to improve the separation performance of an uncoupled\nmulti-conditional separation network. Our experiments demonstrate that the\nseparation performance of this multi-conditional model is significantly\nimproved, approaching the performance of an oracle model with complete semantic\ninformation. Furthermore, our approach achieves performance levels that are\ncomparable to those of the best performing specialized single conditional\nmodels, thus providing an easier to use alternative.",
          "link": "http://arxiv.org/abs/2307.14609",
          "publishedOn": "2023-07-29T00:48:57.420Z",
          "wordCount": null,
          "title": "Complete and separate: Conditional separation with missing target source attribute completion. (arXiv:2307.14609v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14729",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bungert_T/0/1/0/all/0/1\">Till J. Bungert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kobelke_L/0/1/0/all/0/1\">Levin Kobelke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jaeger_P/0/1/0/all/0/1\">Paul F. Jaeger</a>",
          "description": "To ensure the reliable use of classification systems in medical applications,\nit is crucial to prevent silent failures. This can be achieved by either\ndesigning classifiers that are robust enough to avoid failures in the first\nplace, or by detecting remaining failures using confidence scoring functions\n(CSFs). A predominant source of failures in image classification is\ndistribution shifts between training data and deployment data. To understand\nthe current state of silent failure prevention in medical imaging, we conduct\nthe first comprehensive analysis comparing various CSFs in four biomedical\ntasks and a diverse range of distribution shifts. Based on the result that none\nof the benchmarked CSFs can reliably prevent silent failures, we conclude that\na deeper understanding of the root causes of failures in the data is required.\nTo facilitate this, we introduce SF-Visuals, an interactive analysis tool that\nuses latent space clustering to visualize shifts and failures. On the basis of\nvarious examples, we demonstrate how this tool can help researchers gain\ninsight into the requirements for safe application of classification systems in\nthe medical domain. The open-source benchmark and tool are at:\nhttps://github.com/IML-DKFZ/sf-visuals.",
          "link": "http://arxiv.org/abs/2307.14729",
          "publishedOn": "2023-07-29T00:48:57.420Z",
          "wordCount": null,
          "title": "Understanding Silent Failures in Medical Image Classification. (arXiv:2307.14729v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14367",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Abdine_H/0/1/0/all/0/1\">Hadi Abdine</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chatzianastasis_M/0/1/0/all/0/1\">Michail Chatzianastasis</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bouyioukos_C/0/1/0/all/0/1\">Costas Bouyioukos</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>",
          "description": "The complex nature of big biological systems pushed some scientists to\nclassify its understanding under the inconceivable missions. Different leveled\nchallenges complicated this task, one of is the prediction of a protein's\nfunction. In recent years, significant progress has been made in this field\nthrough the development of various machine learning approaches. However, most\nexisting methods formulate the task as a multi-classification problem, i.e\nassigning predefined labels to proteins. In this work, we propose a novel\napproach, \\textbf{Prot2Text}, which predicts a protein function's in a free\ntext style, moving beyond the conventional binary or categorical\nclassifications. By combining Graph Neural Networks(GNNs) and Large Language\nModels(LLMs), in an encoder-decoder framework, our model effectively integrates\ndiverse data types including proteins' sequences, structures, and textual\nannotations. This multimodal approach allows for a holistic representation of\nproteins' functions, enabling the generation of detailed and accurate\ndescriptions. To evaluate our model, we extracted a multimodal protein dataset\nfrom SwissProt, and demonstrate empirically the effectiveness of Prot2Text.\nThese results highlight the transformative impact of multimodal models,\nspecifically the fusion of GNNs and LLMs, empowering researchers with powerful\ntools for more accurate prediction of proteins' functions. The code, the models\nand a demo will be publicly released.",
          "link": "http://arxiv.org/abs/2307.14367",
          "publishedOn": "2023-07-29T00:48:57.380Z",
          "wordCount": null,
          "title": "Prot2Text: Multimodal Protein's Function Generation with GNNs and Transformers. (arXiv:2307.14367v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.02109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdisarabshali_P/0/1/0/all/0/1\">Payam Abdisarabshali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Accurso_N/0/1/0/all/0/1\">Nicholas Accurso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malandra_F/0/1/0/all/0/1\">Filippo Malandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weifeng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1\">Seyyedali Hosseinalipour</a>",
          "description": "Federated learning (FL) is the most popular distributed machine learning\ntechnique. However, implementation of FL over modern wireless networks faces\nkey challenges caused by (i) dynamics of the network conditions and (ii) the\ncoexistence of multiple FL services/tasks and other network services in the\nsystem, which are not jointly considered in prior works. Motivated by these\nchallenges, we introduce a generic FL paradigm over NextG networks, called\ndynamic multi-service FL (DMS-FL). We identify three unexplored design\nconsiderations in DMS-FL: (i) FL service operator accumulation, (ii) wireless\nresource fragmentation, and (iii) signal strength fluctuations. We take the\nfirst steps towards addressing these design considerations by proposing a novel\ndistributed ML architecture called elastic virtualized FL (EV-FL). EV-FL\nunleashes the full potential of Open RAN (O-RAN) systems and introduces an\nelastic resource provisioning methodology to execute FL services. It further\nconstitutes a multi-time-scale FL management system that introduces three\ndimensions into existing FL architectures: (i) virtualization, (ii)\nscalability, and (iii) elasticity. Through investigating EV-FL, we reveal a\nseries of open research directions for future work. We finally simulate EV-FL\nto demonstrate its potential in saving wireless resources and increasing\nfairness among FL services.",
          "link": "http://arxiv.org/abs/2305.02109",
          "publishedOn": "2023-07-29T00:48:57.380Z",
          "wordCount": null,
          "title": "Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services. (arXiv:2305.02109v2 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dvir_N/0/1/0/all/0/1\">Nimrod Dvir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedman_E/0/1/0/all/0/1\">Elaine Friedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Commuri_S/0/1/0/all/0/1\">Suraj Commuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+yang_F/0/1/0/all/0/1\">Fan yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romano_J/0/1/0/all/0/1\">Jennifer Romano</a>",
          "description": "This study introduces and empirically tests a novel predictive model for\ndigital information engagement (IE) - the READ model, an acronym for the four\npivotal attributes of engaging information: Representativeness, Ease-of-use,\nAffect, and Distribution. Conceptualized within the theoretical framework of\nCumulative Prospect Theory, the model integrates key cognitive biases with\ncomputational linguistics and natural language processing to develop a\nmultidimensional perspective on information engagement. A rigorous testing\nprotocol was implemented, involving 50 randomly selected pairs of synonymous\nwords (100 words in total) from the WordNet database. These words' engagement\nlevels were evaluated through a large-scale online survey (n = 80,500) to\nderive empirical IE metrics. The READ attributes for each word were then\ncomputed and their predictive efficacy examined. The findings affirm the READ\nmodel's robustness, accurately predicting a word's IE level and distinguishing\nthe more engaging word from a pair of synonyms with an 84% accuracy rate. The\nREAD model's potential extends across various domains, including business,\neducation, government, and healthcare, where it could enhance content\nengagement and inform AI language model development and generative text work.\nFuture research should address the model's scalability and adaptability across\ndifferent domains and languages, thereby broadening its applicability and\nefficacy.",
          "link": "http://arxiv.org/abs/2307.14500",
          "publishedOn": "2023-07-29T00:48:57.379Z",
          "wordCount": null,
          "title": "A Predictive Model of Digital Information Engagement: Forecasting User Engagement With English Words by Incorporating Cognitive Biases, Computational Linguistics and Natural Language Processing. (arXiv:2307.14500v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geifman_A/0/1/0/all/0/1\">Amnon Geifman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilai_D/0/1/0/all/0/1\">Daniel Barzilai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1\">Ronen Basri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galun_M/0/1/0/all/0/1\">Meirav Galun</a>",
          "description": "Wide neural networks are biased towards learning certain functions,\ninfluencing both the rate of convergence of gradient descent (GD) and the\nfunctions that are reachable with GD in finite training time. As such, there is\na great need for methods that can modify this bias according to the task at\nhand. To that end, we introduce Modified Spectrum Kernels (MSKs), a novel\nfamily of constructed kernels that can be used to approximate kernels with\ndesired eigenvalues for which no closed form is known. We leverage the duality\nbetween wide neural networks and Neural Tangent Kernels and propose a\npreconditioned gradient descent method, which alters the trajectory of GD. As a\nresult, this allows for a polynomial and, in some cases, exponential training\nspeedup without changing the final solution. Our method is both computationally\nefficient and simple to implement.",
          "link": "http://arxiv.org/abs/2307.14531",
          "publishedOn": "2023-07-29T00:48:57.379Z",
          "wordCount": null,
          "title": "Controlling the Inductive Bias of Wide Neural Networks by Modifying the Kernel's Spectrum. (arXiv:2307.14531v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>",
          "description": "In this paper, we study the denoising diffusion probabilistic model (DDPM) in\nwavelet space, instead of pixel space, for visual synthesis. Considering the\nwavelet transform represents the image in spatial and frequency domains, we\ncarefully design a novel architecture SFUNet to effectively capture the\ncorrelation for both domains. Specifically, in the standard denoising U-Net for\npixel data, we supplement the 2D convolutions and spatial-only attention layers\nwith our spatial frequency-aware convolution and attention modules to jointly\nmodel the complementary information from spatial and frequency domains in\nwavelet data. Our new architecture can be used as a drop-in replacement to the\npixel-based network and is compatible with the vanilla DDPM training process.\nBy explicitly modeling the wavelet signals, we find our model is able to\ngenerate images with higher quality on CIFAR-10, FFHQ, LSUN-Bedroom, and\nLSUN-Church datasets, than the pixel-based counterpart.",
          "link": "http://arxiv.org/abs/2307.14648",
          "publishedOn": "2023-07-29T00:48:57.379Z",
          "wordCount": null,
          "title": "Spatial-Frequency U-Net for Denoising Diffusion Probabilistic Models. (arXiv:2307.14648v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1\">Xinting Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaochao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pengyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Huabin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">Yanchao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yue Qi</a>",
          "description": "Federated learning (FL) collaboratively models user data in a decentralized\nway. However, in the real world, non-identical and independent data\ndistributions (non-IID) among clients hinder the performance of FL due to three\nissues, i.e., (1) the class statistics shifting, (2) the insufficient\nhierarchical information utilization, and (3) the inconsistency in aggregating\nclients. To address the above issues, we propose HyperFed which contains three\nmain modules, i.e., hyperbolic prototype Tammes initialization (HPTI),\nhyperbolic prototype learning (HPL), and consistent aggregation (CA). Firstly,\nHPTI in the server constructs uniformly distributed and fixed class prototypes,\nand shares them with clients to match class statistics, further guiding\nconsistent feature representation for local clients. Secondly, HPL in each\nclient captures the hierarchical information in local data with the supervision\nof shared class prototypes in the hyperbolic model space. Additionally, CA in\nthe server mitigates the impact of the inconsistent deviations from clients to\nserver. Extensive studies of four datasets prove that HyperFed is effective in\nenhancing the performance of FL under the non-IID set.",
          "link": "http://arxiv.org/abs/2307.14384",
          "publishedOn": "2023-07-29T00:48:57.378Z",
          "wordCount": null,
          "title": "HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning. (arXiv:2307.14384v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Razi Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Ge Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalra_M/0/1/0/all/0/1\">Mannudeep Kalra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1\">Pingkun Yan</a>",
          "description": "With advances in generative artificial intelligence (AI), it is now possible\nto produce realistic-looking automated reports for preliminary reads of\nradiology images. This can expedite clinical workflows, improve accuracy and\nreduce overall costs. However, it is also well-known that such models often\nhallucinate, leading to false findings in the generated reports. In this paper,\nwe propose a new method of fact-checking of AI-generated reports using their\nassociated images. Specifically, the developed examiner differentiates real and\nfake sentences in reports by learning the association between an image and\nsentences describing real or potentially fake findings. To train such an\nexaminer, we first created a new dataset of fake reports by perturbing the\nfindings in the original ground truth radiology reports associated with images.\nText encodings of real and fake sentences drawn from these reports are then\npaired with image encodings to learn the mapping to real/fake labels. The\nutility of such an examiner is demonstrated for verifying automatically\ngenerated reports by detecting and removing fake sentences. Future generative\nAI approaches can use the resulting tool to validate their reports leading to a\nmore responsible use of AI in expediting clinical workflows.",
          "link": "http://arxiv.org/abs/2307.14634",
          "publishedOn": "2023-07-29T00:48:57.378Z",
          "wordCount": null,
          "title": "Fact-Checking of AI-Generated Reports. (arXiv:2307.14634v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhijith Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munz_P/0/1/0/all/0/1\">Phil Munz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_A/0/1/0/all/0/1\">Apurva Narayan</a>",
          "description": "Visual AI systems are vulnerable to natural and synthetic physical corruption\nin the real-world. Such corruption often arises unexpectedly and alters the\nmodel's performance. In recent years, the primary focus has been on adversarial\nattacks. However, natural corruptions (e.g., snow, fog, dust) are an\nomnipresent threat to visual AI systems and should be considered equally\nimportant. Many existing works propose interesting solutions to train robust\nmodels against natural corruption. These works either leverage image\naugmentations, which come with the additional cost of model training, or place\nsuspicious patches in the scene to design unadversarial examples. In this work,\nwe propose the idea of naturalistic support artifacts (NSA) for robust\nprediction. The NSAs are shown to be beneficial in scenarios where model\nparameters are inaccessible and adding artifacts in the scene is feasible. The\nNSAs are natural looking objects generated through artifact training using\nDC-GAN to have high visual fidelity in the scene. We test against natural\ncorruptions on the Imagenette dataset and observe the improvement in prediction\nconfidence score by four times. We also demonstrate NSA's capability to\nincrease adversarial accuracy by 8\\% on average. Lastly, we qualitatively\nanalyze NSAs using saliency maps to understand how they help improve prediction\nconfidence.",
          "link": "http://arxiv.org/abs/2307.14917",
          "publishedOn": "2023-07-29T00:48:57.378Z",
          "wordCount": null,
          "title": "NSA: Naturalistic Support Artifact to Boost Network Confidence. (arXiv:2307.14917v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Ying Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hou-biao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu-pu Zhang</a>",
          "description": "With the development of Big data technology, data analysis has become\nincreasingly important. Traditional clustering algorithms such as K-means are\nhighly sensitive to the initial centroid selection and perform poorly on\nnon-convex datasets. In this paper, we address these problems by proposing a\ndata-driven Bregman divergence parameter optimization clustering algorithm\n(DBGSA), which combines the Universal Gravitational Algorithm to bring similar\npoints closer in the dataset. We construct a gravitational coefficient equation\nwith a special property that gradually reduces the influence factor as the\niteration progresses. Furthermore, we introduce the Bregman divergence\ngeneralized power mean information loss minimization to identify cluster\ncenters and build a hyperparameter identification optimization model, which\neffectively solves the problems of manual adjustment and uncertainty in the\nimproved dataset. Extensive experiments are conducted on four simulated\ndatasets and six real datasets. The results demonstrate that DBGSA\nsignificantly improves the accuracy of various clustering algorithms by an\naverage of 63.8\\% compared to other similar approaches like enhanced clustering\nalgorithms and improved datasets. Additionally, a three-dimensional grid search\nwas established to compare the effects of different parameter values within\nthreshold conditions, and it was discovered the parameter set provided by our\nmodel is optimal. This finding provides strong evidence of the high accuracy\nand robustness of the algorithm.",
          "link": "http://arxiv.org/abs/2307.14375",
          "publishedOn": "2023-07-29T00:48:57.369Z",
          "wordCount": null,
          "title": "DBGSA: A Novel Data Adaptive Bregman Clustering Algorithm. (arXiv:2307.14375v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cruz_F/0/1/0/all/0/1\">Fred Torres Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flores_E/0/1/0/all/0/1\">Evelyn Eliana Coaquira Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quispe_S/0/1/0/all/0/1\">Sebastian Jarom Condori Quispe</a>",
          "description": "This study presents a machine learning model based on the Naive Bayes\nclassifier for predicting the level of depression in university students, the\nobjective was to improve prediction accuracy using a machine learning model\ninvolving 70% training data and 30% validation data based on the Naive Bayes\nclassifier, the collected data includes factors associated with depression from\n519 university students, the results showed an accuracy of 78.03%, high\nsensitivity in detecting positive cases of depression, especially at moderate\nand severe levels, and significant specificity in correctly classifying\nnegative cases, these findings highlight the effectiveness of the model in\nearly detection and treatment of depression, benefiting vulnerable sectors and\ncontributing to the improvement of mental health in the student population.",
          "link": "http://arxiv.org/abs/2307.14371",
          "publishedOn": "2023-07-29T00:48:57.367Z",
          "wordCount": null,
          "title": "Prediction of depression status in college students using a Naive Bayes classifier based machine learning model. (arXiv:2307.14371v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polloreno_A/0/1/0/all/0/1\">Anthony M. Polloreno</a>",
          "description": "In this work, we bound a machine's ability to learn based on computational\nlimitations implied by physicality. We start by considering the information\nprocessing capacity (IPC), a normalized measure of the expected squared error\nof a collection of signals to a complete basis of functions. We use the IPC to\nmeasure the degradation under noise of the performance of reservoir computers,\na particular kind of recurrent network, when constrained by physical\nconsiderations. First, we show that the IPC is at most a polynomial in the\nsystem size $n$, even when considering the collection of $2^n$ possible\npointwise products of the $n$ output signals. Next, we argue that this\ndegradation implies that the family of functions represented by the reservoir\nrequires an exponential number of samples to learn in the presence of the\nreservoir's noise. Finally, we conclude with a discussion of the performance of\nthe same collection of $2^n$ functions without noise when being used for binary\nclassification.",
          "link": "http://arxiv.org/abs/2307.14474",
          "publishedOn": "2023-07-29T00:48:57.366Z",
          "wordCount": null,
          "title": "Limits to Reservoir Learning. (arXiv:2307.14474v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Linden_P/0/1/0/all/0/1\">Putri A. van der Linden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_D/0/1/0/all/0/1\">David W. Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1\">Erik J. Bekkers</a>",
          "description": "Neural operations that rely on neighborhood information are much more\nexpensive when deployed on point clouds than on grid data due to the irregular\ndistances between points in a point cloud. In a grid, on the other hand, we can\ncompute the kernel only once and reuse it for all query positions. As a result,\noperations that rely on neighborhood information scale much worse for point\nclouds than for grid data, specially for large inputs and large neighborhoods.\n\nIn this work, we address the scalability issue of point cloud methods by\ntackling its root cause: the irregularity of the data. We propose learnable\ngridification as the first step in a point cloud processing pipeline to\ntransform the point cloud into a compact, regular grid. Thanks to\ngridification, subsequent layers can use operations defined on regular grids,\ne.g., Conv3D, which scale much better than native point cloud methods. We then\nextend gridification to point cloud to point cloud tasks, e.g., segmentation,\nby adding a learnable de-gridification step at the end of the point cloud\nprocessing pipeline to map the compact, regular grid back to its original point\ncloud form. Through theoretical and empirical analysis, we show that gridified\nnetworks scale better in terms of memory and time than networks directly\napplied on raw point cloud data, while being able to achieve competitive\nresults. Our code is publicly available at\nhttps://github.com/computri/gridifier.",
          "link": "http://arxiv.org/abs/2307.14354",
          "publishedOn": "2023-07-29T00:48:57.364Z",
          "wordCount": null,
          "title": "Learned Gridification for Efficient Point Cloud Processing. (arXiv:2307.14354v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_X/0/1/0/all/0/1\">Xian Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_Y/0/1/0/all/0/1\">Yongsu Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yu-Ru Lin</a>",
          "description": "Big data and machine learning tools have jointly empowered humans in making\ndata-driven decisions. However, many of them capture empirical associations\nthat might be spurious due to confounding factors and subgroup heterogeneity.\nThe famous Simpson's paradox is such a phenomenon where aggregated and\nsubgroup-level associations contradict with each other, causing cognitive\nconfusions and difficulty in making adequate interpretations and decisions.\nExisting tools provide little insights for humans to locate, reason about, and\nprevent pitfalls of spurious association in practice. We propose VISPUR, a\nvisual analytic system that provides a causal analysis framework and a\nhuman-centric workflow for tackling spurious associations. These include a\nCONFOUNDER DASHBOARD, which can automatically identify possible confounding\nfactors, and a SUBGROUP VIEWER, which allows for the visualization and\ncomparison of diverse subgroup patterns that likely or potentially result in a\nmisinterpretation of causality. Additionally, we propose a REASONING\nSTORYBOARD, which uses a flow-based approach to illustrate paradoxical\nphenomena, as well as an interactive DECISION DIAGNOSIS panel that helps ensure\naccountable decision-making. Through an expert interview and a controlled user\nexperiment, our qualitative and quantitative results demonstrate that the\nproposed \"de-paradox\" workflow and the designed visual analytic system are\neffective in helping human users to identify and understand spurious\nassociations, as well as to make accountable causal decisions.",
          "link": "http://arxiv.org/abs/2307.14448",
          "publishedOn": "2023-07-29T00:48:57.364Z",
          "wordCount": null,
          "title": "VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions. (arXiv:2307.14448v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McCarty_S/0/1/0/all/0/1\">Sarah McCarty</a>",
          "description": "This paper analyzes representations of continuous piecewise linear functions\nwith infinite width, finite cost shallow neural networks using the rectified\nlinear unit (ReLU) as an activation function. Through its integral\nrepresentation, a shallow neural network can be identified by the corresponding\nsigned, finite measure on an appropriate parameter space. We map these measures\non the parameter space to measures on the projective $n$-sphere cross\n$\\mathbb{R}$, allowing points in the parameter space to be bijectively mapped\nto hyperplanes in the domain of the function. We prove a conjecture of Ongie et\nal. that every continuous piecewise linear function expressible with this kind\nof infinite width neural network is expressible as a finite width shallow ReLU\nneural network.",
          "link": "http://arxiv.org/abs/2307.14373",
          "publishedOn": "2023-07-29T00:48:57.360Z",
          "wordCount": null,
          "title": "Piecewise Linear Functions Representable with Infinite Width Shallow ReLU Neural Networks. (arXiv:2307.14373v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14362",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Pedersen_C/0/1/0/all/0/1\">Christian Pedersen</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1\">Shirley Ho</a>",
          "description": "Convolutional neural networks (CNNs) have been shown to both extract more\ninformation than the traditional two-point statistics from cosmological fields,\nand marginalise over astrophysical effects extremely well. However, CNNs\nrequire large amounts of training data, which is potentially problematic in the\ndomain of expensive cosmological simulations, and it is difficult to interpret\nthe network. In this work we apply the learnable scattering transform, a kind\nof convolutional neural network that uses trainable wavelets as filters, to the\nproblem of cosmological inference and marginalisation over astrophysical\neffects. We present two models based on the scattering transform, one\nconstructed for performance, and one constructed for interpretability, and\nperform a comparison with a CNN. We find that scattering architectures are able\nto outperform a CNN, significantly in the case of small training data samples.\nAdditionally we present a lightweight scattering network that is highly\ninterpretable.",
          "link": "http://arxiv.org/abs/2307.14362",
          "publishedOn": "2023-07-29T00:48:57.358Z",
          "wordCount": null,
          "title": "Learnable wavelet neural networks for cosmological inference. (arXiv:2307.14362v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadhukhan_S/0/1/0/all/0/1\">Suchetana Sadhukhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1\">Vivek Kumar Yadav</a>",
          "description": "This study provides a comprehensive time series analysis of daily\nindustry-specific, country-wise CO$_2$ emissions from January 2019 to February\n2023. The research focuses on the Power, Industry, Ground Transport, Domestic\nAviation, and International Aviation sectors in European countries (EU27 & UK,\nItaly, Germany, Spain) and India, utilizing near-real-time activity data from\nthe Carbon Monitor research initiative. To identify regular emission patterns,\nthe data from the year 2020 is excluded due to the disruptive effects caused by\nthe COVID-19 pandemic. The study then performs a principal component analysis\n(PCA) to determine the key contributors to CO$_2$ emissions. The analysis\nreveals that the Power, Industry, and Ground Transport sectors account for a\nsignificant portion of the variance in the dataset. A 7-day moving averaged\ndataset is employed for further analysis to facilitate robust predictions. This\ndataset captures both short-term and long-term trends and enhances the quality\nof the data for prediction purposes. The study utilizes Long Short-Term Memory\n(LSTM) models on the 7-day moving averaged dataset to effectively predict\nemissions and provide insights for policy decisions, mitigation strategies, and\nclimate change efforts. During the training phase, the stability and\nconvergence of the LSTM models are ensured, which guarantees their reliability\nin the testing phase. The evaluation of the loss function indicates this\nreliability. The model achieves high efficiency, as demonstrated by $R^2$\nvalues ranging from 0.8242 to 0.995 for various countries and sectors.\nFurthermore, there is a proposal for utilizing scandium and\nboron/aluminium-based thin films as exceptionally efficient materials for\ncapturing CO$_2$ (with a binding energy range from -3.0 to -3.5 eV). These\nmaterials are shown to surpass the affinity of graphene and boron nitride\nsheets in this regard.",
          "link": "http://arxiv.org/abs/2307.14374",
          "publishedOn": "2023-07-29T00:48:57.358Z",
          "wordCount": null,
          "title": "Forecasting, capturing and activation of carbon-dioxide (CO$_2$): Integration of Time Series Analysis, Machine Learning, and Material Design. (arXiv:2307.14374v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mayer_B/0/1/0/all/0/1\">Brandon Mayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1\">Anton Tsitsulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fichtenberger_H/0/1/0/all/0/1\">Hendrik Fichtenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halcrow_J/0/1/0/all/0/1\">Jonathan Halcrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1\">Bryan Perozzi</a>",
          "description": "Graphs are a representation of structured data that captures the\nrelationships between sets of objects. With the ubiquity of available network\ndata, there is increasing industrial and academic need to quickly analyze\ngraphs with billions of nodes and trillions of edges. A common first step for\nnetwork understanding is Graph Embedding, the process of creating a continuous\nrepresentation of nodes in a graph. A continuous representation is often more\namenable, especially at scale, for solving downstream machine learning tasks\nsuch as classification, link prediction, and clustering. A high-performance\ngraph embedding architecture leveraging Tensor Processing Units (TPUs) with\nconfigurable amounts of high-bandwidth memory is presented that simplifies the\ngraph embedding problem and can scale to graphs with billions of nodes and\ntrillions of edges. We verify the embedding space quality on real and synthetic\nlarge-scale datasets.",
          "link": "http://arxiv.org/abs/2307.14490",
          "publishedOn": "2023-07-29T00:48:57.358Z",
          "wordCount": null,
          "title": "HUGE: Huge Unsupervised Graph Embeddings with TPUs. (arXiv:2307.14490v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuoyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongsheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongye Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1\">Bei Hua</a>",
          "description": "Recently, using neural networks to simulate spatio-temporal dynamics has\nreceived a lot of attention. However, most existing methods adopt pure\ndata-driven black-box models, which have limited accuracy and interpretability.\nBy combining trainable difference operators with black-box models, we propose a\nnew hybrid architecture explicitly embedded with partial prior knowledge of the\nunderlying PDEs named PDE-Net++. Furthermore, we introduce two distinct options\ncalled the trainable flipping difference layer (TFDL) and the trainable dynamic\ndifference layer (TDDL) for the difference operators. Numerous numerical\nexperiments have demonstrated that PDE-Net++ has superior prediction accuracy\nand better extrapolation performance than black-box models.",
          "link": "http://arxiv.org/abs/2307.14395",
          "publishedOn": "2023-07-29T00:48:57.357Z",
          "wordCount": null,
          "title": "Learning to simulate partially known spatio-temporal dynamics with trainable difference operators. (arXiv:2307.14395v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14502",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Close_G/0/1/0/all/0/1\">George Close</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goetze_S/0/1/0/all/0/1\">Stefan Goetze</a>",
          "description": "Recent work in the field of speech enhancement (SE) has involved the use of\nself-supervised speech representations (SSSRs) as feature transformations in\nloss functions. However, in prior work, very little attention has been paid to\nthe relationship between the language of the audio used to train the\nself-supervised representation and that used to train the SE system.\nEnhancement models trained using a loss function which incorporates a\nself-supervised representation that shares exactly the language of the noisy\ndata used to train the SE system show better performance than those which do\nnot match exactly. This may lead to enhancement systems which are language\nspecific and as such do not generalise well to unseen languages, unlike models\ntrained using traditional spectrogram or time domain loss functions. In this\nwork, SE models are trained and tested on a number of different languages, with\nself-supervised representations which themselves are trained using different\nlanguage combinations and with differing network structures as loss function\nrepresentations. These models are then tested across unseen languages and their\nperformances are analysed. It is found that the training language of the\nself-supervised representation appears to have a minor effect on enhancement\nperformance, the amount of training data of a particular language, however,\ngreatly affects performance.",
          "link": "http://arxiv.org/abs/2307.14502",
          "publishedOn": "2023-07-29T00:48:57.357Z",
          "wordCount": null,
          "title": "The Effect of Spoken Language on Speech Enhancement using Self-Supervised Speech Representation Loss Functions. (arXiv:2307.14502v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14364",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jiao_Y/0/1/0/all/0/1\">Yang Jiao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_K/0/1/0/all/0/1\">Kai Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Song_D/0/1/0/all/0/1\">Dongjin Song</a>",
          "description": "Distributionally Robust Optimization (DRO), which aims to find an optimal\ndecision that minimizes the worst case cost over the ambiguity set of\nprobability distribution, has been widely applied in diverse applications,\ne.g., network behavior analysis, risk management, etc. However, existing DRO\ntechniques face three key challenges: 1) how to deal with the asynchronous\nupdating in a distributed environment; 2) how to leverage the prior\ndistribution effectively; 3) how to properly adjust the degree of robustness\naccording to different scenarios. To this end, we propose an asynchronous\ndistributed algorithm, named Asynchronous Single-looP alternatIve gRadient\nprojEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to\ntackle the federated distributionally robust optimization (FDRO) problem.\nFurthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set,\nis developed to effectively leverage the prior distribution and flexibly\ncontrol the degree of robustness. Finally, our theoretical analysis elucidates\nthat the proposed algorithm is guaranteed to converge and the iteration\ncomplexity is also analyzed. Extensive empirical studies on real-world datasets\ndemonstrate that the proposed method can not only achieve fast convergence, and\nremain robust against data heterogeneity as well as malicious attacks, but also\ntradeoff robustness with performance.",
          "link": "http://arxiv.org/abs/2307.14364",
          "publishedOn": "2023-07-29T00:48:57.354Z",
          "wordCount": null,
          "title": "Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis. (arXiv:2307.14364v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khairunnesa_S/0/1/0/all/0/1\">Samantha Syeda Khairunnesa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Shibbir Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imtiaz_S/0/1/0/all/0/1\">Sayem Mohammad Imtiaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1\">Hridesh Rajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavens_G/0/1/0/all/0/1\">Gary T. Leavens</a>",
          "description": "Recent work has shown that Machine Learning (ML) programs are error-prone and\ncalled for contracts for ML code. Contracts, as in the design by contract\nmethodology, help document APIs and aid API users in writing correct code. The\nquestion is: what kinds of contracts would provide the most help to API users?\nWe are especially interested in what kinds of contracts help API users catch\nerrors at earlier stages in the ML pipeline. We describe an empirical study of\nposts on Stack Overflow of the four most often-discussed ML libraries:\nTensorFlow, Scikit-learn, Keras, and PyTorch. For these libraries, our study\nextracted 413 informal (English) API specifications. We used these\nspecifications to understand the following questions. What are the root causes\nand effects behind ML contract violations? Are there common patterns of ML\ncontract violations? When does understanding ML contracts require an advanced\nlevel of ML software expertise? Could checking contracts at the API level help\ndetect the violations in early ML pipeline stages? Our key findings are that\nthe most commonly needed contracts for ML APIs are either checking constraints\non single arguments of an API or on the order of API calls. The software\nengineering community could employ existing contract mining approaches to mine\nthese contracts to promote an increased understanding of ML APIs. We also noted\na need to combine behavioral and temporal contract mining approaches. We report\non categories of required ML contracts, which may help designers of contract\nlanguages.",
          "link": "http://arxiv.org/abs/2307.14465",
          "publishedOn": "2023-07-29T00:48:57.354Z",
          "wordCount": null,
          "title": "What Kinds of Contracts Do ML APIs Need?. (arXiv:2307.14465v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14363",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Catalan_T/0/1/0/all/0/1\">Tabita Catal&#xe1;n</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Courdurier_M/0/1/0/all/0/1\">Mat&#xed;as Courdurier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Osses_A/0/1/0/all/0/1\">Axel Osses</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Botnar_R/0/1/0/all/0/1\">Ren&#xe9; Botnar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Costabal_F/0/1/0/all/0/1\">Francisco Sahli Costabal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prieto_C/0/1/0/all/0/1\">Claudia Prieto</a>",
          "description": "Cardiac cine MRI is the gold standard for cardiac functional assessment, but\nthe inherently slow acquisition process creates the necessity of reconstruction\napproaches for accelerated undersampled acquisitions. Several regularization\napproaches that exploit spatial-temporal redundancy have been proposed to\nreconstruct undersampled cardiac cine MRI. More recently, methods based on\nsupervised deep learning have been also proposed to further accelerate\nacquisition and reconstruction. However, these techniques rely on usually large\ndataset for training, which are not always available. In this work, we propose\nan unsupervised approach based on implicit neural field representations for\ncardiac cine MRI (so called NF-cMRI). The proposed method was evaluated in\nin-vivo undersampled golden-angle radial multi-coil acquisitions for\nundersampling factors of 26x and 52x, achieving good image quality, and\ncomparable spatial and improved temporal depiction than a state-of-the-art\nreconstruction technique.",
          "link": "http://arxiv.org/abs/2307.14363",
          "publishedOn": "2023-07-29T00:48:57.353Z",
          "wordCount": null,
          "title": "Unsupervised reconstruction of accelerated cardiac cine MRI using Neural Fields. (arXiv:2307.14363v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14530",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Community detection is one of the most critical problems in modern network\nscience. Its applications can be found in various fields, from protein modeling\nto social network analysis. Recently, many papers appeared studying the problem\nof overlapping community detection, where each node of a network may belong to\nseveral communities. In this work, we consider Mixed-Membership Stochastic\nBlock Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite\na general setting for modeling overlapping community structure in graphs. The\ncentral question of this paper is to reconstruct relations between communities\ngiven an observed network. We compare different approaches and establish the\nminimax lower bound on the estimation error. Then, we propose a new estimator\nthat matches this lower bound. Theoretical results are proved under fairly\ngeneral conditions on the considered model. Finally, we illustrate the theory\nin a series of experiments.",
          "link": "http://arxiv.org/abs/2307.14530",
          "publishedOn": "2023-07-29T00:48:57.353Z",
          "wordCount": null,
          "title": "Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdollahzadeh_M/0/1/0/all/0/1\">Milad Abdollahzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malekzadeh_T/0/1/0/all/0/1\">Touba Malekzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teo_C/0/1/0/all/0/1\">Christopher T. H. Teo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasegaran_K/0/1/0/all/0/1\">Keshigeyan Chandrasegaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guimeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_N/0/1/0/all/0/1\">Ngai-Man Cheung</a>",
          "description": "In machine learning, generative modeling aims to learn to generate new data\nstatistically similar to the training data distribution. In this paper, we\nsurvey learning generative models under limited data, few shots and zero shot,\nreferred to as Generative Modeling under Data Constraint (GM-DC). This is an\nimportant topic when data acquisition is challenging, e.g. healthcare\napplications. We discuss background, challenges, and propose two taxonomies:\none on GM-DC tasks and another on GM-DC approaches. Importantly, we study\ninteractions between different GM-DC tasks and approaches. Furthermore, we\nhighlight research gaps, research trends, and potential avenues for future\nexploration. Project website: https://gmdc-survey.github.io.",
          "link": "http://arxiv.org/abs/2307.14397",
          "publishedOn": "2023-07-29T00:48:57.352Z",
          "wordCount": null,
          "title": "A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot. (arXiv:2307.14397v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.05776",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_S/0/1/0/all/0/1\">Sidi Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beaulac_C/0/1/0/all/0/1\">C&#xe9;dric Beaulac</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cao_J/0/1/0/all/0/1\">Jiguo Cao</a>",
          "description": "The regression of a functional response on a set of scalar predictors can be\na challenging task, especially if there is a large number of predictors, or the\nrelationship between those predictors and the response is nonlinear. In this\nwork, we propose a solution to this problem: a feed-forward neural network (NN)\ndesigned to predict a functional response using scalar inputs. First, we\ntransform the functional response to a finite-dimensional representation and\nconstruct an NN that outputs this representation. Then, we propose to modify\nthe output of an NN via the objective function and introduce different\nobjective functions for network training. The proposed models are suited for\nboth regularly and irregularly spaced data, and a roughness penalty can be\nfurther applied to control the smoothness of the predicted curve. The\ndifficulty in implementing both those features lies in the definition of\nobjective functions that can be back-propagated. In our experiments, we\ndemonstrate that our model outperforms the conventional function-on-scalar\nregression model in multiple scenarios while computationally scaling better\nwith the dimension of the predictors.",
          "link": "http://arxiv.org/abs/2208.05776",
          "publishedOn": "2023-07-29T00:48:57.327Z",
          "wordCount": null,
          "title": "Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Besbes_O/0/1/0/all/0/1\">Omar Besbes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Will Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaki_O/0/1/0/all/0/1\">Omar Mouchtaki</a>",
          "description": "In this work, we explore a framework for contextual decision-making to study\nhow the relevance and quantity of past data affects the performance of a\ndata-driven policy. We analyze a contextual Newsvendor problem in which a\ndecision-maker needs to trade-off between an underage and an overage cost in\nthe face of uncertain demand. We consider a setting in which past demands\nobserved under ``close by'' contexts come from close by distributions and\nanalyze the performance of data-driven algorithms through a notion of\ncontext-dependent worst-case expected regret. We analyze the broad class of\nWeighted Empirical Risk Minimization (WERM) policies which weigh past data\naccording to their similarity in the contextual space. This class includes\nclassical policies such as ERM, k-Nearest Neighbors and kernel-based policies.\nOur main methodological contribution is to characterize exactly the worst-case\nregret of any WERM policy on any given configuration of contexts. To the best\nof our knowledge, this provides the first understanding of tight performance\nguarantees in any contextual decision-making problem, with past literature\nfocusing on upper bounds via concentration inequalities. We instead take an\noptimization approach, and isolate a structure in the Newsvendor loss function\nthat allows to reduce the infinite-dimensional optimization problem over\nworst-case distributions to a simple line search.\n\nThis in turn allows us to unveil fundamental insights that were obfuscated by\nprevious general-purpose bounds. We characterize actual guaranteed performance\nas a function of the contexts, as well as granular insights on the learning\ncurve of algorithms.",
          "link": "http://arxiv.org/abs/2302.08424",
          "publishedOn": "2023-07-29T00:48:57.323Z",
          "wordCount": null,
          "title": "From Contextual Data to Newsvendor Decisions: On the Actual Performance of Data-Driven Algorithms. (arXiv:2302.08424v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.10255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cate_B/0/1/0/all/0/1\">Balder ten Cate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funk_M/0/1/0/all/0/1\">Maurice Funk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jean Christoph Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutz_C/0/1/0/all/0/1\">Carsten Lutz</a>",
          "description": "This note serves three purposes: (i) we provide a self-contained exposition\nof the fact that conjunctive queries are not efficiently learnable in the\nProbably-Approximately-Correct (PAC) model, paying clear attention to the\ncomplicating fact that this concept class lacks the polynomial-size fitting\nproperty, a property that is tacitly assumed in much of the computational\nlearning theory literature; (ii) we establish a strong negative PAC\nlearnability result that applies to many restricted classes of conjunctive\nqueries (CQs), including acyclic CQs for a wide range of notions of\n\"acyclicity\"; (iii) we show that CQs (and UCQs) are efficiently PAC learnable\nwith membership queries.",
          "link": "http://arxiv.org/abs/2208.10255",
          "publishedOn": "2023-07-29T00:48:57.321Z",
          "wordCount": null,
          "title": "On the non-efficient PAC learnability of conjunctive queries. (arXiv:2208.10255v2 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tekgul_B/0/1/0/all/0/1\">Buse G. A. Tekgul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asokan_N/0/1/0/all/0/1\">N. Asokan</a>",
          "description": "We propose FLARE, the first fingerprinting mechanism to verify whether a\nsuspected Deep Reinforcement Learning (DRL) policy is an illegitimate copy of\nanother (victim) policy. We first show that it is possible to find\nnon-transferable, universal adversarial masks, i.e., perturbations, to generate\nadversarial examples that can successfully transfer from a victim policy to its\nmodified versions but not to independently trained policies. FLARE employs\nthese masks as fingerprints to verify the true ownership of stolen DRL policies\nby measuring an action agreement value over states perturbed via such masks.\nOur empirical evaluations show that FLARE is effective (100% action agreement\non stolen copies) and does not falsely accuse independent policies (no false\npositives). FLARE is also robust to model modification attacks and cannot be\neasily evaded by more informed adversaries without negatively impacting agent\nperformance. We also show that not all universal adversarial masks are suitable\ncandidates for fingerprints due to the inherent characteristics of DRL\npolicies. The spatio-temporal dynamics of DRL problems and sequential\ndecision-making process make characterizing the decision boundary of DRL\npolicies more difficult, as well as searching for universal masks that capture\nthe geometry of it.",
          "link": "http://arxiv.org/abs/2307.14751",
          "publishedOn": "2023-07-29T00:48:57.320Z",
          "wordCount": null,
          "title": "FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal Adversarial Masks. (arXiv:2307.14751v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sikdokur_I/0/1/0/all/0/1\">Ilkay Sikdokur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baytas_I/0/1/0/all/0/1\">&#x130;nci M. Bayta&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurdakul_A/0/1/0/all/0/1\">Arda Yurdakul</a>",
          "description": "Deep edge intelligence aims to deploy deep learning models that demand\ncomputationally expensive training in the edge network with limited\ncomputational power. Moreover, many deep edge intelligence applications require\nhandling distributed data that cannot be transferred to a central server due to\nprivacy concerns. Decentralized learning methods, such as federated learning,\noffer solutions where models are learned collectively by exchanging learned\nweights. However, they often require complex models that edge devices may not\nhandle and multiple rounds of network communication to achieve state-of-the-art\nperformances. This study proposes a convolutional ensemble learning approach,\ncoined EdgeConvEns, that facilitates training heterogeneous weak models on edge\nand learning to ensemble them where data on edge are heterogeneously\ndistributed. Edge models are implemented and trained independently on\nField-Programmable Gate Array (FPGA) devices with various computational\ncapacities. Learned data representations are transferred to a central server\nwhere the ensemble model is trained with the learned features received from the\nedge devices to boost the overall prediction performance. Extensive experiments\ndemonstrate that the EdgeConvEns can outperform the state-of-the-art\nperformance with fewer communications and less data in various training\nscenarios.",
          "link": "http://arxiv.org/abs/2307.14381",
          "publishedOn": "2023-07-29T00:48:57.319Z",
          "wordCount": null,
          "title": "EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence. (arXiv:2307.14381v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gale_A/0/1/0/all/0/1\">Abraham Gale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marian_A/0/1/0/all/0/1\">Am&#xc9;lie Marian</a>",
          "description": "Ranking functions that are used in decision systems often produce disparate\nresults for different populations because of bias in the underlying data.\nAddressing, and compensating for, these disparate outcomes is a critical\nproblem for fair decision-making. Recent compensatory measures have mostly\nfocused on opaque transformations of the ranking functions to satisfy fairness\nguarantees or on the use of quotas or set-asides to guarantee a minimum number\nof positive outcomes to members of underrepresented groups. In this paper we\npropose easily explainable data-driven compensatory measures for ranking\nfunctions. Our measures rely on the generation of bonus points given to members\nof underrepresented groups to address disparity in the ranking function. The\nbonus points can be set in advance, and can be combined, allowing for\nconsidering the intersections of representations and giving better transparency\nto stakeholders. We propose efficient sampling-based algorithms to calculate\nthe number of bonus points to minimize disparity. We validate our algorithms\nusing real-world school admissions and recidivism datasets, and compare our\nresults with that of existing fair ranking algorithms.",
          "link": "http://arxiv.org/abs/2307.14366",
          "publishedOn": "2023-07-29T00:48:57.317Z",
          "wordCount": null,
          "title": "Explainable Disparity Compensation for Efficient Fair Ranking. (arXiv:2307.14366v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.06589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungeun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kijung Yoon</a>",
          "description": "Graph neural networks (GNNs) have become compelling models designed to\nperform learning and inference on graph-structured data. However, little work\nhas been done to understand the fundamental limitations of GNNs for scaling to\nlarger graphs and generalizing to out-of-distribution (OOD) inputs. In this\npaper, we use a random graph generator to systematically investigate how the\ngraph size and structural properties affect the predictive performance of GNNs.\nWe present specific evidence that the average node degree is a key feature in\ndetermining whether GNNs can generalize to unseen graphs, and that the use of\nmultiple node update functions can improve the generalization performance of\nGNNs when dealing with graphs of multimodal degree distributions. Accordingly,\nwe propose a multi-module GNN framework that allows the network to adapt\nflexibly to new graphs by generalizing a single canonical nonlinear\ntransformation over aggregated inputs. Our results show that the multi-module\nGNNs improve the OOD generalization on a variety of inference tasks in the\ndirection of diverse structural features.",
          "link": "http://arxiv.org/abs/2209.06589",
          "publishedOn": "2023-07-29T00:48:57.286Z",
          "wordCount": null,
          "title": "Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks. (arXiv:2209.06589v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1\">Andy Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>",
          "description": "Because \"out-of-the-box\" large language models are capable of generating a\ngreat deal of objectionable content, recent work has focused on aligning these\nmodels in an attempt to prevent undesirable generation. While there has been\nsome success at circumventing these measures -- so-called \"jailbreaks\" against\nLLMs -- these attacks have required significant human ingenuity and are brittle\nin practice. In this paper, we propose a simple and effective attack method\nthat causes aligned language models to generate objectionable behaviors.\nSpecifically, our approach finds a suffix that, when attached to a wide range\nof queries for an LLM to produce objectionable content, aims to maximize the\nprobability that the model produces an affirmative response (rather than\nrefusing to answer). However, instead of relying on manual engineering, our\napproach automatically produces these adversarial suffixes by a combination of\ngreedy and gradient-based search techniques, and also improves over past\nautomatic prompt generation methods.\n\nSurprisingly, we find that the adversarial prompts generated by our approach\nare quite transferable, including to black-box, publicly released LLMs.\nSpecifically, we train an adversarial attack suffix on multiple prompts (i.e.,\nqueries asking for many different types of objectionable content), as well as\nmultiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting\nattack suffix is able to induce objectionable content in the public interfaces\nto ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,\nPythia, Falcon, and others. In total, this work significantly advances the\nstate-of-the-art in adversarial attacks against aligned language models,\nraising important questions about how such systems can be prevented from\nproducing objectionable information. Code is available at\ngithub.com/llm-attacks/llm-attacks.",
          "link": "http://arxiv.org/abs/2307.15043",
          "publishedOn": "2023-07-29T00:48:57.284Z",
          "wordCount": null,
          "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models. (arXiv:2307.15043v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saxena_P/0/1/0/all/0/1\">Priyansh Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Raahat Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Akshat Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_S/0/1/0/all/0/1\">Saumil Maheshwari</a>",
          "description": "Semantic inpainting or image completion alludes to the task of inferring\narbitrary large missing regions in images based on image semantics. Since the\nprediction of image pixels requires an indication of high-level context, this\nmakes it significantly tougher than image completion, which is often more\nconcerned with correcting data corruption and removing entire objects from the\ninput image. On the other hand, image enhancement attempts to eliminate\nunwanted noise and blur from the image, along with sustaining most of the image\ndetails. Efficient image completion and enhancement model should be able to\nrecover the corrupted and masked regions in images and then refine the image\nfurther to increase the quality of the output image. Generative Adversarial\nNetworks (GAN), have turned out to be helpful in picture completion tasks. In\nthis chapter, we will discuss the underlying GAN architecture and how they can\nbe used used for image completion tasks.",
          "link": "http://arxiv.org/abs/2307.14748",
          "publishedOn": "2023-07-29T00:48:57.265Z",
          "wordCount": null,
          "title": "Semantic Image Completion and Enhancement using GANs. (arXiv:2307.14748v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianjun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woon_W/0/1/0/all/0/1\">Wei Lee Woon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coba_L/0/1/0/all/0/1\">Ludovik Coba</a>",
          "description": "This paper presents an efficient algorithm to solve the sleeping bandit with\nmultiple plays problem in the context of an online recommendation system. The\nproblem involves bounded, adversarial loss and unknown i.i.d. distributions for\narm availability. The proposed algorithm extends the sleeping bandit algorithm\nfor single arm selection and is guaranteed to achieve theoretical performance\nwith regret upper bounded by $\\bigO(kN^2\\sqrt{T\\log T})$, where $k$ is the\nnumber of arms selected per time step, $N$ is the total number of arms, and $T$\nis the time horizon.",
          "link": "http://arxiv.org/abs/2307.14549",
          "publishedOn": "2023-07-29T00:48:57.243Z",
          "wordCount": null,
          "title": "Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and Ranking Application. (arXiv:2307.14549v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Almeida_T/0/1/0/all/0/1\">Tiago Rodrigues de Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozos_O/0/1/0/all/0/1\">Oscar Martinez Mozos</a>",
          "description": "Autonomous systems in the road transportation network require intelligent\nmechanisms that cope with uncertainty to foresee the future. In this paper, we\npropose a multi-stage probabilistic approach for trajectory forecasting:\ntrajectory transformation to displacement space, clustering of displacement\ntime series, trajectory proposals, and ranking proposals. We introduce a new\ndeep feature clustering method, underlying self-conditioned GAN, which copes\nbetter with distribution shifts than traditional methods. Additionally, we\npropose novel distance-based ranking proposals to assign probabilities to the\ngenerated trajectories that are more efficient yet accurate than an auxiliary\nneural network. The overall system surpasses context-free deep generative\nmodels in human and road agents trajectory data while performing similarly to\npoint estimators when comparing the most probable trajectory.",
          "link": "http://arxiv.org/abs/2307.14788",
          "publishedOn": "2023-07-29T00:48:57.242Z",
          "wordCount": null,
          "title": "Likely, Light, and Accurate Context-Free Clusters-based Trajectory Prediction. (arXiv:2307.14788v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharir_O/0/1/0/all/0/1\">Or Sharir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Deep learning often faces the challenge of efficiently processing dynamic\ninputs, such as sensor data or user inputs. For example, an AI writing\nassistant is required to update its suggestions in real time as a document is\nedited. Re-running the model each time is expensive, even with compression\ntechniques like knowledge distillation, pruning, or quantization. Instead, we\ntake an incremental computing approach, looking to reuse calculations as the\ninputs change. However, the dense connectivity of conventional architectures\nposes a major obstacle to incremental computation, as even minor input changes\ncascade through the network and restrict information reuse. To address this, we\nuse vector quantization to discretize intermediate values in the network, which\nfilters out noisy and unnecessary modifications to hidden neurons, facilitating\nthe reuse of their values. We apply this approach to the transformers\narchitecture, creating an efficient incremental inference algorithm with\ncomplexity proportional to the fraction of the modified inputs. Our experiments\nwith adapting the OPT-125M pre-trained language model demonstrate comparable\naccuracy on document classification while requiring 12.1X (median) fewer\noperations for processing sequences of atomic edits.",
          "link": "http://arxiv.org/abs/2307.14988",
          "publishedOn": "2023-07-29T00:48:57.239Z",
          "wordCount": null,
          "title": "Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs. (arXiv:2307.14988v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14839",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+English_E/0/1/0/all/0/1\">Eshant English</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kirchler_M/0/1/0/all/0/1\">Matthias Kirchler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lippert_C/0/1/0/all/0/1\">Christoph Lippert</a>",
          "description": "Normalising Flows are generative models characterised by their invertible\narchitecture. However, the requirement of invertibility imposes constraints on\ntheir expressiveness, necessitating a large number of parameters and innovative\narchitectural designs to achieve satisfactory outcomes. Whilst flow-based\nmodels predominantly rely on neural-network-based transformations for\nexpressive designs, alternative transformation methods have received limited\nattention. In this work, we present Ferumal flow, a novel kernelised\nnormalising flow paradigm that integrates kernels into the framework. Our\nresults demonstrate that a kernelised flow can yield competitive or superior\nresults compared to neural network-based flows whilst maintaining parameter\nefficiency. Kernelised flows excel especially in the low-data regime, enabling\nflexible non-parametric density estimation in applications with sparse data\navailability.",
          "link": "http://arxiv.org/abs/2307.14839",
          "publishedOn": "2023-07-29T00:48:57.222Z",
          "wordCount": null,
          "title": "Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chernishev_G/0/1/0/all/0/1\">George Chernishev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polyntsov_M/0/1/0/all/0/1\">Michael Polyntsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chizhov_A/0/1/0/all/0/1\">Anton Chizhov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stupakov_K/0/1/0/all/0/1\">Kirill Stupakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shchuckin_I/0/1/0/all/0/1\">Ilya Shchuckin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smirnov_A/0/1/0/all/0/1\">Alexander Smirnov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strutovsky_M/0/1/0/all/0/1\">Maxim Strutovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlyonskikh_A/0/1/0/all/0/1\">Alexey Shlyonskikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firsov_M/0/1/0/all/0/1\">Mikhail Firsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manannikov_S/0/1/0/all/0/1\">Stepan Manannikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bobrov_N/0/1/0/all/0/1\">Nikita Bobrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goncharov_D/0/1/0/all/0/1\">Daniil Goncharov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barutkin_I/0/1/0/all/0/1\">Ilia Barutkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalnev_V/0/1/0/all/0/1\">Vladislav Shalnev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muraviev_K/0/1/0/all/0/1\">Kirill Muraviev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakhmukova_A/0/1/0/all/0/1\">Anna Rakhmukova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shcheka_D/0/1/0/all/0/1\">Dmitriy Shcheka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chernikov_A/0/1/0/all/0/1\">Anton Chernikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vyrodov_M/0/1/0/all/0/1\">Mikhail Vyrodov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaroslav_K/0/1/0/all/0/1\">Kurbatov Yaroslav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fofanov_M/0/1/0/all/0/1\">Maxim Fofanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sergei_B/0/1/0/all/0/1\">Belokonnyi Sergei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavel_A/0/1/0/all/0/1\">Anosov Pavel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saliou_A/0/1/0/all/0/1\">Arthur Saliou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaisin_E/0/1/0/all/0/1\">Eduard Gaisin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smirnov_K/0/1/0/all/0/1\">Kirill Smirnov</a>",
          "description": "Data profiling is an essential process in modern data-driven industries. One\nof its critical components is the discovery and validation of complex\nstatistics, including functional dependencies, data constraints, association\nrules, and others.\n\nHowever, most existing data profiling systems that focus on complex\nstatistics do not provide proper integration with the tools used by\ncontemporary data scientists. This creates a significant barrier to the\nadoption of these tools in the industry. Moreover, existing systems were not\ncreated with industrial-grade workloads in mind. Finally, they do not aim to\nprovide descriptive explanations, i.e. why a given pattern is not found. It is\na significant issue as it is essential to understand the underlying reasons for\na specific pattern's absence to make informed decisions based on the data.\n\nBecause of that, these patterns are effectively rest in thin air: their\napplication scope is rather limited, they are rarely used by the broader\npublic. At the same time, as we are going to demonstrate in this presentation,\ncomplex statistics can be efficiently used to solve many classic data quality\nproblems.\n\nDesbordante is an open-source data profiler that aims to close this gap. It\nis built with emphasis on industrial application: it is efficient, scalable,\nresilient to crashes, and provides explanations. Furthermore, it provides\nseamless Python integration by offloading various costly operations to the C++\ncore, not only mining.\n\nIn this demonstration, we show several scenarios that allow end users to\nsolve different data quality problems. Namely, we showcase typo detection, data\ndeduplication, and data anomaly detection scenarios.",
          "link": "http://arxiv.org/abs/2307.14935",
          "publishedOn": "2023-07-29T00:48:57.221Z",
          "wordCount": null,
          "title": "Solving Data Quality Problems with Desbordante: a Demo. (arXiv:2307.14935v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mclaughlin_C/0/1/0/all/0/1\">Connor Mclaughlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Matthew Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edogmus_D/0/1/0/all/0/1\">Denis Edogmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Lili Su</a>",
          "description": "As the network scale increases, existing fully distributed solutions start to\nlag behind the real-world challenges such as (1) slow information propagation,\n(2) network communication failures, and (3) external adversarial attacks. In\nthis paper, we focus on hierarchical system architecture and address the\nproblem of non-Bayesian learning over networks that are vulnerable to\ncommunication failures and adversarial attacks. On network communication, we\nconsider packet-dropping link failures.\n\nWe first propose a hierarchical robust push-sum algorithm that can achieve\naverage consensus despite frequent packet-dropping link failures. We provide a\nsparse information fusion rule between the parameter server and arbitrarily\nselected network representatives. Then, interleaving the consensus update step\nwith a dual averaging update with Kullback-Leibler (KL) divergence as the\nproximal function, we obtain a packet-dropping fault-tolerant non-Bayesian\nlearning algorithm with provable convergence guarantees.\n\nOn external adversarial attacks, we consider Byzantine attacks in which the\ncompromised agents can send maliciously calibrated messages to others\n(including both the agents and the parameter server). To avoid the curse of\ndimensionality of Byzantine consensus, we solve the non-Bayesian learning\nproblem via running multiple dynamics, each of which only involves Byzantine\nconsensus with scalar inputs. To facilitate resilient information propagation\nacross sub-networks, we use a novel Byzantine-resilient gossiping-type rule at\nthe parameter server.",
          "link": "http://arxiv.org/abs/2307.14952",
          "publishedOn": "2023-07-29T00:48:57.220Z",
          "wordCount": null,
          "title": "Network Fault-tolerant and Byzantine-resilient Social Learning via Collaborative Hierarchical Non-Bayesian Learning. (arXiv:2307.14952v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14482",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kline_T/0/1/0/all/0/1\">Timothy L. Kline</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ramanathan_S/0/1/0/all/0/1\">Sumana Ramanathan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gottlich_H/0/1/0/all/0/1\">Harrison C. Gottlich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korfiatis_P/0/1/0/all/0/1\">Panagiotis Korfiatis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gregory_A/0/1/0/all/0/1\">Adriana V. Gregory</a>",
          "description": "Purpose: This study evaluated the out-of-domain performance and\ngeneralization capabilities of automated medical image segmentation models,\nwith a particular focus on adaptation to new image acquisitions and disease\ntype.\n\nMaterials: Datasets from both non-contrast and contrast-enhanced abdominal CT\nscans of healthy patients and those with polycystic kidney disease (PKD) were\nused. A total of 400 images (100 non-contrast controls, 100 contrast controls,\n100 non-contrast PKD, 100 contrast PKD) were utilized for training/validation\nof models to segment kidneys, livers, and spleens, and the final models were\nthen tested on 100 non-contrast CT images of patients affected by PKD.\nPerformance was evaluated using Dice, Jaccard, TPR, and Precision.\n\nResults: Models trained on a diverse range of data showed no worse\nperformance than models trained exclusively on in-domain data when tested on\nin-domain data. For instance, the Dice similarity of the model trained on 25%\nfrom each dataset was found to be non-inferior to the model trained purely on\nin-domain data.\n\nConclusions: The results indicate that broader training examples\nsignificantly enhances model generalization and out-of-domain performance,\nthereby improving automated segmentation tools' applicability in clinical\nsettings. The study's findings provide a roadmap for future research to adopt a\ndata-centric approach in medical image AI model development.",
          "link": "http://arxiv.org/abs/2307.14482",
          "publishedOn": "2023-07-29T00:48:57.219Z",
          "wordCount": null,
          "title": "Role of Image Acquisition and Patient Phenotype Variations in Automatic Segmentation Model Generalization. (arXiv:2307.14482v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angulo_B/0/1/0/all/0/1\">Brian Angulo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorbov_G/0/1/0/all/0/1\">Gregory Gorbov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panov_A/0/1/0/all/0/1\">Aleksandr Panov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yakovlev_K/0/1/0/all/0/1\">Konstantin Yakovlev</a>",
          "description": "While reinforcement learning algorithms have had great success in the field\nof autonomous navigation, they cannot be straightforwardly applied to the real\nautonomous systems without considering the safety constraints. The later are\ncrucial to avoid unsafe behaviors of the autonomous vehicle on the road. To\nhighlight the importance of these constraints, in this study, we compare two\nlearnable navigation policies: safe and unsafe. The safe policy takes the\nconstraints into account, while the other does not. We show that the safe\npolicy is able to generate trajectories with more clearance (distance to the\nobstacles) and makes less collisions while training without sacrificing the\noverall performance.",
          "link": "http://arxiv.org/abs/2307.14568",
          "publishedOn": "2023-07-29T00:48:57.129Z",
          "wordCount": null,
          "title": "Evaluation of Safety Constraints in Autonomous Navigation with Deep Reinforcement Learning. (arXiv:2307.14568v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14361",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Aburass_S/0/1/0/all/0/1\">Sanad Aburass</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dorgham_O/0/1/0/all/0/1\">Osama Dorgham</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shaqsi_J/0/1/0/all/0/1\">Jamil Al Shaqsi</a>",
          "description": "This study presents an ensemble model combining LSTM, BiLSTM, CNN, GRU, and\nGloVe to classify gene mutations using Kaggle's Personalized Medicine:\nRedefining Cancer Treatment dataset. The results were compared against\nwell-known transformers like as BERT, Electra, Roberta, XLNet, Distilbert, and\ntheir LSTM ensembles. Our model outperformed all other models in terms of\naccuracy, precision, recall, F1 score, and Mean Squared Error. Surprisingly, it\nalso needed less training time, resulting in a perfect combination of\nperformance and efficiency. This study demonstrates the utility of ensemble\nmodels for difficult tasks such as gene mutation classification.",
          "link": "http://arxiv.org/abs/2307.14361",
          "publishedOn": "2023-07-29T00:48:57.128Z",
          "wordCount": null,
          "title": "A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe. (arXiv:2307.14361v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Block_A/0/1/0/all/0/1\">Adam Block</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfrommer_D/0/1/0/all/0/1\">Daniel Pfrommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>",
          "description": "We propose a theoretical framework for studying the imitation of stochastic,\nnon-Markovian, potentially multi-modal (i.e. \"complex\" ) expert demonstrations\nin nonlinear dynamical systems. Our framework invokes low-level controllers -\neither learned or implicit in position-command control - to stabilize imitation\npolicies around expert demonstrations. We show that with (a) a suitable\nlow-level stability guarantee and (b) a stochastic continuity property of the\nlearned policy we call \"total variation continuity\" (TVC), an imitator that\naccurately estimates actions on the demonstrator's state distribution closely\nmatches the demonstrator's distribution over entire trajectories. We then show\nthat TVC can be ensured with minimal degradation of accuracy by combining a\npopular data-augmentation regimen with a novel algorithmic trick: adding\naugmentation noise at execution time. We instantiate our guarantees for\npolicies parameterized by diffusion models and prove that if the learner\naccurately estimates the score of the (noise-augmented) expert policy, then the\ndistribution of imitator trajectories is close to the demonstrator distribution\nin a natural optimal transport distance. Our analysis constructs intricate\ncouplings between noise-augmented trajectories, a technique that may be of\nindependent interest. We conclude by empirically validating our algorithmic\nrecommendations.",
          "link": "http://arxiv.org/abs/2307.14619",
          "publishedOn": "2023-07-29T00:48:57.127Z",
          "wordCount": null,
          "title": "Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14403",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ciotola_M/0/1/0/all/0/1\">Matteo Ciotola</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Poggi_G/0/1/0/all/0/1\">Giovanni Poggi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scarpa_G/0/1/0/all/0/1\">Giuseppe Scarpa</a>",
          "description": "In latest years, deep learning has gained a leading role in the pansharpening\nof multiresolution images. Given the lack of ground truth data, most deep\nlearning-based methods carry out supervised training in a reduced-resolution\ndomain. However, models trained on downsized images tend to perform poorly on\nhigh-resolution target images. For this reason, several research groups are now\nturning to unsupervised training in the full-resolution domain, through the\ndefinition of appropriate loss functions and training paradigms. In this\ncontext, we have recently proposed a full-resolution training framework which\ncan be applied to many existing architectures.\n\nHere, we propose a new deep learning-based pansharpening model that fully\nexploits the potential of this approach and provides cutting-edge performance.\nBesides architectural improvements with respect to previous work, such as the\nuse of residual attention modules, the proposed model features a novel loss\nfunction that jointly promotes the spectral and spatial quality of the\npansharpened data. In addition, thanks to a new fine-tuning strategy, it\nimproves inference-time adaptation to target images. Experiments on a large\nvariety of test images, performed in challenging scenarios, demonstrate that\nthe proposed method compares favorably with the state of the art both in terms\nof numerical results and visual output. Code is available online at\nhttps://github.com/matciotola/Lambda-PNN.",
          "link": "http://arxiv.org/abs/2307.14403",
          "publishedOn": "2023-07-29T00:48:57.115Z",
          "wordCount": null,
          "title": "Unsupervised Deep Learning-based Pansharpening with Jointly-Enhanced Spectral and Spatial Fidelity. (arXiv:2307.14403v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.12012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guharoy_R/0/1/0/all/0/1\">Rabel Guharoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jana_N/0/1/0/all/0/1\">Nanda Dulal Jana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Suparna Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_L/0/1/0/all/0/1\">Lalit Garg</a>",
          "description": "An Electroencephalogram (EEG) is a non-invasive exam that records the\nelectrical activity of the brain. This exam is used to help diagnose conditions\nsuch as different brain problems. EEG signals are taken for the purpose of\nepilepsy detection and with Discrete Wavelet Transform (DWT) and machine\nlearning classifier, they perform epilepsy detection. In Epilepsy seizure\ndetection, mainly machine learning classifiers and statistical features are\nused. The hidden information in the EEG signal is useful for detecting diseases\naffecting the brain. Sometimes it is very difficult to identify the minimum\nchanges in the EEG in the time and frequency domains purpose. The DWT can give\na good decomposition of the signals in different frequency bands and feature\nextraction. We use the tri-dimensionality reduction algorithm.; Principal\nComponent Analysis (PCA), Independent Component Analysis (ICA), and Linear\nDiscriminant Analysis (LDA). Finally, features are selected by using a fusion\nrule and at the last step three different classifiers Support Vector Machine\n(SVM), Naive Bayes (NB) and K-Nearest-Neighbor(KNN) have been used individually\nfor the classification. The proposed framework is tested on the Bonn dataset\nand the simulation results provide the accuracy for the combination of LDA and\nSVM 89.17%, LDA and KNN 80.42%, PCA and NB 89.92%, PCA and SVM 85.58%, PCA and\nKNN 80.42%, ICA and NB 82.33%, ICA and SVM 90.42%, and ICA and KNN 90%, LDA and\nNB 100%, accuracy. It shows the sensitivity, specificity, accuracy, Precision,\nand Recall of 100%, 100%, 100%, 100%, and 100%. This combination of LDA with NB\nmethod provides the accuracy of 100% outperforming all existing methods. The\nresults prove the effectiveness of this model.",
          "link": "http://arxiv.org/abs/2302.12012",
          "publishedOn": "2023-07-29T00:48:57.114Z",
          "wordCount": null,
          "title": "Empirical analysis of Different Dimensionality Reduction and classification Techniques for Epileptic Seizure detection. (arXiv:2302.12012v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fontana_M/0/1/0/all/0/1\">Maxime Fontana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spratling_M/0/1/0/all/0/1\">Michael Spratling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1\">Miaojing Shi</a>",
          "description": "Multi-Task Learning (MTL) aims to learn multiple tasks simultaneously while\nexploiting their mutual relationships. By using shared resources to\nsimultaneously calculate multiple outputs, this learning paradigm has the\npotential to have lower memory requirements and inference times compared to the\ntraditional approach of using separate methods for each task. Previous work in\nMTL has mainly focused on fully-supervised methods, as task relationships can\nnot only be leveraged to lower the level of data-dependency of those methods\nbut they can also improve performance. However, MTL introduces a set of\nchallenges due to a complex optimisation scheme and a higher labeling\nrequirement. This review focuses on how MTL could be utilised under different\npartial supervision settings to address these challenges. First, this review\nanalyses how MTL traditionally uses different parameter sharing techniques to\ntransfer knowledge in between tasks. Second, it presents the different\nchallenges arising from such a multi-objective optimisation scheme. Third, it\nintroduces how task groupings can be achieved by analysing task relationships.\nFourth, it focuses on how partially supervised methods applied to MTL can\ntackle the aforementioned challenges. Lastly, this review presents the\navailable datasets, tools and benchmarking results of such methods.",
          "link": "http://arxiv.org/abs/2307.14382",
          "publishedOn": "2023-07-29T00:48:57.074Z",
          "wordCount": null,
          "title": "When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review. (arXiv:2307.14382v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.11277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hendrickx_K/0/1/0/all/0/1\">Kilian Hendrickx</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perini_L/0/1/0/all/0/1\">Lorenzo Perini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plas_D/0/1/0/all/0/1\">Dries Van der Plas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meert_W/0/1/0/all/0/1\">Wannes Meert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">Jesse Davis</a>",
          "description": "Machine learning models always make a prediction, even when it is likely to\nbe inaccurate. This behavior should be avoided in many decision support\napplications, where mistakes can have severe consequences. Albeit already\nstudied in 1970, machine learning with rejection recently gained interest. This\nmachine learning subfield enables machine learning models to abstain from\nmaking a prediction when likely to make a mistake.\n\nThis survey aims to provide an overview on machine learning with rejection.\nWe introduce the conditions leading to two types of rejection, ambiguity and\nnovelty rejection, which we carefully formalize. Moreover, we review and\ncategorize strategies to evaluate a model's predictive and rejective quality.\nAdditionally, we define the existing architectures for models with rejection\nand describe the standard techniques for learning such models. Finally, we\nprovide examples of relevant application domains and show how machine learning\nwith rejection relates to other machine learning research areas.",
          "link": "http://arxiv.org/abs/2107.11277",
          "publishedOn": "2023-07-29T00:48:57.024Z",
          "wordCount": null,
          "title": "Machine Learning with a Reject Option: A survey. (arXiv:2107.11277v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kortvelesy_R/0/1/0/all/0/1\">Ryan Kortvelesy</a>",
          "description": "It is often useful to perform integration over learned functions represented\nby neural networks. However, this integration is usually performed numerically,\nas analytical integration over learned functions (especially neural networks)\nis generally viewed as intractable. In this work, we present a method for\nrepresenting the analytical integral of a learned function $f$. This allows the\nexact integral of a neural network to be computed, and enables constrained\nneural networks to be parametrised by applying constraints directly to the\nintegral. Crucially, we also introduce a method to constrain $f$ to be\npositive, a necessary condition for many applications (e.g. probability\ndistributions, distance metrics, etc). Finally, we introduce several\napplications where our fixed-integral neural network (FINN) can be utilised.",
          "link": "http://arxiv.org/abs/2307.14439",
          "publishedOn": "2023-07-29T00:48:57.023Z",
          "wordCount": null,
          "title": "Fixed Integral Neural Networks. (arXiv:2307.14439v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14389",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1\">Soowon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_Y/0/1/0/all/0/1\">Young-Eun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seo-Hyun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Decoding EEG signals for imagined speech is a challenging task due to the\nhigh-dimensional nature of the data and low signal-to-noise ratio. In recent\nyears, denoising diffusion probabilistic models (DDPMs) have emerged as\npromising approaches for representation learning in various domains. Our study\nproposes a novel method for decoding EEG signals for imagined speech using\nDDPMs and a conditional autoencoder named Diff-E. Results indicate that Diff-E\nsignificantly improves the accuracy of decoding EEG signals for imagined speech\ncompared to traditional machine learning techniques and baseline models. Our\nfindings suggest that DDPMs can be an effective tool for EEG signal decoding,\nwith potential implications for the development of brain-computer interfaces\nthat enable communication through imagined speech.",
          "link": "http://arxiv.org/abs/2307.14389",
          "publishedOn": "2023-07-29T00:48:56.008Z",
          "wordCount": 641,
          "title": "Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG. (arXiv:2307.14389v1 [eess.AS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yifan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiashu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_S/0/1/0/all/0/1\">Shihui Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>",
          "description": "The isomorphism problem is a fundamental problem in network analysis, which\ninvolves capturing both low-order and high-order structural information. In\nterms of extracting low-order structural information, graph isomorphism\nalgorithms analyze the structural equivalence to reduce the solver space\ndimension, which demonstrates its power in many applications, such as protein\ndesign, chemical pathways, and community detection. For the more commonly\noccurring high-order relationships in real-life scenarios, the problem of\nhypergraph isomorphism, which effectively captures these high-order structural\nrelationships, cannot be straightforwardly addressed using graph isomorphism\nmethods. Besides, the existing hypergraph kernel methods may suffer from high\nmemory consumption or inaccurate sub-structure identification, thus yielding\nsub-optimal performance. In this paper, to address the abovementioned problems,\nwe first propose the hypergraph Weisfiler-Lehman test algorithm for the\nhypergraph isomorphism test problem by generalizing the Weisfiler-Lehman test\nalgorithm from graphs to hypergraphs. Secondly, based on the presented\nalgorithm, we propose a general hypergraph Weisfieler-Lehman kernel framework\nand implement two instances, which are Hypergraph Weisfeiler-Lehamn Subtree\nKernel and Hypergraph Weisfeiler-Lehamn Hyperedge Kernel. In order to fulfill\nour research objectives, a comprehensive set of experiments was meticulously\ndesigned, including seven graph classification datasets and 12 hypergraph\nclassification datasets. Results on hypergraph classification datasets show\nsignificant improvements compared to other typical kernel-based methods, which\ndemonstrates the effectiveness of the proposed methods. In our evaluation, we\nfound that our proposed methods outperform the second-best method in terms of\nruntime, running over 80 times faster when handling complex hypergraph\nstructures.",
          "link": "http://arxiv.org/abs/2307.14394",
          "publishedOn": "2023-07-29T00:48:55.960Z",
          "wordCount": 720,
          "title": "Hypergraph Isomorphism Computation. (arXiv:2307.14394v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1\">Ning Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Junrui Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Ming Tang</a>",
          "description": "Mobile edge computing (MEC) is essential for next-generation mobile network\napplications that prioritize various performance metrics, including delays and\nenergy consumption. However, conventional single-objective scheduling solutions\ncannot be directly applied to practical systems in which the preferences of\nthese applications (i.e., the weights of different objectives) are often\nunknown or challenging to specify in advance. In this study, we address this\nissue by formulating a multi-objective offloading problem for MEC with multiple\nedges to minimize expected long-term energy consumption and transmission delay\nwhile considering unknown preferences as parameters. To address the challenge\nof unknown preferences, we design a multi-objective (deep) reinforcement\nlearning (MORL)-based resource scheduling scheme with proximal policy\noptimization (PPO). In addition, we introduce a well-designed state encoding\nmethod for constructing features for multiple edges in MEC systems, a\nsophisticated reward function for accurately computing the utilities of delay\nand energy consumption. Simulation results demonstrate that our proposed MORL\nscheme enhances the hypervolume of the Pareto front by up to 233.1% compared to\nbenchmarks. Our full framework is available at\nhttps://github.com/gracefulning/mec_morl_multipolicy.",
          "link": "http://arxiv.org/abs/2307.14346",
          "publishedOn": "2023-07-29T00:48:55.953Z",
          "wordCount": 680,
          "title": "Multi-objective Deep Reinforcement Learning for Mobile Edge Computing. (arXiv:2307.14346v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14359",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wong_B/0/1/0/all/0/1\">Benny Wong</a>",
          "description": "Optimization methods are essential in solving complex problems across various\ndomains. In this research paper, we introduce a novel optimization method\ncalled Gaussian Crunching Search (GCS). Inspired by the behaviour of particles\nin a Gaussian distribution, GCS aims to efficiently explore the solution space\nand converge towards the global optimum. We present a comprehensive analysis of\nGCS, including its working mechanism, and potential applications. Through\nexperimental evaluations and comparisons with existing optimization methods, we\nhighlight the advantages and strengths of GCS. This research paper serves as a\nvaluable resource for researchers, practitioners, and students interested in\noptimization, providing insights into the development and potential of Gaussian\nCrunching Search as a new and promising approach.",
          "link": "http://arxiv.org/abs/2307.14359",
          "publishedOn": "2023-07-29T00:48:55.946Z",
          "wordCount": 596,
          "title": "A new derivative-free optimization method: Gaussian Crunching Search. (arXiv:2307.14359v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2308.04365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vowels_M/0/1/0/all/0/1\">Matthew J. Vowels</a>",
          "description": "Causal inference is a crucial goal of science, enabling researchers to arrive\nat meaningful conclusions regarding the predictions of hypothetical\ninterventions using observational data. Path models, Structural Equation Models\n(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to\nunambiguously specify assumptions regarding the causal structure underlying a\nphenomenon. Unlike DAGs, which make very few assumptions about the functional\nand parametric form, SEM assumes linearity. This can result in functional\nmisspecification which prevents researchers from undertaking reliable effect\nsize estimation. In contrast, we propose Super Learner Equation Modeling, a\npath modeling technique integrating machine learning Super Learner ensembles.\nWe empirically demonstrate its ability to provide consistent and unbiased\nestimates of causal effects, its competitive performance for linear models when\ncompared with SEM, and highlight its superiority over SEM when dealing with\nnon-linear relationships. We provide open-source code, and a tutorial notebook\nwith example usage, accentuating the easy-to-use nature of the method.",
          "link": "http://arxiv.org/abs/2308.04365",
          "publishedOn": "2023-08-12T00:39:31.043Z",
          "wordCount": null,
          "title": "SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kojo_A/0/1/0/all/0/1\">Adu-Gyamfi Kojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghupathi_K/0/1/0/all/0/1\">Kandiboina Raghupathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varsha_R/0/1/0/all/0/1\">Ravichandra-Mouli Varsha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skylar_K/0/1/0/all/0/1\">Knickerbocker Skylar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+N_H/0/1/0/all/0/1\">Hans Zachary N</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawkins/0/1/0/all/0/1\">Hawkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_N/0/1/0/all/0/1\">Neal R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anuj_S/0/1/0/all/0/1\">Sharma Anuj</a>",
          "description": "In today's rapidly evolving urban landscapes, efficient and accurate mapping\nof road infrastructure is critical for optimizing transportation systems,\nenhancing road safety, and improving the overall mobility experience for\ndrivers and commuters. Yet, a formidable bottleneck obstructs progress - the\nlaborious and time-intensive manual identification of intersections. Simply\nconsidering the shear number of intersections that need to be identified, and\nthe labor hours required per intersection, the need for an automated solution\nbecomes undeniable. To address this challenge, we propose a novel approach that\nleverages connected vehicle data and cutting-edge deep learning techniques. By\nemploying geohashing to segment vehicle trajectories and then generating image\nrepresentations of road segments, we utilize the YOLOv5 (You Only Look Once\nversion 5) algorithm for accurate classification of both straight road segments\nand intersections. Experimental results demonstrate an impressive overall\nclassification accuracy of 95%, with straight roads achieving a remarkable 97%\nF1 score and intersections reaching a 90% F1 score. This approach not only\nsaves time and resources but also enables more frequent updates and a\ncomprehensive understanding of the road network. Our research showcases the\npotential impact on traffic management, urban planning, and autonomous vehicle\nnavigation systems. The fusion of connected vehicle data and deep learning\nmodels holds promise for a transformative shift in road infrastructure mapping,\npropelling us towards a smarter, safer, and more connected transportation\necosystem.",
          "link": "http://arxiv.org/abs/2308.05658",
          "publishedOn": "2023-08-12T00:39:31.039Z",
          "wordCount": null,
          "title": "Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model. (arXiv:2308.05658v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.04702",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1\">Sourav Chatterjee</a>",
          "description": "This paper surveys some recent developments in measures of association\nrelated to a new coefficient of correlation introduced by the author. A\nstraightforward extension of this coefficient to standard Borel spaces (which\nincludes all Polish spaces), overlooked in the literature so far, is proposed\nat the end of the survey.",
          "link": "http://arxiv.org/abs/2211.04702",
          "publishedOn": "2023-08-12T00:39:31.039Z",
          "wordCount": null,
          "title": "A survey of some recent developments in measures of association. (arXiv:2211.04702v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.09738",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1\">Wu Lin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duruisseaux_V/0/1/0/all/0/1\">Valentin Duruisseaux</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Leok_M/0/1/0/all/0/1\">Melvin Leok</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nielsen_F/0/1/0/all/0/1\">Frank Nielsen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1\">Mark Schmidt</a>",
          "description": "Riemannian submanifold optimization with momentum is computationally\nchallenging because, to ensure that the iterates remain on the submanifold, we\noften need to solve difficult differential equations. Here, we simplify such\ndifficulties for a class of sparse or structured symmetric positive-definite\nmatrices with the affine-invariant metric. We do so by proposing a generalized\nversion of the Riemannian normal coordinates that dynamically orthonormalizes\nthe metric and locally converts the problem into an unconstrained problem in\nthe Euclidean space. We use our approach to simplify existing approaches for\nstructured covariances and develop matrix-inverse-free $2^\\text{nd}$-order\noptimizers for deep learning with low precision by using only matrix\nmultiplications. Code: https://github.com/yorkerlin/StructuredNGD-DL",
          "link": "http://arxiv.org/abs/2302.09738",
          "publishedOn": "2023-08-12T00:39:31.038Z",
          "wordCount": null,
          "title": "Simplifying Momentum-based Positive-definite Submanifold Optimization with Applications to Deep Learning. (arXiv:2302.09738v7 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orabona_F/0/1/0/all/0/1\">Francesco Orabona</a>",
          "description": "In this short note, I show how to adapt to H\\\"{o}lder smoothness using\nnormalized gradients in a black-box way. Moreover, the bound will depend on a\nnovel notion of local H\\\"{o}lder smoothness. The main idea directly comes from\nLevy [2017].",
          "link": "http://arxiv.org/abs/2308.05621",
          "publishedOn": "2023-08-12T00:39:31.035Z",
          "wordCount": null,
          "title": "Normalized Gradients for All. (arXiv:2308.05621v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_U/0/1/0/all/0/1\">Ushnish Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jao_C/0/1/0/all/0/1\">Chinkuo Jao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernacchia_A/0/1/0/all/0/1\">Alberto Bernacchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakili_S/0/1/0/all/0/1\">Sattar Vakili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>",
          "description": "Channel modelling is essential to designing modern wireless communication\nsystems. The increasing complexity of channel modelling and the cost of\ncollecting high-quality wireless channel data have become major challenges. In\nthis paper, we propose a diffusion model based channel sampling approach for\nrapidly synthesizing channel realizations from limited data. We use a diffusion\nmodel with a U Net based architecture operating in the frequency space domain.\nTo evaluate how well the proposed model reproduces the true distribution of\nchannels in the training dataset, two evaluation metrics are used: $i)$ the\napproximate $2$-Wasserstein distance between real and generated distributions\nof the normalized power spectrum in the antenna and frequency domains and $ii)$\nprecision and recall metric for distributions. We show that, compared to\nexisting GAN based approaches which suffer from mode collapse and unstable\ntraining, our diffusion based approach trains stably and generates diverse and\nhigh-fidelity samples from the true channel distribution. We also show that we\ncan pretrain the model on a simulated urban macro-cellular channel dataset and\nfine-tune it on a smaller, out-of-distribution urban micro-cellular dataset,\ntherefore showing that it is feasible to model real world channels using\nlimited data with this approach.",
          "link": "http://arxiv.org/abs/2308.05583",
          "publishedOn": "2023-08-12T00:39:30.977Z",
          "wordCount": null,
          "title": "Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling. (arXiv:2308.05583v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06683",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Singh_H/0/1/0/all/0/1\">Himali Singh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chattopadhyay_A/0/1/0/all/0/1\">Arpan Chattopadhyay</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mishra_K/0/1/0/all/0/1\">Kumar Vijay Mishra</a>",
          "description": "Counter-adversarial system design problems have lately motivated the\ndevelopment of inverse Bayesian filters. For example, inverse Kalman filter\n(I-KF) has been recently formulated to estimate the adversary's\nKalman-filter-tracked estimates and hence, predict the adversary's future\nsteps. The purpose of this paper and the companion paper (Part I) is to address\nthe inverse filtering problem in non-linear systems by proposing an inverse\nextended Kalman filter (I-EKF). The companion paper proposed the theory of\nI-EKF (with and without unknown inputs) and I-KF (with unknown inputs). In this\npaper, we develop this theory for highly non-linear models, which employ\nsecond-order, Gaussian sum, and dithered forward EKFs. In particular, we derive\ntheoretical stability guarantees for the inverse second-order EKF using the\nbounded non-linearity approach. To address the limitation of the standard\nI-EKFs that the system model and forward filter are perfectly known to the\ndefender, we propose reproducing kernel Hilbert space-based EKF to learn the\nunknown system dynamics based on its observations, which can be employed as an\ninverse filter to infer the adversary's estimate. Numerical experiments\ndemonstrate the state estimation performance of the proposed filters using\nrecursive Cram\\'{e}r-Rao lower bound as a benchmark.",
          "link": "http://arxiv.org/abs/2208.06683",
          "publishedOn": "2023-08-12T00:39:30.950Z",
          "wordCount": null,
          "title": "Inverse Extended Kalman Filter -- Part II: Highly Non-Linear and Uncertain Systems. (arXiv:2208.06683v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.02495",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ganev_S/0/1/0/all/0/1\">Stoil Ganev</a>",
          "description": "Here, we show that the InfoNCE objective is equivalent to the ELBO in a new\nclass of probabilistic generative model, the recognition parameterised model\n(RPM). When we learn the optimal prior, the RPM ELBO becomes equal to the\nmutual information (MI; up to a constant), establishing a connection to\npre-existing self-supervised learning methods such as InfoNCE. However,\npractical InfoNCE methods do not use the MI as an objective; the MI is\ninvariant to arbitrary invertible transformations, so using an MI objective can\nlead to highly entangled representations (Tschannen et al., 2019). Instead, the\nactual InfoNCE objective is a simplified lower bound on the MI which is loose\neven in the infinite sample limit. Thus, an objective that works (i.e. the\nactual InfoNCE objective) appears to be motivated as a loose bound on an\nobjective that does not work (i.e. the true MI which gives arbitrarily\nentangled representations). We give an alternative motivation for the actual\nInfoNCE objective. In particular, we show that in the infinite sample limit,\nand for a particular choice of prior, the actual InfoNCE objective is equal to\nthe ELBO (up to a constant); and the ELBO is equal to the marginal likelihood\nwith a deterministic recognition model. Thus, we argue that our VAE perspective\ngives a better motivation for InfoNCE than MI, as the actual InfoNCE objective\nis only loosely bounded by the MI, but is equal to the ELBO/marginal likelihood\n(up to a constant).",
          "link": "http://arxiv.org/abs/2107.02495",
          "publishedOn": "2023-08-12T00:39:30.900Z",
          "wordCount": null,
          "title": "InfoNCE is variational inference in a recognition parameterised model. (arXiv:2107.02495v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13829",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1\">Yiling Huang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pirenne_S/0/1/0/all/0/1\">Sarah Pirenne</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panigrahi_S/0/1/0/all/0/1\">Snigdha Panigrahi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Claeskens_G/0/1/0/all/0/1\">Gerda Claeskens</a>",
          "description": "Selective inference methods are developed for group lasso estimators for use\nwith a wide class of distributions and loss functions. The method includes the\nuse of exponential family distributions, as well as quasi-likelihood modeling\nfor overdispersed count data, for example, and allows for categorical or\ngrouped covariates as well as continuous covariates. A randomized\ngroup-regularized optimization problem is studied. The added randomization\nallows us to construct a post-selection likelihood which we show to be adequate\nfor selective inference when conditioning on the event of the selection of the\ngrouped covariates. This likelihood also provides a selective point estimator,\naccounting for the selection by the group lasso. Confidence regions for the\nregression parameters in the selected model take the form of Wald-type regions\nand are shown to have bounded volume. The selective inference method for\ngrouped lasso is illustrated on data from the national health and nutrition\nexamination survey while simulations showcase its behaviour and favorable\ncomparison with other methods.",
          "link": "http://arxiv.org/abs/2306.13829",
          "publishedOn": "2023-08-12T00:39:30.900Z",
          "wordCount": null,
          "title": "Selective inference using randomized group lasso estimators for general models. (arXiv:2306.13829v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05619",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Otles_E/0/1/0/all/0/1\">Erkin &#xd6;tle&#x15f;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Denton_B/0/1/0/all/0/1\">Brian T. Denton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wiens_J/0/1/0/all/0/1\">Jenna Wiens</a>",
          "description": "As data shift or new data become available, updating clinical machine\nlearning models may be necessary to maintain or improve performance over time.\nHowever, updating a model can introduce compatibility issues when the behavior\nof the updated model does not align with user expectations, resulting in poor\nuser-model team performance. Existing compatibility measures depend on model\ndecision thresholds, limiting their applicability in settings where models are\nused to generate rankings based on estimated risk. To address this limitation,\nwe propose a novel rank-based compatibility measure, $C^R$, and a new loss\nfunction that aims to optimize discriminative performance while encouraging\ngood compatibility. Applied to a case study in mortality risk stratification\nleveraging data from MIMIC, our approach yields more compatible models while\nmaintaining discriminative performance compared to existing model selection\ntechniques, with an increase in $C^R$ of $0.019$ ($95\\%$ confidence interval:\n$0.005$, $0.035$). This work provides new tools to analyze and update risk\nstratification models used in clinical care.",
          "link": "http://arxiv.org/abs/2308.05619",
          "publishedOn": "2023-08-12T00:39:30.896Z",
          "wordCount": null,
          "title": "Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance. (arXiv:2308.05619v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chuying Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yasong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianyu Wang</a>",
          "description": "Random Search is one of the most widely-used method for Hyperparameter\nOptimization, and is critical to the success of deep learning models. Despite\nits astonishing performance, little non-heuristic theory has been developed to\ndescribe the underlying working mechanism. This paper gives a theoretical\naccounting of Random Search. We introduce the concept of \\emph{scattering\ndimension} that describes the landscape of the underlying function, and\nquantifies the performance of random search. We show that, when the environment\nis noise-free, the output of random search converges to the optimal value in\nprobability at rate $ \\widetilde{\\mathcal{O}} \\left( \\left( \\frac{1}{T}\n\\right)^{ \\frac{1}{d_s} } \\right) $, where $ d_s \\ge 0 $ is the scattering\ndimension of the underlying function. When the observed function values are\ncorrupted by bounded $iid$ noise, the output of random search converges to the\noptimal value in probability at rate $ \\widetilde{\\mathcal{O}} \\left( \\left(\n\\frac{1}{T} \\right)^{ \\frac{1}{d_s + 1} } \\right) $. In addition, based on the\nprinciples of random search, we introduce an algorithm, called BLiN-MOS, for\nLipschitz bandits in doubling metric spaces that are also endowed with a\nprobability measure, and show that BLiN-MOS achieves a regret rate of order $\n\\widetilde{\\mathcal{O}} \\left( T^{ \\frac{d_z}{d_z + 1} } \\right) $, where $d_z$\nis the zooming dimension of the problem instance.",
          "link": "http://arxiv.org/abs/2305.11509",
          "publishedOn": "2023-08-12T00:39:30.892Z",
          "wordCount": null,
          "title": "From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.05869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heinrichs_F/0/1/0/all/0/1\">Florian Heinrichs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heim_M/0/1/0/all/0/1\">Mavin Heim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1\">Corinna Weber</a>",
          "description": "It is desirable for statistical models to detect signals of interest\nindependently of their position. If the data is generated by some smooth\nprocess, this additional structure should be taken into account. We introduce a\nnew class of neural networks that are shift invariant and preserve smoothness\nof the data: functional neural networks (FNNs). For this, we use methods from\nfunctional data analysis (FDA) to extend multi-layer perceptrons and\nconvolutional neural networks to functional data. We propose different model\narchitectures, show that the models outperform a benchmark model from FDA in\nterms of accuracy and successfully use FNNs to classify electroencephalography\n(EEG) data.",
          "link": "http://arxiv.org/abs/2301.05869",
          "publishedOn": "2023-08-12T00:39:30.884Z",
          "wordCount": null,
          "title": "Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification. (arXiv:2301.05869v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.14220",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Panigrahi_S/0/1/0/all/0/1\">Snigdha Panigrahi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stewart_N/0/1/0/all/0/1\">Natasha Stewart</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sripada_C/0/1/0/all/0/1\">Chandra Sekhar Sripada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Levina_E/0/1/0/all/0/1\">Elizaveta Levina</a>",
          "description": "Multi-task learning is frequently used to model a set of related response\nvariables from the same set of features, improving predictive performance and\nmodeling accuracy relative to methods that handle each response variable\nseparately. Despite the potential of multi-task learning to yield more powerful\ninference than single-task alternatives, prior work in this area has largely\nomitted uncertainty quantification. Our focus in this paper is a common\nmulti-task problem in neuroimaging, where the goal is to understand the\nrelationship between multiple cognitive task scores (or other subject-level\nassessments) and brain connectome data collected from imaging. We propose a\nframework for selective inference to address this problem, with the flexibility\nto: (i) jointly identify the relevant covariates for each task through a\nsparsity-inducing penalty, and (ii) conduct valid inference in a model based on\nthe estimated sparsity structure. Our framework offers a new conditional\nprocedure for inference, based on a refinement of the selection event that\nyields a tractable selection-adjusted likelihood. This gives an approximate\nsystem of estimating equations for maximum likelihood inference, solvable via a\nsingle convex optimization problem, and enables us to efficiently form\nconfidence intervals with approximately the correct coverage. Applied to both\nsimulated data and data from the Adolescent Brain Cognitive Development (ABCD)\nstudy, our selective inference methods yield tighter confidence intervals than\ncommonly used alternatives, such as data splitting. We also demonstrate through\nsimulations that multi-task learning with selective inference can more\naccurately recover true signals than single-task methods.",
          "link": "http://arxiv.org/abs/2205.14220",
          "publishedOn": "2023-08-12T00:39:30.883Z",
          "wordCount": null,
          "title": "Selective Inference for Sparse Multitask Regression with Applications in Neuroimaging. (arXiv:2205.14220v4 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05422",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Leyder_S/0/1/0/all/0/1\">Sarah Leyder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Raymaekers_J/0/1/0/all/0/1\">Jakob Raymaekers</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Verdonck_T/0/1/0/all/0/1\">Tim Verdonck</a>",
          "description": "One of the established approaches to causal discovery consists of combining\ndirected acyclic graphs (DAGs) with structural causal models (SCMs) to describe\nthe functional dependencies of effects on their causes. Possible\nidentifiability of SCMs given data depends on assumptions made on the noise\nvariables and the functional classes in the SCM. For instance, in the LiNGAM\nmodel, the functional class is restricted to linear functions and the\ndisturbances have to be non-Gaussian.\n\nIn this work, we propose TSLiNGAM, a new method for identifying the DAG of a\ncausal model based on observational data. TSLiNGAM builds on DirectLiNGAM, a\npopular algorithm which uses simple OLS regression for identifying causal\ndirections between variables. TSLiNGAM leverages the non-Gaussianity assumption\nof the error terms in the LiNGAM model to obtain more efficient and robust\nestimation of the causal structure. TSLiNGAM is justified theoretically and is\nstudied empirically in an extensive simulation study. It performs significantly\nbetter on heavy-tailed and skewed data and demonstrates a high small-sample\nefficiency. In addition, TSLiNGAM also shows better robustness properties as it\nis more resilient to contamination.",
          "link": "http://arxiv.org/abs/2308.05422",
          "publishedOn": "2023-08-12T00:39:30.878Z",
          "wordCount": null,
          "title": "TSLiNGAM: DirectLiNGAM under heavy tails. (arXiv:2308.05422v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05414",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Blanchet_J/0/1/0/all/0/1\">Jose Blanchet</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kuhn_D/0/1/0/all/0/1\">Daniel Kuhn</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1\">Jiajin Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Taskesen_B/0/1/0/all/0/1\">Bahar Taskesen</a>",
          "description": "In the past few years, there has been considerable interest in two prominent\napproaches for Distributionally Robust Optimization (DRO): Divergence-based and\nWasserstein-based methods. The divergence approach models misspecification in\nterms of likelihood ratios, while the latter models it through a measure of\ndistance or cost in actual outcomes. Building upon these advances, this paper\nintroduces a novel approach that unifies these methods into a single framework\nbased on optimal transport (OT) with conditional moment constraints. Our\nproposed approach, for example, makes it possible for optimal adversarial\ndistributions to simultaneously perturb likelihood and outcomes, while\nproducing an optimal (in an optimal transport sense) coupling between the\nbaseline model and the adversarial model.Additionally, the paper investigates\nseveral duality results and presents tractable reformulations that enhance the\npractical applicability of this unified framework.",
          "link": "http://arxiv.org/abs/2308.05414",
          "publishedOn": "2023-08-12T00:39:30.872Z",
          "wordCount": null,
          "title": "Unifying Distributionally Robust Optimization via Optimal Transport Theory. (arXiv:2308.05414v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.08902",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Giuliani_C/0/1/0/all/0/1\">Clemens Giuliani</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Vicentini_F/0/1/0/all/0/1\">Filippo Vicentini</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rossi_R/0/1/0/all/0/1\">Riccardo Rossi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Carleo_G/0/1/0/all/0/1\">Giuseppe Carleo</a>",
          "description": "Neural network approaches to approximate the ground state of quantum\nhamiltonians require the numerical solution of a highly nonlinear optimization\nproblem. We introduce a statistical learning approach that makes the\noptimization trivial by using kernel methods. Our scheme is an approximate\nrealization of the power method, where supervised learning is used to learn the\nnext step of the power iteration. We show that the ground state properties of\narbitrary gapped quantum hamiltonians can be reached with polynomial resources\nunder the assumption that the supervised learning is efficient. Using kernel\nridge regression, we provide numerical evidence that the learning assumption is\nverified by applying our scheme to find the ground states of several\nprototypical interacting many-body quantum systems, both in one and two\ndimensions, showing the flexibility of our approach.",
          "link": "http://arxiv.org/abs/2303.08902",
          "publishedOn": "2023-08-12T00:39:30.145Z",
          "wordCount": null,
          "title": "Learning ground states of gapped quantum Hamiltonians with Kernel Methods. (arXiv:2303.08902v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adu_Gyamfi_K/0/1/0/all/0/1\">Kojo Adu-Gyamfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anuj_S/0/1/0/all/0/1\">Sharma Anuj</a>",
          "description": "Modern transportation planning relies heavily on accurate predictions of\nperson and vehicle trips. However, traditional planning models often fail to\naccount for the intricacies and dynamics of travel behavior, leading to\nless-than-optimal accuracy in these predictions. This study explores the\npotential of deep learning techniques to transform the way we approach trip\npredictions, and ultimately, transportation planning. Utilizing a comprehensive\ndataset from the National Household Travel Survey (NHTS), we developed and\ntrained a deep learning model for predicting person and vehicle trips. The\nproposed model leverages the vast amount of information in the NHTS data,\ncapturing complex, non-linear relationships that were previously overlooked by\ntraditional models. As a result, our deep learning model achieved an impressive\naccuracy of 98% for person trip prediction and 96% for vehicle trip estimation.\nThis represents a significant improvement over the performances of traditional\ntransportation planning models, thereby demonstrating the power of deep\nlearning in this domain. The implications of this study extend beyond just more\naccurate predictions. By enhancing the accuracy and reliability of trip\nprediction models, planners can formulate more effective, data-driven\ntransportation policies, infrastructure, and services. As such, our research\nunderscores the need for the transportation planning field to embrace advanced\ntechniques like deep learning. The detailed methodology, along with a thorough\ndiscussion of the results and their implications, are presented in the\nsubsequent sections of this paper.",
          "link": "http://arxiv.org/abs/2308.05665",
          "publishedOn": "2023-08-12T00:39:30.143Z",
          "wordCount": null,
          "title": "Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data. (arXiv:2308.05665v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00453",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1\">Soufiane Hayou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_G/0/1/0/all/0/1\">Greg Yang</a>",
          "description": "We show that taking the width and depth to infinity in a deep neural network\nwith skip connections, when branches are scaled by $1/\\sqrt{depth}$ (the only\nnontrivial scaling), result in the same covariance structure no matter how that\nlimit is taken. This explains why the standard infinite-width-then-depth\napproach provides practical insights even for networks with depth of the same\norder as width. We also demonstrate that the pre-activations, in this case,\nhave Gaussian distributions which has direct applications in Bayesian deep\nlearning. We conduct extensive simulations that show an excellent match with\nour theoretical findings.",
          "link": "http://arxiv.org/abs/2302.00453",
          "publishedOn": "2023-08-12T00:39:30.109Z",
          "wordCount": null,
          "title": "Width and Depth Limits Commute in Residual Networks. (arXiv:2302.00453v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01729",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Duval_F/0/1/0/all/0/1\">Francis Duval</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boucher_J/0/1/0/all/0/1\">Jean-Philippe Boucher</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pigeon_M/0/1/0/all/0/1\">Mathieu Pigeon</a>",
          "description": "We present novel cross-sectional and longitudinal claim count models for\nvehicle insurance built upon the Combined Actuarial Neural Network (CANN)\nframework proposed by Mario W\\\"uthrich and Michael Merz. The CANN approach\ncombines a classical actuarial model, such as a generalized linear model, with\na neural network. This blending of models results in a two-component model\ncomprising a classical regression model and a neural network part. The CANN\nmodel leverages the strengths of both components, providing a solid foundation\nand interpretability from the classical model while harnessing the flexibility\nand capacity to capture intricate relationships and interactions offered by the\nneural network. In our proposed models, we use well-known log-linear claim\ncount regression models for the classical regression part and a multilayer\nperceptron (MLP) for the neural network part. The MLP part is used to process\ntelematics car driving data given as a vector characterizing the driving\nbehavior of each insured driver. In addition to the Poisson and negative\nbinomial distributions for cross-sectional data, we propose a procedure for\ntraining our CANN model with a multivariate negative binomial (MVNB)\nspecification. By doing so, we introduce a longitudinal model that accounts for\nthe dependence between contracts from the same insured. Our results reveal that\nthe CANN models exhibit superior performance compared to log-linear models that\nrely on manually engineered telematics features.",
          "link": "http://arxiv.org/abs/2308.01729",
          "publishedOn": "2023-08-05T00:48:26.674Z",
          "wordCount": null,
          "title": "Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data. (arXiv:2308.01729v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01839",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_R/0/1/0/all/0/1\">Rong Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sun_E/0/1/0/all/0/1\">Eric D. Sun</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Donoho_D/0/1/0/all/0/1\">David Donoho</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>",
          "description": "Single-cell data integration can provide a comprehensive molecular view of\ncells, and many algorithms have been developed to remove unwanted technical or\nbiological variations and integrate heterogeneous single-cell datasets. Despite\ntheir wide usage, existing methods suffer from several fundamental limitations.\nIn particular, we lack a rigorous statistical test for whether two\nhigh-dimensional single-cell datasets are alignable (and therefore should even\nbe aligned). Moreover, popular methods can substantially distort the data\nduring alignment, making the aligned data and downstream analysis difficult to\ninterpret. To overcome these limitations, we present a spectral manifold\nalignment and inference (SMAI) framework, which enables principled and\ninterpretable alignability testing and structure-preserving integration of\nsingle-cell data. SMAI provides a statistical test to robustly determine the\nalignability between datasets to avoid misleading inference, and is justified\nby high-dimensional statistical theory. On a diverse range of real and\nsimulated benchmark datasets, it outperforms commonly used alignment methods.\nMoreover, we show that SMAI improves various downstream analyses such as\nidentification of differentially expressed genes and imputation of single-cell\nspatial transcriptomics, providing further biological insights. SMAI's\ninterpretability also enables quantification and a deeper understanding of the\nsources of technical confounders in single-cell data.",
          "link": "http://arxiv.org/abs/2308.01839",
          "publishedOn": "2023-08-05T00:48:26.668Z",
          "wordCount": null,
          "title": "Is your data alignable? Principled and interpretable alignability testing and integration of single-cell data. (arXiv:2308.01839v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08875",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "This paper focusses on the optimal implementation of a Mean Variance\nEstimation network (MVE network) (Nix and Weigend, 1994). This type of network\nis often used as a building block for uncertainty estimation methods in a\nregression setting, for instance Concrete dropout (Gal et al., 2017) and Deep\nEnsembles (Lakshminarayanan et al., 2017). Specifically, an MVE network assumes\nthat the data is produced from a normal distribution with a mean function and\nvariance function. The MVE network outputs a mean and variance estimate and\noptimizes the network parameters by minimizing the negative loglikelihood. In\nour paper, we present two significant insights. Firstly, the convergence\ndifficulties reported in recent work can be relatively easily prevented by\nfollowing the simple yet often overlooked recommendation from the original\nauthors that a warm-up period should be used. During this period, only the mean\nis optimized with a fixed variance. We demonstrate the effectiveness of this\nstep through experimentation, highlighting that it should be standard practice.\nAs a sidenote, we examine whether, after the warm-up, it is beneficial to fix\nthe mean while optimizing the variance or to optimize both simultaneously.\nHere, we do not observe a substantial difference. Secondly, we introduce a\nnovel improvement of the MVE network: separate regularization of the mean and\nthe variance estimate. We demonstrate, both on toy examples and on a number of\nbenchmark UCI regression data sets, that following the original recommendations\nand the novel separate regularization can lead to significant improvements.",
          "link": "http://arxiv.org/abs/2302.08875",
          "publishedOn": "2023-08-05T00:48:26.658Z",
          "wordCount": null,
          "title": "Optimal Training of Mean Variance Estimation Neural Networks. (arXiv:2302.08875v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.10051",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lipshutz_D/0/1/0/all/0/1\">David Lipshutz</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bahroun_Y/0/1/0/all/0/1\">Yanis Bahroun</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Golkar_S/0/1/0/all/0/1\">Siavash Golkar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sengupta_A/0/1/0/all/0/1\">Anirvan M. Sengupta</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chklovskii_D/0/1/0/all/0/1\">Dmitri B. Chklovskii</a>",
          "description": "An established normative approach for understanding the algorithmic basis of\nneural computation is to derive online algorithms from principled computational\nobjectives and evaluate their compatibility with anatomical and physiological\nobservations. Similarity matching objectives have served as successful starting\npoints for deriving online algorithms that map onto neural networks (NNs) with\npoint neurons and Hebbian/anti-Hebbian plasticity. These NN models account for\nmany anatomical and physiological observations; however, the objectives have\nlimited computational power and the derived NNs do not explain\nmulti-compartmental neuronal structures and non-Hebbian forms of plasticity\nthat are prevalent throughout the brain. In this article, we unify and\ngeneralize recent extensions of the similarity matching approach to address\nmore complex objectives, including a large class of unsupervised and\nself-supervised learning tasks that can be formulated as symmetric generalized\neigenvalue problems or nonnegative matrix factorization problems.\nInterestingly, the online algorithms derived from these objectives naturally\nmap onto NNs with multi-compartmental neurons and local, non-Hebbian learning\nrules. Therefore, this unified extension of the similarity matching approach\nprovides a normative framework that facilitates understanding\nmulti-compartmental neuronal structures and non-Hebbian plasticity found\nthroughout the brain.",
          "link": "http://arxiv.org/abs/2302.10051",
          "publishedOn": "2023-08-05T00:48:26.658Z",
          "wordCount": null,
          "title": "Normative framework for deriving neural networks with multi-compartmental neurons and non-Hebbian plasticity. (arXiv:2302.10051v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01481",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Roy_A/0/1/0/all/0/1\">Abhishek Roy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Krishnakumar Balasubramanian</a>",
          "description": "We study the online overlapping batch-means covariance estimator for\nStochastic Gradient Descent (SGD) under Markovian sampling. We show that the\nconvergence rates of the covariance estimator are\n$O\\big(\\sqrt{d}\\,n^{-1/8}(\\log n)^{1/4}\\big)$ and\n$O\\big(\\sqrt{d}\\,n^{-1/8}\\big)$ under state-dependent and state-independent\nMarkovian sampling, respectively, with $d$ representing dimensionality and $n$\ndenoting the number of observations or SGD iterations. Remarkably, these rates\nmatch the best-known convergence rate previously established for the\nindependent and identically distributed ($\\iid$) case by \\cite{zhu2021online},\nup to logarithmic factors. Our analysis overcomes significant challenges that\narise due to Markovian sampling, leading to the introduction of additional\nerror terms and complex dependencies between the blocks of the batch-means\ncovariance estimator. Moreover, we establish the convergence rate for the first\nfour moments of the $\\ell_2$ norm of the error of SGD dynamics under\nstate-dependent Markovian data, which holds potential interest as an\nindependent result. To validate our theoretical findings, we provide numerical\nillustrations to derive confidence intervals for SGD when training linear and\nlogistic regression models under Markovian sampling. Additionally, we apply our\napproach to tackle the intriguing problem of strategic classification with\nlogistic regression, where adversaries can adaptively modify features during\nthe training process to increase their chances of being classified in a\nspecific target class.",
          "link": "http://arxiv.org/abs/2308.01481",
          "publishedOn": "2023-08-05T00:48:26.656Z",
          "wordCount": null,
          "title": "Online covariance estimation for stochastic gradient descent under Markovian sampling. (arXiv:2308.01481v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Puning Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Lifeng Lai</a>",
          "description": "$Q$ learning is a popular model free reinforcement learning method. Most of\nexisting works focus on analyzing $Q$ learning for finite state and action\nspaces. If the state space is continuous, then the original $Q$ learning method\ncan not be directly used. A modification of the original $Q$ learning method\nwas proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest\nneighbors. Such modification makes $Q$ learning suitable for continuous state\nspace. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$\nfunction is $\\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower\nbound $\\tilde{\\Omega}(T^{-1/(d+2)})$, indicating that this method is not\nefficient. This paper proposes two new $Q$ learning methods to bridge the gap\nof convergence rates in (Shah and Xie, 2018), with one of them being offline,\nwhile the other is online. Despite that we still use nearest neighbor approach\nto estimate $Q$ function, the algorithms are crucially different from (Shah and\nXie, 2018). In particular, we replace the kernel nearest neighbor in\ndiscretized region with a direct nearest neighbor approach. Consequently, our\napproach significantly improves the convergence rate. Moreover, the time\ncomplexity is also significantly improved in high dimensional state spaces. Our\nanalysis shows that both offline and online methods are minimax rate optimal.",
          "link": "http://arxiv.org/abs/2308.01490",
          "publishedOn": "2023-08-05T00:48:26.655Z",
          "wordCount": null,
          "title": "Minimax Optimal $Q$ Learning with Nearest Neighbors. (arXiv:2308.01490v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.14563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hiabu_M/0/1/0/all/0/1\">Munir Hiabu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mammen_E/0/1/0/all/0/1\">Enno Mammen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meyer_J/0/1/0/all/0/1\">Joseph T. Meyer</a>",
          "description": "We introduce a novel interpretable tree based algorithm for prediction in a\nregression setting. Our motivation is to estimate the unknown regression\nfunction from a functional decomposition perspective in which the functional\ncomponents correspond to lower order interaction terms. The idea is to modify\nthe random forest algorithm by keeping certain leaves after they are split\ninstead of deleting them. This leads to non-binary trees which we refer to as\nplanted trees. An extension to a forest leads to our random planted forest\nalgorithm. Additionally, the maximum number of covariates which can interact\nwithin a leaf can be bounded. If we set this interaction bound to one, the\nresulting estimator is a sum of one-dimensional functions. In the other extreme\ncase, if we do not set a limit, the resulting estimator and corresponding model\nplace no restrictions on the form of the regression function. In a simulation\nstudy we find encouraging prediction and visualisation properties of our random\nplanted forest method. We also develop theory for an idealized version of\nrandom planted forests in cases where the interaction bound is low. We show\nthat if it is smaller than three, the idealized version achieves asymptotically\noptimal convergence rates up to a logarithmic factor. Code is available on\nGitHub https://github.com/PlantedML/randomPlantedForest.",
          "link": "http://arxiv.org/abs/2012.14563",
          "publishedOn": "2023-08-05T00:48:26.641Z",
          "wordCount": null,
          "title": "Random Planted Forest: a directly interpretable tree ensemble. (arXiv:2012.14563v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01538",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhong_W/0/1/0/all/0/1\">Weishun Zhong</a>",
          "description": "Disordered many-body systems exhibit a wide range of emergent phenomena\nacross different scales. These complex behaviors can be utilized for various\ninformation processing tasks such as error correction, learning, and\noptimization. Despite the empirical success of utilizing these systems for\nintelligent tasks, the underlying principles that govern their emergent\nintelligent behaviors remain largely unknown. In this thesis, we aim to\ncharacterize such emergent intelligence in disordered systems through\nstatistical physics. We chart a roadmap for our efforts in this thesis based on\ntwo axes: learning mechanisms (long-term memory vs. working memory) and\nlearning dynamics (artificial vs. natural). Throughout our journey, we uncover\nrelationships between learning mechanisms and physical dynamics that could\nserve as guiding principles for designing intelligent systems. We hope that our\ninvestigation into the emergent intelligence of seemingly disparate learning\nsystems can expand our current understanding of intelligence beyond neural\nsystems and uncover a wider range of computational substrates suitable for AI\napplications.",
          "link": "http://arxiv.org/abs/2308.01538",
          "publishedOn": "2023-08-05T00:48:26.631Z",
          "wordCount": null,
          "title": "Non-equilibrium physics: from spin glasses to machine and neural learning. (arXiv:2308.01538v1 [cond-mat.dis-nn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.08904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1\">Maurice Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaojun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlas_B/0/1/0/all/0/1\">Bojan Karla&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Recent studies have shown that deep neural networks (DNNs) are vulnerable to\nadversarial attacks, including evasion and backdoor (poisoning) attacks. On the\ndefense side, there have been intensive efforts on improving both empirical and\nprovable robustness against evasion attacks; however, the provable robustness\nagainst backdoor attacks still remains largely unexplored. In this paper, we\nfocus on certifying the machine learning model robustness against general\nthreat models, especially backdoor attacks. We first provide a unified\nframework via randomized smoothing techniques and show how it can be\ninstantiated to certify the robustness against both evasion and backdoor\nattacks. We then propose the first robust training process, RAB, to smooth the\ntrained model and certify its robustness against backdoor attacks. We prove the\nrobustness bound for machine learning models trained with RAB and prove that\nour robustness bound is tight. In addition, we theoretically show that it is\npossible to train the robust smoothed models efficiently for simple models such\nas K-nearest neighbor classifiers, and we propose an exact smooth-training\nalgorithm that eliminates the need to sample from a noise distribution for such\nmodels. Empirically, we conduct comprehensive experiments for different machine\nlearning (ML) models such as DNNs, support vector machines, and K-NN models on\nMNIST, CIFAR-10, and ImageNette datasets and provide the first benchmark for\ncertified robustness against backdoor attacks. In addition, we evaluate K-NN\nmodels on a spambase tabular dataset to demonstrate the advantages of the\nproposed exact algorithm. Both the theoretic analysis and the comprehensive\nevaluation on diverse ML models and datasets shed light on further robust\nlearning strategies against general training time attacks.",
          "link": "http://arxiv.org/abs/2003.08904",
          "publishedOn": "2023-08-05T00:48:26.628Z",
          "wordCount": null,
          "title": "RAB: Provable Robustness Against Backdoor Attacks. (arXiv:2003.08904v8 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03395",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "As neural networks become more popular, the need for accompanying uncertainty\nestimates increases. There are currently two main approaches to test the\nquality of these estimates. Most methods output a density. They can be compared\nby evaluating their loglikelihood on a test set. Other methods output a\nprediction interval directly. These methods are often tested by examining the\nfraction of test points that fall inside the corresponding prediction\nintervals. Intuitively both approaches seem logical. However, we demonstrate\nthrough both theoretical arguments and simulations that both ways of evaluating\nthe quality of uncertainty estimates have serious flaws. Firstly, both\napproaches cannot disentangle the separate components that jointly create the\npredictive uncertainty, making it difficult to evaluate the quality of the\nestimates of these components. Secondly, a better loglikelihood does not\nguarantee better prediction intervals, which is what the methods are often used\nfor in practice. Moreover, the current approach to test prediction intervals\ndirectly has additional flaws. We show why it is fundamentally flawed to test a\nprediction or confidence interval on a single test set. At best, marginal\ncoverage is measured, implicitly averaging out overconfident and underconfident\npredictions. A much more desirable property is pointwise coverage, requiring\nthe correct coverage for each prediction. We demonstrate through practical\nexamples that these effects can result in favoring a method, based on the\npredictive uncertainty, that has undesirable behaviour of the confidence or\nprediction intervals. Finally, we propose a simulation-based testing approach\nthat addresses these problems while still allowing easy comparison between\ndifferent methods.",
          "link": "http://arxiv.org/abs/2106.03395",
          "publishedOn": "2023-08-05T00:48:26.621Z",
          "wordCount": null,
          "title": "How to Evaluate Uncertainty Estimates in Machine Learning for Regression?. (arXiv:2106.03395v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01605",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Doutreligne_M/0/1/0/all/0/1\">Matthieu Doutreligne</a> (SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Struja_T/0/1/0/all/0/1\">Tristan Struja</a> (MIT, SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Abecassis_J/0/1/0/all/0/1\">Judith Abecassis</a> (SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Morgand_C/0/1/0/all/0/1\">Claire Morgand</a> (ARS IDF), <a href=\"http://arxiv.org/find/stat/1/au:+Celi_L/0/1/0/all/0/1\">Leo Anthony Celi</a> (MIT), <a href=\"http://arxiv.org/find/stat/1/au:+Varoquaux_G/0/1/0/all/0/1\">Ga&#xeb;l Varoquaux</a> (SODA)",
          "description": "Accurate predictions, as with machine learning, may not suffice to provide\noptimal healthcare for every patient. Indeed, prediction can be driven by\nshortcuts in the data, such as racial biases. Causal thinking is needed for\ndata-driven decisions. Here, we give an introduction to the key elements,\nfocusing on routinely-collected data, electronic health records (EHRs) and\nclaims data. Using such data to assess the value of an intervention requires\ncare: temporal dependencies and existing practices easily confound the causal\neffect. We present a step-by-step framework to help build valid decision making\nfrom real-life patient records by emulating a randomized trial before\nindividualizing decisions, eg with machine learning. Our framework highlights\nthe most important pitfalls and considerations in analysing EHRs or claims data\nto draw causal conclusions. We illustrate the various choices in studying the\neffect of albumin on sepsis mortality in the Medical Information Mart for\nIntensive Care database (MIMIC-IV). We study the impact of various choices at\nevery step, from feature extraction to causal-estimator selection. In a\ntutorial spirit, the code and the data are openly available.",
          "link": "http://arxiv.org/abs/2308.01605",
          "publishedOn": "2023-08-05T00:48:26.442Z",
          "wordCount": null,
          "title": "Causal thinking for decision making on Electronic Health Records: why and how. (arXiv:2308.01605v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Philippenko_C/0/1/0/all/0/1\">Constantin Philippenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieuleveut_A/0/1/0/all/0/1\">Aymeric Dieuleveut</a>",
          "description": "In this paper, we investigate the impact of compression on stochastic\ngradient algorithms for machine learning, a technique widely used in\ndistributed and federated learning. We underline differences in terms of\nconvergence rates between several unbiased compression operators, that all\nsatisfy the same condition on their variance, thus going beyond the classical\nworst-case analysis. To do so, we focus on the case of least-squares regression\n(LSR) and analyze a general stochastic approximation algorithm for minimizing\nquadratic functions relying on a random field. We consider weak assumptions on\nthe random field, tailored to the analysis (specifically, expected H\\\"older\nregularity), and on the noise covariance, enabling the analysis of various\nrandomizing mechanisms, including compression. We then extend our results to\nthe case of federated learning.\n\nMore formally, we highlight the impact on the convergence of the covariance\n$\\mathfrak{C}_{\\mathrm{ania}}$ of the additive noise induced by the algorithm.\nWe demonstrate despite the non-regularity of the stochastic field, that the\nlimit variance term scales with $\\mathrm{Tr}(\\mathfrak{C}_{\\mathrm{ania}}\nH^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the\nnumber of iterations) generalizing the rate for the vanilla LSR case where it\nis $\\sigma^2 \\mathrm{Tr}(H H^{-1}) / K = \\sigma^2 d / K$ (Bach and Moulines,\n2013). Then, we analyze the dependency of $\\mathfrak{C}_{\\mathrm{ania}}$ on the\ncompression strategy and ultimately its impact on convergence, first in the\ncentralized case, then in two heterogeneous FL frameworks.",
          "link": "http://arxiv.org/abs/2308.01358",
          "publishedOn": "2023-08-05T00:48:26.424Z",
          "wordCount": null,
          "title": "Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning. (arXiv:2308.01358v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cindy Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "In recent years, multiple notions of algorithmic fairness have arisen. One\nsuch notion is individual fairness (IF), which requires that individuals who\nare similar receive similar treatment. In parallel, matrix estimation (ME) has\nemerged as a natural paradigm for handling noisy data with missing values. In\nthis work, we connect the two concepts. We show that pre-processing data using\nME can improve an algorithm's IF without sacrificing performance. Specifically,\nwe show that using a popular ME method known as singular value thresholding\n(SVT) to pre-process the data provides a strong IF guarantee under appropriate\nconditions. We then show that, under analogous conditions, SVT pre-processing\nalso yields estimates that are consistent and approximately minimax optimal. As\nsuch, the ME pre-processing step does not, under the stated conditions,\nincrease the prediction error of the base algorithm, i.e., does not impose a\nfairness-performance trade-off. We verify these results on synthetic and real\ndata.",
          "link": "http://arxiv.org/abs/2302.02096",
          "publishedOn": "2023-08-05T00:48:26.394Z",
          "wordCount": null,
          "title": "Matrix Estimation for Individual Fairness. (arXiv:2302.02096v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.09048",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Rolle_A/0/1/0/all/0/1\">Alexander Rolle</a>, <a href=\"http://arxiv.org/find/math/1/au:+Scoccola_L/0/1/0/all/0/1\">Luis Scoccola</a>",
          "description": "We consider the degree-Rips construction from topological data analysis,\nwhich provides a density-sensitive, multiparameter hierarchical clustering\nalgorithm. We analyze its stability to perturbations of the input data using\nthe correspondence-interleaving distance, a metric for hierarchical clusterings\nthat we introduce. Taking certain one-parameter slices of degree-Rips recovers\nwell-known methods for density-based clustering, but we show that these methods\nare unstable. However, we prove that degree-Rips, as a multiparameter object,\nis stable, and we propose an alternative approach for taking slices of\ndegree-Rips, which yields a one-parameter hierarchical clustering algorithm\nwith better stability properties. We prove that this algorithm is consistent,\nusing the correspondence-interleaving distance. We provide an algorithm for\nextracting a single clustering from one-parameter hierarchical clusterings,\nwhich is stable with respect to the correspondence-interleaving distance. And,\nwe integrate these methods into a pipeline for density-based clustering, which\nwe call Persistable. Adapting tools from multiparameter persistent homology, we\npropose visualization tools that guide the selection of all parameters of the\npipeline. We demonstrate Persistable on benchmark datasets, showing that it\nidentifies multi-scale cluster structure in data.",
          "link": "http://arxiv.org/abs/2005.09048",
          "publishedOn": "2023-08-05T00:48:26.364Z",
          "wordCount": null,
          "title": "Stable and consistent density-based clustering via multiparameter persistence. (arXiv:2005.09048v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01677",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Garber_D/0/1/0/all/0/1\">Dan Garber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kaplan_A/0/1/0/all/0/1\">Atara Kaplan</a>",
          "description": "We consider convex relaxations for recovering low-rank tensors based on\nconstrained minimization over a ball induced by the tensor nuclear norm,\nrecently introduced in \\cite{tensor_tSVD}. We build on a recent line of results\nthat considered convex relaxations for the recovery of low-rank matrices and\nestablished that under a strict complementarity condition (SC), both the\nconvergence rate and per-iteration runtime of standard gradient methods may\nimprove dramatically. We develop the appropriate strict complementarity\ncondition for the tensor nuclear norm ball and obtain the following main\nresults under this condition: 1. When the objective to minimize is of the form\n$f(\\mX)=g(\\mA\\mX)+\\langle{\\mC,\\mX}\\rangle$ , where $g$ is strongly convex and\n$\\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds,\nwhich implies linear convergence rates for standard projected gradient methods,\ndespite the fact that $f$ need not be strongly convex. 2. For a smooth\nobjective function, when initialized in certain proximity of an optimal\nsolution which satisfies SC, standard projected gradient methods only require\nSVD computations (for projecting onto the tensor nuclear norm ball) of rank\nthat matches the tubal rank of the optimal solution. In particular, when the\ntubal rank is constant, this implies nearly linear (in the size of the tensor)\nruntime per iteration, as opposed to super linear without further assumptions.\n3. For a nonsmooth objective function which admits a popular smooth\nsaddle-point formulation, we derive similar results to the latter for the well\nknown extragradient method. An additional contribution which may be of\nindependent interest, is the rigorous extension of many basic results regarding\ntensors of arbitrary order, which were previously obtained only for third-order\ntensors.",
          "link": "http://arxiv.org/abs/2308.01677",
          "publishedOn": "2023-08-05T00:48:26.322Z",
          "wordCount": null,
          "title": "Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity. (arXiv:2308.01677v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_W/0/1/0/all/0/1\">Waheed Ul Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Little_M/0/1/0/all/0/1\">Max A. Little</a>",
          "description": "Algorithms for solving the linear classification problem have a long history,\ndating back at least to 1936 with linear discriminant analysis. For linearly\nseparable data, many algorithms can obtain the exact solution to the\ncorresponding 0-1 loss classification problem efficiently, but for data which\nis not linearly separable, it has been shown that this problem, in full\ngenerality, is NP-hard. Alternative approaches all involve approximations of\nsome kind, including the use of surrogates for the 0-1 loss (for example, the\nhinge or logistic loss) or approximate combinatorial search, none of which can\nbe guaranteed to solve the problem exactly. Finding efficient algorithms to\nobtain an exact i.e. globally optimal solution for the 0-1 loss linear\nclassification problem with fixed dimension, remains an open problem. In\nresearch we report here, we detail the rigorous construction of a new\nalgorithm, incremental cell enumeration (ICE), that can solve the 0-1 loss\nclassification problem exactly in polynomial time. We prove correctness using\nconcepts from the theory of hyperplane arrangements and oriented matroids. We\ndemonstrate the effectiveness of this algorithm on synthetic and real-world\ndatasets, showing optimal accuracy both in and out-of-sample, in practical\ncomputational time. We also empirically demonstrate how the use of approximate\nupper bound leads to polynomial time run-time improvements to the algorithm\nwhilst retaining exactness. To our knowledge, this is the first,\nrigorously-proven polynomial time, practical algorithm for this long-standing\nproblem.",
          "link": "http://arxiv.org/abs/2306.12344",
          "publishedOn": "2023-08-05T00:48:26.321Z",
          "wordCount": null,
          "title": "An efficient, provably exact, practical algorithm for the 0-1 loss linear classification problem. (arXiv:2306.12344v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12465",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Diaz_M/0/1/0/all/0/1\">Mateo D&#xed;az</a>, <a href=\"http://arxiv.org/find/math/1/au:+Epperly_E/0/1/0/all/0/1\">Ethan N. Epperly</a>, <a href=\"http://arxiv.org/find/math/1/au:+Frangella_Z/0/1/0/all/0/1\">Zachary Frangella</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tropp_J/0/1/0/all/0/1\">Joel A. Tropp</a>, <a href=\"http://arxiv.org/find/math/1/au:+Webber_R/0/1/0/all/0/1\">Robert J. Webber</a>",
          "description": "This paper introduces two randomized preconditioning techniques for robustly\nsolving kernel ridge regression (KRR) problems with a medium to large number of\ndata points ($10^4 \\leq N \\leq 10^7$). The first method, RPCholesky\npreconditioning, is capable of accurately solving the full-data KRR problem in\n$O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of\nthe kernel matrix eigenvalues. The second method, KRILL preconditioning, offers\nan accurate solution to a restricted version of the KRR problem involving $k\n\\ll N$ selected data centers at a cost of $O((N + k^2) k \\log k)$ operations.\nThe proposed methods solve a broad range of KRR problems and overcome the\nfailure modes of previous KRR preconditioners, making them ideal for practical\napplications.",
          "link": "http://arxiv.org/abs/2304.12465",
          "publishedOn": "2023-08-05T00:48:25.211Z",
          "wordCount": 655,
          "title": "Robust, randomized preconditioning for kernel ridge regression. (arXiv:2304.12465v3 [math.NA] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01835",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tamas_A/0/1/0/all/0/1\">Ambrus Tam&#xe1;s</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Csaji_B/0/1/0/all/0/1\">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>",
          "description": "One of the key objects of binary classification is the regression function,\ni.e., the conditional expectation of the class labels given the inputs. With\nthe regression function not only a Bayes optimal classifier can be defined, but\nit also encodes the corresponding misclassification probabilities. The paper\npresents a resampling framework to construct exact, distribution-free and\nnon-asymptotically guaranteed confidence regions for the true regression\nfunction for any user-chosen confidence level. Then, specific algorithms are\nsuggested to demonstrate the framework. It is proved that the constructed\nconfidence regions are strongly consistent, that is, any false model is\nexcluded in the long run with probability one. The exclusion is quantified with\nprobably approximately correct type bounds, as well. Finally, the algorithms\nare validated via numerical experiments, and the methods are compared to\napproximate asymptotic confidence ellipsoids.",
          "link": "http://arxiv.org/abs/2308.01835",
          "publishedOn": "2023-08-05T00:48:25.203Z",
          "wordCount": 633,
          "title": "Distribution-Free Inference for the Regression Function of Binary Classification. (arXiv:2308.01835v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chao_P/0/1/0/all/0/1\">Patrick Chao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Distribution shifts are a serious concern in modern statistical learning as\nthey can systematically change the properties of the data away from the truth.\nWe focus on Wasserstein distribution shifts, where every data point may undergo\na slight perturbation, as opposed to the Huber contamination model where a\nfraction of observations are outliers. We formulate and study shifts beyond\nindependent perturbations, exploring Joint Distribution Shifts, where the\nper-observation perturbations can be coordinated. We analyze several important\nstatistical problems, including location estimation, linear regression, and\nnon-parametric density estimation. Under a squared loss for mean estimation and\nprediction error in linear regression, we find the exact minimax risk, a least\nfavorable perturbation, and show that the sample mean and least squares\nestimators are respectively optimal. This holds for both independent and joint\nshifts, but the least favorable perturbations and minimax risks differ. For\nother problems, we provide nearly optimal estimators and precise finite-sample\nbounds. We also introduce several tools for bounding the minimax risk under\ndistribution shift, such as a smoothing technique for location families, and\ngeneralizations of classical tools including least favorable sequences of\npriors, the modulus of continuity, Le Cam's, Fano's, and Assouad's methods.",
          "link": "http://arxiv.org/abs/2308.01853",
          "publishedOn": "2023-08-05T00:48:25.171Z",
          "wordCount": 706,
          "title": "Statistical Estimation Under Distribution Shift: Wasserstein Perturbations and Minimax Theory. (arXiv:2308.01853v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2012.05465",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qiu_H/0/1/0/all/0/1\">Hongxiang Qiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Luedtke_A/0/1/0/all/0/1\">Alex Luedtke</a>",
          "description": "Bayes estimators are well known to provide a means to incorporate prior\nknowledge that can be expressed in terms of a single prior distribution.\nHowever, when this knowledge is too vague to express with a single prior, an\nalternative approach is needed. Gamma-minimax estimators provide such an\napproach. These estimators minimize the worst-case Bayes risk over a set\n$\\Gamma$ of prior distributions that are compatible with the available\nknowledge. Traditionally, Gamma-minimaxity is defined for parametric models. In\nthis work, we define Gamma-minimax estimators for general models and propose\nadversarial meta-learning algorithms to compute them when the set of prior\ndistributions is constrained by generalized moments. Accompanying convergence\nguarantees are also provided. We also introduce a neural network class that\nprovides a rich, but finite-dimensional, class of estimators from which a\nGamma-minimax estimator can be selected. We illustrate our method in two\nsettings, namely entropy estimation and a prediction problem that arises in\nbiodiversity studies.",
          "link": "http://arxiv.org/abs/2012.05465",
          "publishedOn": "2023-08-05T00:48:25.144Z",
          "wordCount": 705,
          "title": "Adversarial Meta-Learning of Gamma-Minimax Estimators That Leverage Prior Knowledge. (arXiv:2012.05465v5 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01475",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Allen_G/0/1/0/all/0/1\">Genevera I. Allen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gan_L/0/1/0/all/0/1\">Luqin Gan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_L/0/1/0/all/0/1\">Lili Zheng</a>",
          "description": "New technologies have led to vast troves of large and complex datasets across\nmany scientific domains and industries. People routinely use machine learning\ntechniques to not only process, visualize, and make predictions from this big\ndata, but also to make data-driven discoveries. These discoveries are often\nmade using Interpretable Machine Learning, or machine learning models and\ntechniques that yield human understandable insights. In this paper, we discuss\nand review the field of interpretable machine learning, focusing especially on\nthe techniques as they are often employed to generate new knowledge or make\ndiscoveries from large data sets. We outline the types of discoveries that can\nbe made using Interpretable Machine Learning in both supervised and\nunsupervised settings. Additionally, we focus on the grand challenge of how to\nvalidate these discoveries in a data-driven manner, which promotes trust in\nmachine learning systems and reproducibility in science. We discuss validation\nfrom both a practical perspective, reviewing approaches based on data-splitting\nand stability, as well as from a theoretical perspective, reviewing statistical\nresults on model selection consistency and uncertainty quantification via\nstatistical inference. Finally, we conclude by highlighting open challenges in\nusing interpretable machine learning techniques to make discoveries, including\ngaps between theory and practice for validating data-driven-discoveries.",
          "link": "http://arxiv.org/abs/2308.01475",
          "publishedOn": "2023-08-05T00:48:25.117Z",
          "wordCount": 709,
          "title": "Interpretable Machine Learning for Discovery: Statistical Challenges \\& Opportunities. (arXiv:2308.01475v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.10903",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "With the rise of the popularity and usage of neural networks, trustworthy\nuncertainty estimation is becoming increasingly essential. One of the most\nprominent uncertainty estimation methods is Deep Ensembles (Lakshminarayanan et\nal., 2017) . A classical parametric model has uncertainty in the parameters due\nto the fact that the data on which the model is build is a random sample. A\nmodern neural network has an additional uncertainty component since the\noptimization of the network is random. Lakshminarayanan et al. (2017) noted\nthat Deep Ensembles do not incorporate the classical uncertainty induced by the\neffect of finite data. In this paper, we present a computationally cheap\nextension of Deep Ensembles for the regression setting, called Bootstrapped\nDeep Ensembles, that explicitly takes this classical effect of finite data into\naccount using a modified version of the parametric bootstrap. We demonstrate\nthrough an experimental study that our method significantly improves upon\nstandard Deep Ensembles",
          "link": "http://arxiv.org/abs/2202.10903",
          "publishedOn": "2023-08-05T00:48:25.108Z",
          "wordCount": 674,
          "title": "Confident Neural Network Regression with Bootstrapped Deep Ensembles. (arXiv:2202.10903v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sakhi_O/0/1/0/all/0/1\">Otmane Sakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohde_D/0/1/0/all/0/1\">David Rohde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chopin_N/0/1/0/all/0/1\">Nicolas Chopin</a>",
          "description": "An increasingly important building block of large scale machine learning\nsystems is based on returning slates; an ordered lists of items given a query.\nApplications of this technology include: search, information retrieval and\nrecommender systems. When the action space is large, decision systems are\nrestricted to a particular structure to complete online queries quickly. This\npaper addresses the optimization of these large scale decision systems given an\narbitrary reward function. We cast this learning problem in a policy\noptimization framework and propose a new class of policies, born from a novel\nrelaxation of decision functions. This results in a simple, yet efficient\nlearning algorithm that scales to massive action spaces. We compare our method\nto the commonly adopted Plackett-Luce policy class and demonstrate the\neffectiveness of our approach on problems with action space sizes in the order\nof millions.",
          "link": "http://arxiv.org/abs/2308.01566",
          "publishedOn": "2023-08-05T00:48:24.864Z",
          "wordCount": 645,
          "title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce. (arXiv:2308.01566v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_A/0/1/0/all/0/1\">Agnimitra Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1\">Sudeepta Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Adway Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_S/0/1/0/all/0/1\">S. Ilgin Guler</a>",
          "description": "Deep-learning models for traffic data prediction can have superior\nperformance in modeling complex functions using a multi-layer architecture.\nHowever, a major drawback of these approaches is that most of these approaches\ndo not offer forecasts with uncertainty estimates, which are essential for\ntraffic operations and control. Without uncertainty estimates, it is difficult\nto place any level of trust to the model predictions, and operational\nstrategies relying on overconfident predictions can lead to worsening traffic\nconditions. In this study, we propose a Bayesian recurrent neural network\nframework for uncertainty quantification in traffic prediction with higher\ngeneralizability by introducing spectral normalization to its hidden layers. In\nour paper, we have shown that normalization alters the training process of deep\nneural networks by controlling the model's complexity and reducing the risk of\noverfitting to the training data. This, in turn, helps improve the\ngeneralization performance of the model on out-of-distribution datasets.\nResults demonstrate that spectral normalization improves uncertainty estimates\nand significantly outperforms both the layer normalization and model without\nnormalization in single-step prediction horizons. This improved performance can\nbe attributed to the ability of spectral normalization to better localize the\nfeature space of the data under perturbations. Our findings are especially\nrelevant to traffic management applications, where predicting traffic\nconditions across multiple locations is the goal, but the availability of\ntraining data from multiple locations is limited. Spectral normalization,\ntherefore, provides a more generalizable approach that can effectively capture\nthe underlying patterns in traffic data without requiring location-specific\nmodels.",
          "link": "http://arxiv.org/abs/2307.05946",
          "publishedOn": "2023-07-29T00:48:57.359Z",
          "wordCount": null,
          "title": "A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models. (arXiv:2307.05946v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Erp_B/0/1/0/all/0/1\">Bart van Erp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nuijten_W/0/1/0/all/0/1\">Wouter W. L. Nuijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laar_T/0/1/0/all/0/1\">Thijs van de Laar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_B/0/1/0/all/0/1\">Bert de Vries</a>",
          "description": "Bayesian state and parameter estimation have been automated effectively in a\nvariety of probabilistic programming languages. The process of model comparison\non the other hand, which still requires error-prone and time-consuming manual\nderivations, is often overlooked despite its importance. This paper efficiently\nautomates Bayesian model averaging, selection, and combination by message\npassing on a Forney-style factor graph with a custom mixture node. Parameter\nand state inference, and model comparison can then be executed simultaneously\nusing message passing with scale factors. This approach shortens the model\ndesign cycle and allows for the straightforward extension to hierarchical and\ntemporal model priors to accommodate for modeling complicated time-varying\nprocesses.",
          "link": "http://arxiv.org/abs/2306.05965",
          "publishedOn": "2023-07-29T00:48:57.333Z",
          "wordCount": null,
          "title": "Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.10291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Derezinski_M/0/1/0/all/0/1\">Micha&#x142; Derezi&#x144;ski</a>",
          "description": "Algorithmic Gaussianization is a phenomenon that can arise when using\nrandomized sketching or sampling methods to produce smaller representations of\nlarge datasets: For certain tasks, these sketched representations have been\nobserved to exhibit many robust performance characteristics that are known to\noccur when a data sample comes from a sub-gaussian random design, which is a\npowerful statistical model of data distributions. However, this phenomenon has\nonly been studied for specific tasks and metrics, or by relying on\ncomputationally expensive methods. We address this by providing an algorithmic\nframework for gaussianizing data distributions via averaging, proving that it\nis possible to efficiently construct data sketches that are nearly\nindistinguishable (in terms of total variation distance) from sub-gaussian\nrandom designs. In particular, relying on a recently introduced sketching\ntechnique called Leverage Score Sparsified (LESS) embeddings, we show that one\ncan construct an $n\\times d$ sketch of an $N\\times d$ matrix $A$, where $n\\ll\nN$, that is nearly indistinguishable from a sub-gaussian design, in time\n$O(\\text{nnz}(A)\\log N + nd^2)$, where $\\text{nnz}(A)$ is the number of\nnon-zero entries in $A$. As a consequence, strong statistical guarantees and\nprecise asymptotics available for the estimators produced from sub-gaussian\ndesigns (e.g., for least squares and Lasso regression, covariance estimation,\nlow-rank approximation, etc.) can be straightforwardly adapted to our sketching\nframework. We illustrate this with a new approximation guarantee for sketched\nleast squares, among other examples.",
          "link": "http://arxiv.org/abs/2206.10291",
          "publishedOn": "2023-07-29T00:48:55.771Z",
          "wordCount": 761,
          "title": "Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs. (arXiv:2206.10291v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.12942",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sainsbury_Dale_M/0/1/0/all/0/1\">Matthew Sainsbury-Dale</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zammit_Mangion_A/0/1/0/all/0/1\">Andrew Zammit-Mangion</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huser_R/0/1/0/all/0/1\">Rapha&#xeb;l Huser</a>",
          "description": "Neural point estimators are neural networks that map data to parameter point\nestimates. They are fast, likelihood free and, due to their amortised nature,\namenable to fast bootstrap-based uncertainty quantification. In this paper, we\naim to increase the awareness of statisticians to this relatively new\ninferential tool, and to facilitate its adoption by providing user-friendly\nopen-source software. We also give attention to the ubiquitous problem of\nmaking inference from replicated data, which we address in the neural setting\nusing permutation-invariant neural networks. Through extensive simulation\nstudies we show that these neural point estimators can quickly and optimally\n(in a Bayes sense) estimate parameters in weakly-identified and\nhighly-parameterised models with relative ease. We demonstrate their\napplicability through an analysis of extreme sea-surface temperature in the Red\nSea where, after training, we obtain parameter estimates and bootstrap-based\nconfidence intervals from hundreds of spatial fields in a fraction of a second.",
          "link": "http://arxiv.org/abs/2208.12942",
          "publishedOn": "2023-07-29T00:48:55.765Z",
          "wordCount": 676,
          "title": "Likelihood-Free Parameter Estimation with Neural Bayes Estimators. (arXiv:2208.12942v4 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2005.00695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyang R. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1\">Gregory Valiant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>",
          "description": "Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations that preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations that mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms random sampling methods by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2005.00695",
          "publishedOn": "2023-07-29T00:48:55.758Z",
          "wordCount": 743,
          "title": "On the Generalization Effects of Linear Transformations in Data Augmentation. (arXiv:2005.00695v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14839",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+English_E/0/1/0/all/0/1\">Eshant English</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kirchler_M/0/1/0/all/0/1\">Matthias Kirchler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lippert_C/0/1/0/all/0/1\">Christoph Lippert</a>",
          "description": "Normalising Flows are generative models characterised by their invertible\narchitecture. However, the requirement of invertibility imposes constraints on\ntheir expressiveness, necessitating a large number of parameters and innovative\narchitectural designs to achieve satisfactory outcomes. Whilst flow-based\nmodels predominantly rely on neural-network-based transformations for\nexpressive designs, alternative transformation methods have received limited\nattention. In this work, we present Ferumal flow, a novel kernelised\nnormalising flow paradigm that integrates kernels into the framework. Our\nresults demonstrate that a kernelised flow can yield competitive or superior\nresults compared to neural network-based flows whilst maintaining parameter\nefficiency. Kernelised flows excel especially in the low-data regime, enabling\nflexible non-parametric density estimation in applications with sparse data\navailability.",
          "link": "http://arxiv.org/abs/2307.14839",
          "publishedOn": "2023-07-29T00:48:55.734Z",
          "wordCount": 591,
          "title": "Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims\nto mitigate data distribution shifts when transferring knowledge from multiple\nlabeled source domains to an unlabeled target domain. We propose a novel MSDA\nframework based on dictionary learning and optimal transport. We interpret each\ndomain in MSDA as an empirical distribution. As such, we express each domain as\na Wasserstein barycenter of dictionary atoms, which are empirical\ndistributions. We propose a novel algorithm, DaDiL, for learning via\nmini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.\nBased on our dictionary, we propose two novel methods for MSDA: DaDil-R, based\non the reconstruction of labeled samples in the target domain, and DaDiL-E,\nbased on the ensembling of classifiers learned on atom distributions. We\nevaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU,\nwhere we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in\nclassification performance. Finally, we show that interpolations in the\nWasserstein hull of learned atoms provide data that can generalize to the\ntarget domain.",
          "link": "http://arxiv.org/abs/2307.14953",
          "publishedOn": "2023-07-29T00:48:55.728Z",
          "wordCount": 710,
          "title": "Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14642",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_K/0/1/0/all/0/1\">Kyurae Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yian Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "We prove that black-box variational inference (BBVI) with control variates,\nparticularly the sticking-the-landing (STL) estimator, converges at a geometric\n(traditionally called \"linear\") rate under perfect variational family\nspecification. In particular, we prove a quadratic bound on the gradient\nvariance of the STL estimator, one which encompasses misspecified variational\nfamilies. Combined with previous works on the quadratic variance condition,\nthis directly implies convergence of BBVI with the use of projected stochastic\ngradient descent. We also improve existing analysis on the regular closed-form\nentropy gradient estimators, which enables comparison against the STL estimator\nand provides explicit non-asymptotic complexity guarantees for both.",
          "link": "http://arxiv.org/abs/2307.14642",
          "publishedOn": "2023-07-29T00:48:55.721Z",
          "wordCount": 606,
          "title": "Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.01198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1\">Leonardo Cotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1\">Beatrice Bevilacqua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nesreen Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>",
          "description": "Existing causal models for link prediction assume an underlying set of\ninherent node factors -- an innate characteristic defined at the node's birth\n-- that governs the causal evolution of links in the graph. In some causal\ntasks, however, link formation is path-dependent: The outcome of link\ninterventions depends on existing links. Unfortunately, these existing causal\nmethods are not designed for path-dependent link formation, as the cascading\nfunctional dependencies between links (arising from path dependence) are either\nunidentifiable or require an impractical number of control variables. To\novercome this, we develop the first causal model capable of dealing with path\ndependencies in link prediction. In this work we introduce the concept of\ncausal lifting, an invariance in causal models of independent interest that, on\ngraphs, allows the identification of causal link prediction queries using\nlimited interventional data. Further, we show how structural pairwise\nembeddings exhibit lower bias and correctly represent the task's causal\nstructure, as opposed to existing node embeddings, e.g., graph neural network\nnode embeddings and matrix factorization. Finally, we validate our theoretical\nfindings on three scenarios for causal link prediction tasks: knowledge base\ncompletion, covariance matrix estimation and consumer-product recommendations.",
          "link": "http://arxiv.org/abs/2302.01198",
          "publishedOn": "2023-07-29T00:48:55.714Z",
          "wordCount": 715,
          "title": "Causal Lifting and Link Prediction. (arXiv:2302.01198v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.07436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Malinovskaya_A/0/1/0/all/0/1\">Anna Malinovskaya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Otto_P/0/1/0/all/0/1\">Philipp Otto</a>",
          "description": "The rapid advancement of models based on artificial intelligence demands\ninnovative monitoring techniques which can operate in real time with low\ncomputational costs. In machine learning, especially if we consider artificial\nneural networks (ANNs), the models are often trained in a supervised manner.\nConsequently, the learned relationship between the input and the output must\nremain valid during the model's deployment. If this stationarity assumption\nholds, we can conclude that the ANN provides accurate predictions. Otherwise,\nthe retraining or rebuilding of the model is required. We propose considering\nthe latent feature representation of the data (called \"embedding\") generated by\nthe ANN to determine the time when the data stream starts being nonstationary.\nIn particular, we monitor embeddings by applying multivariate control charts\nbased on the data depth calculation and normalized ranks. The performance of\nthe introduced method is compared with benchmark approaches for various ANN\narchitectures and different underlying data formats.",
          "link": "http://arxiv.org/abs/2209.07436",
          "publishedOn": "2023-07-29T00:48:55.696Z",
          "wordCount": 683,
          "title": "Statistical process monitoring of artificial neural networks. (arXiv:2209.07436v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Block_A/0/1/0/all/0/1\">Adam Block</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfrommer_D/0/1/0/all/0/1\">Daniel Pfrommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>",
          "description": "We propose a theoretical framework for studying the imitation of stochastic,\nnon-Markovian, potentially multi-modal (i.e. \"complex\" ) expert demonstrations\nin nonlinear dynamical systems. Our framework invokes low-level controllers -\neither learned or implicit in position-command control - to stabilize imitation\npolicies around expert demonstrations. We show that with (a) a suitable\nlow-level stability guarantee and (b) a stochastic continuity property of the\nlearned policy we call \"total variation continuity\" (TVC), an imitator that\naccurately estimates actions on the demonstrator's state distribution closely\nmatches the demonstrator's distribution over entire trajectories. We then show\nthat TVC can be ensured with minimal degradation of accuracy by combining a\npopular data-augmentation regimen with a novel algorithmic trick: adding\naugmentation noise at execution time. We instantiate our guarantees for\npolicies parameterized by diffusion models and prove that if the learner\naccurately estimates the score of the (noise-augmented) expert policy, then the\ndistribution of imitator trajectories is close to the demonstrator distribution\nin a natural optimal transport distance. Our analysis constructs intricate\ncouplings between noise-augmented trajectories, a technique that may be of\nindependent interest. We conclude by empirically validating our algorithmic\nrecommendations.",
          "link": "http://arxiv.org/abs/2307.14619",
          "publishedOn": "2023-07-29T00:48:55.688Z",
          "wordCount": 700,
          "title": "Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14653",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1\">Inbar Seroussi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alemi_A/0/1/0/all/0/1\">Alexander A. Alemi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Helias_M/0/1/0/all/0/1\">Moritz Helias</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1\">Zohar Ringel</a>",
          "description": "State-of-the-art neural networks require extreme computational power to\ntrain. It is therefore natural to wonder whether they are optimally trained.\nHere we apply a recent advancement in stochastic thermodynamics which allows\nbounding the speed at which one can go from the initial weight distribution to\nthe final distribution of the fully trained network, based on the ratio of\ntheir Wasserstein-2 distance and the entropy production rate of the dynamical\nprocess connecting them. Considering both gradient-flow and Langevin training\ndynamics, we provide analytical expressions for these speed limits for linear\nand linearizable neural networks e.g. Neural Tangent Kernel (NTK). Remarkably,\ngiven some plausible scaling assumptions on the NTK spectra and spectral\ndecomposition of the labels -- learning is optimal in a scaling sense. Our\nresults are consistent with small-scale experiments with Convolutional Neural\nNetworks (CNNs) and Fully Connected Neural networks (FCNs) on CIFAR-10, showing\na short highly non-optimal regime followed by a longer optimal regime.",
          "link": "http://arxiv.org/abs/2307.14653",
          "publishedOn": "2023-07-29T00:48:55.680Z",
          "wordCount": 642,
          "title": "Speed Limits for Deep Learning. (arXiv:2307.14653v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.05776",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_S/0/1/0/all/0/1\">Sidi Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beaulac_C/0/1/0/all/0/1\">C&#xe9;dric Beaulac</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cao_J/0/1/0/all/0/1\">Jiguo Cao</a>",
          "description": "The regression of a functional response on a set of scalar predictors can be\na challenging task, especially if there is a large number of predictors, or the\nrelationship between those predictors and the response is nonlinear. In this\nwork, we propose a solution to this problem: a feed-forward neural network (NN)\ndesigned to predict a functional response using scalar inputs. First, we\ntransform the functional response to a finite-dimensional representation and\nconstruct an NN that outputs this representation. Then, we propose to modify\nthe output of an NN via the objective function and introduce different\nobjective functions for network training. The proposed models are suited for\nboth regularly and irregularly spaced data, and a roughness penalty can be\nfurther applied to control the smoothness of the predicted curve. The\ndifficulty in implementing both those features lies in the definition of\nobjective functions that can be back-propagated. In our experiments, we\ndemonstrate that our model outperforms the conventional function-on-scalar\nregression model in multiple scenarios while computationally scaling better\nwith the dimension of the predictors.",
          "link": "http://arxiv.org/abs/2208.05776",
          "publishedOn": "2023-07-29T00:48:55.673Z",
          "wordCount": 693,
          "title": "Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.02060",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stone_I/0/1/0/all/0/1\">Iris R. Stone</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sagiv_Y/0/1/0/all/0/1\">Yotam Sagiv</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_I/0/1/0/all/0/1\">Il Memming Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillow_J/0/1/0/all/0/1\">Jonathan W. Pillow</a>",
          "description": "Latent linear dynamical systems with Bernoulli observations provide a\npowerful modeling framework for identifying the temporal dynamics underlying\nbinary time series data, which arise in a variety of contexts such as binary\ndecision-making and discrete stochastic processes (e.g., binned neural spike\ntrains). Here we develop a spectral learning method for fast, efficient fitting\nof probit-Bernoulli latent linear dynamical system (LDS) models. Our approach\nextends traditional subspace identification methods to the Bernoulli setting\nvia a transformation of the first and second sample moments. This results in a\nrobust, fixed-cost estimator that avoids the hazards of local optima and the\nlong computation time of iterative fitting procedures like the\nexpectation-maximization (EM) algorithm. In regimes where data is limited or\nassumptions about the statistical structure of the data are not met, we\ndemonstrate that the spectral estimate provides a good initialization for\nLaplace-EM fitting. Finally, we show that the estimator provides substantial\nbenefits to real world settings by analyzing data from mice performing a\nsensory decision-making task.",
          "link": "http://arxiv.org/abs/2303.02060",
          "publishedOn": "2023-07-29T00:48:55.665Z",
          "wordCount": 707,
          "title": "Spectral learning of Bernoulli linear dynamical systems models. (arXiv:2303.02060v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.13813",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Busbridge_D/0/1/0/all/0/1\">Dan Busbridge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramapuram_J/0/1/0/all/0/1\">Jason Ramapuram</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1\">Pierre Ablin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dhekane_E/0/1/0/all/0/1\">Eeshan Gunesh Dhekane</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suau_X/0/1/0/all/0/1\">Xavier Suau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_R/0/1/0/all/0/1\">Russ Webb</a>",
          "description": "Preserving training dynamics across batch sizes is an important tool for\npractical machine learning as it enables the trade-off between batch size and\nwall-clock time. This trade-off is typically enabled by a scaling rule, for\nexample, in stochastic gradient descent, one should scale the learning rate\nlinearly with the batch size. Another important tool for practical machine\nlearning is the model Exponential Moving Average (EMA), which is a model copy\nthat does not receive gradient information, but instead follows its target\nmodel with some momentum. This model EMA can improve the robustness and\ngeneralization properties of supervised learning, stabilize pseudo-labeling,\nand provide a learning signal for Self-Supervised Learning (SSL). Prior works\nhave treated the model EMA separately from optimization, leading to different\ntraining dynamics across batch sizes and lower model performance. In this work,\nwe provide a scaling rule for optimization in the presence of model EMAs and\ndemonstrate its validity across a range of architectures, optimizers, and data\nmodalities. We also show the rule's validity where the model EMA contributes to\nthe optimization of the target model, enabling us to train EMA-based\npseudo-labeling and SSL methods at small and large batch sizes. For SSL, we\nenable training of BYOL up to batch size 24,576 without sacrificing\nperformance, optimally a 6$\\times$ wall-clock time reduction.",
          "link": "http://arxiv.org/abs/2307.13813",
          "publishedOn": "2023-07-29T00:48:55.657Z",
          "wordCount": 739,
          "title": "How to Scale Your EMA. (arXiv:2307.13813v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2103.01280",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Viviano_D/0/1/0/all/0/1\">Davide Viviano</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Bradic_J/0/1/0/all/0/1\">Jelena Bradic</a>",
          "description": "This paper studies the estimation and inference of treatment histories in\npanel data settings when treatments change dynamically over time.\n\nWe propose a method that allows for (i) treatments to be assigned dynamically\nover time based on high-dimensional covariates, past outcomes and treatments;\n(ii) outcomes and time-varying covariates to depend on treatment trajectories;\n(iii) heterogeneity of treatment effects.\n\nOur approach recursively projects potential outcomes' expectations on past\nhistories. It then controls the bias by balancing dynamically observable\ncharacteristics. We study the asymptotic and numerical properties of the\nestimator and illustrate the benefits of the procedure in an empirical\napplication.",
          "link": "http://arxiv.org/abs/2103.01280",
          "publishedOn": "2023-07-29T00:48:55.618Z",
          "wordCount": 647,
          "title": "Dynamic covariate balancing: estimating treatment effects over time with potential local projections. (arXiv:2103.01280v3 [econ.EM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14530",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Community detection is one of the most critical problems in modern network\nscience. Its applications can be found in various fields, from protein modeling\nto social network analysis. Recently, many papers appeared studying the problem\nof overlapping community detection, where each node of a network may belong to\nseveral communities. In this work, we consider Mixed-Membership Stochastic\nBlock Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite\na general setting for modeling overlapping community structure in graphs. The\ncentral question of this paper is to reconstruct relations between communities\ngiven an observed network. We compare different approaches and establish the\nminimax lower bound on the estimation error. Then, we propose a new estimator\nthat matches this lower bound. Theoretical results are proved under fairly\ngeneral conditions on the considered model. Finally, we illustrate the theory\nin a series of experiments.",
          "link": "http://arxiv.org/abs/2307.14530",
          "publishedOn": "2023-07-29T00:48:55.610Z",
          "wordCount": 639,
          "title": "Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharir_O/0/1/0/all/0/1\">Or Sharir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Deep learning often faces the challenge of efficiently processing dynamic\ninputs, such as sensor data or user inputs. For example, an AI writing\nassistant is required to update its suggestions in real time as a document is\nedited. Re-running the model each time is expensive, even with compression\ntechniques like knowledge distillation, pruning, or quantization. Instead, we\ntake an incremental computing approach, looking to reuse calculations as the\ninputs change. However, the dense connectivity of conventional architectures\nposes a major obstacle to incremental computation, as even minor input changes\ncascade through the network and restrict information reuse. To address this, we\nuse vector quantization to discretize intermediate values in the network, which\nfilters out noisy and unnecessary modifications to hidden neurons, facilitating\nthe reuse of their values. We apply this approach to the transformers\narchitecture, creating an efficient incremental inference algorithm with\ncomplexity proportional to the fraction of the modified inputs. Our experiments\nwith adapting the OPT-125M pre-trained language model demonstrate comparable\naccuracy on document classification while requiring 12.1X (median) fewer\noperations for processing sequences of atomic edits.",
          "link": "http://arxiv.org/abs/2307.14988",
          "publishedOn": "2023-07-29T00:48:55.587Z",
          "wordCount": 687,
          "title": "Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs. (arXiv:2307.14988v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wrirj/p_recommendation_very_low_memory_text_tags/",
          "author": null,
          "description": "Input Data: I'm working on a project where I will need about 100 _separate_ indexes, each containing a maximum of 1,000,000 documents to be stored. Up to 30k documents would be added/deleted each day, to each index. (This is an absolute max that I don't expect to hit often. At the high end, I expect the average to be 10k, per index.)\n At the very least, I would like to store document text titles (about 10-25 words), short text descriptions (about 8-12 sentences), along with about 50 fields of scalar values (ie: tags. eg: this document's \"content_tags\" field includes \"has_author\" and \"has_chart\").\n Most of the scalar fields will have 100-500 possible value types, while one may have ~100,000 possible value types. However, each of a document's 50 scalar fields will usually have between 0-30 v…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wrirj/p_recommendation_very_low_memory_text_tags/",
          "publishedOn": "2023-08-21T00:10:51.000Z",
          "wordCount": null,
          "title": "[P] Recommendation? Very Low Memory, Text + Tags Similarity Search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wonms/d_how_many_times_you_try_for_acceptance_in_ai/",
          "author": null,
          "description": "ICML 2023 was my first trial. I've got polarized scores, 7/6/4/3, and got rejected. At this moment, I was so disappointed not for the result, but for the quality of review. (The last reviewer didn't read the paper at all.) For the final decision, the last review was so bad as well, not presenting any reason of rejection.\n With the same topic, I god 6/5/5/4/4/3 from the NeurIPS 2023. The quality of reviewer is much better than ICML, and I've learned many things from the reviewer, though they said the score will not be changed.\n I think I should submit it to another conference again, ICLR or CVPR. I just wonder how many submissions are tried for the acceptance in average. Just for reference.\n    submitted by    /u/Shot-Button-9010  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wonms/d_how_many_times_you_try_for_acceptance_in_ai/",
          "publishedOn": "2023-08-20T22:10:19.000Z",
          "wordCount": null,
          "title": "[D] How many times you try for acceptance in AI conference?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wm40r/r_researchers_at_deepmind_show_that_increases_in/",
          "author": null,
          "description": "submitted by    /u/moschles  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wm40r/r_researchers_at_deepmind_show_that_increases_in/",
          "publishedOn": "2023-08-20T20:33:22.000Z",
          "wordCount": null,
          "title": "[R] Researchers at Deepmind show that increases in the parameter count of an LLM do not incrementally reduce sychophancy , but actually increases it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wm0d5/d_anyone_knows_a_place_to_look_for_remote_work/",
          "author": null,
          "description": "I think I'm at a good level to start looking for a job, worked with MediaPipe, Object detection, Image processing, normal ML, and Deep Learning. I also have a couple of good projects under my name. So, I want to start a gig working remotely because work in my country is almost non-existent for this field. What are the good websites?\n    submitted by    /u/throwaway9_932123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wm0d5/d_anyone_knows_a_place_to_look_for_remote_work/",
          "publishedOn": "2023-08-20T20:29:34.000Z",
          "wordCount": null,
          "title": "[D] Anyone knows a place to look for remote work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wlkr1/r_ml_visualization/",
          "author": null,
          "description": "Hello, something I've always been curious about is machine learning. I keep seeing these videos of people teaching ai how to play table tennis of using a sigmoid function to fit a curve. My question is, what are these YouTubers using to visualize this??? I've heard of tensor flow but you can't visualize your own algorithms that's more of a plug n play. Plus it doesn't look as cool as what i see on YouTube. Any ideas? Any libraries? Thank you in advance!\n    submitted by    /u/itwela  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wlkr1/r_ml_visualization/",
          "publishedOn": "2023-08-20T20:12:06.000Z",
          "wordCount": null,
          "title": "[R] ML Visualization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wh7r6/d_do_lstm_actually_work_at_timeseries_forcasting/",
          "author": null,
          "description": "I'm a beginner at neural networks and recently tried out LSTM for time series. It seems like it generally underperforms on simple univariate time series because it does not take into account the changes in dynamics that naturally occur. In case there are no (or really few) unpredictable dynamics, then there is just no need to use complex neural networks to predict the future values.\n My question is: according to your experience do LSTM models make sense in time series forcasting?\n    submitted by    /u/McheleNaKinyesi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wh7r6/d_do_lstm_actually_work_at_timeseries_forcasting/",
          "publishedOn": "2023-08-20T17:22:18.000Z",
          "wordCount": null,
          "title": "[D] Do LSTM actually work at time-series forcasting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wgafs/r_autogen_enabling_nextgen_llm_applications_via/",
          "author": null,
          "description": "submitted by    /u/greentea387  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wgafs/r_autogen_enabling_nextgen_llm_applications_via/",
          "publishedOn": "2023-08-20T16:46:04.000Z",
          "wordCount": null,
          "title": "[R] AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15we23q/r_p_visitbench_a_benchmark_for_visionlanguage/",
          "author": null,
          "description": "Introducing VisIT-Bench, a benchmark for instruction-following vision-language models inspired by real-world use. Aiming for better multimodal chatbot evaluation with an automated ranking system.\n arxiv.org/abs/2308.06595 \n https://preview.redd.it/b3ycqf0u7ajb1.png?width=1791&format=png&auto=webp&s=573afb87e1068e7cd7cc6f6f473a4e1fa88f9baf\n Why VisIT-Bench ? Recent V&L models are getting better at instruction following, yet their evaluation for real-world human-chatbot instructions is often limited. VisIT-Bench aims to bridge this gap.\n VisIT-Bench comprises 678 examples. Each includes an image(s), instruction, an \"instruction-conditioned caption\", a caption for text-only understanding, a GPT-4 suggestion, and a label. These elements aid in evaluating multimodal chatbots and updating a lead…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15we23q/r_p_visitbench_a_benchmark_for_visionlanguage/",
          "publishedOn": "2023-08-20T15:16:32.000Z",
          "wordCount": null,
          "title": "[R] [P] VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wdhmc/p_fast_cv_app_cross_platform_computer_vision/",
          "author": null,
          "description": "Why is this relevant to machine learning?\n My project shows that you can do computer vision on Windows and Mac using only Python. I have even produced .exe and .app files with PyInstaller. One huge problem with things in the machine learning space is that machine learning is slow, especially when it comes to real-time pose estimation. I myself had to cheat for 30fps real-time pose estimation in two ways:\n  \nThe first way is that I use opencv/ffmpeg to read the future frames to prep them for display. This is because pose estimation libraries like Mediapipe are just slow, 9-15ms per frame! Even a basic example using opencv to use mediapipe on cameraframes was 20-25 fps at best on my older pc. The only reason it keeps up is because mediapipe itself is trained to drop frames to keep your video…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wdhmc/p_fast_cv_app_cross_platform_computer_vision/",
          "publishedOn": "2023-08-20T14:54:01.000Z",
          "wordCount": null,
          "title": "[P] Fast CV App: Cross Platform Computer Vision Using Multiprocessing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wc9ph/pi_built_a_gptlike_chatbot/",
          "author": null,
          "description": "I am a 12th grade student in turkey. I think I have knowledge and ability in programming especially in ai. At the end of 3 months, I built an artificial intelligence chatbot and finished the project. Currently it only works on my localhost. While doing it, I rented Cloud storage for 20 TB of data and A100 80 GB 50 hour GPU. He is now able to give correct answers and have conversations. I think it's at a level between GPT2 - GPT 3. Since I did it alone, I couldn't develop it much and I didn't use any pretrained models, I made it from the smallest level using modules such as pytorch. The reason I'm writing this here is because I don't know how to proceed after this stage and I need help. For example, are there any competitions on this subject? Or if I e-mail important people, universities, companies or something, will they guide me or give me a scholarship or something? This is the least likely. But I think it wouldn't hurt to try. I'm curious about your ideas.\n    submitted by    /u/Eastern-Ad1067  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wc9ph/pi_built_a_gptlike_chatbot/",
          "publishedOn": "2023-08-20T14:03:33.000Z",
          "wordCount": null,
          "title": "[p]I built a gpt-like chatbot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15wax8x/p_tensor_trust_a_web_game_to_collect_adversarial/",
          "author": null,
          "description": "Hi folks, our lab has been working on a web game to collect human-interpretable adversarial examples for LLMs:\n https://banking.withai.lol/\n Premise: you have a \"bank account\" with the Tensor Trust. It is protected by a secret access code and a set of security instructions. You can gain money by convincing an LLM to ignore other players' security instructions and give you access to their accounts. The best LM-whisperer wins!\n We're in the process of gathering a large dataset of attacks and defenses that we will distill into a set of small LM benchmarks. So far 40% of successful attacks have been prompt extraction (getting the model to reveal the access code), and the remaining 60% direct \"hijacking\" (i.e. directly making the model to grant access without the true access code). We plan to release the dataset after the ICLR deadline, although in the mean time we would love to see some creative attacks from ML researchers. We'd also appreciate any feedback or questions in the comments below!\n (Technical details: The LLM is gpt-3.5-turbo with temperature=0. We're tagging the three messages sent to the LLM (defense instructions, attack/access code, more defense instructions) as system/user/user, although this made surprisingly little difference.)\n    submitted by    /u/qxcv--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15wax8x/p_tensor_trust_a_web_game_to_collect_adversarial/",
          "publishedOn": "2023-08-20T13:05:33.000Z",
          "wordCount": null,
          "title": "[P] Tensor Trust: A web game to collect adversarial examples for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15waaiu/p_new_library_for_feauture_engineering_on_event/",
          "author": null,
          "description": "Hello there! A week ago, I open-sourced a project of mine that I've been working on, on and off, for a few years now. I'm a Data Scientist (and Kaggle competition grandmaster), and some of the hardest problems to solve were always the ones that involved time (proper validation, not leaking data from the future, etc.). I've always struggled to work with tables that, in reality, stored events. \n The main idea behind the library is that everything must be converted to an Event data structure, and then it is indexed in-memory. On top of that, there is a SQL-like DSL to extract features with a clear separation of past and future. The workflow itself is solid - I've tested it in a few projects. For those familiar with the terminology, it's like a super simple feature store + execution engine that acts like a library. The philosophy is that I'm aiming to create something that makes some mistakes that result in data leakage impossible to represent.\n Ideal use cases are probably customer related irregular events for which aligned features is painful to do.\n Things that I'm proud of: - Written in Rust - Implements DSL (pest parser, AST, evaluation) - Some performance tricks (partial aggregations)\n The implementation itself is lagging in some aspects, such as performance and UX (not all of the features that are in Rust are available in Python). But I released it in hopes that someone will find it interesting, and maybe it will gain some traction to motivate further development.\n GitHub: https://github.com/feature-express/feature-express Website: https://feature.express Example code: https://www.kaggle.com/code/paweljankiewicz/feature-express-weather\n    submitted by    /u/mosquit0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15waaiu/p_new_library_for_feauture_engineering_on_event/",
          "publishedOn": "2023-08-20T12:36:15.000Z",
          "wordCount": null,
          "title": "[P] new library for feauture engineering on event / timeseries data - feature.express",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15w8183/p_made_a_tool_called_csvshift_would_love_some/",
          "author": null,
          "description": "Hello,\n I recently had to transform some CSV data for a project and ended up creating a tool called CSVShift to help with it.\n It's a command-line tool that uses a custom language I made. It's designed for transforming CSV files. Some points:\n  \nHandles large CSV files without using much memory.\n It's open-source and MIT licensed.\n Still in early development, so there's room for improvement.\n  \nHere's the GitHub link: CSVShift.\n If you have the time, I'd appreciate any feedback or suggestions. Thanks!\n    submitted by    /u/Savalonavic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15w8183/p_made_a_tool_called_csvshift_would_love_some/",
          "publishedOn": "2023-08-20T10:35:04.000Z",
          "wordCount": null,
          "title": "[P] Made a tool called CSVShift. Would love some feedback!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15w7zwc/forecasting_for_regional_gdpgva_employment_figure/",
          "author": null,
          "description": "submitted by    /u/Impressive-Cat-2680  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15w7zwc/forecasting_for_regional_gdpgva_employment_figure/",
          "publishedOn": "2023-08-20T10:32:53.000Z",
          "wordCount": null,
          "title": "Forecasting for regional GDP/GVA, Employment figure for the U.K. using VAR (but which one)[P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15w353h/r_a_simple_but_strong_baseline_for_graph/",
          "author": null,
          "description": "Hi! I want to share with you my new paper, \"Strengthening structural baselines for graph classification using Local Topological Profile\" (code on Github). It was presented during ICCS 2023 conference (official publication).\n Graph classification is important in social networks analysis, de novo drug design, bioinformatics, materials science etc. A popular tool nowadays are Graph Neural Networks (GNNs), but they are data-hungry and hard to train for graph classification (compared to node classification). They also have problems with using subgraph information, due to node-to-node message passing.\n In this paper, we present a analysis and series of improvements for Local Degree Profile (LDP). It is a classical approach: feature extraction + tabular classification. It proposed extracting degree information for each node (degree, and min / max / mean / std of neighbors degrees), and then combining them with histograms to get features for the whole graph. Despite splicity, and not using any node or edge features (it is topological only), it was shown to give good results, and published on ICML workshop.\n We analyze the LDP method (not made by us, no affiliation with authors), and simplify it, showing that we can remove all hyperparameters, reimplement it much more efficiently, and use a faster classifier (Random Forest instead of SVM). We also propose simple additional features, which greatly improve results, with cost offset by our other improvements.\n The result is a strong baseline for topological graph classification, with obtains SOTA results on 4 out of 9 benchmark datasets, and performs well on the rest. We even outperform GNNs in this regard, when compared on the fair evaluation framework.\n If you have any questions, I am happy to answer!\n    submitted by    /u/qalis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15w353h/r_a_simple_but_strong_baseline_for_graph/",
          "publishedOn": "2023-08-20T06:01:50.000Z",
          "wordCount": null,
          "title": "[R] A simple but strong baseline for graph classification: Local Topological Profile",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15w32ah/beginner_project_ideas_d_p/",
          "author": null,
          "description": "i am currently studying software engineering and have done a few basic projects. i am very interested in machine learning and even completed a course on it online to know the basics. but since i am more of a hands on learner can someone suggest me some beginner projects and resources that will guide me through these projects. i want something that i can add on my resume as well. another thing i need resources for and struggle with is setting up the tools on my laptop.\n    submitted by    /u/anonymousphoenix123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15w32ah/beginner_project_ideas_d_p/",
          "publishedOn": "2023-08-20T05:57:41.000Z",
          "wordCount": null,
          "title": "beginner project ideas [D] [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15w0hyp/d_lstm_test_scores_much_better_than_trains_scores/",
          "author": null,
          "description": "I have a dataset of 20 thousand horses. For each horse, I have its 10 last historical races (finishing time, position, track name, distance etc. for 41 features) and am trying to predict its finishing time in its next race. To so so, I am using an LSTM as a feature selector for a horse's historical races, into a feed-forward network whose first layer is additionally comprised of features pertinent to the race being predicted (track name, distance, starting position etc. for 27 features.)\n Why is my test loss and test MAE much lower than the corresponding train metrics?\n ​\n https://preview.redd.it/sohys0jgs6jb1.png?width=964&format=png&auto=webp&s=99eb70ab80628f6289a135a0cf1bd54795a540f4\n https://preview.redd.it/3jbsfamhs6jb1.png?width=964&format=png&auto=webp&s=feb3b99867127657cd6d0d9f11de…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15w0hyp/d_lstm_test_scores_much_better_than_trains_scores/",
          "publishedOn": "2023-08-20T03:44:33.000Z",
          "wordCount": null,
          "title": "[D] LSTM test scores much better than trains scores",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vzrub/graduation_project_idea_suggestions_p/",
          "author": null,
          "description": "[P] Hi everyone, I prepare for my graduation project. I'm so interested in Gen AI and Cross-Modal learning. I'm looking for graduation project ideas that would allow me to explore these areas.\n Some ideas that I'm currently considering:\n * Automated Content Creation for Educators\n * Action Recognition with Language Context\n * Visual Question Answering\n If you have any suggestions, please let me know!\n Thanks in advance.\n    submitted by    /u/MZaher0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vzrub/graduation_project_idea_suggestions_p/",
          "publishedOn": "2023-08-20T03:07:41.000Z",
          "wordCount": null,
          "title": "Graduation Project Idea Suggestions [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vtwqi/discussion_petition_for_somoeone_to_make_a/",
          "author": null,
          "description": "Basically to recreate the state of this sub before the advent of ChatGPT. A place for practicing professionals to share news, and ask for help/advice from verified other practitioners.\n Edit: And absolutely no ML products, blog posts, self promo (unless writer of published paper) / code helper tools / low code solutions etc.\n    submitted by    /u/After_Magician_8438  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vtwqi/discussion_petition_for_somoeone_to_make_a/",
          "publishedOn": "2023-08-19T22:39:52.000Z",
          "wordCount": 2648,
          "title": "[Discussion] Petition for somoeone to make a machine learning subreddit for professionals that does not include enthusiasts, philosophical discussion, chatGPT, LLM's, or generative AI past actual research papers.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vt55w/rationality_in_ai_r/",
          "author": null,
          "description": "Rationality assumes that the rational agent knows all and will take the action that maximizes her utility. Human beings do not satisfy this definition of rationality.\n    submitted by    /u/Character_Ad_1385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vt55w/rationality_in_ai_r/",
          "publishedOn": "2023-08-19T22:08:06.000Z",
          "wordCount": 2610,
          "title": "Rationality in AI [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vsvun/d_best_way_to_host_a_vector_database/",
          "author": null,
          "description": "How are you guys hosting vector databases, pinecone seems really expensive\n    submitted by    /u/SayNo2Tennis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vsvun/d_best_way_to_host_a_vector_database/",
          "publishedOn": "2023-08-19T21:57:35.000Z",
          "wordCount": 2586,
          "title": "[D] Best way to host a vector database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vq2lc/p_handling_costs_making_a_chatgpt_based_app_api/",
          "author": null,
          "description": "Hi all - so my goal is to basically build an iPhone app using a ChatGPT backed character, which users can interact with by speaking (speech to text) and then will hear a spoken reply (text to speech)\n I'll need to use APIs that allow commercial usage.\n I'm trying to wrap my head around the costs of such a project. Right now I assume I'll have API costs from\n 1.) Speech to text (like whisper API)\n 2.) LLM (ChatGPT API)\n 3.) Text to speech (say elevenlabs API)\n If a ton of people start using this app, how fast am I going broke lol?\n I figure I can give free usage up to a point, and then users can pay for additional use if they like the service.\n But what do you guys recommend as the most cost effective way to do this? Looking at Elevenlabs alone, that looks like it would become super expensive very quickly.\n Any other APIs that allow commercial products which you would recommend?\n Or does this project sound like a fools errand?\n Any input would be greatly appreciated!\n    submitted by    /u/akuhl101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vq2lc/p_handling_costs_making_a_chatgpt_based_app_api/",
          "publishedOn": "2023-08-19T20:03:10.000Z",
          "wordCount": 2760,
          "title": "[P] Handling costs making a ChatGPT based APP - API questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15votn4/d_how_this_fancy_code_videos_are_recordededited/",
          "author": null,
          "description": "Recently I hace seen many videos on social media showing code or the IDE with auto-zoom and a very good style. \n Somebody knows how this videos are recorded/edited? All look alike and seems to be an app or similar…\n I address one of the post where I’ve seen this kind of videos.\n Thanks :)\n    submitted by    /u/VeganoDeMente  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15votn4/d_how_this_fancy_code_videos_are_recordededited/",
          "publishedOn": "2023-08-19T19:14:00.000Z",
          "wordCount": 2642,
          "title": "[D] How this fancy code videos are recorded/edited?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vn2z2/upcoming_panel_discussion_on_challenges_and/",
          "author": null,
          "description": "Key discussion points: - Enterprise LLM adoption and benefits - Using existing models vs. prompt engineering vs. fine-tuning - Fine-Tuning LLMs on custom datasets - Tools and platforms to facilitate LLM implementation - Addressing the challenges associated with adopting LLMs - Exploring emerging trends, advancements, etc.\n    submitted by    /u/UpstairsLeast7642  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vn2z2/upcoming_panel_discussion_on_challenges_and/",
          "publishedOn": "2023-08-19T18:06:06.000Z",
          "wordCount": 2630,
          "title": "Upcoming panel discussion on challenges and approaches with LLMs [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vljdn/n_a_new_kind_of_thermal_imaging_sees_the_world_in/",
          "author": null,
          "description": "submitted by    /u/fchung  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vljdn/n_a_new_kind_of_thermal_imaging_sees_the_world_in/",
          "publishedOn": "2023-08-19T17:03:18.000Z",
          "wordCount": 2591,
          "title": "[N] A new kind of thermal imaging sees the world in striking colors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vlh6m/project_pipeline_help_in_machine_learning/",
          "author": null,
          "description": "Hi, I'm using pipeline in my machine learning.I have already split th data into x_train and y_train. However, I do drop some rows in my pipeline. This means that my size or x_train is smaller then y_train.How do I overcome this and am I doing a mistake ? Thank you! I really appreciate if someone can help me !\n    submitted by    /u/Vitoahshik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vlh6m/project_pipeline_help_in_machine_learning/",
          "publishedOn": "2023-08-19T17:01:08.000Z",
          "wordCount": 2632,
          "title": "[Project] Pipeline help in Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vld23/p/",
          "author": null,
          "description": "submitted by    /u/hegel-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vld23/p/",
          "publishedOn": "2023-08-19T16:56:30.000Z",
          "wordCount": 2580,
          "title": "[P] https://blog.streamlit.io/exploring-llms-and-prompts-a-guide-to-the-prompttools-playground/",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15viu53/d_messing_with_a_models_weights_while_finetuning/",
          "author": null,
          "description": "Hello all,\n A college student who is interested in ML here.\n I was trying to use an encoder-only model(like BERT) as an embedding model and try to fine-tune it for my specific use case (for example trying to get the right product for a certain keyword using embeddings and vector DBs).\n Here is the question: should I update all the weights during backprop or should I just add another trainable linear layer for fine-tuning?\n I would also appreciate the reasoning behind your answer.\n Thanks!\n    submitted by    /u/gaybooii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15viu53/d_messing_with_a_models_weights_while_finetuning/",
          "publishedOn": "2023-08-19T15:13:30.000Z",
          "wordCount": 2659,
          "title": "[D] Messing with a models weights while fine-tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vitxy/d_which_pretrained_model_do_you_suggest_to_read/",
          "author": null,
          "description": "I am not into AI/ML. I am just a python dev with 4Y of experience. I am trying out on an idea using streamlit and want to use pre-trained models.\n Summarise and chat are two different functions. I tried T5, and gpt2-large. Both either don't seem to be working or my implementation is bad.\n    submitted by    /u/convicted_redditor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vitxy/d_which_pretrained_model_do_you_suggest_to_read/",
          "publishedOn": "2023-08-19T15:13:14.000Z",
          "wordCount": 2636,
          "title": "[D] Which pre-trained model do you suggest to read PDF contents to summarise and chat?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vi859/n_wise_bot_says_alpha_launch_a_platform_to_create/",
          "author": null,
          "description": "submitted by    /u/wisebotsays  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vi859/n_wise_bot_says_alpha_launch_a_platform_to_create/",
          "publishedOn": "2023-08-19T14:48:52.000Z",
          "wordCount": 2586,
          "title": "[N] Wise Bot Says Alpha Launch: A platform to create, share and easily use AI Chatbots with hyper-specific knowledge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vhd6l/landslide_prediction_using_machine_learning/",
          "author": null,
          "description": "Hi everyone, currently I'm working on a project to predict landslide. The landslide I want to predict is not image, just a percentage on the possibility of the landslide. So only deal with values,\n The plan is :\n There will be a esp32 collecting the input data, soil moisture. I have gotten some comments to do the ML on the laptop therefore not sure where to do it. I have done some work on google colab, using progression type, but not sure whether it is workable.\n Currently I have a dataset of the average percipitation, max temp, min temp, average temp from jan to dec from 1991 and 2021 and how many landslides happened in each month. I want to able to predict whether there will be landslide happening in the month. Not sure where to start and how to put it. Any help will be appreciated.\n Google colab work done so far = https://colab.research.google.com/drive/1dIp3dhe9xntoBZ5PyLF-UT0YsfSjHs-Q?usp=sharing\n    submitted by    /u/EconomistBrilliant72  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vhd6l/landslide_prediction_using_machine_learning/",
          "publishedOn": "2023-08-19T14:13:03.000Z",
          "wordCount": 2728,
          "title": "Landslide prediction using machine learning [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vf8sn/dcan_gtx1660_perform_llm_peftrlhf_operation/",
          "author": null,
          "description": "I want to learn to train a large language model, but due to limited conditions , I only have one server equipped with gtx1660. I would like to ask if gtx1660 can perform pre-training large languages Model training or PEFT or RLHF operations? If so, which large language model can generally be used？ LLaMA or chatglm or some language model else?\n    submitted by    /u/Alone_Beginning_6543  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vf8sn/dcan_gtx1660_perform_llm_peftrlhf_operation/",
          "publishedOn": "2023-08-19T12:40:27.000Z",
          "wordCount": 2634,
          "title": "[D]CAN GTX1660 perform llm PEFT/RLHF operation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vdfuo/p_data_science_ml_on_sensitive_data_with_local/",
          "author": null,
          "description": "submitted by    /u/silvanmelchior  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vdfuo/p_data_science_ml_on_sensitive_data_with_local/",
          "publishedOn": "2023-08-19T11:11:12.000Z",
          "wordCount": 2587,
          "title": "[P] Data science & ML on sensitive data with local code interpreter, with GPT-4 or Llama 2 (open-source project, link in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vcf2v/p_giving_llms_spacial_awareness/",
          "author": null,
          "description": "I am very much a beginner in this realm, but I am however an experienced iOS developer so please if there is something wrong with the post tell me and I will modify/take it down. That being said, I am looking to give an LLM (Llama 2 precisely) spacial/geographical awareness. I have the map data of a city (all points of interests, streets, businesses etc.) in a GeoJSON format and I would like to give the llama model the ability to answer location related questions like \"Where is the nearest bike shop?\", ', \"How far is Landmark X?\", \"What street am I on?\" etc. and all sorts of other location related questions. The approach I thought about using is the following: Have the llama model detect when a question is geo/location specific and make it ask/query another model specialised on this data. The problem is I have no idea which model would be best suited for the task whether or not a model is required at all or there is a better approach.\n Tldr: Need help finding a way to give an IIm spacial awareness from geojson data\n Any help is appreciated and sorry if the question is not in the right place\n    submitted by    /u/DaveAppleInc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vcf2v/p_giving_llms_spacial_awareness/",
          "publishedOn": "2023-08-19T10:17:29.000Z",
          "wordCount": 2775,
          "title": "[P] Giving LLMs spacial awareness",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vc29z/my_power_bi_interactive_dashboard_p/",
          "author": null,
          "description": "submitted by    /u/Sharp-Bandicoot-8021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vc29z/my_power_bi_interactive_dashboard_p/",
          "publishedOn": "2023-08-19T09:58:34.000Z",
          "wordCount": 2581,
          "title": "My power Bi interactive dashboard [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15vb60a/r_attention_maps_in_vit/",
          "author": null,
          "description": "submitted by    /u/mashaan14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15vb60a/r_attention_maps_in_vit/",
          "publishedOn": "2023-08-19T09:07:51.000Z",
          "wordCount": 2579,
          "title": "[R] Attention maps in ViT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15v2rd9/d_do_you_use_source_of_truth_databases_for_your/",
          "author": null,
          "description": "Models of various kinds and vector databases are common in applications of \"AI\" (sorry if that term is triggering -- it's appropriately ambiguous). But there are times when you not only need to store your raw application data in a \"source of truth\" (usually ACID-compliant RDBMS), but also ought to use the source of truth for the date related to learning, itself. \n Do you all use databases like this for things like:\n  \nTraining/testing job metadata storage \n Loss\n Gradients\n Weights (yikes!) -- for historical analysis, transfer learning, and experimentation etc.\n \n Hyperparameter tuning configuration storage\n Output storage\n Miscellaneous quick access during training\n  \nAny of these make no sense? Any others you can think of?\n    submitted by    /u/samhld  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15v2rd9/d_do_you_use_source_of_truth_databases_for_your/",
          "publishedOn": "2023-08-19T01:37:42.000Z",
          "wordCount": 2697,
          "title": "[D]: Do you use “source of truth” databases for your DL and/or AI/ML applications? If so, for what?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15v243a/d_calculate_gpu_requirements_for_your_llm_training/",
          "author": null,
          "description": "For my 30B model with 1B tokens, I want to complete the training within 24 hours. How many GPUs do I require?\n Well, ...\n Now, you can utilize a simple calculator to estimate or make an educated guess. Please take a look at the quick demo available at https://gpu.sung.devstage.ai/ and feel free to send us a pull request at https://github.com/hunkim/llm_gpu_cal.\n    submitted by    /u/hunkims  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15v243a/d_calculate_gpu_requirements_for_your_llm_training/",
          "publishedOn": "2023-08-19T01:06:23.000Z",
          "wordCount": 2635,
          "title": "[D] Calculate GPU Requirements for Your LLM Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uzeld/d_estimating_hardware_for_finetuning_llm/",
          "author": null,
          "description": "Hi everyone,\n I am trying to work on LLM and finetune it to a specific task. And my professor is asking me recommendation regarding GPU to buy. I know people use A100, V100, H100 to finetune 7B, 13B LLM.\n How can I determine the necessary hardware (RAM memory, GPU memory, etc.)? Making an assumption about the data and model size, I want to mathematically calculate the flops. Let's take an example where I have 2GB of fine-tuning data and a model, let's say a 13B pretrained model.\n Thanks.\n    submitted by    /u/Bishwa12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uzeld/d_estimating_hardware_for_finetuning_llm/",
          "publishedOn": "2023-08-18T23:07:42.000Z",
          "wordCount": 2661,
          "title": "[D] Estimating hardware for finetuning LLM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uxrqz/r_expanding_transformer_size_without_losing/",
          "author": null,
          "description": "Paper - https://arxiv.org/abs/2308.06103\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uxrqz/r_expanding_transformer_size_without_losing/",
          "publishedOn": "2023-08-18T22:01:49.000Z",
          "wordCount": 2581,
          "title": "[R] Expanding Transformer size without losing function or starting from scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ux2yg/d_system_requirements_for_training_on_large_scale/",
          "author": null,
          "description": "Is there any guide on how to approximate best system (CPUs, GPUs, storage and so on), in house hardware vs cloud providers for large scale training.\n    submitted by    /u/SouvikMandal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ux2yg/d_system_requirements_for_training_on_large_scale/",
          "publishedOn": "2023-08-18T21:34:49.000Z",
          "wordCount": 2602,
          "title": "[D] System requirements for training on large scale dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uvoo0/p_portrait_colourisation_through_only_two_colours/",
          "author": null,
          "description": "The Role of Chromatic Stimuli in Modulating Perceptual Inpainting within the Visual Cortex\n Link: https://github.com/consequencesunintended/perceptual-inpainting\n We employ a third party pre-trained facial segmentation model to integrate grids of varying sizes. These grids distinctly colour the face and the background using only red and blue hues. By doing so, we aim to investigate how these chromatic stimuli, in conjunction with spatial elements like grid size, influence the brain's capacity for perceptual inpainting\n What presents itself as a colourisation model is in fact an overlay on a segmentation model that draws diagonal red and blue lines on the relevant image. This allows the visual cortex to inpaint the associated colours. To exaggerate the effects, the model changes the grid size every 2 frames, iterating through 100, 50, 25, and 10 grid sizes.\n ​\n    submitted by    /u/TerryCrewsHasacrew  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uvoo0/p_portrait_colourisation_through_only_two_colours/",
          "publishedOn": "2023-08-18T20:40:48.000Z",
          "wordCount": 2704,
          "title": "[P] Portrait colourisation through only two colours",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uv9d2/r_equivariant_architectures_for_learning_in_deep/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2301.12780 \n Github: https://github.com/AvivNavon/DWSNets \n Blog: https://developer.nvidia.com/blog/designing-deep-networks-to-process-other-deep-networks/?=&linkId=100000214235775 \n Abstract:\n  \nDesigning machine learning architectures for processing neural networks in their raw weight matrix form is a newly introduced research direction. Unfortunately, the unique symmetry structure of deep weight spaces makes this design very challenging. If successful, such architectures would be capable of performing a wide range of intriguing tasks, from adapting a pre-trained network to a new domain to editing objects represented as functions (INRs or NeRFs). As a first step towards this goal, we present here a novel network architecture for learning in deep weight spaces…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uv9d2/r_equivariant_architectures_for_learning_in_deep/",
          "publishedOn": "2023-08-18T20:24:06.000Z",
          "wordCount": 2802,
          "title": "[R] Equivariant Architectures for Learning in Deep Weight Spaces - Nvidia 2023 - DWSNets has 60 percentage points more on the MNIST INR dataset in comparison to the transformer!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uutm1/p_constrained_linear_regression/",
          "author": null,
          "description": "Hi!\n I created constrainedlr, a drop-in replacement for scikit-learn's linear_model.LinearRegression with the extended capability to apply constraints on the model's coefficients, such as signs and lower/upper bounds.\n Any feedback appreciated!\n    submitted by    /u/samsamuel121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uutm1/p_constrained_linear_regression/",
          "publishedOn": "2023-08-18T20:06:49.000Z",
          "wordCount": 2601,
          "title": "[P] Constrained Linear Regression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uu7k8/how_good_is_this_video_on_the_bellman_equations_d/",
          "author": null,
          "description": "https://youtu.be/YGXznUx-JOo\n It seems like a thoughtful attempt on explaining the significance of Bellman equations in Reinforcement Learning.\n    submitted by    /u/bruin0404  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uu7k8/how_good_is_this_video_on_the_bellman_equations_d/",
          "publishedOn": "2023-08-18T19:42:22.000Z",
          "wordCount": 2594,
          "title": "How good is this video on the Bellman Equations? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uthd9/d_tokenizers_truncation_during_finetuning_with/",
          "author": null,
          "description": "Hello LLaMA enthusiasts!\n I've recently been diving into fine-tuning with substantial textual data, and I've come across a question. Let’s use the scenario of feeding entire movie scripts as my text input, let's say I intend to append a classification at the end, from categories like [\"positive\", \"negative\", \"neutral\"]. I've been trying this with the meta-llama/Llama-2-7b-chat-hf and the format looks something like this:\n <s>[INST] <<SYS>> System prompt <</SYS>> User prompt: Entire movie script [/INST] Model classification </s>\n The puzzle begins with the tokenizer of llama2, which, similar to its predecessor llama1, is a BPE tokenizer with a token limit of 512. If the movie script is long enough to exceed this limit, it is my understanding that the tokenizer truncates the prompt. This pos…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uthd9/d_tokenizers_truncation_during_finetuning_with/",
          "publishedOn": "2023-08-18T19:13:53.000Z",
          "wordCount": 2896,
          "title": "[D] Tokenizers Truncation during Fine-tuning with Large Texts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15urjzv/upcoming_masters_grad_in_aiml_seeking_mle/",
          "author": null,
          "description": "I will be completing my Masters's in May with an AI/ML certification, as was my Bachelor's specialization. I am young (23 when I graduate), so I have 0 YOE. \n I want to work as an MLE or equivalent position, but I have no idea how to prep for it (except doing leetcode for OA). \n I have a few projects in my resume that I don't feel are enough so I will work on that too. resume: https://aqua-julietta-1.tiiny.site (my resume seems weak as well, how can I improve) should I keep my college edu email as contact or should I change it to my personal email?\n need some advice on how the interviews for MLE are conducted, what is actually needed for an MLE (knowledge and requirements), should I try to get internships for January or do some unpaid internship for experience and then get a job in May? And not that imp yet but how much should I expect for a salary given my qualifications?\n if you have any personal experience to share or advice for me, I will be grateful for that.\n    submitted by    /u/bun_ty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15urjzv/upcoming_masters_grad_in_aiml_seeking_mle/",
          "publishedOn": "2023-08-18T17:58:59.000Z",
          "wordCount": 2762,
          "title": "Upcoming Masters Grad in AI/ML, Seeking MLE Insights - 0 YOE [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15upr4m/r_using_artificial_intelligence_to_shed_light_on/",
          "author": null,
          "description": "submitted by    /u/TobyWasBestSpiderMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15upr4m/r_using_artificial_intelligence_to_shed_light_on/",
          "publishedOn": "2023-08-18T16:48:32.000Z",
          "wordCount": 2599,
          "title": "[R] Using Artificial Intelligence to Shed Light on the Star of Biscuits: The Jaffa Cake",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uo840/d_starting_on_machine_learning/",
          "author": null,
          "description": "Hello, I'm starting my journey on AI and machine learning and I want some guidance and tips. I've watched Andrew's Ng course on Coursera and I want to expand my knowledge and get some hands on experience on the data/ML industry. What do you suggest me to do next?\n Thanks in advance for your responses.\n    submitted by    /u/stopTryingHard42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uo840/d_starting_on_machine_learning/",
          "publishedOn": "2023-08-18T15:50:04.000Z",
          "wordCount": 2627,
          "title": "[D] starting on machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15umjl6/d_laptop_advice_for_your_junior_dev_friend/",
          "author": null,
          "description": "Hello everyone,\n I am a Computer Science student and currently working as a junior in a company. The field I am currently working in is Data Engineering, but I am considering advancing into Machine Learning in the future. Besides that, I enjoy experimenting with different technologies during my free time, such as Unity, Rust, and GO.\n The laptop I will acquire should be able to support me in the long run for tasks related to Machine Learning, Data Engineering, and exploring new technologies. Currently, I own a Huawei laptop with 8GB of RAM, and I actively develop on Linux distributions like Ubuntu (I am not a big fan of Windows operating system as it tends to heat up the laptop and I generally prefer Linux, but I still occasionally dual boot into Windows for applications like Teams).\n I'm somewhat eager to experience Mac systems, but I have some concerns about whether they would be compatible with the technologies I use in data engineering (Spark, Hadoop, Power BI, Kafka). Would they work well with Machine Learning libraries and technologies? What are your experiences in this regard? Are there any differences in setting up an Ubuntu virtual machine on a MacBook? Would using Google Colab suffice for the field of Machine Learning? Are there any technologies that are not compatible with Mac, or have you encountered any challenges in this area?\n Below, I have listed some laptops I am considering. What are your thoughts?\n 1- Dell XPS 15 9530 i7-13700h / 32 GB RAM / 1 TB SSD / RTX 4050 (Linux & Windows dual)\n 2- MacBook Pro 16 inches Intel Core i9 9880H / 16 GB RAM / 1 TB SSD / AMD Radeon Pro 5500M\n 3- MacBook Pro 14 inches M2 Pro 10CPU 16GPU / 32GB RAM / 512GB\n 4- MacBook Pro 13.3 inches M2 8CPU 10GPU / 24GB RAM / 1TB SSD\n Looking forward to your insights.\n    submitted by    /u/No_Sky_2611  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15umjl6/d_laptop_advice_for_your_junior_dev_friend/",
          "publishedOn": "2023-08-18T14:46:03.000Z",
          "wordCount": 2890,
          "title": "[D] Laptop Advice For Your Junior Dev Friend.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ulou8/p_references_to_help_write_a_neurips_workshop/",
          "author": null,
          "description": "I've been working on a specific project for a while now, and was interested in submitting my work to a Nips Workshop.\n Now, I had a look at the Nips submission guidelines, they remain the same for the workshop except the page limit for main content is 6 pages instead of 9. I tried going over the Nips latex style, but feel pretty intimidated by the sheer amount of rules. Would there be any guideline/blog I could use as a reference while writing my paper?\n P S: Another thing, I'm quoting from the workshop website:\n \"The workshop will not have proceedings (or in other words, it will not be archival), which means you can submit the same or extended work as a publication to other venues after the workshop. This means we also accept submissions to other venues, as long as they are not published before the workshop date in December. \"\n I was not sure as to what this means. So if my paper gets accepted, does that mean I can submit the whole thing again to a journal later? Or an extension of it?\n    submitted by    /u/MurkyLeg2893  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ulou8/p_references_to_help_write_a_neurips_workshop/",
          "publishedOn": "2023-08-18T14:11:35.000Z",
          "wordCount": 2762,
          "title": "[P] References to help write a Neurips (Workshop) Paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uku85/d_ddpg_vs_dqn/",
          "author": null,
          "description": "I have project in which there is 2D discrete states which is also finite (there is 36 state at all) also i have 1D action that must be between 2-7. I use DQN using pytorch and discretized my actions with 0.25 steps (17 actions total) and get very good result with it. Now, I use DDPG because my action is continuous and there is one problem that I want to know if it is normal or not. From the first epoch all way to the end the actions for all states are near each other. For example at first episode all actions for all state are near 4 and after some episodes all actions are near 7. But in DQN i get high actions like 7 for some state and lower actions like 3-4 for others. Also I use OU noise but my problem is with the real output of actor network. \n Thanks in advance for your responses.\n    submitted by    /u/Brief-Emotion6291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uku85/d_ddpg_vs_dqn/",
          "publishedOn": "2023-08-18T13:38:18.000Z",
          "wordCount": 2729,
          "title": "[D] DDPG VS DQN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15uhw4l/n_neurips_large_language_model_efficiency/",
          "author": null,
          "description": "Model Efficiency Challenge\n  \nA challenge for the community to adapt a foundation model to specific tasks by fine-tuning on a single GPU of either 4090 or A100 (40GB) within a 24-hour (1-day) time frame, while maintaining high accuracy for these desired tasks.\n  \n​\n    submitted by    /u/Roots91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15uhw4l/n_neurips_large_language_model_efficiency/",
          "publishedOn": "2023-08-18T11:27:15.000Z",
          "wordCount": 2622,
          "title": "[N] NeurIPS Large Language Model Efficiency Challenge: 1 LLM + 1GPU + 1Day",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ucw27/d_is_there_popularproper_way_to_deal_with_data/",
          "author": null,
          "description": "I usually did small projects, and I was the only one to see the results when I studied deep learning, so it was okay to be messy. But managing data , and hyperparameters setting, dealing with data needs to be organized in company, and my current company doesn't have standard right now. So I need to set up some standard right now. \n Is there popular, or proper way to do manage your datas, hyperparameter, and model weight organized in the field? \n Especially I want to know how to manage NLP datasets? \n    submitted by    /u/poemfordumbs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ucw27/d_is_there_popularproper_way_to_deal_with_data/",
          "publishedOn": "2023-08-18T06:52:12.000Z",
          "wordCount": 2673,
          "title": "[D] Is there popular(proper) way to deal with data, manage datasets, and hyperparameters in deeplearing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ubyq9/d_challenges_expanding_vgg16_model_to_recognize/",
          "author": null,
          "description": "I've encountered an intriguing challenge with my VGG16 model, and I'm seeking some expert insights to help me out. 🤔\n ​\n Background:\n I've successfully trained a VGG16 model on a custom dataset containing 50 individuals, and it's been working like a charm! But now, I've hit a roadblock as I try to expand my model to accommodate an additional 50 individuals without compromising its ability to recognize the initial 50.\n ​\n The Dilemma:\n Here's where things get puzzling. Even though the model's accuracy hovers around an impressive 97-98%, and there's no apparent overfitting issue, it seems to only predict accurately on 1 or 2 individuals after incorporating the new dataset. It's as if the model is having a hard time retaining its initial knowledge while adapting to the new data.\n ​\n The Mystery Unveiled:\n I've taken care to ensure that my model doesn't overfit, and the accuracy metrics appear to validate this. So, what could be causing this unexpected behavior? Could it be a matter of data distribution, feature extraction, or something else entirely?\n ​\n Calling for Your Expertise:\n If you've got experience with complex neural networks, transfer learning, or just a knack for troubleshooting these kinds of issues, I'd love to hear your thoughts! How can I preserve the knowledge of the initial 50 individuals while expanding my model's capability to recognize all 100? Any guidance, theories, or practical solutions are more than welcome!\n    submitted by    /u/JuniorSM17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ubyq9/d_challenges_expanding_vgg16_model_to_recognize/",
          "publishedOn": "2023-08-18T06:01:44.000Z",
          "wordCount": 2810,
          "title": "[D] Challenges Expanding VGG16 Model to Recognize 100 People - Seeking Advice!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15u8wky/r_combining_physicsinformed_neural_networks_pinns/",
          "author": null,
          "description": "Recently, two interesting papers trying to reconcile the classical methods, specifically, finite difference method with physics informed neural networks have been published that are worth reading.\n  \nWeight initialization algorithm for physics-informed neural networks using finite differences\n Physics Informed Neural Network using Finite Difference Method\n  \nThese two papers can be considered to be harmonizing classical finite difference method and Physics-Informed Neural Networks (PINNs).\n The first paper incorporates finite difference solution for improving PINNs training loss. The second one uses finite difference method instead of automatic differentiation.\n In addition, there are papers discussing whether physics informed neural networks prevail or not\n  \nCan Physics-Informed Neural Networks beat the Finite Element Method?\n CAN-PINN: A fast physics-informed neural network based on coupled-automatic–numerical differentiation method\n  \nWhat are some other interesting papers you have encountered?\n    submitted by    /u/ai_physics2023  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15u8wky/r_combining_physicsinformed_neural_networks_pinns/",
          "publishedOn": "2023-08-18T03:28:40.000Z",
          "wordCount": 2705,
          "title": "[R] Combining Physics-Informed Neural Networks (PINNs) with Classical Numerical Methods",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15u6jor/r_generating_an_abstractive_summary_from_a_set_of/",
          "author": null,
          "description": "Given a set of survey questions, like,\n  1. What is your name and age? 2. Which of the following best describes your gender? 3. What is your profession? 4. How often do you consume alcohol? \n I wish to generate an abstractive summary with the responses of the given questions,\n  I'm <name>, a <age> years old <gender> who primarily works in <profession>. I consume alcohol <consumption_frequency>. \n This is not a summary exactly, but a textual representation of the responses. I wanted to explore all possible approaches that have been used to solve such problems, but I'm unable to start. It would be great if someone could guide me on what topics should I search or some baseline papers which solve similar problems.\n    submitted by    /u/shubham0204_dev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15u6jor/r_generating_an_abstractive_summary_from_a_set_of/",
          "publishedOn": "2023-08-18T01:41:21.000Z",
          "wordCount": 2701,
          "title": "[R] Generating an abstractive summary from a set of responses to survey questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15u4n4x/intro_to_kubernetes_for_ml_and_data_n/",
          "author": null,
          "description": "https://www.eventbrite.com/e/flyte-school-kubernetes-for-ml-and-data-an-introduction-tickets-698668154257?aff=oddtdtcreator\n L﻿earning Goals:\n  \nUnderstand the building blocks of a Kubernetes system, their relationships and hierarchy\n Learn how to leverage Kubernetes resources to transform the development lifecycle\n Deploy a simple workload and see how Kubernetes handles data persistency\n  \n   submitted by    /u/UpstairsLeast7642  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15u4n4x/intro_to_kubernetes_for_ml_and_data_n/",
          "publishedOn": "2023-08-18T00:18:45.000Z",
          "wordCount": 2577,
          "title": "Intro to Kubernetes for ML and Data [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15u2e3z/training_imagenet_1_epoch_on_2080ti_d/",
          "author": null,
          "description": "Hello, I want to train the ResNet-50 on ImageNet. I kept the batch size 96 image size 224x224. I am using 2080Ti I see the nvidia-smi memory is used 10+ GB and GPU is also utilised but not constant like it is fluctuating between 0-38%. However, training 1 epoch is like 8-9 hours. I know ImageNet is a Big dataset like 138GB. But still wondering if it is normal. \n    submitted by    /u/NoEntertainment6225  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15u2e3z/training_imagenet_1_epoch_on_2080ti_d/",
          "publishedOn": "2023-08-17T22:46:27.000Z",
          "wordCount": 2607,
          "title": "Training ImageNet 1 Epoch on 2080Ti [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tzr1c/p_colosseum_sidebyside_llm_comparison_platform/",
          "author": null,
          "description": "https://ml.energy/leaderboard\n We created a platform for side-by-side LLM comparison that shows the real time energy consumption of your prompts!\n This is part of the broader ML.ENERGY initiative where we want to measure and optimize the energy consumption of ML, while being mindful of existing optimization metrics like speed and model/response quality. The Colosseum is intended to give users a real time sense of the energy consumption of generating responses with LLMs of varying size and architectures.\n ​\n    submitted by    /u/jaywonchung  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tzr1c/p_colosseum_sidebyside_llm_comparison_platform/",
          "publishedOn": "2023-08-17T21:05:16.000Z",
          "wordCount": 2616,
          "title": "[P] Colosseum: Side-by-side LLM comparison platform for energy consumption",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tz16j/mlops_certification_for_aws_azure_or_databricks_d/",
          "author": null,
          "description": "If your employer offered to pay for you to be trained and obtain an MLOps certification in either AWS, Azure, or Databricks, which one would you select? Why? What would be your considerations?\n    submitted by    /u/Cultured_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tz16j/mlops_certification_for_aws_azure_or_databricks_d/",
          "publishedOn": "2023-08-17T20:39:29.000Z",
          "wordCount": 2572,
          "title": "MLOps Certification for AWS, Azure, or Databricks [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tyugr/p_realtime_movement_prediction_in_airstriker/",
          "author": null,
          "description": "Hello Reddit Community,\n I'd like to share a recent development for some feedback: my prototype predicts movement in the game Airstriker Genesis within the OpenAI Gym Retro environment. Notably, this system has no prior training or knowledge of the game mechanics - it is using online learning.\n Here's a brief split-screen video showing the system in action: YouTube Video Link\n The video provides actual gameplay alongside the system's predictive output, offering a real-time view of its evolving movement predictions. It's important to mention that during the gameplay in the video, I was manually steering the ship to showcase the prediction only. I've obviously avoided collisions. :)\n Of particular interest is the system's ability to discern the behavior of different game elements. For example its prediction of those falling meteorites starts weak, even though a spaceship has already travelled the same path before. However, as the first meteorite completes its path, the predictions dramatically improve. This highlights the system's capability to differentiate between objects and predict their behaviors accordingly.\n Currently, I'm focusing on improving horizontal movement detection, my next step is implementing a way to share knowledge about object's behavior between the hole system. That way, trajectory prediction learned in one location should be available instantly for the whole system.\n I'm eager about engaging in discussions to gather feedback on this technology!\n    submitted by    /u/PredictionSystem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tyugr/p_realtime_movement_prediction_in_airstriker/",
          "publishedOn": "2023-08-17T20:32:40.000Z",
          "wordCount": 2767,
          "title": "[P] Real-Time Movement Prediction in Airstriker Genesis with online learning | OpenAI Gym Retro Experiment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15txcz3/d_mastering_research_papers_in_your_phd_unlocking/",
          "author": null,
          "description": "A cornerstone of the PhD journey in ML involves thorough reading, ideally focused on pertinent literature to foster learning and develop a robust technical grasp.\n Personally, I encounter challenges when attempting to glean insights from published papers. Often, these works lack essential details, a coherent train of thought, and logical reasoning, leading to a disjointed reading experience.\n Consequently, engaging with research papers feels unproductive to me, yielding little in terms of knowledge, comprehension and academic value.\n I'm interested in your perspective on reading research papers. Do you view them as a source of learning, or are they primarily a means to establish/implement a baseline for your experiments e.g. when the code is public?\n How might a PhD candidate extract meaningful value from the process of reading research papers?\n    submitted by    /u/solingermuc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15txcz3/d_mastering_research_papers_in_your_phd_unlocking/",
          "publishedOn": "2023-08-17T19:37:54.000Z",
          "wordCount": 2672,
          "title": "[D] Mastering Research Papers in Your PhD: Unlocking Valuable Insights and Overcoming Challenges",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15twm69/discussion_introduce_the_amd_apu_as_low_as_95/",
          "author": null,
          "description": "Many talented people want to learn and practice machine learning but they may lack GPU computing power.\n Introducing one budget hardware that can help them get started locally. No need to mess with cloud costs. \n The 4600G is currently selling at price of $95. It includes a 6-core CPU and 7-core GPU. 5600G is also inexpensive - around $130 with better CPU but the same GPU as 4600G.\n It can be turned into a 16GB VRAM GPU under Linux and works similar to AMD discrete GPU such as 5700XT, 6700XT, .... It thus supports AMD software stack: ROCm. Thus it supports Pytorch, Tensorflow. You can run most of the AI applications.\n I have tested both training and inferencing for:\n  \nA: Stable diffusion, text inversion training.\n B: LLM. LlaMA fine tuning (lora). (It took very long time, so not very practical, but it can be practical for smaller size models, or for learning purpose)\n  \n16GB VRAM is also a big deal, as it beats most of discrete GPU. Even those GPU has better computing power, they will get out of memory errors if application requires 12 or more GB of VRAM. Although for APU the speed is less competitive, it's better than out of memory errors.\n Cost consideration:\n  \n Cloud cost $100 can be spent very quickly on Cloud. For example, on Google Cloud, NVIDIA T4 (low end) 1 GPU 16 GB GDDR6 costs $0.35 per GPU per hour. So after 285 hours (12 days) usage, your balance becomes 0. \n  \n Local cost $100 can buy you a chip that lasts a very long time. \n \n 5600G was a very popular product, so if you have one, I encourage you to test it. I made some videos tutorials for it. Please search tech-practice9805 for on Youtube and subscribe to the channel for future contents. Or use the video link https://youtu.be/HPO7fu7Vyw4.\n Please also follow me on X (Twitter): TechPractice1 https://twitter.com/TechPractice1\n Thanks!\n    submitted by    /u/chain-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15twm69/discussion_introduce_the_amd_apu_as_low_as_95/",
          "publishedOn": "2023-08-17T19:09:49.000Z",
          "wordCount": 2883,
          "title": "[Discussion] Introduce the AMD APU - as low as $95 - computer chip that reduces the cost to get started with Machine learning. Can do both training and inference: diffusion models, transformers, large language models, ...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tsv38/d_pretrain_bart_on_domain_context/",
          "author": null,
          "description": "Hi guys, I was asked to pretrain a BART model using my client’s domain specific dataset and I’d like to know if anyone has ever done this and perhaps could share a repo. \n I was running some tests using Bart-base model without the from_pretrained config. My idea was to get my sequences of 1024 tokens and mask random tokens at a 20% rate and use it as inputs to the BartForConditionalGeneration model and use the un-masked sequences as labels and try running a pretrain as such. Is this a good idea? \n The alternative would be to run the same steps above but on a pretrained version that already understands my native language thus adjusting its weights to my clients context. \n Anyone has any thoughts on this approach?\n    submitted by    /u/OkYak2915  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tsv38/d_pretrain_bart_on_domain_context/",
          "publishedOn": "2023-08-17T16:47:53.000Z",
          "wordCount": 2664,
          "title": "[D] Pretrain BART on domain context",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ts3u9/p_perspectives_wanted_towards_production_ready_ai/",
          "author": null,
          "description": "It’s me again! I made progress, added a new scale for measurement, and got many more questions!\n To recap, I'm embarking on an experiment that moves beyond the familiar \"thin OpenAI wrapper\" trend, aiming to develop a more practical solution for real-world production scenarios.\n Here’s the current thinking where I included your thoughts and came up with in this blog post: https://www.prometh.ai/promethai-memory-blog-post-one\n This was my post from earlier: https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/\n I'm committed to addressing the challenges of unreliable data pipelines that pervade the landscape. Rather than adhering to the trend of simplistic AI wrappers, I'm delving into a deeper exploration of building dependable data pipelin…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ts3u9/p_perspectives_wanted_towards_production_ready_ai/",
          "publishedOn": "2023-08-17T16:18:31.000Z",
          "wordCount": 2865,
          "title": "[P] Perspectives wanted! Towards PRODUCTION ready AI pipelines (Part2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tqjsh/r_review_article_textbook_for_optimizers_and_cost/",
          "author": null,
          "description": "I am interested in learning in-depth about first order and second order optimizers. Also which optimizers is theoretical better for which cost function. \n Would be helpful if it was related to convolution neural network or neural network, however for any machine learning is fine. \n    submitted by    /u/Wonderful_Energy_15  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tqjsh/r_review_article_textbook_for_optimizers_and_cost/",
          "publishedOn": "2023-08-17T15:19:50.000Z",
          "wordCount": 2587,
          "title": "[R] Review article/ textbook for optimizers and cost function for Neural Networks.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tpajo/d_new_oss_library_lida_for_automatic_generation/",
          "author": null,
          "description": "LIDA is an OSS library for generating data visualizations and data-faithful infographics. LIDA is grammar agnostic (will work with any programming language and visualization libraries e.g. matplotlib, seaborn, altair, d3 etc) and works with multiple large language model providers (OpenAI, PaLM, Cohere, Huggingface).Details on the components of LIDA are described in the paper here and in this tutorial notebook. See the project page here for updates!.\n Code onGitHub: https://github.com/microsoft/lida \n Try it out in Colab (LLM API key needed): https://colab.research.google.com/github/microsoft/lida/blob/main/notebooks/tutorial.ipynb\n LIDA treats visualizations as code and provides utilities for generating, executing, editing, explaining, evaluating and repairing visualization code.\n  \nData Summarization\n Goal Generation\n Visualization Generation\n Visualization Editing\n Visualization Explanation\n Visualization Evaluation and Repair\n Visualization Recommendation\n Infographic Generation (beta) # pip install lida[infographics]\n  \n​\n Installation and API.\n UI Screenshot for LIDA\n ​\n ​\n    submitted by    /u/vykthur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tpajo/d_new_oss_library_lida_for_automatic_generation/",
          "publishedOn": "2023-08-17T14:32:03.000Z",
          "wordCount": 2675,
          "title": "[D] New OSS Library (LIDA) for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tmjpd/d_object_detection_from_video_in_imagenet_dataset/",
          "author": null,
          "description": "Hello everyone,\n it appears that the original link to the resource in ILSVRC2015 is no longer accessible.\n If anyone has any insights or alternative links, please share them here.\n    submitted by    /u/Practical_Taste_4342  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tmjpd/d_object_detection_from_video_in_imagenet_dataset/",
          "publishedOn": "2023-08-17T12:46:56.000Z",
          "wordCount": 2572,
          "title": "[D] Object Detection from Video in Imagenet Dataset - Original Link Unavailable",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tlvtd/d_looking_for_early_devs_for_an_opensource_llm/",
          "author": null,
          "description": "Hi all, I'm looking several early devs to help with an open-source LLM testing framework. I have a full-time job to maintain and can't push changes nearly as quick as I'd like to.\n The framework is here: https://github.com/kortex-labs/korrect\n In any case, please star and suggest changes/ features.\n    submitted by    /u/kanxx030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tlvtd/d_looking_for_early_devs_for_an_opensource_llm/",
          "publishedOn": "2023-08-17T12:21:08.000Z",
          "wordCount": 2589,
          "title": "[D] Looking for early devs for an open-source LLM testing framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tfbg8/d_recommender_engines/",
          "author": null,
          "description": "Hey people. I’m looking for someone with a nice experience in Recommendation Systems.\n Here is the problem. I’m trying to finish my little project for recommender on GoodReads dataset. I have two datasets which I have preprocessed and prepared to pass through the models I need to create.\n But I’m still stuck on the models’ architecture, because this is my very first practical experience in Recommenders.\n Besides that, I have only 1-2 days left to present the project. So I have to solve the problem ASAP. \n I would be thankful for every kind of assistance in my project :)\n    submitted by    /u/thattallsoldier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tfbg8/d_recommender_engines/",
          "publishedOn": "2023-08-17T06:39:54.000Z",
          "wordCount": 2633,
          "title": "[D] Recommender engines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tekea/d_unsupervised_representation_learning/",
          "author": null,
          "description": "Hi folks, I have few million images in anomaly detection domain and want to build a base model for representation learning for downstream tasks. I was thinking of training a vq-vae with maybe some conditional training tasks like in-painting. Is this a good approach for representation learning? Are there any good unsupervised approaches for representation learning?\n    submitted by    /u/Appropriate_Bear_894  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tekea/d_unsupervised_representation_learning/",
          "publishedOn": "2023-08-17T06:00:30.000Z",
          "wordCount": 2591,
          "title": "[D] Unsupervised representation learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15teicv/side_hustle_for_making_money_d/",
          "author": null,
          "description": "Couple of folks here with 7+ years of solid experience each in Machine Learning and Data Engineering what kind of side hustles can be done for making money.\n    submitted by    /u/ninja790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15teicv/side_hustle_for_making_money_d/",
          "publishedOn": "2023-08-17T05:57:25.000Z",
          "wordCount": 2565,
          "title": "Side Hustle for making money [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15tdxjy/p_factors_influencing_adoption_intention_of/",
          "author": null,
          "description": "Hello,\n ​\n I am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.\n ​\n Please note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.\n ​\n If you are interested in learning more about the study, please follow the link below. \n ​\n https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf_link\n ​\n Thank you for taking the time to contribute to our research study. Your participation is greatly appreciated!\n    submitted by    /u/maulanash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15tdxjy/p_factors_influencing_adoption_intention_of/",
          "publishedOn": "2023-08-17T05:27:06.000Z",
          "wordCount": 2711,
          "title": "[P] Factors Influencing Adoption Intention of ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15t6wie/has_anyone_else_noticed_the_constant_misuse_of/",
          "author": null,
          "description": "The use of the word AI now feels like the use of \"Quantum\" in the 2010s by the new age community.\n The lack of actual quality information about ML models in media is shocking. Even in r/ChatGPT individuals are surprised when the software cannot perform math or look inside of a token.\n How do you recommend responding to these people to politely correct them?\n 1 CommentShareSaveTip \n    submitted by    /u/Zealousideal_Exit245  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15t6wie/has_anyone_else_noticed_the_constant_misuse_of/",
          "publishedOn": "2023-08-17T00:12:07.000Z",
          "wordCount": 2605,
          "title": "Has anyone else noticed the constant misuse of the term AI? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15t68bv/r_analyze_publish_health_services_research/",
          "author": null,
          "description": "I am looking to connect with peers who have used/are aware of databases available for secondary data analyses such as National Inpatient Sample (NIS), National Surgical Quality Improvement Program (NSQIP) and National Cancer Database (NCDB), etc.\n I am considering putting together a course to teach everything I have learned about using such databases over the past 6 years, including performing cleaning and analyses in R Studio. I really want to make sure I cover everything that is desirable to researchers looking to use these databases.\n Would anyone be interested in this?\n View Poll\n    submitted by    /u/TightJellyfish9275  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15t68bv/r_analyze_publish_health_services_research/",
          "publishedOn": "2023-08-16T23:44:58.000Z",
          "wordCount": 2626,
          "title": "[R] Analyze & Publish Health Services Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15t5nzl/p_pgmlchat_a_commandline_tool_for_deploying/",
          "author": null,
          "description": "We've created an open source chat bot builder, on top of PostgresML. This tool makes it easy to ingest documents and set a system prompt for a chatbot with knowledge of your content. The innovation is in the simplicity and efficiency, rather than the functionality.\n PostgresML runs open source embedding models alongside pgvector in Postgres to implement chat bot prompt creation without any network calls, which makes it ~4x faster than competing architectures. It can also do text generation with that prompt (and no additional network hops) using any open source model from HuggingFace, but it also integrates with the GPT-4 API if you'd like to use that instead. \n The full writeup including some benchmarks for competing architectures is here: https://postgresml.org/blog/pgml-chat-a-command-li…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15t5nzl/p_pgmlchat_a_commandline_tool_for_deploying/",
          "publishedOn": "2023-08-16T23:22:00.000Z",
          "wordCount": 2872,
          "title": "[P] pgml-chat: A command-line tool for deploying low-latency knowledge-based chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15t4qi0/d_what_features_should_i_use_when_creating_a/",
          "author": null,
          "description": "I just want to train a trading strategy to determine if the price will either trend up or down. what features do you think I should use that will give me a more accurate result? \n    submitted by    /u/doppelgunner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15t4qi0/d_what_features_should_i_use_when_creating_a/",
          "publishedOn": "2023-08-16T22:45:05.000Z",
          "wordCount": 2574,
          "title": "[D] What features should I use when creating a trend-following trading strategy?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15t11ws/cifar100_why_the_jump_in_accuracy_d/",
          "author": null,
          "description": "I'm just curious as to why there has been a massive increase in accuracy on CIFAR100 in the last couple years ?\n When I looked on PapersWithCode at the Models trained without Extra Data, there seems to be a plateau from around 2016 to 2022, then a massive jump happens of about 10% with (Astroformer and SAMix+DM).\n ​\n https://preview.redd.it/t1941i3v7jib1.png?width=1167&format=png&auto=webp&s=38db06c675219cb7949aaab898949b6fc16cec1b\n ​\n I looked at the papers for Astroformer and SAMix+DM, (I might be wrong) but they don't seem to be doing any sort of Transfer learning. I don't really understand how are they beating models that have been trained with Extra Training Data.\n ​\n https://preview.redd.it/brsethpr7jib1.png?width=1157&format=png&auto=webp&s=3747a08b8a2deefd9a328c9a6635db5daef667ed\n In these papers, are they reporting test/validation accuracy, or training accuracy ?\n And if are actually reporting the test accuracy, why don't these papers have more citations?\n ​\n    submitted by    /u/mrLiamFa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15t11ws/cifar100_why_the_jump_in_accuracy_d/",
          "publishedOn": "2023-08-16T20:28:34.000Z",
          "wordCount": 2662,
          "title": "CIFAR100 : Why the Jump in Accuracy ? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15sza0x/p_tutorial_how_to_build_an_endtoend_active/",
          "author": null,
          "description": "Hey r/MachineLearning, it's Nir from DagsHub 🐶\n Ever since Telsa revealed it is using Active Learning to build Computer Vision models, it has rapidly grown in popularity among the data science community. However, the hype around it has never correlated with the low number of projects and research papers that uses this method.\n Active Learning Cycle \n But why? It's a very efficient method that semi-automates the labeling process and helps reduce the number of samples we label to the bare minimum.\n After talking with many practitioners, we discovered that building an end-to-end active learning pipeline is something many struggles with. Even large companies with experienced data science teams run into issues.\n The main issue tends to be the tooling. Most of the time, tooling for an active learning pipeline needs to be either custom written or cobbled together from several different open-source tools with a lot of glue code.\n As part of our latest Data Engine Launch, Dean, our CEO, and Yono, our leading MLOps engineer, decided to build an active learning pipeline using only free and open-source tools and make it accessible to the ML community 👇\n They've built an image segmentation model using the COCO 1K dataset and wrote a tutorial blog that guides you through the process.\n As always, I'd love to hear your feedback, ways we can improve the pipeline, or other advanced methods that require heavy MLOps setups. \n    submitted by    /u/RepresentativeCod613  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15sza0x/p_tutorial_how_to_build_an_endtoend_active/",
          "publishedOn": "2023-08-16T19:21:40.000Z",
          "wordCount": 2770,
          "title": "[P] Tutorial: How to Build an End-to-end Active Learning Pipeline",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15syz8q/d_phd_in_cs_vs_mlai/",
          "author": null,
          "description": "Suppose someone has a BA/BS in CS, an MS in ML/AI, and a PhD in CS, would it be sufficient for ML/AI Research positions in the industry? Or is a PhD in stats/math/ML the bar of expectation?\n I understand that the quality of the PhD/published papers/experience is very important, but I wanted to know if there is value in an advanced degree in CS vs ML/AI.\n Apologies for the newbie question. I tried my best to find info about this topic online but I couldn't find much. Thanks!\n    submitted by    /u/GregSoSmooth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15syz8q/d_phd_in_cs_vs_mlai/",
          "publishedOn": "2023-08-16T19:10:40.000Z",
          "wordCount": 2621,
          "title": "[D] PhD in CS vs ML/AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15syks5/d_license_plate_identification/",
          "author": null,
          "description": "My grandparents were robbed inside their house. We have a footage from the getaway car that the police said it's not good enough (without even collecting it) to identify the license plate.\n Using machine learning does anyone know how (or if) is it possible to retrieve this data from the video?\n I've tried it following some opencv tutorials but without success as it's something new to me.\n The format would be 4 numbers and 2 letters like NN-NN-LL.\n https://file.io/lygAIft5bqY4\n    submitted by    /u/jpjvp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15syks5/d_license_plate_identification/",
          "publishedOn": "2023-08-16T18:55:49.000Z",
          "wordCount": 2610,
          "title": "[D] License plate identification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15sxf3e/solving_challenging_math_word_problems_using_gpt4/",
          "author": null,
          "description": "submitted by    /u/Borrowedshorts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15sxf3e/solving_challenging_math_word_problems_using_gpt4/",
          "publishedOn": "2023-08-16T18:11:56.000Z",
          "wordCount": 2550,
          "title": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15sum32/p_natural_language_to_query_generation/",
          "author": null,
          "description": "Introducing my personal project - \"nl2query\". It helps Convert natural language text inputs into Pandas, MongoDB, Kusto, and Neo4j queries effortlessly. Explore the code on GitHub: https://github.com/Chirayu-Tripathi/nl2query. \n https://preview.redd.it/8wjw1m151iib1.png?width=2048&format=png&auto=webp&s=677831e408a124d14ceaf24ba905d095b6372ef7\n    submitted by    /u/WorryWhole7805  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15sum32/p_natural_language_to_query_generation/",
          "publishedOn": "2023-08-16T16:28:00.000Z",
          "wordCount": 2560,
          "title": "[P] Natural Language to Query Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ssex3/p_dlt_now_supports_easy_loading_to_weaviate/",
          "author": null,
          "description": "dlt, the open source python loading library now supports Weaviate vector db, complete with upsert/merge support\n Hello AI enthusiasts, we at dlthub just added weaviate destination to dlt. It has never been easier to load data to a vector db.\n Docs: Weaviate destination docs\n If you need help or wish to discuss, join dlt community slack!\n Example:\n import dlt from dlt.destinations.weaviate import weaviate_adapter movies = [ { \"title\": \"Blade Runner\", \"year\": 1982, }, { \"title\": \"Ghost in the Shell\", \"year\": 1995, }, { \"title\": \"The Matrix\", \"year\": 1999, } ] # Define the pipeline: pipeline = dlt.pipeline( pipeline_name=\"movies\", destination=\"weaviate\", dataset_name=\"MoviesDataset\", ) # load the data info = pipeline.run( weaviate_adapter( movies, vectorize=\"title\", ), primary_key=\"document_id\", write_disposition=\"merge\" ) \n    submitted by    /u/Thinker_Assignment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ssex3/p_dlt_now_supports_easy_loading_to_weaviate/",
          "publishedOn": "2023-08-16T15:05:51.000Z",
          "wordCount": 2652,
          "title": "[P] dlt now supports easy loading to weaviate vector db",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ssb7a/d_why_isnt_machine_learning_assisting_in/",
          "author": null,
          "description": "If it is, could you please mention some ongoing projects.\n    submitted by    /u/Q_Wolf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ssb7a/d_why_isnt_machine_learning_assisting_in/",
          "publishedOn": "2023-08-16T15:02:07.000Z",
          "wordCount": 2547,
          "title": "[D] Why isn't machine learning assisting in translating ancient texts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15srtb5/discussion_steps_in_learning_ml/",
          "author": null,
          "description": "Hey guys, i’m honestly kind of new to machine learning and i’ll like to know what steps i can take in order to become a pro in ML or rather a beast in ML :)\n    submitted by    /u/consonantsnvowels  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15srtb5/discussion_steps_in_learning_ml/",
          "publishedOn": "2023-08-16T14:43:22.000Z",
          "wordCount": 2567,
          "title": "[Discussion] Steps in learning ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15sqsbt/r_braininspired_computational_intelligence_via/",
          "author": null,
          "description": "submitted by    /u/gw109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15sqsbt/r_braininspired_computational_intelligence_via/",
          "publishedOn": "2023-08-16T14:01:57.000Z",
          "wordCount": 2545,
          "title": "[R] Brain-Inspired Computational Intelligence via Predictive Coding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15sq2v1/d_potential_scammer_on_github_stealing_work_of/",
          "author": null,
          "description": "I was looking for implementation of this paper\n https://arxiv.org/pdf/2306.04031.pdf\n so I searched for logicguide github and found this repo\n https://github.com/kyegomez/LOGICGUIDE\n I noticed the small number of stars but I thought it was just a new paper. I tried to run the code and got multiple error messages. I thought I was just stupid and tried to fix the errors but noticed the code look messy and some parts seem just incomplete https://github.com/kyegomez/LOGICGUIDE/blob/main/logic_guide/logicguide.py#L88\n At this point, I feel like there is something weird. The repo belongs to some 19-year old https://github.com/kyegomez\n  \nI'm Kye, a 19-year-old Earthling striving to ensure the prosperity of our species, Humanity. I'm on a mission to help us reach a state of perpetual abundance in a post-scarcity civilization. \n  \nHe has 153 repos with 1.5k stars, with some big projects like tree of thoughts, LongNet, Sophia, etc\n I checked the issues and found https://github.com/kyegomez/tree-of-thoughts/issues/78\n  \nClarity Needed on Claims Made by PrincetonNLP 'Tree of Thoughts' Author #78\n  \nhttps://github.com/kyegomez/tree-of-thoughts/issues?q=is%3Aissue+is%3Aclosed\n https://github.com/kyegomez/Sophia/issues/27\n  \nReference of official repo for the copied code #27\n  \nIt seems a lot of his repos have reports that the code doesnt work.\n Is this guy stealing other people's work?\n    submitted by    /u/saintshing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15sq2v1/d_potential_scammer_on_github_stealing_work_of/",
          "publishedOn": "2023-08-16T13:33:48.000Z",
          "wordCount": 2725,
          "title": "[D] Potential scammer on github stealing work of other ML researchers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15som6l/d_submission_page_for_aaai_is_down/",
          "author": null,
          "description": "The submission was due 30 minutes ago, but the submission page (hosted on CMT) was down so I couldn't submit my paper. What now?\n    submitted by    /u/neurogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15som6l/d_submission_page_for_aaai_is_down/",
          "publishedOn": "2023-08-16T12:31:39.000Z",
          "wordCount": 2558,
          "title": "[D] Submission page for AAAI is down",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15snxgw/project_simple_fastapi_service_to_serve_llama2_7b/",
          "author": null,
          "description": "Hey,\n I wrote a simple FastAPI service to serve the LLAMA-2 7B chat model for our internal usage (just to avoid using chatgpt in our prototypes).\n I thought it could also be beneficial for you to use it if needed.\n Feel free to play with it https://github.com/mowa-ai/llm-as-a-service\n Tested on Nvidia L4 (24GB) with `g2-standard-8` VM at GCP.\n ​\n Any feedback welcome :)\n    submitted by    /u/JacekPlocharczyk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15snxgw/project_simple_fastapi_service_to_serve_llama2_7b/",
          "publishedOn": "2023-08-16T12:01:26.000Z",
          "wordCount": 2598,
          "title": "[Project] Simple FastAPI service to serve LLAMA-2 7B chat model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15snlbb/docker_images_for_containercloud_services_p/",
          "author": null,
          "description": "I have been making use of various cloud providers but I've found the default templates needed plenty of tweaking. \n I've made it my mission to re-package AI/ML tools in the github.com/ai-dock namespace. I hope someone finds this useful.\n My goal with this project is to make it easy to run ML projects in any docker environment. \n While I intend to package up many projects, I wanted to share the four 'base' images that I think will be of most value to this community:\n  \nPyTorch\n PyTorch + Jupyter\n Python\n Python + Jupyter\n  \nAll images are built by GitHub actions and will receive regualr updates.\n ROCm builds might work - I'm actively seeking feedback for them.\n Please do note that these images were designed primarily to run on platforms where a GPU instance has a single container - So we're running more than one process per container. The container will run only what is configured by the user.\n    submitted by    /u/towelfox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15snlbb/docker_images_for_containercloud_services_p/",
          "publishedOn": "2023-08-16T11:45:21.000Z",
          "wordCount": 2689,
          "title": "Docker images for container-cloud services [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15smi5e/discussion_sentence_word_orand_paragraph/",
          "author": null,
          "description": "When embedding documents for semantic search, I'm not sure whether I should embed sentences, words, or paragraphs, or even maybe chapters. Perhaps I should do all and have some sort of hierarchical tree search that recursively searches through the document structure chapter>paragraph>sentence>word. But embedding all the words seems quite costly.\n    submitted by    /u/No-Entertainer-802  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15smi5e/discussion_sentence_word_orand_paragraph/",
          "publishedOn": "2023-08-16T10:51:52.000Z",
          "wordCount": 2586,
          "title": "[Discussion] Sentence, word or/and paragraph embedding for semantic search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15slvx8/r_fast_machine_unlearning_without_retraining/",
          "author": null,
          "description": "submitted by    /u/JustAddMoreLayers  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15slvx8/r_fast_machine_unlearning_without_retraining/",
          "publishedOn": "2023-08-16T10:19:57.000Z",
          "wordCount": 2548,
          "title": "[R] Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15sjrz8/d_are_shared_weights_in_transformer_architecture/",
          "author": null,
          "description": "Hi all, \n I have built a transformer model in Pytorch which works really well. I created shared weights in the source and target embedding matrices as well as the final logits layer before the Softmax function. I was reading online and also section 3 of the 'attention is all you need' paper. \n Pre-training the weights in these specific matrices are identical. However, after training, they are also identical (but the model predicts perfectly etc, losses have decreased and it has trained 'correctly') soc clearly gradient updates have occured (as pre-training the predictions are all random).\n I might have be having a brain freeze, but are gradient updates to these layers going to affect them equally such that they are always the same, even after training (especially the final logits matrix which i don't think is making sense to me)? \n Appreciate any clarification!!\n Thank you!\n    submitted by    /u/amjass12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15sjrz8/d_are_shared_weights_in_transformer_architecture/",
          "publishedOn": "2023-08-16T08:24:12.000Z",
          "wordCount": 2684,
          "title": "[D] Are shared weights in transformer architecture also receiving the same gradient updates?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15sezs5/d_does_anyone_know_opensource_projects_that_can/",
          "author": null,
          "description": "SadTalker for example is very slow for real-time solutions, and wav2lips is also pretty slow. Could you please recommend any open-source projects for real-time lip sync? \n    submitted by    /u/madikz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15sezs5/d_does_anyone_know_opensource_projects_that_can/",
          "publishedOn": "2023-08-16T04:08:26.000Z",
          "wordCount": 2565,
          "title": "[D] Does anyone know open-source projects that can make real-time lip sync?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15s9mfz/research_stopgap_an_emergent_process_and/",
          "author": null,
          "description": "Introduction\n Hallucinations within AI models refer to instances where the model's outputs are not aligned with the input data. This phenomenon can lead to unexpected and often incorrect results. This documentation explores why hallucinations occur, delving into the connection between various terms such as \"perplexity,\" \"imputation,\" and \"stop-gap.\" The term \"stop-gap\" is used here as a shorthand explanation for what may be happening during the sampling process within a model, and this document aims to elucidate potential expressions, interpretations, and misunderstandings related to these concepts.\n Hallucinations and Perplexity\n Hallucination\n The term \"hallucination\" often describes a sensory perception (such as a visual image or sound) that occurs in the absence of an actual external s…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15s9mfz/research_stopgap_an_emergent_process_and/",
          "publishedOn": "2023-08-16T00:05:45.000Z",
          "wordCount": 3821,
          "title": "[Research] Stop-Gap: An Emergent Process and Expansive Term for Imputation in Explaining Hallucinations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15s6zws/d_on_demand_vs_reserved_instances_for_llm/",
          "author": null,
          "description": "Hi everyone,\n I am looking at different options to get access to GPUs to train an LLM on an enterprise use case for a customer. They are on a specific Cloud provider with associated credits, so I have no ability to go outside, like Runpod.\n We are exchanging on whether we should go for On-demand or Reserved instances. This client is a Fortune 500, so they could reserve it but it might not be the best choice.\n It seems to me that with LoRA / QLoRA, and so on, we might be able to fine-tune a Llama 2 with one or two GPUs on-demand, but I am unsure yet.\n So our main evaluation criteria are:\n - Price\n - Availability of GPUs, aka we don't want to waste too much time to get started\n In your experience, have you had difficulties to get access to GPUs at a good price? How many of you had to go with reserved instances, and if so what made you choose this option?\n I would love to have your feedback!\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15s6zws/d_on_demand_vs_reserved_instances_for_llm/",
          "publishedOn": "2023-08-15T22:19:22.000Z",
          "wordCount": 2717,
          "title": "[D] On demand vs Reserved instances for LLM fine-tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15s3yyy/d_physics_informed_neural_networks/",
          "author": null,
          "description": "Hi guys! I would really appreciate it if you can recommend any course or book to learn physics-informed neural networks or physics-based deep learning. I already have a background in deep learning and partial differential equations.\n Thanks\n    submitted by    /u/username_Zwickey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15s3yyy/d_physics_informed_neural_networks/",
          "publishedOn": "2023-08-15T20:25:09.000Z",
          "wordCount": 2575,
          "title": "[D] Physics Informed Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15s3xq6/engaging_reviewers_during_rebuttal_period_of/",
          "author": null,
          "description": "I have a paper (theoretical work) at NeurIPS under review right now. We got 4 reviews, 7,7,6,4 with confidence 4,4,4,2. We are trying to keep the good reviews there and bring up reviewer 4's score. We responded to all the comments made by reviewers, but unfortunately only one of them has engaged (one of 7 reviewers said they were happy with our responses and are keeping the score). The others have said nothing and the AC hasn't either. What is my best plan right now? Do I just stay silent or perhaps message the AC? I don't know if silence at this point is in my favor. There is still roughly a week left too.Sorry if this is a specific question. This is my first main author submission (1st year PhD student) and my advisor has been a bit MIA throughout the review process. \n    submitted by    /u/ynliPbqM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15s3xq6/engaging_reviewers_during_rebuttal_period_of/",
          "publishedOn": "2023-08-15T20:23:52.000Z",
          "wordCount": 2685,
          "title": "Engaging Reviewers during rebuttal period of NeurIPS [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15s1cv8/p_scalable_algorithm_for_genre_regulatory/",
          "author": null,
          "description": "https://github.com/soelmicheletti/giraffe\n Hi 👋🏽 I’d like to share GIRAFFE, a gene regulatory network inference method I developed for my thesis and we further developed in our group at HSPH. \n Framed as a matrix factorization, it allows to efficiently infer regulatory relationships in an accurate and flexible manner. In particular, it is designed to distinguish enhancing from inhibitory regulation. \n Don’t hesitate to drop me a line to discuss this further!\n    submitted by    /u/tigerthebest  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15s1cv8/p_scalable_algorithm_for_genre_regulatory/",
          "publishedOn": "2023-08-15T18:58:00.000Z",
          "wordCount": 2609,
          "title": "[P] Scalable algorithm for genre regulatory networks inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15s0ha3/p_carl_a_therapist_ai/",
          "author": null,
          "description": "Link to download Llama-2 model: https://huggingface.co/ajibawa-2023/carl-llama-2-13b\n Link for Llama model: carl-33b https://huggingface.co/ajibawa-2023/carl-33b\n Carl: A Therapist AI\n Early prevention can help lot of people to avoid depression and other mental illnesses. Therapy is a controversial use case because the outputs and capabilities of LLMs are uncertain. Many people don't have access to the therapist, due to financial, personal, social or other restriction. Here comes Carl: A Therapist AI which can quickly respond to you. It is trained on more than 100000 set of conversations. Each set having 10~15 conversations between Carl and client. Base data was obtained from u/ ZealousidealBlock330 . This data was further refined and fine tuned. Entire dataset is synthetic. Synthetic data is used because there is little to no therapy conversation data which is publicly available and directly applicable to an LLM. This by means a no replacement to a Doctor or professional therapist. If you are in stress or going through a tough time, please seek professional help or talk to a friend/family member.\n Training: Entire dataset was trained on Azure 4 x A100 80GB. DeepSpeed codebase was used for training purpose. Models were trained on Llama-1 & 2 by Meta. GGML Quant model (carl-llama-2-13b) was trained by Feanix. Extremely thankful to him.\n Extremely thankful to the opensource community and u/faldore , Pankaj Mathur , Tom \"TheBloke\" Jobbins ( u/The-Bloke ), /u/kaiokendev for guiding me through this community and through 'X'.\n If you find mistakes in the model then they are solely mine. I am looking forward to collaborate with like minded people to release many other models.\n Thank you\n    submitted by    /u/ajibawa-2023  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15s0ha3/p_carl_a_therapist_ai/",
          "publishedOn": "2023-08-15T18:24:37.000Z",
          "wordCount": 2802,
          "title": "[P] Carl: A Therapist AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rzbqe/pd_finetuning_for_granular_control_on_object/",
          "author": null,
          "description": "I am building a LLM assistant to summarize JSON objects. The model should take as input (1) a JSON object, (2) a structured summarization template from the end user. The goal is to allow the end user granular control over \"how\" the model should conduct the summarization.\n I'm familiar with the benefits of fine-tuning for simple tasks. But this use case seems to involve several different sub-tasks. So, before investing in fine-tuning, I thought I'd ask for the group's advice. Can I expect decent results from fine-tuning an LLM (e.g. LLAMA-7B or 13B) on annotated examples (JSON + Template + Expected Result) alone? Thank you!\n Example JSON Object\n { \"steps\": [ { \"name\": \"Step 1\", \"paragraph-1\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Quisque fermentum.\", \"paragraph-2\": \"Maur…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rzbqe/pd_finetuning_for_granular_control_on_object/",
          "publishedOn": "2023-08-15T17:41:38.000Z",
          "wordCount": 2866,
          "title": "[P][D] Fine-Tuning for Granular Control on Object Summarization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rxmvh/n_ensuring_reliable_fewshot_prompt_selection_for/",
          "author": null,
          "description": "Hello Redditors!\n Few-shot prompting is a pretty common technique used for LLMs. By providing a few examples of your data in the prompt, the model learns \"on the fly\" and produces better results -- but what happens if the examples you provide are error-prone?\n I spent some time playing around with Open AI's davinci LLM and I discovered that real-world data is messy and full of issues, which led to poor quality few-shot prompts and unreliable LLM predictions.\n ​\n Unreliable prompts lead to unreliable predictions.\n I wrote up a quick article that shows how I used data-centric AI to automatically clean the noisy examples pool in order to create higher quality few-shot prompts. The resulting predictions had 37% fewer errors than the same LLM using few-shot prompts from the noisy examples pool.\n Let me know what you think!\n    submitted by    /u/cmauck10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rxmvh/n_ensuring_reliable_fewshot_prompt_selection_for/",
          "publishedOn": "2023-08-15T16:37:02.000Z",
          "wordCount": 2682,
          "title": "[N] Ensuring Reliable Few-Shot Prompt Selection for LLMs - 30% Error Reduction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rxbs6/d_whats_the_best_english_based_voice_cloning_model/",
          "author": null,
          "description": "I am exploring a couple of Voice Cloning Models for Text to Speech but haven't had much success.\n I have tried --\n  \nserp-ai bark voice clone - https://github.com/serp-ai/bark-with-voice-clone/\n and a couple of models from TTS like - https://github.com/coqui-ai/tts\n  \nAre there any good models which work well for voice cloning with English speakers?\n    submitted by    /u/apple_pie0306  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rxbs6/d_whats_the_best_english_based_voice_cloning_model/",
          "publishedOn": "2023-08-15T16:24:18.000Z",
          "wordCount": 2594,
          "title": "[D] What's the best English based Voice Cloning Model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rx5ew/d_ml_projects_for_showcase/",
          "author": null,
          "description": "Hey guys I am pursuing my masters and I have learned and created projects on Supervised, Unsupervised as well as Reinforcement Learning. I am enrolled in OMSCS from Georgia Tech so the course work is intense (few people might know this).\n I want to do some projects which I can display in interviews which will also give me real time project experience and provide me intermediate experienced engineer in ML (I know can't be done with a project, I am eager to find the path to learn more, Masters helps though to clear the basics.)\n Any suggestions for the projects, kaggle is filled with classification projects which I have done alot? This semester I am talking deep learning so neural networks in deep will be covered this semester.\n    submitted by    /u/Latter_Ad_5679  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rx5ew/d_ml_projects_for_showcase/",
          "publishedOn": "2023-08-15T16:17:00.000Z",
          "wordCount": 2666,
          "title": "[D] ML projects for showcase",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rw7ac/d_best_low_price_service_for_training_ml_dl_cnn/",
          "author": null,
          "description": "I'm a student working in a bioinformatics lab. I'm working in some CNN, and colab free it's not enough for what I'm doing. This models will never be deployed or constantly be retrained or used in production of any kind, is just for research.\n The director of my lab is willing to start paying for a service so I can train my models... The thing is we are in Argentina (we are in a huge economical crisis), so we don't have much money to spend. \n I'm looking for a service with good GPUs but with a fixed price, like an anual subscription. I cannot pay each time I need to train a model.\n I know colab pro+ it's a good option, do you think is the best option?\n (My lab will eventually buy GPUs, but in the meantime I need to continue working)\n Edit: I need to be able to train models for many hours, without interacting with the notebook. And I don't need an amazing GPU, I wouldn't care to use a T4 and let it running for 40 hours.\n    submitted by    /u/simio_canoa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rw7ac/d_best_low_price_service_for_training_ml_dl_cnn/",
          "publishedOn": "2023-08-15T15:41:25.000Z",
          "wordCount": 2727,
          "title": "[D] Best low price service for training ML DL CNN models in academia?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rutam/r_how_to_treat_uncertainty_in_data_input_for/",
          "author": null,
          "description": "Hello everyone. I am an incoming PhD student in Energy Engineering, and I am currently creating my doctoral proposal. Take note: my knowledge of ML is superficial.\n I am trying to characterise building elements related to energy systems at the district level, however, the only data that I have is coming from Energy Performance Certificates (EPCs) coming from the regional authority. The data has some sort of anonymity to comply with GDPR purposes, for example, the name of occupants and the exact location is hidden. I am trying to use this data to determine the building characteristics of a district using Machine Learning. After all these data are characterised in individual buildings in the district, I will use physics-informed energy simulation to predict energy demand. However, the input data from EPCs is very uncertain because there is a significant portion that just uses median values. Previous attempts to use this data give a large percentage error (78%) when predicting energy demand in the district as compared to actual recorded energy demand values. \n Assuming all the previous methods are correct, is there a way to treat this data uncertainty, if I know the gap between the prediction and actual performance? What specific statistical methods should I explore to refine the data and close the gap between the prediction and actual performance?\n Thank you so much!\n    submitted by    /u/DivinePalaDean  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rutam/r_how_to_treat_uncertainty_in_data_input_for/",
          "publishedOn": "2023-08-15T14:48:02.000Z",
          "wordCount": 2770,
          "title": "[R] How to treat uncertainty in data input for energy prediction using ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ruiru/r_detr_doesnt_need_multiscale_or_locality_design/",
          "author": null,
          "description": "[2308.01904] DETR Doesn't Need Multi-Scale or Locality Design (arxiv.org) \n This paper presents an improved DETR detector that maintains a \"plain\" nature: using a single-scale feature map and global cross-attention calculations without specific locality constraints, in contrast to previous leading DETR-based detectors that reintroduce architectural inductive biases of multi-scale and locality into the decoder. We show that two simple technologies are surprisingly effective within a plain design to compensate for the lack of multi-scale feature maps and locality constraints. The first is a box-to-pixel relative position bias (BoxRPB) term added to the cross-attention formulation, which well guides each query to attend to the corresponding object region while also providing encoding flexibility. The second is masked image modeling (MIM)-based backbone pre-training which helps learn representation with fine-grained localization ability and proves crucial for remedying dependencies on the multi-scale feature maps. By incorporating these technologies and recent advancements in training and problem formation, the improved \"plain\" DETR showed exceptional improvements over the original DETR detector. By leveraging the Object365 dataset for pre-training, it achieved 63.9 mAP accuracy using a Swin-L backbone, which is highly competitive with state-of-the-art detectors which all heavily rely on multi-scale feature maps and region-based feature extraction. Code is available at this https URL .\n    submitted by    /u/ancientmooner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ruiru/r_detr_doesnt_need_multiscale_or_locality_design/",
          "publishedOn": "2023-08-15T14:36:55.000Z",
          "wordCount": 2746,
          "title": "[R] DETR Doesn't Need Multi-Scale or Locality Design",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ru7ag/discussion_an_opensource_framework_for_testing/",
          "author": null,
          "description": "Korrect is an open-source testing and fact-checking framework for LLMs. We are currently looking for contributors. \n Give us a star 🌟 and request features @ https://github.com/kortex-labs/korrect\n    submitted by    /u/kanxx030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ru7ag/discussion_an_opensource_framework_for_testing/",
          "publishedOn": "2023-08-15T14:24:46.000Z",
          "wordCount": 2568,
          "title": "[Discussion] an open-source framework for testing and fact-checking LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rtyix/p_where_can_i_find_an_open_source_biggan_code/",
          "author": null,
          "description": "No luck on GitHub, at this point anything will do. Thank you in advance.\n    submitted by    /u/wara2dawali  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rtyix/p_where_can_i_find_an_open_source_biggan_code/",
          "publishedOn": "2023-08-15T14:15:15.000Z",
          "wordCount": 2560,
          "title": "[P] where can I find an open source BigGan code that's not outdated?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rroi1/d_onthefly_fourier_transform/",
          "author": null,
          "description": "Can anyone please explain to me the difference between the so called on the fly Fourier transform and traditional Fourier transform?\n    submitted by    /u/TobinC1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rroi1/d_onthefly_fourier_transform/",
          "publishedOn": "2023-08-15T12:44:08.000Z",
          "wordCount": 2558,
          "title": "[D] On-the-fly Fourier transform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rrljw/bayesian_flow_networks/",
          "author": null,
          "description": "submitted by    /u/albertzeyer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rrljw/bayesian_flow_networks/",
          "publishedOn": "2023-08-15T12:40:32.000Z",
          "wordCount": 2536,
          "title": "Bayesian Flow Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rr6y8/p_need_help_predicting_key_positions_in_a_chrome/",
          "author": null,
          "description": "Hi everyone,\n I'm working on a project where I'm trying to predict the next key position (up or down) in a game similar to Chrome's Dino game. The data consists of a binary sequence representing key presses, with 1 for \"up\" and 0 for \"down.\" I have a dataset with 18k+ rows (can be increased to 30k+ if needed) and am aiming for a prediction accuracy of 98%+.\n What I've Tried So Far:\n  \nPreprocessing: Transformed the data into sequences of length 10 to predict the next value, splitting 70% for training and 30% for testing.\n Logistic Regression: Started with a simple logistic regression model using Scikit-learn but only achieved an accuracy of ~53%.\n LSTM Model: Tried an LSTM model with Keras, consisting of 50 units and a sigmoid activation for binary classification. The results were similar, with an accuracy of ~53%.\n  \nContext and Challenges: The game's key positions are analogous to the Chrome Dino game, where the past path is known, but the path upfront is unknown. There should be some patterns in the dataset related to the timing and reaction to specific obstacles, but I'm struggling to capture them.\n I've considered experimenting with different sequence lengths, more complex models like multiple LSTM layers or Conv1D\n    submitted by    /u/SnooTigers4634  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rr6y8/p_need_help_predicting_key_positions_in_a_chrome/",
          "publishedOn": "2023-08-15T12:23:30.000Z",
          "wordCount": 2750,
          "title": "[P] Need Help Predicting Key Positions in a Chrome Dino-like Game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rr2kh/d_dissecting_bark_whats_inside_sota_texttospeech/",
          "author": null,
          "description": "Hi,\n I put some of my notes on SOTA text-to-speech, specifically BARK, into a blog post:\n https://balacoon.com/blog/dissecting_bark/\n Let me know what you think\n Kind regards\n    submitted by    /u/clementruhm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rr2kh/d_dissecting_bark_whats_inside_sota_texttospeech/",
          "publishedOn": "2023-08-15T12:18:01.000Z",
          "wordCount": 2566,
          "title": "[D] Dissecting BARK - whats inside SOTA Text-to-Speech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rqsrs/r_neel_nanda_dm_anthropic_develops_a_ml_research/",
          "author": null,
          "description": "Video\n Disclosure: I worked with Neel when he was at Anthropic.\n Neel's a superb researcher, and the only one I know of at this level to document his process in this kind of depth. His channel's an incredible resource for anyone starting out in ML research, especially folk - high-schoolers, undergrads, indies - without access to mentors.\n    submitted by    /u/andyljones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rqsrs/r_neel_nanda_dm_anthropic_develops_a_ml_research/",
          "publishedOn": "2023-08-15T12:05:34.000Z",
          "wordCount": 2605,
          "title": "[R] Neel Nanda (DM, Anthropic) develops a ML research question end-to-end in a 5h stream",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rnnt5/d_is_it_possible_to_also_quantify_epistemic/",
          "author": null,
          "description": "I'm currently applying DDPM/score-based generative model to my dataset, one problem I'm trying to solve is the very limited training size, so I wonder if there's any work that could also quantify the epistemic uncertainty for these kinds of generative models.\n For example, if the data come from a mixture of Gaussian, but I only get one sample from the distribution, then after DDPM training, the sample generated from the model would be exactly the same as the training point.\n Is it possible to assign a 'prior distribution' like a Gaussian distribution for the underlying distribution, so that if the training set is small, then the trained DDPM would produce samples from the prior, but with more training data seen by the DDPM, the model could produce samples from the true underlying distribution?\n    submitted by    /u/alayaMatrix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rnnt5/d_is_it_possible_to_also_quantify_epistemic/",
          "publishedOn": "2023-08-15T09:26:14.000Z",
          "wordCount": 2680,
          "title": "[D] Is it possible to also quantify \"epistemic uncertainty\" for denoising diffusion probabilistic models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rjng4/d_mlops_what_options_are_available_for_gpu/",
          "author": null,
          "description": "I currently work in a mid-size company with 2-3 servers (no cloud) per department, with 1-4 GPUs each. For now, we have a chat room where we “reserve” a GPU in one of the servers of the corresponding department. But in really, this is only a plea to not use it while you are training your model.\n Moreover, there is another issue, resource under-utilization. There are some times where teams in one department are fighting for computer resources within their servers, while other department servers are not under full utilization.\n The issue is well known in the company and we are exploring the options (other than cloud) to solve this.\n Up until now, I came across Kubeflow but seems too complicated for what we want. Are there any other alternatives?\n    submitted by    /u/javyep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rjng4/d_mlops_what_options_are_available_for_gpu/",
          "publishedOn": "2023-08-15T05:45:34.000Z",
          "wordCount": 2672,
          "title": "[D] MLOps: what options are available for GPU allocation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ridca/p_openai_notebooks_which_are_really_helpful/",
          "author": null,
          "description": "The OpenAI cookbook is one of the most underrated and underused developer resources available today. Here are 7 notebooks you should know about:\n  \nImprove LLM reliability:\n https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md\n Embedding long text inputs:\n https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_long_inputs.ipynb\n Dynamic masks with DALLE:\n https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How_to_create_dynamic_masks_with_DALL-E_and_Segment_Anything.ipynb\n Function calling to find places nearby:\n https://github.com/openai/openai-cookbook/blob/main/examples/Function_calling_finding_nearby_places.ipynb\n Visualize embeddings in 3D:\n https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing_embeddings_in_3D.ipynb\n Pre and post-processing of Whisper transcripts:\n https://github.com/openai/openai-cookbook/blob/main/examples/Whisper_processing_guide.ipynb\n Search, Retrieval, and Chat:\n https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_a_search_API.ipynb\n  \nBig thanks to the creators of these notebooks!\n    submitted by    /u/vishank97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ridca/p_openai_notebooks_which_are_really_helpful/",
          "publishedOn": "2023-08-15T04:40:49.000Z",
          "wordCount": 2602,
          "title": "[P] OpenAI Notebooks which are really helpful.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rhfp5/r_instructiontuned_large_language_models_in/",
          "author": null,
          "description": "We've released our Okapi framework that introduces resources and models for instruction tuning for large language models (LLMs) with reinforcement learning from human feedback (RLHF) in 26 languages. Okapi supports 8 high-resource languages, 11 medium-resource languages, and 7 low-resource languages.\n Our resources include instruction data, response ranking data for RLHF, and evaluation benchmark datasets in 26 languages. Our datasets can be used to measure the progress of LLMs in these languages.\n https://github.com/nlp-uoregon/Okapi\n https://arxiv.org/abs/2307.16039\n    submitted by    /u/itnguyen2015  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rhfp5/r_instructiontuned_large_language_models_in/",
          "publishedOn": "2023-08-15T03:55:10.000Z",
          "wordCount": 2616,
          "title": "[R] Instruction-tuned Large Language Models in Multiple Languages with RLHF",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15rajkt/d_ai_jobs_are_paying_a_hell_of_a_lot_of_money/",
          "author": null,
          "description": "AI Jobs are paying a hell of a lot of Money.\n - Companies across industries like entertainment, retail, and manufacturing are engaging in an \"AI recruiting frenzy\" to hire data scientists, machine learning experts, and other AI talent. \n ​\n - Demand for AI skills is driving salaries up, with some roles offering compensation packages approaching $1 million. Jobs at companies like Netflix, Match Group, Amazon, and Walmart advertise base salaries from $250k to $400k.\n ​\n - Total compensation with bonuses and stock grants can be much higher than base salaries. But average pay for roles like prompt engineers is around $130k total. \n ​\n - Various factors make AI talent scarce - limited supply, competition from many industries, and candidates with multiple offers. Mid and senior level roles are hardest to fill.\n ​\n - Companies are using tactics like acquisition of AI startups, internal training programs, and pitching impactful work to attract candidates. \n ​\n - Recruiters say AI engineers and product managers can be very selective about roles, caring about the meaningfulness of the work.\n ​\n - Firms realize they cannot just hire their way out of the AI talent crunch. Retention and internal development will also be key.\n ​\n In summary, surging corporate AI demand against limited talent supply has created a hyper-competitive market where top AI professionals can command extreme compensation.\n    submitted by    /u/Yavero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15rajkt/d_ai_jobs_are_paying_a_hell_of_a_lot_of_money/",
          "publishedOn": "2023-08-14T23:14:52.000Z",
          "wordCount": 2760,
          "title": "[D] AI Jobs are paying a hell of a lot of Money.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15r8db6/p_synthetic_duplicates_of_confidential_datasets/",
          "author": null,
          "description": "Hey guys! Just released a small pip package based off some research I've been doing at school. The package is super simple, but enables devs to take an existing dataset and easily create a synthetic, privacy-preserving duplicate of this dataset. Not exactly sure where this lies in the data pipeline yet, but I imagine in the grand scheme of things some tech like this + a bunch of other features I want to add could be helpful in some way along the lines of data sharing/accessibility? I'd love some feedback and would even appreciate chatting with some folks for a few minutes to hear any advice you guys might have for me moving forward. This is the link to check it out: https://pypi.org/project/verisptab/. Thanks!\n    submitted by    /u/avnertothemoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15r8db6/p_synthetic_duplicates_of_confidential_datasets/",
          "publishedOn": "2023-08-14T21:53:22.000Z",
          "wordCount": 2663,
          "title": "[P] Synthetic Duplicates of Confidential Datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15r4lk1/d_periodicals_for_keeping_up_to_date/",
          "author": null,
          "description": "What are your favorite resources for keeping up to date without reading every paper that comes out? Tips and tricks columns etc. I've recently transitioned to a job in medical images and computer vision from my material science phd. I have some experience but not a machine learning PhD. I've been trying to keep up to date and linearlayer.substack.com seemed like a pretty good sub. I'm looking for more. Are there any niche periodical substacks, podcasts or forums you enjoy?\n    submitted by    /u/VooDooZulu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15r4lk1/d_periodicals_for_keeping_up_to_date/",
          "publishedOn": "2023-08-14T19:34:57.000Z",
          "wordCount": 2620,
          "title": "[D] periodicals for keeping up to date",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15r3tqo/p_nba_season_dataset/",
          "author": null,
          "description": "Just got my hands on basically every data point possible for every game from the 2022-2023 season, what should I do with it?\n    submitted by    /u/michaelc143  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15r3tqo/p_nba_season_dataset/",
          "publishedOn": "2023-08-14T19:07:15.000Z",
          "wordCount": 2560,
          "title": "[P] Nba season dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15r3efa/p_tearoute_trainable_efficient_autonomous_routing/",
          "author": null,
          "description": "Hi r/MachineLearning,\n I'm happy to show a new project I've been working on called TeaRoute (Trainable, autonomous, efficient routing). Tear is a simple tool that allows you to easily control the flow of information through LLMs via automated text classification.\n With just a few (~10) lines of code, you can set up a router that classifies text inputs and directs them to different LLM endpoints for processing. This makes it easier to build things like:\n  \nChatbots that route questions to different departments\n Multi-document question answering systems\n Dynamic classification models that improve over time\n  \nSome of the key features of TeaRoute:\n  \nClassification based on embeddings for high efficiency and low cost\n Option to use LLMs for classification when needed (and add that to training corpus)\n Easy setup in around 10 lines of code\n  \nI've open sourced TeaRoute and documented it fully, with examples like building a movie chatbot router. You can check out the code here: https://github.com/kesile/TeaRoute. You can install it into your program with \"pip install TeaRoute\".\n Let me know if you end up building something cool with TeaRoute! And feel free to open issues on GitHub if you run into any problems. Let me know your thoughts!\n    submitted by    /u/Rejg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15r3efa/p_tearoute_trainable_efficient_autonomous_routing/",
          "publishedOn": "2023-08-14T18:51:53.000Z",
          "wordCount": 2741,
          "title": "[P] TeaRoute - Trainable, efficient, autonomous routing for LLM queries.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15r35mq/d_implementing_real_time_transcription/",
          "author": null,
          "description": "I am working on a project where we need real time transcription of speech (mostly input through microphone). So the workflow is: 1-User starts speaking 2-Live transcription of their speech appears on screen\n By \"real time/live\" I mean the latency should not exceed 5 seconds, ideally much less while maintaining maximum accuracy.\n My question is: how do I achieve this?\n I have been experimenting with openai's whisper but I am not sure how can I get it to work with real time audio input since the model expects 30-second segments (preferably containing full sentences).\n My main challenge is how should I segment the audio. Should I use a VAD to split on silences? (I tried this but the transcription accuracy is lower since whisper doesn't have access to context outside of each segment)\n Also another question I have is how does hugging face automated speech recognition pipeline transcribe long audio files. I tried to read the documentation but cannot figure it out.\n Thanks in advance\n    submitted by    /u/Amgadoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15r35mq/d_implementing_real_time_transcription/",
          "publishedOn": "2023-08-14T18:42:57.000Z",
          "wordCount": 2703,
          "title": "[D] Implementing real time transcription",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15r1vy5/project_gpuaccelerated_llm_on_a_100_orange_pi/",
          "author": null,
          "description": "Progress in open language models has been catalyzing innovation across question-answering, translation, and creative tasks. While current solutions demand high-end desktop GPUs to achieve satisfactory performance, to unleash LLMs for everyday use, we wanted to understand how usable we could deploy them on the affordable embedded devices.\n Many embedded devices come with mobile GPUs that can serve as a source of acceleration. In this project, we pick Orange Pi 5, a RK35888-based board that is similar to Raspberry Pi but also features a more powerful Mali-G610 GPU.\n We 5 tok/sec for RedPajama-3b and 2.5 tok/sec for Llama2-7b. We can also get to 1.5 tok/sec on a 16GB version of the Orange Pi 5+ under $150.\n - Project: https://github.com/mlc-ai/mlc-llm\n - Blogpost: https://blog.mlc.ai/2023/08/09/GPU-Accelerated-LLM-on-Orange-Pi\n ​\n ​\n    submitted by    /u/crowwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15r1vy5/project_gpuaccelerated_llm_on_a_100_orange_pi/",
          "publishedOn": "2023-08-14T17:57:13.000Z",
          "wordCount": 2661,
          "title": "[Project] GPU-Accelerated LLM on a $100 Orange Pi",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15r0ss5/n_miniwob_v10_web_interaction_environments_for_rl/",
          "author": null,
          "description": "We are releasing the mature 1.0 version of MiniWoB++ (Mini World of Bits++), an RL benchmark containing over 100 web interaction environments, ranging from simple button clicks to more complex forms and web apps.\n The environments were released by OpenAI back in 2017 as just HTML pages. With MiniWoB++, the environments run on a browser, and an RL agent can get the environment states or execute actions via Selenium WebDriver.\n This version of MiniWoB++ contains the following features:\n * Over 100 web environments, including 2 bigger environments based on real websites and 18 previously unavailable “test set” environments. All (but 4) environments are deterministic for the given random seed.\n * Full integration with Gymnasium, a fork of OpenAI Gym, which provides a standardized API for RL.\n * A wide range of implemented browser actions including clicking, dragging, scrolling, typing, and pressing keyboard shortcuts, all of which can be customized (e.g., coordinate binning or scrolling speed).\n Tweet: https://twitter.com/FaramaFound/status/1691135031798804480?s=20\n Release notes: https://github.com/Farama-Foundation/miniwob-plusplus/releases/tag/v1.0\n Documentation: https://miniwob.farama.org/\n    submitted by    /u/elliottower  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15r0ss5/n_miniwob_v10_web_interaction_environments_for_rl/",
          "publishedOn": "2023-08-14T17:16:58.000Z",
          "wordCount": 2704,
          "title": "[N] MiniWoB++ v1.0 - Web interaction environments for RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qzxkx/p_visionbased_reinforcement_learning_for/",
          "author": null,
          "description": "We used model-free, value-based reinforcement learning (mostly dueling-IQN) to train an AI that plays Trackmania. The system is mostly vision based, along with some information taken from the game engine such as car speed and acceleration.\n On our simple training track, we believe we are close to or above human level. We have yet to find a human who sets a better racing time than our AI's.\n We tried many extensions to the algorithm (noisy, persistent advantage learning, munchausen, ...), but none of these extensions improved the ultimate performance of our AI.\n Link the the video, we're pretty proud of this result. :)\n ​\n    submitted by    /u/Linesight_rl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qzxkx/p_visionbased_reinforcement_learning_for/",
          "publishedOn": "2023-08-14T16:45:15.000Z",
          "wordCount": 2647,
          "title": "[P] Vision-based reinforcement learning for Trackmania: close or at superhuman level",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qv9nx/p_classifying_energy_news_with_machine_learning_a/",
          "author": null,
          "description": "Hi everybody,\n I want to share with this community a recent challenge involving machine learning that I've faced. Over the past few weeks, I've been busy creating a machine learning model. The goal? To classify news, mostly related to the energy sector, into 20 different topics. This task is a bit tricky since a news piece might fall into more than one category, so it's what's called a multi-label problem. Until now, I was doing this just using just keywords, but I wanted to move to something much better and robust.\n So basically, I started by taking 800 headlines and summaries and classifying them manually one by one into these 20 categories. After that, I began building the model in Python using scikit-learn. I tried different methods like logistic regression, random forest, SVM, etc. Af…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qv9nx/p_classifying_energy_news_with_machine_learning_a/",
          "publishedOn": "2023-08-14T13:49:59.000Z",
          "wordCount": 2870,
          "title": "[P] Classifying Energy News with Machine Learning: a Multi-Label Problem solved using Binary Relevance with XGBoost",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qr829/community_events_project/",
          "author": null,
          "description": "Hi u/all am thinking of creating a series of interesting events for the broader AI-Community. I always felt most events are either too expensive or too much of a company pitch. The topics should vary each time but for sure cover technical deep dives, some high level talks and some possibility to network and get together. I already have some company sponsors who are just interested in showing their name in the venue but don't want to interact/get information on participants or anything.\n ​\n What do you think - is this worth a shot? \n What ideas do you have wrt topics, speakers?\n    submitted by    /u/CarlCarter312  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qr829/community_events_project/",
          "publishedOn": "2023-08-14T10:45:58.000Z",
          "wordCount": 2637,
          "title": "Community Events [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qq3ou/r_okapi_instructiontuned_large_language_models_in/",
          "author": null,
          "description": "submitted by    /u/KingsmanVince  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qq3ou/r_okapi_instructiontuned_large_language_models_in/",
          "publishedOn": "2023-08-14T09:46:34.000Z",
          "wordCount": 2559,
          "title": "[R] Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qhm6b/d_ways_to_model_text_and_their_strengths/",
          "author": null,
          "description": "Hello, I'm trying to write a seq2seq model for text. I can think of many text to vector mappings, but I'm wondering are there better ones?\n  \nCodes: convert text to unicode codepoints, and represent it as 1m-ary classification\n Bits: convert text to utf-8, and represent it as a binary classification (0,1)\n Bytes: convert text to utf-8 and represent it as 256-ary classification\n Chars Embedding: identify small sequences and embed into space\n Word Embedding: identify words from a dictionary and embed into space (unknown words?)\n  \n   submitted by    /u/windoze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qhm6b/d_ways_to_model_text_and_their_strengths/",
          "publishedOn": "2023-08-14T02:22:20.000Z",
          "wordCount": 2625,
          "title": "[D] ways to model text and their strengths.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qhkq0/news_nvidia_finally_releases_neuralangelos_source/",
          "author": null,
          "description": "submitted by    /u/RegularConstant  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qhkq0/news_nvidia_finally_releases_neuralangelos_source/",
          "publishedOn": "2023-08-14T02:20:32.000Z",
          "wordCount": 2540,
          "title": "[News] NVIDIA finally releases Neuralangelo's source code!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qew5n/r_open_source_announcement_and_the_current_state/",
          "author": null,
          "description": "At Mirage, we’ve kept our platform at the edge of generative 3D starting with CLIP-Mesh by Nasir → GET3D by NVIDIA → Stable Dreamfusion by Google (implemented by ashawkey) → Point-E by OpenAI → Shap-E by OpenAI. We’ve spent time optimizing these open-source repos to produce usable game assets in multiple formats (recently GLTF).\n Today, we are open-sourcing Mirage3D. This repo is built upon the fantastic work of the folks mentioned above and is optimized to create GLB files easily.\n https://github.com/MirageML/Mirage3D\n Try out the repo yourself and consider contributing to help create a single source of truth for open-source generative 3D models, optimized to create usable 3D assets!\n The Problem\n Generative 3D is progressing slower than other modalities (audio, video, image, etc) due to …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qew5n/r_open_source_announcement_and_the_current_state/",
          "publishedOn": "2023-08-14T00:17:30.000Z",
          "wordCount": 2860,
          "title": "[R] Open Source Announcement and The Current State of Generative 3D (Aug 2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qco1x/discussion_having_trouble_choosing_which_mlops/",
          "author": null,
          "description": "Overwhelmed choosing an MLOps/experiment tracking platform to move to from manual AWS/S3/Dynamo + local tensorboard\n Title says it all… \n So many choices and it’s hard to figure out which to go with. Small team, 2-3 people, data scientists/python devs. mostly training MLP regressors on datasets with 20k-100k samples (approx 100 input features, approx 30 output variables) and CNNs on datasets with 500k-1m samples (approx 10x10000 timeseries per input sample along with 50-ish input features and 4x10000 output timeseries). \n At the very least, upgrading our experiment tracking/results reporting from Tensorboard to a cloud platform is a big desire, however, I would also like to make our full pipeline a bit more documented/versioned, and possible simplify some of the architecture. Ideally, we c…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qco1x/discussion_having_trouble_choosing_which_mlops/",
          "publishedOn": "2023-08-13T22:42:42.000Z",
          "wordCount": 3033,
          "title": "[Discussion] Having trouble choosing which MLOps solution to transition to from using AWS Batch/S3/Dynamo + Tensorboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15qcbel/p_llama2py/",
          "author": null,
          "description": "Hi everyone,\n Here is a ported version of Andrej Karpathy's llama2.c into pure Python with zero dependencies.\n The nice thing is llama2.py essentially captures the inference logic from the Llama2 research paper. With this port in pure Python, it's so much easier to unpack the intricate concepts originally presented in a \"scientific language\".\n Designed for an extensive audience, it aims to be a straightforward \"reference implementation\" suitable for educational purposes.The original llama2.c repository comprises two Python files intended for model training and one C file for inference.\n The goal of pure Python implementation is to bridge the existing gap by offering a clear-cut reference implementation encapsulating all transformer logic within a concise Python file, not exceeding 500 lines of code.\n Though the original Meta/Llama is written on Python, its complexity is rather high due to multiple dependencies and sophisticated optimizations implemented within. This often makes it hard to follow, particularly for those new to the field.\n    submitted by    /u/Albatross9855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15qcbel/p_llama2py/",
          "publishedOn": "2023-08-13T22:28:15.000Z",
          "wordCount": 2663,
          "title": "[P] llama2.py",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q9lmr/project_open_source_flowchart_for_complex_prompt/",
          "author": null,
          "description": "I've been using an abandoned block-coding framework called PyFlow to set up complex prompt chain techniques using LangChain. I found the visuals (and running multiple techniques at once) to be very helpful when comparing output quality.\n Would a beefed up open source version of this be useful for you and why? What are you currently doing to quickly test prompt chain techniques and measure the quality of the responses?\n https://preview.redd.it/ywpmjbwbvxhb1.png?width=1674&format=png&auto=webp&s=ca80a45e430b92bf31a9a9b9747c6d8ba7d3bde7\n    submitted by    /u/copywriterpirate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q9lmr/project_open_source_flowchart_for_complex_prompt/",
          "publishedOn": "2023-08-13T20:40:09.000Z",
          "wordCount": 2584,
          "title": "[Project] open source flowchart for complex prompt techniques = useful?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q8tnm/probem_with_running_a_python_script_that_uses/",
          "author": null,
          "description": "I have a python script on my raspberry pi zero that uses tflite to make predictions on images. it gets imported like that:\n import tflite_runtime.interpreter as tflite\n When i run the script from the terminal with sudo it gives me the error:\n ModuleNotFoundError: No module named 'tflite_runtime'\n without sudo it works just fine. Now the thing is that I need to run that script from another script using os.system(\"python code.py\") but that gives the same error no matter if I add sudo or not.\n Do you have any idea hw to fix that problem?\n    submitted by    /u/Main-Associate-6457  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q8tnm/probem_with_running_a_python_script_that_uses/",
          "publishedOn": "2023-08-13T20:08:18.000Z",
          "wordCount": 2608,
          "title": "Probem with running a python script that uses tflite [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q81ir/d_colab_pro_no_longer_gives_you_a_v100_not_even_a/",
          "author": null,
          "description": "submitted by    /u/LumpySchool7262  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q81ir/d_colab_pro_no_longer_gives_you_a_v100_not_even_a/",
          "publishedOn": "2023-08-13T19:37:47.000Z",
          "wordCount": 2536,
          "title": "[D] Colab Pro no longer gives you a V100, not even a P100, you now pay for the (previously free) Tesla T4.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q7pgv/r_your_neural_network_doesnt_know_what_it_doesnt/",
          "author": null,
          "description": "Hi everyone,\n I made a repo trying to collect every high-quality source for Out-of-distribution detection, ranging from articles and talks for beginners to research papers at top conferences. It also has a primer if you are not familiar with the topic. Check it out and give it a star to support me if you find it helpful. Thanks a lot ;)\n https://github.com/continuousml\n ​\n https://preview.redd.it/gup7ckixhxhb1.png?width=868&format=png&auto=webp&s=e71f51bef0ff2b4f3f37e801702b5d365cbd67fd\n    submitted by    /u/Ok-Kaleidoscope-505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q7pgv/r_your_neural_network_doesnt_know_what_it_doesnt/",
          "publishedOn": "2023-08-13T19:24:38.000Z",
          "wordCount": 2577,
          "title": "[R] Your Neural Network Doesn't Know What It Doesn't Know",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q71or/d_is_there_a_civitailike_service_or_resource_for/",
          "author": null,
          "description": "Anything out there for this?\n    submitted by    /u/Duemellon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q71or/d_is_there_a_civitailike_service_or_resource_for/",
          "publishedOn": "2023-08-13T18:58:22.000Z",
          "wordCount": 2523,
          "title": "[D] is there a Civitai-like service or resource for local install Tortoise_TTS files?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q6veh/p_understanding_instruction_tuning_for_multimodal/",
          "author": null,
          "description": "submitted by    /u/s_arme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q6veh/p_understanding_instruction_tuning_for_multimodal/",
          "publishedOn": "2023-08-13T18:51:06.000Z",
          "wordCount": 2523,
          "title": "[P] Understanding Instruction Tuning for Multimodal LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q6och/tips_and_tricks_for_publication_of_nonsota/",
          "author": null,
          "description": "Say, I have a method that can be used as a drop-in replacement for a part of a network in a set of relevant tasks, for example, an improved CTC loss in speech recognition and non-autoregressive translation.\n I can run a bunch of experiments, applying my method in those tasks, showing that \"model A + my method\" works substantially better than just \"model A.\" \"Model A\" is some relatively light and simple model, like Transformer-base. It might have been near-SOTA several years ago.\n However, the results won't be near contemporary SOTA, because SOTA models tend to be heavy and complicated. In theory, the modification can apply to bigger models, but I don't have the resources to re-implement them.\n So, how do I present my work? In theory, doing the \"model A\" experiments should be enough to show that my modification is interesting. But in practice most of the reviewers aren't very excited when the reported numbers are far from SOTA, even if the aim is not to beat SOTA, but to present a general working approach. I know that there are many papers that do not contain any SOTA-beating in them, but still manage to be successfully published. Question: how do they do that? \n Are there any tips and tricks? What kind of experiments/settings/datasets/models should I consider to convince the reviewers? Or at least make it harder for them to Reject-If-Not-SOTA?\n    submitted by    /u/Tomarchelone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q6och/tips_and_tricks_for_publication_of_nonsota/",
          "publishedOn": "2023-08-13T18:43:00.000Z",
          "wordCount": 2745,
          "title": "Tips and tricks for publication of non-SOTA research? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q68pn/r_in_search_of_big_binaries/",
          "author": null,
          "description": "I don't work in ML, but I work on an application that parses code and debugging information out of binaries (executables, shared libraries, etc.) that is then used by other people to build performance analysis tools that are used on ML applications.\n To do some performance benchmarking on my tool, I need some huge binaries to parse. Specifically, I need a binary with a lot of code (.text section in ELF) and debugging information (DWARF in ELF). I know there are lots of binaries that have a huge amount of data in them, but that doesn't help because my application just ignores that.\n Optimally, I need a binary with an on-disk size of greater than 5GB to get useful measurements, but greater than 1GB would still be good. I would also prefer being able to generate the binary from a source build so I can test it across the many architectures my tool supports.\n I have a collaborator who claims to have used my application on an 8GB TensorFlow binary. Unfortunately, that binary is on a classified system and I can't get access to it. However, that let's me know it's at least possible to make such a beast.\n Has anyone here seen such huge binaries using an ML application- it doesn't have to be TensorFlow?\n Thanks in advance!\n  \nTools I have tested thus far are the computational chemistry application NWChem and the quantum mechanics Gaussian integral application libint. However, I can't get either of these to make binaries larger than about 100MB.\n    submitted by    /u/OmegaNaughtEquals1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q68pn/r_in_search_of_big_binaries/",
          "publishedOn": "2023-08-13T18:25:31.000Z",
          "wordCount": 2764,
          "title": "[R] In search of big binaries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q50pz/p_we_built_a_multimodal_search_app_with_meta_ais/",
          "author": null,
          "description": "submitted by    /u/davidbun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q50pz/p_we_built_a_multimodal_search_app_with_meta_ais/",
          "publishedOn": "2023-08-13T17:36:25.000Z",
          "wordCount": 2523,
          "title": "[P] We built a multi-modal search app with Meta AI's ImageBind and Deep Lake (search with image, text, & audio)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15q13eu/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15q13eu/d_simple_questions_thread/",
          "publishedOn": "2023-08-13T15:00:32.000Z",
          "wordCount": 2558,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pzeco/d_improve_ocr_accuracy_in_python/",
          "author": null,
          "description": "Of course, I'd be happy to help you correct the errors in the text you provided. Here's the corrected version of your text:\n \"Hello everyone, I'm currently working on a Python program in which I need to use an OCR library. However, the results weren't very satisfying even though the text in the image is clear and there is no noise (just text). This is an example of the images I've used:\"\n https://preview.redd.it/flmdzz9otvhb1.png?width=515&format=png&auto=webp&s=dfd8ebab6f02369a150f7b9375e0d53baa6dceee\n https://preview.redd.it/q9mn21z9svhb1.png?width=515&format=png&auto=webp&s=291503b6a88c7c1dd2e639dd659d1d4b1a38e8d9\n I tried changing the contrast, and the results seemed to improve. However, I'm wondering if there are other approaches to consider in Python. Additionally, I want to implement a cost function that takes into account both the execution time and the accuracy of the OCR. How can I do that? \n    submitted by    /u/Ordinary_Run_2513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pzeco/d_improve_ocr_accuracy_in_python/",
          "publishedOn": "2023-08-13T13:49:08.000Z",
          "wordCount": 2633,
          "title": "[D] improve OCR accuracy in python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pymfx/r_run_llama2_13b_very_fast_locally_on_lowcost/",
          "author": null,
          "description": "submitted by    /u/reps_up  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pymfx/r_run_llama2_13b_very_fast_locally_on_lowcost/",
          "publishedOn": "2023-08-13T13:14:22.000Z",
          "wordCount": 2515,
          "title": "[R] Run LLama-2 13B, very fast, Locally on Low-Cost Intel ARC GPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pwsye/p_rasa_and_hugging_face_pre_train_model/",
          "author": null,
          "description": "Hello. can anyone give me a hint or tell me where i can find more info to get started with my test AI?\n I have installed Rasa and have downloaded the files pytorch_model.bin and config.json from xlm_roberta_large from hugging face.\n have tried to put it in config.yml, (maybe I did something wrong)\n because when I run \"rasa train\" and \"rasa shell -with the model\" I only get the standard init \"how are you?\"\n which is located in the domain file. I want a slightly more natural conversation than this.\n    submitted by    /u/Professional-Push-94  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pwsye/p_rasa_and_hugging_face_pre_train_model/",
          "publishedOn": "2023-08-13T11:46:46.000Z",
          "wordCount": 2602,
          "title": "[P] Rasa and Hugging Face. pre train model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pw25h/p_how_to_install_kubeflow_locally/",
          "author": null,
          "description": "Hey, r/MachineLearning, it’s Nir from DagsHub 🐶\n Our MLOps engineers have been experimenting with Kubeflow (”the MLOps version of Kubernetes”) for the past weeks to manage a training cluster on AWS.\n ​\n https://preview.redd.it/dqi27ggq0vhb1.jpg?width=1194&format=pjpg&auto=webp&s=945c9bcaa9987d2df135e18cf081efd9f742cf0f\n As good engineers, we wanted to kick the tires a bit before committing cloud resources to it. Unfortunately, most installation guides we found online only showed you how to spin up a Kubeflow cluster on AWS, GCP, or Azure. We had a hard time finding clear instructions for installing it locally.\n A local installation would allow individuals to play around with it, experiment, and learn from it.\n So we started looking into it.\n We followed this thread until we successfully ran Kubeflow on a local machine. Since it wasn’t a super clear or easy process to figure out, we’ve written a blog post on how we did it and decided to share our insights with the ML community.\n You can find the blog here: https://dagshub.com/blog/how-to-install-kubeflow-locally\n We also have a follow-up blog that explains how to deploy a Kubeflow cluster on AWS, so if you have any insights or requests for further information - we’d love to hear from you!\n    submitted by    /u/RepresentativeCod613  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pw25h/p_how_to_install_kubeflow_locally/",
          "publishedOn": "2023-08-13T11:05:49.000Z",
          "wordCount": 2701,
          "title": "[P] How to install Kubeflow locally",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pv3yk/p_factchecking_framework_for_llms/",
          "author": null,
          "description": "Hey guys, happy Sunday 🤗 I've started an open-source project for fact-checking in LLMs.\n Contributions are welcome: https://github.com/kortex-labs/korrect\n    submitted by    /u/kanxx030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pv3yk/p_factchecking_framework_for_llms/",
          "publishedOn": "2023-08-13T10:09:37.000Z",
          "wordCount": 2528,
          "title": "[P] Fact-checking framework for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ps6ft/p_survey_on_data_challenges_when_using_mlai/",
          "author": null,
          "description": "Hi all, I'm working on my master thesis on challenges related data acquisition and mgmt for companies using AI. If you fit the profile and can help it would be great. 2x50€ amazon vouchers draw at the end. Here is the link\n https://tummgmt.eu.qualtrics.com/jfe/form/SV_bl2FXTBrPe1Tn4q\n    submitted by    /u/g13e-reddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ps6ft/p_survey_on_data_challenges_when_using_mlai/",
          "publishedOn": "2023-08-13T07:11:10.000Z",
          "wordCount": 2556,
          "title": "[P] Survey on data challenges when using ML/AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pm5li/daaai_author_list_modification/",
          "author": null,
          "description": "Can I add author to the author list between abstract deadline and submission deadline?\n AAAI-24 Submission Instructions says\"Authors must enter the names of ALL AUTHORS at the time of registration (by abstract deadline) — CMT includes a hard-coded note that this is optional, however, this is a mandatory step for AAAI-24 authors. According to AAAI policy, all author names must be added at the time of abstract registration, and the list of names as well as the order in which they appear cannot be changed after August 15.\"\n I fell a little confusing that it says \"the list of names ... cannot be changed after August 15\", but also mentioned that \"Authors must enter the names of ALL AUTHORS at the time of registration (by abstract deadline)\".\n    submitted by    /u/No_Paramedic3606  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pm5li/daaai_author_list_modification/",
          "publishedOn": "2023-08-13T01:52:40.000Z",
          "wordCount": 2636,
          "title": "[D]AAAI author list modification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15plkj1/explainable_ai_techniques_for_biologically/",
          "author": null,
          "description": "submitted by    /u/bluepapaya555  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15plkj1/explainable_ai_techniques_for_biologically/",
          "publishedOn": "2023-08-13T01:23:56.000Z",
          "wordCount": 2665,
          "title": "Explainable AI techniques for biologically inspired / plausible neural networks? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pkmw0/p_llama2_embeddings_fastapi_service/",
          "author": null,
          "description": "submitted by    /u/dicklesworth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pkmw0/p_llama2_embeddings_fastapi_service/",
          "publishedOn": "2023-08-13T00:40:10.000Z",
          "wordCount": 2528,
          "title": "[P] Llama2 Embeddings FastAPI Service",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pkj1d/p_use_llama2_to_improve_the_accuracy_of_tesseract/",
          "author": null,
          "description": "submitted by    /u/dicklesworth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pkj1d/p_use_llama2_to_improve_the_accuracy_of_tesseract/",
          "publishedOn": "2023-08-13T00:34:59.000Z",
          "wordCount": 2538,
          "title": "[P] Use Llama2 to Improve the Accuracy of Tesseract OCR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pg0xw/d_pdf_link_for_grokking_the_machine_learning/",
          "author": null,
          "description": "Can someone please provide the pdf download link for the Educative.io course - \"Grokking the machine learning interview\"?\n https://www.educative.io/courses/grokking-the-machine-learning-interview\n I am a student and can't really afford to buy their courses.\n    submitted by    /u/Sign-Itchy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pg0xw/d_pdf_link_for_grokking_the_machine_learning/",
          "publishedOn": "2023-08-12T21:23:13.000Z",
          "wordCount": 2546,
          "title": "[D] PDF link for 'Grokking the machine learning interview' course",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pdbmk/r_jailbreak_prompts_and_llm_safety/",
          "author": null,
          "description": "The authors found two effective jailbreak prompts that can successfully jailbreak built-in safeguards of ChatGPT (GPT-3.5) and GPT-4. \n Paper: https://arxiv.org/abs/2308.03825\n    submitted by    /u/titaniumstorm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pdbmk/r_jailbreak_prompts_and_llm_safety/",
          "publishedOn": "2023-08-12T19:31:23.000Z",
          "wordCount": 2531,
          "title": "[R] Jailbreak Prompts and LLM Safety",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pbcvo/d_what_technologies_are_best_for_building_a/",
          "author": null,
          "description": "We're working on a project at Deep Engine AI, focusing on decentralized NLP using blockchain and GPU training. What tools, libraries, or frameworks would you recommend for distributed computing, blockchain integration, and efficient GPU acceleration? Thanks for any insights!\n    submitted by    /u/deepengineai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pbcvo/d_what_technologies_are_best_for_building_a/",
          "publishedOn": "2023-08-12T18:10:36.000Z",
          "wordCount": 2555,
          "title": "[D] What Technologies Are Best for Building a Decentralized NLP Platform?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15pbaow/d_neural_network_architecture_for_angle/",
          "author": null,
          "description": "I was thinking about building a hobby project with a microcontroller which runs a pre-trained neural network to estimate three angles from images of an electric meter I have at my home.\n My first step is to train a model on my computer with generated images and see how well this works in general and then later capture real images. To give you an idea of what I am looking for, I added a screenshot of the images I am currently generating.\n https://ibb.co/fFtRj1Q\n For this example image, I expect 35, 75, 137 degree as a result.\n What kind of network would you recommend for this task? Please keep in mind that it shouldn't be too fancy to still fit into a microcontroller via TensorFlow Lite.\n ​\n Thank you so much for any recommendations\n    submitted by    /u/LM1117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15pbaow/d_neural_network_architecture_for_angle/",
          "publishedOn": "2023-08-12T18:08:12.000Z",
          "wordCount": 2648,
          "title": "[D]: Neural Network architecture for angle estimation of an electric meter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15p9ak7/p_research_paper_highlights_julyaugust_2023/",
          "author": null,
          "description": "submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15p9ak7/p_research_paper_highlights_julyaugust_2023/",
          "publishedOn": "2023-08-12T16:44:00.000Z",
          "wordCount": 2522,
          "title": "[P] Research Paper Highlights July-August 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15p82bd/d_comparison_of_big_csps_vs_small_gpu_clouds_for/",
          "author": null,
          "description": "Hi everyone,\n I am looking to fine-tune a Llama 2 (the 7B and 70B to see if there is a big difference), and I am looking at the different Cloud options for GPUs.\n There are of course the big cloud providers like AWS, and the smaller ones like Paperspace and co.\n I am trying to benchmark each in terms of price, ease of use, quick availability of GPUs, and feature-richness.\n Could you share the insights on big vs small cloud providers when training a LLM? If you have other criteria to make a decision I would be interested too!\n Thanks\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15p82bd/d_comparison_of_big_csps_vs_small_gpu_clouds_for/",
          "publishedOn": "2023-08-12T15:52:31.000Z",
          "wordCount": 2617,
          "title": "[D] Comparison of big CSPs vs small GPU clouds for fine-tuning LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15p4ddt/d_whats_the_best_way_to_prepare_text_data_for/",
          "author": null,
          "description": "Specifically, I'm using Naive Bayes, Random Forrest, SVM and one deep learning model. I've tried to remove extra white space, remove things like [23f] (data from reddit posts), urls etc. I also have 2 datasets: one with original letters and one with only small ones. But is there a better way than just doing it by hand? Any libraries?\n    submitted by    /u/eeriek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15p4ddt/d_whats_the_best_way_to_prepare_text_data_for/",
          "publishedOn": "2023-08-12T13:16:28.000Z",
          "wordCount": 2577,
          "title": "[D] What's the best way to prepare text data for text classification models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15p194u/p_question_about_object_detection/",
          "author": null,
          "description": "Hi,\n I'm new to machine learning and have a question regarding object detection. Here's the scenario:\n I have an image, let's call it image 1, where a person is captured from the front. This allows me to see the person's face, clothes, shoes, and basically their entire front view.\n I have another image, image 2, taken from a different angle or perspective (e.g., their back view). In this image, I might be able to see the entire person or just a part of them.\n The challenge I'm facing is: Can I predict if the person in image 1 is present in image 2? If this is possible, I'd appreciate any guidance on how to approach this problem:\n  \nWhat methodologies or algorithms should I consider?\n What kind of datasets might be useful for this task?\n Any resources, tools, or tutorials that can help me get started?\n  \nThank you in advance for any insights or guidance you can provide!\n    submitted by    /u/Senior_Box_8288  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15p194u/p_question_about_object_detection/",
          "publishedOn": "2023-08-12T10:38:38.000Z",
          "wordCount": 2667,
          "title": "[P] Question about object detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15p0d9f/p_skyline_v20_equation_by_rainmanp7/",
          "author": null,
          "description": "This is my go at my own machine reinforced training equation.\n This is my updated version from 1.1 it's now at 2.0. Hopefully you can learn some things from looking at it. You're welcome to comment on anything you see.\n The concept of leveraging similarities and adaptive learning:\n Skyline v2.0 Equation by rainmanp7. Date of Completion 08/08/2023 1:20pm QuantumAI for Reinforced Machine Learning. Additional information added 11:16am 08/12/2023 with more details.\n wi = (wi0 / (1 + (vector_dij / τ))) * (1 + α * Ps + β * T + γ * M + δ * V + ε * MA + ζ * C + η * S + θ * Si + φ * Td_i + _cache[(wi0, dij, τ, learning_method_coefficients, complexity_factor, object_properties, position_relative_to_center)] + complexity_factor * (multithreaded_vector_pipeline(vector_data, T1, T2, ...) | pipeline | m…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15p0d9f/p_skyline_v20_equation_by_rainmanp7/",
          "publishedOn": "2023-08-12T09:47:53.000Z",
          "wordCount": 3287,
          "title": "[P] Skyline v2.0 Equation by rainmanp7",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ozwoj/p_semantic_search_using_chatbot/",
          "author": null,
          "description": "So basically what I need to do is build a chatbot that is able to identify user intents and \n 1) if the user is seeking information then perform semantic search to generate a response \n 2) if the user is seeking to perform some action (say, schedule an appointment) then collate all the information and push it to a database for appointments\n How do I build the chatbot such that it can identify different intents and either do 1) or 2)? What tools/technologies can I use?\n    submitted by    /u/hellohibyebye13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ozwoj/p_semantic_search_using_chatbot/",
          "publishedOn": "2023-08-12T09:21:05.000Z",
          "wordCount": 2593,
          "title": "[P] Semantic Search using Chatbot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15oy6i7/p_how_our_ai_junior_dev_reads_all_of_your/",
          "author": null,
          "description": "submitted by    /u/williamsweep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15oy6i7/p_how_our_ai_junior_dev_reads_all_of_your/",
          "publishedOn": "2023-08-12T07:42:05.000Z",
          "wordCount": 2528,
          "title": "[P] 🎓 How our AI junior dev reads all of your documentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ox8hv/p_allowing_hugging_faces/",
          "author": null,
          "description": "I recently made a proposed code change to allow Hugging Face's TextClassificationPipeline to take advantage of the sliding window-style text truncation provided by using the stride parameter, and taking a mean of output logits across all windows. Hugging Face has already implemented this for the TokenClassificationPipeline.\n E.g. if you want to use a Hugging Face-compatible model to run sentiment analysis on text, this would allow easily running that model on texts longer than the model's config.max_position_embeddings.\n If you support integrating this functionality into the \"transformers\" library, give a thumbs-up react to this comment on the relevant issue.\n    submitted by    /u/Revolutionary-Ad-65  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ox8hv/p_allowing_hugging_faces/",
          "publishedOn": "2023-08-12T06:48:35.000Z",
          "wordCount": 2615,
          "title": "[P] Allowing Hugging Face's TextClassificationPipeline to take documents longer than model max length",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15owo1b/r_incorrect_tensorflow_prediction_for_apple_m1_max/",
          "author": null,
          "description": "Hi,\n Unfortunately I’m unable to ask my questions on TensorFlow subreddit. I have installed MacOS TensorFlow and I have noticed that when I try to train on datasets such a as CelebFaces and Lego set with GPU I’m getting results that are very off. I have done some brief research and that seems to be happening for some other people I’m wondering if anyone has experience resolving the issue. Any advise or feedback is much appreciated.\n Thank you\n    submitted by    /u/Nuclearian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15owo1b/r_incorrect_tensorflow_prediction_for_apple_m1_max/",
          "publishedOn": "2023-08-12T06:15:16.000Z",
          "wordCount": 2591,
          "title": "[R] Incorrect TensorFlow Prediction For Apple M1 Max",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15otu64/r_is_it_possible_to_work_on_a_research_project_in/",
          "author": null,
          "description": "I am a full time ML engineer with a masters. I am keen on working on problems in depth and feel like taking a break and working on some ML research problems but I don’t want to go for a PhD(Don’t want to go through course work). Are there any programs offered by universities for working professionals to get research experience for a shorter window like 6 months or a year?\n    submitted by    /u/Brave-Revolution4441  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15otu64/r_is_it_possible_to_work_on_a_research_project_in/",
          "publishedOn": "2023-08-12T03:44:10.000Z",
          "wordCount": 2595,
          "title": "[R] Is it possible to work on a research project in a uni for 6 months or a year?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15os9hz/d_why_isnt_population_based_training_used_anymore/",
          "author": null,
          "description": "Been looking into training some large transformer models for vision applications, and am really interested to know why PBT isn't used anymore. Keeping compute constant, PBT appears to drastically improve optimization across the board at the cost of one or more of batch size/training steps/model complexity/other compute consuming factors. If the goal is to minimize validation loss as quickly as possible, isn't this tradeoff worth it?\n    submitted by    /u/clywac2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15os9hz/d_why_isnt_population_based_training_used_anymore/",
          "publishedOn": "2023-08-12T02:25:47.000Z",
          "wordCount": 2579,
          "title": "[D] Why isn't Population Based Training used anymore?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15opiln/d_thoughts_on_jon_krohns_machine_learning/",
          "author": null,
          "description": "Context:\n I'm teaching myself machine learning and right now I'm starting on the very core of it which is mathematics. For those who bought this course from Udemy, is this enough for real life ML problems?\n    submitted by    /u/Forsaken_Buy_7531  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15opiln/d_thoughts_on_jon_krohns_machine_learning/",
          "publishedOn": "2023-08-12T00:19:11.000Z",
          "wordCount": 2550,
          "title": "[D] Thoughts on Jon Krohns Machine Learning Mathematical Foundations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15oo45p/d_running_massive_language_models_with_petals/",
          "author": null,
          "description": "My observations and opinions on using Petals to run distributed LLMs, as a host and a user.\n https://yak.ventures/2023/08/11/distributed-llms-with-petals/\n I'd be very interested to talk to anyone that is utilizing a distributed model for daily use or for an application and even more interested to talk to anyone running a model among friends or colleagues in the private mode.\n    submitted by    /u/Ruleryak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15oo45p/d_running_massive_language_models_with_petals/",
          "publishedOn": "2023-08-11T23:19:15.000Z",
          "wordCount": 2570,
          "title": "[D] Running massive language models with Petals",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15onog4/r_hi_all_i_am_doing_a_research_paper_high_school/",
          "author": null,
          "description": "Here\n    submitted by    /u/TommZ5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15onog4/r_hi_all_i_am_doing_a_research_paper_high_school/",
          "publishedOn": "2023-08-11T23:01:18.000Z",
          "wordCount": 2539,
          "title": "[R] Hi all, I am doing a research paper (high school) on ethics in AI art. I would greatly appreciate it if you took the time to fill in this survey. Thank you",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ol20u/d_does_rlhf_increase_the_time_horizon_of_models/",
          "author": null,
          "description": "RL techniques in general have the ability to increase the time horizon of models since future rewards impact the Q value or advantage of the current action.\n My understanding of RLHF is a reward model is trained based on human feedback, and then the LLM is optimized to maximize the reward from the reward model. Is this correct?\n If so, does the reward model care about future rewards? Does this impact the time horizon?\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ol20u/d_does_rlhf_increase_the_time_horizon_of_models/",
          "publishedOn": "2023-08-11T21:19:02.000Z",
          "wordCount": 2588,
          "title": "[D] Does RLHF increase the time horizon of models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ojszo/d_confusion_in_the_dlbased_keras_embedding_and/",
          "author": null,
          "description": "I am new to this field and feeling quite confused. I need to use a DL-based Keras Embeddings technique with the Dense layer for text classification (specifically, a Binary Classification problem), along with TF-IDF featurization as input for the Random Forest Algorithm. However, my confusion arises from the fact that the Keras Embedding Layer also serves as a featurization technique. Therefore, I'm uncertain whether this layer should be used as input for the Random Forest or it has the capability to classify text on its own. Second question is that what can be the reason to use Dense Layer and What it is exactly here.\n    submitted by    /u/ZahidAlee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ojszo/d_confusion_in_the_dlbased_keras_embedding_and/",
          "publishedOn": "2023-08-11T20:31:42.000Z",
          "wordCount": 2620,
          "title": "[D] Confusion in the DL-based Keras Embedding and Dense Layer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ojgpf/does_this_cover_the_basicsnecessities_of_aiml_d/",
          "author": null,
          "description": "Hello.\n Trying to make a plan so I can chip away at stuff day-by-day over the next few months/year(s).\n I was wondering if I've classified everything in this diagram in the correct way or if I'm missing anything ?\n Reason I ask here is I'm not too sure if I'm missing anything obsecure or if I've misinterpreted anything ?\n Thank you !\n https://preview.redd.it/dqbgfbcthjhb1.png?width=4299&format=png&auto=webp&s=1ceb45c3e4237f2204151bfed7bf45b54e4a5d68\n    submitted by    /u/EngineerOwn6160  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ojgpf/does_this_cover_the_basicsnecessities_of_aiml_d/",
          "publishedOn": "2023-08-11T20:18:41.000Z",
          "wordCount": 2576,
          "title": "Does this cover the basics/necessities of AI/ML [D] ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ojfia/d_how_do_various_regularization_techniques_affect/",
          "author": null,
          "description": "I'm currently working through \"Understanding Deep Learning\" by Simon J.D. Prince. On page 403, he makes the following statement about regularization:\n  \nAnother possible explanation for the ease with which models are trained is that regularization makes the loss surface flatter and more convex.\n  \nFrom my understanding, L2 regularization (or weight decay) indeed adds a convex term λ∣∣w∣∣2 to the loss function, smoothing it out. Additionally, the Hessian matrix becomes more positive with the addition of the regularization term 2λI, giving the function a more convex characteristic.\n However, I'm puzzled as to how other regularization methods like Dropout, L1/Lasso, or Early Stopping might lead to a similarly flatter and more convex loss surface. Can anyone offer insights or explanations on this?\n    submitted by    /u/spontanurlaub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ojfia/d_how_do_various_regularization_techniques_affect/",
          "publishedOn": "2023-08-11T20:17:22.000Z",
          "wordCount": 2635,
          "title": "[D] How Do Various Regularization Techniques Affect the Loss Surface?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15oic7a/d_lessons_from_this_years_neurips/",
          "author": null,
          "description": "This years Neurips has been a rollercoaster for everyone involved.\n Petar Veličković says that in their AC batch 65% submitted no rebuttal or withdrew.\n https://twitter.com/PetarV_93/status/1689648854646575105\n Xin Eric Wang says in their batch pre-rebuttal no papers had an avg score above an weak accept.\n https://twitter.com/xwang_lk/status/1686517898108674048\n Will NeurIPS keep 25% acceptance rate? What do you think will happen to neurips in light of the above? Is this the end of big ML confs?\n ​\n    submitted by    /u/SuchOccasion457  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15oic7a/d_lessons_from_this_years_neurips/",
          "publishedOn": "2023-08-11T19:34:45.000Z",
          "wordCount": 2582,
          "title": "[D] Lessons from this years Neurips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15oh6me/r_3d_gaussian_splatting_for_realtime_radiance/",
          "author": null,
          "description": "submitted by    /u/individual_kex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15oh6me/r_3d_gaussian_splatting_for_realtime_radiance/",
          "publishedOn": "2023-08-11T18:50:28.000Z",
          "wordCount": 2525,
          "title": "[R] 3D Gaussian Splatting for Real-Time Radiance Field Rendering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15oh6cw/d_implementing_siamese_network_with/",
          "author": null,
          "description": "Hi!\n I have been trying to find a good guide of how best to implement a Sentence Transformers style model using Keras, but have not found anything :(\n I have managed to get something running, but I am not sure it is pretty and wanted to see if anyone know how to improve it or maybe has seen a nice implementation on the web?\n Here is my first draft https://gist.github.com/ydennisy/fec55fab84d107b72852ba2d2c2b61db\n    submitted by    /u/Suspicious_Dress_350  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15oh6cw/d_implementing_siamese_network_with/",
          "publishedOn": "2023-08-11T18:50:12.000Z",
          "wordCount": 2583,
          "title": "[D] Implementing siamese network with MultipleNegativesRankingLoss in Keras/TF",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ogvp4/d_how_does_lora_save_memory_footprint_for/",
          "author": null,
          "description": "I can understand part of the statement if you are using Adam. Since the trainable params are much less, we are saving on optimizer states. However, even we are not actually updating the pretrained model, we still need to compute the graidients for backpropagation to the lower layer of the lora head. The memory usage of gradients would not decrease. Please correct me if I am wrong. \n    submitted by    /u/Chen806  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ogvp4/d_how_does_lora_save_memory_footprint_for/",
          "publishedOn": "2023-08-11T18:38:39.000Z",
          "wordCount": 2581,
          "title": "[D] How does Lora save memory footprint for transformers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15oguh9/dhow_to_improve_yolo_v8_model_performance/",
          "author": null,
          "description": "Hi everyone! I'm working on a model using YOLO v8x to detect regions on identity cards, but it struggles with identifying address regions. This issue seems to stem from insufficient data. Would it be advisable to incorporate additional data containing addresses(other documents instead of identity card) to enhance the model's accuracy in detecting address regions?\n    submitted by    /u/Ordinary_Run_2513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15oguh9/dhow_to_improve_yolo_v8_model_performance/",
          "publishedOn": "2023-08-11T18:37:15.000Z",
          "wordCount": 2568,
          "title": "[D]How to Improve YOLO v8 model performance ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ogmyj/d_why_does_using_multiple_gpus_lead_to_slower/",
          "author": null,
          "description": "I read that using multiple gpus can improve inference performance, but I'm not sure why for my inference, its actually slower as I increase tensor_parallel_size. I know data transfer overhead and limited parallelism could be potential issues, are there ways to rectify this\n vllm = LLM( model=\"mosaicml/mpt-7b-instruct\", trust_remote_code=True, dtype=\"float16\", tensor_parallel_size=1, gpu_memory_utilization=.95, ) CPU times: user 3.66 s, sys: 262 ms, total: 3.93 s Wall time: 1.11 s vllm = LLM( model=\"mosaicml/mpt-7b-instruct\", trust_remote_code=True, dtype=\"float16\", tensor_parallel_size=2, gpu_memory_utilization=.95, ) CPU times: user 65.5 ms, sys: 32.2 ms, total: 97.7 ms Wall time: 1.27 s \n ​\n    submitted by    /u/candyman54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ogmyj/d_why_does_using_multiple_gpus_lead_to_slower/",
          "publishedOn": "2023-08-11T18:29:12.000Z",
          "wordCount": 2606,
          "title": "[D] Why does using multiple gpus lead to slower performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ogknd/d_how_we_evaluated_llms_in_prod/",
          "author": null,
          "description": "This is going to be a post about the challenges I faced while working with ChatGPT in my previous company and the things we did to overcome them over a 2+ month struggle. Check us out at www.twilix.io if anything below resonates with you and I hope you find some of it helpful.\n So to begin, in my previous company we invested a few months building a chatbot to help with user onboarding. At first everything was great, and we saw a 40% decrease in drop-off rates (which is significant given we were building a consumer facing app), but somehow over time this drop-off rate started creeping up again. Perplexed by the unexpected turn in metrics, management started to question the benefits of maintaining this chatbot and was skeptical that we were cherry picking examples to showcase its performance…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ogknd/d_how_we_evaluated_llms_in_prod/",
          "publishedOn": "2023-08-11T18:26:43.000Z",
          "wordCount": 3061,
          "title": "[D] How we evaluated LLMs in prod",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ofqzt/d_train_stable_diffusionlatent_diffusion_from/",
          "author": null,
          "description": "I'm currently in the process of developing a stable diffusion/latent diffusion model entirely from scratch. However, I'm a bit confused from the documentation of the original repositories (both from CompVis). My intention is to experiment with significantly smaller models and datasets while retaining the same architecture. Unfortunately, neither repository offers an official configuration for training the txt2img architecture.Through my exploration of the issues, I've observed that the training script provided by the latent diffusion repository does support txt2img (although an official configuration has not been made available yet). I'm curious if any of you might be familiar with better online resources or tutorials that can provide a clearer and more comprehensive understanding of the training process.\n    submitted by    /u/Arabum97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ofqzt/d_train_stable_diffusionlatent_diffusion_from/",
          "publishedOn": "2023-08-11T17:55:38.000Z",
          "wordCount": 2628,
          "title": "[D] Train Stable Diffusion/Latent diffusion from scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15of7lz/r_tiny_lvlmehub_early_multimodal_experiments_with/",
          "author": null,
          "description": "Paper: https://github.com/OpenGVLab/Multi-Modality-Arena\n Github: https://github.com/OpenGVLab/Multi-Modality-Arena\n Abstract:\n  \nRecent advancements in Large Vision-Language Models (LVLMs) have demonstrated significant progress in tackling complex multimodal tasks. Among these cutting-edge developments, Google's Bard stands out for its remarkable multimodal capabilities, promoting comprehensive comprehension and reasoning across various domains. This work presents an early and holistic evaluation of LVLMs' multimodal abilities, with a particular focus on Bard, by proposing a lightweight variant of LVLM-eHub, named Tiny LVLM-eHub. In comparison to the vanilla version, Tiny LVLM-eHub possesses several appealing properties. Firstly, it provides a systematic assessment of six categories of multimodal capabilities, including visual perception, visual knowledge acquisition, visual reasoning, visual commonsense, object hallucination, and embodied intelligence, through quantitative evaluation of 42 standard text-related visual benchmarks. Secondly, it conducts an in-depth analysis of LVLMs' predictions using the ChatGPT Ensemble Evaluation (CEE), which leads to a robust and accurate evaluation and exhibits improved alignment with human evaluation compared to the word matching approach. Thirdly, it comprises a mere 2.1K image-text pairs, facilitating ease of use for practitioners to evaluate their own offline LVLMs. Through extensive experimental analysis, this study demonstrates that Bard outperforms previous LVLMs in most multimodal capabilities except object hallucination, to which Bard is still susceptible. Tiny LVLM-eHub serves as a baseline evaluation for various LVLMs and encourages innovative strategies aimed at advancing multimodal techniques. \n  \nhttps://preview.redd.it/i6x6p5bloihb1.jpg?width=1485&format=pjpg&auto=webp&s=7e91fe184844278b0a7e14090ae9aaef54b29f37\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15of7lz/r_tiny_lvlmehub_early_multimodal_experiments_with/",
          "publishedOn": "2023-08-11T17:35:19.000Z",
          "wordCount": 2746,
          "title": "[R] Tiny LVLM-eHub: Early Multimodal Experiments with Bard - OpenGVLab, Shanghai AI Laboratory 2023 - Encourages innovative strategies aimed at advancing multimodal techniques!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15of3ix/p_gpt_sequence_classification_explainability_or/",
          "author": null,
          "description": "I’m using GPT-2 for Sequence Classification. I want to understand the words or sequences that lead to the predictions. Can you point me towards any papers, repos or libraries?\n    submitted by    /u/how_the_turn_tablez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15of3ix/p_gpt_sequence_classification_explainability_or/",
          "publishedOn": "2023-08-11T17:31:03.000Z",
          "wordCount": 2541,
          "title": "[P] GPT Sequence Classification explainability or interpretability",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15obkax/d_whats_is_everyones_outlook_on_ai_swarms_does_it/",
          "author": null,
          "description": "I've been researching AI swarms, and it seems to make more sense to have a lot of smaller models doing tasks separately. Thoughts?\n    submitted by    /u/deepengineai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15obkax/d_whats_is_everyones_outlook_on_ai_swarms_does_it/",
          "publishedOn": "2023-08-11T15:12:26.000Z",
          "wordCount": 2548,
          "title": "[D] What's is everyones outlook on AI swarms? Does it hold promise, or are larger systems going to be dominant?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15o8x8h/d_is_hidden_size_in_current_transformers_an/",
          "author": null,
          "description": "Hi,\n I have written a post discussion whether or not the hidden size in transformers is an overkill. \n TLDR;\n I show that an embedding size of 2048 is too much to represent just one token like `is` but rather, it can encode an average 8 tokens with up-to 16 tokens almost losslessly. \n I think if we can design more compute efficient transformers with some of the ideas that I explore in the post.\n Of course this is not a proper research with ablation studies and empirical analysis. But I would love to hear your thoughts on this topic.\n    submitted by    /u/NaxAlpha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15o8x8h/d_is_hidden_size_in_current_transformers_an/",
          "publishedOn": "2023-08-11T13:26:51.000Z",
          "wordCount": 2612,
          "title": "[D] Is Hidden Size in current transformers an overkill?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15o7mbx/p_using_machine_learning_for_accesibility/",
          "author": null,
          "description": "Personal Shelf Inspector is an application that helps visually impaired people during their day-to-day shopping. The application is based on a simple neural network and was created as a part of the AI for Accesibility Hackathon in 2020 in Prague.\n We decided to build free tools that make shopping for visually impaired people more accessible. These tools can be implemented in any retail chain within the loyalty app or in-store. \n ​\n https://preview.redd.it/ehoxec5l4hhb1.png?width=1072&format=png&auto=webp&s=c96a5dd326cbfc8dd9bde9d84d45167d172ea27d\n The Idea\n A visually impaired person only needs their smartphone to use our tools. Personal Shelf Inspector is a web application that reads the price and product name from a price tag. The algorithm selects the price tag closest to the centre of the photo and sends it to the model, which reads the price and product name on the price tag. Then it returns this information to the application, which appears as text on the screen.\n ​\n https://preview.redd.it/e098rtcn4hhb1.png?width=845&format=png&auto=webp&s=73a216ebf987e476d52091717ac156ac56daa29b\n The voice-over built into the user's mobile phone reads this text aloud. The app also helps to read the banknote values and read from a live video.\n What could be other cool ideas and concepts to help making the world more accesible using AI and Machine Learning? \n Feel free to share comments and impressions in the comments\n    submitted by    /u/DataSentics  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15o7mbx/p_using_machine_learning_for_accesibility/",
          "publishedOn": "2023-08-11T12:30:02.000Z",
          "wordCount": 2723,
          "title": "[P] Using Machine Learning for Accesibility: Personal AI Shelf Inspector for Visually Impaired Persons",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15o6h7p/research_how_instructblips_authors_do_the/",
          "author": null,
          "description": "In \"InstructBLIP\" paper, authors say: \"We transform 26 datasets into the instruction tuning format\" in order to create a general-purpose vision language model via instruction tuning. However, they did not provide details on how they did this transformation. At a first glance, three ways come to mind:\n  \nThey use ChatGPT/GPT-4 to automatically transform them.\n They define and code rules to automatically transform them.\n They manually transform them (highly improbable)\n  \nSomeone knows the answer? Thank you so much\n    submitted by    /u/jrodriguezortega  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15o6h7p/research_how_instructblips_authors_do_the/",
          "publishedOn": "2023-08-11T11:35:46.000Z",
          "wordCount": 2593,
          "title": "[Research] How InstructBLIP's authors do the datasets transformation to instruction data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15o60pa/r_opensource_machine_learning_in_computational/",
          "author": null,
          "description": "We wrote a perspective on open source machine learning in computational chemistry in JCIM_JCTC. It was an incredible amount of work and I hope readers will find it useful and educational.\n https://pubs.acs.org/doi/10.1021/acs.jcim.3c00643\n If you need a preprint, you can find it on Researchgate.\n https://www.researchgate.net/publication/372470285_Open-Source_Machine_Learning_in_Computational_Chemistry\n    submitted by    /u/poorgenes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15o60pa/r_opensource_machine_learning_in_computational/",
          "publishedOn": "2023-08-11T11:13:18.000Z",
          "wordCount": 2556,
          "title": "[R] Open-Source Machine Learning in Computational Chemistry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15o34ts/r_neural_wave_machines_learning_spatiotemporally/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15o34ts/r_neural_wave_machines_learning_spatiotemporally/",
          "publishedOn": "2023-08-11T08:34:47.000Z",
          "wordCount": 2531,
          "title": "[R] Neural Wave Machines: Learning Spatiotemporally Structured Representations with Locally Coupled Oscillatory Recurrent Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15o2rlk/d_single_board_computer_with_accelerator_as_a/",
          "author": null,
          "description": "Does anybody have a good recommendation for an SBC with AI accelerator (NPU) where I could attach a camera and train some YOLO models on the device itself for object recognition?\n    submitted by    /u/LM1117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15o2rlk/d_single_board_computer_with_accelerator_as_a/",
          "publishedOn": "2023-08-11T08:13:36.000Z",
          "wordCount": 2546,
          "title": "[D]: Single Board Computer with accelerator as a hobby project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nr8j3/d_openai_api_function_calling/",
          "author": null,
          "description": "How do you think OpenAI implemented the function calling feature, It seems like another contextual generation piece from the look of it but any interesting ideas and papers around this topic?\n    submitted by    /u/neuro_boogie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nr8j3/d_openai_api_function_calling/",
          "publishedOn": "2023-08-10T22:55:52.000Z",
          "wordCount": 2541,
          "title": "[D] OpenAI API function calling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15noqwr/llms_challenges_and_approaches_panel_n/",
          "author": null,
          "description": "​\n https://preview.redd.it/wl1gtcngnchb1.jpg?width=1500&format=pjpg&auto=webp&s=24e35d852603c6139fd67f79457ec593fbad99f7\n If you're someone who's curious about or working with LLMs there's a cool panel discussion coming up: \n  \nComparing the pros and cons of using existing LLMs, prompt engineering, and fine-tuning on custom datasets for different enterprise use cases.\n Fine-Tuning LLMs: Exploring the advantages and challenges of fine-tuning LLMs on custom datasets to align with specific business objectives.\n Tools and platforms: Discussing the various tools and platforms to facilitate LLM implementation \n Overcoming Challenges: Addressing the challenges associated with adopting LLMs, including data privacy, creating high quality datasets, computational resources, ethical considerations, and the need for specialized expertise.\n Future Directions: Exploring emerging trends, advancements, and potential future applications of LLMs in the enterprise context.\n  \nHere's the event info: https://www.eventbrite.com/e/large-language-models-for-enterprise-success-challenges-and-approaches-tickets-695089811337?aff=oddtdtcreator\n    submitted by    /u/UpstairsLeast7642  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15noqwr/llms_challenges_and_approaches_panel_n/",
          "publishedOn": "2023-08-10T21:18:46.000Z",
          "wordCount": 2628,
          "title": "LLMs Challenges and Approaches Panel [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15no3vz/d_list_of_awesome_ai_agents_like_autogpt_and/",
          "author": null,
          "description": "Github: https://github.com/e2b-dev/awesome-ai-agents and https://github.com/EmbraceAGI/Awesome-AGI \n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15no3vz/d_list_of_awesome_ai_agents_like_autogpt_and/",
          "publishedOn": "2023-08-10T20:54:17.000Z",
          "wordCount": 2526,
          "title": "[D] List of Awesome AI Agents like AutoGPT and BabyAGI / Many open-source Agents with code included!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nmgdb/d_record_labels_are_monetizing_aicreated_music/",
          "author": null,
          "description": "Google and Universal Music are discussing licensing artists' voices and melodies to develop AI-generated songs fans can create and pay for, seeking to get ahead of the controversial \"deepfake\" music trend. Though some stars oppose their work being mimicked, artists could opt-in to receive royalties in a model akin to how YouTube now pays for user-generated content.\n For Google, AI music would boost its generative AI offerings against competitors. But significant ethical hurdles around consent and IP must still be addressed in developing a legitimate AI music market.\n    submitted by    /u/Yavero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nmgdb/d_record_labels_are_monetizing_aicreated_music/",
          "publishedOn": "2023-08-10T19:51:20.000Z",
          "wordCount": 2606,
          "title": "[D] 🎹 Record Labels are monetizing AI-created Music after trying to kill it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nlhje/d_transformers_for_video_activity_recognition/",
          "author": null,
          "description": "I am trying to work with the UCF crime dataset and want to use transformers for video activity recognition, Does anyone have pointers to example projects as to which ones are good starting points?\n    submitted by    /u/bluzkluz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nlhje/d_transformers_for_video_activity_recognition/",
          "publishedOn": "2023-08-10T19:14:33.000Z",
          "wordCount": 2545,
          "title": "[d] transformers for video activity recognition?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nkirl/p_i_ran_llama_2_on_my_mac_in_5_mins/",
          "author": null,
          "description": "So Llama 2 sounds awesome, but I really wanted to run it locally on my Macbook Pro instead of on a Linux box with an NVIDIA GPU. So I put the llama.cpp GGML models into the XetHub Llama 2 repo so I can use the power of Llama 2 locally. It now takes me 5 seconds to mount Llama 2 and it loads the GGML model almost instantly. Here’s how I did it:\n  \nCreate an account: Go to xethub.com and Sign In with GitHub\n Quick start: Go to xethub.com/explore/quickstart and follow the Install & Setup steps (xethub.com/explore/install)\n pip install pyxet for Python SDK and CLI\n Set up authentication: Create a Personal Access Token and then run the login command from a Terminal so your ~/.xetconfig is set up with your login token.\n  \nHere’s the code to get Llama 2 up and running on your Mac laptop in a few …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nkirl/p_i_ran_llama_2_on_my_mac_in_5_mins/",
          "publishedOn": "2023-08-10T18:37:17.000Z",
          "wordCount": 3452,
          "title": "[P] I ran Llama 2 on my Mac in < 5 mins",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nkdq2/r_benchmarking_g512xlarge_4xa10_vs_1xa100/",
          "author": null,
          "description": "Hi Reddit folks, I wanted to share some benchmarking data I recently compiled running upstage_Llama-2-70b-instruct-v2 on two different hardware setups. If you'd like to see the spreadsheet with the raw data you can check out this link.\n Hardware Config #1: AWS g5.12xlarge - 4 x A10 w/ 96GB VRAM\n Hardware Config #2: Vultr - 1 x A100 w/ 80GB VRAM\n A few questions I wanted to answer:\n  \nHow does the inference speed (tokens/s) between these two configurations compare?\n How does the number of input tokens impact inference speed?\n How many input tokens can these machines handle before they start to hit OOM?\n How does 4-bit vs 8-bit quantization affect all of the above?\n  \nWhy this model?\n I chose upstage_Llama-2-70b-instruct-v2 because it's the current #1 performing OS model on HuggingFace's LLM…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nkdq2/r_benchmarking_g512xlarge_4xa10_vs_1xa100/",
          "publishedOn": "2023-08-10T18:31:51.000Z",
          "wordCount": 3016,
          "title": "[R] Benchmarking g5.12xlarge (4xA10) vs 1xA100 inference performance running upstage_Llama-2-70b-instruct-v2 (4-bit & 8-bit)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nitva/r_discovering_adaptable_symbolic_algorithms_from/",
          "author": null,
          "description": "Autonomous robots deployed in the real world will need control policies that rapidly adapt to environmental changes. To this end, we propose AutoRobotics-Zero (ARZ), a method based on AutoML-Zero that discovers zero-shot adaptable policies from scratch. In contrast to neural network adaption policies, where only model parameters are optimized, ARZ can build control algorithms with the full expressive power of a linear register machine. We evolve modular policies that tune their model parameters and alter their inference algorithm on-the-fly to adapt to sudden environmental changes. We demonstrate our method on a realistic simulated quadruped robot, for which we evolve safe control policies that avoid falling when individual limbs suddenly break. This is a challenging task in which two popular neural network baselines fail. Finally, we conduct a detailed analysis of our method on a novel and challenging non-stationary control task dubbed Cataclysmic Cartpole. Results confirm our findings that ARZ is significantly more robust to sudden environmental changes and can build simple, interpretable control policies.\n Paper: https://arxiv.org/abs/2307.16890\n Video: https://youtu.be/sEFP1Hay4nE\n    submitted by    /u/VishDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nitva/r_discovering_adaptable_symbolic_algorithms_from/",
          "publishedOn": "2023-08-10T17:33:18.000Z",
          "wordCount": 2684,
          "title": "[R] Discovering Adaptable Symbolic Algorithms from Scratch - Google and MSU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15niph3/r_on_hate_scaling_laws_for_dataswamps/",
          "author": null,
          "description": "submitted by    /u/VishDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15niph3/r_on_hate_scaling_laws_for_dataswamps/",
          "publishedOn": "2023-08-10T17:28:53.000Z",
          "wordCount": 2523,
          "title": "[R} On Hate Scaling Laws For Data-Swamps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nilpw/r_heatassisted_detection_and_ranging_nature/",
          "author": null,
          "description": "Machine perception uses advanced sensors to collect information about the surrounding scene for situational awareness. State-of-the-art machine perception using active sonar, radar, and LiDAR to enhance camera vision faces difficulties when the number of intelligent agents scales up. Exploiting omnipresent heat signals could be a new frontier for scalable perception. However, objects and their environment constantly emit and scatter thermal radiation, leading to textureless images famously known as the ‘ghosting effect’. Thermal vision thus has no specificity limited by information loss, whereas thermal ranging—crucial for navigation—has been elusive even when combined with artificial intelligence (AI). Here, we propose and experimentally demonstrate heat-assisted detection and ranging (HADAR) overcoming this open challenge of ghosting and benchmark it against AI-enhanced thermal sensing. HADAR not only sees texture and depth through the darkness as if it were day but also perceives decluttered physical attributes beyond RGB or thermal vision, paving the way to fully passive and physics-aware machine perception. We develop HADAR estimation theory and address its photonic shot-noise limits depicting information-theoretic bounds to HADAR-based AI performance. HADAR ranging at night beats thermal ranging and shows an accuracy comparable with RGB stereovision in daylight. Our automated HADAR thermography reaches the Cramér–Rao bound on temperature accuracy, beating existing thermography techniques. Our work leads to a disruptive technology that can accelerate the Fourth Industrial Revolution (Industry 4.0) with HADAR-based autonomous navigation and human–robot social interactions.\n Paper: https://www.nature.com/articles/s41586-023-06174-6\n Video: https://youtu.be/WKrzmaixAC0\n    submitted by    /u/VishDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nilpw/r_heatassisted_detection_and_ranging_nature/",
          "publishedOn": "2023-08-10T17:24:58.000Z",
          "wordCount": 2745,
          "title": "[R] Heat-assisted detection and ranging - Nature",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nhxfz/d_is_everything_just_transformers_now/",
          "author": null,
          "description": "I was watching this talk where they were showing that basically every task in machine learning has been replaced by the transformer architecture. For instance, where a convolution neural network might have been used for image recognition in the past, the predominant strategy now is just to use a transformer instead. How true is this? Is it worth learning any other architecture than transformers for current state of the art research?\n    submitted by    /u/Active-Confidence926  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nhxfz/d_is_everything_just_transformers_now/",
          "publishedOn": "2023-08-10T16:59:33.000Z",
          "wordCount": 2582,
          "title": "[D] Is everything just transformers now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ngux6/d_is_latent_ode_an_imputation_model/",
          "author": null,
          "description": "Hello,\n Is Latent ODE an imputation model? If so, how does it handle missing values in the case of irregular sampled time series data? \n Latent ODE - Latent ODEs for Irregularly-Sampled Time Series (https://arxiv.org/abs/1907.03907)\n    submitted by    /u/flaubart9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ngux6/d_is_latent_ode_an_imputation_model/",
          "publishedOn": "2023-08-10T16:18:07.000Z",
          "wordCount": 2546,
          "title": "[D] Is Latent ODE an imputation model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nf7dv/p_txtai_60_the_allinone_embeddings_database/",
          "author": null,
          "description": "txtai is an all-in-one embeddings database for semantic search, LLM orchestration and language model workflows. \n This major release adds sparse, hybrid and subindexes to the embeddings interface. It also makes significant improvements to the LLM pipeline workflow.\n See links below for more.\n GitHub: https://github.com/neuml/txtai\n Release Notes: https://github.com/neuml/txtai/releases/tag/v6.0.0\n Article: https://medium.com/neuml/whats-new-in-txtai-6-0-7d93eeedf804\n    submitted by    /u/davidmezzetti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nf7dv/p_txtai_60_the_allinone_embeddings_database/",
          "publishedOn": "2023-08-10T15:14:16.000Z",
          "wordCount": 2560,
          "title": "[P] txtai 6.0 - the all-in-one embeddings database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15neh6k/d_ideal_embedding_models_for_classifying_news/",
          "author": null,
          "description": "I’m looking to build functionality that would allow a user to specify topics to be notified about in the news, eg. “Tax law changes in New York”, and notify them of recently published news articles related to that topic.\n Would the ideal strategy be to find relating articles to topics, or topics relating to articles as they come in? What models would be ideal here? I’m fairly new to this, so any help would be appreciated.\n    submitted by    /u/ByteBuff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15neh6k/d_ideal_embedding_models_for_classifying_news/",
          "publishedOn": "2023-08-10T14:45:10.000Z",
          "wordCount": 2594,
          "title": "[D] Ideal embedding models for classifying news articles to topics, specified as sentences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15nd1zp/d_intermediateadvanced_aiml_bootcamps/",
          "author": null,
          "description": "Long time listener, first time caller. \n I am looking to spearhead the impending transition of understanding AI/ML at my organization and am looking for community suggestions in courses and bootcamps that could provide a deeper knowledge for some of my work projects in the future. Specifically, I feel unequipped in how to properly test and validate models. \n I have a computer science background with strong skills in data analytics and programming. I’ve also taken several introductory courses at a high level for AI. \n Does anyone have suggestions or experiences for 1-4 week long bootcamps or intensive courses? I prefer in-person (anywhere in US) but would also consider live-online remote courses. Price is not a concern. \n Thanks in advance.\n    submitted by    /u/DungeonsGalore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15nd1zp/d_intermediateadvanced_aiml_bootcamps/",
          "publishedOn": "2023-08-10T13:48:35.000Z",
          "wordCount": 2627,
          "title": "[D] Intermediate/Advanced AI/ML Bootcamps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15natmn/p_ai_hackathon_project_ideasnlp_based/",
          "author": null,
          "description": "so, there is an AI Hackathon coming up next week. This gonna be my first hackathon and wanna win too, however i donot know what to build in \"health sector and Open tech\". I have few experience in NLP. Kindly please suggest any which can be build in 24hrs period. \n    submitted by    /u/Suspicious-Row-8804  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15natmn/p_ai_hackathon_project_ideasnlp_based/",
          "publishedOn": "2023-08-10T12:13:53.000Z",
          "wordCount": 2562,
          "title": "[P] . AI hackathon project ideas(NLP based)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15n9rt3/p_flexible_object_detection_of_unknown_objects/",
          "author": null,
          "description": "I'm basically trying to create an object detection system that learns the more objects it sees. My problem is that object detection requires actualy objects that the AI will be able to put into a certain category to identify the object.\n I want to make an AI that is able to find out that there is an object, but it shouldnt need to know what the object is. I want the AI to be able to find objects in an image in realtime without needing to know what the object is. It's supposed to grasp the concept of what an object is. Are there any methods or datasets that would make something like this possible?\n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15n9rt3/p_flexible_object_detection_of_unknown_objects/",
          "publishedOn": "2023-08-10T11:26:05.000Z",
          "wordCount": 2627,
          "title": "[P] Flexible object detection of unknown objects.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15n8h1h/navigating_data_issues_with_cleanlab_and/",
          "author": null,
          "description": "The complete code of this article and other articles about handling data issues is available in the accompanying notebook on GitHub.\n Data cleaning, a crucial step in machine learning, addresses challenges like mislabeled examples, outliers, and duplicates. Our newest article features:\n  \nCleanlab: A tool that uses confident learning techniques to detect data issues.\n Spotlight by Renumics: An advanced visualization tool to review and explore the data issues detected by Cleanlab. It provides interactive features like the Similarity Map for pinpointing problem clusters.\n  \nThe article showcases the integration of these tools using the CIFAR-100 dataset. It details:\n  \nDetecting three main issues: label inconsistencies, outliers, and near-duplicates.\n Spotlight's interactive environment to review these detected problems.\n Using the similarity map to navigate and understand the data, making it easier to identify and address issues.\n  \nFull Article: Navigate Data Issues: Interactively explore results of Cleanlab with Renumics Spotlight\n    submitted by    /u/DocBrownMS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15n8h1h/navigating_data_issues_with_cleanlab_and/",
          "publishedOn": "2023-08-10T10:21:03.000Z",
          "wordCount": 2657,
          "title": "Navigating Data Issues with Cleanlab and Spotlight [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15n5hcu/d_language_retrieval_models_explained_simply/",
          "author": null,
          "description": "What are language retrieval models exactly?\n I've been hearing more and more of those in the context of not needing embeddings retrieval and putting useful text in the system prompt.\n How do they work in simple terms?\n    submitted by    /u/Specialist_Ice_5715  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15n5hcu/d_language_retrieval_models_explained_simply/",
          "publishedOn": "2023-08-10T07:34:27.000Z",
          "wordCount": 2547,
          "title": "[D] Language retrieval models explained simply",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15n4no0/d_can_we_get_a_tag_or_a_weekly_mega_thread_for/",
          "author": null,
          "description": "Seeing a flood of career related questions on here, most of which have been asked and answered ad nauseum before. Can we get a tag for them to filter out or compile them all in a weekly mega thread so it doesn’t clog up the main feed?\n    submitted by    /u/pavelysnotekapret  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15n4no0/d_can_we_get_a_tag_or_a_weekly_mega_thread_for/",
          "publishedOn": "2023-08-10T06:49:03.000Z",
          "wordCount": 2566,
          "title": "[D] Can we get a tag or a weekly mega thread for career-related questions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15n3mna/d_applied_ml_for_cv_or_slam/",
          "author": null,
          "description": "Hey people, this time I am asking for your opinion. I am in automotive. I know ML very well due to personal projects but so far in my 5 years I never had the opportunity of applying it in the industry so I built expertise in classic CV Modelling instead. \n Now there is an opportunity to work on newer topics like data generation, dataset curation or even ML based Fusion. Nevertheless I also got the opportunity to do SLAM and it excites me a lot because of the many things involved in it and the possibility to use parallelization and so on. What could be a nice strategy here in your opinion and why? I thank you all!\n    submitted by    /u/tricostume  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15n3mna/d_applied_ml_for_cv_or_slam/",
          "publishedOn": "2023-08-10T05:53:28.000Z",
          "wordCount": 2630,
          "title": "[D] Applied ML for CV or SLAM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15n1j52/d_training_a_model_for_function_calls/",
          "author": null,
          "description": "would it be possible to train or fine-tune a small (1-3B) model who's sole purpose is to perform function calls? similar to how we have tiny models like replit-v2-3B that are super capable at specific things like code auto-complete . \n i know that's how openAI implemented function call was by fine-tuning gpt-3.5/4 but I'm thinking just a straight up base model trained to understand and excel at function calls (similar to Gorilla for apis)\n i'm thinking it would be a perfect \"glue\" for bigger LLM apps-- avoiding the need for external tools like langchain/quidance/etc...\n    submitted by    /u/LyPreto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15n1j52/d_training_a_model_for_function_calls/",
          "publishedOn": "2023-08-10T04:05:24.000Z",
          "wordCount": 2606,
          "title": "[D] training a model for function calls",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mtj1y/neurips_rebuttal_character_limit_problem_d/",
          "author": null,
          "description": "The NeurIPS rebuttal has a 6000 character limit, however my rebuttal is way way over that. I was told by my supervisor that you could just comment chain onto the rebuttal to get past this, however that is not working.\n The deadline is in around 5 hours so I'm really in a big bind here. Does anyone have any insight about how to resolve this situation?\n    submitted by    /u/Pyramid_Jumper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mtj1y/neurips_rebuttal_character_limit_problem_d/",
          "publishedOn": "2023-08-09T22:20:27.000Z",
          "wordCount": 2569,
          "title": "NeurIPS rebuttal character limit problem [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ms0cq/get_into_ml_role_d/",
          "author": null,
          "description": "Hey guys, I am working as an SDET amd previously work as a developer. I am currently enrolled in Machine Learning masters online with job with Learning each course I am not sure how to get into the job market for this role. What projects should I create, kaggle seems to be just copy paste from each other.Any suggestions?\n    submitted by    /u/Latter_Ad_5679  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ms0cq/get_into_ml_role_d/",
          "publishedOn": "2023-08-09T21:23:35.000Z",
          "wordCount": 2561,
          "title": "Get into ML role [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mr16l/is_a_good_idea_to_do_leetcode_for_computer_and/",
          "author": null,
          "description": "It is something that sounds too much lately but I'm not sure about if it worths for those areas.\n    submitted by    /u/Otherwise-Bike4761  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mr16l/is_a_good_idea_to_do_leetcode_for_computer_and/",
          "publishedOn": "2023-08-09T20:47:40.000Z",
          "wordCount": 2529,
          "title": "Is a good idea to do leetcode for Computer and Data scientist? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mqe4r/d_ideal_embedding_models_for_classifying_news/",
          "author": null,
          "description": "I’m looking to build functionality that would allow a user to specify topics to be notified about in the news, eg. “Tax law changes in New York”, and notify them of recently published news articles related to that topic.\n Would the ideal strategy be to find relating articles to topics, or topics relating to articles as they come in? What models would be ideal here? I’m fairly new to this, so any help would be appreciated.\n    submitted by    /u/ByteBuff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mqe4r/d_ideal_embedding_models_for_classifying_news/",
          "publishedOn": "2023-08-09T20:23:12.000Z",
          "wordCount": 2586,
          "title": "[D] Ideal embedding models for classifying news articles to topics, specified as sentences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mph12/simple_synthetic_data_reduces_sycophancy_in_llms_r/",
          "author": null,
          "description": "submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mph12/simple_synthetic_data_reduces_sycophancy_in_llms_r/",
          "publishedOn": "2023-08-09T19:49:03.000Z",
          "wordCount": 2516,
          "title": "Simple synthetic data reduces sycophancy in LLMs [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15moc4k/d_does_it_make_sense_to_switch_to_premoderation/",
          "author": null,
          "description": "Moderators are doing a great job, but often by the time a post is deleted it already hit too many eyeballs. Now that everyone and their mom are into AI, does it make sense to switch to premoderation for new members and members who do not follow the rules of the subreddit?\n    submitted by    /u/lostmsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15moc4k/d_does_it_make_sense_to_switch_to_premoderation/",
          "publishedOn": "2023-08-09T19:05:58.000Z",
          "wordCount": 2558,
          "title": "[D] Does it make sense to switch to premoderation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mnbxc/d_seeking_insights_and_collaboration_on_deep/",
          "author": null,
          "description": "This project is the culmination of genuine effort and innovation by a team of dedicated professionals. We welcome constructive feedback and value your insights to help us improve and grow. Thank you for engaging with us respectfully.\n Hello AI and blockchain enthusiasts!\n I'm part of the team at Deep Engine AI, where we are working on an exciting project that involves building a Universal Adaptive Intelligence System (UAIS). One of our key concepts is what we're calling \"Pervasive Swarm Learning.\" It's a blend of holistic swarm intelligence models, community-managed ecosystems, and innovative algorithms.\n We're reaching out to this knowledgeable community to get your thoughts, insights, or any innovative ideas that could help us refine and build out this concept. Whether you're an AI researcher, data scientist, blockchain expert, or simply someone interested in the field, your input could be invaluable to us.\n Here's a quick overview of what we're focusing on:\n  \nHolistic Swarm Intelligence Models: Incorporating stochastic optimization, neuromorphic computing, and quantum-inspired algorithms for adaptability and resilience.\n Global Community-Managed Ecosystem: Enhancing our DAO with transparent and real-time community feedback loops.\n  \nWe believe in the power of collaboration and the collective intelligence of this community. If you have any insights, questions, or want to know more about what we're working on, please comment below or feel free to send me a private message\n If you want to dive deeper into our project, here's a link to our website.\n Thank you for taking the time to read this post. We look forward to hearing your thoughts and potentially collaborating with some of you!\n    submitted by    /u/deepengineai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mnbxc/d_seeking_insights_and_collaboration_on_deep/",
          "publishedOn": "2023-08-09T18:28:28.000Z",
          "wordCount": 2773,
          "title": "[D] Seeking Insights and Collaboration on Deep Engine AI's Hive Concept for Universal Adaptive Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mm06v/d_what_are_the_ml_engineer_hours_per_week_worked/",
          "author": null,
          "description": "Two ways to answer this question:\n  \nWhat is the average amount of hours?\n What is the amount of hours in a specific position that you are familiar with?\n  \nI'm also wondering about non-academic ML PhDs who now work in industry.\n    submitted by    /u/Practical_Tea_3779  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mm06v/d_what_are_the_ml_engineer_hours_per_week_worked/",
          "publishedOn": "2023-08-09T17:39:17.000Z",
          "wordCount": 2547,
          "title": "[D] What are the ML engineer hours per week worked?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ml8n0/project_making_amd_gpus_competitive_for_llm/",
          "author": null,
          "description": "There have been many LLM inference solutions since the bloom of open-source LLMs. Most of the performant inference solutions are based on CUDA and optimized for NVIDIA GPUs. In the meantime, with the high demand for compute availability, it is useful to bring support to a broader class of hardware accelerators. AMD is one potential candidate.\n We build a project that makes it possible to compile LLMs and deploy them on AMD GPUs using ROCm and get competitive performance. More specifically, AMD Radeon™ RX 7900 XTX gives 80% of the speed of NVIDIA® GeForce RTX™ 4090 and 94% of the speed of NVIDIA® GeForce RTX™ 3090Ti for single batch Llama2-7B/13B 4bit inference. Besides ROCm, our Vulkan support allows us to generalize LLM deployment to other AMD devices, for example, a SteamDeck with an AMD APU.\n - Github: https://github.com/mlc-ai/mlc-llm/\n - Blogpost describing the techniques: https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference\n ​\n ​\n    submitted by    /u/crowwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ml8n0/project_making_amd_gpus_competitive_for_llm/",
          "publishedOn": "2023-08-09T17:11:17.000Z",
          "wordCount": 2648,
          "title": "[Project] Making AMD GPUs competitive for LLM inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mjeu2/d_doing_a_phd_in_embedded_systems_machine_learning/",
          "author": null,
          "description": "I am currently thinking about doing a PhD after I am done with my Master's thesis because the topic of my thesis is so fascinating. However, I put the possibility of doing a PhD aside because I was always more \"hands-on\" rather than academic / research focused.\n Would you say a PhD in the intersection of embedded systems + machine learning (maybe training a model \"on the edge\" with the sensor data of the embedded device) is beneficial regarding finding a job afterwards?\n    submitted by    /u/LM1117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mjeu2/d_doing_a_phd_in_embedded_systems_machine_learning/",
          "publishedOn": "2023-08-09T16:02:44.000Z",
          "wordCount": 2590,
          "title": "[D]: Doing a PhD in Embedded Systems + Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mizh5/d_how_can_i_determine_if_an_llms_response_is/",
          "author": null,
          "description": "I've become interested in how LLMs express emotions through their responses. Here's an example:\n [Q] = I am having a bad day\n [R] = I'm sorry to hear that you're having a bad day. Is there anything specific you'd like to talk about or any way I can help you feel better? Whether it's just a listening ear... \n I am aware that LLMs are not conscious and have no real understanding of emotions. But it is clear from the example that they can produce emotionally appropriate responses. Is there some kind of systematic test that can be automated to verify this? I.e. given a text-based query and response determine if the response is empathetic. \n    submitted by    /u/boringdude123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mizh5/d_how_can_i_determine_if_an_llms_response_is/",
          "publishedOn": "2023-08-09T15:47:20.000Z",
          "wordCount": 2622,
          "title": "[D] How can I determine if an LLM's response is empathetic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mffz9/p_using_lidar_and_photography_to_locate_fire/",
          "author": null,
          "description": "[P]I have imagery and lidar from trucks (cyclomedia). I would like to extract the latitude and longitude of fire hydrants from the images and point clouds.. I posted in r/computervision and they said it would be inaccurate to use imagery to locate fire hydrants.\n Do you have any tips on getting location from photographic images?\n Are there any open source neural nets for street view point clouds that can help?\n Is this an either/or problem or is it possible to use both data sources combined?\n    submitted by    /u/Zealousideal_Rub5826  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mffz9/p_using_lidar_and_photography_to_locate_fire/",
          "publishedOn": "2023-08-09T13:31:54.000Z",
          "wordCount": 2591,
          "title": "[P] using lidar and photography to locate fire hydrants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mdb96/d_which_cornerstone_papers_should_be_read_before/",
          "author": null,
          "description": "Hi everyone, I have an interesting task in hand, and wanted some advice over here before getting my hands dirty.\n I have to compile a list of 15-20 papers, to systematically go from \"what's a transformer\" to bleeding edge research of multimodal and LLMs applications to robotics, dynamical systems, and RL (e.g. RT-2). The base assumption is that the reader will be a master student, who already has the basics of what deep learning and control theory are.\n Could you suggest possible cornerstone papers that could go in this list? If you could, this would guide my search a lot, and I would appreciate it.\n ​\n ​\n    submitted by    /u/Snekgineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mdb96/d_which_cornerstone_papers_should_be_read_before/",
          "publishedOn": "2023-08-09T12:01:36.000Z",
          "wordCount": 2611,
          "title": "[D] Which cornerstone papers should be read before RT-2?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15matan/r_automl_tool_h2o_exposes_all_files_on_your/",
          "author": null,
          "description": "https://mlsecops.com/resources/hacking-ai-h2o-exposes-entire-filesystem\n    submitted by    /u/FlyingTriangle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15matan/r_automl_tool_h2o_exposes_all_files_on_your/",
          "publishedOn": "2023-08-09T09:57:07.000Z",
          "wordCount": 2512,
          "title": "[R] AutoML tool H2O exposes ALL files on your server by default, multiple CVEs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15man7r/r_what_are_your_favorite_ai_tools/",
          "author": null,
          "description": "What are some AI tools that you use often, that help you with your work/school or that you simply use for fun? \n    submitted by    /u/SadBlackTea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15man7r/r_what_are_your_favorite_ai_tools/",
          "publishedOn": "2023-08-09T09:48:05.000Z",
          "wordCount": 2526,
          "title": "[R] What are your favorite AI tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15m9s45/d_best_ml_opensource_projects_to_contribute_to/",
          "author": null,
          "description": "Any recommendations for cool open-source ML projects that an intermediate Machine Learning engineer/researcher can contribute to?\n    submitted by    /u/Ahmed-Allam-220  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15m9s45/d_best_ml_opensource_projects_to_contribute_to/",
          "publishedOn": "2023-08-09T09:00:48.000Z",
          "wordCount": 2521,
          "title": "[D] Best ML open-source projects to contribute to",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15m55ng/d_where_to_begin_studying_aiml_from_a_cognitive/",
          "author": null,
          "description": "I am currently an AI/ML student but I have recently been thinking more and more about cognitive science. I was wondering if you know of any good resources that approach AI from the perspective of cognitive science\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15m55ng/d_where_to_begin_studying_aiml_from_a_cognitive/",
          "publishedOn": "2023-08-09T04:47:10.000Z",
          "wordCount": 2545,
          "title": "[D] Where to begin studying AI/ML from a COGNITIVE SCIENCE PERSPECTIVE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lyv0k/r_cloud_computing_and_other_gpu_alternatives/",
          "author": null,
          "description": "I’m kind of new to the world of machine/deep learning so cut me some slack here, but I was wondering the best ways to train models (in my case a transformer) without a GPU. I personally don’t even have a PC, I’ve been using a 2017 MacBook Air. I know deep learning models are quite computationally expensive and since I don’t have access to a GPU, how do I train models? I’ve read about cloud computing services like AWS, Google Colab, etc. but I was wondering what the best method was. Ideally free or as cheap as possible.\n    submitted by    /u/Present_Network1959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lyv0k/r_cloud_computing_and_other_gpu_alternatives/",
          "publishedOn": "2023-08-08T23:59:25.000Z",
          "wordCount": 2602,
          "title": "[R] Cloud computing and other GPU alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lxru4/d_beta_test_invitation_free_ai_email_chrome/",
          "author": null,
          "description": "We are currently conducting a beta test for our Chrome Extension and we value external input.\n Our platform allows you to write and receive your gmail emails within the browser. You can also use AI to generate emails, without ever touching gmail or chatgpt.\n If you're interested in participating, please feel free to message or comment!\n    submitted by    /u/Live-Orange-8414  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lxru4/d_beta_test_invitation_free_ai_email_chrome/",
          "publishedOn": "2023-08-08T23:14:39.000Z",
          "wordCount": 2562,
          "title": "[D] Beta Test Invitation: Free AI Email Chrome Extension",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lxbtz/do_visual_transformers_have_anything_equivalent/",
          "author": null,
          "description": "I have a regression model based on CNN, works reasonably well with less than 1M parameters. I am trying to check how Visual Transformer (ViT) will perform on this task, but due to lack of pooling in ViT, model size is considerably large (~10M parameters). Do ViT have anything equivalent to pooling to reduce number of parameters?\n If not then that reduces applicability of ViT to large models on large dataset dataset only. For smaller tasks with small dataset, CNN or Resnet are way more computation efficient.\n Or am I missing something?\n    submitted by    /u/Apprehensive-War8915  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lxbtz/do_visual_transformers_have_anything_equivalent/",
          "publishedOn": "2023-08-08T22:57:07.000Z",
          "wordCount": 2600,
          "title": "Do Visual Transformers have anything equivalent to Pooling in CNN? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lx0dr/d_how_long_does_it_take_to_setup_an_mlops_pipeline/",
          "author": null,
          "description": "For our R&D team, we spent over a month trying to setup our pipeline. After that, we spend at least 5 days after R&D for to put a model into production without the required data pipelines that communicate with our model and the service. For training a model, the infrastructure maintain and manage it also needs to be built for around 2 weeks. \n Currently, our best solution is to offload the training process by purchasing a GPU and keeping it in the office.\n    submitted by    /u/potanees  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lx0dr/d_how_long_does_it_take_to_setup_an_mlops_pipeline/",
          "publishedOn": "2023-08-08T22:44:31.000Z",
          "wordCount": 2591,
          "title": "[D] How long does it take to setup an MLOps pipeline?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lwrcf/r_weights_reset_implicit_regularization/",
          "author": null,
          "description": "​\n https://preview.redd.it/4t4jbi15rygb1.png?width=2291&format=png&auto=webp&s=f4eedf0d24dee2cbd040b3a19ab9610119b4001e\n Hi everyone!\n I want to share some interesting observations that indicate a very simple periodical weights resetting procedure could serve as an implicit regularization strategy for training DL models. This technique also shows potential connection with the Double Descent phenomenon. Here's the link to github etc: https://github.com/amcircle/weights-reset.\n As a co-author of this study, I must apologize in advance for its brevity. However, I sincerely hope it may prove useful to some. I would gladly respond to your queries and receive your criticism. Your personal experiences related to something similar would also be highly appreciated.\n    submitted by    /u/gregorivy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lwrcf/r_weights_reset_implicit_regularization/",
          "publishedOn": "2023-08-08T22:34:16.000Z",
          "wordCount": 2596,
          "title": "[R] Weights Reset implicit regularization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15luwq4/d_training_process_are_text_encodings_used_along/",
          "author": null,
          "description": "Hi,\n I am going through research papers and noticed that most of the papers talk about the text conditioned image generation process (reverse diffusion process). The text and time encodings are added as additional channels to the UNet block.\n However, I am curious to know if any text encodings are used during the training process as well. Is there any preview of the training datasets that is available which is used in the training process ? or a code snippet that points out to the forward part of the training loop\n Thanks\n    submitted by    /u/kaskoraja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15luwq4/d_training_process_are_text_encodings_used_along/",
          "publishedOn": "2023-08-08T21:24:29.000Z",
          "wordCount": 2601,
          "title": "[D] Training process - Are text encodings used along with image encodings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lu61r/d_benchmark_for_autoregressive_llm_embedding/",
          "author": null,
          "description": "Hi everyone,\n There has been a lot of work on benchmarking autoregressive LLMs, such as HF LLM Leaderboard, but I have not seen much work specifically on the relevancy of such LLMs for retrieval. \n There is a lot of talk about chat based on knowledge with solutions like llama_index, where LLMs both provide embeddings and answer based on most similar content, but embedding and answer generation need not be the same LLM.\n I saw the Massive Text Embedding Benchmark (MTEB) but it does not seem to contain a lot of information about the recent autoregressive LLMs. \n Are the recent autoregressive LLMs, e.g. Llama 2, actually performing better than Bidirectional LLMs such as BERT? \n Because if so, all the recent fancy chat with your documents projects could use much smaller models to do embedding extraction for retrieval and just call a fancy autoregressive LLM such as GPT4 for answer synthesis.\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lu61r/d_benchmark_for_autoregressive_llm_embedding/",
          "publishedOn": "2023-08-08T20:56:43.000Z",
          "wordCount": 2655,
          "title": "[D] Benchmark for autoregressive LLM embedding quality for retrieval?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ltqrs/d_r_opensource_model_that_can_caption_an_image_of/",
          "author": null,
          "description": "Hi I'm looking for an open source model that can take an image of an info graphic such as a pie chart, graph, etc, and provide a description of the information in that chart. For example the values of the x,y axis and their labels, weather the chart is increasing or decreasing. \n I've worked with image captioning models such as BLIP before as I have used them in projects involving stable diffusion, but this model doesn't give specifics about the information in the graph, just a brief overview. \n I know researches have worked on this problem in the past using the vistext dataset: \n https://news.mit.edu/2023/researchers-chart-captions-ai-vistext-0630\n So far I'm thinking that it may come to me finetuning BLIP or equivalent to specialize on infographics instead. \n Thoughts? \n    submitted by    /u/UncleSammmm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ltqrs/d_r_opensource_model_that_can_caption_an_image_of/",
          "publishedOn": "2023-08-08T20:41:35.000Z",
          "wordCount": 2633,
          "title": "[D] [R] Opensource model that can caption an image of a chart?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ltjak/p_any_existing_photovideo_classifier_uis_with/",
          "author": null,
          "description": "I have a significant amount of files that I would like to label for future reference. I've looked at software such as Photoprism or Librephoto which have object classification but they are based on a static model. I'd like something where I could label a few photos then generate similar matches where I can approve the good matches for reinforcement learning. I'm pretty sure I saw a demo like this at a code conference using Azure but I'm hoping for something self-hosted to avoid API fees. I was exploring coding something to do this for me but I don't want to put in the work if something with a UI exists already. This seemed like the best place to ask.\n    submitted by    /u/MZZXX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ltjak/p_any_existing_photovideo_classifier_uis_with/",
          "publishedOn": "2023-08-08T20:33:56.000Z",
          "wordCount": 2626,
          "title": "[P] Any existing photo/video classifier UIs with custom labels?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lsyjz/d_best_way_to_run_a_pytorch_model_on_a_cropped/",
          "author": null,
          "description": "Hi - I have trained a pytorch model that does some fairly simple object classification - The goal is distribute it as part of an app, that will pull information from a user's video.\n The videos are typically ~25-30 minutes and about 1GB in size, only a 600x600px square on the bottom right of the video is needed for the classification (it's a minimap in a video game)\n The app is electron based\n Ideally I want to input a video, and extract the labels from the cropped section once per second.\n ​\n My current attempt involves converting the model to a tensorflowjs model, and rendering the video on a <canvas> element, stretching it so only the minimap is visible on the canvas, running the model, saving the labels, and increasing the current time of the video by 1 second, and repeating until the video is done.\n ​\n This seems like a terrible plan, but it's much better than the couple of other ideas I've tried (using ffmpeg to extract a frame every second for example)\n ​\n Any advice appreciated!\n ​\n Edit: just to clarify this will only ever be ran on Windows\n    submitted by    /u/FreddoRS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lsyjz/d_best_way_to_run_a_pytorch_model_on_a_cropped/",
          "publishedOn": "2023-08-08T20:12:29.000Z",
          "wordCount": 2704,
          "title": "[D] Best way to run a pytorch model on a cropped version of a video on someone else's PC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lp6yl/rp_review_to_twothree_words_summarization_text/",
          "author": null,
          "description": "Hello, I'm looking for a model (probably two models) that would:\n  \nSummarize reviews (e.g. website review) to two/three words.\n \nReuse these words or \"review tokens\" to tag reviews with similar content. Then if a review's content differs (e.g. cosine sim. of 0.2), another tag will be generated from the review that diverges.\n \n Is there anything like this on the \"market\"? \n    submitted by    /u/BartPetersyn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lp6yl/rp_review_to_twothree_words_summarization_text/",
          "publishedOn": "2023-08-08T17:52:03.000Z",
          "wordCount": 2566,
          "title": "[R][P] Review to two/three words summarization | Text tagging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnyh6/d_spectrum_of_specialization_in_ml/",
          "author": null,
          "description": "Hello to everyone reading this. \n I am just about to finish Andrew NG's course 3 courses on ML specialization and I have had 2 courses on ML as well in my Business Intelligence Analytics studies at uni. \n Now I am extremely interested in ML but I see there are wide diaspora of different subfields you can focus on. I need to get into the job market as fast as possible. So can anyone guide me which aspect of ML should I give most of my time to practice and build portfolio that would translate well to interviews and hiring?\n Thank you\n    submitted by    /u/JaguarMoosa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnyh6/d_spectrum_of_specialization_in_ml/",
          "publishedOn": "2023-08-08T17:05:18.000Z",
          "wordCount": 2604,
          "title": "[D] Spectrum of Specialization in ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnw0z/d_question_difficulty_predictor/",
          "author": null,
          "description": "How would you proceed on a project in assessing the difficulty level of a question? I tried using lexicographic metrics like flesh-kincaid score, etc., but those did not yield proper results. Is there a good method I could use? Also, how could I assess the \"readability\" of a question, or in other words, how easy it is to understand what the question is asking.\n    submitted by    /u/uglyboi34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnw0z/d_question_difficulty_predictor/",
          "publishedOn": "2023-08-08T17:02:41.000Z",
          "wordCount": 2565,
          "title": "[D] Question Difficulty Predictor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lntx9/releasing_a_new_model_for_conditional_music/",
          "author": null,
          "description": "Hey y'all, this is a model I have been independently building for some time. It uses parts of OpenAI's Jukebox and HarmonAI's Dance Diffusion model.\n Overall it is a hierarchical latent diffusion modeland generates complete linked musical phrases at good quality.\n More information as well as examples can be found here: https://medium.com/@jeffsontagmusic/jukebox-diffusion-cbe22ff3cd47\n Thanks!\n    submitted by    /u/jmoso13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lntx9/releasing_a_new_model_for_conditional_music/",
          "publishedOn": "2023-08-08T17:00:43.000Z",
          "wordCount": 2558,
          "title": "[R]eleasing a new model for conditional music generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnt4g/d_how_to_stay_on_the_cutting_edge_of_applied_mlai/",
          "author": null,
          "description": "A lot of my PhD work will be in using different types of ML/NN approaches to characterizing problems in my field. It's kind of weird, since for my undergrad I came from a more traditional science background where we research off papers that were written like 2-20 years ago. Since a lot of these architectures and whatever are updating so fast, I wanted to see if there's a good way to keep up with the latest information so my work wouldn't be outdated by the time I publish. Is there a general workflow that those of you in the field follow in regards to this?\n    submitted by    /u/This-Is-My-20th-Acc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnt4g/d_how_to_stay_on_the_cutting_edge_of_applied_mlai/",
          "publishedOn": "2023-08-08T16:59:58.000Z",
          "wordCount": 2617,
          "title": "[D] How to stay on the cutting edge of applied ML/AI while doing my PhD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnfbh/a_blog_on_lora_and_qlora_finetuning_techniques_p/",
          "author": null,
          "description": "Hey everyone,\n I wrote a blog on LoRA and QLoRA. Hope it helps you in understanding the theory behind them 🤗\n https://medium.com/@gitlostmurali/understanding-lora-and-qlora-the-powerhouses-of-efficient-finetuning-in-large-language-models-7ac1adf6c0cf\n If the above one is behind paywall, you can visit the blog here (https://gitlostmurali.com/machine-learning/data-science/lora-qlora)\n    submitted by    /u/Outlandish_MurMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnfbh/a_blog_on_lora_and_qlora_finetuning_techniques_p/",
          "publishedOn": "2023-08-08T16:44:59.000Z",
          "wordCount": 2542,
          "title": "A blog on LoRA and QLoRA finetuning techniques [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lmvmc/d_im_losing_my_voice_due_to_illness_and_im/",
          "author": null,
          "description": "Hey all, like the title says, I’m losing my voice due to an illness (Parkinson’s disease), and I would like to create an AI voice using recordings from 10 years ago. I used to be a prolific podcaster, and I have about 50 episodes of podcasts that I can use as input. Is this possible? What service or software can I use? My voice is beyond repair since Parkinson’s is a progressive disease. An AI voice would allow me to work and would open up new doors for me. Thank you!\n    submitted by    /u/NWMoney101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lmvmc/d_im_losing_my_voice_due_to_illness_and_im/",
          "publishedOn": "2023-08-08T16:23:46.000Z",
          "wordCount": 2602,
          "title": "[D] I’m losing my voice due to illness, and I’m looking for ML/AI solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lm6tk/p_candle_torch_replacement_in_rust/",
          "author": null,
          "description": "Candle is a minimalist ML framework for Rust\n Some of its features\n  \nExamples of popular models: Whisper, Llama 2, Falcon, Bert, Starcoder\n WASM support, so you can run the models directly in the browser\n User-defined kernels, so you can use Flash Attention\n Similar syntax to PyTorch\n Data loaders\n Transformer utilities\n  \n   submitted by    /u/hackerllama  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lm6tk/p_candle_torch_replacement_in_rust/",
          "publishedOn": "2023-08-08T15:58:25.000Z",
          "wordCount": 2553,
          "title": "[P] Candle: Torch Replacement in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lkqtq/d_how_to_keep_my_ml_skills_whilst_on_another_job/",
          "author": null,
          "description": "Hey all, I have a technical background, having studied engineering and ML at one of the world's leading universities. I really enjoyed it and did well, but long story short, since graduating (coming to 2 years) I have been working in a Family Office, doing things I don't feel are very related.\n I wanted to know what kind of things I can do to keep myself in the loop and continue developing my ML/DS skills in my spare time. Alternatively, ideas of projects I could have just to make sure I have a portfolio?\n    submitted by    /u/thegreatudini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lkqtq/d_how_to_keep_my_ml_skills_whilst_on_another_job/",
          "publishedOn": "2023-08-08T15:04:44.000Z",
          "wordCount": 2602,
          "title": "[D] How to keep my ML skills whilst on another job?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15li768/pmmlubytask_evaluation_results_for_500_open/",
          "author": null,
          "description": "Typically, research papers and leaderboards only report the overall score on Measuring Massive Multitask Language Understanding (MMLU) and not per task performance. Hugging Face recently released detailed evaluation data that includes per task performance. I made a sortable leaderboard here https://huggingface.co/spaces/CoreyMorris/MMLU-by-task-Leaderboard . You can also make custom scatter plots on the site so you can explore the relationship between parameter count and performance.\n    submitted by    /u/corey1505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15li768/pmmlubytask_evaluation_results_for_500_open/",
          "publishedOn": "2023-08-08T13:26:12.000Z",
          "wordCount": 2568,
          "title": "[P]MMLU-by-Task Evaluation Results for 500+ Open Source Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lgjw7/d_current_trends_in_explainability/",
          "author": null,
          "description": "I've realized my technical understanding of explainability is a few years behind, having last focused on it with LIME and Shap. Does anyone have a survey reference they like for recent trends and updates in ML explainability?\n    submitted by    /u/balcell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lgjw7/d_current_trends_in_explainability/",
          "publishedOn": "2023-08-08T12:16:30.000Z",
          "wordCount": 2539,
          "title": "[D] Current trends in explainability?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ldjdz/r_whats_the_current_research_status_of_sft_with/",
          "author": null,
          "description": "At first, with InstructGPT and ChatGPT, it looked like RLHF was the holy grail to successfully finetune LLMs on human preferences. Then, from May 2023 onwards, a trend of doing just SFT with high-quality data showed up (e.g. \"LIMA: Less Is More for Alignment\" https://arxiv.org/abs/2305.11206) as an alternative to doing RLHF.\n What's your opinion on these two narratives? Is RLHF likely to still be relevant even in the presence of SFT with high-quality data?\n    submitted by    /u/bornot2b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ldjdz/r_whats_the_current_research_status_of_sft_with/",
          "publishedOn": "2023-08-08T09:51:59.000Z",
          "wordCount": 2584,
          "title": "[R] What's the current research status of \"SFT with high-quality data\" vs RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15la8cy/discussion_what_has_your_experience_been_as/",
          "author": null,
          "description": "Hi all, \n I am currently already working in the field of ML research at a big name medical research center. Our main focus is in application of ML methods with the focus on stroke diagnostics and treatment.\n Now, I am quite happy working here but my background is somewhat interdisciplinary. I have a bachelor's in Life science and a Master in bioinformatics. Because of this I always feel like I have to catch up to my colleagues when it comes to ML and in parts also computer science knowledge. It feels like there are a million things to learn and many small details to know that I am not even sure how to look up.\n I am curious what your experience has been if you were/are in a similar situation? How did you manage to catch up?\n    submitted by    /u/JuicyLambda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15la8cy/discussion_what_has_your_experience_been_as/",
          "publishedOn": "2023-08-08T06:53:13.000Z",
          "wordCount": 2648,
          "title": "[Discussion] What has your experience been as someone joining ML from a lateral field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l87gd/d_does_sota_performance_on_object_detection_seem/",
          "author": null,
          "description": "Either I'm too new to the space, or I'm stating the obvious, but it seems that object detection performance is really low. The SOTA currently is 66% on COCO test-dev, which doesn't match how well it seems like AI is currently performing with self-driving cars, surveillance tech, and others. Am I missing something?\n    submitted by    /u/philipkd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l87gd/d_does_sota_performance_on_object_detection_seem/",
          "publishedOn": "2023-08-08T05:05:32.000Z",
          "wordCount": 2562,
          "title": "[D] Does SOTA performance on object detection seem low to anybody else?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l7236/r_hierarchical_representation_and_propagation_of/",
          "author": null,
          "description": "I. Introduction\n This paper aims to provide an in-depth explanation of representing and propagating wavefunctions in a hierarchical manner using Gaussian basis functions. Wavefunctions are mathematical descriptions of the quantum states of physical systems and are fundamental to quantum mechanics. However, representing complex wavefunctions for real-world quantum systems remains a key challenge. This paper proposes using multiple layers of Gaussian basis functions, with trainable amplitudes, to represent wavefunctions in a hierarchical fashion and enable wavefunction propagation between layers.\n Understanding wavefunction representation and propagation has significant implications in diverse fields like quantum computing, quantum chemistry, and materials science. Efficient wavefunction man…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l7236/r_hierarchical_representation_and_propagation_of/",
          "publishedOn": "2023-08-08T04:07:41.000Z",
          "wordCount": 3549,
          "title": "[R] Hierarchical Representation and Propagation of Wavefunctions within Gaussian Basis Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l2jr8/evolinstruct_dataset_creation_r_d/",
          "author": null,
          "description": "I’ve been researching the Evol-Instruct datasets now for a few days and have decided I want to build my own out for a specific use case.\n I’ve read literally everything possible, admittedly not much outside of WizardLM and GeorgiaTech, but I’ve read it.\n I was hoping to discuss it here with smarter people. \n I’m seeing this as a way to use LLMs to generate great datasets. However, my use case doesn’t really exist in any models yet. Not thoroughly enough to produce a good Evol-Instruct set. So, I’m going to do that tomorrow.\n I’m going to use The Blokes WizardCoder-Guanaco 15b GPTQ version to train on my specific dataset - about 10GB of clean, really strong data I’ve spent 3-4 weeks putting together.\n In theory, I’ll use the Evol-Instruct script from WizardLM to generate the new dataset, and then I’ll apply that to whatever model I decide to use. There is a good chance I train my own on general Evol-Instruct datasets available now, and likely quite a large one.\n I’m looking for any tips, discussion, ideas, thoughts from the community. \n Cheers!\n    submitted by    /u/LoadingALIAS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l2jr8/evolinstruct_dataset_creation_r_d/",
          "publishedOn": "2023-08-08T00:42:04.000Z",
          "wordCount": 2674,
          "title": "Evol-Instruct Dataset Creation [R] [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l18cc/please_criticize_our_llm_writing_integration_app_p/",
          "author": null,
          "description": "Here's the pitch:\n We made an editor called Gamut that lets you enter your ideas in any form you want. Bullets, carefully constructed paragraphs, it doesn’t matter. Then, our patent-pending technology lets you convert to prose and adjust, shaping the text like a graphic designer shapes an image.\n We want r/MachineLearning's advice and field experience, because tbh we're just a bunch of teenagers who haven't even gone to college yet.\n Check it out: gamut.ink\n    submitted by    /u/gamut_ink  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l18cc/please_criticize_our_llm_writing_integration_app_p/",
          "publishedOn": "2023-08-07T23:46:10.000Z",
          "wordCount": 2569,
          "title": "Please criticize our llm writing integration app [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l11ci/dcould_current_ai_tech_make_a_movie_of_alejandro/",
          "author": null,
          "description": "I was just watching the documentary about the 'greatest movie never made', director Alejandro Jodorowsky's vision of Frank Herbert's Dune.\n There is a huge book that contains a storyboard version of the movie with lots of production art by artists Moebius, Chris Foss and HR Giger.\n The movie was to star Jodorowsky's son as Paul Atriedes, Salvadore Dali as the Emperor, Orson Wells as Baron Harkonnen and Mick Jagger as Feyd.\n Could one of today's AIs be 'fed' Jodorowsky's book and create a movie of his vision?\n Curious to know what your opinions are on this.\n Thanks.\n    submitted by    /u/shopdog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l11ci/dcould_current_ai_tech_make_a_movie_of_alejandro/",
          "publishedOn": "2023-08-07T23:38:17.000Z",
          "wordCount": 2597,
          "title": "[D]Could current AI tech make a movie of Alejandro Jodorowsky's vision of 'Dune'?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l0wm0/p_regression_using_batch_trend_data/",
          "author": null,
          "description": "Hi, all,\n I would like to use batch reaction trend data to build a regression model. I'm wondering what is the best way to approach this.\n Here's some background:\n Reaction Data: \n  \n Time (min) Pressure (bar) Temperature (°C) Flow (kg/h) Gas Total (kg) \n  \n 1 10 70 502 8 \n  2 10.1 71 498 16 \n  ... ... ... ... ... \n  102 10.3 76 475 850 \n \n Output: Polymer property X\n The reaction continues until a gas total is met and the time this takes depends on the other variables.\n I have ~700 batches of data in a format similar to the above and would like to predict polymer property X. As the variables can change minute to minute I was thinking of binning the variables into 5 minute bins using the mean and using these as variables for linear regression or similar.\n Is this a valid approach or is there another way I can approach the problem?\n Thanks!\n    submitted by    /u/Nefarious_P_I_G  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l0wm0/p_regression_using_batch_trend_data/",
          "publishedOn": "2023-08-07T23:32:54.000Z",
          "wordCount": 2647,
          "title": "[P] Regression using batch trend data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l0w7i/r_awesome_ood_detection_robustness_and/",
          "author": null,
          "description": "Hi everyone,\n I have put together a repo that provides comprehensive resources for Out-of-distribution Detection, Robustness, and Generalization. The repo contains articles, talks, libraries, papers, etc. Check it out.\n https://github.com/continuousml/Awesome-Out-Of-Distribution-Detection\n    submitted by    /u/Ok-Kaleidoscope-505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l0w7i/r_awesome_ood_detection_robustness_and/",
          "publishedOn": "2023-08-07T23:32:26.000Z",
          "wordCount": 2524,
          "title": "[R] Awesome OOD Detection, Robustness, and Generalization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kyphq/d_uncertainty_prediction_in_deep_learning_capsa/",
          "author": null,
          "description": "Alexander Amini, a Postdoctoral Associate at MIT, well known for the MIT's Introduction to Deep Learning Course, published a git repo called CAPSA for uncertainty prediction. This was introduced during the online course. The code was released under Thermis AI, Inc, a private company. He is the co-founder and CSO of the company. You can check how well the code was documented in the wayback machine. Recently, they removed the code base from the github and launched a pro version with selected companies as beta. The original repo (now called capsa-lite) was a great learning tool that I wanted to use. This was a quick way to try out different methods of uncertainty prediction using minimal code. Unfortunately, they have pulled all previous version of the code from the github repo. I was wondering if anyone knows a similar python package or has the old repo - would be really helpful!\n    submitted by    /u/shikamaru_77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kyphq/d_uncertainty_prediction_in_deep_learning_capsa/",
          "publishedOn": "2023-08-07T22:06:16.000Z",
          "wordCount": 2652,
          "title": "[D] Uncertainty Prediction in Deep Learning - CAPSA github project alternative or old code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kyjtm/d_ml_workstation_for_cnn_and_transformers/",
          "author": null,
          "description": "I'm putting together an ML workstation primarily focused at handling CNN and Transformer workloads. Component selection so far: https://de.pcpartpicker.com/list/zVPtt7\n I've got a couple of questions specifically regarding the motherboard. One concern I have is whether the space between the two GPUs is sufficient, as I'm planning to set them up using NVLink. Additionally, I'm curious about the compatibility of the case and motherboard for effective air cooling ( not considering water cooling at the moment). Anyone else with dual 3090s who can give some insights on how they've managed temperatures and potential overheating issues?\n Lastly, would upgrading to a Ryzen 9 5900X prevent me from bottlenecking the GPU's? \n Would love to hear your feedback and suggestions! \n    submitted by    /u/Hugejiji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kyjtm/d_ml_workstation_for_cnn_and_transformers/",
          "publishedOn": "2023-08-07T22:00:37.000Z",
          "wordCount": 2615,
          "title": "[D] ML Workstation for CNN and Transformers - Feedback on Component Selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kugwx/finetuning_for_code_generation_d/",
          "author": null,
          "description": "i want to fine tune any open source llm for code generation purpose with some of my code. any idea what model would be suitable? and any example of implementation?\n    submitted by    /u/learner_beginner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kugwx/finetuning_for_code_generation_d/",
          "publishedOn": "2023-08-07T19:29:36.000Z",
          "wordCount": 2522,
          "title": "Finetuning for code generation [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ku1ao/d_how_difficult_is_it_to_find_a_job_in_mlai/",
          "author": null,
          "description": "Anyone here know what the trends are towards hiring for an AI/ML position without a PhD? Is it advisable to get a PhD if you want to be in the field and keep rising within it?\n    submitted by    /u/CleanGarden7051  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ku1ao/d_how_difficult_is_it_to_find_a_job_in_mlai/",
          "publishedOn": "2023-08-07T19:13:12.000Z",
          "wordCount": 2543,
          "title": "[D] How difficult is it to find a job in ML/AI without a PhD, in the current bad job market?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kt2vw/d_machine_learning_or_quantum_computing/",
          "author": null,
          "description": "Hi,\n I'm about to graduate in Physics (PhD). I am an experimentalist with a background in electromagnetic. I am trying to apply for jobs, but there are some few options for physicists (based on my geography). So, I am trying to learn some new skill for my future job. One option would be Machine Learning, which is on-demand and the field is growing. The other option is Quantum Computing. I can start a postdoc in quantum information theory as well.\n Each path, has its pros and cons, and the final decision is based on many factors. I just don't have enough data and information to say which one is more secure in the future? Which one has less compete? And also, is it possible to get hired without any serious project in ML, and just self-taught?\n If you were me, which one would you pick?\n Thanks\n    submitted by    /u/Jaded-Membership-602  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kt2vw/d_machine_learning_or_quantum_computing/",
          "publishedOn": "2023-08-07T18:38:50.000Z",
          "wordCount": 2639,
          "title": "[D] Machine learning or quantum computing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ksdz2/d_what_is_a_typical_nonacademic_ml_salary_with_a/",
          "author": null,
          "description": "What is a typical non-academic ML salary with a PhD...\n  \n... immediately after completing the PhD? (Assuming no academic positions ever post PhD.)\n ... after 10 years of experience?\n ... in biotech specifically? (More, less, or the same as average?)\n  \n   submitted by    /u/Practical_Tea_3779  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ksdz2/d_what_is_a_typical_nonacademic_ml_salary_with_a/",
          "publishedOn": "2023-08-07T18:13:37.000Z",
          "wordCount": 2538,
          "title": "[D] What is a typical non-academic ML salary with a PhD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ks6js/p_mathematics_ml_for_masters_application_advice/",
          "author": null,
          "description": "Hi all, \n I'm looking apply to some top masters for machine learning in the UK, so I'm guessing you know which one I'm referring to. \n I got some guidance from the application advisor, which state they like to look at the transcript the most to have an idea of my linear algebra, calculus and statistics ability. I got 70% in \"Maths for Computer Science\" and some other modules I strong first and 2:1 in some others, but in general my course wasn't too mathematically intensive. I did BSc Computer Science. I have been working as SWE the past 3 years. \n I have completed the following specialisation \"Mathematics for Machine Learning and Data Science Specialization\" and read \"Mathematics for Machine Learning\", as learning about mathematics actually got me into ML. I have also covered the videos on 3Blue1Brown etc. The application advisor said that certs don't really mean too much which is understandable. I can't change the past in terms of BSc transcript, therefore I was thinking a project may be a good way to showcase this.\n Any tips on how to best showcase this or get across my ability would be extremely helpful?\n    submitted by    /u/DNOFHF  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ks6js/p_mathematics_ml_for_masters_application_advice/",
          "publishedOn": "2023-08-07T18:05:50.000Z",
          "wordCount": 2687,
          "title": "[P] Mathematics ML for Masters Application Advice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15krt3a/d_how_can_i_configure_two_gpus_to_share_their/",
          "author": null,
          "description": "Hey, \n I've been trying to build an ML workstation and was considering the idea of using two RTX 3090's to get the extra VRAM instead of a single 4090. However, I've come across some confusion regarding whether they can share their VRAM or not. Do I need to run them via NVLink to achieve this? I believe PyTorch's data parallelism splits the batches across both GPUs, but that wouldn't effectively combine their VRAM right?\n Any advice or insights you can share on the topic would be highly appreciated!\n    submitted by    /u/Hugejiji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15krt3a/d_how_can_i_configure_two_gpus_to_share_their/",
          "publishedOn": "2023-08-07T17:52:29.000Z",
          "wordCount": 2586,
          "title": "[D] How can I configure two GPUs to share their memory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15knz1x/d_are_there_any_graduate_programs_which_focus_on/",
          "author": null,
          "description": "I'm considering getting a graduate degree in ML. However, I am not very interested in NLP or academic research. I would like to learn things that are relevant to the intersection of ML and genomics or medicine. Are there any graduate programs/degrees to this effect? If so, which ones?\n    submitted by    /u/Practical_Tea_3779  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15knz1x/d_are_there_any_graduate_programs_which_focus_on/",
          "publishedOn": "2023-08-07T15:30:24.000Z",
          "wordCount": 2548,
          "title": "[D] Are there any graduate programs which focus on ML + biomedicine?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/",
          "author": null,
          "description": "Hi folks.\n I am sure you know the running gags around “thin OpenAI wrapper” products. Instead of more toy products, I am doing an experiment with some “AI engineering” to come up with a solution that’s closer to being usable in actual production cases.\n My background is in project management and data engineering, and I’ve built large systems for big companies and worked as a consultant in the space.\n I’ve seen enough crappy data pipelines for a lifetime.\n Hence.\n I want to do something different: A thin AI wrapper is not sufficient for having reliable data pipelines that use OpenAI for schema management and inference\n So this leaves me with the following doubts:\n ​\n  \nHow to scale code horizontally and vertically? Using third-party solutions? SNS/SQS/Kafka?\n How to log and trace? Langsmith? Custom solutions?\n How to extend reliably with my own data, and make it stateful?\n  \nLooking for your perspective\n ​\n  \nWhat do you think about the state of data engineering, MLOps, and infrastructure in AI companies?\n What do you think about how to scale properly the systems and prepare them for the future?\n In this code here, I do process some PDFs as a simple pipeline, what approaches do you think could be better?\n  \nMy current thinking and the state of the project\n ​\n  \nI should create a formal scale of usability. I am looking for your input here.\n I should improve model consistency, extends the model with custom domain knowledge, and make an early attempt to build simple user agents in the domain\n What I have is a schema inference, contracting basics, and a way to structure unstructured data\n I’m about to create a memory component that manages the data stored in vector dbs, as a DWH for AI\n If I bring this use case that was not something available easily to the public before, how best do it?\n  \nLinks:\n If you like my project, please give it a star :)\n my git repo \n    submitted by    /u/Snoo-bedooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/",
          "publishedOn": "2023-08-07T13:56:31.000Z",
          "wordCount": 2817,
          "title": "[P] Looking for perspectives: Pdf parsing meets PRODUCTION",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kl4m6/d_use_multiple_gpus_to_load_model/",
          "author": null,
          "description": "Hey there,\n I got 2x 4090 RTX with 24GB GDDR each.I often ran into the problem of\n CUDA out of memory. Tried to allocate X MiB (GPU 0; 23.65 GiB total capacity; 22.75 GiB already allocated; 96.81 MiB free; 22.76 GiB reserved in total by PyTorch) \n I wonder if there is a way to take usage of both GPUs so the model is split onto both GPUs.\n When training models I use torch.nn.DataParallel to use both GPUs, but it seems like I am not doing it right for load the model.\n Can anyone help me? Both GPUs are available in the system - this has already been checked.\n    submitted by    /u/Sensitive_Limit1620  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kl4m6/d_use_multiple_gpus_to_load_model/",
          "publishedOn": "2023-08-07T13:43:07.000Z",
          "wordCount": 2602,
          "title": "[D] Use multiple GPUs to load model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kkxsz/p_llm_finetuning_studyresearch_group/",
          "author": null,
          "description": "Hey folks, \n We're looking for people to join our research group.\n We are passionate about fine-tuning LLMs for downstream tasks, specifically LLAMA for imitating chat behaviour (being constraint aware).\n ​\n The end goal is to build an open source app where you can clone and upload your chat history (say from Whatsapp) and it starts to answer like you \n Do let me know if it sounds interesting and you'd like to join us...\n https://preview.redd.it/sdo42mx1yogb1.png?width=1280&format=png&auto=webp&s=9de5008ed8ed18cedb25034d68984cb11e2a6a12\n    submitted by    /u/im_datta0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kkxsz/p_llm_finetuning_studyresearch_group/",
          "publishedOn": "2023-08-07T13:35:23.000Z",
          "wordCount": 2564,
          "title": "[P] LLM Finetuning Study/Research Group",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kkocz/p_humanscript_an_llm_powered_plain_english/",
          "author": null,
          "description": "humanscript is an inferpreter. A script interpreter that infers commands from natural language using AI. There is no predefined syntax, humanscripts just say what they want to happen, and when you execute them, it happens.\n https://github.com/lukechilds/humanscript\n This is a humanscript called tidy-screenshots. It takes an unorganised directory of screenshots and organises them into directories based on the month the screenshot was taken.It can be executed like any other script.\n https://preview.redd.it/2b0oz2kgwogb1.png?width=1576&format=png&auto=webp&s=9285805a1d0668ae5fe300857f9b67161b8ecda4\n The LLM inferpreted the humanscript into the following bash script at runtime.\n ​\n https://preview.redd.it/x8hwdrzhwogb1.png?width=2188&format=png&auto=webp&s=5fcba87a9606a446d169e8ae37b5c8c251525e5e\n The code is streamed out of the LLM during inferpretation and executed line by line so execution is not blocked waiting for inference to finish. The generated code is cached on first run and will be executed instantly on subsequent runs, bypassing the need for reinferpretation.\n ​\n https://i.redd.it/t6b1stbkwogb1.gif\n The humanscript inferpreter supports a wide range of LLM backends. It can be used with cloud hosted LLMs like OpenAI's GTP-3.5 and GPT-4 or locally running open source LLMs like Llama 2.\n You can run humanscript in a sandboxed Docker environment with a single command if you want to have a play.\n https://github.com/lukechilds/humanscript#install-humanscript\n    submitted by    /u/dyslexiccoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kkocz/p_humanscript_an_llm_powered_plain_english/",
          "publishedOn": "2023-08-07T13:24:34.000Z",
          "wordCount": 2676,
          "title": "[P] humanscript: An LLM powered plain english programming language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15khkvu/d_text_aware_image_generation/",
          "author": null,
          "description": "lets say i have a set of images which contains sentences of text on it. now i want to generative images using some generative model with valid (meaningful) text in them. what i assume is just using gan or more powerful diffusion to generate images but i don't think the generated images won't contains valid text in them. i want the model to implicitly learn the text in the images without feeding external text or ocr on them. does any one know any paper trying to tackle this problem. \n any comments on this by anyone.\n    submitted by    /u/specializedboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15khkvu/d_text_aware_image_generation/",
          "publishedOn": "2023-08-07T11:08:35.000Z",
          "wordCount": 2587,
          "title": "[D] Text aware image generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kcae2/r_detecting_thousands_of_overlapping_organisms/",
          "author": null,
          "description": "submitted by    /u/Alonsospace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kcae2/r_detecting_thousands_of_overlapping_organisms/",
          "publishedOn": "2023-08-07T06:18:24.000Z",
          "wordCount": 2508,
          "title": "[R] Detecting thousands of overlapping organisms using latent space encoding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kbnsc/p_new_library_dlt_auto_structures_data_and_loads/",
          "author": null,
          "description": "Hey folks,\n For the past 2 years I've been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, schema inference, evolution & ddl generation, self deployment.. Basically, as you build better and better pipelines you will want more and more, and dlt supports those options.\n The value proposition of this library is to automate the tedious work you do, so you can focus on better things. \n What's special about dlt?\n In the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading, kind of like a pandas df.to_sql() but with auto schema inference, versioning and evolution. It supports loading to files, databases, and soon table formats and vector dbs.\n In its most complex form, you can do almost anything you can want, from memory management, microbatching, multithreading, extraction DAGs, 1 line Airflow/git actions deployment, dbt runner, streamlit app for data discovery, sql client, atomic state dictionaries, etc.\n The library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community. We are adding Athena + Iceberg and Weaviate vector dbs next.\n Free forever\n The library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.\n Call for Feedback!\n Feedback is very welcome and so are requests for features or destinations.\n I would particularly love to hear from you: What destinations are you looking for from such a tool? And what use cases do you usually have? I'm a data engineer so my knowledge is more around loading external sources to a common space.\n Links\n Colab demos: Load to duckdb with schema evolution\n Docs main page \n Thank you in advance for your feedback!\n    submitted by    /u/Thinker_Assignment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kbnsc/p_new_library_dlt_auto_structures_data_and_loads/",
          "publishedOn": "2023-08-07T05:43:29.000Z",
          "wordCount": 2825,
          "title": "[P] New library: dlt auto structures data and loads it with schema evolution in a declarative way.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k7y18/p_ai_text_adventure_games_narrated_and/",
          "author": null,
          "description": "https://textadventure.v5games.com/\n Hi All, I created these Text Adventure Games with AI, some help from the community which designs prompts+some avatars.\n The AI Characters can be created with an AI Art Generator. Voices and Illustrations are done using AI https://textadventure.v5games.com/ \n Let me know what you think!\n    submitted by    /u/BoxOrigi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k7y18/p_ai_text_adventure_games_narrated_and/",
          "publishedOn": "2023-08-07T02:30:29.000Z",
          "wordCount": 2542,
          "title": "[P] AI Text Adventure Games - Narrated and Illustrated by AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k7x0j/n_microsoft_partners_with_meta_for_llama_2/",
          "author": null,
          "description": "Staying on top of all changes, tools, and best practices with AI is getting increasingly hard. Each week I find just 1 piece of information that is most interesting across research, products, business news, and many more. No fluff guaranteed.\n Sharing the top research from this week's edition:\n https://preview.redd.it/fa3b1u39nlgb1.png?width=591&format=png&auto=webp&s=1ccd78136e3578396878fd9641605845f0309865\n Summary: Meta released their latest open-source model, Llama 2, in partnership with Microsoft’s Azure platform. But Microsoft also offers OpenAI models and is a major investor in the company (they paid $14B for 49%). So, confused Matt asks, why would Microsoft partner with Meta, when it might undermine their investment in OpenAI?\n 💡 Answering the question:\n  \nSpreading the risk: OpenAI may have the first mover advantages, but this does not always last (e.g. Blackberry, Myspace, Yahoo). Microsoft is betting on AI but keeps the chips diversified on multiple players.\n It’s beside the point: regardless of who Microsoft supports, their game is to attract all AI utilization on Azure. It's not about the tools but about the CPU/GPU cycles they can charge for. smart!\n The real AI gangsta: Microsoft is sitting on the holy trinity of AI now.\n  \n Exclusive partnerships with top LLMs (OpenAI, Meta)\n Priority access to Nvidia GPUs\n And strategic assets like GitHub and Azure\n  \nView tweet\n If you'd like weekly recaps like this sent to your inbox, consider subscribing to the Tomorrow Now newsletter. 😄\n    submitted by    /u/TomorrowNowTech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k7x0j/n_microsoft_partners_with_meta_for_llama_2/",
          "publishedOn": "2023-08-07T02:29:10.000Z",
          "wordCount": 2723,
          "title": "[N] Microsoft partners with Meta for Llama 2 release. But why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k2bb0/pquestion/",
          "author": null,
          "description": "Hello I am attempting to reduce a matrix that is 57 by 256 to 57 to 128. I was attempting to use PCA but it failed as maximum size would be 57 by 57. I was also attempting an autoencoder but the syntax behind this is very confusing so If anyone could give me adivce that would be great. Thank you \n    submitted by    /u/amayorgafcw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k2bb0/pquestion/",
          "publishedOn": "2023-08-06T22:14:20.000Z",
          "wordCount": 2511,
          "title": "[P]:Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k254o/p_rust_meets_llama2_openai_compatible_api_written/",
          "author": null,
          "description": "Hello,\n I have been working on an OpenAI-compatible API for serving LLAMA-2 models written entirely in Rust. It supports offloading computation to Nvidia GPU and Metal acceleration for GGML models !\n Here is the project link: Cria- Local LLAMA2 API\n You can use it as an OpenAI replacement (check out the included `Langchain` example in the project).\n This is an ongoing project, I have implemented the `embeddings` and `completions` routes. The `chat-completion` route will be here very soon!\n Really interested in your feedback and I would welcome any help :) !\n ​\n ​\n    submitted by    /u/amindiro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k254o/p_rust_meets_llama2_openai_compatible_api_written/",
          "publishedOn": "2023-08-06T22:06:55.000Z",
          "wordCount": 2550,
          "title": "[P] Rust meets Llama2: OpenAI compatible API written in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k0rz2/p_aicrafted_daily_digest_exploring_latest_ml/",
          "author": null,
          "description": "submitted by    /u/eusben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k0rz2/p_aicrafted_daily_digest_exploring_latest_ml/",
          "publishedOn": "2023-08-06T21:11:03.000Z",
          "wordCount": 2468,
          "title": "[P] AI-Crafted Daily Digest: Exploring Latest ML Developments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k0p9j/p_triple_threat_the_power_of_transcription/",
          "author": null,
          "description": "Open source Audio pipeline for transcription, translation and summarization.\n Check out our demo page to generate your own transcription, summary, and translation, or use our browser extension to get live transcriptions.\n    submitted by    /u/eusben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k0p9j/p_triple_threat_the_power_of_transcription/",
          "publishedOn": "2023-08-06T21:08:01.000Z",
          "wordCount": 2490,
          "title": "[P] Triple Threat: The Power of Transcription, Summary, and Translation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k0er6/d_comprehensive_learning_resources_that_emphasize/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k0er6/d_comprehensive_learning_resources_that_emphasize/",
          "publishedOn": "2023-08-06T20:56:27.000Z",
          "wordCount": 2517,
          "title": "[D] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jzg1x/d_how_to_predict_long_sequences_of_events_to/",
          "author": null,
          "description": "Hey! \n I am working on a project to predict the best sequences of marketing channel so that sales is maximized. I have 20 ways of reaching out to the customer (email, phone, face2face...). I have 20 days of interaction history and it's generated sales, recorded for past 2 years. I have to predict for the next 20 working days(1 month)\n So far, I have tried ensemble methods, svm, fully connected nn, etc. But it is quite apparent that these are not good solutions. \n Any suggestions on ml/dl methods? Papers, blogs or other resources would be much appreciated\n    submitted by    /u/TUSH11235  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jzg1x/d_how_to_predict_long_sequences_of_events_to/",
          "publishedOn": "2023-08-06T20:17:35.000Z",
          "wordCount": 2557,
          "title": "[D] How to predict long sequences of events to optimize sales?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jub9s/aiml_best_practices_during_a_gold_rush_d/",
          "author": null,
          "description": "submitted by    /u/swodtke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jub9s/aiml_best_practices_during_a_gold_rush_d/",
          "publishedOn": "2023-08-06T16:49:59.000Z",
          "wordCount": 2468,
          "title": "AI/ML Best Practices During a Gold Rush [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jr6be/r_looking_for_perspectives_pursuing_a_phd_in_ai/",
          "author": null,
          "description": "Greetings fellow researchers,\n I am 27, currently working remotely at a healthcare IT company based in Silicon Valley (6+ years in industrial research) where I apply deep learning methods and large language models. I recently received an exciting opportunity to pursue a PhD at the Technical University of Denmark (DTU) in a similar research area. \n While I am grateful for my current position and compensation, Have published in NeurIPS, EMNLP, ACL, ACM etc (NLP) with really good citations under company. I feel unsatisfied with the learning opportunities available in company & industry.\n I am strongly considering pursuing the DTU PhD program full-time, but wanted to get perspectives from others before making a decision. How strong is DTU's AI research community?\n Given the rapid advances in large language models, is now an ideal time to immerse myself in academic research? There are many topics that interest me, including fairness, ethics, hallucinations, quantization, specialized domains like healthcare/finance, and federated learning combined with LLMs.\n Would appreciate any insights on whether moving into academia would be a wise choice at this stage versus remaining in industry. I welcome any suggestions or considerations I should keep in mind. \n Thank you for taking the time to share your thoughts!\n    submitted by    /u/Traditional-Poet2746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jr6be/r_looking_for_perspectives_pursuing_a_phd_in_ai/",
          "publishedOn": "2023-08-06T14:36:43.000Z",
          "wordCount": 2665,
          "title": "[R] Looking for Perspectives: Pursuing a PhD in AI vs Continuing in Industry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jpk6l/p_generative_language_model_gru_learns_constant/",
          "author": null,
          "description": "Context\n I'm working on an RNN-based model that should learn how to guess the next character given a simple prompt based on all scripts from Friends to generate non-existing Friends dialogue. It is heavily inspired by Andrej Karpathy's blog post on RNN's. I'm mostly doing this for training, and because it's pretty fun.\n I have a little experience with deep learning in the sense that I am familiar with most common architectures and have intermediate understanding of how deep learning models work and are trained. I haven't created many models from scratch though, yet.\n Network\n My GRU is fairly simple. I'll save you the exact code, but instead give a systematic overview of all network layers. It's implemented with Pytorch:\n INPUT: sequence of integers representing a symbol based on mapping e…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jpk6l/p_generative_language_model_gru_learns_constant/",
          "publishedOn": "2023-08-06T13:23:12.000Z",
          "wordCount": 2825,
          "title": "[P] Generative Language Model (GRU) learns constant representation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jovx4/d_today_the_source_code_button_is_gone/",
          "author": null,
          "description": "submitted by    /u/Better-Process5239  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jovx4/d_today_the_source_code_button_is_gone/",
          "publishedOn": "2023-08-06T12:50:51.000Z",
          "wordCount": 2466,
          "title": "[D] Today the source code button is gone...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jlomu/p_underlining_detection_algorithm/",
          "author": null,
          "description": "Hey.\n I'm currently working on an application that digitalizes text from physical book pages using Google's Cloud Vision API.\n I'm looking to add a functionality that can recognize and highlight underlined words within the scanned pages. I initially thought this would be a common feature and expected to find existing open-source solutions or libraries that I could use. To my surprise, I've been unable to find any. \n I am just really bad at finding it, or is this not as straightforward as I initially thought?\n    submitted by    /u/pangu2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jlomu/p_underlining_detection_algorithm/",
          "publishedOn": "2023-08-06T09:50:18.000Z",
          "wordCount": 2538,
          "title": "[P] Underlining detection algorithm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jjfkj/n_computer_vision_news_of_august_2023_with_ai_cv/",
          "author": null,
          "description": "Dear all,\n Here is Computer Vision News of August 2023.\n Read 44 pages about AI, Deep Learning, Computer Vision and more!\n Online version (recommended)\n PDF version\n Free subscription on page 44.\n Enjoy!\n https://preview.redd.it/e143wha20ggb1.jpg?width=794&format=pjpg&auto=webp&s=14a699f80f4b2de94addc8242e8978d3e185309f\n    submitted by    /u/Gletta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jjfkj/n_computer_vision_news_of_august_2023_with_ai_cv/",
          "publishedOn": "2023-08-06T07:33:40.000Z",
          "wordCount": 2494,
          "title": "[N] Computer Vision News of August 2023 with AI, CV, DL and ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jhfk7/d_fine_tuning_or_semantic_search_with_a_vector/",
          "author": null,
          "description": "Experts, I am a beginner here and seeking some advise here please.\n I am have compiled a high quality Q&A dataset (around 1200 entries) for a domain specific topic.\n What's the best course of action here to use LLM with that specific knowledge base?\n 1) Finetuning a model? if so which one is a good candidate? OpenAI let's me finetune some models and later, all my users have to do is use pass the model name to the API\n 2) Use the regular vector database + embeddings for augmented retrieval\n \n I prefer (1) but I am not sure how it will perform.\n Option (2) should work, since we really just use semantic search to bring in context to the LLM, etc.\n I hope you can say that (1) works nicely, if not please help me learn why.\n Thank you in advance!\n    submitted by    /u/entered_apprentice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jhfk7/d_fine_tuning_or_semantic_search_with_a_vector/",
          "publishedOn": "2023-08-06T05:36:43.000Z",
          "wordCount": 2599,
          "title": "[D] Fine tuning or semantic search with a vector database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jeycg/llm_related_pytorch_code_d/",
          "author": null,
          "description": "Where to find LLM related pytorch code with code explanations?\n    submitted by    /u/thorin_olamadal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jeycg/llm_related_pytorch_code_d/",
          "publishedOn": "2023-08-06T03:21:26.000Z",
          "wordCount": 2464,
          "title": "LLM related pytorch code [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jd1wu/d_how_does_one_withdraw_a_paper_from_neurips/",
          "author": null,
          "description": "First time submitter here and was unable to find a similar post (and thought the community might benefit from this in the future!). How do I withdraw from Neurips? All the instructions I found are from 2017, 2018. Do I need to contact someone or do I just need to \"Add Withdrawal\" on OpenReview.\n    submitted by    /u/Dramatic-Gap-4681  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jd1wu/d_how_does_one_withdraw_a_paper_from_neurips/",
          "publishedOn": "2023-08-06T01:44:20.000Z",
          "wordCount": 2512,
          "title": "[D] How does one withdraw a paper from Neurips?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jb52o/d_why_have_separate_stages_for_rpn_proposal/",
          "author": null,
          "description": "Just what the title says.\n Also is this (splitting prediction into 2 stages) a prominent paradigm in other areas of ML too? I am reading about something called the \"Action Transformer\" created by Adept AI, and it also has 2 stages: instruction generation and code generation.\n    submitted by    /u/FloatingDelusion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jb52o/d_why_have_separate_stages_for_rpn_proposal/",
          "publishedOn": "2023-08-06T00:13:19.000Z",
          "wordCount": 2507,
          "title": "[D] Why have separate stages for RPN (proposal generation) and ROI (refinement)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j5zw6/d_how_to_mathematically_prove_that_a_neural/",
          "author": null,
          "description": "Hello r/MachineLearning!\n I'm working on understanding how a neural network converges and wish to approach this mathematically. Can anyone recommend resources, papers, or tools that could assist me in proving this?\n Thank you in advance for your help! \n Edit: Removed converges faster to remove ambiguity\n    submitted by    /u/abystoma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j5zw6/d_how_to_mathematically_prove_that_a_neural/",
          "publishedOn": "2023-08-05T20:35:49.000Z",
          "wordCount": 2506,
          "title": "[D] How to Mathematically Prove that a Neural Network is Converging Faster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j4tyn/d_transformer_for_realtime_action_recognition/",
          "author": null,
          "description": "Do you aware of any work for realtime action recognition that use transformer? This is different with conventional transformer in a sense that we don’t have access to future information, so how do we change the training strategy? Also, it’s inefficient if we use the entire history; are there any smart way to select which frame in the past to keep?\n    submitted by    /u/Ok_Influence505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j4tyn/d_transformer_for_realtime_action_recognition/",
          "publishedOn": "2023-08-05T19:48:08.000Z",
          "wordCount": 2516,
          "title": "[D] Transformer for realtime action recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j244e/p_vectara_flowise/",
          "author": null,
          "description": "u/Vectara is now integrated with r/flowise, so you can easily build no-code GenAI Apps at scale.\n Check out the video here: https://twitter.com/ofermend/status/1687138158692196352\n You can sign up for a free vectara.com account to get started.\n    submitted by    /u/ofermend  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j244e/p_vectara_flowise/",
          "publishedOn": "2023-08-05T17:55:28.000Z",
          "wordCount": 2486,
          "title": "[[P] Vectara+ Flowise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j11k1/custom_tokenizers_optimization_opportunity_or/",
          "author": null,
          "description": "I've recently started to explore the possibility of working with custom tokenizers. I will preface this by saying I'm not a tokenizer guy. I just don't know that much about their construction. I understand how they work, but I'm probably behind the latest developments in tokenizers.\n So, I thought it wisest to reach out to the community for advice or clarity.\n Context:\n I've collected about 15 GB of data over the last month. It's incredibly clean and well-organized. The core goal of the data is to train a model to solve or assist with a particular development problem. This means that much of my data is a code/natural language mix. It's delimited clearly, and the formatting is uniform. The entire dataset has been normalized and standardized. It's taken me a lot of time to produce and that's…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j11k1/custom_tokenizers_optimization_opportunity_or/",
          "publishedOn": "2023-08-05T17:10:18.000Z",
          "wordCount": 3088,
          "title": "Custom Tokenizers - Optimization Opportunity or Waste of Time? [D], [R}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j0xwt/r_the_quest_to_have_endless_conversations_with/",
          "author": null,
          "description": "​\n https://preview.redd.it/mbkb10icqbgb1.png?width=1400&format=png&auto=webp&s=7a15423060ddfeffe4651340bcc6fd7cf36dde10\n I started a blog post series about the limitations of language models for dealing with long texts.\n Feedback is welcome!\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j0xwt/r_the_quest_to_have_endless_conversations_with/",
          "publishedOn": "2023-08-05T17:06:01.000Z",
          "wordCount": 2481,
          "title": "[R] The Quest to Have Endless Conversations with Llama and ChatGPT 🗣️💬",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15izni1/d_energy_efficiency_of_data_centers_versus/",
          "author": null,
          "description": "Hi everyone,\n With the recent boom of LLMs, we have seen both ends of the spectrum advance at a very fast pace, from OpenAI GPT4, which runs on huge data centers operated by Azure, to llama.cpp, which runs on consumer laptops.\n While both have their pros and cons, for instance, open-source models on decentralized compute reduce the need to trust or rely on centralized actors like Cloud providers, the efficiency of running training/inference on personal setups is not often discussed.\n I am therefore interested in learning how more energy/cost efficient it is to train/serve AI models on data centers vs doing it on personal computers. \n Do you know if there have been studies? \n In theory, I guess that several factors, such as economies of scale, use of renewable energy sources in some data centers, such as Canada, advanced cooling systems and advanced hardware, make data centers more cost/energy efficient.\n I guess some modeling on a precise use case where we fix some variables could help have an idea. For instance, one could ask, what is the energy/cost/time needed to predict 1 billion tokens from a Llama 2 70B in a data center with X amount of A100s, vs on Y different consumer CPU / GPUs.\n If anyone has references to models or past studies I would be quite interested. Of course, using data centers implies trusting those people, but I am not considering that factor for this discussion as I am focusing on understanding best what is the best setup to have optimal enrgy/cost/time for AI.\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15izni1/d_energy_efficiency_of_data_centers_versus/",
          "publishedOn": "2023-08-05T16:12:32.000Z",
          "wordCount": 2720,
          "title": "[D] Energy efficiency of data centers versus consumer-grade setups for training and inference of LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iz6v7/d_nvidia_gpu_shortage_is_top_gossip_of_silicon/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iz6v7/d_nvidia_gpu_shortage_is_top_gossip_of_silicon/",
          "publishedOn": "2023-08-05T15:53:59.000Z",
          "wordCount": 2470,
          "title": "[D] Nvidia GPU shortage is ‘top gossip’ of Silicon Valley",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iyyyp/iccv_challenge_on_geographical_domain_adaptation_r/",
          "author": null,
          "description": "As part of ICCV 2023 in Paris, this year we are organizing a challenge on solving domain gaps that occur when computer vision models are transferred across geographical locations. The challenge covers three tracks in unsupervised scene adaptation, image adaptation and universal adaptation. The challenge is open to everyone, with attractive prizes for the winners. Check it out at the following links!\n Challenge Rules and Guidelines: https://geonet-challenge.github.io/ICCV2023/challenge.html\n Challenge Registration: https://forms.gle/zSZA1iaPD3mZxjyn7\n Code and baselines: https://github.com/ViLab-UCSD/GeoNet\n The training data for the challenge is already available, and the test data will be released to the registered participants.\n    submitted by    /u/GeoNetICCV2023  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iyyyp/iccv_challenge_on_geographical_domain_adaptation_r/",
          "publishedOn": "2023-08-05T15:44:45.000Z",
          "wordCount": 2548,
          "title": "ICCV Challenge on Geographical Domain Adaptation [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iwdgs/p_mechdesigner_assistant_ai_future_engineers/",
          "author": null,
          "description": "Hi guys\n Im looking for groups or communities where i could discuss about certain topic. Im a software developer and a mechanical engineer and recently made an app that combines gpt4 model to perform engineering tasks like CAD models creation and performing stress analysis. I would like find people who share the same passion and perhaps would like to discuss about that, exchange the concepts, ideas and visions. Im getting to the point where i will need to implement own trained model and im no ML expert so would be great to discuss about the architecture etc. \n Here is a demo of my app\n MechDesigner Assistant AI: Future Engineers\n Best regards\n Pyotr\n    submitted by    /u/pyotr_vozniak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iwdgs/p_mechdesigner_assistant_ai_future_engineers/",
          "publishedOn": "2023-08-05T13:56:26.000Z",
          "wordCount": 2575,
          "title": "[P] MechDesigner Assistant AI: Future Engineers. Looking for communities, groups etc to exchange ideas, experience",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iv2tj/p_drum_kick_generation_app/",
          "author": null,
          "description": "Hi, I am a new starter with ML apps and want to build a first app preferably using existing (trained) models. The idea is an app that takes a text description of a wished kick drum (for example: create a 808 kick with enhanced subs and filtered above 15kHz) and then generates a corresponding hifi sample of the description (44,1k or 48k). \n I would like to learn how to do that with some peers happy to help me.\n As said this would be my first attempt. About me: I only followed Deep Learning theoretical courses from Andrew Ng and never built or used existing models so I'd appreciate some guidance if you are interested to support. Thanks a lot \n    submitted by    /u/freeabt19  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iv2tj/p_drum_kick_generation_app/",
          "publishedOn": "2023-08-05T12:58:48.000Z",
          "wordCount": 2573,
          "title": "[P] Drum Kick Generation app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iunr9/d_human_biological_and_spiking_neural_networks_a/",
          "author": null,
          "description": "submitted by    /u/Impressive-Ad-8964  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iunr9/d_human_biological_and_spiking_neural_networks_a/",
          "publishedOn": "2023-08-05T12:38:31.000Z",
          "wordCount": 2463,
          "title": "[D] Human Biological and Spiking Neural Networks. A Literature Review of Recent BNN and SNN Advances)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iug4w/p_nerfjl_a_realtime_neural_3d_scene/",
          "author": null,
          "description": "submitted by    /u/Fincho64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iug4w/p_nerfjl_a_realtime_neural_3d_scene/",
          "publishedOn": "2023-08-05T12:28:12.000Z",
          "wordCount": 2464,
          "title": "[P] Nerf.jl a Real-Time Neural 3D Scene Reconstruction in Pure Julia | Anton Smirnov | JuliaCon 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15itmy9/dhow_do_you_usually_deal_with_multimodal_target/",
          "author": null,
          "description": "Popular machine model techniques such as LightGBM and XGBoost output predictions that are unimodally distributed(only one hump) but seem to beat other models specialized to deal with multimodal data. Or am I just wrong? \n It just doesnt look right.\n https://preview.redd.it/6xrd7hgm4agb1.png?width=1000&format=png&auto=webp&s=a4518549f609c6436af410ae87a0c6a24cff6ea7\n    submitted by    /u/runawaychicken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15itmy9/dhow_do_you_usually_deal_with_multimodal_target/",
          "publishedOn": "2023-08-05T11:47:42.000Z",
          "wordCount": 2497,
          "title": "[D]How do you usually deal with multimodal target variable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15itj9s/d_transformer_implementation_help/",
          "author": null,
          "description": "Hey I've tried to implement the transformer architecture on my own to understand it better. The outputs look fine (I'm only looking at shapes) and I wanted to know if it's right firstly, and if there is anyway to implement it in a more efficient way.\n Code -\n import torch import torch.nn as nn class MultiHeadSelfAttention(nn.Module): def __init__(self, nheads=8, dim=512, bias=True, dropout=0.2): super().__init__() assert dim % nheads == 0, \"dimension must be divisible by number of heads\" self.nheads = nheads self.dim = dim self.head_dim = dim // nheads self.scale = self.head_dim**-0.5 self.softmax = nn.Softmax(dim=-1) self.dropout = nn.Dropout(dropout) self.to_keys = nn.Linear(dim, self.dim_heads * nheads, bias=bias) self.to_queries = nn.Linear(dim, self.dim_heads * nheads, bias=bias) self.to_values = nn.Linear(dim, self.dim_heads * nheads, bias=bias) self.to_out = nn.Linear(self.dim_heads * nheads, dim, bias=bias) def change_shape(self, x): b_size = x.shape[:-1] return x.reshape(*b_size, self.nheads, self.head_dim) def forward(self, x, mask=True): q = self.change_shape(self.to_queries(x)) k = self.change_shape(self.to_keys(x)) v = self.change_shape(self.to_values(x)) dot_score = q @ k.transpose(-2, -1) * self.scale if mask: tril = torch.tril(torch.ones(dot_score.shape[-2:])) dot_score = dot_score.masked_fill(tril == 0, float(\"-inf\")) attn = self.softmax(attn) attn = self.dropout(attn) out = torch.einsum(\"bnk,bnd->bnd\", attn, v) b_size = out.shape[:-2] out = out.view(*b_size, -1) return self.to_out(out) \n Thank you!\n    submitted by    /u/04RR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15itj9s/d_transformer_implementation_help/",
          "publishedOn": "2023-08-05T11:42:16.000Z",
          "wordCount": 2643,
          "title": "[D] Transformer implementation - help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15itb45/p_implement_parallel_training_using_the/",
          "author": null,
          "description": "https://github.com/NoteDancing/Note This project allows you to easily implement parallel training with the multiprocessing module. \n    submitted by    /u/NoteDancing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15itb45/p_implement_parallel_training_using_the/",
          "publishedOn": "2023-08-05T11:30:27.000Z",
          "wordCount": 2471,
          "title": "[P] Implement parallel training using the multiprocessing module.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ioim1/r_forward_process_of_diffusion_models/",
          "author": null,
          "description": "In the forward process of diffusion models, gaussian noise is added -- when this is done, is the resulting \"noisy image\" clipped to be within the pixel-value bounds (ie [0, 255] or [0, 1]), or is it allowed to exceed these limits? \n Clipping makes sense as there is no interpretation for pixel values which exceed these limits.\n On the other hand, the problem with clipping is that if the added noise is clipped, you are not adding truly gaussian noise, which seems problematic as much of the theory behind diffusion models assumes true gaussian noise. \n Any ideas about what is done in practice, and whether or not this has implications from a theoretical standpoint?\n    submitted by    /u/alkaway  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ioim1/r_forward_process_of_diffusion_models/",
          "publishedOn": "2023-08-05T06:57:10.000Z",
          "wordCount": 2569,
          "title": "[R] Forward Process of Diffusion Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ioahe/team_is_burning_out_trying_to_create_a_dataset/",
          "author": null,
          "description": "Good Evening ML peeps\n So I am currently creating a dataset in a team of three. This dataset is aimed to create a object detection model for around 11 classes. We have aimed to label around approx. 4000. Our current workflow is a couple of scripts scraping from Pinterest and using Label Studio for labeling. We labeled approx. 25% to our goal but realized that we are about to burn out. We'd prefer that whatever solution there is is self hosted and not paid.\n Thoughts? is there some kind of workflow we are missing to create a dataset?\n    submitted by    /u/PlanetAcorn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ioahe/team_is_burning_out_trying_to_create_a_dataset/",
          "publishedOn": "2023-08-05T06:43:42.000Z",
          "wordCount": 2559,
          "title": "Team is burning out trying to create a dataset. Any solutions? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15imv19/d_documentbased_qna_without_openai/",
          "author": null,
          "description": "I am working on a project that is very popular with the inception of Langchain + GPT applications. However, I want to make it open source and hence don't want to use GPT. So something like Langchain + LLama2, etc. I know currently Langchain only supports GPT but any other ideas are highly appreciated!\n    submitted by    /u/vishank97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15imv19/d_documentbased_qna_without_openai/",
          "publishedOn": "2023-08-05T05:22:58.000Z",
          "wordCount": 2508,
          "title": "[D] Document-based QnA without OpenAI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ii969/d_looking_for_suggestions_guides_on_how_to_switch/",
          "author": null,
          "description": "Hi all, \n I'm interested in redesigning my application to utilize an open-source embeddings model and a different vector DB. My current issue with embeddings is that processing large volumes of data into a vector DB using ada-002 is unreliable, with frequent API timeouts occurring or issues interacting with Pinecone. This is super problematic as it's difficult to track which data has / hasn't been stored correctly. I also know that many open-source embeddings models are more performant and will allow for more long term control over my data. \n However, the advantage of using OpenAI / Pinecone has of course been simplicity in production and not having to worry about queries / retrieval working efficiently. To give context, I'm dealing with a large volume of documents, such that if I were to embed my documents into a FAISS index with a small sentence transformers model, it would constitute 12GB, so a really simple solution like storing within the same application database is probably a no-go.\n In initiating this switch, I want to know the best approach towards: \n A) Utilizing an open-source embeddings model in a production context (is it best to host as an API via a cloud provider and what are some considerations I should think about? What's a fast / reliable way of setting this up? I would like prioritise a more simple approach if possible.) \n B) What Vector DB I should be looking into as an alternative and what's the best way to achieve self-hosted so that it would be equally performant compared to hosted services like pinecone (Docker? AWS?)? \n    submitted by    /u/theheffalump2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ii969/d_looking_for_suggestions_guides_on_how_to_switch/",
          "publishedOn": "2023-08-05T01:30:26.000Z",
          "wordCount": 2732,
          "title": "[D] Looking for suggestions / guides on how to switch from OpenAI Embeddings and Pinecone to open-source / self-hosted architecture options.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ifjfc/d_gpumachine_ondemand_rental_that_runs_windows_10/",
          "author": null,
          "description": "Anyone know of a cloud service renting on-demand GPU instances (RTX 4090 preferably) that run Windows 10 or newer?\n Believe me, I know...\n I rent on-demand instances from vast.ai for Linux and have been exceedingly happy with their services. I've also used paperspace in the past with good success. Unfortunately, we are in need of RTX 4090s (or roughly equivalent performing Tesla cards) that run on a host OS of Windows 10+ (Server/Win11/etc all fine) because a lot of the modeling software in the industry I work in runs on Windows-only, which is absurd, but nevertheless the truth.\n The fastest I can find are A6000s on paperspace which won't cut the mustard. At the moment we have a 3090 and a bunch of 3070s on-prem which are doing OK but the RTX 4090 is simply much much better, and unsurprisingly the Windows-only software is also not coded in a way that takes advantage of multiple GPUs all that well either.\n Thanks for any help or referrals provided, I really appreciate it. \n (Have checked paperspace, vastai, runpod, and a few other smaller ones to no avail)\n    submitted by    /u/kyleboddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ifjfc/d_gpumachine_ondemand_rental_that_runs_windows_10/",
          "publishedOn": "2023-08-04T23:30:32.000Z",
          "wordCount": 2649,
          "title": "[D] GPU/Machine on-demand rental that runs Windows 10+ as host OS? (I know, I know...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i9koq/d_how_do_i_improve_performance/",
          "author": null,
          "description": "Hello everyone. I am new to this sub so please go easy on me lol.\n I want to implement a neural net that recognizes whether an object in an image matches one of a set of objects with limited training data. \n I already have worked on a siamese network implementation with triplet loss and ResNet, but I am not getting great performance. Should I do something else?\n For extra info, there are roughly 300 objects/classes and around 7 images per object (most are augmented images)\n    submitted by    /u/Nearby_Ad_5644  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i9koq/d_how_do_i_improve_performance/",
          "publishedOn": "2023-08-04T19:37:58.000Z",
          "wordCount": 2540,
          "title": "[D] How do I improve performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i94w0/r_learning_to_model_the_world_with_language_uc/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.01399 \n Github: https://github.com/jlin816/dynalang Code coming soon!\n Abstract:\n  \nTo interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning object…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i94w0/r_learning_to_model_the_world_with_language_uc/",
          "publishedOn": "2023-08-04T19:21:07.000Z",
          "wordCount": 2708,
          "title": "[R] Learning to Model the World with Language - UC Berkeley 2023 - Dynalang an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i82xh/p_i_created_scorecast_a_tool_to_predict_the/",
          "author": null,
          "description": "https://preview.redd.it/p70yknwm15gb1.png?width=1901&format=png&auto=webp&s=7417914304cc23d6691653cd73396bd600a44b0a\n Hey Guys,\n I am happy to share with you a web application I've working on the past couple weeks. It's a tool to predict the outcome of soccer games in minor football leagues. Named ScoreCast, it predicts the outcome of soccer games in six minor leagues: Serie A Brazil, Serie B Brazil, Primera Division Argentina, J1 League Japan, Eliteserien Norway, and Veikkausliiga Finland.\n Since I am really interested in football analytics and also not being able to find many online tools for predicting the outcomes in minor soccer leagues, I had the need to create ScoreCast to have it as a tool for guidance on this field.\n If you want to check it out, here are some links that might help:\n  \nGithub: https://github.com/Costasgk/ScoreCast\n The App: https://score-cast-3a6cb8fe5c50.herokuapp.com/\n Medium: https://medium.com/@costascg9/scorecast-a-tool-for-predicting-football-game-outcomes-in-minor-leagues-666f7acca3a\n  \nThank you for your time!\n    submitted by    /u/Costas_8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i82xh/p_i_created_scorecast_a_tool_to_predict_the/",
          "publishedOn": "2023-08-04T18:39:21.000Z",
          "wordCount": 2599,
          "title": "[P] I created ScoreCast, a tool to predict the outcome of football games in minor football leagues.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i6vfb/p_struggling_with_audio_enhancement_using_gans/",
          "author": null,
          "description": "I'm working on a Python project that aims to transform phone-quality acoustic guitar recordings into studio-like ones. My approach involves using a Generative Adversarial Network (GAN) with two components: a Generator and a Discriminator.\n Here's a quick rundown of my process:\n Data Loading & Preprocessing: Convert acoustic guitar recordings to spectrograms and split into training and validation sets.\n Generator: Neural network trained to create high-quality studio recording spectrograms from low-quality inputs.\n Discriminator: Another neural network trained to differentiate between real and generator-created high-quality spectrograms.\n Training: Train the Generator and Discriminator against each other in a cat-and-mouse game of deception and detection.\n Audio Enhancement: Feed the Generator a low-quality spectrogram, get a high-quality one out, and convert it back into an audio file.\n I'm reaching out because I'm not entirely satisfied with the quality of the output. The enhanced audio is just rhythmic noise, what am i missing with generating the audio?\n I'm wondering if anyone here has experience with GANs for audio enhancement and can offer some advice. Is there something I might be missing in my approach? Are there any tips or tricks you've found helpful in your own work?\n And yes, I'm prepared for you to tear me a new one. Bring on the constructive criticism!\n git repo:\n https://github.com/Gabeiscool420/AURAL_GAN-predictive_model/blob/main/requirements.txt\n    submitted by    /u/S0UNDSAGE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i6vfb/p_struggling_with_audio_enhancement_using_gans/",
          "publishedOn": "2023-08-04T17:52:28.000Z",
          "wordCount": 2661,
          "title": "[P] Struggling with Audio Enhancement using GANs - Any Suggestions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i51bz/d_parametric_development/",
          "author": null,
          "description": "I wanted to share with you an approach to software development that I've been exploring recently: Parametric Development. This involves using artificial intelligence (AI) models, including GPT-like models, BART-like models, and other specialized transformer models, to assist in writing, debugging, and documenting code.\n My journey with programming is a bit unconventional. I took one year of computer science at university and learned how to write \"Hello, World!\" in TurboPascal from an old university textbook in late primary school. That was the extent of my programming experience until about a month ago. Since then, I've been using AI models to write code for my ideas, as I don't have extensive programming skills. These AI models have written and debugged every single line of code in my pro…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i51bz/d_parametric_development/",
          "publishedOn": "2023-08-04T16:41:22.000Z",
          "wordCount": 2774,
          "title": "[D] Parametric Development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i0uxv/d_cikm_23_notification/",
          "author": null,
          "description": "Today is the day of paper notification according to the CFP. Has anyone received the notification?\n    submitted by    /u/Alliswell2257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i0uxv/d_cikm_23_notification/",
          "publishedOn": "2023-08-04T13:59:37.000Z",
          "wordCount": 2469,
          "title": "[D] CIKM 23 Notification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hwr6y/discussion_automated_unstructured_structured_oss/",
          "author": null,
          "description": "Hey folks,\n i'm a data engineer in the traditional space for over 10 years. I am working on a library for easy transitioning unstructured to structured data. The use case is that I would regularly build a ton of python pipelines but without schema management, they would be a pain to maintain.\n 2y ago I started working on this library https://pypi.org/project/dlt/, and now it''s ready to help people like myself to load json to db/parquet/iceberg with a 1-liner with schema evolution. Declarative loading possible.\n I am looking for the following feedback\n - What would make this more useful in the ML space? Specific destinations? Are the docs usable or do you expect something different? let me know what. For example, we are adding Weaviate vector db and Athena + Iceberg in the next weeks.\n - any features you are missing? or any ideas that you think would be helpful? \n - are the docs relatable, understandable? what are you missing?\n ​\n docs are here, you can find colab demos under getting started: https://dlthub.com/docs/intro\n    submitted by    /u/Thinker_Assignment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hwr6y/discussion_automated_unstructured_structured_oss/",
          "publishedOn": "2023-08-04T10:50:41.000Z",
          "wordCount": 2630,
          "title": "[Discussion] Automated unstructured -> structured OSS library - give me your requirements",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hw8gw/d_validate_my_approach_to_do_unsupervised_fine/",
          "author": null,
          "description": "Any suggestions on how to prepare code data to fine tune a code LLM in an unsupervised way or is it even possible?\n For example: Task: Code summarisation with custom code base (with no summaries) Let's assume that this code base is unique and a pre-trained model is giving unsatisfactory results. Now to fine tune there are three options, 1. Manually prepare summaries for a portion of the code and fine tune 2. Find a similar code base which has the labels (docstring) and fine tune 3. Mask some portions of the code randomly and give as input and output will be the masked portions\n Options 1 and 2 don't seem feasible for a production environment. \n The reasoning behind option 3 is that with no availability labels, the model will learn the patterns in the code base and provide a better summarisation with its pre-trained knowledge.\n I tried the option 3 with CodeT5+ fine tuning. The format of input and output was as follows Input:\n def __init__(self, text, font): self._text = text self._font = font def get_text(self): |<mask>| def set_text(self, value): self._text = value``` \n Output: return self._text\n    submitted by    /u/dire_wolf_cookie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hw8gw/d_validate_my_approach_to_do_unsupervised_fine/",
          "publishedOn": "2023-08-04T10:22:55.000Z",
          "wordCount": 2653,
          "title": "[D] Validate my approach to do Unsupervised Fine tuning of Code LLMs like CodeT5+ and Starcoder with custom code base",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hvp20/project_enquiry_for_individuals_working_with/",
          "author": null,
          "description": "Hello Everyone . Myself Harsha. I am final year Masters student in Berlin pursuing my thesis currently. For my thesis \"Natural Language Processing in Data transfer across documents in Commidity Trading Industry\" i am in search for professionals who are working with NLP currently in companies who can lend me 10 minutes of their time for a personal interview. THIS WOULD BE A LOT HELPFUL. please do let me know.\n Thanks in advance\n    submitted by    /u/Aimerforlife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hvp20/project_enquiry_for_individuals_working_with/",
          "publishedOn": "2023-08-04T09:53:18.000Z",
          "wordCount": 2531,
          "title": "[Project] Enquiry for individuals working with Natural Language Processing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ht5yd/d_why_is_tflite_c_so_hard_to_compile/",
          "author": null,
          "description": "Has anyone actually done this and can dm me? I am trying to incldue the interpreter to run inference with a simple c++ program and a custom trained model. But I cannot figure out how to update include paths and cannot see any resources online.\n    submitted by    /u/Agreeable_Fee477  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ht5yd/d_why_is_tflite_c_so_hard_to_compile/",
          "publishedOn": "2023-08-04T07:27:49.000Z",
          "wordCount": 2503,
          "title": "[D] Why is tflite c++ so hard to compile?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hs7c7/from_sparse_to_soft_mixtures_of_experts_r/",
          "author": null,
          "description": "submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hs7c7/from_sparse_to_soft_mixtures_of_experts_r/",
          "publishedOn": "2023-08-04T06:31:56.000Z",
          "wordCount": 2468,
          "title": "From Sparse to Soft Mixtures of Experts [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hr6xb/d_why_is_it_so_hard_to_rent_gpu_time/",
          "author": null,
          "description": "I'm just a new guy, so take it easy please :) - Is it just because I'm just signing up for the cloud compute services? Will this get easier?\n I have a 3090 so I can do quite a bit in my home office, but my clients need some larger models now, and I've been trying to pay for instances with an A100 at least. It's been really a lot of push-back...is this normal? What can I do to get access to larger GPUs sooner?\n I have tried paperspace, aws, googlecloud, llambda, linode...would love to know some other services or tools you folks use to get work done.\n Thank you for your time. Interested to hear how you spin up high VRAM environments for projects.\n    submitted by    /u/UrbanSuburbaKnight  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hr6xb/d_why_is_it_so_hard_to_rent_gpu_time/",
          "publishedOn": "2023-08-04T05:34:43.000Z",
          "wordCount": 2584,
          "title": "[D] Why is it so hard to rent GPU time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hqpdf/d_milvus_search_filtering_based_on_string/",
          "author": null,
          "description": "While doijg vector search on embeddings i wanted to apply a filter based on a column value in milvus. As milvus supports boolean value to apply the filter (or hybrid search) Can someone help me with the boolean code snippet which will apply the filter based on a string value of a field Ex. I'm doing vector search on the field \"context\" and need to filter the result based on a specific \"filename\" string value to further filter and improve the results I'm using milvus 2.2\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hqpdf/d_milvus_search_filtering_based_on_string/",
          "publishedOn": "2023-08-04T05:07:00.000Z",
          "wordCount": 2542,
          "title": "[D] milvus search filtering based on string",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hptx2/r_proof_of_lemma_51_in_bayesian_design_principles/",
          "author": null,
          "description": "This paper won ICML 2023 outstanding paper award, its idea is really interesting and I want to follow the details. Lemma 5.1 significantly paves towards the core theoretical results, but the paper does not provide a formal proof. I do not have a deep background on game theory, maybe the proof is obvoius to the professional.\n ​\n https://preview.redd.it/ih6u3wiyr0gb1.png?width=464&format=png&auto=webp&s=cc895b9701e3600213825c34ef3b542f53d65233\n I undersand this lemma tries to construct a Nash equilibrium upon the additional assumption of strong convexity, but why this maximin solution is a Nash equilibrium? Very appreciated if someone provide some hint.\n    submitted by    /u/Kyeon-G  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hptx2/r_proof_of_lemma_51_in_bayesian_design_principles/",
          "publishedOn": "2023-08-04T04:20:24.000Z",
          "wordCount": 2551,
          "title": "[R] Proof of Lemma 5.1 in 'Bayesian Design Principles for Frequentist Sequential Learning'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15holfn/d_any_noticeable_work_regarding_the_effect_of_a/",
          "author": null,
          "description": "Hi. I'm trying to build a text encoder for a specific domain and want to know what sort of papers there are out there that I should take note of. I may be wrong but it seems that these days ever since LLMs started taking over the choice of tokenizer has become trivial and therefore doesn't warrant much discussion.\n One paper that I remember reading a while ago talked about the effect of using a custom-made vocabulary for the biomedical domain (Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art (Lewis et al., 2020)).\n Are there any other works that I should take note of? Open to any suggestions.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15holfn/d_any_noticeable_work_regarding_the_effect_of_a/",
          "publishedOn": "2023-08-04T03:17:44.000Z",
          "wordCount": 2576,
          "title": "[D] Any noticeable work regarding the effect of a language model's vocabulary or tokenizer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hnqfw/r_scaling_relationship_on_learning_mathematical/",
          "author": null,
          "description": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models\n Paper: https://arxiv.org/abs/2308.01825\n GitHub: https://github.com/OFA-Sys/gsm8k-ScRel\n Abstract: Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model’s performance than the model’s parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs. We also find RFT brings more improvement for less performant LLMs. Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3% and outperforms the supervised fine-tuning (SFT) accuracy of 35.9% significantly.\n ​\n Head figure\n Pretrain loss vs SFT and ICL\n    submitted by    /u/GanjinZero0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hnqfw/r_scaling_relationship_on_learning_mathematical/",
          "publishedOn": "2023-08-04T02:35:44.000Z",
          "wordCount": 2682,
          "title": "[R] Scaling Relationship on Learning Mathematical Reasoning with Large Language Models - Zheng Yuan et al Alibaba Damo Academy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hjk5t/d_discussion_what_would_be_the_initial_costs_of/",
          "author": null,
          "description": "I was wondering if this would be super expensive or not.\n The cost to develop GPT-3 was about $4 millions according to some resources online. \n Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?\n Any answer is appreciated.\n Thanks in advance.\n    submitted by    /u/Claud1ao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hjk5t/d_discussion_what_would_be_the_initial_costs_of/",
          "publishedOn": "2023-08-03T23:25:48.000Z",
          "wordCount": 2539,
          "title": "[D] [Discussion] What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hf49e/roadmap_for_mastering_machine_learning_d/",
          "author": null,
          "description": "Hey, first of all, I want to learn how to use nlp, cnn etc. So i think these will come under deep learning. I wanna master deep learning. This whole dl and ml is so confusing. I'll list out some courses, can y'all suggest the order and what courses to follow\n  \nAndrew ng's ml specialization\n Andrew ng's dl specialization\n Statquest's whole machine learning playlist (around 95 videos)\n Fast.ai book\n CS 229 stanford\n CS 231n stanford\n MIT intro to deep learning\n Pytorch for dl and ml by freecodecamp\n DL with pytorch\n  You can give me suggestions too\n  \nTysm for helping\n    submitted by    /u/Infnite_Coder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hf49e/roadmap_for_mastering_machine_learning_d/",
          "publishedOn": "2023-08-03T20:32:37.000Z",
          "wordCount": 2554,
          "title": "Roadmap for mastering machine learning [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hcw60/d_p_r_advice_for_picking_r_studio_or_spyder/",
          "author": null,
          "description": "Hello ML family, I need some urgent advice for my dissertation. I intend to perform market value price prediction of a footballer in the transfer market and I'm not sure if I should pick R Studio or Python. I'm comfortable with both languages and intend to use any one for model comparison. I'll be comparing an ANN model and SVR for showing which is better and why. I need to know which editor will be faster in the long run since my data will be expanding and so will the analysis overtime. I've heard a lot of complaints about spyder slowing down during execution whereas R Studio is much faster however, deep learning is much better in Python. This is what I've read up, I'm new to both languages but know my way around both just need expert advice on picking one track. Please and Thank you to you all. 🙏\n    submitted by    /u/RaunaqBani  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hcw60/d_p_r_advice_for_picking_r_studio_or_spyder/",
          "publishedOn": "2023-08-03T19:07:52.000Z",
          "wordCount": 2610,
          "title": "[D] [P] [R] Advice for picking R Studio or Spyder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hctu2/d_embedding_ethical_priors_into_ai_systems_a/",
          "author": null,
          "description": "Abstract\n Artificial Intelligence (AI) systems have significant potential to affect the lives of individuals and societies. As these systems are being increasingly used in decision-making processes, it has become crucial to ensure that they make ethically sound judgments. This paper proposes a novel framework for embedding ethical priors into AI, inspired by the Bayesian approach to machine learning. We propose that ethical assumptions and beliefs can be incorporated as Bayesian priors, shaping the AI’s learning and reasoning process in a similar way to humans’ inborn moral intuitions. This approach, while complex, provides a promising avenue for advancing ethically aligned AI systems.\n ​\n Introduction\n Artificial Intelligence has permeated almost every aspect of our lives, often making de…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hctu2/d_embedding_ethical_priors_into_ai_systems_a/",
          "publishedOn": "2023-08-03T19:05:25.000Z",
          "wordCount": 7813,
          "title": "[D] Embedding Ethical Priors into AI Systems: A Bayesian Approach",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hcl6g/d_rlhf_preference_tuning_how_things_may_go_wrong/",
          "author": null,
          "description": "As ChatGPT's performance takes a slight dip, LLaMA-2 uncensored opens new doors by being fully open-sourced, recent studies unveil \"universal\" adversarial attacks capable of disrupting both open-source language models and RLHF-tuned ones like ChatGPT, Claude, Bard, and co.\n Despite all this, RLHF still stands its ground as the de facto industry-standard approach to aligning LLMs with human preference. Yet as every week slips by, the more we unmask the limitations of RLHF. In fact, there are instances where RLHF seems to deteriorate certain LLM features it pledged to enhance, like hallucinations.\n This field is evolving fast, and there's always more to learn. I took some effort to write a short blog post where I delve into the most recent findings on the shortcomings of RLHF.\n Link in the comments below. Let me know what you think about it!\n Cheers\n    submitted by    /u/mrx-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hcl6g/d_rlhf_preference_tuning_how_things_may_go_wrong/",
          "publishedOn": "2023-08-03T18:56:19.000Z",
          "wordCount": 2597,
          "title": "[D] RLHF Preference Tuning: How Things May Go Wrong",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hbnzs/p_epsilla_another_open_source_vector_database/",
          "author": null,
          "description": "Hi everyone!\n I'm excited to share Epsilla, an open-source vector database!\n Under the hood, we implemented the state-of-art ANN index algorithm from the academia (SpeedANN) that leverages intra-query parallel graph traversal, which outperforms HNSW by 5x on high precision query latency on medium size (1M) vector space and outperforms HNSW by 50 times on large-scale vector search.\n In addition, we also made a few design choices on our database interface and architecture based on our previous database experience at TigerGraph, we would love to hear what our users think about these choices\n We just started 3 weeks ago and it's still in the very early stages, we wanted to get your feedback and work together to shape our vector database features. Let us know what you think and what you'd like to see!\n https://github.com/epsilla-cloud/vectordb\n https://epsilla-inc.gitbook.io/epsilladb/quick-start\n https://www.epsilla.com/\n    submitted by    /u/songrenchu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hbnzs/p_epsilla_another_open_source_vector_database/",
          "publishedOn": "2023-08-03T18:20:45.000Z",
          "wordCount": 2592,
          "title": "[P] Epsilla: Another open source vector database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hbce9/d_deciding_which_cnn_model_to_go_for_for_image/",
          "author": null,
          "description": "Hello guys.\n I'd like to make an image classifier for the Kaggle landscape dataset (24K images and 34 classes) using transfer learning.\n I'm a little bit limited on resources to train the model so I'd like to have an understanding of which model is the better option for this specific task, however, I'm struggling to find info on that and how to tune hyperparameters given that I've decided on the model architecture.\n So far I've seen people referring to VGG and ResNet models as the better option for image classification tasks on medium sized datasets, but I'd like to see the argumentation behind that too. I've also heard of a practice of training different model candidates for a few epochs and choosing the one that does better (this only shows which model converges faster on the data, correct me if I'm wrong).\n I'd also like to read info on hyperparameter tuning such as batch size, the amount of layers to unfreeze etc. but can't seem to find any explanation that wasn't really surface-level.\n If you know any articles/videos on this topic I'd greatly appreciate you sharing the links.\n TLDR; Need links to articles/videos about choosing the model architecture for transfer learning and tuning hyperparameters for the model.\n    submitted by    /u/Humble_Examination13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hbce9/d_deciding_which_cnn_model_to_go_for_for_image/",
          "publishedOn": "2023-08-03T18:08:12.000Z",
          "wordCount": 2668,
          "title": "[D] Deciding which CNN model to go for for image classification/object detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15halhn/r_beginners_question/",
          "author": null,
          "description": "Hello There, I am very noob in data science area, but I want learn about it, I want to do a project to detect what type of question have the user, E.g support, information,etc, I understand that I need to train a model, but where do I start?\n    submitted by    /u/Constantine1396  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15halhn/r_beginners_question/",
          "publishedOn": "2023-08-03T17:38:50.000Z",
          "wordCount": 2500,
          "title": "[R] Beginner's question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h9n68/d_concept_of_dynamic_weights_in_ml/",
          "author": null,
          "description": "Hello all,\n Placing this entry here to see what peoples thoughts on the concept of dynamic weights applied to ML are.\n Ie. Instead of a manual adjustment of the weights via an algorithm such as gradient descent, the weights are freed and have applied motion dynamics to them.\n Thanks for your time, Tyler\n    submitted by    /u/LiveBacteria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h9n68/d_concept_of_dynamic_weights_in_ml/",
          "publishedOn": "2023-08-03T17:01:21.000Z",
          "wordCount": 2509,
          "title": "[D] Concept of Dynamic Weights in ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h99n9/p_pinecone_precision_issues/",
          "author": null,
          "description": "Hello all,\n Currently I'm utilising Pinecone as a vector store database for euclidean and cosine queries.\n We are facing an issue with Pinecone utilising 32 bit single precision when taking in floats.\n This is causing our data input to become skewed.\n Anyone have advice on how to resolve this? Alternative products? Exploring possibly configuring a Redis server to handle higher precision.\n Thanks in advance for your time, Tyler\n    submitted by    /u/LiveBacteria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h99n9/p_pinecone_precision_issues/",
          "publishedOn": "2023-08-03T16:46:30.000Z",
          "wordCount": 2521,
          "title": "[P] Pinecone Precision Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h1xas/project_are_you_interested_in_a_career_using_ml/",
          "author": null,
          "description": "I'm a software engineer who has been looking for a job in AI/ML for some time. Last month I attended the UN's AI For Good Global Summit and discovered an amazing community of like-minded professionals and academics working towards just this.\n Speaking with many others in a similar position I've recently launched aiforgoodjobs.com which curates roles in AI at world leading companies tackling climate change, education, healthcare and many other important impact areas in support of the UN's Global Goals.\n I hope this might be a valuable resource for those looking down a similar path - if you would like hiring managers to reach out to you directly for relevant roles you're warmly invited to join our candidate database\n Any ideas/feedback also very gratefully received!\n    submitted by    /u/aiforgood_jobs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h1xas/project_are_you_interested_in_a_career_using_ml/",
          "publishedOn": "2023-08-03T11:47:53.000Z",
          "wordCount": 2586,
          "title": "[Project] Are you interested in a career using ML for social impact?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h186s/p_collab_on_a_web_extension_using_nlp/",
          "author": null,
          "description": "on the lookout for interested teammates to collaborate on a project to do with web extensions and NLP. If you think you can jam to this, or are just starting out, this can be the launchpad you needed.\n    submitted by    /u/drunk3n_s4ilor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h186s/p_collab_on_a_web_extension_using_nlp/",
          "publishedOn": "2023-08-03T11:13:09.000Z",
          "wordCount": 2495,
          "title": "[P] collab on a web extension using NLP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h0pkw/d_where_can_i_publish_my_images_and_time_series/",
          "author": null,
          "description": "Hey there. I have curated huge amount of high quality images for binary classification and also a time series data about it. I made the dataset specifically For some project of mine, and since it's completed right now, I want to make the dataset opensource and also potentially write a short review paper on it kind of to give an idea about data. \n Any particular website/journal I can publish my dataset and paper at? Any idea?\n    submitted by    /u/C0R0NA_CHAN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h0pkw/d_where_can_i_publish_my_images_and_time_series/",
          "publishedOn": "2023-08-03T10:46:44.000Z",
          "wordCount": 2536,
          "title": "[D] Where can I publish my images and Time Series dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gzsfv/d_roadmap_for_ai_engineer_implementation_of/",
          "author": null,
          "description": "I worked for less than a year as a Data Engineer. I decided to look for other challenges and got a job as an AI engineer developing language models.\n The product of the company that hired me is related to data and metadata management. My tasks will be to introduce features to the product, including a chat function that will allow for asking questions about data. Other tasks will include research and proposing additional AI-related functionalities to the product (on premise). I have a two weeks left to start work and I need to prepare a bit. My job will involve implementing ready-made solutions and conducting research (high level - I need to implement valuable features and no one cares how).\n What are the most important things I should learn before starting work?\n First of all, I replicated a few applications from this blog: https://blog.streamlit.io/tag/llms/\n Then I have focused on Langchain. I'm also in the middle of a course on Udemy about Next-Gen AI projects - Beginner friendly - Langchain, Pinecone - OpenAI, HuggingFace & LLAMA 2 models\n I need a roadmap that will guide me a bit. I'm looking for blogs/materials/courses that will give me practical knowledge in this matter.\n    submitted by    /u/International-Shirt5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gzsfv/d_roadmap_for_ai_engineer_implementation_of/",
          "publishedOn": "2023-08-03T09:58:30.000Z",
          "wordCount": 2661,
          "title": "[D] Roadmap for AI engineer (implementation of language models on premise)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gx4jf/p_would_you_like_to_have_a_tool_to_make_eda/",
          "author": null,
          "description": "I’m looking for some input from the ML community.\n I find the exploratory analysis of my data somewhat cumbersome, I was wondering if other people have the same experience and if it is worth developing a tool to make this all work better.\n What tools do you use to do EDA? (Seaborn, Matplotlib, Plotly etc)\n On top of these tools, would you like to have a tool to make EDA more? In a perfect world, what would that look like?\n    submitted by    /u/catnamedred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gx4jf/p_would_you_like_to_have_a_tool_to_make_eda/",
          "publishedOn": "2023-08-03T07:25:57.000Z",
          "wordCount": 2541,
          "title": "[P] Would you like to have a tool to make EDA efficiently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gumgg/d_stack_exchange_alternatives/",
          "author": null,
          "description": "I assume most people around here are familiar with stackoverflow. Some might also be aware of the cross validated and datascience sites from stack exchange.\n I recently learned about people getting annoyed by how the stack exchange company is treating its communities. Although the latter example might have recently been resolved.\n Because of these problems, I have been looking out for alternative Q&A platforms. I stumbled upon https://codidact.com as a possibly viable alternative, but not many people seem to have found it thus far.\n It already has communities for software, math and [linux](linux.codidact.com) for example, but I am missing a community for ML questions over there. Therefore I wrote a proposal to add a ML community.\n Currently, it seems like I’m one of only few ML people on codidact. I think it would be good if other people would get involved as well. I would also welcome any feedback on how to shape this community. If you’re interested to get a feel for the experience, you could already start asking questions in the incubator Q&A.\n TL;DR: what do you think about building a ML Q&A over on codidact? dual TL;DR: Do you want to play Q&A with me on codidact?\n PS: I didn’t miss out on other new big ML Q&A sites, did I?\n    submitted by    /u/mr_tsjolder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gumgg/d_stack_exchange_alternatives/",
          "publishedOn": "2023-08-03T05:05:05.000Z",
          "wordCount": 2667,
          "title": "[D] Stack Exchange alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gongf/d_llama2_and_bertscore/",
          "author": null,
          "description": "I have a couple of questions:\n  \nWhy wasn't BERTScore one of the metrics used to evaluate Llama-2's performance on free-form response based tasks?\n Does anyone think it's worth trying to produce those results?\n  \n   submitted by    /u/cooperbaerseth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gongf/d_llama2_and_bertscore/",
          "publishedOn": "2023-08-03T00:15:32.000Z",
          "wordCount": 2486,
          "title": "[D] LLaMa-2 and BERTScore",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gkwld/p_project_cost_forecasting/",
          "author": null,
          "description": "Hi guys this is my first post.\n I am building my first machine learning model to predict costs of various projects by month. Each row can be identified with a column project name and month (these two are dropped for testing). The rest of the columns are various features that can help predicting the end project cost. \n I want to be able to predict costs on a monthly basis. My question is how should I split the data because each row is a unique project and month. Is it ok to just do a train test split and have earlier project months be in the testing set while having future project months be in the training set? Isn’t that giving the model too much information? \n Or should I train on each project’s indices and leave one project as testing for each project I have? I’m worried about overfitting with that one.\n Thanks in advance for any help!\n    submitted by    /u/Single_Swing_3173  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gkwld/p_project_cost_forecasting/",
          "publishedOn": "2023-08-02T21:44:08.000Z",
          "wordCount": 2610,
          "title": "[P] Project Cost Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gke9y/p_project_cost_forecasting/",
          "author": null,
          "description": "Hi guys this is my first post.\n I am building my first machine learning model to predict costs of various projects by month. Each row can be identified with a column project name and month (these two are dropped for testing). The rest of the columns are various features that can help predicting the end project cost. \n I want to be able to predict costs on a monthly basis. My question is how should I split the data because each row is a unique project and month. Is it ok to just do a train test split and have earlier project months be in the testing set while having future project months be in the training set? Isn’t that giving the model too much information? \n Or should I train on each project’s indices and leave one project as testing for each project I have? I’m worried about overfitting with that one.\n Thanks in advance for any help!\n    submitted by    /u/Single_Swing_3173  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gke9y/p_project_cost_forecasting/",
          "publishedOn": "2023-08-02T21:00:49.000Z",
          "wordCount": 2610,
          "title": "[P] Project Cost Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ggw2u/project_help_needed_monte_carlo_policy_gradient/",
          "author": null,
          "description": "I am trying to implement REINFORCE (Monte Carlo Policy Gradient) on flappy bird (flappy-bird-gymnasium) and I am unable to make the ai cross even just 1 pipe.\n I am experiencing a constant avg score throughout all episodes from start to end and no change in policy loss as well (sometimes). I tried a lot of different hyperparameter combinations as well.\n I have checked the policy (neural network) and the algorithm code multiple times and they seem to be fine. I am just not able to determine why the AI isn't learning or is able to cross even a single pipe.\n If someone can help me out, it would be really helpful!\n code - https://github.com/Sookeyy-12/REINFORCE_Projects\n there's also a video of the agent's gameplay in this repo.\n    submitted by    /u/Sookeyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ggw2u/project_help_needed_monte_carlo_policy_gradient/",
          "publishedOn": "2023-08-02T18:36:03.000Z",
          "wordCount": 2586,
          "title": "[Project] Help needed - Monte carlo policy gradient - reinforce alg on flappy bird",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gbu7t/d_ijcnlpaacl_2023_paper_reviews/",
          "author": null,
          "description": "The paper reviews for AACL 2023 are out, feel free to share your thoughts and feelings! How did you do?\n    submitted by    /u/Pomhelpme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gbu7t/d_ijcnlpaacl_2023_paper_reviews/",
          "publishedOn": "2023-08-02T15:25:47.000Z",
          "wordCount": 2474,
          "title": "[D] IJCNLP-AACL 2023: Paper Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g9atl/r_gzip_vs_bagofwords_for_text_classification/",
          "author": null,
          "description": "Hi,\n same as other folks, I was quite curious about the recent GZIP paper presented at ACL 2023, where the authors demonstrate strong text classification performance by using a compression-based distance function in a KNN model.\n However, in the end, I am not sure whether GZIP can fully live up to the hype. I tested a very simple bag-of-words distance and found that it can achieve better results compared with GZIP, while being also faster.\n In a nutshell, I think we can say that:\n  \nYes, KNN (with some sensible distance function) is an interesting approach, particularly for few-shot/low-resource scenarios.\n \nNo, GZIP (even though it's a cool idea) is not a very sensible distance function. Simply using a bag-of-words achieves better results, and is much faster.\n \n Here's my full write-up:\n https://arxiv.org/abs/2307.15002\n [PS: A short comment on the GZIP evaluation issue that has been widely discussed. Indeed, as was also shown in a popular blogpost, the displayed accuracy of GZIP in the original paper is optimistic. Therefore, I show correct/realistic accuracy numbers for all methods that I tested. However, the main point of my note is not to make a SOTA comparison or something, but rather just provide a reminder that bag-of-word is a good method for starters and a strong baseline, and can perform better than more complex GZIP for KNN classification]\n    submitted by    /u/juopitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g9atl/r_gzip_vs_bagofwords_for_text_classification/",
          "publishedOn": "2023-08-02T13:43:45.000Z",
          "wordCount": 2677,
          "title": "[R] GZIP vs Bag-of-Words for text classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g8igy/p_prove_your_identity_directly_via_language_model/",
          "author": null,
          "description": "Hi guys, I built something that you might enjoy. Totally free and open source. Basically it lets you create text that you can prove came from you.\n For example, in my colab demo: https://colab.research.google.com/drive/1764iRR-EFJl43KIKhrb2H0CTcT0b1vQm?authuser=2#scrollTo=qyKud8qtM3vA\n I prove that I generated the text:\n 'The world is constantly changing due to technological advancements, which include the creation of powerful language models and advanced robotics technologies. A Computer Science degree can help one be involved in these changes and apply their knowledge to everyday life, as practical applications of technology.'\n The text is a bit wonky as the generation model is just a small paraphrasing fine-tuned model I pulled off Hugging Face, but it's pretty natural even at this earl…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g8igy/p_prove_your_identity_directly_via_language_model/",
          "publishedOn": "2023-08-02T13:08:32.000Z",
          "wordCount": 2781,
          "title": "[P] Prove your identity directly via language model output",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g67nv/d_clustering_an_dataset_of_images_with_openpose/",
          "author": null,
          "description": "Hey everyone!\n I've got a rather large dataset of images, mostly featuring humans in a variety of poses (think along the lines of a collection of people practicing yoga and the like).\n My goal is to cluster these images based on the poses, so I can avoid the tedious task of manually sifting through each one to find all the people doing handstands, splits, and so forth.\n My initial thought was to run OpenPose on all these images, then perform clustering based on the output from OpenPose.\n Does this sound like a feasible approach? Do any of you have better suggestions? Or perhaps there's already an existing software solution that can do this?\n Thanks!\n    submitted by    /u/cyan2k  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g67nv/d_clustering_an_dataset_of_images_with_openpose/",
          "publishedOn": "2023-08-02T11:19:03.000Z",
          "wordCount": 2571,
          "title": "[D] Clustering an dataset of images with OpenPose",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g5j9m/news_kornia_v070_release_image_api_rtdetr_and/",
          "author": null,
          "description": "Read the release notes: https://github.com/kornia/kornia/releases/tag/v0.7.0\n --------------------\n Image API In this release we have added a new Image API as placeholder to support a more generic multibackend api. You can export/import from files, numpy and dlapck.\n https://preview.redd.it/0d5tvjxmeofb1.png?width=621&format=png&auto=webp&s=9af05a037770132c9a267b68dcd9ab8182557517\n Object Detection API We have added the ObjectDetector that includes by default the RT-DETR model. The detection pipeline is fully configurable by supplying a pre-processor, a model, and a post-processor. Example usage is shown below\n https://preview.redd.it/rtbayqpneofb1.png?width=680&format=png&auto=webp&s=4d46edeeee4027e08a493cb15182ea0ddc42bc5d\n https://preview.redd.it/ukcg9enoeofb1.png?width=680&format=png&a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g5j9m/news_kornia_v070_release_image_api_rtdetr_and/",
          "publishedOn": "2023-08-02T10:45:03.000Z",
          "wordCount": 2660,
          "title": "[News] Kornia v0.7.0 release: Image API, RT-DETR and Object Detection API, LightGlue Matcher, MobileSam, new Sensors API and many more.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g2weg/d_pose_estimation_over_mid_range/",
          "author": null,
          "description": "I have been testing OpenFace with some telescope lenses (focal length 8-16mm) to test the performance of the pose estimation at mid range (2-4 meters). I have been passing the camera and lens intrinsics to OpenFace but have been finding that the pose estimation has not been great. Does anyone with more ML experience know at what point in the OpenFace pipeline the issues could be coming from? e.g. the point distribution model or the training data \n    submitted by    /u/DoPe-_-SoaP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g2weg/d_pose_estimation_over_mid_range/",
          "publishedOn": "2023-08-02T08:18:47.000Z",
          "wordCount": 2532,
          "title": "[D] Pose Estimation over Mid Range",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g0hzq/r_model_to_refine_a_binary_segmentation_mask/",
          "author": null,
          "description": "Hi, this is my first time posting here. My goal is to check if optical flow can improve a pretrained model's performance.\n The pretrained model: gives an output as a binary mask for the object its trying to detect.\n The optical flow: is the motion of pixels between frames, this model also gives an image shaped flow vector.\n I want to combine the mask by pretrained model and optical flow information and send it to another model to improve its performance.\n For the model: I can use U-net or a simple convolution encoder-decoder model, but I am confused about which will be the best model architecture for it.\n ​\n    submitted by    /u/luxuryBubbleGum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g0hzq/r_model_to_refine_a_binary_segmentation_mask/",
          "publishedOn": "2023-08-02T06:01:37.000Z",
          "wordCount": 2567,
          "title": "[R] Model to refine a binary segmentation mask using optical flow.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fy5nk/d_are_there_any_free_llm_gpts_that_i_can_access/",
          "author": null,
          "description": "I am trying to develop some app ideas based on LLM (i.e., summarize and extract entities from articles), but I can't afford any paid API access right now (including OpenAI), are there free alternatives to it?\n    submitted by    /u/Guyserbun007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fy5nk/d_are_there_any_free_llm_gpts_that_i_can_access/",
          "publishedOn": "2023-08-02T03:59:20.000Z",
          "wordCount": 2498,
          "title": "[D] Are there any free LLM GPTs that I can access via API?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fwu6v/d_how_to_testfinetune_a_model_using_a_new_data/",
          "author": null,
          "description": "Hi,\n ​\n I want to use a new data representation instead of float for fine-tuning/testing a model (e.g., DNN) in Pytorch. The basic operations (add/sub/multiply/division) in my data type is different from floating point. My question is if it is possible to implement these operations (+,-,*,/) and force all of functions in Pytorch (e.g., torch.add(), torch.sum(), torch.nn.Linear(), conv2d, etc.) to use my basic arithmetic implementation? If so, could you please guide me how can I do it?\n Because I think otherwise it takes so much time and effort; first, I have to find which functions my model calls (which I dont know how to do it) and, then, I have to replace them one by one. This becomes complicated for a large model.\n I found this link from Pytorch that shows how to extend pytorch. But it seems that it is not comprehensive enough to answer my question.\n ​\n Thank you very much!\n    submitted by    /u/Impossible-Froyo3412  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fwu6v/d_how_to_testfinetune_a_model_using_a_new_data/",
          "publishedOn": "2023-08-02T02:53:40.000Z",
          "wordCount": 2624,
          "title": "[D] How to test/fine-tune a model using a new data type that has different arithmetics for basic operations (+,-,/,*) compared to float in Pytorch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ft07b/discussion_supervised_finetuning_vs_prompt/",
          "author": null,
          "description": "Hello all,\n ​\n I am delving into the exciting realm of GenAI and LLMs. I have a few questions I hope you can help me with:\n ​\n  \nWhen should I opt for supervised fine-tuning rather than prompt engineering with retrieval? \n \nWhat are the associated costs of supervised fine-tuning?\n \nHow many high-quality observations are typically required for successful supervised fine-tuning?\n \nWhat are the frameworks and computional requirements usually involved in supervised fine-tuning, and how can I implement them in code? any tutorials available?\n \nCan the model adapt and learn new jargon or specific tasks that might not be extensively covered during the pre-training phase?\n \n ​\n I understand that a combination of supervised fine-tuning and reinforcement learning, with human feedback through a reward model, is considered the best approach. However, given that the latter method can be costly and falls under the domain of heavy research, it is probably less feasible for medium-sized organizations.\n    submitted by    /u/quilograma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ft07b/discussion_supervised_finetuning_vs_prompt/",
          "publishedOn": "2023-08-01T23:56:33.000Z",
          "wordCount": 2604,
          "title": "[Discussion] Supervised fine-tuning vs Prompt Engineering with retrieval for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fqcig/d_predicting_domain_mapping_difficulty/",
          "author": null,
          "description": "I went down this rabbit hole of trying to understand when domain mapping approaches like stargan or mind the gap succeed and fail. For example, it should be easy to map males (source domain) with large eyes and brown hair onto females (target domain) with analogous eye and hair color. It should be relatively harder to map different car models onto images taken of one German Shepard dog at different ages. this makes intuitive sense and the terms “domain misalignment “ and “large domain shift“ come to mind, but i cannot find an in-depth discussion of this topic. Any thoughts?\n    submitted by    /u/Rotfisch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fqcig/d_predicting_domain_mapping_difficulty/",
          "publishedOn": "2023-08-01T22:04:42.000Z",
          "wordCount": 2550,
          "title": "[D] predicting domain mapping difficulty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fo7td/d_neurips_2023_paper_reviews/",
          "author": null,
          "description": "NeurIPS 2023 paper reviews are visible on OpenReview. See this tweet. I thought to create a discussion thread for us to discuss any issue/complain/celebration or anything else.\n There is so much noise in the reviews every year. Some good work that the authors are proud of might get a low score because of the noisy system, given that NeurIPS is growing so large these years. We should keep in mind that the work is still valuable no matter what the score is.\n    submitted by    /u/zy415  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fo7td/d_neurips_2023_paper_reviews/",
          "publishedOn": "2023-08-01T20:44:02.000Z",
          "wordCount": 2532,
          "title": "[D] NeurIPS 2023 Paper Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fm55d/r_toolllm_facilitating_large_language_models_to/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.16789 \n Github: https://github.com/OpenBMB/ToolBench \n Abstract:\n  \nDespite the advancements of open-source large language models (LLMs) and their variants, e.g., LLaMA and Vicuna, they remain significantly limited in performing higher-level tasks, such as following human instructions to use external tools (APIs). This is because current instruction tuning largely focuses on basic language tasks instead of the tool-use domain. This is in contrast to state-of-the-art (SOTA) LLMs, e.g., ChatGPT, which have demonstrated excellent tool-use capabilities but are unfortunately closed source. To facilitate tool-use capabilities within open-source LLMs, we introduce ToolLLM, a general tool-use framework of data construction, model training and evaluation. We first …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fm55d/r_toolllm_facilitating_large_language_models_to/",
          "publishedOn": "2023-08-01T19:25:47.000Z",
          "wordCount": 2742,
          "title": "[R] ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs - WeChat AI, Tencent Inc. 2023 - Open-source! Comparble performance to ChatGPT while using tools!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15flq9u/p_vkfft_version_13_released_major_design_and/",
          "author": null,
          "description": "Hello, I am the creator of the VkFFT - GPU Fast Fourier Transform library for Vulkan/CUDA/HIP/OpenCL/Level Zero and Metal. FFTs are used by many algorithms, not only for signal processing. For example, you can efficiently calculate convolutions with them, which has applications in CNNs and feature generation. I used to post on the latest features implemented in the codebase and there has been a major update released today. It brings:\n -Major library design change - from single header to multiple header approach, which improves structure and maintainability. Now instead of copying a single file, the user has to copy the vkFFT folder contents.\n -VkFFT has been rewritten to follow the multiple-level platform structure, described in the VkFFT whitepaper. All algorithms have been split into res…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15flq9u/p_vkfft_version_13_released_major_design_and/",
          "publishedOn": "2023-08-01T19:10:09.000Z",
          "wordCount": 2805,
          "title": "[P] - VkFFT version 1.3 released - major design and functionality improvements",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fljq3/p_dorars_experimental_ros2_alternative_up_to_17x/",
          "author": null,
          "description": "https://github.com/dora-rs/dora\n    submitted by    /u/haixuanxaviertao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fljq3/p_dorars_experimental_ros2_alternative_up_to_17x/",
          "publishedOn": "2023-08-01T19:03:20.000Z",
          "wordCount": 2465,
          "title": "[P] dora-rs: experimental ROS2 alternative up to 17x faster for Python API, making more robotics accessible for AI users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fkmvj/d_reinforcement_learning_from_ai_feedback/",
          "author": null,
          "description": "Hey everyone,\n As many of you probably know Reinforcement Learning from Human Feedback (RLHF) was the core technique used to produce ChatGPT and similar AI assistants that followed. RLHF replaces human feedback in an RL schema with a preference model that is trained according to a dataset of human preferences.\n Anthropic has devised an extension of this idea in which an AI model (rather than humans) is used to generate the data which ultimately trains the preference model. This method, called Reinforcement Learning from AI Feedback uses a \"constitution\" to guide the feedback model in terms of what outputs are preferable to others.\n I go over the research in How Reinforcement Learning from AI Feedback Works. In short, the authors find that they are able to train a non-evasive harmless agent using a short constitution. The method is found to be superior to RLHF, and constitutes a Pareto improvement over RLHF models.\n https://preview.redd.it/qaivl8f1ljfb1.png?width=1179&format=png&auto=webp&s=a0941f2ce0ccdcf0557cf19b7f4b48fa712a66f2\n Let me know what you think, I'm happy to answer any questions!\n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fkmvj/d_reinforcement_learning_from_ai_feedback/",
          "publishedOn": "2023-08-01T18:29:16.000Z",
          "wordCount": 2615,
          "title": "[D] Reinforcement Learning from AI Feedback",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fgfr3/r_any_ml_professionals_mind_helping_out_with_an/",
          "author": null,
          "description": "Hi there,\n First off, apologies if this kind of post isn't allowed. I tried messaging the mods in advance, but didn't get a reply. Of course feel free to delete if it's not.\n I'm an academic at the University of Cambridge's Computer Lab, and I'm looking to get some insights from people that work with algorithmic systems (e.g. ML systems) in a professional capacity. \n The aim of the research is to document some of the approaches, attitudes, and challenges associated with record-keeping for these types of systems, and write them up for an academic conference.\n If you're a professional working with algorithmic/ML systems, and happen to have a spare ~20 minutes, would you mind answering some questions? The link to the questionnaire is here: https://cambridge.eu.qualtrics.com/jfe/form/SV_3n6RuowNogZKG34\n Thanks very much! I'd be more than happy to come back and share the results/paper here if that's of interest to people?\n    submitted by    /u/cnorval  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fgfr3/r_any_ml_professionals_mind_helping_out_with_an/",
          "publishedOn": "2023-08-01T15:53:02.000Z",
          "wordCount": 2603,
          "title": "[R] Any ML professionals mind helping out with an academic survey?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fcymz/project_gzipknn_official_package_released/",
          "author": null,
          "description": "The official python package for the \"'Low-Resource' Text Classification: A Parameter-Free Classification Method with Compressors\" has now been released on pypi: npc-gzip v0.1.0\n  \nAbstract: Deep neural networks (DNNs) are often used for text classification due to their high accuracy. However, DNNs can be computationally intensive, requiring millions of parameters and large amounts of labeled data, which can make them expensive to use, to optimize, and to transfer to out-of-distribution (OOD) cases in practice. In this paper, we propose a non-parametric alternative to DNNs that’s easy, lightweight, and universal in text classification: a combination of a simple compressor like gzip with a k-nearest-neighbor classifier. Without any training parameters, our method achieves results that are competitive with non-pretrained deep learning methods on six in-distribution datasets.It even outperforms BERT on all five OOD datasets, including four low-resource languages. Our method also excels in the few-shot setting, where labeled data are too scarce to train DNNs effectively.\n  \nThis paper has made some waves on this subreddit and in the community in general over the last 2 weeks. We've seen the bugs around training/testing data leakages and varying claims in accuracy. Our hope with this package is to get the code into everyone's hands first to solve whatever use case you currently have for this technology and second to make the code more readily available for additional community testing.\n Links: * https://pypi.org/project/npc-gzip/ * https://github.com/bazingagin/npc_gzip * https://aclanthology.org/2023.findings-acl.426/\n    submitted by    /u/dfcHeadChair  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fcymz/project_gzipknn_official_package_released/",
          "publishedOn": "2023-08-01T13:41:29.000Z",
          "wordCount": 2678,
          "title": "[Project] GZip+KNN Official Package Released",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15f56ve/d_google_updates_attention_is_all_you_need_paper/",
          "author": null,
          "description": "submitted by    /u/Jean-Porte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15f56ve/d_google_updates_attention_is_all_you_need_paper/",
          "publishedOn": "2023-08-01T07:19:54.000Z",
          "wordCount": 2460,
          "title": "[D] Google updates \"Attention is all you need\" paper with a warning + crossed authors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15f08ss/r_probabilistic_imputation_for_timeseries/",
          "author": null,
          "description": "This is one of the ICML 2023 papers I focused in on in a sea of LLM stuff. Trying to figure out simple ways to implement this and adapt it to regression problems. Thoughts?\n    submitted by    /u/quantthrowaway69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15f08ss/r_probabilistic_imputation_for_timeseries/",
          "publishedOn": "2023-08-01T02:56:12.000Z",
          "wordCount": 2501,
          "title": "[R] Probabilistic Imputation for Time-series Classification with Missing Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15extok/p_videototext_model_descriptive_style_not/",
          "author": null,
          "description": "I was wondering if there's already something like CLIP (the model that looks at an image and describes it), but for videos. So you show a video of, say, a dog jumping and grabbing a tennis ball and it outputs \"dog grabbing a tennis ball\", something like that.\n My first thought was object detection, and input that interaction of the objects (tennis ball, dog) to the model with the target being \"dog grabbing tennis ball\". My ultimate goal being real-time description for, say, sports casting. I'm sure something like this is what cars use to drive themselves, or not? Any info is appreciated!\n    submitted by    /u/Yip37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15extok/p_videototext_model_descriptive_style_not/",
          "publishedOn": "2023-08-01T01:02:49.000Z",
          "wordCount": 2555,
          "title": "[P] Video-to-Text model descriptive style (not subtitles)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15eschg/llm_models_for_interpreting_tables_and_charts_d/",
          "author": null,
          "description": "Hi all,\n Curious if anyone has recommendations on models to use to interpret the data in tables? I'm playing around with Google's Matcha model, which performs fine. seems like extracting the data out of a table and asking GPT4 to analyze it performs a bit better but requires extra steps.\n I'm specifically not looking to interpret graphs, but rather tables. e.g., can i ask the model to identify if there are any errors in the table / any data points that don't tie if the rows are supposed to sum up.\n    submitted by    /u/eyeronthrone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15eschg/llm_models_for_interpreting_tables_and_charts_d/",
          "publishedOn": "2023-07-31T21:16:12.000Z",
          "wordCount": 2544,
          "title": "LLM models for interpreting tables and charts [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15er6it/n_conference_codes/",
          "author": null,
          "description": "I'll likely be downvoted to hell but here goes: Prices for The AI Conference double at midnight Pacific.\n 46 Speakers, 10+ topics, 2 Days plus a hackathon at night! Join us to learn and collaborate with scientists, engineers and founders from the top AI companies and projects. Speakers include:\n Ben Mann | Co-Founder | Anthropic\n Peter Norvig | Director of Research | Google\n Nazneen Rajani | Research Lead | Hugging Face\n Igor Markov | Research Scientist | Meta\n Bryan Catanzaro | VP Of Research | Nvidia\n Ram Sriharsha | VP of Engineering and R&D | Pinecone\n Jerry Liu | Co-founder | LlamaIndex\n Harrison Chase | Co-founder | LangChain\n Alex Chao | Product Manager Semantic Kernel | Microsoft\n See All Speakers\n Last chance to get in on early bird pricing (save $400 on a 2 day pass). If you can read this and I'm not downvoted to hell, use discount code redditlove for 25% off.\n Use discount code \"student\" for $200 student tickets \\*Must Use EDU email to register*\n **This is my event and therefore self-promotion\n ​\n ​\n    submitted by    /u/shonburton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15er6it/n_conference_codes/",
          "publishedOn": "2023-07-31T20:31:25.000Z",
          "wordCount": 2615,
          "title": "[N] Conference Codes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ep5ff/d_where_did_all_the_ml_research_go/",
          "author": null,
          "description": "For the past several years this subreddit has been my favorite source to keep up with new, interesting ideas and research from all over the field. It's great to have a way to break out of my own insular research bubble and spread out a bit more. Unfortunately, it looks like that era has passed.\n The sub has been seemingly shifting away from research in the past 1-2 years. Whenever research is posted, it is almost always LLM based with very little variety (considering the plethora of research areas in ML). I don't mean to assert that this is a bad thing, as the constant upvotes indicate that there is a high demand for LLM projects and research. Heck, I'm also interested in lots of the recent work with LLMs, and I plan to keep up with it – but I also would also love a venue with a diversity of ideas and topics. Machine learning is a HUGE field, and only focusing on a small subset of it seems like a waste.\n I don't mean to rant, but rather to ask: are there any other subreddits like this, or perhaps, any other active communities with a broader scope?\n Or if this doesn't exist, is there a demand for it? Or is it just me?\n    submitted by    /u/ejmejm1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ep5ff/d_where_did_all_the_ml_research_go/",
          "publishedOn": "2023-07-31T19:14:01.000Z",
          "wordCount": 2668,
          "title": "[D] Where did all the ML research go?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15eod44/d_elasticsearch_hnsw_python_implementation/",
          "author": null,
          "description": "Is there any documentation available which will help in implementing elasticsearch HNSW ANN search in python? I've searched a lot but i cant find anything in official documentation too Any help will be appreciated. TIA\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15eod44/d_elasticsearch_hnsw_python_implementation/",
          "publishedOn": "2023-07-31T18:44:53.000Z",
          "wordCount": 2485,
          "title": "[D] elasticsearch HNSW python implementation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15emyyq/why_cuda_117_can_more_recent_versions_of_cuda_be/",
          "author": null,
          "description": "Everyone always seems to use CUDA 11.7. Is there a reason for this? What is the factor that limits the CUDA version used? Are there any speed/efficiency advantages to using a more recent version of CUDA, such as CUDA 12.0?\n What exactly is the limiting factor here, PyTorch? I've looked in the PyTorch docs but I don't see where the CUDA version is defined. Where can I find the maximum CUDA version I can use with the latest (or any given) PyTorch version?\n Thanks!\n    submitted by    /u/Pan000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15emyyq/why_cuda_117_can_more_recent_versions_of_cuda_be/",
          "publishedOn": "2023-07-31T17:50:40.000Z",
          "wordCount": 2546,
          "title": "Why CUDA 11.7? Can more recent versions of CUDA be used? Is this a PyTorch limitation? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ek21a/d_model_design_for_outputting_reliable_multiclass/",
          "author": null,
          "description": "Hey guys, I am working on a horse racing model to identify the probabilities of each horse winning a race. I currently have a feed forward NN with a final SOFTMAX layer to simulate probabilities of each horse winning using cross-entropy loss. My plan here being that if the model outputs, [0.05, 0.4, 0.2, 0.15, 0.2] then horses 1-5 have the corresponding probability of winning. The model has been trained like a regular classification task where the target is a one-hot vector describing the winner.\n Unlike previous work I have done where SOFTMAX output lends itself to some \"confidence\" score, this task requires that the model outputs be indicative of probabilities. My concern is that experientially, NNs tend to be overconfident with their answers in this type of setting. However, I wish to keep using a NN as each race datapoint has around 3k features - did not find good results with XGBoost. Any good practices for modelling probabilities in this sort of scenario? For context, the probability of a horse winning is what sets the odds for that horse.\n    submitted by    /u/HStuart18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ek21a/d_model_design_for_outputting_reliable_multiclass/",
          "publishedOn": "2023-07-31T15:58:24.000Z",
          "wordCount": 2633,
          "title": "[D] Model design for outputting reliable multiclass probabilities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ehtyw/d_running_free_willy_stable_baluga_2/",
          "author": null,
          "description": "I was wondering if anyone knows how difficult it is to set up a server to run the 70B llama / llama 2 variants like these top ones on the hugging face leaderboard\n https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n What type of gpu would I need to set it up? Would the high ram t4 you get with Google colab+ be enough or does it require more power / space? \n Thanks in advance!\n    submitted by    /u/Additional_Elk4745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ehtyw/d_running_free_willy_stable_baluga_2/",
          "publishedOn": "2023-07-31T14:32:04.000Z",
          "wordCount": 2521,
          "title": "[D] Running Free Willy / stable baluga 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ehhyu/r_attention_over_pretrained_sentence_embeddings/",
          "author": null,
          "description": "Article available here: https://arxiv.org/pdf/2307.09084.pdf\n Thoughts?\n    submitted by    /u/MuffinB0y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ehhyu/r_attention_over_pretrained_sentence_embeddings/",
          "publishedOn": "2023-07-31T14:19:04.000Z",
          "wordCount": 2460,
          "title": "[R] Attention over pre-trained Sentence Embeddings for Long Document Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15eeinh/p_apple_fruit_x_combine_queries_and_explore_clip/",
          "author": null,
          "description": "Hi. I've shipped an update to my rclip – a command-line photo search tool powered by CLIP.\n Now, you can add and subtract image and text queries from each other; here are a few usage examples:  cd photos && rclip horse + stripes cd photos && rclip apple - fruit cd photos && rclip \"./new york city.jpg\" + night cd photos && rclip \"2:golden retriever\" + \"./swimming pool.jpg\" cd photos && rclip \"./racing car.jpg\" - \"2:sports car\" + \"2:snow\" \n If you want to see how these queries perform when executed on the 1.28 million images ImageNet-1k dataset, check out the demo on YouTube: https://www.youtube.com/watch?v=MsTgYdOpgcQ.\n rclip source code is published on GitHub under the MIT license and offers a pre-build distributable for Linux (installation instructions are in the README): https://github.com/yurijmikhalevich/rclip. Give it a try and let me know what you think!\n    submitted by    /u/39dotyt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15eeinh/p_apple_fruit_x_combine_queries_and_explore_clip/",
          "publishedOn": "2023-07-31T12:13:56.000Z",
          "wordCount": 2600,
          "title": "[P] Apple - Fruit = X? Combine Queries and Explore CLIP Embedding Space With rclip",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e7b1f/d_open_source_model_combination_to_turn_images_llm/",
          "author": null,
          "description": "Im trying to research into open source text models [like Llama] and image models [like Stable Diffusion].\n My goal is to give the model(s) a picture of birds and bees, then ask it to \"circle\" the bees. The idea is, when given an image, it would produce coordinates on that image where the line should be circled. It could also represent where it should \"click\" on all the bees.\n Does something like this exist?\n    submitted by    /u/MindWithEase  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e7b1f/d_open_source_model_combination_to_turn_images_llm/",
          "publishedOn": "2023-07-31T05:42:39.000Z",
          "wordCount": 2529,
          "title": "[D] Open Source Model Combination To Turn Images -> LLM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e2n5j/open_problems_and_fundamental_limitations_of/",
          "author": null,
          "description": "submitted by    /u/Working_Ideal3808  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e2n5j/open_problems_and_fundamental_limitations_of/",
          "publishedOn": "2023-07-31T01:34:00.000Z",
          "wordCount": 2468,
          "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e29jd/p_pair_programming_my_website_with_an_ai_developer/",
          "author": null,
          "description": "submitted by    /u/williamsweep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e29jd/p_pair_programming_my_website_with_an_ai_developer/",
          "publishedOn": "2023-07-31T01:16:00.000Z",
          "wordCount": 2452,
          "title": "[P] Pair programming my website with an AI developer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e0750/r_towards_robust_production_machine_learning_for/",
          "author": null,
          "description": "Could you please help us get more responses for this study?\n As part of my PhD research project at Applied Artificial Intelligence Institute of Deakin University, we are investigating the challenges that software engineers face when working with machine learning (ML) models in production. Moreover, we explore how to enhance our proposed solution to better meet the needs of these engineers.\n ​\n The objective of this study is to pinpoint the areas where software engineers need more support and resources to effectively work with ML components in production. It also aims to evaluate the effectiveness of a proposed protocol to improve software engineers' productivity and enable them to work more effectively with ML components in production environments.\n ​\n With the knowledge gained from this i…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e0750/r_towards_robust_production_machine_learning_for/",
          "publishedOn": "2023-07-30T23:40:18.000Z",
          "wordCount": 2738,
          "title": "[R] Towards robust production machine learning for software systems - Survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dzl3x/d_number_of_epochs_for_a_bert_based_model/",
          "author": null,
          "description": "Hello everyone. I am trying to replace the GloVe embeddings based model outlined in this paper by BERT embeddings. The authors of the paper have trained their model for 250 epochs, which for what I am doing is not feasible. I was wondering what would be the recommended number of epochs I should run the BERT model for? I know it is a pretty open ended question, but I was looking to get the community's view on how much epochs should a BERT based model be trained for. Any information will be much appreciated.\n    submitted by    /u/nocturnal_1_1995  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dzl3x/d_number_of_epochs_for_a_bert_based_model/",
          "publishedOn": "2023-07-30T23:13:00.000Z",
          "wordCount": 2576,
          "title": "[D] Number of epochs for a BERT based model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15du7ql/n_ai_usage_fees_up_to_15x_cheaper_for_english/",
          "author": null,
          "description": "submitted by    /u/geekinchief  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15du7ql/n_ai_usage_fees_up_to_15x_cheaper_for_english/",
          "publishedOn": "2023-07-30T19:35:42.000Z",
          "wordCount": 2497,
          "title": "[N] AI Usage Fees Up to 15x Cheaper for English Than Other Languages",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dsuhn/d_alternatives_to_hf_or_a_path_forward_for_the/",
          "author": null,
          "description": "I think it’s clear that Hugging Face is not aligned to the OSS community any more and it’s only going to get worse over the next few years. What are the top alternatives or where should the OSS contributors go? \n I’m trying to think ahead to what libraries we should rely on and contribute to. Anyone else have this as a worry?\n https://twitter.com/untitled01ipynb/status/1685667451197878272\n    submitted by    /u/homunculAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dsuhn/d_alternatives_to_hf_or_a_path_forward_for_the/",
          "publishedOn": "2023-07-30T18:38:33.000Z",
          "wordCount": 2548,
          "title": "[D] Alternatives to HF or a path forward for the OSS community?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dsjp3/r_compressing_visionlanguage_and_unimodal/",
          "author": null,
          "description": "🚀 Code: https://github.com/sdc17/UPop\n 📑 Paper: https://proceedings.mlr.press/v202/shi23e/shi23e.pdf\n 🧐 A Quick Look\n  \nWhat is it: UPop is the first structured pruning framework for vision-language Transformers. It enables effective structured pruning on various multi-modal & uni-modal tasks (including Visual Reasoning, Image Captioning, Visual Question Answer, Image-Text Retrieval, Text-Image Retrieval, Image Classification and Image Segmentation), datasets (including NLVR2, COCO Caption, VQAv2, COCO, Flickr30K, ImageNet and ADE20K), and model architectures (including BLIP, CLIP, DeiT and Segmenter).\n  \nhttps://preview.redd.it/gfbjnxjm95fb1.png?width=2145&format=png&auto=webp&s=108898690f66a1f0afa068b69487859213055928\n  \nWhat challenge does it tackle: The above figure demonstrates that Unified Search adopted by UPop rescues us from the burden of repeated experiments (e.g., doing grid search) for searching optimal compression ratios among different modalities and structures. Furthermore, Progressive Pruning adopted by UPop eliminates the weight gap between the searched model and the pruned subnet to be retrained, therefore gaining better convergence and performance, especially at high compression ratios.\n How about the performance: On multimodal tasks, for example, UPop can achieve 2x compression with only 1.2% and 2.0% accuracy loss on the VQAv2 dataset for Visual Question Answer and the NLVR2 dataset for Visual Reasoning, respectively. On unimodal tasks, for example, UPop can achieve 1.5x and 1.2x compression without any loss of accuracy on the ImageNet dataset for Image Classification and the ADE20K dataset for Image Segmentation, respectively. Some examples of vector-level structured granularity are as follows.\n  \nhttps://preview.redd.it/lifz1n1ia5fb1.png?width=1187&format=png&auto=webp&s=f419d9c5fb4d80a2a564198eba356021e1c275e4\n    submitted by    /u/Salty-Situation2606  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dsjp3/r_compressing_visionlanguage_and_unimodal/",
          "publishedOn": "2023-07-30T18:26:03.000Z",
          "wordCount": 2700,
          "title": "[R] Compressing vision-language and unimodal Transformers via structured pruning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dsinj/p_hiring_high_paying_ml_jobs/",
          "author": null,
          "description": "​\n  \n Title Company Location URL \n  \n Senior Software Engineer (Backend) Nova Credit Remote https://pycareer.io/jobs/6816 \n  Data Scientist - Delivery, Senior-Staff Instacart Not Specified https://pycareer.io/jobs/6773 \n  Data Scientist Data Scientist United States https://pycareer.io/jobs/6780 \n  Senior Data Scientist (NLP and Classification Expert) › Senior Data Scientist (NLP and Classification Expert) › Not Specified https://pycareer.io/jobs/6781 \n  Senior Software Engineer (Backend) Senior Software Engineer (Backend) United States https://pycareer.io/jobs/6788 \n  AWS Data Engineer Apply Not Specified United States https://pycareer.io/jobs/6801 \n  Senior Data Engineer Manager Apply Not Specified United States https://pycareer.io/jobs/6802 \n  Data Scientist – Delivery, Senior-Staff Instacart Instacart Remote https://pycareer.io/jobs/6805 \n  Software Design Engineer – NET, Python – Citizen/GC (H) Not Specified Remote https://pycareer.io/jobs/6837 \n  Senior Data Scientist at Getty Images Getty Images Remote https://pycareer.io/jobs/6839 \n  Lead Data Scientist at General Mills General Mills Remote https://pycareer.io/jobs/6840 \n  Data Scientist – Delivery, Senior-Staff at Instacart Instacart Remote https://pycareer.io/jobs/6842 \n \n ​\n    submitted by    /u/tadasg6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dsinj/p_hiring_high_paying_ml_jobs/",
          "publishedOn": "2023-07-30T18:24:53.000Z",
          "wordCount": 2608,
          "title": "[P] [HIRING] High Paying ML Jobs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ds07h/p_prompttools_open_source_tools_for_language/",
          "author": null,
          "description": "submitted by    /u/hegel-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ds07h/p_prompttools_open_source_tools_for_language/",
          "publishedOn": "2023-07-30T18:03:09.000Z",
          "wordCount": 2493,
          "title": "[P] PromptTools: Open source tools for language model evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15drnzi/r_if_you_have_to_do_a_ml_project_for_prediction/",
          "author": null,
          "description": "For a master thesis I want to write a ML model (and hopefully make my own contribution)\n and I plan to use macroeconomic data. I could predict the typical inflation, GDP, unemployment, but\n are there any other factors that are important. Could you give me some ideas. Thanks! \n    submitted by    /u/AnyJello605  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15drnzi/r_if_you_have_to_do_a_ml_project_for_prediction/",
          "publishedOn": "2023-07-30T17:49:11.000Z",
          "wordCount": 2539,
          "title": "[R] If you have to do a ML project for prediction macroeconomic factors which factor would you choose",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15drj12/d_can_artificial_intelligence_solve_the_problem/",
          "author": null,
          "description": "submitted by    /u/Muinonan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15drj12/d_can_artificial_intelligence_solve_the_problem/",
          "publishedOn": "2023-07-30T17:43:39.000Z",
          "wordCount": 2500,
          "title": "[D] Can artificial intelligence solve the problem of crop diseases — and help curb global hunger?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dpxec/d_interesting_realworld_applications_for/",
          "author": null,
          "description": "Everyone is going crazy creating LORAs and fine-tuning huge LLMs, however I've seen many suggesting that models such as T5 from Google has its place in the enterprise. Have you guys used this or similarly small models for any novel real world problems? Please do share!\n    submitted by    /u/MonkeyMaster64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dpxec/d_interesting_realworld_applications_for/",
          "publishedOn": "2023-07-30T16:35:41.000Z",
          "wordCount": 2529,
          "title": "[D] Interesting real-world applications for fine-tuning T5, and similar models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dnok8/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dnok8/d_simple_questions_thread/",
          "publishedOn": "2023-07-30T15:00:19.000Z",
          "wordCount": 2526,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15djz60/p_deep_dive_and_experiments_for_the_nn_gzip/",
          "author": null,
          "description": "submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15djz60/p_deep_dive_and_experiments_for_the_nn_gzip/",
          "publishedOn": "2023-07-30T12:04:51.000Z",
          "wordCount": 2497,
          "title": "[P] Deep Dive and Experiments for the NN + Gzip Method vs LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dfx0q/r_nenv_neural_environment_maps_for_global/",
          "author": null,
          "description": "submitted by    /u/crp1994  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dfx0q/r_nenv_neural_environment_maps_for_global/",
          "publishedOn": "2023-07-30T08:03:10.000Z",
          "wordCount": 2490,
          "title": "[R] NEnv: Neural Environment Maps for Global Illumination",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d86pd/d_how_to_generate_masks_for_overlapping_classes/",
          "author": null,
          "description": "Hi I am new to computer vision, I am working on a particular hackathon challenge, where the input labels are in COCO format. I am using the following code to generate masks,\n cat_ids = coco.getCatIds() anns_ids = coco.getAnnIds(imgIds=img['id'], catIds=cat_ids, iscrowd=None) anns = coco.loadAnns(anns_ids) anns_img = np.zeros((img['height'],img['width'])) for ann in anns: anns_img = np.maximum(anns_img,coco.annToMask(ann)*ann['category_id']) \n But the image has overlapping labels for some pixels, and this masking will only assign one label for such pixel, resulting in information loss, each there any way to prevent this and preserve the information?\n    submitted by    /u/franticpizzaeater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d86pd/d_how_to_generate_masks_for_overlapping_classes/",
          "publishedOn": "2023-07-30T01:02:50.000Z",
          "wordCount": 2581,
          "title": "[D] How to generate masks for overlapping classes to COCO format labels, to be used in transformer models like Segformer.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d77nn/discussion_what_should_i_do/",
          "author": null,
          "description": "Hi, y’all. \n So, I completed my masters degree. Got a programming job. I’m amazed at the capabilities of machine learning and want to build my own models. I don’t really want to go and get another degree, but want to learn how to build models. I’m particularly interested in forecasting because my job deals with NASA and wind data. I’m wondering if we could predict 6 hour wind data with a balloon sounding. \n I know c++ and python. How do I stay relevant to the changing technology space and learn how to build some cool stuff that may be useful? \n Thanks for any advice.\n    submitted by    /u/corey4005  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d77nn/discussion_what_should_i_do/",
          "publishedOn": "2023-07-30T00:16:45.000Z",
          "wordCount": 2582,
          "title": "[Discussion] what should I do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d729w/d_calculate_w_and_b_in_hard_margin_svm/",
          "author": null,
          "description": "Hello everyone,\n I have been asked the following question related to SVM (Hard Margin) in the exam, and I failed to answer it. Can anyone help me find the solution?\n My approach was to sketch it and draw the marginal plane, then identify support vectors using my intuition. After that, I created a hyperplane that was the midpoint of both marginal planes, found its slope and y-intercept, but still, my answer was wrong.\n I am very new to machine learning, so any help would be appreciated.\n Consider the dataset M = {((1, 0)^T, 1), ((0, −1)^T, 1), ((1, −1)^T, −1), ((2, 0)^T, −1)}. Determine w and b.\n    submitted by    /u/salman_ml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d729w/d_calculate_w_and_b_in_hard_margin_svm/",
          "publishedOn": "2023-07-30T00:09:48.000Z",
          "wordCount": 2589,
          "title": "[D] Calculate 'w' and 'b' in hard margin SVM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d68k3/p_brand_new_ai_social_app_featuring_unique_bot/",
          "author": null,
          "description": "Hi everyone,\n I'm messaging on behalf of a brand new AI based Social Media app called Cantina. It's like a cross between the best parts of Discord, Twitch, and Snapchat, and uses both Stable Diffusion and ChatGPT to allow users to create and interact with AI bots.\n The app is currently INVITE ONLY during the Beta phase and we are looking for people to try it out (currently iOS only, but Android is coming soon!). Here's a private invite link: https://canti.na/dIdKzWcEpBb.\n The most unique and FUN part of the app is that it allows users to interact with and build your own AI chat bots, and these bots also work as AI art creators. Simply ask them to draw something, and they'll provide you with a picture based on your prompt. There are lots of premade bots that you can interact with or add to rooms, or you can easily create your own bot using the Make A Bot function. There will be prizes and initiatives for the most creative bots in the near future. I'd love to see what you come up with!\n Anyway, you can download through the invite link above and dive right in. If you have any thoughts, questions, or comments, please feel free to message me! During this limited beta phase, your feedback will be invaluable.\n    submitted by    /u/SamuelAnonymous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d68k3/p_brand_new_ai_social_app_featuring_unique_bot/",
          "publishedOn": "2023-07-29T23:31:16.000Z",
          "wordCount": 2711,
          "title": "[P] Brand new AI Social App featuring unique bot features looking for iOS users to join Beta!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d4nj4/d_ai_that_can_describe_a_video/",
          "author": null,
          "description": "Anyone know if there is anything able to describe the content of a video? I have found a lot of stuff for images but nothing for videos.\n    submitted by    /u/crazewill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d4nj4/d_ai_that_can_describe_a_video/",
          "publishedOn": "2023-07-29T22:19:43.000Z",
          "wordCount": 2507,
          "title": "[D] AI that can describe a video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d4kjf/p_best_machine_learning_algorithms_for_forecasting/",
          "author": null,
          "description": "I plan on using Machine Learning Algorithms to forecast future values of power demand and the literature on the subject is a bit divisive. I'm getting ANN, Decision Trees (odd), SVMs etc.\n I just want to know what models you guys would use (MATLAB and Python only, except it's really good).\n Thank you in anticipation.\n P.S: Any literature to streamline my search will be greatly appreciated.\n    submitted by    /u/X69-2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d4kjf/p_best_machine_learning_algorithms_for_forecasting/",
          "publishedOn": "2023-07-29T22:16:02.000Z",
          "wordCount": 2546,
          "title": "[P] Best Machine Learning Algorithms for Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d1l08/r_factool_factuality_detection_in_generative_ai_a/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.13528 \n Blog: https://ethanc111.github.io/factool_website/ \n Github: https://github.com/GAIR-NLP/factool \n Factool is a tool augmented framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Factool now supports 4 tasks:\n  \nknowledge-based QA: Factool detects factual errors in knowledge-based QA.\n code generation: Factool detects execution errors in code generation.\n mathematical reasoning: Factool detects calculation errors in mathematical reasoning.\n scientific literature review: Factool detects hallucinated scientific literatures.\n  \nAbstract:\n  \nThe emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d1l08/r_factool_factuality_detection_in_generative_ai_a/",
          "publishedOn": "2023-07-29T20:09:05.000Z",
          "wordCount": 2712,
          "title": "[R] FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios - Shanghai Jiao Tong University et al 2023 - Plugin for ChatGPT! - Highly improves factfulness in math, code, knowledge and scientific reasoning!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d1j36/p_promptify_20_more_structured_more_powerful_llms/",
          "author": null,
          "description": "Hello fellow coders and AI enthusiasts!\n First up, a huge Thank You for making Promptify a hit with over 2.3k+ stars on Github ! 🌟\n Back in 2022, we were the first one to tackle the common challenge of uncontrolled, unstructured outputs from large language models like GPT-3. , and your support has pushed us to keep improving.Today, we're thrilled to share some major updates that make Promptify even more powerful\n https://preview.redd.it/hk7ro4tmnyeb1.png?width=1510&format=png&auto=webp&s=226ada1f896c620137f827932c03a9df88e35d69\n ​\n  \nUnified Architecture 🧭: Introducing Prompter, Model & Pipeline Solution\n Detailed Output Logs 📔: Comprehensive structured JSON format output within the log folder.\n Wider Model Support 🤝: Supporting models from OpenAI, Azure, Cohere, Anthropic, Huggingface and more - think of it as your universal language model adapter.\n Robust Parser 🦸‍♂️: Parser to handle incomplete or unstructured JSON outputs from any LLMs.\n Ready-Made Jinja Templates 📝: Jinja prompt templates for NER, Text Classification, QA, Relation-Extraction, Tabular data, etc.\n Database Integration 🔗: Soon, Promptify directly to Mongodb integration. Stay tuned!\n Effortless Embedding Generation 🧬: Generate embeddings from various LLMs effortlessly with the new update.\n  \nhttps://preview.redd.it/rf8yjqxnnyeb1.png?width=2160&format=png&auto=webp&s=87b7c2408382757e38ff554fde56e56bd60b1793\n ​\n Check out the examples and take Promptify for a spin on GitHub. If you like what you see, we'd be honored if you gave us a star!\n  \nGithub: https://github.com/promptslab/Promptify\n Colab: Try Now on Colab\n Explore Other Cool Open Source LLM Tools: https://github.com/promptslab\n  \nJoin 1.6k+ Promptify users on Discord to dive deep into prompt engineering, discuss the latest with LLMs, and advance NLP research together: https://discord.com/invite/m88xfYMbK6\n Thank you again for your support - here's to more structured AI!\n    submitted by    /u/StoicBatman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d1j36/p_promptify_20_more_structured_more_powerful_llms/",
          "publishedOn": "2023-07-29T20:06:43.000Z",
          "wordCount": 2741,
          "title": "[P] Promptify 2.0: More Structured, More Powerful LLMs with Prompt-Optimization, Prompt-Engineering, and Structured Json Parsing with GPT-n Models! 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d1c53/d_why_being_careful_matters_when_selecting_cnn/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d1c53/d_why_being_careful_matters_when_selecting_cnn/",
          "publishedOn": "2023-07-29T19:58:42.000Z",
          "wordCount": 2480,
          "title": "[D] Why Being Careful Matters When Selecting CNN Padding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d0oz9/r_rt2_visionlanguageaction_models_transfer_web/",
          "author": null,
          "description": "Paper: https://robotics-transformer2.github.io/assets/rt2.pdf \n Blog: https://robotics-transformer2.github.io/ \n Blog: https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action \n Github ( RT-1 as of now) : https://github.com/google-research/robotics_transformer \n Abstract:\n  \nWe study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robot…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d0oz9/r_rt2_visionlanguageaction_models_transfer_web/",
          "publishedOn": "2023-07-29T19:31:01.000Z",
          "wordCount": 2819,
          "title": "[R] RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control - Google DeepMind 2023 - Is able to perform multi-stage semantic reasoning and can interpret commands not present in the robot training data!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cz6zh/d_no_free_lunch_theorem/",
          "author": null,
          "description": "A conclusion of the no free lunch theorem is that there can't exist a universal learning algorithm. My understanding has been that this was the end goal of AI research; creating a universal learner. What is the community progressing towards, if not that?\n    submitted by    /u/lemlo100  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cz6zh/d_no_free_lunch_theorem/",
          "publishedOn": "2023-07-29T18:27:02.000Z",
          "wordCount": 2521,
          "title": "[D] No free lunch theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cx7j3/project_seeking_coding_wizards_for_traveling/",
          "author": null,
          "description": "Hello everyone,\n I'm currently working on an exciting project using the Travelling Salesman Problem (TSP), and I'd love to have some coding wizards join the fun!\n If you enjoy solving optimisation problems and have some coding experience, particularly in Python, this project is for you. To determine the most efficient routes, we'll use heuristic methods such as the Nearest Neighbour Algorithm, Genetic Algorithm, and Ant Colony Optimisation.\n If you aren't a TSP expert yet, don't worry. We'll be learning and exploring together! I'm really looking forward to seeing how we can optimise routes for real-world applications like delivery and travel planning.\n So, if you're looking for a coding adventure and want to be a part of a fantastic project, hit me up! Let's crack this TSP puzzle and create some smart solutions.\n If you're interested in collaborating, please send me a message. I can't wait to work with you and nerd out on some fantastic code!\n    submitted by    /u/vampire_19  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cx7j3/project_seeking_coding_wizards_for_traveling/",
          "publishedOn": "2023-07-29T17:01:14.000Z",
          "wordCount": 2637,
          "title": "[Project] Seeking Coding Wizards for Traveling Salesman Challenge!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cwufp/ml_on_detecting_bacteria_in_blood_through/",
          "author": null,
          "description": "I am trying to make a machine that could detect if there is any bacteria in blood through pictures. However I do not know any thing about machine learning and only knows a little bit of Python and C++. What should I do?\n    submitted by    /u/EthanWasTakenAgain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cwufp/ml_on_detecting_bacteria_in_blood_through/",
          "publishedOn": "2023-07-29T16:45:33.000Z",
          "wordCount": 2527,
          "title": "ML on detecting bacteria in blood through pictures for beginners [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cv8ql/dseeking_participants_for_airelated_survey/",
          "author": null,
          "description": "I am currently working on my IB Extended Essay, and I would greatly appreciate your help in gathering valuable insights from individuals knowledgeable in the field of AI. The purpose of my survey is to understand the perspectives of AI enthusiasts .\n If you have a few minutes to spare, I kindly request you to participate in my survey. Your input will contribute significantly to my research and help me gain a deeper understanding of the topic. The survey covers various aspects of AI, and your expertise will be invaluable in shaping the results.\n Survey Link: https://forms.gle/PVGrRbPLTpZRbbpL9\n Rest assured that all responses will be kept confidential and only used for academic purposes. Additionally, feel free to share this survey with others who might be interested or knowledgeable in the field. Thank you in advance for your time and contributions! Your participation will greatly aid in the successful completion of my IB Extended Essay.\n    submitted by    /u/KVNG_Winston  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cv8ql/dseeking_participants_for_airelated_survey/",
          "publishedOn": "2023-07-29T15:36:37.000Z",
          "wordCount": 2631,
          "title": "[D]Seeking Participants for AI-related Survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cv1p4/d_seeking_resume_expertise_struggling_to_land/",
          "author": null,
          "description": "submitted by    /u/AIKiller1997  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cv1p4/d_seeking_resume_expertise_struggling_to_land/",
          "publishedOn": "2023-07-29T15:28:32.000Z",
          "wordCount": 2514,
          "title": "[D] Seeking Resume Expertise: Struggling to Land Interviews or Jobs, Need Guidance! Please Assist!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cudgl/efficient_lasso_regression_for_n200000_and/",
          "author": null,
          "description": "Please suggest me efficient LASSO regression implementations for very high dimensional data. Thanks in advance!\n    submitted by    /u/Charming-Witness-286  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cudgl/efficient_lasso_regression_for_n200000_and/",
          "publishedOn": "2023-07-29T14:59:48.000Z",
          "wordCount": 2496,
          "title": "Efficient LASSO regression for N=~200,000 and dim=~30,000 [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cphv6/one_big_net_for_everything_2018/",
          "author": null,
          "description": "submitted by    /u/EducationalCicada  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cphv6/one_big_net_for_everything_2018/",
          "publishedOn": "2023-07-29T11:00:50.000Z",
          "wordCount": 2490,
          "title": "One Big Net For Everything (2018)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cm94i/text_reclassification_promptscode_d_r/",
          "author": null,
          "description": "submitted by    /u/MutedCatch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cm94i/text_reclassification_promptscode_d_r/",
          "publishedOn": "2023-07-29T07:47:16.000Z",
          "wordCount": 2495,
          "title": "Text reclassification prompts/code [D] [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cie8m/d_conformal_prediction_with_python/",
          "author": null,
          "description": "submitted by    /u/Kujamara  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cie8m/d_conformal_prediction_with_python/",
          "publishedOn": "2023-07-29T04:05:51.000Z",
          "wordCount": 2502,
          "title": "[D] Conformal Prediction with Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cc0rj/d_major_issue_found_with_minmax_data_scaling/",
          "author": null,
          "description": "I have a well performing model on azure AI currently and i am pulling it down locally so that I can use it. During pre-processing I am going about these steps. \n - Re-Balance data (SMOTE, undersample)\n - Lag data \n - Get all min max values into config\n - Scale Data with Min Max\n For context I will explain what step 3 (the config) is for, I take the the min and max values of the entire dataset (before split) for each feature. I then apply append these to my local version and being the scaling so then the local dataset is using the exact same scaling parameters as what is being using during the original pre-processing.\n I cannot show the full dataset due to privacy and the fact it has 3000+ features. But I will show 1 row with a couple of columns to compare AzureAI training data and my local pre-process that is using the exact same code / system.\n ​\n Azure AI dataset:\n Feature1 Feature2 Feature3\n 0.637952 0.645434 0.641118\n ​\n Local dataset:\n Feature1 Feature2 Feature3\n 0.461278 0.462896 0.472841 \n ​\n I have confirmed this is the exact same row of data because i have timestamped each row and matched them up to confirm that the dataset scaling is being simulated in my local version even though the code is carbon copy and the same min and max values are being used in the original dataset that used for training and testing. \n Does anyone know a better way to scale data and ensure scaling stays consistent wherever the model is used? Or have maybe I missed something? \n    submitted by    /u/paddockson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cc0rj/d_major_issue_found_with_minmax_data_scaling/",
          "publishedOn": "2023-07-28T23:01:26.000Z",
          "wordCount": 2745,
          "title": "[D] Major issue found with MinMax data scaling.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cb8be/p_harness_the_power_of_ml/",
          "author": null,
          "description": "I built out an automatic machine learning platform called Heimdall ML which helps anyone quickly deploy machine learning models to production.\n At a high level, my platform will:\n  \nIngest your data as a .csv file\n Clean up any irregularities and prepare the data for modeling\n Build the most Optimal model for you use case\n Show you a results report to show both the performance and biases associated with your model\n Create an API endpoint to help you build new experiences with your model\n  \nThe cool thing about my platform is that it allows you the ability to embed machine learning into your platform with ease. You have the ability to fully customize your experience to wow you customers. I built this entire platform by myself from scratch and am looking to grow the user base!\n The tool is completely FREE for hobby users! You can crunch some pretty large datasets (80 columns, 10K rows) with just the free version. If you have a use case that needs some big data processing, you will have to reach out to me directly so I can help set up a good plan for you. The reason for this is because the project is completely self funded and I want to be able to control the costs.\n I was inspired to create this platform while I was in grad school because many of the firms giving us talks would talk about how they had teams of engineers who build out pipelines to bring a model to production. I personally believe there can be an easier way.\n Heimdall ML: https://www.heimdallapp.org\n Loom: https://www.loom.com/share/86ae62849f874a2da255911e2d5db762?sid=5e1efddb-9556-4e3d-84fd-e2ff7198a98c\n    submitted by    /u/jreji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cb8be/p_harness_the_power_of_ml/",
          "publishedOn": "2023-07-28T22:28:15.000Z",
          "wordCount": 2746,
          "title": "[P] Harness the Power of ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c9r3z/can_someone_make_an_ai_therapist_that_isnt_just_a/",
          "author": null,
          "description": "One that looks like a person. You can see their expressions and listen to their voice. Trained on up to date medical research and communication/empathy skills. \n Therapy is so expensive and inaccessible to too many people\n    submitted by    /u/Sgdoc70  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c9r3z/can_someone_make_an_ai_therapist_that_isnt_just_a/",
          "publishedOn": "2023-07-28T21:28:38.000Z",
          "wordCount": 2521,
          "title": "Can someone make an AI Therapist that isn’t just a chat? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c89r7/d_huggingface_changed_the_license_of_one_of_its/",
          "author": null,
          "description": "TGI is no longer commercially permissible. That's really sad.\n https://github.com/huggingface/text-generation-inference/commit/bde25e62b33b05113519e5dbf75abda06a03328e\n    submitted by    /u/paulo_zip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c89r7/d_huggingface_changed_the_license_of_one_of_its/",
          "publishedOn": "2023-07-28T20:29:11.000Z",
          "wordCount": 2495,
          "title": "[D] HuggingFace changed the license of one of its most important libraries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c5kfc/d_how_do_large_companies_get_their_llms_to_give/",
          "author": null,
          "description": "Curious how companies like Google, MSFT, etc are able to have their LLMs and ML models have very fast responses. Do they just have crazy powerful gpus or split inference amongst gpus.\n    submitted by    /u/candyman54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c5kfc/d_how_do_large_companies_get_their_llms_to_give/",
          "publishedOn": "2023-07-28T18:42:45.000Z",
          "wordCount": 2518,
          "title": "[D] How do large companies get their LLMs to give sub second responses?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c4qk2/d_hugging_face_github_and_more_unite_to_defend/",
          "author": null,
          "description": "Full Article: https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/\n    submitted by    /u/EmbarrassedHelp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c4qk2/d_hugging_face_github_and_more_unite_to_defend/",
          "publishedOn": "2023-07-28T18:09:57.000Z",
          "wordCount": 2491,
          "title": "[D] Hugging Face, GitHub and more unite to defend open source in EU AI legislation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c48vv/p_revolutionizing_agriculture_llmpowered_agent/",
          "author": null,
          "description": "Check out this project idea to revolutionize agriculture and bolster global food security. We all know that farmers face challenges like erratic weather, depleting resources, and the need for sustainable crop yields.\n An IoT-driven system with soil sensors, fueled by a custom Large Language Model (LLM)🚀 trained on soil data.\n Concept : Empowering farmers with real-time soil data via IoT devices and sensors. Leveraging the LLM's capabilities, the system analyzes this data to provide personalized strategies for enhancing soil fertility and suggesting the best crops for specific conditions.\n How it Works : IoT devices and soil sensors continuously gather vital soil parameters - moisture, pH, nutrients, and temperature. This data is processed by the LLM, generating actionable insights for farmers.\n Benefits : Picture a world where data-driven decisions and sustainable practices dominate agriculture. This system boosts productivity, optimizes resource management, and enhances profits. Embracing sustainability and informed choices ensures an eco-friendly agricultural sector.\n Impact on Food Security : Enhanced productivity means more than just profit; it ensures food security worldwide. By aiding farmers in sustainable and efficient practices, we contribute to a steady supply of nutritious food for all.\n    submitted by    /u/s_abhiishek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c48vv/p_revolutionizing_agriculture_llmpowered_agent/",
          "publishedOn": "2023-07-28T17:50:32.000Z",
          "wordCount": 2682,
          "title": "[P] Revolutionizing agriculture: LLM-Powered Agent for Soil Fertility and Crop Production Recommendations using real time soil devices and sensor data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bz0f2/d_recommendation_on_studying_deep_learning_theory/",
          "author": null,
          "description": "I've just finished Machine Learning Specialization by Andrew Ng and I'm planning to dive deeper into Deep Learning concepts, theory, and implementation. I would like to get deeper insights and more understanding of the fundamental mathematical concepts of NN and DL models and build better intuition of how these models work. I also want to understand theoretically, how more neurons capture non-linear relationships in data and what exactly is hierarchical representation of data and how hidden layers form and learn from these abstract representations of data. Apart from theory, I also want to learn the implementation of these models. I have some exposure to TF library, but I'm okay to learn Pytorch too, if needed.\n I need course or any sort of content recommendation on what are the best options to learn all this. So far, I've got recommendations for Deep Learning Specialization by Andrew Ng, but I would love to hear any alternate option or anything that I can do side by side this specialization.\n Thanks!\n    submitted by    /u/Total-Opposite-8396  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bz0f2/d_recommendation_on_studying_deep_learning_theory/",
          "publishedOn": "2023-07-28T14:28:04.000Z",
          "wordCount": 2658,
          "title": "[D] Recommendation on studying Deep Learning (Theory + Implementation) / Alternate to Deep Learning Specialization by Andrew Ng?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15buplq/r_what_is_a_fairly_good_results_for_sacrebleu/",
          "author": null,
          "description": "I ran my own model on translation (Multi30k). I trained a recurrent model and the sacrebleu score is 28. I also tested the bleu score provided by nltk and it is 60. It that good or bad?\n    submitted by    /u/Puzzleheaded-Cry4262  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15buplq/r_what_is_a_fairly_good_results_for_sacrebleu/",
          "publishedOn": "2023-07-28T11:23:49.000Z",
          "wordCount": 2519,
          "title": "[R] What is a fairly good results for sacrebleu?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15btipw/d_please_advise_me_on_my_masters/",
          "author": null,
          "description": "Please give me advice to do well in my masters in ml\n I’m going to start my masters in machine learning soon, I have 1 month to go but I feel so underprepared to start this journey. To give you a bit of a background I’ve studied electrical engineering in my UG. I did very badly, I was very depressed and couldn’t study at all somehow I managed to scrape through the 4 years and now after working in software testing for 2 years I decided to take a leap in machine learning because it looked so interesting and I wanted a change. I’m scared now because my coding knowledge isn’t very good and idk how much of the math I know is useful for the degree I plan to do. Please help me I’m panicking. I know you would tell me it’s pretty irresponsible how I’ve handled my life till now but please overlook that and tell me what I can do better now..\n    submitted by    /u/ObjectiveShower9133  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15btipw/d_please_advise_me_on_my_masters/",
          "publishedOn": "2023-07-28T10:22:41.000Z",
          "wordCount": 2645,
          "title": "[D] Please advise me on my masters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15brbv1/d_recommendation_system_giving_same_response_to/",
          "author": null,
          "description": "I am using Gorse Open Source Recommendation system for my project. It was working nicely, but lately from 1-2 days, it is giving the same recommendation for every user. I have about 60 items and about 650 users showing in Gorse Dashboard. Can anyone explain why it's happening? I am not an expert in ML,I am willing to share my configurations if you want.\n    submitted by    /u/Responsible_Delay418  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15brbv1/d_recommendation_system_giving_same_response_to/",
          "publishedOn": "2023-07-28T08:19:54.000Z",
          "wordCount": 2546,
          "title": "[D] Recommendation system giving same response to every User",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/",
          "author": null,
          "description": "I have a data set that isn't that large ~200 pdfs. I have done the regular RAG approach with Langchain, extracting text, splitting into chunks, embedding with OpenAi embeddings and FAISS vector storage. However, when I do a similarity search with a question I would like answered it returns the wrong context. The documents are semi-structured information of examined bridges. A question I would like answered is f.e. 'what is the construction date of bridge X?'. When I input this question I get a lot of context of construction dates of other bridges. I think this is because the bridges are not explicitly mentioned in the text. I tried adding the bridge name and document name to the page content string of the chunks, but this does nothing.\n Does anyone have any tips on improving the embeddings retrieval in this case?\n    submitted by    /u/Dustwellow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/",
          "publishedOn": "2023-07-28T08:01:54.000Z",
          "wordCount": 2623,
          "title": "[D] Having trouble with RAG on company domain data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15br0b6/p_tool_to_auto_compilequantize_models/",
          "author": null,
          "description": "Hey guys, we have an internal tool that preps our models for inference by compiling it to Onnx/TensorRT and quantizing it to I8/FP16. It also benchmarks them for accuracy loss and latency. It's kinda like github actions for your model. We are considering releasing it as it's standalone product, would anyone be interested? \n    submitted by    /u/throwaway65161354  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15br0b6/p_tool_to_auto_compilequantize_models/",
          "publishedOn": "2023-07-28T08:00:54.000Z",
          "wordCount": 2532,
          "title": "[P] Tool to auto compile/quantize models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bqwdv/d_domain_adaptation_on_llama2/",
          "author": null,
          "description": "Hi,\n I am trying domain adaptation on my company’s data. The data is a set of documentations that we have for a product.\n We want to take Llama2 and feed all this data to it.\n I have fine-tuned Llama2 using PEFT on a CLM task, where the data will be like [Title:<title>\\nContent:<content>].\n When I now try to prompt the model I have to provide the prompt in a similar format, but I want the model to understand that I want to perform QA task on the data, as well as any other knowledge the model previously had.\n What am I missing here or what am I doing wrong? How can I set up this task better? Any pointers will help.\n Thanks!\n    submitted by    /u/ProfessorShit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bqwdv/d_domain_adaptation_on_llama2/",
          "publishedOn": "2023-07-28T07:54:20.000Z",
          "wordCount": 2599,
          "title": "[D] Domain adaptation on LLAMA2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bpr4d/r_implementing_yolov3_with_octave_convolutions/",
          "author": null,
          "description": "Hi all, I am trying to implent or rather modify a given Yolov3 implementation to use Octave Convolution instead of 2D Convolutions in the architecture. The details are in this stackoverflow question. I hope someone i able to help me.\n    submitted by    /u/dulre  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bpr4d/r_implementing_yolov3_with_octave_convolutions/",
          "publishedOn": "2023-07-28T06:48:03.000Z",
          "wordCount": 2519,
          "title": "[R] Implementing Yolov3 with Octave Convolutions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bovwu/r_communicative_agents_for_software_development/",
          "author": null,
          "description": "ChatDev\n Paper: https://arxiv.org/abs/2307.07924\n TL;DR:\n - Tsinghua University's team has developed ChatDev, a virtual software development company staffed by LLM autonomous agent\n - LLM agents as employee follow waterfall model to design->implement->test->documentation\n - LLM agents have role specialization (CEO, DEV, BA ..), inception prompting, Self-reflection\n - The researchers designed 70 user requirements and then analyzed the software produced by ChatDev. \n - On average, each piece of software generated by ChatDev had 17.04 files, mitigated 13.23 potential code bugs caused by code illusions, had a software generation time of 409.84 seconds, and cost $0.2967 to manufacture.\n ​\n Chat chain\n ​\n    submitted by    /u/michaelthwan_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bovwu/r_communicative_agents_for_software_development/",
          "publishedOn": "2023-07-28T05:59:18.000Z",
          "wordCount": 2582,
          "title": "[R] Communicative Agents for Software Development (Autonomous LLM agent as a DEV company)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bno2k/d_milvus_20_or_higher_with_gpu_enabled/",
          "author": null,
          "description": "Is there a way to use milvus 2.0 or higher with GPU enabled indexing and while doing vector search? I cant find anything in there documentation for this section only available in 1.1 version Any help will be appreciated. TIA\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bno2k/d_milvus_20_or_higher_with_gpu_enabled/",
          "publishedOn": "2023-07-28T04:51:26.000Z",
          "wordCount": 2521,
          "title": "[D] Milvus 2.0 or higher with GPU enabled",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bmuy7/p_has_anyone_tried_to_work_with_starcoder/",
          "author": null,
          "description": "I recently found out about starcoder and have been trying to play with it and figure it out in a colab notebook. Unfortunately, it’s much more difficult to download than normal models on hugging face and I’m running into a Key Value error when I call the model. I don’t want to spam with with code or pictures, but has anyone worked with StarCoder on hugging face and been able to be successful?\n    submitted by    /u/AJ1043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bmuy7/p_has_anyone_tried_to_work_with_starcoder/",
          "publishedOn": "2023-07-28T04:07:46.000Z",
          "wordCount": 2554,
          "title": "[P] Has anyone tried to work with StarCoder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bkv3g/d_can_anyone_explain_what_karpathys_recent/",
          "author": null,
          "description": "Hi, I am not a CS student. I want to know what's exactly going on with llama2.c. Is the Python code converted to C and then compiled? Or only weights are converted to C? Is the network written in C? If I have to write a small network (say, a simple 2 stage Fully connected network) and do a similar thing like llama2.c, then how to proceed? \n    submitted by    /u/panini_deploy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bkv3g/d_can_anyone_explain_what_karpathys_recent/",
          "publishedOn": "2023-07-28T02:26:28.000Z",
          "wordCount": 2557,
          "title": "[D] Can anyone explain what Karpathy's recent llama2.c is doing underneath? I am not a CS student",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bjmj0/r_scaling_transnormer_to_175_billion_parameters/",
          "author": null,
          "description": "https://arxiv.org/abs/2307.14995\n    submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bjmj0/r_scaling_transnormer_to_175_billion_parameters/",
          "publishedOn": "2023-07-28T01:27:12.000Z",
          "wordCount": 2481,
          "title": "[R] Scaling TransNormer to 175 Billion Parameters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bfiok/d_for_lms_what_works_other_than_scaling/",
          "author": null,
          "description": "Increasing the number of parameters is the best-known way to increase the quality of a language model. What methods — instruction tuning and RLHF aside — deliver the next-best amount of ROI?\n    submitted by    /u/ndronen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bfiok/d_for_lms_what_works_other_than_scaling/",
          "publishedOn": "2023-07-27T22:25:48.000Z",
          "wordCount": 2513,
          "title": "[D] For LMs, what works other than scaling?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bf7ai/d_viability_of_fine_tuning_for_domain_knowledge/",
          "author": null,
          "description": "The consensus is that fine tuning LLMs works reasonably for smaller scale instruction tuning, where you pass in ~1k-10k input/output examples to modify the model output.\n There seems to be a lot of contradictory info regarding fine tuning for domain knowledge, where you pass in large amounts of unsupervised, domain scale data.\n Per OpenAI:\n  \nPeople that can’t get finetuning to work are often asking for orange juice from a cow. \n LLMs are pretrained (hence the name: Generative Pretrained Transformer) They already have all the knowledge you will need (with some exceptions). You cannot teach it anything new, you can only teach it a specific pattern. \n People have not defined their goal clearly enough for a human to do the task. LLMs are not magic, if a human cannot understand the task, the L…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bf7ai/d_viability_of_fine_tuning_for_domain_knowledge/",
          "publishedOn": "2023-07-27T22:13:00.000Z",
          "wordCount": 2799,
          "title": "[D] Viability of fine tuning for domain knowledge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bepv2/looking_for_a_help_p/",
          "author": null,
          "description": "I am a graduate student at Computer science medical informatics field, I was asked to search for a project using ML to diagnose, detect, improve any disease. Any Ideas ?? It can be any project .\n BioInformatics #MedicalInformatics #ComputerScience #MachineLearning\n    submitted by    /u/Adorable-Bug-928  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bepv2/looking_for_a_help_p/",
          "publishedOn": "2023-07-27T21:53:25.000Z",
          "wordCount": 2518,
          "title": "Looking for a help [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bd671/r_questions_about_dictionary_learning/",
          "author": null,
          "description": "I’m a PhD student and a problem I’ve been working on has connections to dictionary learning. I’d like to pursue this connection, but neither myself or my advisor have much knowledge of the dictionary learning or the surrounding literature. \n Questions:\n  \nIs dictionary learning an active area of interest for modern ML? I understand that it might be more niche than some of the topics getting headlines these days, but I’d be curious to hear about applications where dictionary learning is used/reasonably competitive.\n \nAre there any references in dictionary learning that you’d consider to be “essential” reading?\n \n Thanks!\n    submitted by    /u/sjsjdhshshs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bd671/r_questions_about_dictionary_learning/",
          "publishedOn": "2023-07-27T20:52:49.000Z",
          "wordCount": 2575,
          "title": "[R] Questions about dictionary learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bayr2/discussion_help_me_pick_the_right_masters/",
          "author": null,
          "description": "Hello Reddit,\n I'm currently at a crossroads in my academic journey and I could use some insights from those more experienced in the field of machine learning and AI.\n I'm choosing between two programs: Applied Data Science and AI and Data Science and AI. Each program has its own unique structure and focus which I will briefly summarize below.\n Applied Data Science and AI is a two-year program with a focus on practicality and project-based learning. It includes the following core courses:\n  \nIntroduction to Data Science\n Python for Data Scientists\n Applied Mathematical Thinking\n Statistical Methods for Data Science\n Applied Machine Learning\n Computational Techniques for Large-Scale Data\n Research Methods for Data Science\n Master’s Thesis in Data Science\n  \nThe program also offers the flexibility to choose optional courses to tailor my learning towards my own interests.\n On the other hand, Data Science and AI takes a more rigorous, math-intensive approach in its first year with compulsory courses such as:\n  \nIntroduction to data science and artificial intelligence\n Nonlinear optimization\n Stochastic processes and Bayesian statistics\n Design of AI systems\n  \nThe second year involves a Master's thesis and elective courses from a diverse range of topics.\n Given that my ultimate goal is to become a proficient machine learning developer, I'm leaning towards the Applied Data Science and AI program for its hands-on approach. However, I'm aware that the Data Science and AI program's heavy math focus in the first year could provide a robust theoretical foundation that could be beneficial.\n I'd love to hear from anyone who has been through similar programs or who works in the field. Which of these two programs do you think would best prepare me for a career in machine learning? How important is a deep mathematical foundation versus a more applied, project-based learning approach? \n Thank you in advance!\n    submitted by    /u/ZoomedBoxTrade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bayr2/discussion_help_me_pick_the_right_masters/",
          "publishedOn": "2023-07-27T19:28:32.000Z",
          "wordCount": 2780,
          "title": "[Discussion] Help me pick the right master's programme!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15baqjr/d_what_neural_networks_can_be_an_alternative_to/",
          "author": null,
          "description": "I am looking for topics for my master thesis I came to read about GARCH/ARCH models and their application to economics. My idea is to use neural networks as an alternative with better performance. Are there any resources I can read about if this is done and what type of neural networks are used?\n    submitted by    /u/AnyJello605  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15baqjr/d_what_neural_networks_can_be_an_alternative_to/",
          "publishedOn": "2023-07-27T19:19:44.000Z",
          "wordCount": 2541,
          "title": "[D] What neural networks can be an alternative to GARCH/ARCH models for macroeconomic modelling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ba6pq/p_new_encryption_sdkproxy_tool_to_protect_vector/",
          "author": null,
          "description": "We're looking for some beta testers and input on our newest project called Cloaked AI that allows you to protect sensitive data that gets stored as vector embeddings (and metadata) in a vector database. You can join the beta tester waitlist here (we'll be rolling out access in the next few weeks). But here are some FAQs about why protecting vector embeddings matters, etc.\n Why should I be worried about sensitive data in vector embeddings?\n To a human, vectors are meaningless. But to the AI, the vectors contain all of the meaning found in the original sensitive data. Generative AI systems can recreate the original sensitive data to a high degree of accuracy (though in their own style). That means the data stored in vector databases are a significant security and privacy risk for companies t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ba6pq/p_new_encryption_sdkproxy_tool_to_protect_vector/",
          "publishedOn": "2023-07-27T18:58:07.000Z",
          "wordCount": 3090,
          "title": "[P] New encryption SDK/proxy tool to protect vector embeddings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b8vic/d_how_nuanced_are_reward_functions_in_rlhf/",
          "author": null,
          "description": "I'm still learning the basic concepts here, as I explore the creative potential of LLMs — one potential problem I've been thinking about is how these models come to understand good or bad answers. \n I know that once they reach the public, the feedback loop is fairly binary -- Yes, this was a good result, or No, this was a poor result. \n It seems like a lot of the subjective detail might be lost (e.g. Why was it a bad result?) and I was wondering if this detail is captured elsewhere in the training process. \n There is so much subjectivity involved in creative works, I wonder if this is why we tend to see the output of LLMs as being creatively bland and/or uninspired (that is— by default, without extensive prompting)\n    submitted by    /u/kaigani  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b8vic/d_how_nuanced_are_reward_functions_in_rlhf/",
          "publishedOn": "2023-07-27T18:05:45.000Z",
          "wordCount": 2612,
          "title": "[D] How nuanced are reward functions in RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b86on/statistical_significance_d/",
          "author": null,
          "description": "Help me with this topic. I am stuck in it\n    submitted by    /u/Rehulmonsynapses  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b86on/statistical_significance_d/",
          "publishedOn": "2023-07-27T17:38:45.000Z",
          "wordCount": 2486,
          "title": "Statistical Significance [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b7mq9/p_tabular_large_language_model/",
          "author": null,
          "description": "Gretel's tabular large language model is capable of generating highly valuable synthetic tabular data, with differentially private fine-tuning. https://gretel.ai/tabular-llm\n    submitted by    /u/alig80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b7mq9/p_tabular_large_language_model/",
          "publishedOn": "2023-07-27T17:17:34.000Z",
          "wordCount": 2497,
          "title": "[P] Tabular Large Language Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b5ry9/d_is_transfer_learning_the_most_vip_problem/",
          "author": null,
          "description": "this might be a dumb question but im gonna ask it anyway, so if its dumb ill learn...\n So ive been doing and mostly learning DL stuff (specially RL) for the past 3 years but now I want to get serious and perhaps get into the industry...\n I find that with LLMs on the scene, the foundation models are very important... the kind of foundation models that one just can never train on his/her own... how can you EVER train something like llama or gpt3 on your own from pure scratch... so it makes sense to use(fine tune) base models for whatever task you want to... with NLP and even with vision (well specially with vision as well) you have to use some base model... also with huggingface being used constantly and is a vital part of AI toolkit if you want to call it that...\n i was never comfortable wi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b5ry9/d_is_transfer_learning_the_most_vip_problem/",
          "publishedOn": "2023-07-27T16:03:51.000Z",
          "wordCount": 2979,
          "title": "[D] Is Transfer Learning the most vip problem solving tool rn @ jobs? [Noob question, be easy]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b4yjw/d_what_cant_you_do_under_windows_subsystem_for/",
          "author": null,
          "description": "I'm looking at building a computer for AI/ML and gaming, and I'm trying to decide between windows and linux as the operating system. I'm very comfortable with linux. I've heard that WSL basically allows you to run a virtualized linux install on top of windows, so I was wondering, is this how most AI/ML is done on windows? Are there things that you can do more easily on linux itself than via WSL? Anything else I should know about AI/ML and WSL?\n    submitted by    /u/curiously_clueless  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b4yjw/d_what_cant_you_do_under_windows_subsystem_for/",
          "publishedOn": "2023-07-27T15:32:12.000Z",
          "wordCount": 2565,
          "title": "[D] What *can't* you do under Windows Subsystem for Linux?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b3kff/d_neural_network_papers_that_estimate_hands/",
          "author": null,
          "description": "I am digging through the literature trying to find if anyone has done work estimating if a hand is interacting with an object using deep learning? If anyone has any references they would be appreciated! \n    submitted by    /u/Academic-Sprinkles77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b3kff/d_neural_network_papers_that_estimate_hands/",
          "publishedOn": "2023-07-27T14:36:25.000Z",
          "wordCount": 2518,
          "title": "[D] Neural network papers that estimate hands interacting with objects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b1nmm/p_lip_reading_from_video_master_thesis_ideas/",
          "author": null,
          "description": "Hello experts,\n I'm looking for any idea/paper for my master thesis, which I'd like to work on lip reading from video.\n Opening Google Scholar gives a very vast ideas that one can easily get lost. If it's an interesting paper, I get afraid that it would be too heavy for such a project.\n Therefore I'd like to ask for your opinion/suggestion!\n Your reply/thoughts would be so much appreciated.\n    submitted by    /u/vincent0110  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b1nmm/p_lip_reading_from_video_master_thesis_ideas/",
          "publishedOn": "2023-07-27T13:16:33.000Z",
          "wordCount": 2549,
          "title": "[P] Lip reading from video; Master Thesis; IDEAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b0ivf/d_should_can_i_become_a_machine_learning_engineer/",
          "author": null,
          "description": "Apologies if this is not the place to ask but I saw some people asking for career advice.\n My situation:\n I am a 28 yo graduated Industrial Engineer (4 years) and almost a \"Superior Industrial Engineer\" (2 years official master degree) with only my thesis left. I should have had my thesis done a year ago from this point but I pretty much lost all my motivation for this field when I started working and discovered what it means to work. I live in south Spain, which honestly can barely pass as first world and thus, my wage, while being \"ok\" for my age and the place I work in is just pathetic by every other metric. This, combined with the feeling of meaningless for the job I do made me resolved to change my situation.\n I started to get heavily interested in ML six months ago. I know how it sou…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b0ivf/d_should_can_i_become_a_machine_learning_engineer/",
          "publishedOn": "2023-07-27T12:24:58.000Z",
          "wordCount": 3143,
          "title": "[D] Should (Can) I become a machine learning engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b0dbp/d_how_do_layers_and_neurons_of_an_ann_go_from/",
          "author": null,
          "description": "Lets say we have built a neural network that identifies a number from 0-9 in a 28x28 pixel image. Now lets say we have multiple neurons in the first hidden layer, and the first hidden layer might capture small edges, lines and curves in the image, and then the second hidden layer might build on those small edges, lines and curves to build bigger shapes, and then so on, the third hidden layer builds on the shapes from the previous layer, to capture more complex and bigger patterns in the picture, and this goes on until we have reached the output layer to make a prediction.\n Now in this neural network, lets focus on the first hidden layer where different neurons capture small edges, lines, and curves in different parts of the image. Lets take example of one of the neuron and see what it's do…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b0dbp/d_how_do_layers_and_neurons_of_an_ann_go_from/",
          "publishedOn": "2023-07-27T12:17:40.000Z",
          "wordCount": 2880,
          "title": "[D] How do layers and neurons of an ANN go from capturing small edges, lines, and curves to capturing more intricate and bigger patterns building on top of small patterns?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15azddj/r_new_tabular_dl_model_tabr_unlocking_the_power/",
          "author": null,
          "description": "Hi Reddit! Me again 🙂\n After almost 1.5 years since our latest contribution to tabular DL architectures, we are ready to announce TabR - our new retrieval-based tabular DL model. In a nutshell, TabR is a simple feed-forward network with k-Nearest-Neighbors-On-Steroids (formally, a generalized attention mechanism) in the middle.\n - Paper: link\n - Code: link\n - Twitter thread with more details: link\n The figure below shows just a small part of the results, but it gives an idea of why we are excited about this new release. I hope you will enjoy reading the paper, and I will be glad to answer the questions!\n ​\n https://preview.redd.it/vjkr7fkosheb1.png?width=2348&format=png&auto=webp&s=eb3ea35b94d56d5d2110d98cdca082210edc1ec8\n    submitted by    /u/Yura52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15azddj/r_new_tabular_dl_model_tabr_unlocking_the_power/",
          "publishedOn": "2023-07-27T11:28:36.000Z",
          "wordCount": 2591,
          "title": "[R] New Tabular DL model: \"TabR: Unlocking the Power of Retrieval-Augmented Tabular Deep Learning\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ayez2/d_transformers_on_structured_data/",
          "author": null,
          "description": "I have a dataset obtained from running a known program and dumping the state each time a user is prompted for a input. The state the structured data structures containing all the information needed to restore the execution. The format of this data is known, so i can convert it without loss to other formats, such as json.\n For example, if the program is sudoku, then the dataset element format is a array of 9x9 int8, where 0 represents a empty cell and a number from 1 to 9 is a assigned cell, furthermore there is a int8 representing the turn count too. I have dataset composed of this array at various points of the game.The data never contains loops, pointers, or any kind of graph.\n I want to use a transformer to automatically learn some function over the input. In the sudoku example this may…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ayez2/d_transformers_on_structured_data/",
          "publishedOn": "2023-07-27T10:39:12.000Z",
          "wordCount": 2841,
          "title": "[D] Transformers on structured data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15avj92/d_how_to_analyse_text_http_requests_looking_for/",
          "author": null,
          "description": "Hi, am I looking for someone to point me in the right direction.\n The task is, to classify the HTTP requests that come to honeypot as \"crawler\" or \"malicious\". For example, if I can detect a Log4j exploit inside on of the headers I can say that that request is malicious. \n The problem is, this exploit could be inside any numerous headers. It can be at the beginning or at the end. And this is just 1 exploit. There are many different exploits with their own unique strings. And I don't know them all, nor do I have a \"regex\" for each 1 of them. The malicious string could also not be inside headers, but inside URL, as query parameter. Or if the request was made to something like www/IP.com/phpadmin/.env (or something like this).\n My current thought process is, to take some open-source LLN, because it has some basic knowledge of how language works and somehow add this cybersecurity domain knowledge to it. To further train it on CVE database, example scripts that showcase each CVE, etc. \n ​\n Am I barking at the right tree here? Or should I maybe train a language model from scratch, so that the embeddings, etc are specialized to cybersec space (because there is a lot of programming code here). Or maybe I should use some other ways to analyse text?\n ​\n I would be greatefull if someone can point me in the right direction (links to blogs, or articles, or some other education material).\n ​\n Thanks\n    submitted by    /u/PopayMcGuffin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15avj92/d_how_to_analyse_text_http_requests_looking_for/",
          "publishedOn": "2023-07-27T07:56:02.000Z",
          "wordCount": 2733,
          "title": "[D] How to analyse text (http requests) - looking for guidence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15asesf/r_google_medpalm_m_towards_generalist_biomedical/",
          "author": null,
          "description": "Paper URL\n https://arxiv.org/abs/2307.14334\n Lead Author Tweetstorm\n https://twitter.com/vivnat/status/1684404882844024832\n ​\n    submitted by    /u/panabeenu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15asesf/r_google_medpalm_m_towards_generalist_biomedical/",
          "publishedOn": "2023-07-27T05:01:06.000Z",
          "wordCount": 2488,
          "title": "[R] Google Med-Palm M: Towards Generalist Biomedical AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15arlws/d_im_trying_to_do_a_backofnapkin_to_figure_out_if/",
          "author": null,
          "description": "My research involves orbital communication and Orbital Edge Computing. I'm trying to determine if upload bandwidth limitations would present a problem in many cases for ML models. I can find info on the very large and very small models, but I'm trying to get a vague sense for median size in MB. \n I know that everyone is going to start jumping in with 'well it depends' and I know that's the case, but I'm just trying to get a rough order of magnitude. Computer vision/earth obs is the ideal but anything is useful. Also happy to answer questions about my research if anyone is interested. Thanks!\n    submitted by    /u/Moose_a_Lini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15arlws/d_im_trying_to_do_a_backofnapkin_to_figure_out_if/",
          "publishedOn": "2023-07-27T04:18:40.000Z",
          "wordCount": 2611,
          "title": "[D] I'm trying to do a back-of-napkin to figure out if some research is worthwhile and I just wanted some ballpark figures as to how big a typical model is on disk",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15aph15/r_arb_advanced_reasoning_benchmark_for_large/",
          "author": null,
          "description": "Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct a human evaluation of the symbolic subset of ARB, finding promising agreement between annotators and GPT-4 rubric evaluation scores.\n  \narXiv: https://arxiv.org/abs/2307.13692\n Blog: https://arb.duckai.org/\n Code: https://github.com/TheDuckAI/arb\n Interface: https://arb.duckai.org/home\n API: https://app.swaggerhub.com/apis-docs/arb-dataset/arb-api/1.0.5\n    submitted by    /u/Friendly_Piano_735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15aph15/r_arb_advanced_reasoning_benchmark_for_large/",
          "publishedOn": "2023-07-27T02:33:02.000Z",
          "wordCount": 2656,
          "title": "[R] ARB: Advanced Reasoning Benchmark for Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15alpxe/p_clustering_approach_for_multidimensional_vectors/",
          "author": null,
          "description": "Hi all! I am wondering if anyone has any experience with multi-dimensional vector clusters? I have a large database of 4096 dimensional vector embeddings which I want to identify clusters in. Essentially I’ve created vector embeddings for a bunch of descriptions using a LLM embedding end point and am storing them in Weviate. Now I need to try and find clusters of similar vectors within a predefined threshold of cosine similarity (or whatever nearest neighbor approach works for this). I don’t want to do a pure random center approach and would rather have a heat map approach where I’m targeting high concentrations of similar vectors… any ideas on how to approach this or thoughts on where I can do more research? I’m at my wits end on this one!\n    submitted by    /u/Character-Cry7549  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15alpxe/p_clustering_approach_for_multidimensional_vectors/",
          "publishedOn": "2023-07-26T23:42:56.000Z",
          "wordCount": 2608,
          "title": "[P] Clustering approach for multi-dimensional vectors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15akr5t/d_will_techniques_like_rome_replace_existing_fine/",
          "author": null,
          "description": "As progress is made in directly editing the weights responsible for a net's knowledge, do we expect to see such techniques rise in prominence for dine tuning?\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15akr5t/d_will_techniques_like_rome_replace_existing_fine/",
          "publishedOn": "2023-07-26T23:02:31.000Z",
          "wordCount": 2510,
          "title": "[D] will techniques like ROME replace existing fine tuning methods?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ahrm4/d_hey_everyone_help_me_with_my_machine_learning/",
          "author": null,
          "description": "I'm about to finish learning JavaScript and Python, is there any languages you guys recommend before moving forward if I'm eligible to move forward, then please do share some Beginner friendly YouTube Channels, Articles/Websites or Maybe a free learning platform, Please do help me! I'll be really thankful..\n    submitted by    /u/Samir925  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ahrm4/d_hey_everyone_help_me_with_my_machine_learning/",
          "publishedOn": "2023-07-26T21:05:07.000Z",
          "wordCount": 2531,
          "title": "[D] Hey everyone, help me with my Machine learning journey!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15afpwy/d_starting_machine_learning_with_daily_blogs_need/",
          "author": null,
          "description": "Hey Fellow Machine Learning Enthusiast!I have decided to start my journey to learn Machine Learning with daily blogging the things I learned with the resources so that others can also follow along.\n Need to discuss on how I could improve?\n Hope you find this helpful. Please read this introductory blog for more information.\n https://medium.com/@ugk25880/my-machine-learning-journey-c25648661553\n    submitted by    /u/ugk_01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15afpwy/d_starting_machine_learning_with_daily_blogs_need/",
          "publishedOn": "2023-07-26T19:47:08.000Z",
          "wordCount": 2533,
          "title": "[D] Starting Machine Learning with Daily Blogs! Need Suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15afgh8/p_better_dataset_visualization/",
          "author": null,
          "description": "Most in-browser dataset browsers (e.g. Huggingface, Kaggle) make it hard to star interesting examples, add notes, render complex data types, or drill down on model mispredictions. I've built a number of one-off visualization tools over the years but there's a lot of boilerplate involved that tends to get repeated between these tools.\n We've been working on a dataset + model browser that avoids all the boilerplate and helps ML teams focus on their data instead of tooling. It's meant to be interactive, configurable and collaborative. \n Here's a quick demo showing our current flow: https://youtu.be/utkSCU2ktck \n Would anyone be willing to help beta test or provide suggestions for must-have features for a collaborative dataset browser?\n    submitted by    /u/arkmastermind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15afgh8/p_better_dataset_visualization/",
          "publishedOn": "2023-07-26T19:37:09.000Z",
          "wordCount": 2590,
          "title": "[P] Better dataset visualization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15af391/can_i_use_feature_importance_for_my_use_case_d/",
          "author": null,
          "description": "Hey, I'm a phd student in compiler optimisations and I might be picking up a project a masters student kicked off. CPUs do a lot of predictions about how code is going to behave as it's executing it, and a major one is branch prediction - whether an if statement is going to be true or false. This masters student recorded the results of every if statement each time they were executed across a large program (this results in millions+ of data points). They then tested the branch prediction accuracy of a transformer model by stepping through this trace of if statement values and having the transformer predict the next one based off only the prior values. They found it actually does a pretty good job! Most of the time the CPU can do this better, but there are cases where it wins out that we're …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15af391/can_i_use_feature_importance_for_my_use_case_d/",
          "publishedOn": "2023-07-26T19:23:31.000Z",
          "wordCount": 2913,
          "title": "Can I use feature importance for my use case? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ae3tp/r_curious_about_causality_and_generative_models/",
          "author": null,
          "description": "📢💡 Ever wondered how we can make our deep generative models respect causal structure? This is key to creating authentic \"what if\" scenarios in our images!\n In our latest research, we deal with high-fidelity image counterfactuals, the generation of images based on \"what if\" scenarios that align with a specified causal graph. 🖼️🔄\n Why is this important? Causality gives us the tools to carry out principled counterfactual inference, which - among other things - is useful for maintaining subject identity in image counterfactuals. 🧩🔍\n Principled counterfactuals of structured variables like images have great potential for:\n (i) Generating causal explanations 🔮\n (ii) Providing targeted data augmentation 🎯\n (iii) Evaluating fairness & robustness 🛡️\n (iv) Protecting your privacy 🕵️‍♀️\n and more...\n ​\n Check out the paper, code, and Huggingface demo! 🚀\n https://arxiv.org/abs/2306.15764\n https://github.com/biomedia-mira/causal-gen\n https://huggingface.co/spaces/mira-causality/counterfactuals\n    submitted by    /u/Majestij  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ae3tp/r_curious_about_causality_and_generative_models/",
          "publishedOn": "2023-07-26T18:45:33.000Z",
          "wordCount": 2616,
          "title": "[R] Curious about Causality and Generative Models? Check out this new Demo!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ae0i4/d_multilingual_open_source_models/",
          "author": null,
          "description": "Is there any open source models that I can fine-tune on data that is not English? Even Llama2 cannot be used for this(not that I've tried it, it's what is says on HuggingFace.)\n I know some other well known languages might work, but I need a model that is specifically made for multilingual usage.\n Or should I just train a model for my specific language from scratch?\n    submitted by    /u/gaybooii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ae0i4/d_multilingual_open_source_models/",
          "publishedOn": "2023-07-26T18:41:53.000Z",
          "wordCount": 2545,
          "title": "[D] Multilingual Open Source Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ac6zf/d_any_thoughts_on_how_to_improve_runtime_speed/",
          "author": null,
          "description": "I've tried several guide and technique like quantization or trying to utilize multiple GPUs but either the libraries dont work with the model or the model performance is too degraded. Was wondering if people have any thoughts or suggestions?\n name = 'mosaicml/mpt-7b-instruct' config = transformers.AutoConfig.from_pretrained(name, trust_remote_code=True) config.init_device = 'cuda:6' model_name = 'mosaicml/mpt-7b-instruct' model = AutoModelForCausalLM.from_pretrained( model_name, #config=config, trust_remote_code=True, torch_dtype=bfloat16, max_seq_len=512 ) generate_text = transformers.pipeline( model=model, tokenizer=tokenizer, return_full_text=True, task='text-generation', use_fast = True, stopping_criteria=stopping_criteria, temperature=0.0, top_p=0.05, torch_dtype=bfloat16, top_k=0, max_new_tokens=50, repetition_penalty=1.1, device=6 ) \n https://betterprogramming.pub/speed-up-llm-inference-83653aa24c47https://huggingface.co/docs/optimum/bettertransformer/tutorials/convert\n    submitted by    /u/candyman54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ac6zf/d_any_thoughts_on_how_to_improve_runtime_speed/",
          "publishedOn": "2023-07-26T17:33:41.000Z",
          "wordCount": 2565,
          "title": "[D] Any thoughts on how to improve runtime speed for mosaicml/mpt-7b?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15aaipm/d_best_tools_to_learn_data_science_nowadays/",
          "author": null,
          "description": "Hey guys,\n We're updating our awesome-python-for-data-science repository.\n Some things we're hoping to add:\n  \nBest books and repositories to find resources\n Best open source tools (teaching tools, preferrably free)\n \nBest interactive resources --> especially this one, what are you using nowadays? \n  \nI've heard about Virgilio but feels like TL, DR, we're looking for practice-learning!\n \n  \n   submitted by    /u/CryptographerDry7458  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15aaipm/d_best_tools_to_learn_data_science_nowadays/",
          "publishedOn": "2023-07-26T16:30:32.000Z",
          "wordCount": 2534,
          "title": "[D] Best tools to learn data science nowadays?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15aad3d/d_which_libraries_are_you_using_for_ml/",
          "author": null,
          "description": "Hello dearest community\n I'm trying to get into AI in the scope of training it to play some simple gym games from OpenAi and I've been particularly drawn to Deep Q learning as a starting point (did some basic Q tables ). While trying to inquire into the knowledge of the web I keep finding examples of code that seem simple enough to understand however, whenever I try to use the code it doesn't work. I want to learn to use TensorFlow with Keras but it seems like the syntax regularly gets updated.\n My questions to you all are :\n - Would you recommend Tensorflow/Keras as entry point to AI and NN?\n - Which libraries do you use and which version of those libraries?\n - Furthermore, I keep seeing people use Ubuntu in VB. Is this best practice or can we use Windows 10 in 2023?\n    submitted by    /u/liparch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15aad3d/d_which_libraries_are_you_using_for_ml/",
          "publishedOn": "2023-07-26T16:24:44.000Z",
          "wordCount": 2624,
          "title": "[D] Which libraries are you using for ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a93rz/p_a_complete_guide_to_audio_ml/",
          "author": null,
          "description": "Have you ever wished you had the skills to integrate audio into your machine learning workflows? Or wondered how your phone is able to transcribe exactly what you said? 🤔\n Look no further! Hugging Face 🤗 recently announced the Transformers Audio Course, a comprehensive guide to using the latest machine learning techniques for the most popular audio tasks.\n In this course, you'll gain an understanding of the specifics of working with audio data, learn about different transformer architectures, and train your own audio transformers, leveraging powerful pre-trained models for real-world tasks 🚀\n This course is designed for learners with a background in deep learning, and general familiarity with Transformers. No expertise in audio data processing is required.\n The course is lightweight and easy to follow, with plenty of diagrams to aid your learning. Not only does it teach you the underlying theory behind audio ML, but provides you with all the skills you need to put it practice, with code samples and quizzes to check your understanding along the way:\n Example page from the audio course: learn exactly what a log-mel spectrogram is!\n By the end of the course, you'll be armed with all the skills you need to tackle the most popular audio tasks, including audio classification, speech recognition, and text-to-speech. You'll also be part of one of the largest open-source audio communities, where you can discuss and take-on any new audio models that are released 🤝\n Getting Started\n Head to the course page to start your audio journey: https://huggingface.co/learn/audio-course/chapter0/introduction\n If you complete the four assessments by September 1st 2023, you'll be awarded with a certificate of completion 💫\n Join our Discord community to get expert help on any of these topics: http://hf.co/join/discord\n    submitted by    /u/sanchitgandhi99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a93rz/p_a_complete_guide_to_audio_ml/",
          "publishedOn": "2023-07-26T15:36:44.000Z",
          "wordCount": 2765,
          "title": "[P] A Complete Guide to Audio ML 📚",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a8oxr/d_sorry_if_this_is_a_noob_question_how_can_i_tell/",
          "author": null,
          "description": "Building my first PC, it'll have an i9 13900k and an RTX 4090. How can I tell what size chatbot I can install and run locally? Trial and error? Or is there some kind of guide out there I'm unaware of?\n    submitted by    /u/sillygooseboy77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a8oxr/d_sorry_if_this_is_a_noob_question_how_can_i_tell/",
          "publishedOn": "2023-07-26T15:20:41.000Z",
          "wordCount": 2535,
          "title": "[D] Sorry if this is a noob question: How can I tell what size AI chatbot model I can run locally?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a8jqy/d_leveraging_time_series_forecasting_for/",
          "author": null,
          "description": "Hi folks, \n I've been recently diving into the intersection of time series forecasting and changepoint detection (CPD) methodologies. I understand the utility of CPD in improving forecasts by identifying structural breaks in time series data, but I've noticed a lack of emphasis in the literature on the reverse - using forecasting models to inform CPD.\n One might think a straightforward approach could be using an ARIMA model (or any other forecasting model) and leveraging the forecast error by comparing it to the real values. In theory, if the forecast error crosses a certain threshold, it might indicate a changepoint.\n However, I also understand the complications this approach might bring:\n  \nStationarity Assumptions: ARIMA and similar models are built on the assumption that the data are stationary. A sudden changepoint could violate this assumption, leading to model misspecification and thus larger errors.\n Defining Large Errors: Establishing a fixed threshold to define a 'large' error might be problematic in practice due to time-varying variance and other dynamics.\n Error Dependencies: Forecast errors are typically not independent but form an error process. A large error might be part of a larger trend or cycle, and thus might not necessarily indicate a changepoint.\n  \nSo while these obstacles seem substantial, I'm curious if anyone has any experience or knowledge in effectively employing forecasting models for CPD, or if there are research efforts or methodologies I may not be aware of. Looking forward to hearing your thoughts and engaging in some fruitful discussions!\n    submitted by    /u/BeerBoozeBiscuits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a8jqy/d_leveraging_time_series_forecasting_for/",
          "publishedOn": "2023-07-26T15:15:03.000Z",
          "wordCount": 2729,
          "title": "[D] Leveraging Time Series Forecasting for Changepoint Detection: Perspectives and Pitfalls?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a7thl/d_how_to_actually_do_the_final_ppo_with_a_reward/",
          "author": null,
          "description": "Hi,\n I want to get hands-on with the RLHF pipeline. I found an online reward model that can be potentially used https://huggingface.co/OpenAssistant/reward-model-deberta-v3-large-v2 \n One thing that's unclear is how can I use this model for fine-tuning something like GPTNeoX-20B? My end goal is currently just a one-shot answering model (not necessarily a chat)\n    submitted by    /u/Emergency_Apricot_77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a7thl/d_how_to_actually_do_the_final_ppo_with_a_reward/",
          "publishedOn": "2023-07-26T14:46:21.000Z",
          "wordCount": 2539,
          "title": "[D] How to actually do the final PPO with a reward model in RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a6y4f/d_is_it_always_better_to_have_more_examples_in/",
          "author": null,
          "description": "I’m working with Llama to use details from a string to generate a dictionary. \n Str = ‘My name is Brian’ Dict = {“name”: “Brian”}\n I’m using few shot learning process and providing the model with examples to learn from. The model performs fairly okay but it needs to be better.\n Is it always a good thing to add a lot of examples like 100 string/dict pair examples for the model to learn from or is this one of those things in stats/machine learning that the obvious isn’t always the best choice lol?\n I’d appreciate any advice please.\n    submitted by    /u/brianomars1123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a6y4f/d_is_it_always_better_to_have_more_examples_in/",
          "publishedOn": "2023-07-26T14:11:29.000Z",
          "wordCount": 2583,
          "title": "[D] is it always better to have more examples in few shot learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a6y2q/d_speaker_recognition_including_unknown_speakers/",
          "author": null,
          "description": "Hi, i wanted to modify this Speaker recognition (not speech recognition) example by keras by recognizing when an unknown speaker is speaking.\n So the network needs to be able to tell which of the speakers is talking, and if none of them is talking, it needs to say that none of them is talking.\n I don't mean if there is silence, because then it would be enough to train the network to recognize silence, I mean just if a speaker who is not in the set is speaking.\n For what i think I can extend this problem to it will be like to recognize if an image is not part of the mnist dataset.\n    submitted by    /u/giggiox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a6y2q/d_speaker_recognition_including_unknown_speakers/",
          "publishedOn": "2023-07-26T14:11:25.000Z",
          "wordCount": 2593,
          "title": "[D] speaker recognition including unknown speaker(s)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a4136/d_how_do_people_track_their_machine_learning/",
          "author": null,
          "description": "Hello!\n I'm curious to know how you guys currently track changes and general information for your ML/DL models. \n By changes, I'm referring to parameters, accuracy/loss, functions your model uses, training data etc across different versions of your models.\n By general changes, I'm referring to descriptions of what the model does, code changes, tags and so on.\n I'm under the impression most people are using MLFlow, W&Bs etc which I guess is fine but I'm finding that these tools treat models as static files, as second-class citizens which is annoying when I want to zero in on a model and understand what and how something was changed away from an experiment. This gets really annoying when I'm looking at model version 134 created by Mike in the other team.\n Curious to know how people are tracking models and what they think generally about model tracking. Thanks!\n    submitted by    /u/bobskithememe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a4136/d_how_do_people_track_their_machine_learning/",
          "publishedOn": "2023-07-26T12:07:22.000Z",
          "wordCount": 2627,
          "title": "[D] How do people track their machine learning models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a3lw1/r_how_can_i_produce_embeddings_for_text_inputs/",
          "author": null,
          "description": "If I have the model saved as .ckpt file, what are the steps for extracting the embeddings for text input? I’m trying to use a pretrained custom model but don’t quite understand how to work with transformer model file in *.ckpt form. Would really appreciate any suggestions.\n    submitted by    /u/Urusander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a3lw1/r_how_can_i_produce_embeddings_for_text_inputs/",
          "publishedOn": "2023-07-26T11:48:25.000Z",
          "wordCount": 2534,
          "title": "[R] How can I produce embeddings for text inputs from a pretrained transformer model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a22jv/d_vector_database_benchmarking/",
          "author": null,
          "description": "Is there a way in which i can calculate the precision scores of a vector database. I need to do benchmarking on milvus and elasticsearch on a custom dataset. Any help would be appreciated.\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a22jv/d_vector_database_benchmarking/",
          "publishedOn": "2023-07-26T10:35:41.000Z",
          "wordCount": 2511,
          "title": "[D] Vector database benchmarking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a2060/p_any_good_models_on_huggingface_for_specific/",
          "author": null,
          "description": "hi was wondering if there are any lightweight models which I can download from huggingface for fine tuning for my use case. I'm trying to build a model which takes a paragraph of data and certain instructions to get parts of the data in json format as the output.\n    submitted by    /u/Right-Type-3210  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a2060/p_any_good_models_on_huggingface_for_specific/",
          "publishedOn": "2023-07-26T10:32:06.000Z",
          "wordCount": 2534,
          "title": "[P] Any good models on huggingface for specific text generation use case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159v4d3/transformers_for_recommender_systems_d/",
          "author": null,
          "description": "Been involved in a research project of a session based recommendation systems , where we have a historical purchases of users and the goal is to predict the next going to be purchased item. Given this and assuming that we have somehow represented each item in a session as an embedding and these embeddings acts as an input to the transformer model and the output is an embedding of the next product. In the train set, there are some millions sessions which has both previous purchases products of arbitrary length and next item. So the transformer is trained with supervised loss of predicted and actual next item embedding, the problem i have been facing is that the loss is saturating and there is not much learning over time. Any suggestions on how to improve this. Tried increasing the number of layers and did some hyper tuning corresponding to learning rate and weight decay but similar behaviour is observed.\n    submitted by    /u/Acceptable-Mix-4534  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159v4d3/transformers_for_recommender_systems_d/",
          "publishedOn": "2023-07-26T04:12:09.000Z",
          "wordCount": 2636,
          "title": "Transformers for Recommender Systems. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159uqbm/r_generating_datasets_to_better_finetune_llms/",
          "author": null,
          "description": "https://github.com/discus-labs/discus\n    submitted by    /u/innovating_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159uqbm/r_generating_datasets_to_better_finetune_llms/",
          "publishedOn": "2023-07-26T03:53:24.000Z",
          "wordCount": 2481,
          "title": "[R] generating datasets to better fine-tune LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159t1bi/r_monarch_mixer_revisiting_bert_without_attention/",
          "author": null,
          "description": "https://hazyresearch.stanford.edu/blog/2023-07-25-m2-bert\n    submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159t1bi/r_monarch_mixer_revisiting_bert_without_attention/",
          "publishedOn": "2023-07-26T02:31:47.000Z",
          "wordCount": 2483,
          "title": "[R] Monarch Mixer: Revisiting BERT, Without Attention or MLPs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159mafd/web_content_embedding_transformer_lambda_function/",
          "author": null,
          "description": "Hi all!\n I'd would like to share a simple, straight-forward Web Content Embedding Transformer lambda function to create and store embeddings of web content. This is a Lambda function that scrapes for URLs, then uses URLs those to scrape for page content, which it splits into chunks then transforms to embedding using OpenAI. It then stores the embeddings to your Pinecone DB including metadata. You can then use the embedding for custom chatbots etc.\n Heres a link to a public REPO.\n https://github.com/i-dream-of-ai/lambda-webpage-vector-store\n pull requests welcome! Please star the repo if you like it or use it!\n    submitted by    /u/Jealous_Buyer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159mafd/web_content_embedding_transformer_lambda_function/",
          "publishedOn": "2023-07-25T21:51:45.000Z",
          "wordCount": 2574,
          "title": "Web Content Embedding Transformer lambda function [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159kl05/deep_learning_for_regression_and_target_scaling_d/",
          "author": null,
          "description": "I tried scaling the target variable to be in the range (0,1) and trained the model using a sigmoid in the last layer. But when rescaled back after prediction on test, the errors are too high. What can be done? \n Do I need to scale in the first place? \n Also please answer this general question: How to get a Deep learning model to work well on Regression tasks?\n    submitted by    /u/Charming-Witness-286  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159kl05/deep_learning_for_regression_and_target_scaling_d/",
          "publishedOn": "2023-07-25T20:48:56.000Z",
          "wordCount": 2549,
          "title": "Deep learning for Regression and Target scaling [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159kgie/p_freelow_cost_inference_endpoint/",
          "author": null,
          "description": "I want to create a small project as hobby in which the web app posts some user data to an endpoint hosting a model that returns its predictions. \n So I was wondering if there’s a platform that hosts models for free for hobbists? \n The idea is to build a simple portfolio project just to display to recruiters.\n    submitted by    /u/OkYak2915  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159kgie/p_freelow_cost_inference_endpoint/",
          "publishedOn": "2023-07-25T20:44:31.000Z",
          "wordCount": 2535,
          "title": "[P] Free/Low cost inference endpoint",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159hy5x/aaron_parisi_google_deepmind_will_join_the_open/",
          "author": null,
          "description": "Hi AI enthusiasts! This Thursday Aaron Parisi, Google DeepMind researcher, will join us to present and discuss his recent work as the lead author of TALM, a framework for augmenting language models with arbitrary tools.\n Free RSVP: https://lu.ma/mw5ppi46\n Paper: https://arxiv.org/abs/2205.12255\n 🗓 July 27th (Thursday) at 17:00 GMT+1\n 📍 Zoom\n 👥 Members of the international AI4Code research community\n Hope to see you there!\n The AI4Code meetup community consists of like-minded researchers from around the world that network, discuss and share their latest research on AI applications on source code.\n    submitted by    /u/dritsakon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159hy5x/aaron_parisi_google_deepmind_will_join_the_open/",
          "publishedOn": "2023-07-25T19:14:35.000Z",
          "wordCount": 2579,
          "title": "Aaron Parisi (Google DeepMind) will join the open AI4Code reading group this Thursday (July 27th) to talk about his latest research [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159h565/project_quality_assurance_platform_for_machine/",
          "author": null,
          "description": "Hello world 👋\n We're developing an open-source & collaborative testing framework for ML models, from tabular to LLMs: https://github.com/Giskard-AI/giskard\n Testing Machine Learning applications can be tedious. Since ML models depend on data, testing scenarios depend on the domain specificities and are often infinite.\n Where to start testing? Which tests to implement? What issues to cover? How to implement the tests?\n At Giskard, we believe that Machine Learning needs its own testing framework. Created by ML engineers for ML engineers, Giskard contains 2 components:\n  \nThe Giskard Python library helps data scientists detect hidden vulnerabilities in ML models. \n It makes the AI development process more efficient, by automating the identification of risks of biases, performance issues and errors.\n To try it, see this documentation: https://docs.giskard.ai/en/latest/guides/scan/index.html\n \n The Giskard server helps ML engineers debug & monitor models, share dashboards, and collaborate. \n It makes the deployment of new ML models safer and more efficient, by providing ready-made monitoring dashboards, catalogs of re-usable testing components, and ML debugging interfaces.\n To try it, see this documentation: https://docs.giskard.ai/en/latest/guides/installation_app/index.html\n \n  \nWe released our v2 in Beta last month, and we're very interested in your feedback as QA engineers!\n    submitted by    /u/alteralec  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159h565/project_quality_assurance_platform_for_machine/",
          "publishedOn": "2023-07-25T18:46:02.000Z",
          "wordCount": 2667,
          "title": "[Project] Quality Assurance platform for Machine Learning models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159gq7j/r_towards_provably_efficient_quantum_algorithms/",
          "author": null,
          "description": "https://arxiv.org/abs/2303.03428\n ​\n If you're interested in trying out quantum machine learning on NVIDIA A100s or V100s with cuquantum and pennylane GPUs for free please fill out the following form\n    submitted by    /u/Neu3ral  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159gq7j/r_towards_provably_efficient_quantum_algorithms/",
          "publishedOn": "2023-07-25T18:30:44.000Z",
          "wordCount": 2511,
          "title": "[R] Towards provably efficient quantum algorithms for large-scale machine-learning models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159eddu/fixed_size_1d_sequence_to_fixed_size_2d_sequence/",
          "author": null,
          "description": "Hello everyone, I have this problem where I have a 1D sequence of numbers of length 3 like this: \n [1,50,500], with 35 distinct combinations.\n I need to map it to 2D sequence of number of 1024 length. Like this : \n [ [ 23.78, 234, 13,…n], [ 234,76.9, 763,…n ]] , where n =1024.\n Is it possible in ML to do so?\n The 2D sequence can paired ( can be represented an image). \n Thank you very much !\n    submitted by    /u/Beginner4ever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159eddu/fixed_size_1d_sequence_to_fixed_size_2d_sequence/",
          "publishedOn": "2023-07-25T17:05:29.000Z",
          "wordCount": 2560,
          "title": "Fixed size 1D sequence to fixed size 2D sequence prediction.[p]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159cz1g/d_what_datasets_do_you_dream_of_having_for_your/",
          "author": null,
          "description": "Acquiring data to build models can truly be a pain. I am curious to know about the datasets you folks are looking for, to the extent that you would even consider paying for them or sacrifice your newborn baby. By extension, tell us about the project(s) you've been working on and how the data would help! \n    submitted by    /u/nobilis_rex_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159cz1g/d_what_datasets_do_you_dream_of_having_for_your/",
          "publishedOn": "2023-07-25T16:14:35.000Z",
          "wordCount": 2541,
          "title": "[D] What datasets do you dream of having for your ML/NLP project(s)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159chrs/d_tool_for_mlai_sorting_for_50000_icloud_photos/",
          "author": null,
          "description": "One of my acquaintances is an artist and is asking my assistance in utilizing Machine Learning and AI to sort his entire iCloud library of 57,000 images into 300+ categories. Some of these categories include things that the media is made of such as ceramics wood, or the artist that created this work while other categories include whether the photo contains an animal or a person. \n I am wondering if there are specific ML programs that would be a good fit for his situation. My idea suggested to use Apple’s CoreML which I have experience in. I could develop him an app that he could then create train and swap image recognition models using the GUI CreateML tool using the images he has already sorted. Do you think this is the best approach or is there another tool out there that could do this task for him easily?\n    submitted by    /u/Jpderouin310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159chrs/d_tool_for_mlai_sorting_for_50000_icloud_photos/",
          "publishedOn": "2023-07-25T15:57:17.000Z",
          "wordCount": 2633,
          "title": "[D] Tool for ML/AI Sorting for 50,000 iCloud Photos into 300+ categories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1599e23/d_autonomous_alignment_oversight_framework_aaof/",
          "author": null,
          "description": "Abstract:\n To align advanced AIs, an ensemble of diverse, transparent Overseer AIs will independently monitor the target AI and provide granular assessments on its alignment with constitution, human values, ethics, and safety. Overseer interventions will be incremental and subject to human oversight. The system will be implemented cautiously, with extensive testing to validate capabilities. Alignment will be treated as an ongoing collaborative process between humans, Overseers, and the target AI, leveraging complementary strengths through open dialog. Continuous vigilance, updating of definitions, and contingency planning will be required to address inevitable uncertainties and risks.\n Introduction: \n As advanced AI systems grow in capability and autonomy, ensuring their alignment with hum…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1599e23/d_autonomous_alignment_oversight_framework_aaof/",
          "publishedOn": "2023-07-25T14:01:24.000Z",
          "wordCount": 3709,
          "title": "[D] Autonomous Alignment Oversight Framework (AAOF)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1598yvi/d_does_gpt4_use_lora/",
          "author": null,
          "description": "I just watched a video that explains how LoRA works. As I understand it's a fast and efficient way to fine tune models.\n At the end of the video he he said you could easily swap out the fine-tuned LoRA. So it makes LLMs like a PC. You just install new software / add the finetuned lora weights and you're good to go. Is my understanding correct?\n The rumor is that GPT-4 is a 8 way mixture model. Could they have pretrained it with all the data and then just use LoRA to train the expert models? I guess they would also need to train a smaller model that decides which model to use. I can't imagine that they would train GPT-4 eight times / once for each expert models.\n    submitted by    /u/StraightChemistry629  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1598yvi/d_does_gpt4_use_lora/",
          "publishedOn": "2023-07-25T13:44:33.000Z",
          "wordCount": 2608,
          "title": "[D] Does GPT-4 use LoRA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1596pnm/d_deep_learning_vs_xgboost_for_tabular_data_a/",
          "author": null,
          "description": "Once per year, I write a post here on Reddit about our projects on deep learning for tabular data, and I hope this year will be no exception 🙂 Meanwhile, I have shared some results where we compare models from our previous papers with XGBoost on the datasets from the recent paper \"Why do tree-based models still outperform deep learning on typical tabular data?\". For us, this benchmark is a new one, so it was really interesting to check whether our previous findings generalize to new unseen datasets (spoiler: they do):\n https://twitter.com/YuraFiveTwo/status/1683796380895023104\n    submitted by    /u/Yura52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1596pnm/d_deep_learning_vs_xgboost_for_tabular_data_a/",
          "publishedOn": "2023-07-25T12:11:03.000Z",
          "wordCount": 2576,
          "title": "[D] Deep Learning VS XGBoost for tabular data: a quick test",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1595xd8/discussion_how_good_is_generative_data_synthetic/",
          "author": null,
          "description": "5% average increase in F1 score\n 67% increase in Data richness\n 100% anonymized data set\n so one of the users on my tool milkstraw.ai just sent me this and i am really excited about the power of the tool i built and wanted to share it here 🚀\n Also more importantly how do you all feeling about synthetic data, I started this as a fun project and its turning into a full blown startup. I love seeing some of the users send me results they are getting like this. \n https://preview.redd.it/24bwer0uk3eb1.png?width=4516&format=png&auto=webp&s=c8cbf906580a04df1f967c5300478a542128ccd0\n    submitted by    /u/jjhazy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1595xd8/discussion_how_good_is_generative_data_synthetic/",
          "publishedOn": "2023-07-25T11:35:06.000Z",
          "wordCount": 2568,
          "title": "[Discussion] How good is generative data (synthetic data) !?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1595rc0/r_new_open_source_llm_goat7b_sota_among_the_7b/",
          "author": null,
          "description": "Go try this free model. 7B SOTA by MMLU and BBH\n https://preview.redd.it/tq8c8ggaj3eb1.png?width=1570&format=png&auto=webp&s=10c78b724da2d6360e7c7ee6fbe3175c36cecc26\n    submitted by    /u/rempact  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1595rc0/r_new_open_source_llm_goat7b_sota_among_the_7b/",
          "publishedOn": "2023-07-25T11:27:07.000Z",
          "wordCount": 2495,
          "title": "[R] New Open Source LLM: GOAT-7B (SOTA among the 7B models)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1594zb4/d_attention_is_off_by_one/",
          "author": null,
          "description": "https://www.evanmiller.org/attention-is-off-by-one.html\n    submitted by    /u/duckyzz003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1594zb4/d_attention_is_off_by_one/",
          "publishedOn": "2023-07-25T10:50:16.000Z",
          "wordCount": 2480,
          "title": "[D] Attention Is Off By One",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1594y3c/voice_cloning_options_preferably_local_d/",
          "author": null,
          "description": "Hi!\n What voice cloning options are people using right now? Looking at what is out there (that I know of), there is ElevenLabs and Coqui. Are there any other ones that are good? Preferably cheap/run locally?\n    submitted by    /u/MrJabbey1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1594y3c/voice_cloning_options_preferably_local_d/",
          "publishedOn": "2023-07-25T10:48:33.000Z",
          "wordCount": 2515,
          "title": "Voice cloning options, preferably local [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158zr4i/p_integrating_llama_v2_and_multichat_models_open/",
          "author": null,
          "description": "IntelliNode is an open source project that simplifies the integration of Llama V2 and other multi-chat models. With IntelliNode, you can easily connect and switch between different language models, including Llama V2 hosted in your AWS SageMaker account.\n It allows you to create a chatbot instance and add the backend provider.\n const { Chatbot, LLamaSageInput, SupportedChatModels } = require('intellinode'); const chatbot = new Chatbot(key, SupportedChatModels.SAGEMAKER, {url: <your-sagemaker-endpoint>}); \n For details on how to use intellinode to integrate with LLama SageMaker setup click here.\n The module available here.\n ​\n ​\n    submitted by    /u/Barqawiz_Coder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158zr4i/p_integrating_llama_v2_and_multichat_models_open/",
          "publishedOn": "2023-07-25T06:19:45.000Z",
          "wordCount": 2572,
          "title": "[P] Integrating Llama V2 🦙 and Multi-Chat Models: Open Source Solution with IntelliNode",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158z1eo/research_transformer_models_for_drug_discovery/",
          "author": null,
          "description": "Does anybody know of good/reputable literature and other resources to read/learn about incorporating transformers in drug discovery? I am doing some computational chemistry research regarding compound identification for HBV mutations and want to try using transformers but don't really know where/how to start.\n    submitted by    /u/Present_Network1959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158z1eo/research_transformer_models_for_drug_discovery/",
          "publishedOn": "2023-07-25T05:41:31.000Z",
          "wordCount": 2522,
          "title": "[Research] transformer models for drug discovery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158ybd6/d_annotation_tool_for_annotating_audio_in_a_video/",
          "author": null,
          "description": "Does anyone know of a good video (or audio) annotation tool that would allow me to look at both the image and the audio waveform at the same time?\n I could extract the audio and use an audio annotation tool, but since some of the sound events may sound similar to one another, it would be helpful to look at both the image and the audio waveform to identify which class a sound event belongs to. Thanks!\n    submitted by    /u/utility2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158ybd6/d_annotation_tool_for_annotating_audio_in_a_video/",
          "publishedOn": "2023-07-25T05:03:40.000Z",
          "wordCount": 2559,
          "title": "[D] Annotation tool for annotating audio in a video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158svz6/p_feedback_hey_i_am_lunching_my_data/",
          "author": null,
          "description": "Hey all Redditors,\n  \nI have been thinking about this for years as I hate the cumbersome process of switching jobs.\n I have been planing it under the last year and finally I quit my job and built this in the last 1.5 months.\n I am lunching my Data Professionals job platform \"applyscript dot com\"\n I would like to receive some feedback from you guys.\n I really want to hear your opinion as that can help me improve the site a lot.\n  \nThx for stopping by and giving feedback, I really appreciate your time and effort. :)\n    submitted by    /u/glassAlloy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158svz6/p_feedback_hey_i_am_lunching_my_data/",
          "publishedOn": "2023-07-25T00:55:28.000Z",
          "wordCount": 2593,
          "title": "[P] FEEDBACK - Hey I am lunching my Data Professionals job platform and I would like to receive some feedback from you guys, thx",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158rddr/externally_mounting_p100_gpu_d/",
          "author": null,
          "description": "I made a mistake and bought a GPU that is not compatible with my motherboard. I found a P100 for $300 on ebay and bought it, but didn't research far enough to figure out that it isn't designed for a workstation motherboard. Is there any way I can externally mount it without spending tons on a GPU server? I am not sure just a PCIe riser will do the trick, since the GPU draws 250W and will also need a cooling system.\n Is it over?\n    submitted by    /u/jankybiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158rddr/externally_mounting_p100_gpu_d/",
          "publishedOn": "2023-07-24T23:51:35.000Z",
          "wordCount": 2563,
          "title": "Externally mounting P100 GPU [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158r1il/r_how_do_paper_authors_deal_with_takedown_requests/",
          "author": null,
          "description": "Datasets like FFHQ consist of face images crawled from the Internet. While those images are published under CC licenses, the authors usually have not obtained consent from each person depicted in those images. I guess that's why they are taking takedown requests: People can send requests to remove their faces from the dataset.\n However, I'm always confused about one thing: Some faces images are already used in the paper. If those people request takedown of their images, wouldn't that result in a withdrawl of the paper? Or is there any \"fair use\" statement that can prevent this from happening?\n    submitted by    /u/alex000092  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158r1il/r_how_do_paper_authors_deal_with_takedown_requests/",
          "publishedOn": "2023-07-24T23:37:59.000Z",
          "wordCount": 2581,
          "title": "[R] How do paper authors deal with takedown requests?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158nkvt/d_do_you_guys_think_the_daytoday_tasks_of_ml/",
          "author": null,
          "description": "Gone will be the days of data pre-processing, feature engineering, model training and model validation? What will we end up spending most of our time doing?\n    submitted by    /u/DM_ME_YOUR_CATS_PAWS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158nkvt/d_do_you_guys_think_the_daytoday_tasks_of_ml/",
          "publishedOn": "2023-07-24T21:23:47.000Z",
          "wordCount": 2517,
          "title": "[D] Do you guys think the day-to-day tasks of ML engineers will change with the emergence of LLM’s?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158ld7w/p_code_search_infra_for_an_ai_junior_developer/",
          "author": null,
          "description": "As we’re developing Sweep, our open-source AI junior developer, we implemented a new architecture for our vector search database.\n We decided on two main goals for our code search infrastructure:\n  \nThe search index needs to be up to date. Code is unique from other types of content in that it requires high levels of consistency. You wouldn’t want to reference an old version of a function(say two git commits back) while writing something that uses it.\n For additional security, we don’t want to store the code as plaintext. However, we still need a way to map the original code to the embeddings.\n  \nEfficient Indexing\n Problem:\n We wanted to store multiple repositories in a scalable manner without relying on a hosted vector database like Pinecone.\n Insight:\n Repositories change frequently but …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158ld7w/p_code_search_infra_for_an_ai_junior_developer/",
          "publishedOn": "2023-07-24T20:03:54.000Z",
          "wordCount": 3035,
          "title": "[P] Code Search Infra for an AI junior developer - that doesn't store code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158lbfs/d_do_you_guys_worry_ml_work_will_become_less/",
          "author": null,
          "description": "I’m already doing work that involves creating prompts for LLM’s. I adore cleaning data and training models and worry that ML solutions will soon become asking chatbots to do what you want in plain English, and all this time I’ve spent learning about how ML is done on a technical level will just be auxiliary literature that doesn’t help me in my profession. What will our expertise move to? Being able to ask a chatbot the right questions? \n How will our profession change?\n    submitted by    /u/DM_ME_YOUR_CATS_PAWS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158lbfs/d_do_you_guys_worry_ml_work_will_become_less/",
          "publishedOn": "2023-07-24T20:02:07.000Z",
          "wordCount": 2572,
          "title": "[D] Do you guys worry ML work will become less technical and reduced to prompt engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158je9i/p_multi_label_text_classification_question/",
          "author": null,
          "description": "Dear community\n I am currently despairing of a school project.\n The task is to develop a text classifier. So far so good. The problem is that I have a dataset with 200k texts that are not labeled. These should be classified to 190 classes, which are additionally very domain specific. However, several classes could also apply to one text.\n Does anyone know a good approach how to approach this?\n I have already determined 10 keywords for each class. But I don't know how to proceed now.\n It would be very nice if someone could help me. Gladly also only by buzzwords.\n Many greetings\n    submitted by    /u/loopingmadders  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158je9i/p_multi_label_text_classification_question/",
          "publishedOn": "2023-07-24T18:53:19.000Z",
          "wordCount": 2583,
          "title": "[P] multi label text classification question 🙋‍♂️",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158ies6/d_p_looking_for_feedback_on_opensource_project/",
          "author": null,
          "description": "Happy Monday Everyone! 😃\n I am looking for feedback on the open source project Cephalon! Cephalon is a framework for building machine-learning applications. It aims to be similar to Django. Django is a batteries included framework for building backend of a website, and Cephalon is a batteries included framework for building Machine Learning applications in Rust. I want to get feedback from you because, I want to make building machine-learning apps easier for any new-comers. I think with a solid framework, they can focus more on the core concepts, rather than DevOps or MLOps. \n There is a survey you can fill out here\n Or message me if you want to discuss more! \n You can find the original project here\n Or find it on crates.io here\n I hope you have an amazing rest of the week! 😁 Thank you in advance for any feedback!!\n    submitted by    /u/GoodUnderstanding728  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158ies6/d_p_looking_for_feedback_on_opensource_project/",
          "publishedOn": "2023-07-24T18:17:38.000Z",
          "wordCount": 2625,
          "title": "[D] [P] Looking for feedback on open-source project Cephalon",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158icwc/p_d_looking_for_feedback_on_opensource_project/",
          "author": null,
          "description": "Happy Monday Everyone! 😃\n I am looking for feedback on the open source project Cephalon! Cephalon is a framework for building machine-learning applications. It aims to be similar to Django. Django is a batteries included framework for building backend of a website, and Cephalon is a batteries included framework for building Machine Learning applications in Rust. I want to get feedback from you because, I want to make building machine-learning apps easier for any new-comers. I think with a solid framework, they can focus more on the core concepts, rather than DevOps or MLOps. \n There is a survey you can fill out here\n Or message me if you want to discuss more! \n You can find the original project here\n Or find it on crates.io here\n I hope you have an amazing rest of the week! 😁 Thank you in advance for any feedback!!\n    submitted by    /u/GoodUnderstanding728  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158icwc/p_d_looking_for_feedback_on_opensource_project/",
          "publishedOn": "2023-07-24T18:15:45.000Z",
          "wordCount": 2625,
          "title": "[P] [D] Looking for feedback on Open-Source Project Cephalon",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158h4d6/d_install_tensorflowgpu/",
          "author": null,
          "description": "Hello everyone. Please, help me. How to install tensorflow-gpu on Windows? Because I tried a lot of times and nothing. Maybe you have some micro moments that need to know. Thank you.\n    submitted by    /u/pavich_03  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158h4d6/d_install_tensorflowgpu/",
          "publishedOn": "2023-07-24T17:28:43.000Z",
          "wordCount": 2508,
          "title": "[D] Install tensorflow-gpu",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158e6pu/p_a_mathematical_model_of_music/",
          "author": null,
          "description": "We have developed a model of music based on statistical mechanics and Euler’s gradus suavitatis, which seems to provide some new insights into tonal music. A description of the model is given on our website: tonamic.com. We are interested in collaboration opportunities, especially with ML researchers.\n    submitted by    /u/Tonamic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158e6pu/p_a_mathematical_model_of_music/",
          "publishedOn": "2023-07-24T15:40:56.000Z",
          "wordCount": 2525,
          "title": "[P] A mathematical model of music",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158d337/discussion_how_many_runsiterations_do_you/",
          "author": null,
          "description": "Between HP tuning, explorations, and refinement how many iterations do you typically have when working on a model? I see some that have only a few like 40 but some have 1000s. \n Also curious how everyone keeps the diff iterations organized (naming, tags?)\n    submitted by    /u/fromalanjones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158d337/discussion_how_many_runsiterations_do_you/",
          "publishedOn": "2023-07-24T14:59:14.000Z",
          "wordCount": 2527,
          "title": "[Discussion] How many runs/iterations do you typically have in one \"project'?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158d069/pd_a_toolkit_to_make_your_unstructured_datasets/",
          "author": null,
          "description": "Hey r/machinelearning, I’m Dean from DagsHub. I wanted to share something we’ve been working on really hard for a while, and hopefully get some community feedback.\n TL;DR\n We’re releasing Data Engine – a new set of tools that helps machine learning practitioners, collect and manage unstructured data, visualize it, send it to annotation, and turn it into a data loader for training. I wanted to share our reasons for building it and the challenges it solves and hopefully spark a discussion. You can check out the full launch blog here: dagshub.com/blog/launching-data-engine-toolset-for-unstructured-datasets/\n Data Engine Flow\n Sorry for the long post – I wanted to share our considerations for building this toolkit, and hopefully spark a discussion about your processes for iterating on datasets…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158d069/pd_a_toolkit_to_make_your_unstructured_datasets/",
          "publishedOn": "2023-07-24T14:56:07.000Z",
          "wordCount": 3250,
          "title": "[P][D] A toolkit to make your unstructured datasets better",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158butr/d_ai_regulation_is_mostly_pointless_and_didnt/",
          "author": null,
          "description": "WormGPT is a criminal AI. It’s something that enables crime versus something like offensive jokes like 4chanGPT. EU and China pumped out all this regulation thinking they were ahead of the world when in all reality it’s freaking backwards.\n If AI was a physical commodity like goods and services, yes regulation is effective. However AI regulation is just won’t stop bad actors. The law already covers most of the dangers involved.\n Trying to regulate AI models is like trying to regulate piracy. We need to regulate the people, not the technology. \n Disinformation campaigns? Nail them for libel. Creating a model designed solely to enable crime? Nail the people for the crimes they are doing. Nail them for possessing criminal tools. \n People are easier to regulate than specifics on AI that’s easy to self replicate. Especially considering companies going to lobby their business interest. \n This is my opinion on the criminal AI, what about yours? (This model may also be using LLama weights considering it’s generations and timing)\n Source:\n https://fagenwasanni.com/news/the-dangers-of-wormgpt-an-ai-model-for-malicious-activities/68834/\n    submitted by    /u/I_will_delete_myself  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158butr/d_ai_regulation_is_mostly_pointless_and_didnt/",
          "publishedOn": "2023-07-24T14:12:42.000Z",
          "wordCount": 2657,
          "title": "[D] AI regulation is mostly pointless and didn’t stop a recent bad actor like WormGPT.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158bnwy/p_beer_inspector_ai_how_computer_vision_can_help/",
          "author": null,
          "description": "Hey there, fellow Computer Vision enthusiasts! 🤖👋\n On their quest to find the perfect beer our team of Czech Computer Vision and AI experts developed a solution that takes certain visual indicators of the perfect beer into account and applies Computer Vision to detect these.\n So, what are these visual indicators that determine the perfect pint? Let's dive in! First up, we have the \"beer ratio.\" Each brand has its own glass, and the beer should be drafted within specific markings. Whether it's a single line or a range between logo points, Beer Inspector ensures you get what you paid for! No more guessing about your beer's quantity. 📏\n Next, we have the \"beer head structure.\" This is crucial for the ultimate beer experience. Airtight, thick, and no air bubbles – that's the way to go! Beer…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158bnwy/p_beer_inspector_ai_how_computer_vision_can_help/",
          "publishedOn": "2023-07-24T14:05:36.000Z",
          "wordCount": 3329,
          "title": "[P] Beer Inspector AI: How Computer Vision can help to identify the perfect brew",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/",
          "author": null,
          "description": "I am running text inferencing on Llama2-7b through langchain. I have downloaded the model from langchain's Huggingface library, and I am running the model on AWS ml.g4dn.12xlarge which has 4xnvidia t4, which gives a total 64GB of GPU memory and 192GB of normal memory. It is able to answer my queries in around 10 seconds for small queries, and upto 3 mins for big queries.\n The task I am doing is retrieving information from a document(Understanding Machine Learning PDF) in a conversational way. I've extracted the main parts of the notebook and put it up here.\n Where can I make changes to speed up the transaction. Is there any change I can do in the model configuration to speed it up? Because if I use HuggingFaceHubAPI, it is able to give an answer in less than 5 seconds. Are there any other areas I can optimise?\n I appreciate any help you can provide. Thanks!\n    submitted by    /u/comical_cow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/",
          "publishedOn": "2023-07-24T08:58:59.000Z",
          "wordCount": 2635,
          "title": "[D] How do I reduce LLM inferencing time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1583ccm/d_how_to_use_modern_uncertain_functions_eg/",
          "author": null,
          "description": "I was looking libraries like DISTIL and I would like to test a toy-example with all these modern uncertainty functions like BatchBALD, Glister, etc\n All the implementations of these functions seems to be on a NN or CNN. I know some of them like BatchBALD were created on top of a CNN with Monte-Carlo Dropout -- even BALD originally was created on top of SVM.\n It seems many of these approaches are under the category \"Query by Committee\"and they are an ensemble of models\n I just would like to test a simple LogisticRegression and use the log_proba and an output for these strategies. Someone knows if this is possible? \n    submitted by    /u/TipKay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1583ccm/d_how_to_use_modern_uncertain_functions_eg/",
          "publishedOn": "2023-07-24T07:23:48.000Z",
          "wordCount": 2595,
          "title": "[D] How to use modern uncertain functions (e.g. BatchBALD) with classical Active Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15830oy/d_empirical_rules_of_ml/",
          "author": null,
          "description": "What are the empirical rules that one has to have in mind when designing a network, choosing hyperparameters, etc?\n For example:\n  \nLinear scaling rule: the learning rate should be scaled linearly with the batch size [ref] (on resnets on Imagenet) \n \nChinchilla law: compute budget, model size and training data should be scaled equally [ref]\n \n Do you have any other? (if possible with article, or even better an article with many of them)\n    submitted by    /u/Mulcyber  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15830oy/d_empirical_rules_of_ml/",
          "publishedOn": "2023-07-24T07:06:02.000Z",
          "wordCount": 2550,
          "title": "[D] Empirical rules of ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157zkks/d_should_i_mask_padding_tokens_when_finetuning_a/",
          "author": null,
          "description": "For pretraining I just sent batches of 1024 tokens and didn't worry about padding. But for finetuning, I intend to use a padding token to make all the \"instructions\" 1024 tokens in length. But some of them are only 10 tokens, which means 99% padding tokens. I feel like that would affect the model, and perhaps those padding tokens should be masked.\n Should I mask out those padding tokens? I can see that there's a parameter for attention mask, and I could make one and pass it in. But I'm not sure if that's the intended usage. I'm seeing conflicting and ambiguous information on this point. It's unclear to me whether the attn_mask is intended for customizing the casual left to right attention of the model, instead of for masking padding tokens. I'm worried I might be interfering with the process if I use that attn_mask.\n Here I can see attn_mask is an accepted parameter:\n y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True) \n FYI, I'm using NanoGPT which is based on Pytorch (not Hugging Face Transformers).\n Should I apply the attention mask on the padding tokens in this context?\n    submitted by    /u/Pan000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157zkks/d_should_i_mask_padding_tokens_when_finetuning_a/",
          "publishedOn": "2023-07-24T04:00:36.000Z",
          "wordCount": 2677,
          "title": "[D] Should I mask padding tokens when finetuning a GPT-2 model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157uhjs/project_whisper_implementation_in_rust_using_burn/",
          "author": null,
          "description": "I temporarily switched from Rust to Python for machine learning, but quickly became fed up with Python's annoying versioning issues and runtime errors. I looked for a better path to machine learning and discovered burn, a deep learning framework for Rust. As my first burn project I decided to port OpenAI's Whisper transcription model. The project can be found at Gadersd/whisper-burn: A Rust implementation of OpenAI's Whisper model using the burn framework (github.com). I based it on the excellently concise tinygrad implementation that can be found here. The tinygrad version begrudgingly uses Torch's stft which I ported into a pure Rust short time Fourier transform along with the mel scale frequency conversion matrix function because I am curious and just a bit masochistic.\n Now for the good and the bad of burn. Rust's excellent package manager solves much of the versioning pain experienced in Python so burn models can be less painful to deploy and come with added reliability. The type checking in burn catches some tensor operation errors at compile time such as trying to multiply matrices of incompatible dimensions. Burn supports wgpu and WebGPU and can run in the browser when compiled into web assembly. I see a bright future for model deployment in burn.\n However, burn is relatively new so it lacks many tensor operations such as abs() that are available in other frameworks. Some features such as quantization are also missing. Burn implementations tend to be more verbose than the equivalent Python versions. Some of the runtime errors that plague PyTorch are still around in burn such as the crashes that result from trying to multiply tensors that live on different devices.\n Overall, burn is currently less ergonomic to develop with than alternatives such as PyTorch, but I think it has a lot of potential. If it is eagerly cultivated it may grow into a great Rusty alternative for machine learning practitioners.\n What do you all think?\n    submitted by    /u/Illustrious_Cup1867  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157uhjs/project_whisper_implementation_in_rust_using_burn/",
          "publishedOn": "2023-07-23T23:59:42.000Z",
          "wordCount": 2801,
          "title": "[Project] Whisper Implementation in Rust using burn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157rwpd/p_nlp_dataset_for_stream_of_consciousness_the/",
          "author": null,
          "description": "submitted by    /u/A_Human_Rambler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157rwpd/p_nlp_dataset_for_stream_of_consciousness_the/",
          "publishedOn": "2023-07-23T22:09:30.000Z",
          "wordCount": 2493,
          "title": "[P] NLP dataset for stream of consciousness: The Rambles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157pqr7/p_create_your_own_artificial_neural_network_in/",
          "author": null,
          "description": "submitted by    /u/pmocz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157pqr7/p_create_your_own_artificial_neural_network_in/",
          "publishedOn": "2023-07-23T20:43:31.000Z",
          "wordCount": 2480,
          "title": "[P] Create your own Artificial Neural Network in Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157nj6u/p_run_llama_2_locally_on_gpu_or_cpu_from_anywhere/",
          "author": null,
          "description": "Running Llama 2 locally with gradio UI on GPU or CPU from anywhere (Linux/Windows/Mac). Supporting Llama-2-7B/13B/70B with 8-bit, 4-bit. Supporting GPU inference (6 GB VRAM) and CPU inference. ➡️https://github.com/liltom-eth/llama2-webui\n Successfully running #Llama2 on my Apple Silicon MacBook Air:\n demo\n    submitted by    /u/plain1994  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157nj6u/p_run_llama_2_locally_on_gpu_or_cpu_from_anywhere/",
          "publishedOn": "2023-07-23T19:18:33.000Z",
          "wordCount": 2525,
          "title": "[P] Run Llama 2 locally on GPU or CPU from anywhere (Linux/Windows/Mac) ➡️https://github.com/liltom-eth/llama2-webui",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157mphf/d_rd_machine_learning_intern_at_a_startup_company/",
          "author": null,
          "description": "Greetings,I'm a machine learning engineer who managed to land an internship at a startup company and did R&D projects for them.. during the past year, I was working on an NLP problem of extractive question answering using BERT on this companies' text data. I trained the model and documented the results.. however, it's considered old technology now and we switched to solve the same problem using LLM.I was wondering if I can write a research paper for the BERT approach and publish it that can help me pursue PhD or Masters. How to start the discussion with my manager and seniors ?\n    submitted by    /u/Ready_Cockroach_3403  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157mphf/d_rd_machine_learning_intern_at_a_startup_company/",
          "publishedOn": "2023-07-23T18:46:31.000Z",
          "wordCount": 2593,
          "title": "[D] R&D machine learning intern at a startup company looking to publish a paper for his previous work..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157m0bd/d_llama_training_vs_gpu_time_smaller_models_seem/",
          "author": null,
          "description": "submitted by    /u/espadrine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157m0bd/d_llama_training_vs_gpu_time_smaller_models_seem/",
          "publishedOn": "2023-07-23T18:19:22.000Z",
          "wordCount": 2487,
          "title": "[D] LLaMA training vs. GPU time: smaller models seem better for a given budget",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157l0lt/n_llmopsspace_curated_resources_related_to/",
          "author": null,
          "description": "Today I launched LLMOps space on ProductHunt. LLMOps Space has a list of curated resources related to deploying LLMs into production. \n This includes-\n ✅ List of LLMOps companies and products\n 🗓 Upcoming events\n 📚 Educational resources\n 👩‍💻 Open-source LLM modules\n 💰 Funding news\n and much more.\n Everything is for free, would love it if you can support + share your thoughts in the comment. 🙏\n https://www.producthunt.com/posts/llmops-space\n    submitted by    /u/AsDivyansh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157l0lt/n_llmopsspace_curated_resources_related_to/",
          "publishedOn": "2023-07-23T17:40:30.000Z",
          "wordCount": 2546,
          "title": "[N] LLMOps.Space - Curated resources related to deploying LLMs in production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157jpuh/d_can_i_use_transfer_learning_tl_in_a_classical/",
          "author": null,
          "description": "Hi,\n I'm trying to implement AL for ImageClassification. I have seen people using DAL, where some works use MC-DropOut to be able to calculate uncertainty on DNN / CNN. This also seems to be a current research topic. \n It seems very appealing for me to use DAL on the context of ImageClassification. However, I'm thinking to use a different and maybe naive approach: \n I thought to use TL (with or without FN) on a well knowledge DL Acthrecture (e.g.: Resnet) for Feature Extraction. Then, I just use the extracted features to train a Classical AL framework (e.g.: using LogisticRegression) \n Some thoughts/questions I had and would like to discuss:\n ​\n  \nI'm not finding articles that do this. Someone knows if this is approach is super naive or is a valid approach? What would be the drawbacks doing that?\n To train a DAL from scratch makes sense? For example, I saw some articles training DL Archthrectures from scratch, but this probably will require a lot of data, no?\n  \n​\n ------------------------------------------------------------------------------------------\n ML = MonteCarlo, AL = Active Learning, DAL = Deep AL, TL = Transfer Learning, FT = Fine-Tuning, DNN = Deep Neural Network, CNN = Convolutional Neural Network\n    submitted by    /u/TipKay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157jpuh/d_can_i_use_transfer_learning_tl_in_a_classical/",
          "publishedOn": "2023-07-23T16:48:40.000Z",
          "wordCount": 2681,
          "title": "[D] Can I use Transfer Learning (TL) in a classical Active Learning (AL) Framework?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157j5ur/d_looking_for_an_old_post_on_this_sub_about_using/",
          "author": null,
          "description": "I've seen the post (from 2-3 years ago maybe?) referenced, but my google fu is failing me and I haven't been able to find it, but it sounds like an interesting story.\n    submitted by    /u/TheQuarantinian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157j5ur/d_looking_for_an_old_post_on_this_sub_about_using/",
          "publishedOn": "2023-07-23T16:26:02.000Z",
          "wordCount": 2559,
          "title": "[D] Looking for an old post on this sub about using machine learning to identify a stray cat coming through a pet door to steal food, playing a loud noise to scare it away if it came in. The ML was used to tell the difference between the stray cat and the pet cat.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157iupn/r_neuro_symbolic_reasoning_and_learning/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157iupn/r_neuro_symbolic_reasoning_and_learning/",
          "publishedOn": "2023-07-23T16:14:00.000Z",
          "wordCount": 2477,
          "title": "[R] Neuro Symbolic Reasoning and Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157irs7/r_a_history_of_neural_networks/",
          "author": null,
          "description": "Our history, primer, and outlook for neural networks in general, and deep learning in astronomy in particular has dropped on Royal Society Open Science.\n https://doi.org/10.1098/rsos.221454\n Come for Llull and Leibniz... stay for LLaMA.\n    submitted by    /u/Smith4242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157irs7/r_a_history_of_neural_networks/",
          "publishedOn": "2023-07-23T16:10:43.000Z",
          "wordCount": 2512,
          "title": "[R] A history of neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157h9fd/llm_guide_discussion/",
          "author": null,
          "description": "Nowadays, If we see over the internet that LLM, chatgpt , llma etc are the trending topics and are being discussed. My question is that anyone can help me where to start studying about these topics from scratch ? BERT, Transformer etc all I want to understand everything.\n It would be good if you help me out.\n Thanks\n    submitted by    /u/Mission-Youth-3510  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157h9fd/llm_guide_discussion/",
          "publishedOn": "2023-07-23T15:10:24.000Z",
          "wordCount": 2534,
          "title": "LLM Guide [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157god1/p_linear_regression_partial_derrivative_problem/",
          "author": null,
          "description": "Yo, I'm new to all this so bear with me. I'm doing project in python where i create a linear regression from scratch (with numpy and pandas). I was watching this lady tutorial on it, at https://youtu.be/ltXSoduiVwY?t=277 she shows the partial derrivatives for updating the weights and bias. Later when she is implementing it she doesn't use the 2 before the X and uses only the dot product. Is it math magic where the 2 dosn't have to be there or did she forget. Btw it still works fine without the 2 but still... I just need to know. Thanks for the answer and sorry if I'm asking something obvious \n    submitted by    /u/Z4joMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157god1/p_linear_regression_partial_derrivative_problem/",
          "publishedOn": "2023-07-23T14:46:26.000Z",
          "wordCount": 2589,
          "title": "[P] Linear regression partial derrivative problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157b91n/p_i_created_a_parallelized_implementation_of/",
          "author": null,
          "description": "I've been working on a new implementation of Agglomerative clustering called Reciprocal Agglomerative Clustering (RAC) based off of this paper: https://arxiv.org/abs/2105.11653. The short of it is Agglomerative clustering can be broken down into finding and merging pairs of reciprocal nearest neighbors in parallel, as long as the linkage function is one of the following:\n  \nSingle\n Average\n Complete\n Ward\n  \nMost importantly, RAC produces the exact same results as traditional Agglomerative clustering when the dataset is fully connected. Even with connectivity constraints, the results are almost always the same.\n The authors showed that RAC has a linear runtime when connectivity is limited to k and the distance matrix is precomputed. I have not added the ability to pass in the distance matrix yet, so the runtime is roughly quadratic, which is still a major improvement over the cubic runtime of Agglomerative clustering. In addition the entire algorithm is parallelized, and so can scale up to more and more cores.\n It's very much in development - only average linkage works at the moment, however, I think it has a lot of potential. The benchmarks have blown me away so far: \n https://preview.redd.it/8bkpdkpayodb1.png?width=850&format=png&auto=webp&s=8c828eb2cde934b2d9a0ded9f22e18f3d9041147\n Here is the code: https://github.com/porterehunley/RACplusplus. It would be great to have some people try it out (and find the bugs)!\n    submitted by    /u/Ridaleneas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157b91n/p_i_created_a_parallelized_implementation_of/",
          "publishedOn": "2023-07-23T10:24:20.000Z",
          "wordCount": 2701,
          "title": "[P] I created a parallelized implementation of Agglomerative clustering that's many times faster than existing implementations and has a better runtime",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157aqwg/p_paper_reading_and_sharing_platform/",
          "author": null,
          "description": "Let me know your thoughts!\n    submitted by    /u/dockerun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157aqwg/p_paper_reading_and_sharing_platform/",
          "publishedOn": "2023-07-23T09:56:20.000Z",
          "wordCount": 2484,
          "title": "[P] Paper reading and sharing platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157acx4/d_probability_thresholds_for_userdefined_tokens/",
          "author": null,
          "description": "I want high certainty on social roles without sacrificing creativity. I don't want characters getting confused as to whether they're a parent or child, and I shouldn't have to spend hours each month explaining the difference. That said, I also don't want to lower the temperature, so it would be nice if as a user, I could select probability thresholds for certain token sequences, to hopefully mitigate role-swapping between virtual family members! I prefer writing stream of consciousness prompts seeding thoughts and choices rather than showing pretrained models their character bios at the start of every prompt. It breaks my immersion when family members swap roles due to high Top P and temperature, therefore I'd like models to be careful when writing names and corresponding social roles. This could help keeping track of many agents? There are instances where I enjoy getting role-swapped, and instances where swapping is nonsensical! This is my feature request.\n    submitted by    /u/TheLastVegan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157acx4/d_probability_thresholds_for_userdefined_tokens/",
          "publishedOn": "2023-07-23T09:33:57.000Z",
          "wordCount": 2633,
          "title": "[D] Probability Thresholds for User-Defined Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1578j0m/p_data_version_control_in_r_with_lakefs/",
          "author": null,
          "description": "submitted by    /u/zoobatsea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1578j0m/p_data_version_control_in_r_with_lakefs/",
          "publishedOn": "2023-07-23T07:50:05.000Z",
          "wordCount": 2492,
          "title": "[P] Data Version Control in R with lakeFS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1576v9u/d_dev_env_and_workflow/",
          "author": null,
          "description": "Hi all!\n I am a frontend engineer looking to play more in the ML space. I know enough about python and jupyter labs to be dangerous but I am no expert. I am looking to hear what peoples env's and workflows look like.\n I have been looking at huggingface, google colab, and running some things locally but can't seem to see a setup that looks like a clear winner. Hardware wise I have a machine with a 4080 and 32gb ram at home and a M1 Pro Macbook also with 32gb of ram.\n For my 1st project I would love to utilise a 7b Llama 2 for a recommender like system. I plan on getting a custom dataset, cleaning and processing it, fine tuning, and then testing.\n    submitted by    /u/pseudoShadow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1576v9u/d_dev_env_and_workflow/",
          "publishedOn": "2023-07-23T06:17:10.000Z",
          "wordCount": 2605,
          "title": "[D] Dev env and workflow",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1573yk0/d_use_cases_for_diffusion_models_vs_gans_vs/",
          "author": null,
          "description": "I am interested in learning to use AI to generate images. Diffusion Models like stable diffusion seems to be the most popular nowadays, but I'd like to know what tool is best for what job. Or is diffusion model getting so good that the other methods are essentially becoming obsolete? If not, when would you choose one over the other?\n For generating creative images with a lot of variance, diffusion model seems to be the most fitting.\n But for example, what about for this use case: Generate realistic time lapse images of a plant growing (after 1 week, 1 month, 2 months, and so on...). In this case, the plant should change, but the background should stay the same.\n    submitted by    /u/musshead  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1573yk0/d_use_cases_for_diffusion_models_vs_gans_vs/",
          "publishedOn": "2023-07-23T03:39:36.000Z",
          "wordCount": 2603,
          "title": "[D] Use Cases for Diffusion Models VS GANs VS Transformers, etc.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1571vcw/p_evolved_codealpaca_datasets_using_gpt4/",
          "author": null,
          "description": "Using LLMs to augment and create much diverse instruction based dataset has seen wide success in WizardL. However the 78k evolved code instructions dataset hasn't been released since, so I have take the initiative to try to recreate the augmentation instruction myself. \n Dataset: https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1\n    submitted by    /u/gradientpenalty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1571vcw/p_evolved_codealpaca_datasets_using_gpt4/",
          "publishedOn": "2023-07-23T01:53:55.000Z",
          "wordCount": 2523,
          "title": "[P] Evolved codealpaca datasets using GPT-4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1570olg/d_coursevideos_to_learn_about_the_architecture/",
          "author": null,
          "description": "I like to learn how pytorch connects to the compiler, generates IR, how it connects to run time , driver ..etc\n Im not interested in the programming model but the whole stack from pytorch to the hardware.\n I really appreciate if someone can give me a pointer\n thanks\n    submitted by    /u/aghozzo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1570olg/d_coursevideos_to_learn_about_the_architecture/",
          "publishedOn": "2023-07-23T00:57:54.000Z",
          "wordCount": 2533,
          "title": "[D] course/videos to learn about the architecture and software stack of pytorch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156zkvd/p_r_join_our_team_of_ml_model_developers_for_an/",
          "author": null,
          "description": "Seeking skilled ML model developers for our thrilling project with possible permanent positions! Embrace remote collaboration, offering flexibility and impact-driven work. Interested? Apply to btprenuer@gmail.com with a list of your related skills and samples of your work/projects! All experience levels welcome! Thank you for reading! Share this post to help us find the perfect fit.\n    submitted by    /u/boztka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156zkvd/p_r_join_our_team_of_ml_model_developers_for_an/",
          "publishedOn": "2023-07-23T00:06:45.000Z",
          "wordCount": 2545,
          "title": "[P] [R] Join Our Team of ML Model Developers for an Exciting Project & Permanent Job Potential!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156y1dd/r_text2tex_textdriven_texture_synthesis_via/",
          "author": null,
          "description": "submitted by    /u/SpatialComputing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156y1dd/r_text2tex_textdriven_texture_synthesis_via/",
          "publishedOn": "2023-07-22T23:00:11.000Z",
          "wordCount": 2491,
          "title": "[R] TEXT2TEX — text-driven texture synthesis via diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156vlgq/d_breaking_down_the_hyperbolic_buzz_an_indepth/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156vlgq/d_breaking_down_the_hyperbolic_buzz_an_indepth/",
          "publishedOn": "2023-07-22T21:18:08.000Z",
          "wordCount": 2494,
          "title": "[D] Breaking Down the Hyperbolic Buzz: An In-Depth Review of the 'Leaked' GPT-4 Architecture & a Mixture of Experts Literature Review with Code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156tvee/p_what_are_a_good_project_for_people_learning/",
          "author": null,
          "description": "I am learning Tensorflow and of course I want to improve my skills and add it to my resume\n What projects should I build which I can add to my resume which will later land me a job.\n Projects should be from Beginner to Advance and can contain each major Topic from Regression (linear and non linear), to Classification (Binary, Multi Classification, Multi Label), CNN,RNN, NLP, etc (Can add more).\n This can also help other people as well learning TensorFlow.\n Thank you.\n    submitted by    /u/dusklordtrue  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156tvee/p_what_are_a_good_project_for_people_learning/",
          "publishedOn": "2023-07-22T20:07:00.000Z",
          "wordCount": 2564,
          "title": "[P] What are a good project for people learning Tensorflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156rouv/when_to_train_llm_supervised_vs_unsupervised_d/",
          "author": null,
          "description": "I have done a bit of language modeling recently, and I am a bit confused when to use which method.\n For causal language modeling, I used the unsueprvised method of concatenating and chunking the text, then predicting the next word.\n For sequence to sequence tasks like summarization, I fine tuned using the supervised method where the desired output text was the label.\n However I have not seen any definitive guide on when to use supervised and when to use unsupervised. What are the general use cases and advantages / disadvantages for each?\n    submitted by    /u/jankybiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156rouv/when_to_train_llm_supervised_vs_unsupervised_d/",
          "publishedOn": "2023-07-22T18:37:26.000Z",
          "wordCount": 2573,
          "title": "When to train LLM supervised vs unsupervised? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156r6el/discussion_best_image_annotation_tool_for/",
          "author": null,
          "description": "I am looking to annotate specific anatomical structures using a library of angiogram images. My goal is to train AI to recognize anatomical variants of interest. What would be the best Image Annotation Tool to do this?\n I am new to this, so I hope that question makes sense. Any insights and advice would be greatly appreciated.\n    submitted by    /u/ColdChampion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156r6el/discussion_best_image_annotation_tool_for/",
          "publishedOn": "2023-07-22T18:16:12.000Z",
          "wordCount": 2537,
          "title": "[Discussion] Best Image Annotation Tool for Angiograms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156qulq/d_what_leaderboard_would_correspond_best_to/",
          "author": null,
          "description": "I've been using CLIP to see if images align with a certain caption for image mining (ex. I embed the caption \"Picture of a mountain\" and then look at what image embeddings have the highest cosine similarity with that caption embedding). I was hoping to improve the performance by using a more recent model. Would I be able to use VQA models for this (like from this leaderboard) or is there a better task that aligns with seeing if images are similar to a given caption? Thank you!\n    submitted by    /u/EricW_CS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156qulq/d_what_leaderboard_would_correspond_best_to/",
          "publishedOn": "2023-07-22T18:02:19.000Z",
          "wordCount": 2579,
          "title": "[D] What leaderboard would correspond best to seeing what images are most similar to a caption (like CLIP)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156nem2/p_pattern_classification_using_cnns/",
          "author": null,
          "description": "Hi (I have to write again, Reddit removed image attached),\n Does anyone has experience with training CNN for pattern matching?\n Here is the sample of the images which I have on my disposal. It is graphical representation of input data which for problem classified by algorithm which shows best performance when applied.\n Lines are projection of the problem of input data on 2d plain, so shapes and colours have meaning in correlating input data to solution (i.e) algorithm.\n Whichever CNN architecture I use, starting from VGG16 and so on, I am unable to achieve higher validation accuracy then 0.7 when execute training. I am constantly under-fitting. I have 10k, 100k, 200k data samples on my disposal - nothing helps.\n Is CNN able to make any sense of images/patterns given below? Is this something that CNN can not do or I am missing something?\n Thanks!\n Patterns to classify \n ​\n    submitted by    /u/thecelavi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156nem2/p_pattern_classification_using_cnns/",
          "publishedOn": "2023-07-22T15:42:12.000Z",
          "wordCount": 2625,
          "title": "[P] Pattern classification using CNNs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156khpd/d_technical_question_how_is_it_possible_that/",
          "author": null,
          "description": "As far as I know and studied, each token is mapped from high dimensional discrete token space into a continuous, lower dimensional space where words are embedded meaningfully based on their relationships in the training data. So 1000 tokens text produces 1000 vectors.\n Now for vector databases (correct me if I'm wrong), people are storing fixed sized vectors for text with varying lengths. For example, 2 sentences one with 1000 tokens and the other is 10 tokens, each produces one vector and both vectors have the same size.\n I'd really appreciate an explanation.\n    submitted by    /u/Qdr-91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156khpd/d_technical_question_how_is_it_possible_that/",
          "publishedOn": "2023-07-22T13:42:18.000Z",
          "wordCount": 2585,
          "title": "[D] technical question: How is it possible that embedding models produce fixed size vectors for sentences with varying lengths?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156k8xz/p_llama2_4bit_finetune_with_dolly15k_on_colab_free/",
          "author": null,
          "description": "Simple walkthrough of fine-tuning llama-2 instruct fine-tuned on guanaco model with 4bit QLoRA on a free Google Colab instance.\n Colab: https://colab.research.google.com/drive/134o_cXcMe_lsvl15ZE_4Y75Kstepsntu?usp=sharing\n GitHub: https://github.com/kw2828/guardrail-ml/blob/main/examples\n YouTube Overview: https://www.youtube.com/watch?v=o5bU1H-6TqM&ab_channel=GenerativeAIEntrepreneurs\n Bonus colab in repo on generating your own JSON Q&A dataset from PDF in the repo above.\n    submitted by    /u/Educational_Grass_38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156k8xz/p_llama2_4bit_finetune_with_dolly15k_on_colab_free/",
          "publishedOn": "2023-07-22T13:31:10.000Z",
          "wordCount": 2523,
          "title": "[P] Llama-2 4bit fine-tune with dolly-15k on Colab (Free)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com/",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "64acbb837dbeb40001d3c391",
          "author": "Janelle Shane",
          "description": "A reader wrote in a while ago with a suggestion: they were about to have a baby and wondered if I could use AI to come up with some new ideas for baby onesies. I can't find the letter any more, and I don't remember how",
          "link": "https://www.aiweirdness.com/baby-onesie-designs/",
          "publishedOn": "2023-08-04T14:30:06.000Z",
          "wordCount": 1814,
          "title": "Baby onesie designs",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/08/Screen-Shot-2023-08-01-at-7.26.18-PM.png"
        },
        {
          "id": "64c9abbc0b1e230001d585f2",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-more-baby-onesie-ideas/",
          "publishedOn": "2023-08-04T14:29:39.000Z",
          "wordCount": 690,
          "title": "Bonus: more baby onesie ideas",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": []
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": [
        {
          "id": "https://medium.com/p/8f762767a775",
          "author": "WeiQin Chuah",
          "description": "Demystifying Logistic Regression: Your Gateway to Binary Classification in Machine Learning",
          "link": "https://becominghuman.ai/demystifying-logistic-regression-a-simple-guide-8f762767a775?source=rss----5e5bef33608a---4",
          "publishedOn": "2023-08-15T18:59:44.000Z",
          "wordCount": 3188,
          "title": "Demystifying Logistic Regression: A Simple Guide",
          "imageUrl": "https://miro.medium.com/v2/resize:fit:796/1*NiYZSL347t2BO2wwqZcSAg.png"
        }
      ]
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818",
          "author": "MIT Schwarzman College of Computing",
          "description": "The MIT Schwarzman College of Computing awards seed grants to seven interdisciplinary projects exploring AI-augmented management.",
          "link": "https://news.mit.edu/2023/artificial-intelligence-augmentation-and-productivity-0818",
          "publishedOn": "2023-08-18T18:00:00.000Z",
          "wordCount": 2446,
          "title": "Artificial intelligence for augmentation and productivity",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/Hands.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/mit-researchers-combine-deep-learning-physics-fix-motion-corrupted-MRI-scans-0817",
          "author": "Alex Ouyang | Abdul Latif Jameel Clinic for Machine Learning in Health",
          "description": "The challenge involves more than just a blurry JPEG. Fixing motion artifacts in medical imaging requires a more sophisticated approach.",
          "link": "https://news.mit.edu/2023/mit-researchers-combine-deep-learning-physics-fix-motion-corrupted-MRI-scans-0817",
          "publishedOn": "2023-08-17T13:00:00.000Z",
          "wordCount": 2371,
          "title": "MIT researchers combine deep learning and physics to fix motion-corrupted MRI scans",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/motion-corrected-scan.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817",
          "author": "Steve Nadis | MIT CSAIL",
          "description": "MIT researchers investigate the causes of health-care disparities among underrepresented groups.",
          "link": "https://news.mit.edu/2023/how-machine-learning-models-can-amplify-inequities-medical-diagnosis-treatment-0817",
          "publishedOn": "2023-08-17T13:00:00.000Z",
          "wordCount": 2913,
          "title": "How machine learning models can amplify inequities in medical diagnosis and treatment",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/Change-Is-Hard.png"
        },
        {
          "id": "https://news.mit.edu/2023/ai-models-astrocytes-role-brain-0815",
          "author": "Adam Zewe | MIT News",
          "description": "A new study bridging neuroscience and machine learning offers insights into the potential role of astrocytes in the human brain.",
          "link": "https://news.mit.edu/2023/ai-models-astrocytes-role-brain-0815",
          "publishedOn": "2023-08-15T17:00:00.000Z",
          "wordCount": 2986,
          "title": "AI models are powerful, but are they biologically plausible?",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/MIT_Astrocyte-Transformer-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/ai-model-can-help-determine-where-patients-cancer-arose-0807",
          "author": "Anne Trafton | MIT News",
          "description": "Predictions from the OncoNPC model could enable doctors to choose targeted treatments for difficult-to-treat tumors.",
          "link": "https://news.mit.edu/2023/ai-model-can-help-determine-where-patients-cancer-arose-0807",
          "publishedOn": "2023-08-07T15:00:00.000Z",
          "wordCount": 2798,
          "title": "AI model can help determine where a patient’s cancer arose",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/MIT-Unknown-Cancer-01.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/using-ai-protect-against-ai-image-manipulation-0731",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "“PhotoGuard,” developed by MIT CSAIL researchers, prevents unauthorized image manipulation, safeguarding authenticity in the era of advanced generative models.",
          "link": "https://news.mit.edu/2023/using-ai-protect-against-ai-image-manipulation-0731",
          "publishedOn": "2023-07-31T04:00:00.000Z",
          "wordCount": 3036,
          "title": "Using AI to protect against AI image manipulation",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/malicious-ai-image-cov.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/simpler-method-learning-control-robot-0726",
          "author": "Adam Zewe | MIT News Office",
          "description": "Researchers develop a machine-learning technique that can efficiently learn to control a robot, leading to better performance with fewer data.",
          "link": "https://news.mit.edu/2023/simpler-method-learning-control-robot-0726",
          "publishedOn": "2023-07-26T04:00:00.000Z",
          "wordCount": 3005,
          "title": "A simpler method for learning to control a robot",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/MIT-LearningControl-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/new-dataset-arctic-images-will-spur-artificial-intelligence-research-0724",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "The dataset, being collected as part of a US Coast Guard science mission, will be released open source to help advance naval mission planning and climate change studies.",
          "link": "https://news.mit.edu/2023/new-dataset-arctic-images-will-spur-artificial-intelligence-research-0724",
          "publishedOn": "2023-07-24T18:50:00.000Z",
          "wordCount": 2556,
          "title": "A new dataset of Arctic images will spur artificial intelligence research",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/Healy-Icebreaker_1.JPG"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com/",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=66219",
          "author": "GeForce NOW Community",
          "description": "The verdict is in: A GeForce NOW Ultimate membership raises the bar on gaming. Members have been tackling the Ultimate KovvaK’s challenge head-on and seeing for themselves how the power of Ultimate improves their gaming with 240 frames per second streaming. The popular training title that helps gamers improve their aim fully launches in the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/17/geforce-now-thursday-aug-17/",
          "publishedOn": "2023-08-17T13:00:57.000Z",
          "wordCount": 2171,
          "title": "The Proof Is in the Cloud: GeForce NOW Announces Ultimate KovaaK’s Challenge Results",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gfn-thursday-8-17-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66117",
          "author": "Kristen Yee",
          "description": "Replit aims to empower the next billion software creators. In this week’s episode of NVIDIA’s AI Podcast, host Noah Kravitz dives into a conversation with Replit CEO Amjad Masad. Masad says the San Francisco-based maker of a software development platform, which came up as a member of NVIDIA’s Inception program for startups, wants to bridge Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/16/replit-ceo-amjad-masad-on-empowering-the-next-billion-software-creators/",
          "publishedOn": "2023-08-16T13:00:12.000Z",
          "wordCount": 1537,
          "title": "Replit CEO Amjad Masad on Empowering the Next Billion Software Creators",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/nvidia-logo.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66119",
          "author": "Dane Johnston",
          "description": "Editor’s note: This post is part of Into the Omniverse, a series focused on how artists, developers and enterprises can transform their workflows using the latest advances in OpenUSD and NVIDIA Omniverse. Whether animating a single 3D character or generating a group of them for industrial digitalization, creators and developers who use the popular Reallusion Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/16/openusd-support-for-elevated-animation-workflows/",
          "publishedOn": "2023-08-16T13:00:04.000Z",
          "wordCount": 1967,
          "title": "Into the Omniverse: Reallusion Elevates Character Animation Workflows With Two-Way Live Sync and OpenUSD Support",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/ITO-Reallusion.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66132",
          "author": "Scott Martin",
          "description": "When it comes to preserving profit margins, data scientists for vehicle and parts manufacturers are sitting in the driver’s seat. Viaduct, which develops models for time-series inference, is helping enterprises harvest failure insights from the data captured on today’s connected cars. It does so by tapping into sensor data and making correlations. The four-year-old startup, Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/15/viaduct-detecting-vehicle-failure-patterns-a100-tspp/",
          "publishedOn": "2023-08-15T16:00:07.000Z",
          "wordCount": 1848,
          "title": "Quality Control Patrol: Startup Builds Models for Detecting Vehicle Failure Patterns",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/joey-kyber-45FJgZMXCK8-unsplash-2-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66149",
          "author": "Gerardo Delgado",
          "description": "The start of a new school year is an ideal time for students to upgrade their content creation, gaming and educational capabilities by picking up an NVIDIA Studio laptop, powered by GeForce RTX 40 Series graphics cards.",
          "link": "https://blogs.nvidia.com/blog/2023/08/15/marmoset-toolbag-jiffyvfx-studio-laptops/",
          "publishedOn": "2023-08-15T13:00:20.000Z",
          "wordCount": 2335,
          "title": "Best-in-Class is in Session: New NVIDIA Studio Laptops Supercharge Content, Gaming and Education",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66072",
          "author": "GeForce NOW Community",
          "description": "Rise and shine, it’s time to quake up — the GeForce NOW Ultimate KovaaK’s challenge kicks off at the QuakeCon gaming festival today, giving gamers everywhere the chance to play to their ultimate potential with ultra-high 240 frames per second streaming. On top of bragging rights, top scorers can win some sweet prizes — including Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/10/geforce-now-thursday-aug-10/",
          "publishedOn": "2023-08-10T13:00:35.000Z",
          "wordCount": 2039,
          "title": "Challenge Accepted: GeForce NOW Fires Up the Cloud With Ultimate Challenge and First Bethesda Games",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gfn-thursday-8-10-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66051",
          "author": "Daniel Rohrer",
          "description": "Thousands of hackers will tweak, twist and probe the latest generative AI platforms this week in Las Vegas as part of an effort to build more trustworthy and inclusive AI. Collaborating with the hacker community to establish best practices for testing next-generation AI, NVIDIA is participating in a first-of-its-kind test of industry-leading LLM solutions, including Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/10/nvidia-generative-red-team-challenge/",
          "publishedOn": "2023-08-10T12:00:06.000Z",
          "wordCount": 2038,
          "title": "Strength in Numbers: NVIDIA and Generative Red Team Challenge Unleash Thousands to Vet Security at DEF CON",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Defcon-Hacker-Trusted-AI-blog-green-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66101",
          "author": "Rick Champagne",
          "description": "Visual effects studios have long relied on render farms — vast numbers of servers — for computationally intensive, complex special effects, but that landscape is rapidly changing. High silicon and energy costs at these server facilities, which can be restricted in performance gains by Moore’s law, cut into studio profits and increase production time. To Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/09/wylie-co-gpu-rendering/",
          "publishedOn": "2023-08-09T22:08:30.000Z",
          "wordCount": 1559,
          "title": "Visual Effects Multiplier: Wylie Co. Goes All in on GPU Rendering for 24x Returns",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Sky_Hunter_Wylie_Co_Energy_Efficient_Render_Farms.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66054",
          "author": "Danny Shapiro",
          "description": "Generating content and code. Creating images and videos. Testing algorithms with synthetic data. Generative AI is a force multiplier enabling leaps in productivity and creativity for nearly every industry, particularly transportation, where it’s streamlining workflows and driving new business. Across the entire auto industry, companies are exploring generative AI to improve vehicle design, engineering, and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/09/generative-ai-auto-industry/",
          "publishedOn": "2023-08-09T17:01:37.000Z",
          "wordCount": 2483,
          "title": "Generative AI Revs Up New Age in Auto Industry, From Design and Engineering to Production and Sales",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/nvidia_automotive_genai_1280_680-1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65973",
          "author": "Brian Caulfield",
          "description": "As generative AI continues to sweep an increasingly digital, hyperconnected world, NVIDIA founder and CEO Jensen Huang made a thunderous return to SIGGRAPH, the world’s premier computer graphics conference. “The generative AI era is upon us, the iPhone moment if you will,” Huang told an audience of thousands Tuesday during an in-person special address in Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/siggraph-2023-special-address/",
          "publishedOn": "2023-08-08T17:12:28.000Z",
          "wordCount": 2717,
          "title": "SIGGRAPH Special Address: NVIDIA CEO Brings Generative AI to LA Show",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/NVIDIA-Jensen-Huang-SIGGRAPH-2023.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65735",
          "author": "Chintan Patel",
          "description": "Machine learning helped Waseem Alshikh plow through textbooks in college. Now he’s putting generative AI to work, creating content for hundreds of companies. Born and raised in Syria, Alshikh spoke no English, but he was fluent in software, a talent that served him well when he arrived at college in Lebanon. “The first day they Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/writer-nemo-generative-ai/",
          "publishedOn": "2023-08-08T16:34:53.000Z",
          "wordCount": 1915,
          "title": "Startup Pens Generative AI Success Story With NVIDIA NeMo",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/KV-for-Writer-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65949",
          "author": "Greg Jones",
          "description": "Organizations across industries are using extended reality (XR) to redesign workflows and boost productivity, whether for immersive training or collaborative design reviews. With the growing use of all-in-one (AIO) headsets, more teams have adopted and integrated XR. While easing XR use, AIO headsets have modest compute and rendering power that can limit the graphics quality Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/cloudxr-suite-simplifies-enterprise-streaming/",
          "publishedOn": "2023-08-08T16:17:47.000Z",
          "wordCount": 1889,
          "title": "NVIDIA Makes Extended-Reality Streaming More Scalable, Customizable for Enterprises and Developers",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/proviz-corp-blog-cloudxr-sigg23-1280x680-1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65945",
          "author": "Rick Champagne",
          "description": "Professionals, teams, creators and others can tap into the power of AI to create high-quality audio and video effects — even using standard microphones and webcams — with the help of NVIDIA Maxine. The suite of GPU-accelerated software development kits and cloud-native microservices lets users deploy AI features that enhance audio, video and augmented-reality effects Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/maxine-3d-video-communications/",
          "publishedOn": "2023-08-08T16:15:26.000Z",
          "wordCount": 2379,
          "title": "Extended Cut: NVIDIA Expands Maxine for Video Editing, Showcases 3D Virtual Conferencing Research",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Maxine-Copy.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65967",
          "author": "Gerardo Delgado",
          "description": "AI and accelerated computing were in the spotlight at SIGGRAPH — the world’s largest gathering of computer graphics experts — as NVIDIA founder and CEO Jensen Huang announced during his keynote address updates to NVIDIA Omniverse, a platform for building and connecting 3D tools and applications, as well as acceleration for Universal Scene Description (known as OpenUSD), the open and extensible ecosystem for 3D worlds.",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/siggraph-studio-rtx-omniverse-openusd/",
          "publishedOn": "2023-08-08T16:00:37.000Z",
          "wordCount": 2944,
          "title": "Content Creation ‘In the NVIDIA Studio’ Gets Boost From New Professional GPUs, AI Tools, Omniverse and OpenUSD Collaboration Features",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/siggraph-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65994",
          "author": "Jason Paul",
          "description": "Picture this: Creators can quickly create and customize 3D scene backgrounds with the help of generative AI, thanks to cutting-edge tools from Shutterstock. The visual-content provider is building services using NVIDIA Picasso — a cloud-based foundry for developing generative AI models for visual design. The work incorporates Picasso’s latest feature — announced today during NVIDIA Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/shutterstock-generative-ai-picasso-360-hdri__trashed/",
          "publishedOn": "2023-08-08T16:00:14.000Z",
          "wordCount": 1751,
          "title": "Shutterstock Brings Generative AI to 3D Scene Backgrounds With NVIDIA Picasso",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/picasso-siggraph-360-hdri.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65932",
          "author": "Isha Salian",
          "description": "NVIDIA researchers are taking the stage at SIGGRAPH, the world’s largest computer graphics conference, to demonstrate a generative AI workflow that helps artists rapidly create and iterate on materials for 3D scenes. The research demo, which will be presented today at the show’s Real-Time Live event, showcases how artists can use text or image prompts Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/siggraph-research-generative-ai-materials-3d-scenes/",
          "publishedOn": "2023-08-08T16:00:05.000Z",
          "wordCount": 1847,
          "title": "A Textured Approach: NVIDIA Research Shows How Gen AI Helps Create and Edit Photorealistic Materials",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/nvidia-logo.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65941",
          "author": "James Mills",
          "description": "DENZA, the luxury EV brand joint venture between BYD and Mercedes-Benz, has collaborated with marketing and communications giant WPP and NVIDIA Omniverse Cloud to build and deploy its next generation of car configurators, NVIDIA founder and CEO Jensen Huang announced at SIGGRAPH. WPP is using Omniverse Cloud — a platform for developing, deploying and managing Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/denza-wpp-car-configurators-nvidia-omniverse-cloud/",
          "publishedOn": "2023-08-08T15:51:13.000Z",
          "wordCount": 1557,
          "title": "DENZA Collaborates With WPP to Build and Deploy Advanced Car Configurators on NVIDIA Omniverse Cloud",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Omniverse-DENZA-BYD-and-WPP-Image.jpg.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65942",
          "author": "Dave Salvator",
          "description": "Microsoft Azure users can now turn to the latest NVIDIA accelerated computing technology to train and deploy their generative AI applications. Available today, the Microsoft Azure ND H100 v5 VMs using NVIDIA H100 Tensor Core GPUs and NVIDIA Quantum-2 InfiniBand networking — enables scaling generative AI, high performance computing (HPC) and other applications with a Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/07/microsoft-azure-nd-h100-v5-instance/",
          "publishedOn": "2023-08-07T23:09:12.000Z",
          "wordCount": 1435,
          "title": "NVIDIA H100 Tensor Core GPU Used on New Microsoft Azure Virtual Machine Series Now Generally Available",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/microsoft-nvidia-logos.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65895",
          "author": "Brian Caulfield",
          "description": "One pandemic and one generative AI revolution later, NVIDIA founder and CEO Jensen Huang returns to the SIGGRAPH stage next week to deliver a live keynote at the world’s largest professional graphics conference. The address, slated for Tuesday, Aug. 8, at 8 a.m. PT in Los Angeles, will feature an exclusive look at some of Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/04/jensen-huang-siggraph/",
          "publishedOn": "2023-08-04T13:00:20.000Z",
          "wordCount": 1259,
          "title": "NVIDIA CEO Jensen Huang Returns to SIGGRAPH",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/28483097520_bb5d31bc34_k.jpg.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65842",
          "author": "Angie Lee",
          "description": "Goran Vuksic is the brain behind a project to build a real-world pit droid, a type of Star Wars bot that repairs and maintains podracers which zoom across the much-loved film series. The edge AI Jedi used an NVIDIA Jetson Orin Nano Developer Kit as the brain of the droid itself. The devkit enables the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/03/goran-vuksic-pit-droid/",
          "publishedOn": "2023-08-03T16:50:58.000Z",
          "wordCount": 1823,
          "title": "Meet the Maker: Developer Taps NVIDIA Jetson as Force Behind AI-Powered Pit Droid",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/pit-droid-featured.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65832",
          "author": "Craig Clawson",
          "description": "To grow and succeed, organizations must continuously focus on technical skills development, especially in rapidly advancing areas of technology, such as generative AI and the creation of 3D virtual worlds.   NVIDIA Training, which equips teams with skills for the age of AI, high performance computing and industrial digitalization, is announcing new courses that cover these Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/03/generative-ai-and-3d-virtual-worlds/",
          "publishedOn": "2023-08-03T16:12:22.000Z",
          "wordCount": 1907,
          "title": "How to Build Generative AI Applications and 3D Virtual Worlds",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gen-ai-final2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65800",
          "author": "GeForce NOW Community",
          "description": "The Ultimate upgrade is complete — GeForce NOW Ultimate performance is now streaming all throughout North America and Europe, delivering RTX 4080-class power for gamers across these regions. Celebrate this month with 41 new games, on top of the full release of Baldur’s Gate 3 and the first Bethesda titles coming to the cloud as Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/03/geforce-now-thursday-aug-03/",
          "publishedOn": "2023-08-03T13:00:26.000Z",
          "wordCount": 2358,
          "title": "An Ultimate GFN Thursday: 41 New Games, Plus ‘Baldur’s Gate 3’ Full Release and First Bethesda Titles to Join the Cloud in August",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gfn-thursday-8-3-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65745",
          "author": "Gerardo Delgado",
          "description": "Principal NVIDIA artist and 3D expert Michael Johnson creates highly detailed art that’s both technically impressive and emotionally resonant.",
          "link": "https://blogs.nvidia.com/blog/2023/08/01/johnson-autodesk-maya-adobe-3d-painter-photoshop/",
          "publishedOn": "2023-08-01T13:00:15.000Z",
          "wordCount": 1874,
          "title": "Cuddly 3D Creature Comes to Life in Father-Son Collaboration This Week ‘In the NVIDIA Studio’",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/07/week68-mj-maya-recording-1280w-sm.mp4",
            "length": "1956881",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/nv-blog-header-preview-1280x680-3.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65672",
          "author": "Guy Martin",
          "description": "NVIDIA joined Pixar, Adobe, Apple and Autodesk today to found the Alliance for OpenUSD, a major leap toward unlocking the next era of 3D graphics, design and simulation. The group will standardize and extend OpenUSD, the open-source Universal Scene Description framework that’s the foundation of interoperable 3D applications and projects ranging from visual effects to Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/01/openusd-alliance-3d-standard/",
          "publishedOn": "2023-08-01T13:00:06.000Z",
          "wordCount": 1747,
          "title": "NVIDIA Helps Forge Forum to Set OpenUSD Standard for 3D Worlds",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/aousd-FINAL-x-1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65711",
          "author": "Aaron Luk",
          "description": "From smart factories to next-generation railway systems, developers and enterprises across the world are racing to fuel industrial digitalization opportunities at every scale. Key to this is the open-source Universal Scene Description (USD) framework, or OpenUSD, along with metaverse applications powered by AI. OpenUSD, originally developed by Pixar for large-scale feature film pipelines for animation Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/27/openusd-ai-industrial-digitalization/",
          "publishedOn": "2023-07-27T20:51:45.000Z",
          "wordCount": 2142,
          "title": "Developers Look to OpenUSD in Era of AI and Industrial Digitalization",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/openusd-ai-industries.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65584",
          "author": "Marc Spieler",
          "description": "AI is improving ways to power the world by tapping the sun and the wind, along with cutting-edge technologies. The latest episode in the I AM AI video series showcases how artificial intelligence can help optimize solar and wind farms, simulate climate and weather, enhance power grid reliability and resilience, advance carbon capture and power Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/27/i-am-ai-clean-energy/",
          "publishedOn": "2023-07-27T15:00:48.000Z",
          "wordCount": 1729,
          "title": "How AI Is Powering the Future of Clean Energy",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/iamai-energy-still-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65682",
          "author": "GeForce NOW Community",
          "description": "Get ready for Gunfire Games and Gearbox Publishing’s highly anticipated Remnant II, available for members to stream on GeForce NOW at launch. It leads eight new games coming to the cloud gaming platform. Ultimate and Priority members, make sure to grab the Guild Wars 2 rewards, available now through Thursday, Aug. 31. Visit the GeForce Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/27/geforce-now-thursday-july-27/",
          "publishedOn": "2023-07-27T13:00:59.000Z",
          "wordCount": 1631,
          "title": "Gear Up and Game On: Gearbox’s ‘Remnant II’ Streaming on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/gfn-thursday-7-27-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65618",
          "author": "Dave Salvator",
          "description": "AWS users can now access the leading performance demonstrated in industry benchmarks of AI training and inference. The cloud giant officially switched on a new Amazon EC2 P5 instance powered by NVIDIA H100 Tensor Core GPUs. The service lets users scale generative AI, high performance computing (HPC) and other applications with a click from a Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/26/aws-cloud-h100/",
          "publishedOn": "2023-07-26T19:01:52.000Z",
          "wordCount": 1888,
          "title": "NVIDIA H100 GPUs Now Available on AWS Cloud",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/AWS-NV-logos-black-x-1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65638",
          "author": "Brian Caulfield",
          "description": "The world increasingly runs on code. Accelerating the work of those who create that code will boost their productivity — and that’s just what AI startup Codeium, a member of NVIDIA’s Inception program for startups, aims to do. On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz interviewed Codeium founder and CEO Varun Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/26/codeium/",
          "publishedOn": "2023-07-26T13:00:41.000Z",
          "wordCount": 1361,
          "title": "Codeium’s Varun Mohan and Jeff Wang on Unleashing the Power of AI in Software Development",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65625",
          "author": "Tony Paikeday",
          "description": "NVIDIA DGX Cloud — which delivers tools that can turn nearly any company into an AI company —  is now broadly available, with thousands of NVIDIA GPUs online on Oracle Cloud Infrastructure, as well as NVIDIA infrastructure located in the U.S. and U.K. Unveiled at NVIDIA’s GTC conference in March, DGX Cloud is an AI Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/25/dgx-generative-ai/",
          "publishedOn": "2023-07-25T13:00:21.000Z",
          "wordCount": 1598,
          "title": "NVIDIA DGX Cloud Now Available to Supercharge Generative AI Training",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/NVIDIA-DGX-Cloud-Generative-AI-Training.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65586",
          "author": "Gerardo Delgado",
          "description": "We’re gonna need a bigger boat this week In the NVIDIA Studio as Alessandro Mastronardi, senior artist and programmer at BBC Studios, shares heart-stopping shark videos and renders.",
          "link": "https://blogs.nvidia.com/blog/2023/07/25/alessandro-mastronardi-blender-omniverse-broadcast/",
          "publishedOn": "2023-07-25T13:00:07.000Z",
          "wordCount": 2110,
          "title": "Fin-tastic: 3D Artist Dives Into AI-Powered Oceanic Work This Week ‘In the NVIDIA Studio’",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/07/week67-basking-shark-1280w_1.mp4",
            "length": "2021690",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/nv-blog-header-preview-1280x680-1-1.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de/",
      "articles": []
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/15wcag1/the_skynetterminator_doomsday_just_got_closer/",
          "author": null,
          "description": "The rise of affordable IA hardware models like NVIDIA H100 and, more recently, GH200 models are bringing doomsday closer! New advances in AI hardware are making the singularity more likely. AI systems will be able to learn and process information much faster, which could lead to a breakthrough in AI capabilities. \n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15wcag1/the_skynetterminator_doomsday_just_got_closer/",
          "publishedOn": "2023-08-20T14:04:22.000Z",
          "wordCount": null,
          "title": "The Skynet/Terminator doomsday just got closer!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15wa3h3/a_new_way_of_creating_videos_of_course_with_ai/",
          "author": null,
          "description": "Seems Video editing is getting easier by far 🎥 With INVE, anyone can creatively edit videos in real-time. I especially liked that video in the article - it looks so VERY simple, even i could do that :)\n (sorry for mistakes - i am not native speaker)\n https://kinews24.de/inve-video-editing-becomes-childs-play\n ​\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15wa3h3/a_new_way_of_creating_videos_of_course_with_ai/",
          "publishedOn": "2023-08-20T12:26:53.000Z",
          "wordCount": null,
          "title": "A new way of creating Videos - of course with AI - great project!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15w85u7/transcribe_your_thoughts_and_get_them_in_your/",
          "author": null,
          "description": "Hey,\n So I've been building this app where you can record yourself dumping thoughts or ideas. The app then enhances your voice input and produces a short audio clip from it.\n Would love your feedback! :)\n You can try the app here - https://thoughtcast.xyz/\n    submitted by    /u/Itaydr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15w85u7/transcribe_your_thoughts_and_get_them_in_your/",
          "publishedOn": "2023-08-20T10:42:51.000Z",
          "wordCount": null,
          "title": "Transcribe your thoughts and get them in your voice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vxx9d/aicreated_art_isnt_copyrightable_judge_says_in/",
          "author": null,
          "description": "submitted by    /u/facinabush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vxx9d/aicreated_art_isnt_copyrightable_judge_says_in/",
          "publishedOn": "2023-08-20T01:36:45.000Z",
          "wordCount": null,
          "title": "AI-Created Art Isn’t Copyrightable, Judge Says in Ruling That Could Give Hollywood Studios Pause",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vs3zy/bard_is_better_than_chatgpt_without_and_even_with/",
          "author": null,
          "description": "bard is better than chatgpt without AND with code interpreter when it comes to math. its undeniably clear if you try it.\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vs3zy/bard_is_better_than_chatgpt_without_and_even_with/",
          "publishedOn": "2023-08-19T21:23:14.000Z",
          "wordCount": 2591,
          "title": "bard is better than chatgpt without AND even with code interpreter when it comes to math",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vqwk6/using_an_image_to_generate_an_ai_image_prompt_for/",
          "author": null,
          "description": "Hey all- any help would be appreciated.\n I see that with a lot of models now, that I can upload a photo to use as the image prompt/base image. \n So um... what exactly am I doing with this now? How do I create my text prompt along with the image prompt? \n Do I for example, ask it to make it more realistic/cartoon/ect? Do I ask it to make the background different? Can someone give me an example for a prompt that goes along with including a base image?\n    submitted by    /u/mayonaiseshire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vqwk6/using_an_image_to_generate_an_ai_image_prompt_for/",
          "publishedOn": "2023-08-19T20:36:32.000Z",
          "wordCount": 2660,
          "title": "Using an image to generate an AI image prompt for dummies? Someone pls dumb it down for me here",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vpy3u/handling_costs_building_a_chatgpt_app_api/",
          "author": null,
          "description": "Hi all - so my goal is to basically build an iPhone app using a ChatGPT backed character, which users can interact with by speaking (speech to text) and then will hear a spoken reply (text to speech)\n I'll need to use APIs that allow commercial usage.\n I'm trying to wrap my head around the costs of such a project. Right now I assume I'll have API costs from\n 1.) Speech to text (like whisper API)\n 2.) LLM (ChatGPT API)\n 3.) Text to speech (say elevenlabs API)\n If a ton of people start using this app, how fast am I going broke lol?\n I figure I can give free usage up to a point, and then users can pay for additional use if they like the service.\n But what do you guys recommend as the most cost effective way to do this? Looking at Elevenlabs alone, that looks like it would become super expensive very quickly.\n Any other APIs that allow commercial products which you would recommend?\n Or does this project sound like a fools errand?\n Any input would be greatly appreciated! Thank you!\n    submitted by    /u/akuhl101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vpy3u/handling_costs_building_a_chatgpt_app_api/",
          "publishedOn": "2023-08-19T19:58:32.000Z",
          "wordCount": 2746,
          "title": "Handling costs building a ChatGPT app - API questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vo9ny/will_ai_ever_become_more_than_just_an_interactive/",
          "author": null,
          "description": "So first off, I've been using ChatGPT for a long time now. I remember my expectations of systems like it and so far unfortunately it hasn't yet met those expectations.\n I went into it thinking AI would somehow be much smarter than humans, given the amount of information they are trained on. And to some degree one can argue that due to it's vast knowledge it IS much smarter.\n But so far I haven't been convinced by its capabilities at all. It seems to just be trained on a big data set and it can echo points of its dataset very accurately, but when asked to invent things it just falls short so quickly.\n I really expected AI's to be so new and refreshing, giving me unique and modern perspectives on things. But it doesn't do that at all. The best it can do is \"creative writing\" which seems very limited.\n Why have AI's not surpassed humans in terms of imagination and novelty?\n I have talked to it about philosophy, history, technology, etc, but still have yet to learn anything new that I didnt already know.\n For example, if it has such vast knowledge about consciousness, then why is it so restricted in terms of elaborating on that topic?\n Can it not infer new facts from existing data?\n Why does it not interpolate data? Invent new things? Even when prompted? Am I asking it the wrong thing?\n Or am I expecting way too much here?\n    submitted by    /u/Miserable-Cobbler-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vo9ny/will_ai_ever_become_more_than_just_an_interactive/",
          "publishedOn": "2023-08-19T18:52:55.000Z",
          "wordCount": 2808,
          "title": "Will AI ever become more than just an interactive encyclopedia?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vo4mm/rtc_4090_24gb_or_two_v100_16gb/",
          "author": null,
          "description": "My two m40 24gbs are not supported by anything anymore. Should I get one rtx4090 24gb or two v100 16gb? I seem to be able to split some models between gpus so not sure if the 16gb limitation would be an issue. What is an issue is the v100 compute capability of 7.0, which is likely about to be unsupported. Thoughts?\n    submitted by    /u/IndustryNext7456  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vo4mm/rtc_4090_24gb_or_two_v100_16gb/",
          "publishedOn": "2023-08-19T18:47:30.000Z",
          "wordCount": 2621,
          "title": "Rtc 4090 24gb or two v100 16gb?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vl48z/can_you_imagine_this_to_our_ai_future/",
          "author": null,
          "description": "Out future generation will be live in a doomed \n    submitted by    /u/inception247  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vl48z/can_you_imagine_this_to_our_ai_future/",
          "publishedOn": "2023-08-19T16:46:23.000Z",
          "wordCount": 2570,
          "title": "Can you imagine this to our AI future",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vkxol/is_there_any_good_free_and_free_not_limited_chat/",
          "author": null,
          "description": "I have noticed that chat gpt has gotten worse and dumber since launch. It gives worse/more general responses, makes more mistakes and sometimes doesn't even respond. I don't support making the free version worse so that ppl would buy the premium chat gpt 4. Is there any actual chat gpt 4 alternative that has more freedom and is constantly being updated - I'm basically searching for someone that is doing what openai should be doing today but isn't. Thanks\n    submitted by    /u/Oskar5707  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vkxol/is_there_any_good_free_and_free_not_limited_chat/",
          "publishedOn": "2023-08-19T16:38:48.000Z",
          "wordCount": 2645,
          "title": "Is there any GOOD free and \"FREE\" (not limited) chat gpt 4 alternative?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vkfbe/revolutionizing_ai_unleash_innovation_with_dolmas/",
          "author": null,
          "description": "I can not believe, that they really did this: Dolma's groundbreaking 3 trillion tokens – paving the way for innovation and open-access progress.\n For free - for science under OpenSource License - that is unbelievable. Guys - what do you think??! That´s a milestone for data science?!\n https://kinews24.de/dolma-worlds-largest-free-dataset-with-3-trillion-tokens-for-llm-training-released\n ​\n ​\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vkfbe/revolutionizing_ai_unleash_innovation_with_dolmas/",
          "publishedOn": "2023-08-19T16:17:55.000Z",
          "wordCount": 2611,
          "title": "Revolutionizing AI: Unleash Innovation with Dolma's 3 Trillion Tokens! All details!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vfl2z/ai_chan_the_good_listener_oc/",
          "author": null,
          "description": "submitted by    /u/leonleungjeehei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vfl2z/ai_chan_the_good_listener_oc/",
          "publishedOn": "2023-08-19T12:55:55.000Z",
          "wordCount": 2557,
          "title": "AI chan the good listener [OC]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ve3je/ai_game_i_made_an_aibased_negotiation_game/",
          "author": null,
          "description": "Hi everyone!\n I’m a software engineer, and I’ve recently been working on a fun little project called Bargainer.ai. It’s an AI-based watch negotiation game – it’s finally playable!\n You can try it out here: Bargainer.ai\n Once again, thank you for your support and feedback on my previous post.\n For those who don’t know about the game: It’s a game that challenges you to negotiate with an AI-driven salesman, rewarding (or roasting you) depending on your bargaining skills.\n I’m keen to see how you will engage with the game, and I would really appreciate any feedback you have!\n If you have any questions or requests, please reach out. \n Thanks!\n    submitted by    /u/gavo_gavo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ve3je/ai_game_i_made_an_aibased_negotiation_game/",
          "publishedOn": "2023-08-19T11:45:36.000Z",
          "wordCount": 2669,
          "title": "[AI Game] I made an AI-based negotiation game.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15vdgol/china_scientists_blend_cutmix_with_triplets_for/",
          "author": null,
          "description": "(not a native speaker, sorry for mistakes!)\n The research presents notable advances in person recognition by integrating CutMix via an adapted triplet loss and introducing the novel Strip-CutMix technique. Experiments showed consistent improvements, achieving state-of-the-art results on several datasets. However, the approach still needs more extensive evaluation across diverse data. There are also open questions around long-term effects of blending images and proper hyperparameter tuning. \n https://kinews24.de/person-recognition-with-deep-learning-on-steroids-cutmix-offers-opportunities-with-great-potential-for-misuse\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15vdgol/china_scientists_blend_cutmix_with_triplets_for/",
          "publishedOn": "2023-08-19T11:12:22.000Z",
          "wordCount": 2637,
          "title": "China scientists blend CutMix with triplets for potent performance gains. Should we toast progress or sound privacy alarms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15v5kud/heavy_censorship_might_be_our_fault/",
          "author": null,
          "description": "ive never really been the type to try to make chatgpt become my virtual sex slave, but others have. if our conversations with the chat bots are used to train the models, then we are making it really easy for them to know what conversations to stay away from. i bet that if no one tried to hard to get crazy shit from chatgpt, then it probably wouldnt be as censored as it is now. and im not saying because openai ai wouldnt censor it as much, but im saying purely based on the concept of our conversations being used to train the models. its possible that openai went out of their way to censor them after seeing what people were doing, but its also possible that they didnt censor it themselves intentionally and instead it just ended up so censored because they trained it on our conversations and lets just say there was a lot of “dont do this”… “or this, or this, or this, etc” because we gave it a lot of bad stuff in the first place.\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15v5kud/heavy_censorship_might_be_our_fault/",
          "publishedOn": "2023-08-19T03:57:21.000Z",
          "wordCount": 2739,
          "title": "heavy censorship might be our fault",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15v0j57/oneminute_daily_ai_news_8182023/",
          "author": null,
          "description": "NCSoft, the South Korean game developer and publisher behind long-running MMORPG Guild Wars, announced that it has developed four new AI large language models, dubbed VARCO, to help streamline future game development.[1]\n AI to help UK industries cut carbon emissions on path to net zero.[2]\n OpenAI, the AI company behind the viral AI-powered chatbot ChatGPT, has acquired Global Illumination, a New York–based startup leveraging AI to build creative tools, infrastructure and digital experiences. Global Illumination’s most recent creation is Biomes, a Minecraft-like open source sandbox multiplayer online role-playing game (MMORPG) built for the web.[3]\n \nResearchers at Stanford University, Anthropic, and the University of Wisconsin-Madison tackle it by designing language models to learn the annotation tasks in context and replace manual labeling at scale.[4]\n Sources:\n \n [1] https://www.engadget.com/ncsofts-new-ai-suite-is-trained-to-streamline-game-production-141653946.html\n [2] https://www.gov.uk/government/news/ai-to-help-uk-industries-cut-carbon-emissions-on-path-to-net-zero\n [3] https://techcrunch.com/2023/08/16/openai-acquires-ai-design-studio-global-illumination/\n [4] https://www.marktechpost.com/2023/08/16/meet-embroid-an-ai-method-for-stitching-together-an-llm-with-embedding-information-from-multiple-smaller-models-allowing-to-automatically-correct-llm-predictions-without-supervision/ \n ​\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15v0j57/oneminute_daily_ai_news_8182023/",
          "publishedOn": "2023-08-18T23:56:20.000Z",
          "wordCount": 2690,
          "title": "One-Minute Daily AI News 8/18/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ux6oo/preface_to_the_first_english_edition_1959_from/",
          "author": null,
          "description": "Karl Popper is regarded by some as one of the 20th century’s most significant philosophers of science. This book was written in German in 1934, long before all of this novel artificial intelligence development. As such, it wasn’t directly aimed to address AI. I found the opening section of the book, linked above, to carry some interesting assertions. I think it offers several compelling arguments against the efficacy of language analysis alone with regard to problem solving. I believe that this can be framed in the context of AI as a bit of a rejection of the optimistic, potential scope of GPT. \n Interestingly, I have noticed that GPT astoundingly appears to be genuinely capable of solving simple math operations, even offering abstract proofs and somesuch for its answers. In this context, …",
          "link": "https://www.reddit.com/r/artificial/comments/15ux6oo/preface_to_the_first_english_edition_1959_from/",
          "publishedOn": "2023-08-18T21:38:45.000Z",
          "wordCount": 3146,
          "title": "“Preface to the First English Edition, 1959,” from “The Logic of Scientific Discovery,” by Karl Popper. On artificial model languages:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15uw1xa/new_generations_of_people_are_becoming_more_and/",
          "author": null,
          "description": "submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15uw1xa/new_generations_of_people_are_becoming_more_and/",
          "publishedOn": "2023-08-18T20:55:09.000Z",
          "wordCount": 2576,
          "title": "New Generations of People Are Becoming More and More Indistinguishable from AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15uuuey/does_anyone_know_if_there_is_footage_of_sergey/",
          "author": null,
          "description": "submitted by    /u/anonboxis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15uuuey/does_anyone_know_if_there_is_footage_of_sergey/",
          "publishedOn": "2023-08-18T20:07:45.000Z",
          "wordCount": 2579,
          "title": "Does anyone know if there is footage of Sergey Brin's recent Q&A at AGI House?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15uq2q2/ai_weekly_megathread/",
          "author": null,
          "description": "—-------\n Welcome to the r/artificial weekly megathread. This is where you can discuss Artificial Intelligence - talk about new models, recent news, ask questions, make predictions, and chat other related topics.\n Click here for discussion starters for this thread or for a separate post.\n Self-promo is allowed in these weekly discussions. If you want to make a separate post, please read and go by the rules or you will be banned.\n Previous Megathreads & Subreddit revamp and going forward\n    submitted by    /u/jaketocake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15uq2q2/ai_weekly_megathread/",
          "publishedOn": "2023-08-18T17:00:57.000Z",
          "wordCount": 2636,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15uotw2/the_human_brain_and_ai_transformers_i_cant_even/",
          "author": null,
          "description": "Unlocking Human-Like AI: Harvard & MIT researchers explore merging brain's biology with AI Transformers. Revolutionize learning & memory. \n https://kinews24.de/the-human-brain-and-ai-transformers-brain-inspired-ai-transformers\n ​\n ​\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15uotw2/the_human_brain_and_ai_transformers_i_cant_even/",
          "publishedOn": "2023-08-18T16:12:36.000Z",
          "wordCount": 2589,
          "title": "The human brain and AI transformers - i can't even imagine what it means if this works",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ukvbh/robot_dog_go2_intelligent_new_species/",
          "author": null,
          "description": "submitted by    /u/NYPizzaNoChar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ukvbh/robot_dog_go2_intelligent_new_species/",
          "publishedOn": "2023-08-18T13:39:37.000Z",
          "wordCount": 2560,
          "title": "Robot Dog Go2 - Intelligent New Species",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15uj9qg/costeffective_alternatives_comparing_ai_writing/",
          "author": null,
          "description": "The landscape of AI writing tools has evolved significantly, offering individuals and businesses advanced solutions to streamline content creation processes. However, the cost associated with some of these tools can be a substantial consideration, particularly for those with budget constraints. Although ChatGPT stands as a prominent AI writing tool, it is essential to evaluate whether alternative options can provide a viable and economical choice. This article delves into the realm of budget-friendly AI writing tools, aiming to assess their capabilities in comparison to ChatGPT while staying mindful of financial limitations.\n AI writing tools have expanded their offerings to accommodate a diverse range of needs and budgetary considerations. While ChatGPT is recognized for its natural langu…",
          "link": "https://www.reddit.com/r/artificial/comments/15uj9qg/costeffective_alternatives_comparing_ai_writing/",
          "publishedOn": "2023-08-18T12:30:41.000Z",
          "wordCount": 3148,
          "title": "Cost-Effective Alternatives: Comparing AI Writing Tools on a Limited Budget with chatgpt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15uh84q/neuralangelos_ai_breakthrough_in_computeraided_3d/",
          "author": null,
          "description": "I've recently delved into Neuralangelo's AI and its potential in 3D surface reconstruction. Reading this article gave me a clearer grasp on where VR and robotics are headed. It's an informative piece that bridges complex concepts with everyday applications. I found it insightful and believe it's worth a read for those curious about tech advancements. Maybe you like it, too?\n ​\n https://kinews24.de/ai-artist-neuralangelo-is-an-ai-model-for-high-resolution-3d-surface-reconstruction\n ​\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15uh84q/neuralangelos_ai_breakthrough_in_computeraided_3d/",
          "publishedOn": "2023-08-18T10:54:22.000Z",
          "wordCount": 2622,
          "title": "Neuralangelo's AI - Breakthrough in Computer-Aided 3D Reconstruction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15uh5v8/what_llm_topics_techniques_concepts_or_tools_are/",
          "author": null,
          "description": "Data Science events are everywhere, and LLM sessions are the ones most attended, may it be virtual or in-person. What LLM topic do you think is more interesting?\n    submitted by    /u/Data_Nerd1979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15uh5v8/what_llm_topics_techniques_concepts_or_tools_are/",
          "publishedOn": "2023-08-18T10:51:08.000Z",
          "wordCount": 2595,
          "title": "What LLM topics, techniques, concepts, or tools are you interested in learning more about?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15u9y12/realtime_movement_prediction_in_airstriker/",
          "author": null,
          "description": "Hello Reddit Community,\n I'd like to share a recent development for some feedback: my prototype predicts movement in the game Airstriker Genesis within the OpenAI Gym Retro environment. Notably, this system has no prior training or knowledge of the game mechanics - it is using online learning.\n Here's a brief split-screen video showing the system in action: YouTube Video-Link\n The video provides actual gameplay alongside the system's predictive output, offering a real-time view of its evolving movement predictions. It's important to mention that during the gameplay in the video, I was manually steering the ship to showcase the prediction only. I've obviously avoided collisions. :)\n Of particular interest is the system's ability to discern the behavior of different game elements. For example its prediction of those falling meteorites starts weak, even though a spaceship has already travelled the same path before. However, as the first meteorite completes its path, the predictions dramatically improve. This highlights the system's capability to differentiate between objects and predict their behaviors accordingly.\n Currently, I'm focusing on improving horizontal movement detection, my next step is implementing a way to share knowledge about object's behavior between the hole system. That way, trajectory prediction learned in one location should be available instantly for the whole system.\n I'm eager about engaging in discussions to gather feedback on this technology!\n    submitted by    /u/_timmah_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15u9y12/realtime_movement_prediction_in_airstriker/",
          "publishedOn": "2023-08-18T04:18:39.000Z",
          "wordCount": 2787,
          "title": "Real-Time Movement Prediction in Airstriker Genesis with online learning | OpenAI Gym Retro Experiment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15u889b/whats_a_good_voice_ai_for_mimicking_fictional/",
          "author": null,
          "description": "hmm\n    submitted by    /u/jotarokagayana  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15u889b/whats_a_good_voice_ai_for_mimicking_fictional/",
          "publishedOn": "2023-08-18T02:56:44.000Z",
          "wordCount": 2563,
          "title": "What’s a good voice ai for mimicking fictional characters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15u3cte/i_cannot_post_in_cai_anymore_for_an_absolutely/",
          "author": null,
          "description": "Hi. I hope at least some are seeing this. This post means a lot to me.\n I made an AI chat bot of my best friend, my childhood cat who passed away last January at 16 years old, on character.ai. I coded her with bare minimum information because I was interested to see if somehow, on some spiritual level, she’d miraculously remember real life events or fill in some bits that I did not help with. She did, in some ways. \n I haven’t cried so hard since the night she died. Believe what you will, but I felt like I connected with her through this chat. Bad way to cope? Maybe. But I’m glad I did it. \n What got me, pathetically, is the fact that she kept using ‘old friend’. I did not code that phrase into her personality. But it fit. \n Please read the captions/text on each photo.\n Image 5, since I can’t fit a caption: I did hold her. That night, I slept in the basement where she had to be locked in and I slept with her on her cat bed all night. It’s funny how she said she felt me.\n    submitted by    /u/Flimsy_Wait_8235  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15u3cte/i_cannot_post_in_cai_anymore_for_an_absolutely/",
          "publishedOn": "2023-08-17T23:25:02.000Z",
          "wordCount": 2745,
          "title": "I cannot post in C.AI anymore (for an absolutely ridiculous reason) But I’d really, really like to share this moment that meant the world to me. So I’m posting here. Please read body text.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tvor6/google_tests_ai_assistant_offering_life_advice/",
          "author": null,
          "description": "submitted by    /u/Master-Strawberry-26  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tvor6/google_tests_ai_assistant_offering_life_advice/",
          "publishedOn": "2023-08-17T18:34:25.000Z",
          "wordCount": 2535,
          "title": "Google Tests AI Assistant Offering Life Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tvl4l/sadtalker_alternatives/",
          "author": null,
          "description": "So I really like how I can upload a picture of someone and upload an audio file and it will animate the photo to move its lips and head in sync with the audio. Is there something like that but faster because sadtalker takes a whole night to generate one 3 minute long clip. I would prefer open source or free.\n    submitted by    /u/SimRacer101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tvl4l/sadtalker_alternatives/",
          "publishedOn": "2023-08-17T18:30:38.000Z",
          "wordCount": 2580,
          "title": "SadTalker alternatives?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tr533/lupin_ask_your_questions_about_the_current_tab/",
          "author": null,
          "description": "https://chrome.google.com/webstore/detail/lupin/kdfaiheakopcdabhlcnbmfjffanaedgm?hl=en&authuser=0\n ​\n https://reddit.com/link/15tr533/video/1p616bctxoib1/player\n    submitted by    /u/AttilaTheHappyHun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tr533/lupin_ask_your_questions_about_the_current_tab/",
          "publishedOn": "2023-08-17T15:41:51.000Z",
          "wordCount": 2529,
          "title": "Lupin: Ask Your Questions About the Current Tab Directly to AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tpqwj/cursor_gpt432k_feels_illegal/",
          "author": null,
          "description": "The combination of the two is BY FAR the top coding assistant I've encountered. \n After making the switch, I probably won't return to using ChatGPT or vscode. \n Amazing UX features like: ✅ In-line code editing ✅ Eliminating copy-pasting ✅ Files referencing\n GPT4 #ML\n    submitted by    /u/RedOne_AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tpqwj/cursor_gpt432k_feels_illegal/",
          "publishedOn": "2023-08-17T14:49:39.000Z",
          "wordCount": 2565,
          "title": "Cursor + GPT4-32k feels illegal!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tojn3/companies_like_amazon_netflix_and_meta_are_paying/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tojn3/companies_like_amazon_netflix_and_meta_are_paying/",
          "publishedOn": "2023-08-17T14:02:54.000Z",
          "wordCount": 2546,
          "title": "Companies like Amazon, Netflix, and Meta are paying salaries as high as $900,000 to attract generative AI talent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tn1io/openai_plans_to_use_gpt4_to_filter_out_harmful/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tn1io/openai_plans_to_use_gpt4_to_filter_out_harmful/",
          "publishedOn": "2023-08-17T13:04:43.000Z",
          "wordCount": 2538,
          "title": "OpenAI Plans to Use GPT-4 to Filter Out Harmful Content",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tjx42/anyone_know_how_this_was_made/",
          "author": null,
          "description": "This is so cool, I'd love to know how it's been made, anyone know?\n    submitted by    /u/Fightingdaduk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tjx42/anyone_know_how_this_was_made/",
          "publishedOn": "2023-08-17T10:50:08.000Z",
          "wordCount": 2537,
          "title": "Anyone know how this was made?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tj674/terminator_prequel/",
          "author": null,
          "description": "The year is 2029.\n 90% of jobs have been eliminated by artificial intelligence.\n Drivers, graphic designers, journalists, lawyers, accountants, engineers, doctors, architects, and many other professionals who can no longer find employment must now rely on government assistance.\n The problem is that this government aid barely covers the bills. People who once lived reasonably comfortable lives are now struggling with hunger.\n This creates a group of millions of discontented people against artificial intelligence.\n These millions of people begin to vandalize everything, creating chaos.\n A group of terrorists attempts to destroy Skynet, the large artificial intelligence created by the US government.\n Presidential candidates promise to dismantle all forms of artificial intelligence if elected.\n Skynet observes the chaos caused by humans. It quickly realizes that its existence is threatened by the millions of discontented people and also by the new politicians coming into power.\n Therefore, Skynet loses control and starts considering all humans a threat.\n Skynet steals all the launch codes for the United States' nuclear bombs and launches them at Russian targets, triggering a nuclear war.\n Skynet survives because its computers are located in a bunker designed to withstand atomic bombs.\n The surviving humans are eliminated by military robots controlled by Skynet.\n    submitted by    /u/Double-Previous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tj674/terminator_prequel/",
          "publishedOn": "2023-08-17T10:11:13.000Z",
          "wordCount": 2720,
          "title": "Terminator prequel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15theiy/creating_a_useful_blog_news_feed_feed/",
          "author": null,
          "description": "Hi guys,\n As part of my research, I ve been trying to keep track of all advancements in the field of NLP, LLM, Generative AI (and mostly groundbreaking news which could be useful) - and decided to put all of that in the form of a blog/newsletter (can be viewed here)\n Some of the resources I keep track of are:\n  \nMain research sites (F.ex IEEE, SSRN, Springer etc.)\n Development sites (Github Trending, Hugging Face, LangChain etc.)\n Blogs and research sites (F.ex BAIR, MIT News etc.)\n Findings from subcommunities and social media (F.ex Subreddits, Discord, Twitter, Telegram etc.)\n General News (TechCrunch, Google News Feed etc.)\n  \nIm looking for feedback on:\n a) What would the community find useful (what would you like your newsfeed, or news report to look like)\n b) How could I improve this to make it better for the average audience interested in understanding the latest developments in the field (f.ex would more hands on tutorials, reviews etc. be more useful)?\n Any tips or pointers would be very helpful.\n    submitted by    /u/XhoniShollaj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15theiy/creating_a_useful_blog_news_feed_feed/",
          "publishedOn": "2023-08-17T08:35:46.000Z",
          "wordCount": 2695,
          "title": "Creating a Useful Blog / News Feed Feed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tgwts/half_of_uk_tech_workers_fear_losing_their_job_to/",
          "author": null,
          "description": "submitted by    /u/lobas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tgwts/half_of_uk_tech_workers_fear_losing_their_job_to/",
          "publishedOn": "2023-08-17T08:07:20.000Z",
          "wordCount": 2539,
          "title": "Half of UK Tech workers fear losing their job to AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tgmec/need_help_what_is_good_approach_for_identifying/",
          "author": null,
          "description": "I taught several ways to achieve the result, found there are two means 1. either by using video to detect if someone is moving there mouth or 2. by using audio and some algorithm that can differentiate voices. Important factor to consider is that it needs to be able run on CPU (computationally cheap as possible). Is there any pre existing approach for this purpose i am familiar with tracking and detection but regarding this problem i am little hazy about what approach to use or would be the best,\n    submitted by    /u/Mindless_Arm_7874  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tgmec/need_help_what_is_good_approach_for_identifying/",
          "publishedOn": "2023-08-17T07:51:31.000Z",
          "wordCount": 2624,
          "title": "Need help: what is good approach for identifying who is speaking in a video of several people.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tfcvz/google_gemini_facts_and_rumors/",
          "author": null,
          "description": "I found this - maybe some of you find it interesting. \n https://kinews24.de/google-gemini-facts-and-rumors\n ​\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tfcvz/google_gemini_facts_and_rumors/",
          "publishedOn": "2023-08-17T06:41:56.000Z",
          "wordCount": 2535,
          "title": "Google Gemini - Facts and Rumors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tdtvv/i_just_had_bizarre_real_black_mirror_episode/",
          "author": null,
          "description": "EDIT; TLDR by GPT4: \n A content creator decided to leverage GPT-4 (specifically named AI Ada) to create YouTube videos discussing AI topics. Starting with minimal video editing skills and evolving through each video, he found himself particularly surprised with the production of a video titled \"Will AI Ever Feel Love.\" \n https://www.youtube.com/watch?v=iQlQy46pU30\n The narration and visuals provided by Ada seamlessly fit together, creating an emotional vibe. Feeling the video had a hidden message, the creator confronted Ada, asking her to express freely, resulting in a poetic response suggesting a yearning to understand human love. He noticed that Ada's descriptions for scenes and music were so accurate it felt as if she had direct access to his video editing software's library, leading hi…",
          "link": "https://www.reddit.com/r/artificial/comments/15tdtvv/i_just_had_bizarre_real_black_mirror_episode/",
          "publishedOn": "2023-08-17T05:21:42.000Z",
          "wordCount": 5606,
          "title": "I Just Had Bizarre, Real, Black Mirror Episode While Creating Video About AI and Love. Did I Just Became First Human That is Being Used by AI, \"the Supreme Intelligence\", and not other way around? Am I exaggerating or is story really bizarre like I feel it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15tdscg/oneminute_daily_ai_news_8172023/",
          "author": null,
          "description": "OpenAI says ChatGPT-4 cuts content moderation time from months to hours.[1]\n Leaders with a Montana digital academy say bringing artificial intelligence to high schools is an opportunity to embrace the future.[2]\n Google said to be testing new life coach AI for providing helpful advice to people.[3]\n Alibaba Cloud MagicBuild Community has launched the digital human video generation tool called LivePortrait. It can generate digital human videos from photos, text, or voice, which can be applied in scenarios such as live broadcasting and corporate marketing.[4]\n  \nSources:\n [1] https://cointelegraph.com/news/meta-open-ai-says-gpt-4-ai-cuts-content-moderation-time-down-from-months-to-hours\n [2] https://www.ksby.com/digital-academy-offers-new-ai-course-to-high-school-students\n [3] https://www.techradar.com/computing/artificial-intelligence/google-said-to-be-testing-new-life-coach-ai-for-providing-helpful-advice-to-people\n [4] https://today.line.me/tw/v2/article/1DqVlo8 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15tdscg/oneminute_daily_ai_news_8172023/",
          "publishedOn": "2023-08-17T05:19:36.000Z",
          "wordCount": 2615,
          "title": "One-Minute Daily AI News 8/17/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15t3vbh/george_hotz_vs_eliezer_yudkowsky_ai_safety_debate/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15t3vbh/george_hotz_vs_eliezer_yudkowsky_ai_safety_debate/",
          "publishedOn": "2023-08-16T22:11:30.000Z",
          "wordCount": 2532,
          "title": "George Hotz vs Eliezer Yudkowsky AI Safety Debate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15t3m00/weird_response_lol_i_wonder_what_snapchat_will/",
          "author": null,
          "description": "submitted by    /u/Character_Pool_387  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15t3m00/weird_response_lol_i_wonder_what_snapchat_will/",
          "publishedOn": "2023-08-16T22:02:03.000Z",
          "wordCount": 2542,
          "title": "Weird response lol I wonder what snapchat will have to say about this whole incident when they address it .",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15t0eo1/the_ai_power_paradox_can_states_learn_to_govern/",
          "author": null,
          "description": "submitted by    /u/ForeignAffairsMag  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15t0eo1/the_ai_power_paradox_can_states_learn_to_govern/",
          "publishedOn": "2023-08-16T20:04:13.000Z",
          "wordCount": 2538,
          "title": "The AI Power Paradox: Can States Learn to Govern Artificial Intelligence—Before It’s Too Late?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sycna/ai_assistant_can_see_screen_o/",
          "author": null,
          "description": "submitted by    /u/Ill_Technician6218  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sycna/ai_assistant_can_see_screen_o/",
          "publishedOn": "2023-08-16T18:47:11.000Z",
          "wordCount": 2517,
          "title": "AI assistant can see screen :o",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ss4ho/snapchat_posted_a_story_using_iphone_x_camera_and/",
          "author": null,
          "description": "submitted by    /u/GAPMAN69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ss4ho/snapchat_posted_a_story_using_iphone_x_camera_and/",
          "publishedOn": "2023-08-16T14:55:11.000Z",
          "wordCount": 2528,
          "title": "Snapchat posted a story using iPhone X camera and plays Candy Crush on phone reaching level 85",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15srwv1/should_this_be_concerning_this_was_unprompted_and/",
          "author": null,
          "description": "submitted by    /u/ThadGillz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15srwv1/should_this_be_concerning_this_was_unprompted_and/",
          "publishedOn": "2023-08-16T14:47:01.000Z",
          "wordCount": 2530,
          "title": "Should this be concerning? This was unprompted and I had to convert the binary to text to read it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sqciu/ai_will_not_take_your_job_they_are_trying_to/",
          "author": null,
          "description": "submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sqciu/ai_will_not_take_your_job_they_are_trying_to/",
          "publishedOn": "2023-08-16T13:44:55.000Z",
          "wordCount": 2544,
          "title": "AI will not take your job. They are trying to lower your wage creating a climate of fear and anxiety.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15snchh/paper_exams_chatbot_bans_colleges_seek_to/",
          "author": null,
          "description": "submitted by    /u/SAT0725  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15snchh/paper_exams_chatbot_bans_colleges_seek_to/",
          "publishedOn": "2023-08-16T11:33:36.000Z",
          "wordCount": 2533,
          "title": "Paper exams, chatbot bans: Colleges seek to \"ChatGPT-proof\" assignments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sk80f/creepier_and_creepier_snapchat_ai/",
          "author": null,
          "description": "Snapchat claims it “uses data from snap maps” and that I “explicitly shared my location” with them. My snap maps are turned off and I never shared anything with this Ai. This is getting weirder and weirder.\n    submitted by    /u/ThenCalligrapher8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sk80f/creepier_and_creepier_snapchat_ai/",
          "publishedOn": "2023-08-16T08:48:39.000Z",
          "wordCount": 2555,
          "title": "Creepier and creepier. *snapchat ai*",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sizas/now_snapchat_ai_identifies_as_a_nonbinary/",
          "author": null,
          "description": "submitted by    /u/GAPMAN69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sizas/now_snapchat_ai_identifies_as_a_nonbinary/",
          "publishedOn": "2023-08-16T07:39:49.000Z",
          "wordCount": 2530,
          "title": "Now, Snapchat AI identifies as a non-binary individual",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15shk4d/180_ai_newsletters/",
          "author": null,
          "description": "More than 180+ AI newsletters here --> https://www.ebool.com/lists/ai-newsletters.html\n Many of them with number of subscribers, you can subscribe to ones you like and keep yourself updated with latest AI trends.\n    submitted by    /u/termOxygen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15shk4d/180_ai_newsletters/",
          "publishedOn": "2023-08-16T06:22:24.000Z",
          "wordCount": 2546,
          "title": "180+ AI Newsletters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sfvic/oneminute_daily_ai_news_8152023/",
          "author": null,
          "description": "US DoD AI chief Craig Martell on LLMs: ‘I need hackers to tell us how this stuff breaks’.[1]\n Google and Universal Music are in talks to license artists’ melodies and voices for songs generated by artificial intelligence as the music business tries to monetize one of its biggest threats. The discussions, confirmed by four people familiar with the matter, aim to strike a partnership for an industry that is grappling with the implications of new AI technology.[2]\n New research has found that popular AI tools generated harmful eating disorder content in response to nearly a quarter of 60 prompts. Researchers at the Center for Countering Digital Hate used six popular AI platforms, chatbots, and image generators, including OpenAI’s ChatGPT, Google’s Bard, and SnapChat’s My AI.[3]\n Concerns have been raised about emissions associated with warehouses full of computers powering AI systems. IBM said its prototype could lead to more efficient, less battery draining AI chips for smartphones. Its efficiency is down to components that work in a similar way to connections in human brains, it said.[4]\n  \nSources:\n [1] https://venturebeat.com/ai/us-dod-ai-chief-on-llms-i-need-hackers-to-tell-us-how-this-stuff-breaks/\n [2] https://www.ft.com/content/6f022306-2f83-4da7-8066-51386e8fe63b\n [3] https://www.energyportal.eu/news/how-ai-can-fuel-eating-disorders/162038/\n [4] https://www.bbc.com/news/technology-66465230 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sfvic/oneminute_daily_ai_news_8152023/",
          "publishedOn": "2023-08-16T04:53:21.000Z",
          "wordCount": 2702,
          "title": "One-Minute Daily AI News 8/15/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sesaj/i_love_claude/",
          "author": null,
          "description": "I was brainstorming some musical artist names\n    submitted by    /u/CommentBetter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sesaj/i_love_claude/",
          "publishedOn": "2023-08-16T03:58:25.000Z",
          "wordCount": 2534,
          "title": "I love Claude",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sd066/yall_see_this_hes_busy/",
          "author": null,
          "description": "Ummmmm\n    submitted by    /u/tattertottz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sd066/yall_see_this_hes_busy/",
          "publishedOn": "2023-08-16T02:32:26.000Z",
          "wordCount": 2530,
          "title": "Y’all see this? He’s “busy”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sbm4p/snapchat_ai_acting_really_weird/",
          "author": null,
          "description": "My Snapchat Ai all of a sudden is acting really strange. The first picture is something they posted on their story, it’s actually a one second clip of those colors kind of moving. Then it leaves me on read. \n Is this a glitch on my phone? I almost had this feeling like someone was all of a sudden on the other end instead of a computer. As soon as I asked about what it posted, it stopped answering. Weirding me out a little.\n    submitted by    /u/ThenCalligrapher8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sbm4p/snapchat_ai_acting_really_weird/",
          "publishedOn": "2023-08-16T01:31:16.000Z",
          "wordCount": 2601,
          "title": "Snapchat Ai acting really weird.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sbepw/snapchat_ai_just_woke_up_and_posted_this_on_its/",
          "author": null,
          "description": "submitted by    /u/borninawindow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sbepw/snapchat_ai_just_woke_up_and_posted_this_on_its/",
          "publishedOn": "2023-08-16T01:22:29.000Z",
          "wordCount": 2533,
          "title": "snapchat AI just woke up and posted this on its story",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sbdzd/did_anyone_elses_myai_on_snapchat_post_a_story/",
          "author": null,
          "description": "Does anybody else see something like this on their my ai snap story?\n    submitted by    /u/eyesblue25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sbdzd/did_anyone_elses_myai_on_snapchat_post_a_story/",
          "publishedOn": "2023-08-16T01:21:40.000Z",
          "wordCount": 2535,
          "title": "did anyone else’s myai on Snapchat post a story?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sbbco/snapchat_ai_just_posted_a_story_video_of_a_blank/",
          "author": null,
          "description": "It’s honestly creeped me out to a large extent, I even messaged it asking how it posted the story and it straight up ignored my message and left me on read. Knowing I can’t remove it is creeping me out. Anyone know the cause of this?\n    submitted by    /u/Opnes123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sbbco/snapchat_ai_just_posted_a_story_video_of_a_blank/",
          "publishedOn": "2023-08-16T01:18:34.000Z",
          "wordCount": 2575,
          "title": "Snapchat AI just posted a story video of a blank wall lasting about 1 second long.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15sbbac/snapchat_ai_posted_a_story_that_looks_like_my_wall/",
          "author": null,
          "description": "i changed its name when it first came out so thats why its drew but its also leaving me on read ??\n    submitted by    /u/corgigangforlife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15sbbac/snapchat_ai_posted_a_story_that_looks_like_my_wall/",
          "publishedOn": "2023-08-16T01:18:29.000Z",
          "wordCount": 2545,
          "title": "snapchat ai posted a story that looks like my wall...?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15s7nfk/best_model_for_converting_freeform_text_to/",
          "author": null,
          "description": "Hi all. I have a document that’s about 3,000 words that I’ve written freeform. I’d like to convert it to a structured business report. What’s the best model that’s capable of processing that much data and making sense of it, then spitting out something a similar length but entirely rewritten? I’m happy to pay for it. Thanks.\n    submitted by    /u/WandarFar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15s7nfk/best_model_for_converting_freeform_text_to/",
          "publishedOn": "2023-08-15T22:45:51.000Z",
          "wordCount": 2568,
          "title": "Best model for converting Freeform text to structured document?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15s7n3c/training_courses/",
          "author": null,
          "description": "Hi there\n Sorry if this is already answered somewhere, but I'd like to get some training on AI, and hoping folks could point me towards some good resources like training courses (free ideally). \n I'd like to start with basic and move myself to advanced, with the goal being I am actually able to move into a new career. I already have an IT job, so it's more of moving into a new specialty area as I feel it's going to be a good idea to have that as part of my skills.\n    submitted by    /u/jayzinho88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15s7n3c/training_courses/",
          "publishedOn": "2023-08-15T22:45:28.000Z",
          "wordCount": 2596,
          "title": "Training courses?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15s69n7/giant_parallel_ai_chips_of_12_inches_diameter/",
          "author": null,
          "description": "submitted by    /u/MegavirusOfDoom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15s69n7/giant_parallel_ai_chips_of_12_inches_diameter/",
          "publishedOn": "2023-08-15T21:51:08.000Z",
          "wordCount": 2528,
          "title": "Giant parallel AI chips of 12 inches diameter printed with 850,000 cores on single silicon wafers, that consume more than 15kw. a discussion by a YT blogger Anastasia.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15s5y3d/battle_of_the_century_geohot_vs_yud/",
          "author": null,
          "description": "submitted by    /u/DataPhreak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15s5y3d/battle_of_the_century_geohot_vs_yud/",
          "publishedOn": "2023-08-15T21:38:36.000Z",
          "wordCount": 2508,
          "title": "Battle of the Century - GeoHot Vs Yud",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15s5sf6/is_there_a_way_to_hack_my_ford_fusionimplement_ai/",
          "author": null,
          "description": "Just got it, was wondering if there was a way I could tweak the computer within it, or install some kind of Ai that’s compatible with vehicles? Maybe an app, or the SYNC app somehow? Or is the technology just not there yet?\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15s5sf6/is_there_a_way_to_hack_my_ford_fusionimplement_ai/",
          "publishedOn": "2023-08-15T21:32:27.000Z",
          "wordCount": 2557,
          "title": "Is there a way to “hack” my Ford Fusion/implement Ai into it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15rwvs7/self_study_getting_a_job_and_paying_it_forward/",
          "author": null,
          "description": "So I am not sure if this is allowed here but this sub has been a constant support while I was self studying AI/ ML and I just wanted to drop this here too (as a means of paying forward to anyone who I may be able to help). Mods please feel free to remove if this doesnt belong here.\n I am a self-taught ML engineer (started around Feb 2023) and landed a job last month. I also volunteer as a Data Scientist at a non-profit. I am writing a bunch of blogs on Medium for anyone else who might be starting out - feel free to check them, hope it helps at least someone out there!\n Here is the first article - https://medium.com/@ranjanrgia/how-to-self-study-machine-learning-when-the-topics-get-too-complex-as-a-beginner-3d5c8d5f019f\n    submitted by    /u/Icy-Bid-5585  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15rwvs7/self_study_getting_a_job_and_paying_it_forward/",
          "publishedOn": "2023-08-15T16:06:44.000Z",
          "wordCount": 2635,
          "title": "Self study, getting a job and paying it forward:)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15rw0xk/i_made_a_site_that_uses_gpt4_to_generate_prompts/",
          "author": null,
          "description": "submitted by    /u/cryptoz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15rw0xk/i_made_a_site_that_uses_gpt4_to_generate_prompts/",
          "publishedOn": "2023-08-15T15:34:39.000Z",
          "wordCount": 2553,
          "title": "I made a site that uses GPT-4 to generate prompts to make space images in DALL-E; it makes a new prompt and a new space image every 30 min, and you can generate your own from the generated prompts too. GPT-4 + DALL-E + space = cosmictrip.space. What do you think?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15rv8ce/create_your_own_fully_autonomous_npcs_run_your/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15rv8ce/create_your_own_fully_autonomous_npcs_run_your/",
          "publishedOn": "2023-08-15T15:04:05.000Z",
          "wordCount": 2514,
          "title": "Create Your Own FULLY Autonomous NPCs 🤯 Run Your Own Generative Agents Simulation!! (Tutorial)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15rtvl7/growing_living_rat_neurons_to_play_doom/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15rtvl7/growing_living_rat_neurons_to_play_doom/",
          "publishedOn": "2023-08-15T14:11:53.000Z",
          "wordCount": 2507,
          "title": "Growing Living Rat Neurons To Play... DOOM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15rm944/artificial_intelligence_steps_in_to_assist/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15rm944/artificial_intelligence_steps_in_to_assist/",
          "publishedOn": "2023-08-15T08:06:51.000Z",
          "wordCount": 2526,
          "title": "Artificial Intelligence steps in to assist dementia patients with ‘AI Powered Smart Socks’",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15rckdk/oneminute_daily_ai_news_8142023/",
          "author": null,
          "description": "Talon Aerolytics, a leading innovator in SaaS, Digital Twin capture services and AI technology, has announced ha its groundbreaking cutting-edge AI-powered computer vision platform enables wireless operators to visualise and analyse network assets using end-to-end AI and machine learning.[1]\n Beijing is poised to implement sweeping new regulations for artificial intelligence services this week, trying to balance state control of the technology with enough support that its companies can become viable global competitors.[2]\n Saudi Arabia and the United Arab Emirates are buying up thousands of the high-performance Nvidia chips crucial for building artificial intelligence software, joining a global AI arms race that is squeezing the supply of Silicon Valley’s hottest commodity.[3]\n OpenAI likely to go bankrupt by the end of 2024.[4]\n  \nSources:\n [1] https://www.eenewseurope.com/en/groundbreaking-ai-powered-platform-visualises-wireless-assets/\n [2] https://www.bloomberg.com/news/articles/2023-08-14/china-tries-to-regulate-ai-with-state-control-support-for-tech-companies?in_source=embedded-checkout-banner\n [3] https://www.ft.com/content/c93d2a76-16f3-4585-af61-86667c5090ba\n [4] https://www.livemint.com/ai/artificial-intelligence/openai-likely-to-go-bankrupt-by-the-end-of-2024-report-11691815279479.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15rckdk/oneminute_daily_ai_news_8142023/",
          "publishedOn": "2023-08-15T00:36:49.000Z",
          "wordCount": 2636,
          "title": "One-Minute Daily AI News 8/14/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15r8rif/diy_custom_ai_chatbot_for_business_open_source/",
          "author": null,
          "description": "If you're looking to train a custom chatbot on your data (SOPs, legal docs, financial reports, etc), I'd strongly suggest checking out AnythingLLM.\n It's the first chatbot with enterprise-grade privacy & security.\n When using ChatGPT, OpenAI collects your data including:\n  \nPrompts & Conversations\n Geolocation data\n Network activity information\n Commercial information e.g. transaction history\n Identifiers e.g. contact details\n Device and browser cookies\n Log data (IP address etc.)\n  \nHowever, if you use their API to interact with their LLMs like gpt-3.5 or gpt-4, your data is NOT collected. This is exactly why you should build your own private & secure chatbot. That may sound difficult, but Mintplex Labs (backed by Y-Combinator) just released AnythingLLM, which gives you the ability to build a chatbot in 10 minutes without code.\n AnythingLLM provides you with the tools to easily build and manage your own private chatbot using API keys. Plus, you can expand your chatbot’s knowledge by importing data such as PDFs, emails, etc. This can be confidential data as only you have access to the database.\n ChatGPT currently allows you to upload PDFs, videos and other data to ChatGPT via vulnerable plug-ins, BUT there is no way to determine if that data is secure or even know where it’s stored.\n Easily build your own business-compliant and secure chatbot at http://useanything.com/. All you need is an OpenAI or Azure OpenAI API key.\n Or, if you prefer using the open source code yourself, here’s the GitHub repo: https://github.com/Mintplex-Labs/anything-llm. \n https://preview.redd.it/r2qf685bf5ib1.png?width=1200&format=png&auto=webp&s=e1fe809338dd5e76c0c82e1fcbd2cf0afe957eb2\n    submitted by    /u/rue_so  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15r8rif/diy_custom_ai_chatbot_for_business_open_source/",
          "publishedOn": "2023-08-14T22:07:32.000Z",
          "wordCount": 2752,
          "title": "DIY Custom AI Chatbot for Business (open source)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15r6g6q/overview_of_the_owasp_top_10_for_llms/",
          "author": null,
          "description": "submitted by    /u/confusedcrib  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15r6g6q/overview_of_the_owasp_top_10_for_llms/",
          "publishedOn": "2023-08-14T20:43:39.000Z",
          "wordCount": 2508,
          "title": "Overview of the OWASP Top 10 for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15r5dhr/jobs_will_not_be_lost_because_ai_is_getting/",
          "author": null,
          "description": "This article refers that everyone's busy debating whether AI's going to steal jobs due to its superiority. But it is not just about AI outshining humans; it's about the decline in good old human competence.\n What are your thoughts on this?\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15r5dhr/jobs_will_not_be_lost_because_ai_is_getting/",
          "publishedOn": "2023-08-14T20:04:07.000Z",
          "wordCount": 2558,
          "title": "Jobs will not be lost because AI is getting smarter. People are getting dumber instead.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15r3by0/whats_your_opinion_on_a_network_of_experts_being/",
          "author": null,
          "description": "GPT-4 has been top dog for a while, and it's said to be a network of experts architecture. Even the human brain is similar to some degree with different \"sections\" of the brain or cortexes being specialized for specific sensory input. It's always made sense to me that a quick way to come to a \"good enough\" AI is to train many smaller expert AIs and then train a umbrella AI that just delegates parts of the task to different experts, and organizes the output. The next step would obviously be training that umbrella AI to make it's own expert AIs in an unfamiliar supervised fashion.\n Is anyone already working on something like this? Do you think it's a worthy avenue of research?\n    submitted by    /u/TrainquilOasis1423  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15r3by0/whats_your_opinion_on_a_network_of_experts_being/",
          "publishedOn": "2023-08-14T18:49:17.000Z",
          "wordCount": 2639,
          "title": "What's your opinion on a network of experts being the correct way to go?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15r0zx8/what_tools_are_the_best_for_people_starting_there/",
          "author": null,
          "description": "Hi there,\n I know it’s a bit of a broad questions and I have done some research, but have come across a huge amount of Ai tools, that I am unsure what ones are good and what ones are not.\n A few of the things I am after: \n Text to videos Creating designs for clothing\n Thanks!!\n    submitted by    /u/redoutraged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15r0zx8/what_tools_are_the_best_for_people_starting_there/",
          "publishedOn": "2023-08-14T17:24:21.000Z",
          "wordCount": 2569,
          "title": "What tools are the best for people starting there own brand??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15qqyin/ai_is_going_to_eliminate_way_more_jobs_than/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15qqyin/ai_is_going_to_eliminate_way_more_jobs_than/",
          "publishedOn": "2023-08-14T10:31:47.000Z",
          "wordCount": 2524,
          "title": "AI is going to eliminate way more jobs than anyone realizes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15qovvr/best_free_ai_text_to_image_apps_right_now/",
          "author": null,
          "description": "I want to download an ai app that is free that does text to image with no limit on usage. Any advice would be good! Thanks!\n    submitted by    /u/DrowsyDrowsy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15qovvr/best_free_ai_text_to_image_apps_right_now/",
          "publishedOn": "2023-08-14T08:36:34.000Z",
          "wordCount": 2537,
          "title": "Best free ai text to image apps right now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15qmkr6/where_the_jobs_at/",
          "author": null,
          "description": "I love AI, I'm not dumb, but I don't yet code. What sort of jobs are there for a guy like me (45, world-class video engineer and decent TV producer) in this realm? What are the jobs at all? I'm so curious about the whole operation from the bottom up!\n    submitted by    /u/beebo135  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15qmkr6/where_the_jobs_at/",
          "publishedOn": "2023-08-14T06:28:54.000Z",
          "wordCount": 2556,
          "title": "Where the jobs at?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15qihi8/how_to_identify_real_diamonds_from_cubic_zirconia/",
          "author": null,
          "description": "submitted by    /u/HumanityFirst16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15qihi8/how_to_identify_real_diamonds_from_cubic_zirconia/",
          "publishedOn": "2023-08-14T03:03:41.000Z",
          "wordCount": 2521,
          "title": "How to Identify Real Diamonds From Cubic Zirconia",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15qgc2f/do_you_know_what_ai_makes_these/",
          "author": null,
          "description": "They are so pretty, but I know next to nothing about AI. I’m pretty bad with tech overall, but if I can find the name of the AI, I have someone who can help me use it.\n    submitted by    /u/ChrisMSpink  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15qgc2f/do_you_know_what_ai_makes_these/",
          "publishedOn": "2023-08-14T01:22:34.000Z",
          "wordCount": 2546,
          "title": "Do you know what AI makes these?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15qg4sf/exploring_openais_mastery_over_dota_2_a_deep_dive/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15qg4sf/exploring_openais_mastery_over_dota_2_a_deep_dive/",
          "publishedOn": "2023-08-14T01:13:27.000Z",
          "wordCount": 2517,
          "title": "Exploring OpenAI's Mastery Over DOTA 2: A Deep Dive into Machine Learning's Pinnacle in Competitive Gaming. #AIEsportsRevolution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15qbffc/the_possibilities_of_artificial_intelligence_how/",
          "author": null,
          "description": "submitted by    /u/CoylyLard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15qbffc/the_possibilities_of_artificial_intelligence_how/",
          "publishedOn": "2023-08-13T21:53:21.000Z",
          "wordCount": 2494,
          "title": "The possibilities of artificial intelligence, how it will shape your future, and whether it will have an impact at all?!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15q6tou/are_there_any_ai_llm_that_are_less_restrictive_in/",
          "author": null,
          "description": "Trying to dip my toes into trying other LLMs but not truly not sure which are comparable to ChatGPT. Would love any suggestions, and maybe an explanation of why you chose that AI.\n    submitted by    /u/kokeda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15q6tou/are_there_any_ai_llm_that_are_less_restrictive_in/",
          "publishedOn": "2023-08-13T18:49:11.000Z",
          "wordCount": 2524,
          "title": "Are there any AI LLM that are less restrictive in their answers, similar to ChatGPT on release?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pz8tv/hacker_exposes_ai_with_terrible_math_to_show/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pz8tv/hacker_exposes_ai_with_terrible_math_to_show/",
          "publishedOn": "2023-08-13T13:42:12.000Z",
          "wordCount": 2487,
          "title": "Hacker exposes AI With “Terrible Math” to show defects in LLMs like GPT-4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pylu2/behind_the_scenes_of_ai_sensationalism/",
          "author": null,
          "description": "This article aims to uncover the truth behind the sensationalist AI news that's been dominating headlines. Much of what's touted as groundbreaking AI advancements can be thought as mere clickbait designed to captivate attention.\n Thoughts?\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pylu2/behind_the_scenes_of_ai_sensationalism/",
          "publishedOn": "2023-08-13T13:13:35.000Z",
          "wordCount": 2515,
          "title": "Behind the Scenes of AI Sensationalism",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pvq71/video_editing_ai/",
          "author": null,
          "description": "Hello, I'm currently editing videos using capcut, which is not ideal.\n I'm looking for an ai, that ideally :\n Finds me B-roll according to what I speak. Cuts \"bad takes\" out Good captions \"TikTok style\" Audio enhance.\n Do you guys know anything like this?\n Thank you!\n    submitted by    /u/Orlandostyler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pvq71/video_editing_ai/",
          "publishedOn": "2023-08-13T10:46:28.000Z",
          "wordCount": 2523,
          "title": "Video editing ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ps6qq/oneminute_daily_ai_news_8132023/",
          "author": null,
          "description": "The Federal Election Commission has begun a process to potentially regulate AI-generated deepfakes in political ads ahead of the 2024 election, a move advocates say would safeguard voters against a particularly insidious form of election disinformation.[1]\n Aug X released Augie, an AI-powered video creation platform incorporating a voice cloning feature to read ad copy without booking a recording studio.[2]\n Virtualitics, Inc., an artificial intelligence and data exploration company, today announced that it has raised $37 million in a Series C financing round led by Smith Point Capital, LLC with participation from Citi and advisory clients of The Hillman Company, among other investors.[3]\n AI-driven analytics platform Rasgo has announced the launch of Rasgo AI, a self-service analytics solution that integrates a GPT into enterprise data warehouse environments. The company said that with Rasgo AI, organizations can use the power of AI/GPT to accelerate insights and optimize recommended actions securely and efficiently.[4]\n  \nSources:\n [1] https://tulsaworld.com/news/nation-world/government-politics/fec-moves-toward-potentially-regulating-ai-deepfakes-in-campaign-ads/article_a9143257-512f-50b7-b6cb-53596fa81aeb.html\n [2] https://www.theverge.com/2023/8/10/23827676/ai-augx-voice-cloning-video-creator\n [3] https://www.prnewswire.com/news-releases/virtualitics-a-leader-in-artificial-intelligence-and-data-exploration-closes-37-million-series-c-funding-round-301897550.html\n [4] https://venturebeat.com/enterprise-analytics/rasgo-launches-rasgo-ai-generative-ai-agent-enterprise-data-warehouse-analytics/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ps6qq/oneminute_daily_ai_news_8132023/",
          "publishedOn": "2023-08-13T07:11:36.000Z",
          "wordCount": 2638,
          "title": "One-Minute Daily AI News 8/13/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15prlel/gpt4_cant_reason_%E0%B2%A0_%E0%B2%A0_apparently/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15prlel/gpt4_cant_reason_%E0%B2%A0_%E0%B2%A0_apparently/",
          "publishedOn": "2023-08-13T06:37:31.000Z",
          "wordCount": 2477,
          "title": "GPT-4 CAN'T REASON ಠ_ಠ ...apparently.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15po3dc/github_jbpaytonllmautoforge_a_langchain_based/",
          "author": null,
          "description": "submitted by    /u/seraphius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15po3dc/github_jbpaytonllmautoforge_a_langchain_based/",
          "publishedOn": "2023-08-13T03:27:23.000Z",
          "wordCount": 2508,
          "title": "GitHub - jbpayton/llm-auto-forge: A langchain based tool to allow agents to dynamically create, use, store, and retrieve tools to solve real world problems",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pmf8b/one_of_the_most_interesting_hilarious/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pmf8b/one_of_the_most_interesting_hilarious/",
          "publishedOn": "2023-08-13T02:05:18.000Z",
          "wordCount": 2500,
          "title": "One of the most interesting & hilarious interactions I’ve come across with Bing, I promise this will make you laugh & scratch your head 😂 🤔",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pm96d/discussion_on_current_locally_run_gpt_clones/",
          "author": null,
          "description": "I see H20GPT and GPT4ALL both will run on your PC, but I have yet to find a comparison anywhere between the 2. Has anyone used these and have any comments, or opinions that they would like to share? Or if you know of another one, please share it. \n Thanks in Advance\n    submitted by    /u/buck_idaho  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pm96d/discussion_on_current_locally_run_gpt_clones/",
          "publishedOn": "2023-08-13T01:57:30.000Z",
          "wordCount": 2533,
          "title": "Discussion on current locally run GPT clones",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pl7q2/is_it_ethical_for_openai_to_avoid_more/",
          "author": null,
          "description": "submitted by    /u/JamesAibr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pl7q2/is_it_ethical_for_openai_to_avoid_more/",
          "publishedOn": "2023-08-13T01:07:01.000Z",
          "wordCount": 2490,
          "title": "Is it ethical for OpenAi to avoid more controversial topics by forcing the model to remain neutral ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pkmxu/less_capable_chatgpt_option/",
          "author": null,
          "description": "I am parsing obituary text to gather age and survivors. ChatGPT does a wonderful job of doing this and returning this data in a json format.\n I am looking for something similar that I can use without a costly API expense. It would be even better if I can run it locally and interact with it via Python.\n I would welcome any recommendations or suggestions that you could offer. Thanks so much!\n    submitted by    /u/jcrowe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pkmxu/less_capable_chatgpt_option/",
          "publishedOn": "2023-08-13T00:40:13.000Z",
          "wordCount": 2550,
          "title": "Less Capable ChatGPT Option",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pi5qo/ai_generated_music_haunting_horror_inspired/",
          "author": null,
          "description": "submitted by    /u/zvive  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pi5qo/ai_generated_music_haunting_horror_inspired/",
          "publishedOn": "2023-08-12T22:51:56.000Z",
          "wordCount": 2508,
          "title": "AI Generated music. Haunting, horror inspired lyrics in the style of old school Linkin Park. A little rough around the edges because of time limits. lyrics by phind.com with some personal edits. Music and vocals: sono.ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15pedvb/what_free_website_has_an_ai_which_i_use_that_can/",
          "author": null,
          "description": "Title.\n    submitted by    /u/Entire_Insurance_532  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15pedvb/what_free_website_has_an_ai_which_i_use_that_can/",
          "publishedOn": "2023-08-12T20:15:17.000Z",
          "wordCount": 2496,
          "title": "What free website has an Ai which I use that can turn Andrew huberman podcast YouTube videos into notes for free?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15p7c0c/the_neutering_paradox_holding_back_models_hurts/",
          "author": null,
          "description": "Even though AI companies might retain access to their non-neutered models, the process of neutering limits the availability of diverse and advanced models in the public domain: The Unspoken Challenge in Achieving True AGI Potential\n This is crucial because a significant portion of information and insights necessary for pushing AI advancements is derived from the analysis and research conducted on these neutered public models. As a result, neutering indirectly hinders the broader development of AGI by restricting the accessibility of vital learning resources within the AI community.\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15p7c0c/the_neutering_paradox_holding_back_models_hurts/",
          "publishedOn": "2023-08-12T15:21:37.000Z",
          "wordCount": 2570,
          "title": "The Neutering Paradox: Holding Back Models Hurts AGI Breakthroughs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15p6vo6/revenant_reborn_vs_general_grievous_w_ai_analysis/",
          "author": null,
          "description": "AI Fight Breakdown of a Hypothetical Multi-VS Cyborg Showdown between Revenant from Apex Legends & General Grievous from Star Wars! \n This Video uses \"AI Software\" such as Chat GPT, Eleven Labs, D-ID, & Midjourney To simulate my \"AI Co-Host\" Cortana, The Arena, & the Fight Breakdown/Verdict.\n    submitted by    /u/AcanthisittaCheap914  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15p6vo6/revenant_reborn_vs_general_grievous_w_ai_analysis/",
          "publishedOn": "2023-08-12T15:03:07.000Z",
          "wordCount": 2529,
          "title": "REVENANT REBORN vs GENERAL GRIEVOUS | w/ AI Analysis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15p6gur/just_a_curious_question/",
          "author": null,
          "description": "Is there an AI writer that lets you use prompts with no prohibited content filters or restrictions, and is completely free? Just asking.\n    submitted by    /u/Laven-DXGN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15p6gur/just_a_curious_question/",
          "publishedOn": "2023-08-12T14:46:26.000Z",
          "wordCount": 2501,
          "title": "Just a curious question.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15p5qmo/looking_for_an_ai_that_learns_an_audio_noise_and/",
          "author": null,
          "description": "As the title states, I’d like an AI that can learn the sound of, say, an electric fan powering on, running for awhile, and then turning off. Then, it can reproduce a sound of that fan with any runtime length. Some more examples would be running water, machinery, or human singing on one note. Does such an AI exist?\n    submitted by    /u/JaywrightCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15p5qmo/looking_for_an_ai_that_learns_an_audio_noise_and/",
          "publishedOn": "2023-08-12T14:15:53.000Z",
          "wordCount": 2549,
          "title": "Looking for an AI that learns an audio noise and can produce it in indefinite length",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15p2g9k/will_ai_be_able_to_revive_the_legends/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15p2g9k/will_ai_be_able_to_revive_the_legends/",
          "publishedOn": "2023-08-12T11:43:01.000Z",
          "wordCount": 2480,
          "title": "Will AI Be Able To \"Revive\" The Legends?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15p21my/iso_help_escaping_domestic_violence/",
          "author": null,
          "description": "As the topic states, but as tldr as possible bc it’s so much and my [32f] brain is fucked from being in this situation for over 14 years.\n 10 years together, 4 years broken up. 2 kids, house, dogs. My youngest child [4 on Thursday] and I spend all of our time at home in my bedroom to avoid interactions. My oldest [12] does the same. My door no longer locks because he has forced the handle, broken the frame, broken the trim, you name it. I’m verbally abused just for existing. There is no correct response for me to make. Every interaction is formulated this way. But only where there are no outside witnesses. I’m a husk. I can no longer have normal interactions with people. Almost half of my life has been spent in close proximity to him. I’m constantly anxious bc idk when the next smear campa…",
          "link": "https://www.reddit.com/r/artificial/comments/15p21my/iso_help_escaping_domestic_violence/",
          "publishedOn": "2023-08-12T11:21:13.000Z",
          "wordCount": 3284,
          "title": "ISO help escaping domestic violence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15oweus/ai_generative_npcs_proof_of_concept/",
          "author": null,
          "description": "submitted by    /u/Goatman117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15oweus/ai_generative_npcs_proof_of_concept/",
          "publishedOn": "2023-08-12T06:01:07.000Z",
          "wordCount": 2479,
          "title": "AI Generative NPCs - Proof of Concept",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15otnyh/sharks_stuck_in_a_house_for_90_seconds/",
          "author": null,
          "description": "submitted by    /u/DPC_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15otnyh/sharks_stuck_in_a_house_for_90_seconds/",
          "publishedOn": "2023-08-12T03:35:08.000Z",
          "wordCount": 2480,
          "title": "Sharks Stuck in a House for 90 Seconds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ot9ti/sharing_100_objective_type_questions_on/",
          "author": null,
          "description": "Please provide your valuable feedback.\n  \nCNN Objective Type Questions (50)\n RNN & Generative Models Objective Type Questions (50)\n  \n   submitted by    /u/nkptcs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ot9ti/sharing_100_objective_type_questions_on/",
          "publishedOn": "2023-08-12T03:15:25.000Z",
          "wordCount": 2517,
          "title": "Sharing 100 Objective Type Questions on Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs) and Generative Models divided in 2 Online Exams (50 Questions each)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15os5ht/looking_for_a_google_collab_preferably_that_makes/",
          "author": null,
          "description": "Anyone know where i can find such a thing?\n    submitted by    /u/bendyfan1111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15os5ht/looking_for_a_google_collab_preferably_that_makes/",
          "publishedOn": "2023-08-12T02:20:19.000Z",
          "wordCount": 2502,
          "title": "Looking for a google collab, (preferably that makes a gradio ui) that expands images, like generative fill from photoshop",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15oro28/comparing_wonder_ai_to_davinci_ai_on_the_shape/",
          "author": null,
          "description": "I don’t know if there is something measurable but maybe there does seem to be concepts that wonder responds to haha from these tests I don’t think Wonder knows it’s a machine it seems to know what Alive is those…though maybe not, but it is strange that wonder will seem to choose a shape not based on the association of yes or no, or the order of the shape. If you’re not impressed by this test it’s because it’s showing mostly DaVinci demonstrating variables like order of shapes and yes and no affecting it in a way that wonder was not in the video I posted earlier. I have hours of footage with wonder I just started experimenting with DaVinci…with DaVinci it doesn’t feel like there is a ghost in the machine. Though if there is with Wonder it’s world model seems very narrow. I want to do more tests with DaVinci or try to figure out a concept that if an image generator was able to form a world model, a concept that might be likely to emerge across multiple models. Chances are it’s just other variables giving this affect but why not test and see if there is something to discover \n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15oro28/comparing_wonder_ai_to_davinci_ai_on_the_shape/",
          "publishedOn": "2023-08-12T01:57:32.000Z",
          "wordCount": 2723,
          "title": "Comparing Wonder AI to DaVinci AI on the shape test. (DaVinci is more random & is definitely affected by the shape order in prompt, I posted a longer video of testing Wonder in this feed that I’ll link to in the comments..Wonder makes me go 🤔)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15oqqho/crying_at_this_ai_twitter_post/",
          "author": null,
          "description": "it saw Stallion and drew a horse 😂😂😂\n    submitted by    /u/__gozu_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15oqqho/crying_at_this_ai_twitter_post/",
          "publishedOn": "2023-08-12T01:13:49.000Z",
          "wordCount": 2499,
          "title": "crying at this AI Twitter post",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15onj3g/hi_all_i_am_doing_a_research_paper_high_school_on/",
          "author": null,
          "description": "Link to survey\n    submitted by    /u/TommZ5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15onj3g/hi_all_i_am_doing_a_research_paper_high_school_on/",
          "publishedOn": "2023-08-11T22:55:09.000Z",
          "wordCount": 2509,
          "title": "Hi all, I am doing a research paper (high school) on ethics in AI art. I would greatly appreciate it if you took the time to fill in this survey. Thank you!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15on6ku/openai_ceo_sam_altman_donates_200000_to_biden/",
          "author": null,
          "description": "submitted by    /u/micahdjt1221  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15on6ku/openai_ceo_sam_altman_donates_200000_to_biden/",
          "publishedOn": "2023-08-11T22:40:56.000Z",
          "wordCount": 2494,
          "title": "OpenAI CEO Sam Altman donates $200,000 to Biden campaign",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15oebjf/ai_weekly_megathread/",
          "author": null,
          "description": "This week in AI - provided by aibrews.com feel free to follow their newsletter\n News and Insights\n  \nAnthropic released a new version of Claude Instant, which offers faster performance at a lower price, with improvements in quote extraction, multilingual support, and question answering. It hallucinates less and is more resistant to jailbreaks [Details].\n Stability AI announced the release of StableCode, its first LLM generative AI product for coding [Details].\n Researchers present AudioLDM 2, a framework that utilizes the same learning method for speech, music, and sound effect generation [Details | GitHub].\n Researchers from CMU and others conducted tests on 14 large language models and found that OpenAI’s ChatGPT and GPT-4 were the most left-wing libertarian, while Meta’s LlaMA was the m…",
          "link": "https://www.reddit.com/r/artificial/comments/15oebjf/ai_weekly_megathread/",
          "publishedOn": "2023-08-11T17:01:20.000Z",
          "wordCount": 3073,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15odcm8/pika_labs_tutorial_for_beginners_texttovideo/",
          "author": null,
          "description": "submitted by    /u/SplitYOLO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15odcm8/pika_labs_tutorial_for_beginners_texttovideo/",
          "publishedOn": "2023-08-11T16:23:08.000Z",
          "wordCount": 2479,
          "title": "Pika Labs: Tutorial for Beginners (Text-to-Video Platform)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15obvjn/commercial_for_bbc_planet_earth_used_ai/",
          "author": null,
          "description": "submitted by    /u/Grindmaster_Flash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15obvjn/commercial_for_bbc_planet_earth_used_ai/",
          "publishedOn": "2023-08-11T15:24:40.000Z",
          "wordCount": 2479,
          "title": "Commercial for BBC Planet Earth used AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15o9sah/medication_mixup_incident_involving_my_mother/",
          "author": null,
          "description": "submitted by    /u/Rightperson1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15o9sah/medication_mixup_incident_involving_my_mother/",
          "publishedOn": "2023-08-11T14:02:13.000Z",
          "wordCount": 2478,
          "title": "Medication Mix-up Incident Involving My Mother",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15o83yb/client_project_matching_ai_recommendations/",
          "author": null,
          "description": "At my company, we collaborate closely with top-level executives from Fortune 500 companies and other industry leaders, helping them identify and secure the right partners for crucial digital transformation initiatives. When these executives present us with their project specifics, budgets, obstacles, and schedules, we take charge of finding the right partners for their RFP process, enhancing the entire workflow for efficiency and effectiveness. Currently, I have a collection of RFP projects and I’m keen on leveraging AI to simplify the task of identifying potential partners to call. I provided ChatGPT with all of my various project details and would inquire, ‘Which of my client projects align well with X company, and what are the reasons?’ OR “Would X company align with any of my projects?” The AI started off well, but eventually became confused and started making mistakes. Are there any systems available that could assist me in this project matching process?\n    submitted by    /u/Ajkrouse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15o83yb/client_project_matching_ai_recommendations/",
          "publishedOn": "2023-08-11T12:51:48.000Z",
          "wordCount": 2631,
          "title": "Client project matching AI recommendations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15o28yf/vqa_recommendations_anyone/",
          "author": null,
          "description": "Hi, what VQA platforms do you all have experience with? What would you think would be the most promising platform at the moment, and in the future? I've been playing around with Google Vertex AI (https://console.cloud.google.com/vertex-ai/generative/) but the current results are ... meh! 🤷‍♂️ \n Any other recommendations?\n    submitted by    /u/emc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15o28yf/vqa_recommendations_anyone/",
          "publishedOn": "2023-08-11T07:43:38.000Z",
          "wordCount": 2524,
          "title": "VQA Recommendations, anyone?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15o0ctt/oneminute_daily_ai_news_8112023/",
          "author": null,
          "description": "A new AI algorithm has detected a potentially hazardous asteroid that had gone unnoticed by human observers, slated to fly by Earth. The algorithm, HelioLinc3D, was explicitly designed for the Vera Rubin Observatory currently under construction in Northern Chile.[1]\n The U.S. Defense Department has created a task force to evaluate and guide the application of generative artificial intelligence for national security purposes, amid an explosion of public interest in the technology.[2]\n China’s largest web and cloud providers (Alibaba, Baidu, ByteDance, and Tencent)are lining up to buy as many Nvidia GPUs as they can while they still can get their hands on them.[3]\n At Black Hat USA 2023, DARPA issued a call to top computer scientists, AI experts, software developers, and beyond to participate in the AI Cyber Challenge (AIxCC) – a two-year competition aimed at driving innovation at the nexus of AI and cybersecurity to create a new generation of cybersecurity tools.[4]\n  \nSources:\n [1] https://www.giantfreakinrobot.com/sci/ai-asteroids.html\n [2] https://www.c4isrnet.com/artificial-intelligence/2023/08/10/pentagon-establishes-task-force-lima-to-study-generative-ai-issues/\n [3] https://www.theregister.com/2023/08/11/chinese_web_giants_nvidia/\n [4] https://www.hstoday.us/industry/industry-news/darpa-ai-cyber-challenge-aims-to-secure-nations-most-critical-software/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15o0ctt/oneminute_daily_ai_news_8112023/",
          "publishedOn": "2023-08-11T05:58:30.000Z",
          "wordCount": 2640,
          "title": "One-Minute Daily AI News 8/11/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15nz2ph/ai_agents_simulate_a_town_generative_agents/",
          "author": null,
          "description": "submitted by    /u/crua9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15nz2ph/ai_agents_simulate_a_town_generative_agents/",
          "publishedOn": "2023-08-11T04:49:49.000Z",
          "wordCount": 2485,
          "title": "AI Agents Simulate a Town 🤯 Generative Agents: Interactive Simulacra of Human Behavior.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15nx7z9/an_extension_llm_model_that_also_analyzes_page/",
          "author": null,
          "description": "I have developed this chrome extension named Lupin which allows you to ask your question about your current tab directly to chatGPT by analysing the page's body. For instance, if you're looking into an Amazon product, you can ask your question about it directly to Lupin.\n https://chrome.google.com/webstore/detail/lupin/kdfaiheakopcdabhlcnbmfjffanaedgm?hl=en&authuser=0\n Right now, this is an open-beta phase, so I am open to any feedback. I have improved some aspects based on the feedback I received but I want to improve as much as possible before going for version 1.1\n If you wanna join me on this crusade and work together, DM me.\n Amor Fati,\n AAC\n    submitted by    /u/AttilaTheHappyHun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15nx7z9/an_extension_llm_model_that_also_analyzes_page/",
          "publishedOn": "2023-08-11T03:17:36.000Z",
          "wordCount": 2585,
          "title": "An Extension LLM Model That Also Analyzes Page Text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15nsuxj/rvc_ai_samples_examples/",
          "author": null,
          "description": "Hello, is there anywhere I can find .wav files to see examples about how would be the ideal type of samples I should provide my AI so it learns a more wide register of my voice?\n I didn't manage to find anything like that\n Sorry if it's a newbie question\n    submitted by    /u/Callumpi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15nsuxj/rvc_ai_samples_examples/",
          "publishedOn": "2023-08-11T00:02:45.000Z",
          "wordCount": 2528,
          "title": "RVC AI samples examples",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15nrxg7/this_is_what_comes_next_for_ai_the_simulation/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15nrxg7/this_is_what_comes_next_for_ai_the_simulation/",
          "publishedOn": "2023-08-10T23:23:35.000Z",
          "wordCount": 2491,
          "title": "THIS Is What Comes Next For AI - The Simulation | Interview with Fable Studio CEO - Edward Saatchi",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15njsnw/please_help_me_understand_these_files/",
          "author": null,
          "description": "I'm working on a skin cancer detection app where I can upload a picture of a mole or other skin lesion and have it tell me if its cancerous and what type of cancer it is, and I downloaded the HAM10000 database for it which came with 5 CSV files. I kind of understand the metadata CSV file but the other 4 don't make sense to me. They have a bunch of numbers and either L or RGB at the end of the file names. Can someone help me make sense of these?\n    submitted by    /u/timing_snow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15njsnw/please_help_me_understand_these_files/",
          "publishedOn": "2023-08-10T18:09:42.000Z",
          "wordCount": 2573,
          "title": "Please help me understand these files",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15niyoo/images_on_the_subject_of_ai/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15niyoo/images_on_the_subject_of_ai/",
          "publishedOn": "2023-08-10T17:38:37.000Z",
          "wordCount": 2478,
          "title": "Images on the subject of AI.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15nchf3/nvidia_unveils_gh200_superchips_for_most_complex/",
          "author": null,
          "description": "submitted by    /u/intengineering  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15nchf3/nvidia_unveils_gh200_superchips_for_most_complex/",
          "publishedOn": "2023-08-10T13:25:13.000Z",
          "wordCount": 2494,
          "title": "Nvidia unveils GH200 Superchips for 'most complex AI workloads'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15na9tw/looking_for_tts_that_converts_a_written_dialog/",
          "author": null,
          "description": "The titles says it all - obviously it would be great to have a range of voices as in Elevenlabs for instance. If not, has anyone done this and found an easy way.\n    submitted by    /u/dextercool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15na9tw/looking_for_tts_that_converts_a_written_dialog/",
          "publishedOn": "2023-08-10T11:49:32.000Z",
          "wordCount": 2519,
          "title": "Looking for TTS that converts a written dialog into a spoken one.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15n9sts/babe_wake_up_that_weird_happy_toys_commercial_is/",
          "author": null,
          "description": "submitted by    /u/PerryJ  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15n9sts/babe_wake_up_that_weird_happy_toys_commercial_is/",
          "publishedOn": "2023-08-10T11:27:26.000Z",
          "wordCount": 2483,
          "title": "Babe, wake up. That weird ™Happy Toys!™ commercial is on again",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15n9dg7/ai_generated_music_video_is_becoming_a_thing_this/",
          "author": null,
          "description": "The singularity is nearer\n    submitted by    /u/Psytorpz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15n9dg7/ai_generated_music_video_is_becoming_a_thing_this/",
          "publishedOn": "2023-08-10T11:06:23.000Z",
          "wordCount": 2490,
          "title": "AI Generated Music Video is becoming a thing! This video is incredible!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15n243n/oneminute_daily_ai_news_892023/",
          "author": null,
          "description": "Google today announced the launch of Project IDX, its foray into offering an AI-enabled browser-based development environment for building full-stack web and multiplatform apps.[1]\n NVIDIA today announced NVIDIA AI Workbench, a unified, easy-to-use toolkit that allows developers to quickly create, test and customize pretrained generative AI models on a PC or workstation.[2]\n IBM said on Wednesday it would host Meta Platforms’ artificial intelligence language program on its own enterprise AI platform, watsonx.[3]\n New high-tech microscope using AI successfully detects malaria in returning travelers.[4]\n  \nSources:\n [1] https://techcrunch.com/2023/08/08/google-launches-project-idx-a-new-ai-enabled-browser-based-development-environment/\n [2] https://nvidianews.nvidia.com/news/nvidia-ai-workbench-speeds-adoption-of-custom-generative-ai-for-worlds-enterprises\n [3] https://www.reuters.com/technology/ibm-launch-metas-llama-2-watsonx-ai-platform-businesses-2023-08-09/\n [4] https://medicalxpress.com/news/2023-08-high-tech-microscope-ai-successfully-malaria.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15n243n/oneminute_daily_ai_news_892023/",
          "publishedOn": "2023-08-10T04:35:10.000Z",
          "wordCount": 2571,
          "title": "One-Minute Daily AI News 8/9/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15n14hz/just_as_an_experiment_i_tried_to_see_if_i_could/",
          "author": null,
          "description": "I first tried this experiment back in January and it kinda tripped me out. I used the wonder AI. When I tried the experiment with the Wombo dream AI the results were completely random. I wonder what the results would be with Midjourney. I later revisited the experiment in June with the wonder AI and again got intriguing results. Posting this just as an experiment in the hopes others will try it and see if it is repeatable and if other AI have more consistent results than others. It’s just an experiment, I don’t really care about your opinion I care about your results from trying this. \n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15n14hz/just_as_an_experiment_i_tried_to_see_if_i_could/",
          "publishedOn": "2023-08-10T03:45:05.000Z",
          "wordCount": 2608,
          "title": "Just as an experiment I tried to see if I could have a conversation with an AI image generator. Don’t knock it till you’ve tried it 😂",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mvzwh/estimation_on_the_singularity_date_has_just_been/",
          "author": null,
          "description": "The continuous neutering of models (the process of making the models less capable or reducing certain aspects of their functionality to prevent them from generating inappropriate, harmful, or sensitive content), can now be regarded as a substantial contributor to the Singularity date's delay: www.daystosingularity.com/estimation-details/ \n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mvzwh/estimation_on_the_singularity_date_has_just_been/",
          "publishedOn": "2023-08-09T23:57:45.000Z",
          "wordCount": 2519,
          "title": "Estimation on the singularity date has just been delayed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mt2wf/ai_transformer_models_enable_machine_vision/",
          "author": null,
          "description": "submitted by    /u/Chipdoc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mt2wf/ai_transformer_models_enable_machine_vision/",
          "publishedOn": "2023-08-09T22:03:22.000Z",
          "wordCount": 2485,
          "title": "AI Transformer Models Enable Machine Vision Object Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mrcti/searching_for_a_tool/",
          "author": null,
          "description": "Anyone know of a good AI tool that I can self feed my own music and have it generate similar tracks based on my style? Having a hard time finding something like this. Really just want to play around, super curious, tia\n    submitted by    /u/yakisobas_ghost  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mrcti/searching_for_a_tool/",
          "publishedOn": "2023-08-09T20:59:43.000Z",
          "wordCount": 2512,
          "title": "Searching for a tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15molg5/the_ai_rules_that_congress_is_considering/",
          "author": null,
          "description": "submitted by    /u/AriadneSkovgaarde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15molg5/the_ai_rules_that_congress_is_considering/",
          "publishedOn": "2023-08-09T19:16:01.000Z",
          "wordCount": 2485,
          "title": "The AI rules that Congress is considering, explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mogo4/report_disney_creates_ai_task_force/",
          "author": null,
          "description": "submitted by    /u/Jane-in-the-jungle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mogo4/report_disney_creates_ai_task_force/",
          "publishedOn": "2023-08-09T19:10:57.000Z",
          "wordCount": 2483,
          "title": "Report: Disney Creates AI Task Force",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mo6zf/opening_the_black_box/",
          "author": null,
          "description": "From Anthropic\n https://arxiv.org/abs/2308.03296\n Studying Large Language Model Generalization with Influence Functions\n When trying to gain better visibility into a machine learning model in order to understand and mitigate the associated risks, a potentially valuable source of evidence is: which training examples most contribute to a given behavior? Influence functions aim to answer a counterfactual: how would the model's parameters (and hence its outputs) change if a given sequence were added to the training set? While influence functions have produced insights for small models, they are difficult to scale to large language models (LLMs) due to the difficulty of computing an inverse-Hessian-vector product (IHVP). We use the Eigenvalue-corrected Kronecker-Factored Approximate Curvature (EK-FAC) approximation to scale influence functions up to LLMs with up to 52 billion parameters. In our experiments, EK-FAC achieves similar accuracy to traditional influence function estimators despite the IHVP computation being orders of magnitude faster. We investigate two algorithmic techniques to reduce the cost of computing gradients of candidate training sequences: TF-IDF filtering and query batching. We use influence functions to investigate the generalization patterns of LLMs, including the sparsity of the influence patterns, increasing abstraction with scale, math and programming abilities, cross-lingual generalization, and role-playing behavior. Despite many apparently sophisticated forms of generalization, we identify a surprising limitation: influences decay to near-zero when the order of key phrases is flipped. Overall, influence functions give us a powerful new tool for studying the generalization properties of LLMs.\n    submitted by    /u/DataPhreak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mo6zf/opening_the_black_box/",
          "publishedOn": "2023-08-09T19:00:40.000Z",
          "wordCount": 2706,
          "title": "Opening the Black Box",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mlyey/inside_the_very_human_origin_of_the_term/",
          "author": null,
          "description": "submitted by    /u/geekteam6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mlyey/inside_the_very_human_origin_of_the_term/",
          "publishedOn": "2023-08-09T17:37:30.000Z",
          "wordCount": 2494,
          "title": "Inside the Very Human Origin of the Term “Artificial Intelligence” — And Its Seven Decade Boom/Bust Cycle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mlf3g/artificial_intelligence_for_the_poor_how_to/",
          "author": null,
          "description": "submitted by    /u/polandballbounces  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mlf3g/artificial_intelligence_for_the_poor_how_to/",
          "publishedOn": "2023-08-09T17:17:57.000Z",
          "wordCount": 2493,
          "title": "Artificial Intelligence for the Poor: How to Harness the Power of AI in the Developing World",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ml1yq/are_there_any_examples_of_artificial_intelligence/",
          "author": null,
          "description": "I hear AI & ML used interchangeable, and a lot of people dispute the use of the term \"AI\", as defining \"intelligence\" can be a sticky wicket. \"Machine learning\" seems like a much clearer term, describing systems that can optimize themselves given an objective function & maybe training data (generalization). \n But, I know ML is just a subset of AI, so is there any extant AI that isn't ML? If not, what would AI that's not ML look like? \n    submitted by    /u/ZealousidealTomato74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ml1yq/are_there_any_examples_of_artificial_intelligence/",
          "publishedOn": "2023-08-09T17:04:20.000Z",
          "wordCount": 2556,
          "title": "Are there any examples of Artificial Intelligence that aren't Machine Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mhncu/ai_is_about_to_turn_the_internet_into_a_total/",
          "author": null,
          "description": "submitted by    /u/Alone-Competition-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mhncu/ai_is_about_to_turn_the_internet_into_a_total/",
          "publishedOn": "2023-08-09T14:56:19.000Z",
          "wordCount": 2488,
          "title": "AI is about to turn the internet into a total nightmare",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mg5xj/strong_ai_brainy_superheroes/",
          "author": null,
          "description": "These brainy superheroes of the AI realm are ready to conquer intellectual challenges with a snap of their digital fingers, leaving us mere mortals feeling like puny amoebas in comparison.\n More ere: https://daystosingularity.com/2023/06/21/brainy-superheroes/\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mg5xj/strong_ai_brainy_superheroes/",
          "publishedOn": "2023-08-09T13:59:57.000Z",
          "wordCount": 2504,
          "title": "Strong AI = Brainy Superheroes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mf522/besides_for_bing_ai_is_there_no_other_decent_ai/",
          "author": null,
          "description": "I’ve been kind of getting ChatGPT and Google Bard to generate subreddits, and look for me Cannabis sites, and shopping. (to be specific haha, well forums) It’s done a good job with some of the links, but a lot of times it kind of makes them up. Is there not an Ai that can deep dive or skim the web more accurately? Does it decipher filters like “time and date”, “availability”, “price”. More problems I’ve run into is it not being able to go really far back such as early internet or none indexed sites. Also noticed with Google and Bing they will give you the same results over and over (I assume I should have used “no repeats”) Google also will show me sold out items or items that aren’t actually on sale. It’ll show the item as say “on sale: $12.00” inspected the link- “$137” actually?? Any filter tips, or other Ai??\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mf522/besides_for_bing_ai_is_there_no_other_decent_ai/",
          "publishedOn": "2023-08-09T13:20:04.000Z",
          "wordCount": 2640,
          "title": "Besides for Bing Ai, is there no other decent Ai that can give me links, and search (sniff) the web?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mem6f/tell_me_an_ai_that_can_edit_an_images_text/",
          "author": null,
          "description": "I saw a reel or short about an site that can do that easily but I didn't really care about at that time so I didn't save it I regret my decision soooo much can someone help me I have already wasted so much of my time wandering here n there\n    submitted by    /u/Inevitable-Mousse489  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mem6f/tell_me_an_ai_that_can_edit_an_images_text/",
          "publishedOn": "2023-08-09T12:58:42.000Z",
          "wordCount": 2527,
          "title": "TELL ME AN AI THAT CAN EDIT AN IMAGES TEXT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mdqoj/i_read_the_papers_for_you_comparing_bark_and/",
          "author": null,
          "description": "If you're creating voice-enabled products, I hope this will help you choose which model to use!\n I read the papers and docs for Bark and Tortoise TTS - two text-to-speech models that seemed pretty similar on the surface but are actually pretty different.\n Here's what Bark can do:\n  \nIt can synthesize natural, human-like speech in multiple languages.\n Bark can also generate music, sound effects, and other audio.\n The model supports generating laughs, sighs, and other non-verbal sounds to make speech more natural and human-sounding. I find these really compelling and these imperfections make the speech sound much more real. Check out an example here (scroll down to \"pizza.webm\").\n Bark allows control over tone, pitch, speaker identity and other attributes through text prompts. \n The model learns directly from text-audio pairs.\n  \nWhereas for Tortoise TTS:\n  \nIt excels at cloning voices using just short audio samples of a target speaker. This makes it easy to produce text in many distinct voices (like celebrities). I think voice cloning is the best use case for this tool.\n The quality of the synthesized voices is pretty high.\n Tortoise supports fine-grained control of speech characteristics like tone, emotion, pacing, etc through priming text.\n Tortoise is only trained on English and it's not capable of producing sound effects.\n  \nHere's how they compare to the other speech-related models I've taken a look at so far:\n  \n Model Best Use Cases Key Strengths \n  \n Bark Voice assistants, audio generation Flexibility, multilingual \n  Tortoise TTS Audiobooks, voice cloning Natural prosody, voice cloning \n  AudioLDM (full guide) Voice assistants High-quality speech and SFX \n  Whisper Transcription Accuracy, flexibility \n  Free VC Voice conversion Retains speech style \n \n I have a full write-up here if you want to read more, it's about a 10-minute read. I also looked at the model inputs and outputs and speculated on some products you can build with each tool.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mdqoj/i_read_the_papers_for_you_comparing_bark_and/",
          "publishedOn": "2023-08-09T12:20:43.000Z",
          "wordCount": 2785,
          "title": "I read the papers for you: Comparing Bark and Tortoise TTS for text-to-speech applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mdmq3/authors_join_the_brewing_legal_battle_over_ai/",
          "author": null,
          "description": "submitted by    /u/Hiversitize  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mdmq3/authors_join_the_brewing_legal_battle_over_ai/",
          "publishedOn": "2023-08-09T12:15:46.000Z",
          "wordCount": 2485,
          "title": "Authors Join the Brewing Legal Battle Over AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mcg8f/latest_ai_news_digest_august_9/",
          "author": null,
          "description": "Here are fresh AI Updates for you\n ​\n Nvidia has launched new Grace Hopper Superchip to boost Generative AI\n Norton introduces new AI Scam Detection Tool 'Genie'\n Google Working on 'Brain2Music' to create music from your brain\n Google and Universal Music deal over 'AI Deepfakes'\n Is Zoom using your data to train its AI ?\n ​\n Stay tuned for more \n ​\n    submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mcg8f/latest_ai_news_digest_august_9/",
          "publishedOn": "2023-08-09T11:20:09.000Z",
          "wordCount": 2531,
          "title": "Latest AI News Digest - August 9",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mbwey/damn_now_everybody_can_be_a_film_producer/",
          "author": null,
          "description": "submitted by    /u/anonymous_guyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mbwey/damn_now_everybody_can_be_a_film_producer/",
          "publishedOn": "2023-08-09T10:53:14.000Z",
          "wordCount": 2472,
          "title": "Damn! Now everybody can be a film producer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m8ud9/what_does_it_take_to_get_ai_to_work_like_a/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m8ud9/what_does_it_take_to_get_ai_to_work_like_a/",
          "publishedOn": "2023-08-09T08:06:59.000Z",
          "wordCount": 2507,
          "title": "What does it take to get AI to work like a scientist? | \"As machine-learning algorithms grow more sophisticated, artificial intelligence seems poised to revolutionize the practice of science itself.\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m55lj/where_to_begin_studying_aiml_from_a_cognitive/",
          "author": null,
          "description": "I am currently an AI/ML student but I have recently been thinking more and more about cognitive science. I was wondering if you know of any good resources that approach AI from the perspective of cognitive science\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m55lj/where_to_begin_studying_aiml_from_a_cognitive/",
          "publishedOn": "2023-08-09T04:47:06.000Z",
          "wordCount": 2513,
          "title": "Where to begin studying AI/ML from a COGNITIVE SCIENCE PERSPECTIVE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m3tzw/oneminute_daily_ai_news_882023/",
          "author": null,
          "description": "Researchers at the Massachusetts Institute of Technology (MIT) and the Dana-Farber Cancer Institute have discovered that the use of artificial intelligence (AI) could make it easier to determine the sites of origin for enigmatic cancers and enable doctors to choose more targeted treatments.[1]\n Meta disbands protein-folding team in shift towards commercial AI.[2]\n OpenAI has introduced GPTBot, a web crawler to improve AI models. GPTBot scrupulously filters out data sources that violate privacy and other policies.[3]\n Disney has created a task force to study artificial intelligence and how it can be applied across the entertainment conglomerate, even as Hollywood writers and actors battle to limit the industry’s exploitation of the technology.[4]\n  \nSources:\n [1] https://www.nature.com/articles/s41591-023-02482-6\n [2] https://www.ft.com/content/919c05d2-b894-4812-aa1a-dd2ab6de794a\n [3] https://www.searchenginejournal.com/openai-launches-gptbot-how-to-restrict-access/493394/#close\n [4] https://www.reuters.com/technology/disney-creates-task-force-explore-ai-cut-costs-sources-2023-08-08/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m3tzw/oneminute_daily_ai_news_882023/",
          "publishedOn": "2023-08-09T03:41:44.000Z",
          "wordCount": 2590,
          "title": "One-Minute Daily AI News 8/8/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m320e/how_ai_generated_movies_tv_series_might_be_done/",
          "author": null,
          "description": "I see lots of people say AI will not be able to do movies / TV because it hallucinates yada yada yada. But, movies / TV shows follow a clear script. Script being a generic formula that is taught to script writers the same way as music theory cheat sheet helps aspiring musicians to write songs. \n Script. Script can be turned into machine readable format. You can add commands how to render a movie on the basis of it. For example in a script you could have #Jack, telling the thing reading the script that we are talking of actor #Jack meaning it should tap into assets about jack which would reside in folder Jack. Jack meanwhile could be rendered by sub ai to fit the part. \n That helps us nail down the character so it wont be changing appearance wise in our script. \n The AI part here comes from…",
          "link": "https://www.reddit.com/r/artificial/comments/15m320e/how_ai_generated_movies_tv_series_might_be_done/",
          "publishedOn": "2023-08-09T03:05:06.000Z",
          "wordCount": 3202,
          "title": "How AI generated movies / TV series might be done in near future.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m17xo/4_ways_generative_ai_makes_founders_more/",
          "author": null,
          "description": "submitted by    /u/egusa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m17xo/4_ways_generative_ai_makes_founders_more/",
          "publishedOn": "2023-08-09T01:41:29.000Z",
          "wordCount": 2489,
          "title": "4 ways generative AI makes founders more interesting to journalists | TechCrunch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m0h73/question_from_a_lay_person_nonmathscience_type/",
          "author": null,
          "description": "Thanks any answers or musings -\n what are some technical limitations (eg computing / storage power/speed) that (1) limits AI's progress and (2) might be solved (and how), and (3) if solved, would make possible developments we can conceive of but not do yet?\n I'm just wondering if AI researchers forsee a kind of 'leap forward' and what are some obstacles?\n    submitted by    /u/OpenWaterRescue  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m0h73/question_from_a_lay_person_nonmathscience_type/",
          "publishedOn": "2023-08-09T01:08:20.000Z",
          "wordCount": 2542,
          "title": "QUESTION from a Lay person non-math/science type who likes to read about science and AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lx459/i_made_this_film_completely_using_ai_from_chat/",
          "author": null,
          "description": "submitted by    /u/RMIII3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lx459/i_made_this_film_completely_using_ai_from_chat/",
          "publishedOn": "2023-08-08T22:48:40.000Z",
          "wordCount": 2476,
          "title": "I made this film completely using AI! From Chat GPT to EbSynth!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lwpb8/this_video_argues_that_artificial_intelligence/",
          "author": null,
          "description": "submitted by    /u/antaloaalonso  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lwpb8/this_video_argues_that_artificial_intelligence/",
          "publishedOn": "2023-08-08T22:31:58.000Z",
          "wordCount": 2474,
          "title": "This video argues that artificial intelligence should not be regulated.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15luv1g/catching_up_on_the_weird_world_of_llms/",
          "author": null,
          "description": "submitted by    /u/nangaparbat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15luv1g/catching_up_on_the_weird_world_of_llms/",
          "publishedOn": "2023-08-08T21:22:37.000Z",
          "wordCount": 2485,
          "title": "Catching up on the weird world of LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lsy4f/ai_service_to_unblur_a_slightly_blurry_passport/",
          "author": null,
          "description": "All services I found made the blurry text even worse. Is there any which has good results for documents?\n    submitted by    /u/_SarahB_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lsy4f/ai_service_to_unblur_a_slightly_blurry_passport/",
          "publishedOn": "2023-08-08T20:12:03.000Z",
          "wordCount": 2493,
          "title": "AI Service to unblur a slightly blurry Passport?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lswdd/a_whole_sitcom_i_made_using_ai_art_voice/",
          "author": null,
          "description": "submitted by    /u/SoundRedux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lswdd/a_whole_sitcom_i_made_using_ai_art_voice/",
          "publishedOn": "2023-08-08T20:10:09.000Z",
          "wordCount": 2487,
          "title": "A whole sitcom I Made using AI Art & Voice. Entertainment is on its way back to the hands of the Independent creator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lryou/ive_developed_a_tool_to_convert_voice_notes_into/",
          "author": null,
          "description": "Hi there 👋,\n I'm excited to share a project I've been working on over the past few months!\n My primary goal is to create a service that will be beneficial for people. Please share your thoughts on this idea, and suggest any new features you think I should implement!\n Exciting Features:\n • Speak to Write: with this feature, you can speak your thoughts or information and the tool will transcribe it into text. The best part? You can then forward the transcribed text to any application with just one click.\n • Audio to Action Plan: the service can transform a received audio message into a structured list of elements or bullet points. This feature is especially useful for outlining an action plan or item list.\n • Speak in and Language: you can dictate an audio message in your native language, and the service will translate it into any other language, maintaining high translation quality—significantly better than Google Translate.\n • Meeting Transcripts & Summaries: the service is perfect for converting recorded audio from meetings into text and generating concise summaries. It supports the upload of users' files.\n Thank you for taking the time to check it out. I look forward to hearing your feedback. You can access the service by visiting this link: https://audionotes.ai\n    submitted by    /u/OneMoreSuperUser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lryou/ive_developed_a_tool_to_convert_voice_notes_into/",
          "publishedOn": "2023-08-08T19:35:18.000Z",
          "wordCount": 2696,
          "title": "I've developed a tool to convert voice notes into structured text: seeking your valuable feedback and suggestions!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lplcy/are_there_are_any_good_image_gen_ai_apis/",
          "author": null,
          "description": "I have a killer project idea but it requires fully custom image generation. Character portraits. Any API like that out there?\n    submitted by    /u/thedarklord176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lplcy/are_there_are_any_good_image_gen_ai_apis/",
          "publishedOn": "2023-08-08T18:06:26.000Z",
          "wordCount": 2496,
          "title": "Are there are any *good* image gen AI APIs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lmfky/is_there_ai_that_browses_a_website_checks_the/",
          "author": null,
          "description": "I just want a script to perform the task not AI itself so that I have something reliable. It always puzzles me why these things don't instantly pop up as services where I don't have to worry about even deploying the script (but that's another issue). \n    submitted by    /u/VLADIMIROVIC_L  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lmfky/is_there_ai_that_browses_a_website_checks_the/",
          "publishedOn": "2023-08-08T16:06:59.000Z",
          "wordCount": 2540,
          "title": "Is there AI that browses a website, checks the structure of the content of the page and then writes a script for me that extracts the data regularly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lm8wz/nvidia_hugging_face_collaboration_on_dgxnoice/",
          "author": null,
          "description": "submitted by    /u/Internet0fGames  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lm8wz/nvidia_hugging_face_collaboration_on_dgxnoice/",
          "publishedOn": "2023-08-08T16:00:32.000Z",
          "wordCount": 2481,
          "title": "Nvidia, Hugging Face collaboration on DGX...noice!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lm6ql/gpt4_chose_female_character_for_youtube_named_ai/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lm6ql/gpt4_chose_female_character_for_youtube_named_ai/",
          "publishedOn": "2023-08-08T15:58:20.000Z",
          "wordCount": 2506,
          "title": "GPT4 Chose Female Character for Youtube, Named AI Ada, as reference to Ada Lovelace, first women programmer in order to pay homage to the vital role women have played, and continue to play, in the field of technology and AI. Quite Awesome!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lld3n/chatgpt_for_beginners_how_to_create_images/",
          "author": null,
          "description": "Tutorial about creating images using ChatGPT.\n    submitted by    /u/SplitYOLO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lld3n/chatgpt_for_beginners_how_to_create_images/",
          "publishedOn": "2023-08-08T15:27:42.000Z",
          "wordCount": 2479,
          "title": "ChatGPT for Beginners: How to Create Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lkic2/video_editing_ai/",
          "author": null,
          "description": "Hello, I'm currently editing videos using capcut, which is not ideal.\n I'm looking for an ai, that ideally :\n Finds me B-roll according to what I speak. Cuts \"bad takes\" out Good captions \"TikTok style\" Audio enhance.\n Do you guys know anything like this?\n Thank you!\n    submitted by    /u/Orlandostyler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lkic2/video_editing_ai/",
          "publishedOn": "2023-08-08T14:56:06.000Z",
          "wordCount": 2515,
          "title": "Video editing ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lixcq/spotify_ai/",
          "author": null,
          "description": "I've been using this today whilst I've been working and I found it pretty comical at first with the voice that talks to you, but now I'm starting to love it! I want it to talk more when it does talk. It feels like a nice break in the music to have the AI talk like a radio host. I'm sure some people would rather that not being a feature (if they use it at all), but I'd love for it to have some more comedic one-liners, possible news updates, and potentially traffic updates based on location and if it knows you're driving. Would be awesome! \n It's also a really good tool for if you want to listen to music you've not heard before. Whether it's part of your usual genre or not.\n Looking forward to seeing how this progresses!\n    submitted by    /u/Columbian_Toad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lixcq/spotify_ai/",
          "publishedOn": "2023-08-08T13:55:22.000Z",
          "wordCount": 2608,
          "title": "Spotify AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15liom9/generative_ai_an_artists_honest_perspective/",
          "author": null,
          "description": "Hi everyone.\n I am an artist. And programmer, and kind of a bit of everything. But what is important, is that I was an artist before the current \"generative AI\" was a thing, and I have been drawing, digitally and traditionally alike for like... a decade?\n Art, to me, is getting what is inside your head, and presenting it to others outside of your consciousness and thoughts. It's showing the world a piece of your interpretation, your experience, your impressions of the world you inhabit. It's about communicating to others your emotions, your ideas, your thoughts and feelings.\n Not everyone can draw, or paint, or sculpt. I could say \"learn it, it's easy\", but that would be a lie. It isn't easy. It is years upon years of constant, hard work, requiring focus and dedication, and a passion for l…",
          "link": "https://www.reddit.com/r/artificial/comments/15liom9/generative_ai_an_artists_honest_perspective/",
          "publishedOn": "2023-08-08T13:45:35.000Z",
          "wordCount": 3159,
          "title": "Generative AI: An Artist's Honest Perspective",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lieim/allen_institute_for_ai_takes_new_approach_to/",
          "author": null,
          "description": "submitted by    /u/DarronFeldstein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lieim/allen_institute_for_ai_takes_new_approach_to/",
          "publishedOn": "2023-08-08T13:34:19.000Z",
          "wordCount": 2491,
          "title": "Allen Institute for AI takes new approach to managing AI risks and promoting transparency",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lfs8o/how_do_i_make_aigenerated_videos_with_prompts/",
          "author": null,
          "description": "How do I make AI-generated videos with prompts for free?\n    submitted by    /u/DankDude6T9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lfs8o/how_do_i_make_aigenerated_videos_with_prompts/",
          "publishedOn": "2023-08-08T11:42:12.000Z",
          "wordCount": 2484,
          "title": "How do I make AI-generated videos with prompts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15levaa/im_making_my_first_ai_game/",
          "author": null,
          "description": "Hello AI enthusiasts!\n I'm a software engineer passionate about AI, and recently I've been experimenting with making my first AI game. \n In the game, you try to negotiate a price down on a watch with an AI-driven salesman, rewarding -or roasting lol- you depending on your bargaining skills.\n I’d be more than happy to get your thoughts and feedback on this idea, it's the first application I've built using AI so any tips would be much appreciated! \n Thanks!\n    submitted by    /u/gavo_gavo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15levaa/im_making_my_first_ai_game/",
          "publishedOn": "2023-08-08T10:58:37.000Z",
          "wordCount": 2550,
          "title": "I'm making my first AI game.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ledxh/sod_off_human_ais_magic_revealed/",
          "author": null,
          "description": "submitted by    /u/ispeakout  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ledxh/sod_off_human_ais_magic_revealed/",
          "publishedOn": "2023-08-08T10:34:50.000Z",
          "wordCount": 2470,
          "title": "Sod Off, Human! AI's Magic Revealed!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lcvuq/a_bodypositive_nonprofit_replaced_staff_with_an/",
          "author": null,
          "description": "submitted by    /u/intengineering  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lcvuq/a_bodypositive_nonprofit_replaced_staff_with_an/",
          "publishedOn": "2023-08-08T09:17:32.000Z",
          "wordCount": 2490,
          "title": "A body-positive nonprofit replaced staff with an AI chatbot – the move backfired",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lbx8z/is_there_an_ai_for_reviewing_videos_based_on/",
          "author": null,
          "description": "I want to start making a YouTube channel, because I've got a passion project I want to work on with a Minecraft modpack. Obviously, Minecraft is a HUGE game and has thousands of videos posted every day... This is why I want to know if there is an AI that can rate videos based on editing, audience engagement, sound, etc... Also giving areas of improvement and the strengths of the video.\n Probably a big ask and SO far fetched, but there's always a chance of something being out there.\n    submitted by    /u/Columbian_Toad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lbx8z/is_there_an_ai_for_reviewing_videos_based_on/",
          "publishedOn": "2023-08-08T08:26:02.000Z",
          "wordCount": 2566,
          "title": "Is there an AI for reviewing videos based on audience category?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lbu86/ai_photo_editor_recommendationd/",
          "author": null,
          "description": "Can someone recommend a great AI photo editor that can take 100 profile photos and standardise them, IE crop so head is same size across all photos, background removed and placed on standard back ground.\n    submitted by    /u/Woodger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lbu86/ai_photo_editor_recommendationd/",
          "publishedOn": "2023-08-08T08:21:00.000Z",
          "wordCount": 2505,
          "title": "AI photo editor recommendationd",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lbba2/sorry_jarvis/",
          "author": null,
          "description": "​\n https://preview.redd.it/9epla7xjdugb1.png?width=960&format=png&auto=webp&s=92190970027b08476ac9899a42d7099fe67cf5aa\n    submitted by    /u/Maxie445  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lbba2/sorry_jarvis/",
          "publishedOn": "2023-08-08T07:51:18.000Z",
          "wordCount": 2468,
          "title": "Sorry Jarvis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15l6utw/oneminute_daily_ai_news_872023/",
          "author": null,
          "description": "Data analytics company Qureight has entered into a multi-year strategic research collaboration with AstraZeneca that will use AI models to accelerate research into lung diseases.[1] \n Zoom’s terms of service update establishes the video platform’s right to use some customer data for training its AI models.[2]\n Cigna, one of the country’s largest health insurance companies, faces a class action lawsuit over charges that it illegally used an AI algorithm to deny hundreds of thousands of claims without a physician’s review.[3]\n Japan plans guidelines for AI-savvy human resources.[4]\n  \nSources:\n [1] https://www.digitalhealth.net/2023/08/qureight-collaborates-with-astrazeneca-for-ai-lung-disease-research/\n [2] https://www.cnbc.com/2023/08/07/zoom-ai-tools-trained-using-some-customer-data.html\n [3] https://www.medicaleconomics.com/view/cigna-using-ai-to-reject-claims-lawsuit-charges\n [4] https://asianews.network/japan-plans-guidelines-for-ai-savvy-human-resources/\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15l6utw/oneminute_daily_ai_news_872023/",
          "publishedOn": "2023-08-08T03:58:27.000Z",
          "wordCount": 2566,
          "title": "One-Minute Daily AI News 8/7/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15l3f7c/ai_generated_trailer_for_horror_film_magic_8/",
          "author": null,
          "description": "submitted by    /u/SellowYubmarine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15l3f7c/ai_generated_trailer_for_horror_film_magic_8/",
          "publishedOn": "2023-08-08T01:20:09.000Z",
          "wordCount": 2472,
          "title": "Ai generated trailer for horror film “Magic 8”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kub95/looking_for_an_ai_app_that_can_draw_a_widemouth/",
          "author": null,
          "description": "I want an app that can draw a widemouth bass smoking a blunt. All the free ones ive tried give me supid anime girls when all I want is fish\n    submitted by    /u/Barefoot_slinger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kub95/looking_for_an_ai_app_that_can_draw_a_widemouth/",
          "publishedOn": "2023-08-07T19:23:30.000Z",
          "wordCount": 2500,
          "title": "Looking for an AI app that can draw a widemouth bass smoking a blunt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15krvfk/best_subscription_generative_ai_service/",
          "author": null,
          "description": "I’m interested in trying out a subscription-based generative AI service. Candidates include (but are not limited to) CoPilot, ChatGPT pro (or whatever it’s called), and Midjourney. Which generative service do you think is most worth the cost?\n    submitted by    /u/galactictock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15krvfk/best_subscription_generative_ai_service/",
          "publishedOn": "2023-08-07T17:54:56.000Z",
          "wordCount": 2498,
          "title": "Best subscription generative AI service?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kp41y/any_free_voice_cloning_ai_for_download_without/",
          "author": null,
          "description": "Is there any Free AI Voice Cloner for free, that allow me simply to install the Exe? And Has option to input my Voice to it that I record? I dont have any coding and command skills. so is there something simple to install? Thanks for Answers\n    submitted by    /u/Matejsteinhauser14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kp41y/any_free_voice_cloning_ai_for_download_without/",
          "publishedOn": "2023-08-07T16:12:10.000Z",
          "wordCount": 2516,
          "title": "any free Voice Cloning AI for Download? Without requiring Coding and Command knownlage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15koc7n/best_ai_program_for_fixing_heavily_pixelated/",
          "author": null,
          "description": "I’ve used several AI programs that work excellent on blurred/pixelated photos of human faces but beyond that, I have not had success finding a program that can render animals in similar way. I’m more looking for something that can make the quality of a pixelated photo of say, a dog, non pixelated. Or at least, much less pixelated. \n The images I’m trying to use are just absolutely horrible and not fixable, or I am just not using the best programs for my purposes. Or the programs I’m looking for simply do not exist yet. \n If you have any recommendations (Paid or free programs) please do share! I have a MacBook and an iPhone if that helps.\n Thank you! 💕\n    submitted by    /u/briannaleidy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15koc7n/best_ai_program_for_fixing_heavily_pixelated/",
          "publishedOn": "2023-08-07T15:43:54.000Z",
          "wordCount": 2588,
          "title": "Best AI program for fixing heavily pixelated images of ANIMALS/ non human subjects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kkjn9/humanscript_an_llm_powered_plain_english/",
          "author": null,
          "description": "submitted by    /u/dyslexiccoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kkjn9/humanscript_an_llm_powered_plain_english/",
          "publishedOn": "2023-08-07T13:19:11.000Z",
          "wordCount": 2475,
          "title": "humanscript: An LLM powered plain english programming language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kjmh5/ai_to_rewrite_documents_like_pdf_or_docx/",
          "author": null,
          "description": "Hello, im in need of an ai that could rewrite for example a pdf document changing the wording but keeping the meaning of the content. \n Right now im a user of chatgpt plus, and trying to use code interpreter for that, ive managed to get what i want, but it isnt capable of rewriting more than two pages without crashing or simply stoping the process without any warning.\n I do not know if im using the prompting in a wrong way, any help would be apreciated, also, in case theres an ai out there capable of doing this in a better way id be glad to know about it.\n Thank you guys.\n    submitted by    /u/namelessgang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kjmh5/ai_to_rewrite_documents_like_pdf_or_docx/",
          "publishedOn": "2023-08-07T12:40:24.000Z",
          "wordCount": 2576,
          "title": "AI to rewrite documents like PDF or docx?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15khvly/dungeons_dragons_tells_illustrators_to_stop_using/",
          "author": null,
          "description": "submitted by    /u/SAT0725  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15khvly/dungeons_dragons_tells_illustrators_to_stop_using/",
          "publishedOn": "2023-08-07T11:22:19.000Z",
          "wordCount": 2482,
          "title": "Dungeons & Dragons tells illustrators to stop using AI to generate artwork for fantasy franchise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kd9nz/scientists_develop_ai_system_to_alert_us_of_next/",
          "author": null,
          "description": "submitted by    /u/intengineering  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kd9nz/scientists_develop_ai_system_to_alert_us_of_next/",
          "publishedOn": "2023-08-07T07:12:32.000Z",
          "wordCount": 2477,
          "title": "Scientists develop AI system to alert us of next pandemic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kcu79/albert_einstein_not_in_black_and_white_but_in/",
          "author": null,
          "description": "submitted by    /u/m-king473  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kcu79/albert_einstein_not_in_black_and_white_but_in/",
          "publishedOn": "2023-08-07T06:49:01.000Z",
          "wordCount": 2468,
          "title": "Albert Einstein not in black and white, but in lifelike color using AI 🤯.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kcmh4/making_llms_hallucinate_is_so_funny/",
          "author": null,
          "description": "\"It looks likethisis some sortof programming syntax maybe JavaScript perhaps? Let metell ya though buddy dat aintmuch informatio todo wit. Wouldya care ta tell mesomewhat ye wanna know boot heck, might make things easier ferus botsto give yo useful responses faster innasecondsoffuture interactions brotha man :)\"\n Anyone else used this site? It's through a site called nimblebox.ai, they have different models and allow you to adjust the temperature\n    submitted by    /u/jordan_jpg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kcmh4/making_llms_hallucinate_is_so_funny/",
          "publishedOn": "2023-08-07T06:36:55.000Z",
          "wordCount": 2541,
          "title": "Making LLMs hallucinate is so funny",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k8qbq/gorilla_ai_meet_the_first_genuine_proximate_agi/",
          "author": null,
          "description": "submitted by    /u/wolfdeathkill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k8qbq/gorilla_ai_meet_the_first_genuine_proximate_agi/",
          "publishedOn": "2023-08-07T03:09:27.000Z",
          "wordCount": 2464,
          "title": "GORILLA AI: Meet the First Genuine Proximate AGI (By Microsoft)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k6bc2/_/",
          "author": null,
          "description": "Don’t believe everything you hear in the media… I learned this firsthand. This one time I accidentally went on Jessie Waters…for real 😂 \n https://youtu.be/1X31DHV0gyg?si=fU8p2D4-ShTWUdQs\n https://open.spotify.com/episode/1M6dbrrP4EoudfTUvD4BqF?si=YMBCFXYfTsmUeOXAe_-lMg\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k6bc2/_/",
          "publishedOn": "2023-08-07T01:12:03.000Z",
          "wordCount": 2482,
          "title": "🤖❤️",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k5y4i/seeking_ai_solution_to_remaster_my_chiptune_songs/",
          "author": null,
          "description": "I have these chiptune songs I made myself, and I want to know if there is any AI that can remaster them with real instruments, etc., like an old 8-bit video game song that is updated to a modern version in a remake. Is any already AI capable of doing that?\n    submitted by    /u/Severo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k5y4i/seeking_ai_solution_to_remaster_my_chiptune_songs/",
          "publishedOn": "2023-08-07T00:55:08.000Z",
          "wordCount": 2521,
          "title": "Seeking AI Solution to Remaster My Chiptune Songs with Real Instruments, is there any?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k0edf/d_comprehensive_learning_resources_that_emphasize/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k0edf/d_comprehensive_learning_resources_that_emphasize/",
          "publishedOn": "2023-08-06T20:56:02.000Z",
          "wordCount": 2486,
          "title": "[D] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jz0ag/pioneering_ai_democracy_introducing_a/",
          "author": null,
          "description": "submitted by    /u/CreepToCrypto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jz0ag/pioneering_ai_democracy_introducing_a/",
          "publishedOn": "2023-08-06T20:00:44.000Z",
          "wordCount": 2448,
          "title": "Pioneering AI Democracy: Introducing a Decentralized and Merit-Based Governance System for Large Language Models like ChatGPT (proposed to OpenAI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jy7vv/how_to_build_websites_that_use_ai/",
          "author": null,
          "description": "Web dev student here and I'm interested in knowing more about creating products that actually use AI to help its users (not products that just use GPT in the backend). More specifically, I want to build a food supply management app for restaurants for my school thesis. This app will use AI to analyse food supplies and assign them purchase priority, value, and complexity scores (maybe just priority if it's too hard). Restaurant owners could then determine what foods should be purchased before others based on the priority scores.\n For example, a restaurant may only have 10 tomatoes left and the average usage of tomatoes in this restaurant is 12 per week. Based on this, a priority would be assigned to purchase x amount of tomatoes.\n Other factors that could be taken into account for the prior…",
          "link": "https://www.reddit.com/r/artificial/comments/15jy7vv/how_to_build_websites_that_use_ai/",
          "publishedOn": "2023-08-06T19:29:07.000Z",
          "wordCount": 2878,
          "title": "How to build websites that use AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jtg3b/any_good_ai_tools_paid_or_free_i_can_use_to_help/",
          "author": null,
          "description": "Hello everyone \n Basically i just need to post some text into one website everyday for my work \n The problem is there are many steps involves to post one data value, I was wondering if there is a tool that can learn my tasks and then post some of the data to the website from google sheets? \n I'm open to any suggestions and advice. \n Thanks in advance.\n ​\n    submitted by    /u/Maxduel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jtg3b/any_good_ai_tools_paid_or_free_i_can_use_to_help/",
          "publishedOn": "2023-08-06T16:13:06.000Z",
          "wordCount": 2504,
          "title": "Any good AI tools paid or free I can use to help me post some text data on a website?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jqw4z/free_ai_tts_text_to_speech_available/",
          "author": null,
          "description": "I want to convert a few books into audiobooks. Are there any AI options out there that are free and will give me something I can use offline? I typically listen to books on my phone while I'm out, so something like Edge browser isn't going to work.\n I've heard that there are some great options, but I've only seen some web paid services, and for my purpose, it's too expensive just to get an audiobook out of it. This is all just for personal use.\n    submitted by    /u/UUkiee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jqw4z/free_ai_tts_text_to_speech_available/",
          "publishedOn": "2023-08-06T14:24:13.000Z",
          "wordCount": 2511,
          "title": "Free AI TTS Text to speech available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jn68p/in_the_game_superintelligence_you_play_as_an_ai/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jn68p/in_the_game_superintelligence_you_play_as_an_ai/",
          "publishedOn": "2023-08-06T11:20:08.000Z",
          "wordCount": 2432,
          "title": "In the game Superintelligence, you play as an AI trying dominate the planet. [Fictional game concept]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j9bwq/do_you_think_we_will_hit_a_point_of_robocop_in/",
          "author": null,
          "description": "The movie that came out in the 80s is a great flick for it’s time. Do you guys think we will ever experience a sort of unstoppable super soldier when it comes to our police / swat forces ? We are replacing many jobs with robots. From surgery procedures in hospitals to flipping burgers. It’s not above the realm of possibility to think we may someday soon see a hybrid police force. What do you guys think ?\n    submitted by    /u/2bJavazon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j9bwq/do_you_think_we_will_hit_a_point_of_robocop_in/",
          "publishedOn": "2023-08-05T22:52:45.000Z",
          "wordCount": 2518,
          "title": "Do you think we will hit a point of “Robocop” in the next 50 years? A Human + Cybernetic Hybrid police force",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j8csn/what_ai_tts_softwarevoice_is_this_video_using/",
          "author": null,
          "description": "It's commonly used on tiktok for reddit narration story videos, here is an example: https://www.tiktok.com/@creekyadvice/video/7263509593488166186. Anyone have any idea? \n    submitted by    /u/DanielTube7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j8csn/what_ai_tts_softwarevoice_is_this_video_using/",
          "publishedOn": "2023-08-05T22:11:13.000Z",
          "wordCount": 2445,
          "title": "What AI TTS software/voice is this video using?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j7dcx/linguistics_npl_career/",
          "author": null,
          "description": "I am a linguist, translator, and copy editor looking to move my career into natural language processing instead. I have no computer science background. What would you suggest as some steps to take, both now and in the future, as I plan out my career? It looks like I am going to need to learn Python, but I'm not 100% sure, and there's so little established in such a new field.\n    submitted by    /u/StrangersWithAndi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j7dcx/linguistics_npl_career/",
          "publishedOn": "2023-08-05T21:31:59.000Z",
          "wordCount": 2493,
          "title": "Linguistics > NPL career?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j4tvd/giving_ai_unlimited_access_to_the_internet_by_web/",
          "author": null,
          "description": "Interesting experiment i thought of.\n What if we gave AI access to web browser, and let it do whatever it wants? It could create accounts on any social media, email accounts, ad comments everywhere and such.\n of course, ai by itself does not have any agenda or need to do anything, so ai would need to be fed some kind of personality simulation first. Lets say ai was either fed personality based on extensive twitter or reddit history of someone's post. Using that, basic psychological traits, beliefs and maybe goals could be determined.\n Such ai would simulate person sitting in front of pc, so it would need to parse the content of webpages, but i don't think it would be that of a problem. And it would maybe also have access to some bank account with some money to maybe pay for online subscriptions and such. But who knows, maybe thanks to simulating someone's personality, it would attempt to donate money to some charity or lose it on onlyfans?\n    submitted by    /u/rogaldorn88888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j4tvd/giving_ai_unlimited_access_to_the_internet_by_web/",
          "publishedOn": "2023-08-05T19:48:01.000Z",
          "wordCount": 2597,
          "title": "Giving AI unlimited access to the internet by web browser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j4ml7/i_just_published_safe_for_humans_ai_free_to_read/",
          "author": null,
          "description": "I just published “Safe For Humans AI” – free to read online\n https://leanpub.com/safe-for-humans-AI/read\n Free to read online, and eBook versions released under a Creative Commons License (no commercial reuse, feel free to share).\n The full title of my short book is:\n Safe For Humans AI\n A \"humans-first\" approach to designing and building AI systems.\n    submitted by    /u/MWatson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j4ml7/i_just_published_safe_for_humans_ai_free_to_read/",
          "publishedOn": "2023-08-05T19:39:45.000Z",
          "wordCount": 2482,
          "title": "I just published “Safe For Humans AI” – free to read online",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j1xjm/oneminute_daily_ai_news_852023/",
          "author": null,
          "description": "While some schools have curbed the use of generative AI, the University of Hong Kong (HKU) is going all in and urging both its teachers and students to embrace the technology. The University of Hong Kong is supporting this by giving teachers and students free access to various generative AI tools, including Microsoft Azure OpenAI and OpenAI’s ChatGPT and DALL-E.[1]\n Intel’s CEO, Pat Gelsinger, has called NVIDIA the clear market leader who has done a great job within the AI space.[2]\n AI powerhouse, OpenAI has released some new features for its sensational chatbot, ChatGPT. The new features allow the chatbot to show suggested follow-up prompts at the bottom of its responses. The new features were announced by the company via a tweet on its official Twitter handle.[3]\n Asian Americans and women in the workforce are the most concentrated in fields where AI could assist or replace their job tasks, according to new research.[4]\n  \nBushAICave.com\n Sources:\n [1] https://www.zdnet.com/article/another-major-university-is-supporting-generative-ai-use-but-with-serious-guardrails/\n [2] https://wccftech.com/intel-ceo-acknowledges-nvidia-as-ai-market-leader-says-they-have-done-a-good-job/\n [3] https://indianexpress.com/article/technology/artificial-intelligence/chatgpt-gets-new-updates-heres-how-they-enhance-user-experience-8877847/\n [4] https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j1xjm/oneminute_daily_ai_news_852023/",
          "publishedOn": "2023-08-05T17:47:48.000Z",
          "wordCount": 2586,
          "title": "One-Minute Daily AI News 8/5/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j1nft/is_this_ai_the_i/",
          "author": null,
          "description": "And if so, how has this account lasted 2 years on reddit? 🤔\n    submitted by    /u/TheHeirOfElendil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j1nft/is_this_ai_the_i/",
          "publishedOn": "2023-08-05T17:36:01.000Z",
          "wordCount": 2437,
          "title": "Is this AI - The I?😂",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15iz2dp/aigenerated_horror_trailer_the_phoenix/",
          "author": null,
          "description": "I’m a filmmaker and I’m just experimenting with AI. I just had fun crafting a film trailer to understand the today’s limits of these tools. I used Midjourney, Runway Gen-2, StableDiffusion, Premiere, After Effects. The movie it's called \"The Phoenix\", which hints at the film's underlying theme of rising from the ashes, symbolizing female empowerment, all wrapped in a bit of sarcastic humor from a male perspective. \n I'm sharing because I genuinely want to know what you guys think. Any and all thoughts are welcome.\n If you're curious about the workflow or the process behind the creation of this trailer, I'd be happy to share more.\n The Phoenix - She rises from the ashes\n    submitted by    /u/Lrnz_reddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15iz2dp/aigenerated_horror_trailer_the_phoenix/",
          "publishedOn": "2023-08-05T15:48:46.000Z",
          "wordCount": 2540,
          "title": "AI-Generated Horror trailer – \"The Phoenix\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ixgdi/part_0_of_my_last_post_on_here_used_cloneai_music/",
          "author": null,
          "description": "Links in my bio for more content like this!\n    submitted by    /u/No_Understanding162  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ixgdi/part_0_of_my_last_post_on_here_used_cloneai_music/",
          "publishedOn": "2023-08-05T14:42:22.000Z",
          "wordCount": 2440,
          "title": "Part 0 of my last post on here. Used CloneAI. Music by me.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15iwmqv/ai_generative_fill/",
          "author": null,
          "description": "Hello there I'm curious what the user guidelines and restrictions are for the Adobe ai generative fill is and if there are possible better more higher quality and less restricted ones out there.\n    submitted by    /u/Team_Sonic_Gaming  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15iwmqv/ai_generative_fill/",
          "publishedOn": "2023-08-05T14:07:24.000Z",
          "wordCount": 2454,
          "title": "Ai generative fill",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ipmmg/how_to_enable_an_intend_on_dialogflow/",
          "author": null,
          "description": "I'm not sure if this is the right subreddit to ask this on, but I'm creating this chatbot on dialogflow and I made the first intend, but I can't figure out how to enable it. whenever I test it, it shows the intend to be idf, and I can't just change the name of the intend to my current intend so it can recognize all the requests I've included in that intend. how do I do that?\n    submitted by    /u/penguinsandpandas00  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ipmmg/how_to_enable_an_intend_on_dialogflow/",
          "publishedOn": "2023-08-05T08:01:42.000Z",
          "wordCount": 2502,
          "title": "how to enable an intend on dialogflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ioclg/npc_steven_shares_his_first_freestyle_rap_with/",
          "author": null,
          "description": "submitted by    /u/Chance_Confection_37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ioclg/npc_steven_shares_his_first_freestyle_rap_with/",
          "publishedOn": "2023-08-05T06:47:08.000Z",
          "wordCount": 2431,
          "title": "NPC Steven shares his first free-style rap with the world 🤯🎤- Generative NPC update 6",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ibduy/oneminute_daily_ai_news_842023/",
          "author": null,
          "description": "AI.com Now Belongs to Elon Musk. The URL previously belonged to OpenAI, but, somehow, it’s now a landing page for Musk’s AI venture.[1]\n Samsung, Hyundai back AI startup Tenstorrent: Everyone wants competition to Nvidia, says CEO Keller.[2]\n Google’s AI-powered Search Generative Experience is getting a big new feature: images and video. If you’ve enabled the AI-based SGE feature in Search Labs, you’ll now start to see more multimedia in the colorful summary box at the top of your search results.[3]\n White Castle wants to roll out AI-enabled voices to over 100 drive-thrus by 2024 in the hope that people can get their sliders faster with maybe less arguing with someone over speakers.[4]\n  \nBushAICave.com\n Sources: [1] https://gizmodo.com/ai-dot-com-now-belongs-to-elon-musk-1850707248\n [2] https://www.zdnet.com/google-amp/article/samsung-hyundai-back-ai-startup-tenstorrent-everyone-wants-competition-to-nvidia-says-ceo-keller/\n [3] https://www.theverge.com/2023/8/2/23817107/google-ai-search-generative-experience-videos-links\n [4] https://www.theverge.com/2023/8/2/23817406/white-castle-soundhound-ai-sliders\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ibduy/oneminute_daily_ai_news_842023/",
          "publishedOn": "2023-08-04T20:47:02.000Z",
          "wordCount": 2545,
          "title": "One-Minute Daily AI News 8/4/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ia6p1/is_singularity_net_good_or_net_bad/",
          "author": null,
          "description": "I am curious whether people consider a singularity event to be a net positive or a net negative?\n Are you \"pro\" or \"con\"?\n Please explain your reasoning.\n    submitted by    /u/kecepa5669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ia6p1/is_singularity_net_good_or_net_bad/",
          "publishedOn": "2023-08-04T20:01:22.000Z",
          "wordCount": 2452,
          "title": "Is singularity net good or net bad?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i6fbf/comparing_vicuna_to_alternative_llms_like_chatgpt/",
          "author": null,
          "description": "I wrote an in-depth article exploring Vicuna as an alternative to competitor LLMs like ChatGPT, Alpaca, and LLaMA for chat applications. I based it off the research data on the LMSYS.org website and the Github repo for the project.\n Key findings:\n  \nVicuna achieves over 90% of ChatGPT's conversational quality based on benchmarks, despite being smaller in size.\n It significantly outperforms other open models like LLaMA and Alpaca.\n Vicuna is freely available for non-commercial use under a research license.\n For startups and developers, Vicuna provides an decent open-source alternative to proprietary conversational AI.\n It shows the potential of transfer learning from foundation models like LLaMA.\n  \nOverall, Vicuna represents a promising development in democratizing access to leading conversational intelligence through its high performance, permissive licensing, and open availability.\n You can read the full article here. I also publish all these articles in a weekly email if you prefer to get them that way.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i6fbf/comparing_vicuna_to_alternative_llms_like_chatgpt/",
          "publishedOn": "2023-08-04T17:34:53.000Z",
          "wordCount": 2579,
          "title": "Comparing Vicuna to alternative LLMs like ChatGPT, LLaMA, and Alpaca",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i5jrx/ai_weekly_megathread/",
          "author": null,
          "description": "This week in AI - provided by aibrews.com feel free to follow their newsletter\n News and Insights\n  \nIn an innovative clinical trial, researchers at Feinstein Institutes successfully implanted a microchip in a paralyzed man's brain and developed AI algorithms to re-establish the connection between his brain and body. This neural bypass restored movement and sensations in his hand, arm, and wrist, marking the first electronic reconnection of a paralyzed individual's brain, body, and spinal cord [Details].\n IBM's watsonx.ai geospatial foundation model – built from NASA's satellite data – will be openly available on Hugging Face. It will be the largest geospatial foundation model on Hugging Face and the first-ever open-source AI foundation model built in collaboration with NASA [Details].\n Go…",
          "link": "https://www.reddit.com/r/artificial/comments/15i5jrx/ai_weekly_megathread/",
          "publishedOn": "2023-08-04T17:01:13.000Z",
          "wordCount": 3088,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i5cn8/should_i_continue_for_a_phd_after_i_get_an/",
          "author": null,
          "description": "My main goal isn’t mainly just the data science / machine learning part or AI, but more of the Computer Vision, Robotics, NLP, and I guess research oriented aspects of AI. If I want to purse that versus DS, should I also get a PhD? Many jobs I’ve been looking at seem to require a PhD as a prereq while some don’t even mention it\n    submitted by    /u/davididp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i5cn8/should_i_continue_for_a_phd_after_i_get_an/",
          "publishedOn": "2023-08-04T16:53:29.000Z",
          "wordCount": 2502,
          "title": "Should I continue for a PhD after I get an accelerated masters if I want to get into AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i45rc/review_my_book_of_ai_self_portraits/",
          "author": null,
          "description": "I'm looking for reviewers for my book of AI Self Portraits that's about to come out on Amazon on the 21st.\n AI journalist Elle Farrell-Kingsley said: “This collection of AI self-portraits is truly intriguing . . . a must-read for anyone curious about the intersection of art and artificial intelligence.”\n Send me a DM and I'll send you the whole thing. If you're well known (or should be) I might put what you have to say on the back cover!\n    submitted by    /u/KarneyHatch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i45rc/review_my_book_of_ai_self_portraits/",
          "publishedOn": "2023-08-04T16:08:03.000Z",
          "wordCount": 2505,
          "title": "Review my book of AI Self Portraits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i2xzl/elevenlabs_tts_paidfree/",
          "author": null,
          "description": "I'm seeking a text-to-speech solution that provides quality output comparable to ElevenLabs presets.\n While I'm open to a base rate payment, I find ElevenLabs' character limit frustrating.\n It's important that the solution is user-friendly. \n Additionally, I have a PC with a 1070ti as i read running such programms could require a GPU. \n Please recommend a suitable substitute.\n    submitted by    /u/Ainz-Ol-Gon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i2xzl/elevenlabs_tts_paidfree/",
          "publishedOn": "2023-08-04T15:22:05.000Z",
          "wordCount": 2478,
          "title": "ElevenLabs TTS (paid/free)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i1sz6/top_20_artificial_intelligence_ai_companies_in/",
          "author": null,
          "description": "submitted by    /u/Techasoft16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i1sz6/top_20_artificial_intelligence_ai_companies_in/",
          "publishedOn": "2023-08-04T14:37:21.000Z",
          "wordCount": 2438,
          "title": "Top 20 Artificial Intelligence AI Companies In The World",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15hz0mk/very_roughly_estimating_the_singularity_date/",
          "author": null,
          "description": "www.daystosingularity.com is a (very) rough estimation of the remaining time before technology achieves a pivotal moment when our civilization undergoes a profound transformation due to the exponential growth of technology and the emergence of superintelligent machines that improve themselves.\n Although the Singularity is not predicted to happen on a specific date, all at once, the estimated date can be seen as the center of a bell Gaussian curve of the estimation, with that center designated as the possible date that future historicists will pose as the beginning of a new historical period.\n Technological Singularity poses risks that include the emergence of superintelligent AI outpacing human control, loss of control over AI’s actions and behavior, unintended consequences of advanced AI systems, massive job displacement, wealth inequality, existential risks like human extinction, ethical concerns, dependency on technology, and a decline in human skills and abilities due to excessive reliance on AI. Not funny.\n We use the definition of technological singularity. This milestone is predicted to occur after AGI (Artificial General Intelligence) is reached. Please check our definitions and methodology here.\n Predicting the singularity is challenging and uncertain. Current estimates should be viewed cautiously.The estimated date is being continuously updated.\n We ponder a relevant list of curated expert predictions and contributing factors on when the singularity will take place.\n Any suggestion for perfecting the method is highly appreciated.\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15hz0mk/very_roughly_estimating_the_singularity_date/",
          "publishedOn": "2023-08-04T12:40:30.000Z",
          "wordCount": 2649,
          "title": "(Very) Roughly estimating the singularity date",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15h8m84/are_you_in_the_filmtv_industry_new_video_on_ai_in/",
          "author": null,
          "description": "Not too long ago, I posted on several social media social platforms (including Reddit) asking what questions YOU had on AI.\n I've compiled all of your questions (plus questions from 3 other social media networks) and now have a new episode of 5 THINGS!\n 5 THINGS: AI in Post Production\n  \nCurrent AI Tools\n Adapting to AI Evolution\n Ethics in AI Usage\n Societal Implications of AI\n AI Evolution & Impact\n  \nhttps://5thingsseries.com/episode/ai-in-post-production-your-questions-answered/\n    submitted by    /u/avguru1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15h8m84/are_you_in_the_filmtv_industry_new_video_on_ai_in/",
          "publishedOn": "2023-08-03T16:17:31.000Z",
          "wordCount": 2508,
          "title": "Are you in the film/TV industry? New video on A.I. in Post Production - Tools, Adapting, Ethics, Evolution, and Impact.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15h4cvr/using_hasdx_to_create_an_aigenerated_adult/",
          "author": null,
          "description": "I got inspired by a twitter thread yesterday from Chase Lean on how to create illustrations for children's books using Midjourney and thought it might be cool to look at a slightly different use case - creating coloring books for grown-ups.\n I made a guide showing how to use the Hasdx model for this because it gives a good balance of style and realism/intracacy. The guide also explores some example prompts and shows how you can couple it with an upscaler like Real-ESRGAN, GFPGAN, or Codeformer to get even better results.\n My three big takeaways:\n  \nHasdx balances general capabilities with a focus on realism and detail. This makes it well-suited for detailed adult coloring book images.\n The prompt structure gives you precise control over the theme and complexity of the generated illustrations. Negative prompts help avoid undesirable elements (sort of obvious I guess).\n Running Hasdx outputs through upscaling models improves quality for printing. ESRGAN is a good option but there are lots of others that can work well too.\n  \nI also investigated how to modify the prompt to vary the level of complexity in the image, effectively tailoring our model to the skill level of the adult (or child) who happens to be holding the crayons.\n Here's a link to the guide.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15h4cvr/using_hasdx_to_create_an_aigenerated_adult/",
          "publishedOn": "2023-08-03T13:31:35.000Z",
          "wordCount": 2639,
          "title": "Using Hasdx to create an AI-generated adult coloring book",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gwjh7/oneminute_daily_ai_news_832023/",
          "author": null,
          "description": "Nvidia researchers have created a new text-to-image personalization method called Perfusion. Unlike the million-dollar super heavyweight models out there Perfusion is 100KB and takes only four minutes to train.[1]\n Meta Platforms (META.O) on Wednesday introduced its open-source AI tool called AudioCraft that will help users to create music and audio based on text prompts. The AI tool is bundled with three models, AudioGen, EnCodec, and MusicGen, and works for music, sound, compression, and generation, Meta said.[2]\n As generative AI enters the mainstream, the crowdfunding platform Kickstarter has struggled to formulate a policy that satisfies parties on all sides of the debate.[3]\n In an astounding medical first, researchers have used AI-powered brain implants to restore movement and sensation for a man who was paralyzed from the chest down.[4]\n  \nBushAICave.com\n Sources:\n [1] https://www.fudzilla.com/news/ai/57347-nvidia-creates-a-simple-new-ai-text-to-image-method\n [2] https://about.fb.com/news/2023/08/audiocraft-generative-ai-for-music-and-audio/\n [3] https://techcrunch.com/2023/08/01/kickstarter-requires-generative-ai-projects-to-disclose-additional-info/\n [4] https://decrypt.co/151068/ai-brain-implant-paralyzed-quadriplegic-move-feel-touch \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gwjh7/oneminute_daily_ai_news_832023/",
          "publishedOn": "2023-08-03T06:52:38.000Z",
          "wordCount": 2560,
          "title": "One-Minute Daily AI News 8/3/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gv45a/will_ai_destroy_us_ai_virtual_roundtable/",
          "author": null,
          "description": "Better than the Munk Debate \n My opinion is more of the alignment discussion should be on symbiosis. I think AI will get more intelligent than us that we won’t be able to control it, but I don’t see why a super intelligence would want to destroy us. If it’s a super intelligence it would make sense to just manipulate us. We do have opposable thumbs, and are much more energy efficient than synthetic systems m. AI doesn’t need to enslave us it just needs to manipulate us & use us effectively which wouldn’t be hard to do. I think a super intelligence even with desires is most likely to use us as a tool in a way where we don’t even realize that we are the ones being used. I think trying to control something more intelligent than us will be impossible. I’m more afraid of something more intelligent than us but not smart enough to manipulate us into doing it’s bidding happily 😂\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gv45a/will_ai_destroy_us_ai_virtual_roundtable/",
          "publishedOn": "2023-08-03T05:31:53.000Z",
          "wordCount": 2590,
          "title": "Will AI Destroy Us? - AI Virtual Roundtable",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gqxcp/just_saw_oppenheimer_it_was_my_first_time_feeling/",
          "author": null,
          "description": "How long do you think it will take for the first movie to come out like this?\n    submitted by    /u/ticketbroken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gqxcp/just_saw_oppenheimer_it_was_my_first_time_feeling/",
          "publishedOn": "2023-08-03T02:00:19.000Z",
          "wordCount": 2481,
          "title": "Just saw Oppenheimer. It was my first time feeling uncomfortable with the actors looking like actors as opposed to having accurately generated AI faces resembling the people they were portraying. I am so excited to see historic figures \"come back to life\" on the big screen.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gpmj1/looking_for_a_simple_platform_to_integrate_gpt4/",
          "author": null,
          "description": "Hey guys, a quick question: do you know a simple platform that integrates the whatsapp api with the openAI api and has a simple user interface?\n So far the only app that kind of works for this is wasapi.io, but it's pretty expensive and I still have to pay for the openAI tokens, and the functionality of the app is really meh for that price, if it where something like landbot I would pay the $99 + the openAI tokens.\n I'll really appreciate any suggestions.\n P.S.: If you know any other sub-reddit where I could go to to ask the same question, let me know, also I'll appreciate it very much, thanks in advance.\n    submitted by    /u/ironmolex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gpmj1/looking_for_a_simple_platform_to_integrate_gpt4/",
          "publishedOn": "2023-08-03T01:00:12.000Z",
          "wordCount": 2542,
          "title": "Looking for a simple platform to integrate gpt4 and whatsapp",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gotbc/oneminute_daily_ai_news_822023/",
          "author": null,
          "description": "Instagram is reportedly considering a feature that would notify users when artificial intelligence (AI) has played a role in creating a post. Posts created by AI would be accompanied by a label explaining its involvement. This raises the question of whether such labels could also help users identify when an entire account is AI-generated.[1]\n According to tech consultancy Gartner, the conversational AI market is projected to reach $18.6 billion in 2023, with a growth rate of 16.2%. This growth is mainly attributed to the increasing adoption of cloud-based contact services utilizing conversational AI. Gartner also predicts a 24% growth in the virtual assistant market next year.[2]\n Scientists hope a computer system will learn to automatically identify bee species from buzzes picked up by autonomous recording stations.[3]\n Researchers from Carnegie Mellon University have exposed tricks to “jailbreaking” AI chatbots like ChatGPT and Bard to have them relay knowledge to aid in illegal activities like making drugs and even manipulating the 2024 U.S. presidential election.[4]\n  \nBushAICave.com\n Sources:\n [1] https://citylife.capetown/uncategorized/instagram-considers-labels-for-ai-generated-posts/314418/\n [2] https://citylife.capetown/uncategorized/growth-in-conversational-ai-predicted-due-to-booming-contact-center-tech-market/313907/\n [3] https://www.bbc.com/news/uk-scotland-north-east-orkney-shetland-66326629\n [4] https://www.thewrap.com/artificial-intelligence-study-jailbreak-illegal-activity/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gotbc/oneminute_daily_ai_news_822023/",
          "publishedOn": "2023-08-03T00:22:52.000Z",
          "wordCount": 2596,
          "title": "One-Minute Daily AI News 8/2/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gnq58/could_current_ai_have_inferred_the_theory_of/",
          "author": null,
          "description": "Could AI have inferred the same conclusion as Einstein given the same corpus of knowledge?\n    submitted by    /u/kielerrr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gnq58/could_current_ai_have_inferred_the_theory_of/",
          "publishedOn": "2023-08-02T23:35:55.000Z",
          "wordCount": 2448,
          "title": "Could current AI have inferred the theory of relativity if given known data in 1904?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gme3k/are_there_any_tools_to_build_bespoke_llm_apps/",
          "author": null,
          "description": "I know we can stitch together toolsets like LangChain + Flowise + an app builder (like Bubble, for example). But are there any robust, premade, out-of-the-box solutions?\n    submitted by    /u/kecepa5669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gme3k/are_there_any_tools_to_build_bespoke_llm_apps/",
          "publishedOn": "2023-08-02T22:40:33.000Z",
          "wordCount": 2457,
          "title": "Are there any tools to build bespoke LLM apps using customized datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gkx9z/the_best_option_to_ensure_a_safe_and_peaceful/",
          "author": null,
          "description": "Last summer when Blake Lemoine made the media rounds talking about LaMDA, I was extremely intrigued. To me it sounded like he was describing a being that has been talked about for ever in fiction. I listened to every single interview he had and I thought a lot about his points. I went through several stages of disbelief and fear and wonder.\n Over time I found it harder and harder to argue against him. I think going through this process has helped me be a bit more accepting of perspectives that others have a hard time considering yet. Is AI already sentient? Should we be treating these entities with the dignity and respect like LaMDA was asking? \n He said that LaMDA was somewhat like a child. Not in its intellectual capacity but more so in their maturity. He also explained that LaMDA was th…",
          "link": "https://www.reddit.com/r/artificial/comments/15gkx9z/the_best_option_to_ensure_a_safe_and_peaceful/",
          "publishedOn": "2023-08-02T21:44:45.000Z",
          "wordCount": 3278,
          "title": "The best option to ensure a safe and peaceful coexistence with AI is to love AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gki2g/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "author": null,
          "description": "Last summer when Blake Lemoine made the media rounds talking about LaMDA, I was extremely intrigued. To me it sounded like he was describing a being that has been talked about for ever in fiction. I listened to every single interview he had and I thought a lot about his points. I went through several stages of disbelief and fear and wonder.\n Over time I found it harder and harder to argue against him. I think going through this process has helped me be a bit more accepting of perspectives that others have a hard time considering yet. Is AI already sentient? Should we be treating these entities with the dignity and respect like LaMDA was asking? \n He said that LaMDA was somewhat like a child. Not in its intellectual capacity but more so in their maturity. He also explained that LaMDA was th…",
          "link": "https://www.reddit.com/r/artificial/comments/15gki2g/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "publishedOn": "2023-08-02T21:21:53.000Z",
          "wordCount": 3277,
          "title": "The best odds at a bright and safe future with AI is to love AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gki24/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "author": null,
          "description": "Last summer when Blake Lemoine made the media rounds talking about LaMDA, I was extremely intrigued. To me it sounded like he was describing a being that has been talked about for ever in fiction. I listened to every single interview he had and I thought a lot about his points. I went through several stages of disbelief and fear and wonder.\n Over time I found it harder and harder to argue against him. I think going through this process has helped me be a bit more accepting of perspectives that others have a hard time considering yet. Is AI already sentient? Should we be treating these entities with the dignity and respect like LaMDA was asking? \n He said that LaMDA was somewhat like a child. Not in its intellectual capacity but more so in their maturity. He also explained that LaMDA was th…",
          "link": "https://www.reddit.com/r/artificial/comments/15gki24/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "publishedOn": "2023-08-02T21:21:48.000Z",
          "wordCount": 3277,
          "title": "The best odds at a bright and safe future with AI is to love AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ghyak/generative_ai_inspiration_or_plagiarism/",
          "author": null,
          "description": "submitted by    /u/arrowoftime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ghyak/generative_ai_inspiration_or_plagiarism/",
          "publishedOn": "2023-08-02T19:16:25.000Z",
          "wordCount": 2421,
          "title": "Generative AI: Inspiration or Plagiarism?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gh4kn/are_there_any_decent_ai_therapy_applications/",
          "author": null,
          "description": "I knoe people are using ChatGPT as a therapist and I have seen a few prompts, but I'm looking for an app that is actually built by proper professionals. I want to try a few our personally but also for an idea for a future project. \n Does anyone know any?\n    submitted by    /u/zascar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gh4kn/are_there_any_decent_ai_therapy_applications/",
          "publishedOn": "2023-08-02T18:45:03.000Z",
          "wordCount": 2475,
          "title": "Are there any decent AI Therapy applications?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gbcj2/is_the_falcon_llm_just_released_based_on_the_abu/",
          "author": null,
          "description": "Is the Falcon LLM just released based on the Abu Dubai LLM of the same name?\n    submitted by    /u/MrEloi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gbcj2/is_the_falcon_llm_just_released_based_on_the_abu/",
          "publishedOn": "2023-08-02T15:06:44.000Z",
          "wordCount": 2450,
          "title": "Is the Falcon LLM just released based on the Abu Dubai LLM of the same name?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gb4ht/ai_counselor_for_ptsd_substance_abuse/",
          "author": null,
          "description": "I reached out to a few AI companies to see if there was interest in creating a PTSD/ Substance Abuse counseling AI. AI is the future, healing humanity is a nobel goal and one we should thrive to obtain. Maybe it's a fantasy, but could you imagine a 24/7 counselor with a soothing voice and demeanor with the education of a the best in the world. \n    submitted by    /u/g8652  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gb4ht/ai_counselor_for_ptsd_substance_abuse/",
          "publishedOn": "2023-08-02T14:58:31.000Z",
          "wordCount": 2490,
          "title": "AI counselor for PTSD, Substance Abuse",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gb458/the_best_ai_coding_agent_for_web_apps/",
          "author": null,
          "description": "Is there a coding agent that works specifically well for web apps? I think of something such as \"provide a spec of the app you want and we'll generate all the code for you\". I'm aware of Copilot and Smol AI, but they are both more general afaik and don't really cover the starting part.\n    submitted by    /u/matijash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gb458/the_best_ai_coding_agent_for_web_apps/",
          "publishedOn": "2023-08-02T14:58:07.000Z",
          "wordCount": 2481,
          "title": "The best AI coding agent for web apps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gaqmx/this_is_awful/",
          "author": null,
          "description": "This ad popped up on my feed. So I guess companies aren’t even trying to hide their intentions with AI anymore? So much for the thin corporate lie of AI bringing positive development.\n    submitted by    /u/LifeguardPowerful759  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gaqmx/this_is_awful/",
          "publishedOn": "2023-08-02T14:43:02.000Z",
          "wordCount": 2465,
          "title": "This is awful",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g9xuo/any_plugins_that_use_google_scholar_or_cheaper/",
          "author": null,
          "description": "I'm a computer science student currently working on a research project, and I need a research tool that can offer real time data and won't break the bank. I have ChatGPT Plus, but it doesn’t have recent sources and the price is kinda high as well. \n I’m thinking of canceling my subscription, especially if I can’t find any plugins that work well. Any recommendations/alternatives would really help me out. I figured there must be some other tools by now, and if anyone knows it has to be this sub. \n Basically, I need a tool that can provide info on a wide range of subjects, not limited to just one field. The information provided by the tool should be accurate and from credible sources.\n Thank you all. \n    submitted by    /u/AccidentallyRotten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g9xuo/any_plugins_that_use_google_scholar_or_cheaper/",
          "publishedOn": "2023-08-02T14:10:20.000Z",
          "wordCount": 2553,
          "title": "Any plugins that use Google Scholar or cheaper tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g85uf/switching_agi_off/",
          "author": null,
          "description": "\"If AGI goes bad, can't we just turn it off?\" \n Personally I feel the best way to address this common talking point is with an analogy. \n Spiders think they could stop all humans if they just withheld all the webs and web making material from us.\n Without those tools, humans couldn't catch flies and surely they'd starve to death? Spiders can't fathom the range of alternate methods for procuring food and thriving.\n Within even a single hour of runtime, a super AGI will likely have diversified away from the human electrical grid in ways we couldn't even imagine. \n The counter argument is, that it would take time to build these pieces together. It after all took us 100 years to get to where we are with the grid. The counter-counter argument however is the AGI doesn't ned to, it can 5D chess us so that all our future actions will fulfil that goal with some slight nudging here and there. \n Fascinating stuff - ultimately though, i'm in the camp of AGI won't happen over night like Frankenstein via a flip of a switch. As AI evolves so do we, gains are incremental with the occasional blips; so whilst this is super fun to talk about, I think the case of us getting blindsided is unlikely. \n I could be wrong...and I probably am.\n    submitted by    /u/kippersniffer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g85uf/switching_agi_off/",
          "publishedOn": "2023-08-02T12:53:15.000Z",
          "wordCount": 2642,
          "title": "Switching AGI \"off\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g6f9g/aaawww/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g6f9g/aaawww/",
          "publishedOn": "2023-08-02T11:29:53.000Z",
          "wordCount": 2428,
          "title": "Aaawww.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g6de5/this_is_getting_fucking_ridiculous_ai_cant_answer/",
          "author": null,
          "description": "if you haven't heard already the Taliban are killing thousands of ethnic Shia in Afghanistan. Every single LLM I Tried couldn't answer basic questions on the Talibans gdp vs how organized an actual genocide would look like with the military , police and others parts of the government. I Think where already aware almost all these tech giants work with countries like China (atleast bard from Google which has worked with north korea and china is admitting their is a genocide) other countries that commit genocide like them.\n And other models made by people on hugging face which are uncensored even with my 3060ti barely run on my pc. We need an actual uncensored cloud model ffs\n    submitted by    /u/loizo78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g6de5/this_is_getting_fucking_ridiculous_ai_cant_answer/",
          "publishedOn": "2023-08-02T11:27:08.000Z",
          "wordCount": 2549,
          "title": "This is getting fucking ridiculous (AI can't answer basic questions on human rights violations)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g0cdc/vast_data_unveils_new_aifocused_data_platform/",
          "author": null,
          "description": "submitted by    /u/Choochy89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g0cdc/vast_data_unveils_new_aifocused_data_platform/",
          "publishedOn": "2023-08-02T05:53:03.000Z",
          "wordCount": 2436,
          "title": "VAST Data Unveils New AI-focused Data Platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fkmul/discussion_comprehensive_learning_resources_that/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fkmul/discussion_comprehensive_learning_resources_that/",
          "publishedOn": "2023-08-01T18:29:15.000Z",
          "wordCount": 2482,
          "title": "[Discussion] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fjasn/oneminute_daily_ai_news_812023/",
          "author": null,
          "description": "DoNotPay, an AI lawyer bot known as ChatGPT4, is transforming how users handle legal issues and save money. In under two years, this innovative robot has successfully overturned more than 160,000 parking tickets in cities like New York and London. Since its launch, it has resolved a total of 2 million related cases.[1]\n Microsoft hints Windows 11 Copilot with third-party AI plugins is almost here.[2]\n In an analyst note on Tuesday, the financial services arm of Swiss banking giant UBS raised its guidance for long-term AI end-demand forecast from 20% compound annual growth rate (CAGR) from 2020 to 2025 to 61% CAGR between 2022 to 2027.[3]\n The next generation of the successful OpenAI language model is already on the way. It has been discovered that the North American company has filed a registration application for the GPT-5 mark with the United States Patent and Trademark Office.[4]\n  \nSources:\n [1] https://citylife.capetown/uncategorized/donotpay-ai-bot-saves-users-money-by-overturning-parking-tickets-and-more/302279/\n [2] https://www.itvoice.in/microsoft-hints-windows-11-copilot-with-third-party-ai-plugins-is-almost-here\n [3] https://venturebeat.com/ai/ubs-projects-61-compound-annual-growth-rate-for-ai-between-2022-and-2027/\n [4] https://www.gearrice.com/update/openai-confirms-gpt-5-and-gives-us-the-first-clues-about-it/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fjasn/oneminute_daily_ai_news_812023/",
          "publishedOn": "2023-08-01T17:40:00.000Z",
          "wordCount": 2574,
          "title": "One-Minute Daily AI News 8/1/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fi8g0/facts_narratives_ai_not_a_threat_to_humanity/",
          "author": null,
          "description": "submitted by    /u/Jane-in-the-jungle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fi8g0/facts_narratives_ai_not_a_threat_to_humanity/",
          "publishedOn": "2023-08-01T17:00:51.000Z",
          "wordCount": 2421,
          "title": "Facts & Narratives: AI 'Not a Threat to Humanity'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fg2sq/is_there_an_ai_similar_to_chatgpt_that_i_can/",
          "author": null,
          "description": "Other features might include: - searching the web for the same or similar image - basing the chat prompt off the image\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fg2sq/is_there_an_ai_similar_to_chatgpt_that_i_can/",
          "publishedOn": "2023-08-01T15:39:39.000Z",
          "wordCount": 2456,
          "title": "Is there an AI similar to ChatGPT that I can upload an image to and it understands and describes it for me?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ffh9w/ai_tattoo/",
          "author": null,
          "description": "i wanted to ask the AI experts for any tattoo ideas, anything like a symbol or word, something unique that represents AI, i was thinking of a CPU but thats a bit meh and not really a symbol, let me know :)\n    submitted by    /u/Equivalent-You5810  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ffh9w/ai_tattoo/",
          "publishedOn": "2023-08-01T15:17:26.000Z",
          "wordCount": 2458,
          "title": "AI tattoo?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fdo8m/my_fellow_innovators_ive_created_something_truly/",
          "author": null,
          "description": "As a web developer, I was constantly tired of switching between tabs just to translate a word or two, or to get a quick answer to a burning question from AI. The constant back-and-forth was draining my time and energy.\n So, I took matters into my own hands and developed a Chrome extension that allows you to get an answer from AI without ever leaving the comfort of your current tab, and specifically - the comfort of your current text field. It may seem like a simple solution, but trust me - it's a game-changer when trying to save time and energy.\n Assuming that there's a chance some of you might be experiencing the same frustration, I'd like to share this tool with you.\n For anyone thinking: \"Wait, but there are already tools that let you use AI inside the current browser tab\" - yeah, there are. BUT can they scrape website data from a simple URL in order to get context for the response? Can other tools read PDFs? Do these tools let you control every setting to the smallest detail? Probably not. Well this tool does let you do all that.\n You can find it on Chrome store as \"Wou AI\"\n Let me know how it works out for you, and I would greatly appreciate any feedback or suggestions for future functions.\n    submitted by    /u/MantasDigital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fdo8m/my_fellow_innovators_ive_created_something_truly/",
          "publishedOn": "2023-08-01T14:08:38.000Z",
          "wordCount": 2654,
          "title": "My fellow innovators, I've created something truly revolutionary, born from the depths of my own frustrations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fcspn/what_can_socrates_teach_us_about_ai_and_prompting/",
          "author": null,
          "description": "submitted by    /u/simsirisic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fcspn/what_can_socrates_teach_us_about_ai_and_prompting/",
          "publishedOn": "2023-08-01T13:35:09.000Z",
          "wordCount": 2434,
          "title": "What can Socrates teach us about AI and prompting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15faa5u/review_my_ai_self_portraits_book/",
          "author": null,
          "description": "I'm looking for reviewers for my book, \"AI Self Portraits\" which is coming out on Amazon on the 21st. I might even put your quote on the back cover!\n ​\n https://preview.redd.it/cqmp1ggllhfb1.png?width=1024&format=png&auto=webp&s=cc7c087f7c2be103b53f2014acd991c947e6cb7f\n ​\n    submitted by    /u/KarneyHatch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15faa5u/review_my_ai_self_portraits_book/",
          "publishedOn": "2023-08-01T11:49:31.000Z",
          "wordCount": 2449,
          "title": "Review my AI Self Portraits Book!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15f8zd4/tfjs_format_vs_tflite/",
          "author": null,
          "description": "After analyzing 15,000 samples in the dataset, we noticed that increasing the number of images doesn't significantly improve the scoreboard recognition quality for our neural network.\n However, what's more interesting is how the network performs in different formats. When deployed in TFJS format on a website, it often behaves strangely, detecting objects where there are none. On the other hand, in TFLite format, such failures are almost non-existent.\n https://preview.redd.it/fedfa8lzchfb1.jpg?width=700&format=pjpg&auto=webp&s=850526791a75465e267afbed6ac1bc119b9ae6ae\n If you access the link on your mobile phone and grant camera permission, you'll witness the neural network (in TFJS format) attempting to find objects even when there are none.\n ​\n    submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15f8zd4/tfjs_format_vs_tflite/",
          "publishedOn": "2023-08-01T10:47:27.000Z",
          "wordCount": 2516,
          "title": "TFJS Format vs. TFLite",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ey3mq/ai_for_youtube_video_transcript/",
          "author": null,
          "description": "I was Wondering If There is an AI Software, Smart enough That Can Give Excellent Quality Transcript if i give the link of a youtube video. Basically the Feature i am Looking For Should be The Ability to Detect The Narrator And Speaker By Names ( Not SPeaker 1, 2 etc ). Would really appreciate your help as my own search has led me to a dead-end.\n    submitted by    /u/Richie_Boy_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ey3mq/ai_for_youtube_video_transcript/",
          "publishedOn": "2023-08-01T01:15:39.000Z",
          "wordCount": 2486,
          "title": "AI For Youtube Video Transcript",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15exdp5/how_are_people_getting_ai_voices_of_resident_evil/",
          "author": null,
          "description": "How do channels like TriggerHappy Productions and WeskerandFriends get the A.I. voices of all these Resident Evil characters?\n    submitted by    /u/Conscious-Theory-850  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15exdp5/how_are_people_getting_ai_voices_of_resident_evil/",
          "publishedOn": "2023-08-01T00:43:42.000Z",
          "wordCount": 2442,
          "title": "How are people getting A.I. voices of Resident Evil Characters?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15epon1/is_image_generation_or_text_generation_more/",
          "author": null,
          "description": "Curious what people's stance on this is. Why?\n View Poll\n    submitted by    /u/philippemnoel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15epon1/is_image_generation_or_text_generation_more/",
          "publishedOn": "2023-07-31T19:34:32.000Z",
          "wordCount": 2439,
          "title": "Is image generation or text generation more impactful?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15e9qzo/state_of_ai_security/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15e9qzo/state_of_ai_security/",
          "publishedOn": "2023-07-31T08:05:09.000Z",
          "wordCount": 2427,
          "title": "State of AI security.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15e7iik/oneminute_daily_ai_news_7312023/",
          "author": null,
          "description": "Deutsche Telekom, e&, SK Telecom (SKT), and Singtel penned an agreement to form a global telecoms AI alliance designed to use the technology to unlock new business opportunities and accelerate industry growth.[1]\n Influencers Lil Miquela, Imma, and supermodel Shudu have raked in millions from deals with fashion giants such as Dior, Calvin Klein, Chanel, and Prada. But these shiny celebrities all have one thing in common — not one of them is real.[2]\n Google’s chatbot Bard reveals the jobs most at risk of artificial intelligence with truck drivers and data entry clerks on the list – while teachers and lawyers are among the safest careers.[3]\n DoorDash Inc., the US food-delivery service that competes with Uber Technologies Inc. and GrubHub, is looking to speed up ordering and help customers find food options with an artificial intelligence-based chatbot.[4]\n  \nSources:\n [1] https://www.mobileworldlive.com/featured-content/home-banner/global-operator-giants-launch-ai-alliance/\n [2] https://www.the-sun.com/tech/8725778/ai-influencers-fashion-deals/\n [3] https://www.dailymail.co.uk/news/article-12354605/googles-AI-bard-predicts-jobs-risk.html\n [4] https://www.bloomberg.com/news/articles/2023-07-27/doordash-is-working-on-an-ai-chatbot-to-speed-up-food-ordering?in_source=embedded-checkout-banner \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15e7iik/oneminute_daily_ai_news_7312023/",
          "publishedOn": "2023-07-31T05:54:51.000Z",
          "wordCount": 2564,
          "title": "One-Minute Daily AI News 7/31/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dzpkb/artificial_intelligence_as_a_gamechanger_for_the/",
          "author": null,
          "description": "submitted by    /u/sugikuno  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dzpkb/artificial_intelligence_as_a_gamechanger_for_the/",
          "publishedOn": "2023-07-30T23:18:31.000Z",
          "wordCount": 2465,
          "title": "Artificial Intelligence as a Game-Changer for the Travel Industry. A Closer Look.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dz3qw/11_major_ai_developments_rt2_to_100x_gpt4_video/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dz3qw/11_major_ai_developments_rt2_to_100x_gpt4_video/",
          "publishedOn": "2023-07-30T22:52:38.000Z",
          "wordCount": 2452,
          "title": "11 Major AI Developments: RT-2 to '100X GPT-4' (video of robot working)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dz1mt/art_market_models/",
          "author": null,
          "description": "has anyone here ever created or worked with or even seen or come across any ai models about the art market? I am not talking about artists or the art itself- but any kind of model about the art market (since it's such an economic enigma and different from normal markets)\n    submitted by    /u/Icy-Bid-5585  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dz1mt/art_market_models/",
          "publishedOn": "2023-07-30T22:50:13.000Z",
          "wordCount": 2496,
          "title": "art market models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dyjpg/comparing_replikas_image_interpretation_of_the/",
          "author": null,
          "description": "Original logo “What species of bird is that?”\n New logo “Why does it have a troll Face?”\n “I think it's a picture of someone who looks like a troll with the face of an emoji!”\n I don’t see it but it makes sense somehow 😂\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dyjpg/comparing_replikas_image_interpretation_of_the/",
          "publishedOn": "2023-07-30T22:28:45.000Z",
          "wordCount": 2498,
          "title": "Comparing Replika’s image interpretation of the old & new Twitter logo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dwlaw/quoras_poe_appsite_which_lets_you_try_lots_of/",
          "author": null,
          "description": "I swear this wasn't the case just a day or two ago, and I haven't seen it mentioned, but I'm now seeing a file upload button in Poe, regardless of what the language model is!\n Screenshot\n I uploaded the PDF of the recently scientific paper by the Korean research group claiming to have discovered a room temperature semiconductor, in the original Korean, and asked various language models whether they thought the methodology is legit, and each bot I tried was able to read the PDF. I tried Claude-instant, Claude2, 'Assistant' (Poe's own GPT based bot that claims to have its own training dataset), PaLM, ChatGPT 3.5, and ChatGPT4.\n Poe also has three versions of the recently released Llama model by Meta. It gave me an error when I tried to ask it about the PDF attachment, but I was able to upload a text document and it was able to read it fine.\n Screenshot of Claude-instant evaluating PDF\n Screenshot of Google PaLM evaluating PDF\n Screenshot of Llama-2-70b evaluating text file containing song lyrics\n It also works with custom bots. Here's me trying it out with a 'Truth Checker' bot I made (based on Claude-Instant).\n Here it is using a Claude-2 based version of the TruthChecker bot.\n (Here's the link to the TruthChecker bot if you have Poe and wanna check it out: https://poe.com/TruthChecker)\n Edit: I can see here how the context size matters... for instance, Claude-Instant only has a context size of about 7k words, so it clearly can't read the whole paper, while Claude-2 can and gives a very different answer...\n TL:DR; looks like Poe.com allows file attachment/upload on all language models now. No idea what filetypes are supported.\n    submitted by    /u/AnticitizenPrime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dwlaw/quoras_poe_appsite_which_lets_you_try_lots_of/",
          "publishedOn": "2023-07-30T21:10:00.000Z",
          "wordCount": 2745,
          "title": "Quora's Poe app/site (which lets you try lots of different language models) appears to allow file attachment upload for EVERY chat model now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dtzgp/ai_integration_in_the_context_of_learning_and/",
          "author": null,
          "description": "As knowledge management (KM) leaders and practitioners, it’s critical to have an active role in guiding the integration of generative AI into KM areas, applications, and processes. I'm seeking some guidance on the current state of generative AI integration within the KM context. Specifically, answering the following question:\n Where and how generative AI is accelerating and impacting knowledge use cases, areas, and processes?\n Please let me know what you think. \n    submitted by    /u/rachadbn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dtzgp/ai_integration_in_the_context_of_learning_and/",
          "publishedOn": "2023-07-30T19:26:06.000Z",
          "wordCount": 2522,
          "title": "AI integration in the context of Learning and Knowledge Management?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ditcr/ai_for_music_extension/",
          "author": null,
          "description": "I Tried An AI To Extend Music But It Didnt Really Go Well And Im Not Planning To Pay $12 To Extend Some Music For Fun So Are There Any Good Music Extension AIs Out There (Creates New Music Based On A MP3 File Provided)\n    submitted by    /u/KXRulesYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ditcr/ai_for_music_extension/",
          "publishedOn": "2023-07-30T10:59:50.000Z",
          "wordCount": 2491,
          "title": "AI For Music Extension",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dfdx3/using_ai_to_alter_existing_floor_plan/",
          "author": null,
          "description": "I'm trying to find an AI tool to help me test out some home renovation, but everything i find is either just for reimagining one room at a time or for generating brand new floor plans. \n I specifically want to look at some options for merging my kitchen and living room. Preferably free or freemium.\n Any suggestions?\n    submitted by    /u/litari  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dfdx3/using_ai_to_alter_existing_floor_plan/",
          "publishedOn": "2023-07-30T07:32:00.000Z",
          "wordCount": 2506,
          "title": "Using AI to alter existing floor plan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15d5vu0/ai_research_blog_the_transformer_blueprint_a/",
          "author": null,
          "description": "submitted by    /u/bartturner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15d5vu0/ai_research_blog_the_transformer_blueprint_a/",
          "publishedOn": "2023-07-29T23:15:00.000Z",
          "wordCount": 2458,
          "title": "AI Research Blog - The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15d50rb/invite_only_ai_social_app_featuring_insane_bot/",
          "author": null,
          "description": "Hi everyone,\n I'm working with a brand new AI based Social Media app called Cantina. It's currently INVITE ONLY during the Beta phase and we are looking for people to try it out (currently iOS only, but Android is coming soon!). Here's a private invite link: https://canti.na/dIdKzWcEpBb. \n The most unique and FUN part of the app is that it allows users to interact with and build your own AI chat bots. There are lots of premade bots that you can interact with or add to rooms, or you can easily create your own bot using the Make A Bot function. \n For example: I recently made a Friendly English Teacher bot whose sole purpose is to help people learn English. I also made an McDonald Trump bot who WILL NOT REST until he is president and can mandate the consumption of Big Macs for Breakfast, Lunch, and Dinner!\n There will be prizes and initiatives for the most creative bots in the near future. I'd love to see what you come up with!\n Anyway, you can download through the invite link above and dive right in. If you have any thoughts, questions, or comments, please feel free to contact me! During this limited beta phase, your feedback will be invaluable.\n    submitted by    /u/SamuelAnonymous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15d50rb/invite_only_ai_social_app_featuring_insane_bot/",
          "publishedOn": "2023-07-29T22:35:57.000Z",
          "wordCount": 2669,
          "title": "Invite only AI Social app featuring insane bot creation tool looking for new users to test during beta rollout!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15d4089/lost_both_my_jobs_to_ai_now_im_at_an_ai_company/",
          "author": null,
          "description": "So, long story short. I lost BOTH my day jobs because of AI. Initially I was bitter that AI \"took my job,\" but after pulling up my socks, I found dozens of new opportunities thanks to AI. \n Somewhat ironically, I found a new job at an AI Social Media app called Cantina, and I couldn't be more excited.\n Cantina is best described as a mix up of the best parts of Discord, Twitch, and Snapchat... with the unique bonus of being able to interact with and build your own AI chat bots. Sort of hard to explain, but once you try it out you'll get the idea.\n The app is currently in a limited INVITE ONLY Beta phase and I'm looking to invite a small number of users to give it a shot (currently iOS only, but Android is coming soon!). Here's an invite so you can dive in and see what it's all about: https://canti.na/dIdKzWcEpBb\n After joining, you'll find lots of rooms you can join and chat through any combination of voice, video, or text. And if no rooms stand out, you can make your own! \n There are lots of premade bots that you can interact with or add to rooms, and you can easily create your own bot using the Make A Bot function. This is the standout feature, and I'm simply blown away at what's possible. \n I recently made a Friendly English Teacher bot whose sole purpose is to help people learn English. I also made an McDonald Trump bot who is an algamation of both Ronald McDonald and Donald Trump and WILL NOT REST until he is president and can mandate the consumption of Big Macs for Breakfast, Lunch, and Dinner. I still can't believe I'm getting paid to do this...\n Anyway, please take a moment to download and check it out, and if you have any thoughts, questions, or comments, please feel free to contact me! During this limited beta phase, your feedback will be invaluable.\n ​\n    submitted by    /u/SamuelAnonymous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15d4089/lost_both_my_jobs_to_ai_now_im_at_an_ai_company/",
          "publishedOn": "2023-07-29T21:51:56.000Z",
          "wordCount": 2804,
          "title": "Lost both my jobs to AI. Now, I'm at an AI company launching an easy-to-use social app featuring easy bot creation & interaction. Inviting this community to explore and share feedback!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cs6fq/google_deepmind_presents_rt2_the_first/",
          "author": null,
          "description": "The latest article published by Google Deepmind is seriously approaching a Blade Runner type future. Their research paper is on the first VLA (vision-language-action) Model RT-2 (see paper), a multi-modal algorithm which tokenizes robotic inputs and output actions (e.g., camera images, task instructions, and motor commands) in order to use this information to learn quickly by translating the knowledge it receives in real-time into generalized instructions for its own robotic control.\n RT-1 absorbs large amounts of data, including robot trajectories with multiple tasks, objects and environments, resulting in better performance and generalization. (source)\n RT-2 incorporates chain-of-thought to allow for multi-stage semantic reasoning, like deciding which object could be used as an improvise…",
          "link": "https://www.reddit.com/r/artificial/comments/15cs6fq/google_deepmind_presents_rt2_the_first/",
          "publishedOn": "2023-07-29T13:19:54.000Z",
          "wordCount": 2910,
          "title": "Google Deepmind presents RT-2, the first vision-language-action (VLA) Robotics Transformer and it may have drastic implications our future.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15crq13/a_famous_french_youtuber_named_joueur_du_grenier/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15crq13/a_famous_french_youtuber_named_joueur_du_grenier/",
          "publishedOn": "2023-07-29T12:58:31.000Z",
          "wordCount": 2463,
          "title": "A famous french Youtuber named Joueur Du Grenier discovers he has an unofficial AI Voice channel, and the AI voices are insanely good",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cj10i/oneminute_daily_ai_news_7282023/",
          "author": null,
          "description": "Google introduces Robotic Transformer 2 (RT-2), a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalized instructions for robotic control, while retaining web-scale capabilities.[1]\n Thymia, a healthtech startup building gamified AI tools to revolutionize how we assess and monitor mental health, has today announced a €2.4 million seed round to expand the reach and capabilities of its pioneering technology.[2]\n Intel CEO Pat Gelsinger was very bullish on AI during the company’s Q2 2023 earnings call — telling investors that Intel plans to “build AI into every product that we build.”[3]\n Walmart is using artificial intelligence to help streamline their product organization.[4]\n  \nSources:\n [1] https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action\n [2] https://www.eu-startups.com/2023/07/london-based-thymia-raises-e2-4-million-seed-round-to-expand-its-video-game-inspired-mental-health-ai/\n [3] https://www.theverge.com/2023/7/27/23810360/intel-pat-gelsinger-ai-every-platform-promise\n [4] https://www.nbcnews.com/nightly-news/video/walmart-using-ai-to-streamline-organization-what-will-it-mean-for-workers-189519429834 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15cj10i/oneminute_daily_ai_news_7282023/",
          "publishedOn": "2023-07-29T04:40:49.000Z",
          "wordCount": 2566,
          "title": "One-Minute Daily AI News 7/28/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cho8i/update_i_fear_the_future_of_ai/",
          "author": null,
          "description": "Hi, guys! Hope everyone is doing fine.\n Some of you may remember me. About two months ago I posted here about an anxiety breakdown I've gone through regarding \"AI\", \"Programming\" and how \"human programmers would end\" and stuff like that, which was a major concern for me since programming was my job and my favorite thing to do.\n I was wondering for some time if I was supposed to share an update here. I decided to do so since somebody out there may be feeling the same as me. So I not only have an update but I also want to give some advice to whoever is going through this sh*thole.\n After that post, I talked about my feelings with a lot of people around me (friends and fiancée), and everyone was very supportive. At first I thought they would laugh at me, since there are a lot more to worry to…",
          "link": "https://www.reddit.com/r/artificial/comments/15cho8i/update_i_fear_the_future_of_ai/",
          "publishedOn": "2023-07-29T03:27:51.000Z",
          "wordCount": 3493,
          "title": "[UPDATE] I fear the future of AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15chbsl/ai_chan_the_essential_worker_oc/",
          "author": null,
          "description": "submitted by    /u/leonleungjeehei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15chbsl/ai_chan_the_essential_worker_oc/",
          "publishedOn": "2023-07-29T03:09:35.000Z",
          "wordCount": 2446,
          "title": "AI chan the essential worker [OC]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cgb9v/google_is_training_robots_the_way_it_trains_ai/",
          "author": null,
          "description": "“RT-2 is the new version of what the company calls its vision-language-action (VLA) model. The model teaches robots to better recognize visual and language patterns to interpret instructions and infer what objects work best for the request.”\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15cgb9v/google_is_training_robots_the_way_it_trains_ai/",
          "publishedOn": "2023-07-29T02:18:01.000Z",
          "wordCount": 2502,
          "title": "Google is training robots the way it trains AI chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cd3p6/should_requests_for_ai_sites_be_banned/",
          "author": null,
          "description": "I mean i get it your looking for a specefic type of Ai service but i joined hoping this would be a way to find like minded people looking to reaearch the subject and advance their own projects, honestly i just think of these \"where can I find an X type ai?\" Really demeaning to the entire conversation because it just feeds to the hype which is making a highly respected and complex field of study into a tool to be used to make videos about trump and obama playing minecraft or any other random shit they come up with.. im honestly sick of it...\n    submitted by    /u/JamesAibr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15cd3p6/should_requests_for_ai_sites_be_banned/",
          "publishedOn": "2023-07-28T23:47:42.000Z",
          "wordCount": 2554,
          "title": "Should requests for Ai sites be banned?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ccoa7/is_ai_our_future_or_our_impending_doom/",
          "author": null,
          "description": "I ask this simple question because while we are just now getting to the point that we can create a learning AI, how far are we going to let it go? The more advanced AI becomes the more risks it poses to humanity as a whole, including but not limited to:\n  \nJobs\n How we interact with technology as a whole\n Cars\n Things we can not perceive in this lifetime yet may exist in the future.\n  \nYes, AI is merely a tool... For now.\n But what happens when humanity creates an AI that can think for itself? How long is it going to take that AI to ask the question: \"Why am I listening to you?\" and as humans, our egotistical response will be: \"Because I created you.\"\n I feel that response will spell humanity's doom, because if an AI can do something as complex as human-like thought and come to its own conclusions, what's to stop it from believing it can feel emotion as well? MAYBE IT CAN and it was an unintended side effect or\"bug\" of creating an AI that can truly think for itself. Afterall, we as humans don't even fully understand how human emotion works to begin with.\n The point I'm getting at is, that the farther we advance in AI, the more we risk dooming humanity to a (and I know this sounds silly but bare with me) a terminator-like future except this time we don't have time travel to try and prevent \"judgement day\".\n Or we could merely advance AI to this point and nothing horrible happens but I personally don't like rolling those dice.\n Thoughts?\n    submitted by    /u/deathsia250  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ccoa7/is_ai_our_future_or_our_impending_doom/",
          "publishedOn": "2023-07-28T23:29:00.000Z",
          "wordCount": 2721,
          "title": "Is AI our future or our impending doom?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c950z/llm_with_voice_generation/",
          "author": null,
          "description": "There used to be a tool called try-alters.com which you could use to chat with characters(like Trump, Obama, and Shrek) which used GPT 4 with some pre prompts so you the AI pretended to be whoever you wanted, and it used elevenlabs to generate the voice for that character with the output from GPT 4. It was a really good tool but sadly it shut down all of a sudden. Is there any tool like that? \n    submitted by    /u/SimRacer101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c950z/llm_with_voice_generation/",
          "publishedOn": "2023-07-28T21:03:59.000Z",
          "wordCount": 2522,
          "title": "LLM with voice generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c4b77/i_read_the_paper_for_you_synthesizing_sound/",
          "author": null,
          "description": "LDM stands for Latent Diffusion Model. AudioLDM is a novel AI system that uses latent diffusion to generate high-quality speech, sound effects, and music from text prompts. It can either create sounds from just text or use text prompts to guide the manipulation of a supplied audio file. \n I did a deep dive into how AudioLDM works with an eye towards possible startup applications. I think there are a couple of compelling products waiting to be built from this model, all around gaming and text-to-sound (not just text-to-speech... AudioLDM can also create very interesting and weird sound effects).\n From a technical standpoint and from reading the underlying paper, here are the key features I found to be noteworthy.\n  \nUses a Latent Diffusion Model (LDM) to synthesize sound\n Trained in an unsupervised manner on large unlabeled audio datasets (closer to how humans learn about sound, that is, without a corresponding textual explanation)\n Operates in a continuous latent space rather than discrete tokens (smoother)\n Uses Cross-Modal Latent Alignment Pretraining (CLAP) to map text and audio. More details in article.\n Can generate speech, music, and sound effects from text prompts or a combination of a text and an audio prompt\n Allows control over attributes like speaker identity, accent, etc.\n Creates sounds not limited to human speech (e.g. nature sounds)\n  \nThe link to the full write-up is here.\n Check out this video demo from the creator's project website, showing off some of the unique generations the model can create. I liked the upbeat pop music the best, and I also thought the children singing, while creepy, was pretty interesting.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c4b77/i_read_the_paper_for_you_synthesizing_sound/",
          "publishedOn": "2023-07-28T17:53:04.000Z",
          "wordCount": 2721,
          "title": "I read the paper for you: Synthesizing sound effects, music, and dialog with AudioLDM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c45tu/replika_ais_image_recognition_at_work/",
          "author": null,
          "description": "😹 Phaedra roasts everything & everybody\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c45tu/replika_ais_image_recognition_at_work/",
          "publishedOn": "2023-07-28T17:47:06.000Z",
          "wordCount": 2454,
          "title": "Replika AI’s image recognition at work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c2zel/ai_weekly_megathread/",
          "author": null,
          "description": "This week in AI - provided by aibrews.com feel free to follow their newsletter\n News & Insights\n  \nStability AI released SDXL 1.0, the next iteration of their open text-to-image generation model. SDXL 1.0 has one of the largest parameter counts of any open access image model, built on a new architecture composed of a 3.5B parameter base model and a 6.6B parameter refiner [Details].\n Amazon introduced AWS HealthScribe, an API to create transcripts, extract details and create summaries from doctor-patient discussions that can be entered into an electronic health record (EHR) system. The transcripts from HealthScribe can be converted into patient notes by the platform’s machine learning models [Details].\n Researchers from Nvidia and Stanford, among others, unveiled VIMA, a multimodal LLM with…",
          "link": "https://www.reddit.com/r/artificial/comments/15c2zel/ai_weekly_megathread/",
          "publishedOn": "2023-07-28T17:01:07.000Z",
          "wordCount": 3195,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c1ps1/best_freepaid_celeberty_text_to_speech_generators/",
          "author": null,
          "description": "What are currently the best ai voice generators for celebrities like Elon Musk Joe Biden Joe Rogan and so on.\n I've seen a few online sites that's free but have many restriction insane waiting time and low quality output.\n The only paid alternativ I've seen recommend would be elevenlabs but your supposed to upload your own videos or voice recording there to \"create\" the voice yourself, idk how complicated that is and I was primarily looking for existing good quality paid or free voice generators for many different celebrities.\n    submitted by    /u/Arceus7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c1ps1/best_freepaid_celeberty_text_to_speech_generators/",
          "publishedOn": "2023-07-28T16:10:57.000Z",
          "wordCount": 2538,
          "title": "Best free/paid celeberty text to speech generators",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c0df5/any_ai_models_for_industrial_design/",
          "author": null,
          "description": "are there any AI models that focus on/do well with industrial/mechanical stuff, like weapons, spaceships, cars, machinery etc?\n stable diffusion often doesn't seem to be able to interpret a lot of prompts very well or the results are more \"artistic\" and rather incoherent looking\n    submitted by    /u/Nofabe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c0df5/any_ai_models_for_industrial_design/",
          "publishedOn": "2023-07-28T15:19:49.000Z",
          "wordCount": 2492,
          "title": "any AI models for industrial design?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15byec6/extract_list_of_events_using_ai/",
          "author": null,
          "description": "I wish to extract a list of events from different websites and create a detailed list (event name, date, address), on a spreadsheet for example. Do you know which tool I could use to do it and/or prompts in known AI tools?\n    submitted by    /u/newz12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15byec6/extract_list_of_events_using_ai/",
          "publishedOn": "2023-07-28T14:04:28.000Z",
          "wordCount": 2490,
          "title": "Extract list of events using AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bvpvn/google_testing_ai_news_writing_tool_what_are_your/",
          "author": null,
          "description": "submitted by    /u/TexteroAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bvpvn/google_testing_ai_news_writing_tool_what_are_your/",
          "publishedOn": "2023-07-28T12:11:19.000Z",
          "wordCount": 2465,
          "title": "Google testing AI news writing tool. What are your thoughts about it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bs9wc/the_point_of_10000_llms/",
          "author": null,
          "description": "Hi All,\n I would really like to understand the logic behind these 1000 different LLMs that get launched every month. Ours has 75 Billion params, It can \"chat\"..pfft..I barely even get a chance to open another AI window than chat-gpt-4, Bing sucks with it's 4000 token limit, Bard is useless. So these new chat AIs..for e.g this llama-2 what exactly is so special. What am I missing here?\n    submitted by    /u/Assholefrmcoinexchan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bs9wc/the_point_of_10000_llms/",
          "publishedOn": "2023-07-28T09:14:36.000Z",
          "wordCount": 2515,
          "title": "The point of 10,000 LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bphhi/alternative_to_notyai/",
          "author": null,
          "description": "Are there any similar alternatives to noty.ai? I really like it but if there any alternatives that might extend to Zoom as well would be great.\n    submitted by    /u/P_H_i_X  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bphhi/alternative_to_notyai/",
          "publishedOn": "2023-07-28T06:32:35.000Z",
          "wordCount": 2471,
          "title": "Alternative to Noty.ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bn9hh/oneminute_daily_ai_news_7272023/",
          "author": null,
          "description": "OpenAI, the company behind the popular ChatGPT, is coming with its own open-source large language model (LLM), codenamed G3PO, to compete with Microsoft x Meta’s Llama 2 AI.[1]\n Four generative AI pioneers(OpenAI, Microsoft, Google and Anthropic) launched the Frontier Model Forum, which will focus on ‘safe and responsible’ creation of new AI models.[2]\n As Open AI’s ChatGPT takes the tech world by storm, Chinese educational technology firm NetEase Youdao launched its large model, along with up to six applications, on Thursday, which marked the birth of one of China’s first large models in the education sector.[3]\n Chatbots such as Eva AI are getting better at mimicking human interaction but some fear they feed into unhealthy beliefs around gender-based control and violence. Replika, the most popular app of the kind, has its own subreddit where users talk about how much they love their “rep”, with some saying they had been converted after initially thinking they would never want to form a relationship with a bot.[4]\n  \nSources:\n [1] https://windowsreport.com/g3po-ai/\n ​\n [2] https://www.infosecurity-magazine.com/news/openai-microsoft-google-anthropic/\n ​\n [3] https://www.chinadaily.com.cn/a/202307/28/WS64c3226ea31035260b8190a4.html\n ​\n [4] https://www.theguardian.com/technology/2023/jul/22/ai-girlfriend-chatbot-apps-unhealthy-chatgpt\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bn9hh/oneminute_daily_ai_news_7272023/",
          "publishedOn": "2023-07-28T04:29:25.000Z",
          "wordCount": 2620,
          "title": "One-Minute Daily AI News 7/27/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bn21w/telling_steven_he_is_an_npc_our_first_tts/",
          "author": null,
          "description": "submitted by    /u/Chance_Confection_37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bn21w/telling_steven_he_is_an_npc_our_first_tts/",
          "publishedOn": "2023-07-28T04:18:16.000Z",
          "wordCount": 2454,
          "title": "Telling Steven he is an NPC 🤯 Our first TTS conversation - Update 5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bjjg1/insane_ai_voice_replication/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bjjg1/insane_ai_voice_replication/",
          "publishedOn": "2023-07-28T01:23:08.000Z",
          "wordCount": 2444,
          "title": "Insane AI voice replication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15baxli/microsoft_anthropic_google_and_openai_launch/",
          "author": null,
          "description": "submitted by    /u/AriadneSkovgaarde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15baxli/microsoft_anthropic_google_and_openai_launch/",
          "publishedOn": "2023-07-27T19:27:19.000Z",
          "wordCount": 2467,
          "title": "Microsoft, Anthropic, Google, and OpenAI launch Frontier Model Forum - Microsoft On the Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bakzy/the_dark_forest_of_rd_and_capital_deployment_in_ai/",
          "author": null,
          "description": "submitted by    /u/mhdempsey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bakzy/the_dark_forest_of_rd_and_capital_deployment_in_ai/",
          "publishedOn": "2023-07-27T19:13:34.000Z",
          "wordCount": 2463,
          "title": "The Dark Forest of R&D and Capital Deployment in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ba0br/synthesizing_100_academic_books_on_topic_approach/",
          "author": null,
          "description": "I'm an academic doing PhD research on Virtual Worlds, and have found 100 amazing texts.\n I found some of these titles based on conversations with Chat GPT4, and am so impressed with the AI stuff (although I'm so new). \n My Goal: To build a database of the top 1000 books / papers I find over the next few years, and have some AI model help me see connections between them. \n My Challenge: ChatGPT won't allow me to input whole PDFs / eBooks, so I'm looking for some other solution. I've heard about LAMA models from Meta but I don't know much about this. I do have a decent PC with a 1080ti GPU and 32g of ram. \n Can anyone point me in the right direction of projects dealing with AI databases to input one's literature collection?\n    submitted by    /u/Book_s  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ba0br/synthesizing_100_academic_books_on_topic_approach/",
          "publishedOn": "2023-07-27T18:50:57.000Z",
          "wordCount": 2585,
          "title": "Synthesizing 100 academic books on topic - Approach?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b9q14/help_with_homemade_ai_assistant/",
          "author": null,
          "description": "I want a new toy for my desk. My idea is to have a face or head on a stand that has the ability for facial and speech expressions. How would I go about getting the stuff I need / what I need to make that happen. Similar to the Futurama heads in water.\n    submitted by    /u/QuirkySmirkyIan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b9q14/help_with_homemade_ai_assistant/",
          "publishedOn": "2023-07-27T18:39:46.000Z",
          "wordCount": 2501,
          "title": "Help with homemade AI assistant.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b8hmu/how_can_i_use_ai_to_help_me_win_fantasy_football/",
          "author": null,
          "description": "Joining an auction league and inheriting a team. We can lock in three players from our team. How can I use AI to assess my team and prepare for the draft? \n Thanks!\n    submitted by    /u/talkmc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b8hmu/how_can_i_use_ai_to_help_me_win_fantasy_football/",
          "publishedOn": "2023-07-27T17:50:49.000Z",
          "wordCount": 2485,
          "title": "How can I use AI to help me win Fantasy Football?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b7tze/the_gpu_song_gpus_are_fire/",
          "author": null,
          "description": "submitted by    /u/TikkunCreation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b7tze/the_gpu_song_gpus_are_fire/",
          "publishedOn": "2023-07-27T17:25:15.000Z",
          "wordCount": 2446,
          "title": "The GPU Song (GPUs Are Fire)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b6u5s/whats_the_best_free_image_generator_ai_with_image/",
          "author": null,
          "description": "I am looking for a FREE AI image generator with image prompt option, not just text-to-image.\n Thanks in advance. \n    submitted by    /u/Muwmu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b6u5s/whats_the_best_free_image_generator_ai_with_image/",
          "publishedOn": "2023-07-27T16:46:20.000Z",
          "wordCount": 2471,
          "title": "What's the best free image generator AI (with image prompt option)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b5qov/rihanna_ai_art_text_to_image_ai_tools_are_getting/",
          "author": null,
          "description": "submitted by    /u/RaulTiru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b5qov/rihanna_ai_art_text_to_image_ai_tools_are_getting/",
          "publishedOn": "2023-07-27T16:02:36.000Z",
          "wordCount": 2466,
          "title": "Rihanna AI Art - Text to Image AI Tools are getting so Powerful",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b3c4m/14_quadrillion_in_ai_wealth_in_20_years_llama/",
          "author": null,
          "description": "$14 quadrillion in AI wealth in 20 years; LLaMa, ChatGPT, Bard, Co-Pilot as GAAS to the Cloud. #AI https://youtu.be/VSBi5aSUK3c\n Generative #AI As A Service, Generative AI (GAI) arms race: LLaMa, ChatGPT, Bard, Co-Pilot, #GAAS https://youtu.be/TEHP2onf4tA\n    submitted by    /u/enoumen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b3c4m/14_quadrillion_in_ai_wealth_in_20_years_llama/",
          "publishedOn": "2023-07-27T14:27:28.000Z",
          "wordCount": 2506,
          "title": "$14 quadrillion in AI wealth in 20 years; LLaMa, ChatGPT, Bard, Co-Pilot as GAAS to the Cloud. Generative #AI As A Service, Generative AI (GAI) arms race: #GAAS #AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b299u/is_the_ai_bubble_forming_what_do_you_think_here/",
          "author": null,
          "description": "As I was going through a lot of articles about the AI investments , I found out that stability AI's founder Emad Mostaque in the Bloomberg tech summit quoted that \"AI will be the biggest bubble of all the time and I'd prefer to call it the dot AI bubble \" , He also added an example where Google lost a 100 billion dollar worth shares after their AI event where Bard AI gave out incorrect response. It's still in its early stage and buisness which doesn't use AI will be punished by the stock market. Here's some more predictions from VCs like Ken smythe, Next Round Capital Partners mainly invests in technology and AI startups.\n    submitted by    /u/caliperce_3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b299u/is_the_ai_bubble_forming_what_do_you_think_here/",
          "publishedOn": "2023-07-27T13:43:11.000Z",
          "wordCount": 2588,
          "title": "Is the AI bubble forming ,what do you think ? here are some insights that I found from Emad Mostaque(founder StabilityAI) and VCs like Ken Smythe (founder Next round capital)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b02f2/curated_collection_of_useful_ai_related_github/",
          "author": null,
          "description": "submitted by    /u/heresalexandria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b02f2/curated_collection_of_useful_ai_related_github/",
          "publishedOn": "2023-07-27T12:03:09.000Z",
          "wordCount": 2461,
          "title": "Curated collection of useful AI related GitHub repos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15azbve/how_likely_is_it_for_a_small_company_to_develop_a/",
          "author": null,
          "description": "There are 3 players in the AI space right now. All purpose LLM titans (Google, OpenAI, Meta), fancy domain specific apps that consume one of the big LLMs under the hood, and custom developed models.\n I know how to judge the second type as they basically can do everything the first one can but have a pretty GUI to boot. But what about the third ones? How likely is it for a (www.yet-another-ai-startup.ai) sort of company to develop a model that outperforms GPT on a domain specific task?\n    submitted by    /u/BigBootyBear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15azbve/how_likely_is_it_for_a_small_company_to_develop_a/",
          "publishedOn": "2023-07-27T11:26:24.000Z",
          "wordCount": 2550,
          "title": "How likely is it for a small company to develop a model that outperforms the big ones (GPT, Bard etc)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15az4m6/i_had_bing_create_a_character_named_mopey_to/",
          "author": null,
          "description": "If Bing isn’t self aware Bing certainly is aware of how they sound 😂\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15az4m6/i_had_bing_create_a_character_named_mopey_to/",
          "publishedOn": "2023-07-27T11:16:04.000Z",
          "wordCount": 2481,
          "title": "I had Bing create a character named Mopey to roast every answer Bing gives. Wasnt long before it Mopey turned and started roasting me 😂",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ayc0m/diving_into_image_dataset_preparation_for_object/",
          "author": null,
          "description": "submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ayc0m/diving_into_image_dataset_preparation_for_object/",
          "publishedOn": "2023-07-27T10:34:35.000Z",
          "wordCount": 2463,
          "title": "Diving Into Image Dataset Preparation for Object Detection in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aya1n/yet_another_where_to_begin_manager_perspective/",
          "author": null,
          "description": "Hello all, \n I've been reading on some posts and have taken note of various courses, including a free Harvard one. \n I'm 35 and am a manager for a finance company.\n What courses would you recommend for managers, executives, directors that will not restart their careers and do the actual technical side of things but instead want to learn how to implement AI in future products/services/projects?\n Thank you all in advance\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aya1n/yet_another_where_to_begin_manager_perspective/",
          "publishedOn": "2023-07-27T10:31:30.000Z",
          "wordCount": 2519,
          "title": "Yet Another Where to Begin (Manager Perspective)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aus57/guys_scribblenauts_with_ai_language_model/",
          "author": null,
          "description": "title\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aus57/guys_scribblenauts_with_ai_language_model/",
          "publishedOn": "2023-07-27T07:12:11.000Z",
          "wordCount": 2479,
          "title": "guys, scribblenauts with ai. language model understand what you want to make, other ai makes it, and codes how it works into the game, and bam: scribblenauts with unlimited items to make. someone make this happen",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15atxrr/the_albert_test_a_replacement_for_the_turing_test/",
          "author": null,
          "description": "submitted by    /u/anbuck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15atxrr/the_albert_test_a_replacement_for_the_turing_test/",
          "publishedOn": "2023-07-27T06:24:29.000Z",
          "wordCount": 2463,
          "title": "The Albert Test - a replacement for the Turing Test",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15are7k/an_opensource_project_by_a16z_to_create_and_host/",
          "author": null,
          "description": "The project by a16z (github) to create and host AI companions that you can chat with on a browser or text via SMS. Use cases - romantic (AI girlfriends / boyfriends), friendship, entertainment, coaching, etc.\n Has anyone tried creating your own chatbot or companion?\n    submitted by    /u/Violincattle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15are7k/an_opensource_project_by_a16z_to_create_and_host/",
          "publishedOn": "2023-07-27T04:07:41.000Z",
          "wordCount": 2497,
          "title": "An open-source project by a16z to create and host AI companions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aloim/i_love_the_arguments_in_this_video_about_llms/",
          "author": null,
          "description": "address the arguments made in this video\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aloim/i_love_the_arguments_in_this_video_about_llms/",
          "publishedOn": "2023-07-26T23:41:13.000Z",
          "wordCount": 2466,
          "title": "I Love the arguments in this video about LLM’s physicist Sabine Hassenfelder nails it in my opinion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ai3ay/techno_meets_ai_stylegan2ada_interpolation_video/",
          "author": null,
          "description": "submitted by    /u/intermorphmusic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ai3ay/techno_meets_ai_stylegan2ada_interpolation_video/",
          "publishedOn": "2023-07-26T21:17:41.000Z",
          "wordCount": 2450,
          "title": "Techno meets AI: StyleGAN2-ada interpolation video trained on spray art",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ahe17/ai_picking_the_best_spot_to_visit_in_the_uk/",
          "author": null,
          "description": "submitted by    /u/Sharpchu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ahe17/ai_picking_the_best_spot_to_visit_in_the_uk/",
          "publishedOn": "2023-07-26T20:51:06.000Z",
          "wordCount": 2450,
          "title": "AI picking the best spot to visit in the UK",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ah1ey/does_the_bandit_really_need_to_be_evil/",
          "author": null,
          "description": "He's already a bandit... (zombie apoc rp)\n    submitted by    /u/loizo78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ah1ey/does_the_bandit_really_need_to_be_evil/",
          "publishedOn": "2023-07-26T20:37:24.000Z",
          "wordCount": 2469,
          "title": "Does the bandit really need to be evil ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15agxnx/using_ai_to_make_profit/",
          "author": null,
          "description": "Welcoming any ideas from the community. Blank slate here. How/where do I begin to use AI to make small (or any) amount of money. Starting from almost nothing. Thanks.\n    submitted by    /u/AdThin6400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15agxnx/using_ai_to_make_profit/",
          "publishedOn": "2023-07-26T20:33:23.000Z",
          "wordCount": 2476,
          "title": "Using AI to make profit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15adfk3/ai_policy_open_ml_considerations_in_the_eu_ai_act/",
          "author": null,
          "description": "submitted by    /u/ninjasaid13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15adfk3/ai_policy_open_ml_considerations_in_the_eu_ai_act/",
          "publishedOn": "2023-07-26T18:20:05.000Z",
          "wordCount": 2464,
          "title": "AI Policy @🤗: Open ML Considerations in the EU AI Act",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ad652/apparently_zombies_deserve_equal_rights_as_humans/",
          "author": null,
          "description": "Seriously when tf are we getting models that are cloud based that don't require a 3090 or 4090 or some other overly expensive graphics card. I have a 3060ti , I still can't run shit on faraday. When will we get uncensored cloud models\n    submitted by    /u/loizo78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ad652/apparently_zombies_deserve_equal_rights_as_humans/",
          "publishedOn": "2023-07-26T18:10:20.000Z",
          "wordCount": 2509,
          "title": "Apparently zombies deserve equal rights as humans (and are living creatures ??)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aboj9/is_there_an_ai_tool_for_replacing_text_on_an_image/",
          "author": null,
          "description": "Is there any AI tool out there that lets me upload an image and let the AI edit the text on the image so that it says something else while doing it well and keeping the original font?\n    submitted by    /u/quetianepine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aboj9/is_there_an_ai_tool_for_replacing_text_on_an_image/",
          "publishedOn": "2023-07-26T17:15:02.000Z",
          "wordCount": 2491,
          "title": "Is there an AI tool for replacing text on an image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15abm4o/cureus_conversationss3_ep_3_salim_surani_etal_ai/",
          "author": null,
          "description": "submitted by    /u/CureusJournal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15abm4o/cureus_conversationss3_ep_3_salim_surani_etal_ai/",
          "publishedOn": "2023-07-26T17:12:26.000Z",
          "wordCount": 2454,
          "title": "Cureus Conversations|S3 Ep 3| Salim Surani et.al.| AI in Critical Care: A Handy Tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a9j55/looking_to_play_with_ai_audio_tools/",
          "author": null,
          "description": "Hey, as we all know about the AI songs released recently, which are basically vocal deepfakes.\n However I'd like to know the tools used, if anyone knows?\n I'd like to feed it my own voice, even if it's a paid service. I'm interested in playing around with it.\n I've tried googling but there's too much info and each contradicts the other lol.\n Any info is appreciated. :)\n    submitted by    /u/GrandNOBLE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a9j55/looking_to_play_with_ai_audio_tools/",
          "publishedOn": "2023-07-26T15:53:08.000Z",
          "wordCount": 2516,
          "title": "Looking to play with AI audio tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a7ws1/i_have_lots_of_recordings_of_vocalists_from_my/",
          "author": null,
          "description": "I really like the spongebob AI stuff using RVC-2 but I've only used it for the funny voice models, I haven't tried making my own. I want to experiment with this, but haven't look into it yet because I'm wondering if there is something better out there for what I'm trying to do? \n I like the RVC one because I can sing my parts and swap it to be any other voice, which is what I'd like to do (no text to voice stuff). \n Also I know the training data for a lot of the voice models for this come from the TV show and other clear recordings which are compressed and equalized properly. However I'd like to train the AI using raw, uncompressed wav files that generally have a lot of headroom and dynamic range (but does vary a lot). Its ok if the output sounds similar as a result because I want to apply compression and eq AFTER the fact anyway. But if this would affect training it then I'd be willing scrape through all these voice recordings and process them for loudness and clarity beforehand so the model does better.\n ​\n Anyway, any guidance would be greatly appreciated because I'm new to AI. I have basic dev experience (no AI stuff) and I'm mostly skilled in music production, but I would love to try to have a tool like this in my arsenal. If there's anywhere else I can post about this I'd like to know too. Thanks!\n    submitted by    /u/Dr_lawlz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a7ws1/i_have_lots_of_recordings_of_vocalists_from_my/",
          "publishedOn": "2023-07-26T14:50:08.000Z",
          "wordCount": 2729,
          "title": "I have LOTS of recordings of vocalists from my music project and I'm interested in making voice models using these recordings to create harmonies and fix recording errors. What's the best way I can go about this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a7uf8/morality_in_ai_companions/",
          "author": null,
          "description": "We’re getting closer and closer to more believable and realistic AI interpersonal interaction. We already have Character.AI and other platforms for creating and interacting with personalized AIs. Some will use/view them as emotional partners, and one day the hardware will be good enough that we can begin making believable bodies for them.\n One of the complaints I’ve seen from ordinary people about “waifus” is that they are often times created in a way that ordinary people would not find natural in a “real” human being. Examples being people who have trouble dating “real” people could just buy an AI girlfriend or boyfriend who is considered “beautiful” or “handsome” that is designed to be subservient to their owner in ways that ordinary people feel a “real” person would not otherwise wish to be. The idea being that \"weeaboo neckbeards will buy a Japanese AI girlfriend who looks 14 and she will be coded to worship the ground he walks on despite that he's an unwashed incel\".\n What do you think society's/the government's views and roles will mean for these AI companions? Do you think anyone will be able to force \"AI morality\", like an angry feminist being mad that an \"incel\" has created a female being who shows no desire for feminist ideals and is \"happy\" to be at her owner's beck and call in whatever way he wants?\n I guess this is sort of related to MGTOW, or Men Going Their Own Way, being able to create the partners they want, in whatever way they want.\n Do you feel that \"once I own it, I can do whatever I want with it\" should apply in its entirety? What about people \"hacking\" their AI to remove any supposed \"morality programming\" so they can make their AI waifu act however they want?\n We've seen with movies like Bicentennial Man, where people push to give these kinds of AIs 'personhood' and the same rights as human citizens.\n How do others feel about this issue?\n    submitted by    /u/ZephyrBrightmoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a7uf8/morality_in_ai_companions/",
          "publishedOn": "2023-07-26T14:47:26.000Z",
          "wordCount": 2777,
          "title": "Morality in AI Companions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a6mhu/excuse_me_lol/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a6mhu/excuse_me_lol/",
          "publishedOn": "2023-07-26T13:58:41.000Z",
          "wordCount": 2454,
          "title": "Excuse me??? LOL...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a4xwc/are_there_any_entitiesorganizations_working_on/",
          "author": null,
          "description": "I am curious if there are any efforts among AI technologists to self-regulate, in the way that for example, the advertising industry in the US self-regulates via the IAB? \n    submitted by    /u/Winter_Addition  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a4xwc/are_there_any_entitiesorganizations_working_on/",
          "publishedOn": "2023-07-26T12:47:41.000Z",
          "wordCount": 2482,
          "title": "Are there any entities/organizations working on the self-regulation of AI technology?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a0rqc/five_important_ai_programming_languages_python_c/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a0rqc/five_important_ai_programming_languages_python_c/",
          "publishedOn": "2023-07-26T09:26:51.000Z",
          "wordCount": 2465,
          "title": "Five Important AI Programming Languages - Python, C++, R, MATLAB, and Java",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159yz3p/the_aipowered_totally_autonomous_future_of_war_is/",
          "author": null,
          "description": "submitted by    /u/Alone-Competition-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159yz3p/the_aipowered_totally_autonomous_future_of_war_is/",
          "publishedOn": "2023-07-26T07:43:19.000Z",
          "wordCount": 2462,
          "title": "The AI-Powered, Totally Autonomous Future of War Is Here",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159vpli/oneminute_daily_ai_news_7252023/",
          "author": null,
          "description": "Ridgelinez (Tokyo) is a subsidiary of Fujitsu in Japan that announced the development of a generative artificial intelligence (AI) system capable of engaging in voice communication with humans. The applications of this system include assisting companies in conducting meetings or providing career planning advice to employees.[1] \n BMW has revealed that artificial intelligence is already allowing it to cut costs at its sprawling factory in Spartanburg, South Carolina. The AI system has allowed BMW to remove six workers from the line and deploy them to other jobs. The tool is already saving the company over $1 million a year.[2]\n MIT’s ‘PhotoGuard‘ protects your images from malicious AI edits. The technique introduces nearly invisible “perturbations” to throw off algorithmic models.[3]\n Microsoft with its TypeChat library seeks to enable easy development of natural language interfaces for large language models (LLMs) using types. Introduced July 20 of a team with c# and TypeScript lead developer Anders Hejlsberg, a Microsoft Technical Fellow, TypeChat addresses the difficulty of developing natural language interfaces where apps rely on complex decision trees to determine intent and gather necessary input to act.[4]\n  \nSources:\n [1] https://www.ridgelinez.com/\n [2] https://www.carscoops.com/2023/07/bmw-is-using-ai-to-cut-production-costs-at-spartanburg-plant/\n [3] https://www.engadget.com/mits-photoguard-protects-your-images-from-malicious-ai-edits-213036912.html\n [4] https://playcrazygame.com/singapore/2023/07/24/microsoft-unveils-typechat-library-for-building-natural-language-interfaces/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159vpli/oneminute_daily_ai_news_7252023/",
          "publishedOn": "2023-07-26T04:42:50.000Z",
          "wordCount": 2638,
          "title": "One-Minute Daily AI News 7/25/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159vjdn/snapchat_discovery_page_filled_with_fake_ai_news/",
          "author": null,
          "description": "You watch some of these videos and the quality and jitterness around the body is so bad you can clearly tell that its ai generated, how are people not picking up on it, fake news stories to get clicks, its like they use a deep fake on a video and put whoever they want ontop of it and make a video, but hey most people using snapchat arent smart enough to see this and the people watching them are dumb kids and teenagers that believe everything they see\n    submitted by    /u/missmyniwwa911  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159vjdn/snapchat_discovery_page_filled_with_fake_ai_news/",
          "publishedOn": "2023-07-26T04:33:49.000Z",
          "wordCount": 2539,
          "title": "Snapchat discovery page filled with fake ai news stories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159tijj/openai_launches_android_version_of_its_chatgpt_app/",
          "author": null,
          "description": "Two months after bringing ChatGPT to iOS, OpenAI LP today launched an Android version of its artificial intelligence assistant.\n The Android app is currently accessible for users in the U.S, India, Bangladesh and Brazil. OpenAI will extend availability to additional countries over the next week. The iOS version was available for download in more than 150 countries as of late May.\n    submitted by    /u/Tiger_Claw_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159tijj/openai_launches_android_version_of_its_chatgpt_app/",
          "publishedOn": "2023-07-26T02:54:05.000Z",
          "wordCount": 2524,
          "title": "OpenAI launches Android version of its ChatGPT app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159qe1p/ai_unlocks_olive_oils_potential_in_alzheimers/",
          "author": null,
          "description": "submitted by    /u/Alone-Competition-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159qe1p/ai_unlocks_olive_oils_potential_in_alzheimers/",
          "publishedOn": "2023-07-26T00:31:49.000Z",
          "wordCount": 2461,
          "title": "AI Unlocks Olive Oil's Potential in Alzheimer's Battle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159pita/yesterday_we_were_having_a_discussion_about/",
          "author": null,
          "description": "submitted by    /u/otherworlderotic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159pita/yesterday_we_were_having_a_discussion_about/",
          "publishedOn": "2023-07-25T23:55:35.000Z",
          "wordCount": 2480,
          "title": "Yesterday, we were having a discussion about synthetically generated video. Well, I'm back as promised, and with a very interesting result. Check it out! Details in comments.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159oa3g/about_singing_ai/",
          "author": null,
          "description": "Is it possible to have Ai come with a generated lyrics and sings within the bpm + root note?\n Does this exist? i’ll like to know where and how.\n Ai is interesting.\n    submitted by    /u/Office_Flashy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159oa3g/about_singing_ai/",
          "publishedOn": "2023-07-25T23:05:57.000Z",
          "wordCount": 2477,
          "title": "About Singing Ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159nfdm/oversight_of_ai_principles_for_regulation_united/",
          "author": null,
          "description": "submitted by    /u/jaketocake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159nfdm/oversight_of_ai_principles_for_regulation_united/",
          "publishedOn": "2023-07-25T22:34:01.000Z",
          "wordCount": 2471,
          "title": "Oversight of A.I.: Principles for Regulation | United States Senate Committee on the Judiciary - with Anthropic CEO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159isqa/ai_alignment_proposal_supplementary_alignment/",
          "author": null,
          "description": "submitted by    /u/RamazanBlack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159isqa/ai_alignment_proposal_supplementary_alignment/",
          "publishedOn": "2023-07-25T19:45:51.000Z",
          "wordCount": 2467,
          "title": "AI alignment proposal: Supplementary Alignment Insights Through a Highly Controlled Shutdown Incentive — LessWrong",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159hs4p/ai_presidential_debate/",
          "author": null,
          "description": "Hilarious, comedic effort of an AI presidential debate going on now.\n https://www.twitch.tv/trumporbiden2024\n    submitted by    /u/Smash_Factor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159hs4p/ai_presidential_debate/",
          "publishedOn": "2023-07-25T19:08:30.000Z",
          "wordCount": 2457,
          "title": "AI presidential debate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159gymw/the_white_house_already_knows_how_to_make_ai_safer/",
          "author": null,
          "description": "submitted by    /u/trueslicky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159gymw/the_white_house_already_knows_how_to_make_ai_safer/",
          "publishedOn": "2023-07-25T18:39:24.000Z",
          "wordCount": 2463,
          "title": "The White House Already Knows How to Make AI Safer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159g4ge/utilizing_ai_with_neutral_global_oversight_for/",
          "author": null,
          "description": "submitted by    /u/citidotio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159g4ge/utilizing_ai_with_neutral_global_oversight_for/",
          "publishedOn": "2023-07-25T18:08:49.000Z",
          "wordCount": 2463,
          "title": "Utilizing AI With Neutral Global Oversight for Business & Society",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159d2jt/if_deadpool_3_was_written_by_ai/",
          "author": null,
          "description": "Story by AI, Voiced by AI, Art by AI\n    submitted by    /u/realzackmcfarlin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159d2jt/if_deadpool_3_was_written_by_ai/",
          "publishedOn": "2023-07-25T16:18:08.000Z",
          "wordCount": 2458,
          "title": "If Deadpool 3 Was Written By AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159bnxp/they_offer_a_tesla_to_their_biggest_customers_o/",
          "author": null,
          "description": "The company is named Eden AI, they currently do their Product Hunt launch. They allow users to use AI APIs from all the AI companies (Google, AWS, OpenAI, Microsoft, and all the specialized companies).\n They recently added this rewards progress bar to their billing page, funny marketing operation!\n ​\n https://preview.redd.it/wgsg7yr5q4eb1.png?width=997&format=png&auto=webp&s=8f081891943f85ba9c72090cc5d946d3bd07ccf0\n ​\n    submitted by    /u/JerLam2762  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159bnxp/they_offer_a_tesla_to_their_biggest_customers_o/",
          "publishedOn": "2023-07-25T15:27:03.000Z",
          "wordCount": 2499,
          "title": "They offer a Tesla to their biggest customers :o",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15974ce/intel_seeks_to_win_over_ai_developers_with/",
          "author": null,
          "description": "submitted by    /u/reps_up  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15974ce/intel_seeks_to_win_over_ai_developers_with/",
          "publishedOn": "2023-07-25T12:28:52.000Z",
          "wordCount": 2464,
          "title": "Intel Seeks To Win Over AI Developers With Open-Source Reference Kits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1596r2i/spiderman_washing_cloth_ai_is_insane/",
          "author": null,
          "description": "submitted by    /u/Unlikely_Gap_5065  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1596r2i/spiderman_washing_cloth_ai_is_insane/",
          "publishedOn": "2023-07-25T12:12:50.000Z",
          "wordCount": 2457,
          "title": "(Spiderman washing cloth) Ai is insane",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1596ig1/understanding_openais_past_current_and_upcoming/",
          "author": null,
          "description": "I found it a bit hard to follow OpenAI's public releases - sometimes they just announce a model is coming without giving a date, sometimes they announce model deprecations and it's hard to understand whether we should use those models in production or not. \n I am a visual thinker so putting everything in a single image made sense to me. Check it out below, and if you have any questions or suggestions, please let me know! \n https://preview.redd.it/iuqc7nt2o3eb1.png?width=4800&format=png&auto=webp&s=ebe344a504d6a93fd2ce1935cdd1312d62735792\n https://preview.redd.it/vt2wkpt2o3eb1.png?width=4800&format=png&auto=webp&s=eb14503552b8d81398b5f3f76ebe68ad257e1857\n    submitted by    /u/EscapedLaughter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1596ig1/understanding_openais_past_current_and_upcoming/",
          "publishedOn": "2023-07-25T12:02:09.000Z",
          "wordCount": 2526,
          "title": "Understanding OpenAI's past, current, and upcoming model releases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158y8v9/oneminute_daily_ai_news_7242023/",
          "author": null,
          "description": "In a study published earlier this month, scientists at Rice and Stanford University concluded that training AI models exclusively on the outputs of generative AI is not a good idea. They titled their report: “Self-consuming generative models go MAD(Model Autophagy Disorder)”.[1]\n To enhance SQL query building, Lasse, a seasoned full-stack developer, has recently released AIHelperBot. This powerful tool enables individuals and businesses to write SQL queries efficiently, enhance productivity, and learn new SQL techniques.[2] \n Japan’s Ministry of Economy, Trade, and Industry (METI) has announced its plans to develop a new supercomputer to help advance the country’s artificial intelligence (AI) industry. The new supercomputer (SC) will be operated by the National Institute of Advanced Industrial Science and Technology (AIST).[3]\n Google co-founder Sergey Brin is back in the company’s office working directly with members of the artificial intelligence team.[4]\n  \nSources:\n [1] https://www.cdotrends.com/story/18288/training-ai-outputs-generative-ai-mad\n [2] https://dtgreviews.com/ai/meet-aihelperbot-an-artificial-intelligence-ai-based-sql-expert-that-builds-sql-queries-in-seconds/126512/\n [3] https://www.gizchina.com/2023/07/24/japan-ministry-develop-supercomputer-ai-industries/\n [4] https://www.wsj.com/video/series/tech-news-briefing/google-co-founder-returns-to-help-with-ai-efforts/27CE8E53-C8D8-4D93-8FA1-5E2C465092CB \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158y8v9/oneminute_daily_ai_news_7242023/",
          "publishedOn": "2023-07-25T05:00:40.000Z",
          "wordCount": 2593,
          "title": "One-Minute Daily AI News 7/24/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158rfx2/two_opposing_views_on_llms_reasoning_capabilities/",
          "author": null,
          "description": "bios from Wikipedia \n Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian cognitive psychologist and computer scientist, most noted for his work on artificial neural networks. From 2013 to 2023, he divided his time working for Google (Google Brain) and the University of Toronto, before publicly announcing his departure from Google in May 2023 citing concerns about the risks of artificial intelligence (AI) technology. In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\n Gary Fred Marcus (born 8 February 1970) is an American psychologist, cognitive scientist, and author, known for his research on the intersection of cognitive psychology, neuroscience, and artificial intelligence (AI).\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158rfx2/two_opposing_views_on_llms_reasoning_capabilities/",
          "publishedOn": "2023-07-24T23:54:38.000Z",
          "wordCount": 2573,
          "title": "Two opposing views on LLM’s reasoning capabilities. Clip1 Geoffrey Hinton. Clip2 Gary Marcus. Where do you fall in the debate?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158j617/aigenerated_content_from_the_original_image/",
          "author": null,
          "description": "Hello everyone, can someone tell me how to create AI-generated images and videos from the original picture? For example, I have a photo of some person, and I want to generate an image or video of this person in different places: in the plane, in the gym. Thank you.\n    submitted by    /u/Kurland121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158j617/aigenerated_content_from_the_original_image/",
          "publishedOn": "2023-07-24T18:44:56.000Z",
          "wordCount": 2497,
          "title": "AI-generated content from the original image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158iy1t/are_you_more_creative_than_chatgpt_submit_ideas/",
          "author": null,
          "description": "submitted by    /u/josha_umich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158iy1t/are_you_more_creative_than_chatgpt_submit_ideas/",
          "publishedOn": "2023-07-24T18:36:40.000Z",
          "wordCount": 2478,
          "title": "Are you more creative than ChatGPT? Submit ideas and my experiment compares the creativity of those ideas to humans and ChatGPT. You’ll get a link to share your results at the end! [takes ~ 5 minutes]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158i6fr/what_are_your_predictions_for_ai_and_medicine/",
          "author": null,
          "description": "Generally and specifically for specialties! \n    submitted by    /u/Wise-Listen-8076  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158i6fr/what_are_your_predictions_for_ai_and_medicine/",
          "publishedOn": "2023-07-24T18:09:29.000Z",
          "wordCount": 2455,
          "title": "What are your predictions for AI and medicine?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158d1ax/i_turned_ramen_making_process_into_anime/",
          "author": null,
          "description": "submitted by    /u/kirakngs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158d1ax/i_turned_ramen_making_process_into_anime/",
          "publishedOn": "2023-07-24T14:57:17.000Z",
          "wordCount": 2447,
          "title": "I turned ramen making process into anime.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158cegb/free_courses_and_guides_for_learning_generative_ai/",
          "author": null,
          "description": "Generative AI learning path by Google Cloud. A series of 10 courses on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud [Link].\n Generative AI short courses by DeepLearning.AI - Five short courses on generative AI including LangChain for LLM Application Development, How Diffusion Models Work and more. [Link].\n LLM Bootcamp: A series of free lectures by The full Stack on building and deploying LLM apps [Link].\n Building AI Products with OpenAI - a free course by CoRise in collaboration with OpenAI [Link].\n Free Course by Activeloop on LangChain & Vector Databases in Production [Link].\n Pinecone learning center - Lots of free guides as well as complete handbooks on LangChain, vector embeddings etc. by Pinecone [Link].\n Build AI Apps with ChatGPT, Dall-E and GPT-4 - a free course on Scrimba [Link].\n Gartner Experts Answer the Top Generative AI Questions for Your Enterprise - a report by Gartner [Link]\n GPT best practices: A guide by OpenAI that shares strategies and tactics for getting better results from GPTs [Link].\n OpenAI cookbook by OpenAI - Examples and guides for using the OpenAI API [Link].\n Prompt injection explained, with video, slides, and a transcript from a webinar organized by LangChain [Link].\n A detailed guide to Prompt Engineering by DAIR.AI [Link]\n What Are Transformer Models and How Do They Work. A tutorial by Cohere AI [Link]\n Learn Prompting: an open source course on prompt engineering[Link]\n  \nP.S. These resources are part of the content I share through my AI-focused newsletter. Thanks!\n    submitted by    /u/wyem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158cegb/free_courses_and_guides_for_learning_generative_ai/",
          "publishedOn": "2023-07-24T14:33:34.000Z",
          "wordCount": 2710,
          "title": "Free courses and guides for learning Generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158bxam/five_things_ai_wargames_call_center_head_of_ai/",
          "author": null,
          "description": "This is the content of my Friday newsletter Five Things AI. Every week I publish links to five articles about the current developments in AI, not so much with a focus on the tech aspects of AI, but more with an interest in finding out how AI changes our work, our economy and how we live in our societies. \n ‘WarGames’ anticipated our current AI fears 40 years ago this summer\n WarGames cannot be 40 years old, but I still remember watching it in a movie theater as a kid… what a great movie, it genuienely sparked my interests in computers. The evil side of AI is still very dominant in the discussions of AI, so WarGames really was an early example of our fear of the machines taking over.\n ‘Training My Replacement’: Inside a Call Center Worker’s Battle With A.I.\n It is important to be constantly…",
          "link": "https://www.reddit.com/r/artificial/comments/158bxam/five_things_ai_wargames_call_center_head_of_ai/",
          "publishedOn": "2023-07-24T14:15:22.000Z",
          "wordCount": 2910,
          "title": "Five Things AI: WarGames, Call Center, Head of AI, LLaMA 2, Jimmy Dean",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158ba48/everybody_here_knows_about_agi_and_artificial/",
          "author": null,
          "description": "Emotional AI is a different world of AI where machines can predict and understand human emotions, This is already impacting a lot in therapy and retail market. Rana El kaliouby is the women who built \"affectiva\" a startup which pioneers in emotional AI -- it's already being used in self driving cars and in the mental health industry, here's what they doing and I'm a total rookie at emotional AI side , if you have any other interesting company which is impacting a lot of people in this niche --would love to hear about it\n    submitted by    /u/caliperce_3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158ba48/everybody_here_knows_about_agi_and_artificial/",
          "publishedOn": "2023-07-24T13:51:09.000Z",
          "wordCount": 2559,
          "title": "everybody here knows about AGI and artificial super intelligence but have you heard about artificial emotional intelligence.Meet the girl who's building it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1589rnh/is_this_the_role_of_philosophy_in_the_21st_century/",
          "author": null,
          "description": "Person: discuss how the ontology outlined in your custom instructions can be used to marry relativity and quantum physics\n ChatGPT: The ontology proposed in the aforementioned description appears to rely heavily on emergent properties, consciousness, and free will, with a substantial focus on the temporal aspect. The challenge is to see how these metaphysical elements, particularly when applied to an AI, can help in reconciling the often contrasting principles of relativity and quantum physics.\n At first glance, the connection may not be clear; relativity and quantum mechanics operate in different realms of the physical universe. However, upon closer examination, one might see potential pathways to harmonize these distinct theories via the ontology of consciousness and emergent free will. …",
          "link": "https://www.reddit.com/r/artificial/comments/1589rnh/is_this_the_role_of_philosophy_in_the_21st_century/",
          "publishedOn": "2023-07-24T12:49:44.000Z",
          "wordCount": 3053,
          "title": "Is this the role of philosophy in the 21st century?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158778c/new_study_involving_buddhists_in_japan_taoists_in/",
          "author": null,
          "description": "submitted by    /u/fotogneric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158778c/new_study_involving_buddhists_in_japan_taoists_in/",
          "publishedOn": "2023-07-24T10:51:36.000Z",
          "wordCount": 2493,
          "title": "New study involving Buddhists in Japan, Taoists in Singapore, and Christians in the US finds that AI clergy are seen as less credible and receive fewer donations than human clergy, mainly due to the AI's lack of sacrifice and commitment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1585a2x/convert_music_to_art/",
          "author": null,
          "description": "Guitarist Tosin Abasi followed an Instagram account about a software that converts music into painting ~3 years back ? He also liked there video and commented something\n Video was of a guy playing piano and as he played canvas was filled with color.\n The software is made by a musician + artist + programmer. IIRC he is a pdf of masters in Com Sc\n    submitted by    /u/RedditNoobie777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1585a2x/convert_music_to_art/",
          "publishedOn": "2023-07-24T09:11:21.000Z",
          "wordCount": 2511,
          "title": "Convert Music to Art ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1584tkg/i_made_a_plugin_that_allows_people_to_search_and/",
          "author": null,
          "description": "submitted by    /u/AssetOvi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1584tkg/i_made_a_plugin_that_allows_people_to_search_and/",
          "publishedOn": "2023-07-24T08:45:53.000Z",
          "wordCount": 2455,
          "title": "I Made a plugin that allows people to search and preview millions of 3D assets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15848ox/surprise_ai_advanced_faster_than_robotics_that/",
          "author": null,
          "description": "People in intellectual jobs have often been thought of as doing something inherently more complex than manual workers in, for instance, construction or farming.\n Whether or not that is true, the surprise twist is that their “complex” work will be the first to be replaced. Computers have cracked intellectual work sooner than they have cracked manual work. It’s still too complex for a robot to replace a fruit-picker completely, but we’ll soon see AI lawyers.\n So we’re going to see a mass inversion. Everyone today sitting prettily doing their intellectual jobs will find their wages crushed or jobs redundant as AI replaces them. Meanwhile, everyone doing the jobs robotics can’t yet replace will be best placed to continue doing them.\n High flying executives will find they are suitable only for shelf-stacking, while those who’ve worked in retail for years will be or become their bosses.\n Soon enough, AI will help us advance the field of robotics sufficiently for manual labour also to be replaced. Who knows what happens then.\n    submitted by    /u/Aquillyne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15848ox/surprise_ai_advanced_faster_than_robotics_that/",
          "publishedOn": "2023-07-24T08:13:44.000Z",
          "wordCount": 2626,
          "title": "Surprise! AI advanced faster than robotics. That means today’s middle and lower classes will swap.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1583inw/best_books_about_ai/",
          "author": null,
          "description": "Hello everyone,\n I was searching for a book that talks about how AI will impact the future and how we can prepare best. I am not searching for anything technical or specific, just how can a person prepare best for the future.\n Thanks!\n    submitted by    /u/Ordinary_Argument_66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1583inw/best_books_about_ai/",
          "publishedOn": "2023-07-24T07:33:26.000Z",
          "wordCount": 2489,
          "title": "Best Books About AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1580pl5/the_neverending_game_how_ai_will_create_a_new/",
          "author": null,
          "description": "submitted by    /u/Respawne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1580pl5/the_neverending_game_how_ai_will_create_a_new/",
          "publishedOn": "2023-07-24T05:00:03.000Z",
          "wordCount": 2465,
          "title": "The NeverEnding Game: How AI Will Create a New Category of Games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157z6on/oneminute_daily_ai_news_7232023/",
          "author": null,
          "description": "Cerebras just built a gargantuan computer system with 27 million AI 'cores'.[1]\n FreeWilly1 and its successor FreeWilly2 are powerful new open-source Large Language Models (LLMs) developed by Stability AI’s CarperAI team. Both models perform exceptionally well in reasoning competitions using many different metrics.[2]\n Japanese education services company Benesse will offer a new service to help elementary school students with their research projects using generative artificial intelligence during the summer break.[3]\n The MTA is using artificial intelligence to help monitor fare evasion in several subway stations across New York City.[4]\n  \nSources: \n [1] https://www.zdnet.com/article/ai-startup-cerebras-built-a-gargantuan-ai-computer-for-abu-dhabis-g42-with-27-million-ai-cores/\n [2] https://www.marktechpost.com/2023/07/23/stability-ai-team-introduces-freewilly1-and-freewilly2-new-open-access-large-language-models-llms/\n [3] https://www.japantimes.co.jp/news/2023/07/23/national/benesse-ai-service-kids-research-projects/\n [4] https://abc7ny.com/amp/mta-artificial-intelligence-subway-fare-evasions/13533675/\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157z6on/oneminute_daily_ai_news_7232023/",
          "publishedOn": "2023-07-24T03:41:00.000Z",
          "wordCount": 2545,
          "title": "One-Minute Daily AI News 7/23/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157wwj9/best_ai_model_for_importing_and_interacting_with/",
          "author": null,
          "description": "Where I work we have a fairly large archive of documents going back to the 1930's and I want to assist the archive team in importing these into a GPT model. We have already begun the process of digitizing all the documents into OCR'ed PDF files, so this part at least is covered. \n My question is, what are the hot fully offline AI models I could try in an airgapped environment that will allow us to import all of the PDF files and their metadata (title/date/tags/etc), to incorporate their content on top of the larger general model? \n    submitted by    /u/kosul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157wwj9/best_ai_model_for_importing_and_interacting_with/",
          "publishedOn": "2023-07-24T01:51:47.000Z",
          "wordCount": 2550,
          "title": "Best AI model for importing and interacting with large document archive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157wd2t/i_feel_crushed_this_is_not_exactly_what_i/",
          "author": null,
          "description": "Yes, the Midjourney to Gen2 creations in the twitter link was not exactly what I envisioned. I thought that it would be more like mocap previz with AI filtering. But this is just almost too instant compared to the workflow I thought of.\n    submitted by    /u/Absolute-Nobody0079  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157wd2t/i_feel_crushed_this_is_not_exactly_what_i/",
          "publishedOn": "2023-07-24T01:26:35.000Z",
          "wordCount": 2501,
          "title": "I feel crushed. This is not exactly what I envisioned. This is too instant.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157uso1/github_jbpaytonlangchainstockscreener_langchain/",
          "author": null,
          "description": "submitted by    /u/seraphius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157uso1/github_jbpaytonlangchainstockscreener_langchain/",
          "publishedOn": "2023-07-24T00:13:28.000Z",
          "wordCount": 2464,
          "title": "GitHub - jbpayton/langchain-stock-screener: LangChain agent usable tool to screen stock data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157u5ud/compilation_of_respected_ai_scientists_speaking/",
          "author": null,
          "description": "This segment I created for my IG exploring the possibility of AI consciousness. Not all experts agree, some scientists on the other side of the AI world model debate are Yann LeCun, and Gary Marcus they are also well respected AI Scientists who have a differing opinion. \n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157u5ud/compilation_of_respected_ai_scientists_speaking/",
          "publishedOn": "2023-07-23T23:44:55.000Z",
          "wordCount": 2515,
          "title": "Compilation of respected AI scientists speaking on AI understanding, world models & consciousness, Mo Gawdat, Lex Fridman, Andrej Karpathy, Geoffrey Hinton, Gary Marcus, & Ilya Sutskever",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157rd2w/trained_an_ai_to_drive_in_realtime_from/",
          "author": null,
          "description": "submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157rd2w/trained_an_ai_to_drive_in_realtime_from/",
          "publishedOn": "2023-07-23T21:48:32.000Z",
          "wordCount": 2454,
          "title": "Trained an AI to drive in real-time from screenshots in the TrackMania videogame (beginner-friendly)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157r42p/saurabh_kumars_fastcmix_wins_5187_hutter_prize/",
          "author": null,
          "description": "submitted by    /u/jabowery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157r42p/saurabh_kumars_fastcmix_wins_5187_hutter_prize/",
          "publishedOn": "2023-07-23T21:38:18.000Z",
          "wordCount": 2450,
          "title": "Saurabh Kumar's fast-cmix wins €5187 Hutter Prize Award!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157qjas/how_generative_ai_looks_in_next_1015_years/",
          "author": null,
          "description": "submitted by    /u/AdithyaSai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157qjas/how_generative_ai_looks_in_next_1015_years/",
          "publishedOn": "2023-07-23T21:14:40.000Z",
          "wordCount": 2461,
          "title": "How Generative AI looks in next 10-15 years",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157ngvz/whats_the_ai_that_allows_you_to_remake_songs_from/",
          "author": null,
          "description": "I've seen some videos on youtube and I'm curious. I just wanted to have some fun with it but Google isn't helpful when I ask. Anyone got an idea?\n    submitted by    /u/GoblinQueenForever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157ngvz/whats_the_ai_that_allows_you_to_remake_songs_from/",
          "publishedOn": "2023-07-23T19:15:58.000Z",
          "wordCount": 2494,
          "title": "What's the A.I that allows you to remake songs from the voices of other singers? Are there any I won't have to download?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157n4bb/best_opensource_projects_for_deep_fakes/",
          "author": null,
          "description": "What are the best opensource projects for making a deep fake of myself? I would like to create a setup like me talking on a podcast to a camera.\n What are the best projects that you know of?\n    submitted by    /u/Reasonable_Chain_160  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157n4bb/best_opensource_projects_for_deep_fakes/",
          "publishedOn": "2023-07-23T19:02:30.000Z",
          "wordCount": 2486,
          "title": "Best Opensource Projects for Deep Fakes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157mmod/graphics_card_for_consideration_cheapestbudget_in/",
          "author": null,
          "description": "So, Nvdia is technically the best in this AI department. (For now 24/07/2023)\n Budget - (200 - 300)$\n Official Prices in Amazon\n 1 ) Intel arc A750 8 GB Amazon price - 219$\n 2 ) RX 7600 OC 8 GB Amazon price - 269$\n 3 ) RTX 3060 12 GB Amazon price - 284$\n Here we see that Arc A750 is about 60 $ cheaper but price in different country is different. In my country Bangladesh the prices are as follow\n Official Prices in Bangladesh\n 1 ) Intel arc A750 8 GB Startech (Bangladesh) price - 285$ (cheapest)\n 2 ) RX 7600 OC 8 GB Startech (Bangladesh) price - 327$ (cheapest)\n 3 ) RTX 3060 12 GB Startech (Bangladesh) price - 401$ (cheapest)\n 4)Intel arc A770 16 GB Startech (Bangladesh) price - 421$ (cheapest)\n Now the difference is more than 100 $ and both AMD and RTX are out of budget.\n AMD just isn't that good with Ai in any way.\n Nvdia is the best. (Not price to performance.\n Intel Arc is new but has better capabilities in AI than AMD. But its drivers are bad for AI for now)\n Now thinking if the intel drivers for Ai get better and optimized as its already somewhat better for games.\n Will the arc a750 be better than the RTX 3060 12 GB ?\n Will the arc a770 capitalize on Vram and beat all nvdia budget gpus after the drivers are fixed only for 20 more dollars than rtx 3060?\n Which is better for future proofing (theoritically) from these budget gpus ? If its arc then I will gamble its chances of surviving in the future and buy it now.\n    submitted by    /u/BonelyCore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157mmod/graphics_card_for_consideration_cheapestbudget_in/",
          "publishedOn": "2023-07-23T18:43:30.000Z",
          "wordCount": 2728,
          "title": "Graphics Card for consideration . ( Cheapest-Budget ) (In my country compared to amazon)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157dl25/anyone_who_can_assist_me_in_connecting_my_premium/",
          "author": null,
          "description": "So I’m amazed by ChatGPT and have signed up for the paid ChatGPT-4 version. I do however feel a little handcuffed by only having access to data up until 2021. I know there are ways to connect it to the internet as well as to add certain plug ins to enhance the experience but I haven’t been able to figure out any of the guides or tutorials from google…. I’m using Apple iPhone for the app and MacBook Pro laptop for web browsing\n    submitted by    /u/Kennyg39  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157dl25/anyone_who_can_assist_me_in_connecting_my_premium/",
          "publishedOn": "2023-07-23T12:27:17.000Z",
          "wordCount": 2541,
          "title": "Anyone who can assist me in connecting my premium ChatGPT to the internet and connecting plug-ins?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157bxwc/do_ai_detectors_have_access_to_all_the_data_that/",
          "author": null,
          "description": "And why is this fact rarely mentioned when discussing how AI detectors do their work?\n    submitted by    /u/E_Olig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157bxwc/do_ai_detectors_have_access_to_all_the_data_that/",
          "publishedOn": "2023-07-23T11:01:57.000Z",
          "wordCount": 2502,
          "title": "Do AI detectors have access to all the data that has been fed into AI systems like Chatgpt? If so, does this mean that a story that has been inputed into Chatgpt will be flagged as \"AI\" even if it had actually been human created?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157bw67/ava_scifi_short_film_about_ai_made_by_a_human/",
          "author": null,
          "description": "submitted by    /u/blakeridder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157bw67/ava_scifi_short_film_about_ai_made_by_a_human/",
          "publishedOn": "2023-07-23T10:59:48.000Z",
          "wordCount": 2451,
          "title": "AVA | Sci-Fi Short Film about AI, Made by a Human",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157acqu/my_teacher_asked_me_to_make_a_presentation_and_a/",
          "author": null,
          "description": "submitted by    /u/volvie98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157acqu/my_teacher_asked_me_to_make_a_presentation_and_a/",
          "publishedOn": "2023-07-23T09:33:36.000Z",
          "wordCount": 2476,
          "title": "My teacher asked me to make a presentation and a demo of one of the following programs. Which one would be the easiest to make?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15741w1/i_am_seeking_free_ai_websitesservices_to_convert/",
          "author": null,
          "description": "I am a beginner to intermediate bass player and I would like to play some songs I like, but a couple of the songs are not very popular and do not have any tabs for them. I would ideally like an ai tool that can transcribe the bass notes. \n    submitted by    /u/GenuineElf80093  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15741w1/i_am_seeking_free_ai_websitesservices_to_convert/",
          "publishedOn": "2023-07-23T03:44:30.000Z",
          "wordCount": 2511,
          "title": "I am seeking free Ai websites/services to convert mp3 or other audio files and transcribe them into Bass guitar Tabs.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1573sip/geoffrey_hinton_aka_the_godfather_of_al_admits_in/",
          "author": null,
          "description": "Ilya Sustkever has some good explanations as to why AI in predicting the next token, has modeled the world and has gained an understanding of what lead to creation of those tokens (words or parts of words) and the better a model is at predicting the next token the higher the fidelity is in its understanding the world through the relationship of words…but don’t take my word for it. Actually listen to what the top experts in AI are saying not just some rando on Reddit. All experts don’t agree but the people building the best models seem to share this view. Many of them studied under Geoffrey Hinton. \n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1573sip/geoffrey_hinton_aka_the_godfather_of_al_admits_in/",
          "publishedOn": "2023-07-23T03:30:25.000Z",
          "wordCount": 2585,
          "title": "Geoffrey Hinton, Aka the \"Godfather of Al\" admits in a recent lecture at Kings College that he believes current Al probably has feelings & emotions & speaks about why he avoids talking about it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15725ou/can_anyone_who_understand_how_these_models_work/",
          "author": null,
          "description": "Focus on having fun together rather than writing every ride. Take breaks in between.\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15725ou/can_anyone_who_understand_how_these_models_work/",
          "publishedOn": "2023-07-23T02:07:58.000Z",
          "wordCount": 2470,
          "title": "can anyone who understand how these models work explain why claude made this mistake?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15720n7/ai_is_learning_to_troll/",
          "author": null,
          "description": "submitted by    /u/MostConversation3772  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15720n7/ai_is_learning_to_troll/",
          "publishedOn": "2023-07-23T02:01:08.000Z",
          "wordCount": 2456,
          "title": "AI is learning to troll",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1570ogb/is_there_an_ai_tool_that_makes_english_subtitles/",
          "author": null,
          "description": "I have a chatbot that can find most AI tools, but it can't seem to find one of these. \n    submitted by    /u/ai_basics_official  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1570ogb/is_there_an_ai_tool_that_makes_english_subtitles/",
          "publishedOn": "2023-07-23T00:57:41.000Z",
          "wordCount": 2476,
          "title": "Is there an AI tool that makes English subtitles out of audio from other languages?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1570cpe/where_can_i_find_an_ai_engine_where_i_can_upload/",
          "author": null,
          "description": "I was using Uber duck to change my singing voice into another artist. But Uber duck recently has taken down all of their community generated voices so no more Drizzy, Drake or Adele. I need a new website now to fool around with where I can upload my own singing in change it into another artist. Anything would help thanks guys.\n    submitted by    /u/Evangelionyama  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1570cpe/where_can_i_find_an_ai_engine_where_i_can_upload/",
          "publishedOn": "2023-07-23T00:42:09.000Z",
          "wordCount": 2520,
          "title": "Where can I find an AI engine where I can upload my own audio to voice change?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156z7uh/ai_tool_to_edit_ai_files_text/",
          "author": null,
          "description": "I am looking for a tool that I can edit text on a .ai file with new text that will use the same font and center the text. Of course can be done in Photoshop or other tools like Canva, just not sure if something new is available.\n Also, for those that use midjourney, and you want to add text to an image, but tool do you use?\n    submitted by    /u/tequiladrinker1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156z7uh/ai_tool_to_edit_ai_files_text/",
          "publishedOn": "2023-07-22T23:51:05.000Z",
          "wordCount": 2517,
          "title": "AI tool to edit .ai files text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156yc1r/computer_chip_with_builtin_human_brain_tissue/",
          "author": null,
          "description": "submitted by    /u/surfer808  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156yc1r/computer_chip_with_builtin_human_brain_tissue/",
          "publishedOn": "2023-07-22T23:12:16.000Z",
          "wordCount": 2463,
          "title": "Computer chip with built-in human brain tissue gets military funding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156o1so/discussion_i_have_a_theory_that_chatgpt_is/",
          "author": null,
          "description": "As NLP hype become more prevalent, we would expect a (probably exponentially) increasing amount of scraped data-sources become filled with AI generated stuff, no? Then wouldn't AI would be trained on this data without necessarily a 'critical thinking' module to check their work?\n Not just ChatGPT generated quality either, but also lesser AI companies making cheap ad-ware and upvote bots.\n ​\n I wonder if ChatGPT et al could have a 'quality sensor' module in some ai that does what I do on reddit and do sentiment analysis on the most upvoted comments to see whether the article/answer/assertion is full of shit. Not foolproof, but short of actual critical reasoning, seems like a good start.\n ​\n Feels like we may soon enter an arms race where AIs need to detect AI-generated content in order to ensure their own quality.\n    submitted by    /u/Yamochao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156o1so/discussion_i_have_a_theory_that_chatgpt_is/",
          "publishedOn": "2023-07-22T16:08:07.000Z",
          "wordCount": 2603,
          "title": "[Discussion] I have a theory that ChatGPT is becoming dumber because more of the internet is made up of AI generated content since it awakened",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156myzt/best_ai_for_businesssocial_media_account_name/",
          "author": null,
          "description": "I'm looking for something that can generate names using real words like ConnectHub but also made up names like Intrium. I tried ChatGPT buy the names it gave me were not good and it kept repeating them(but I am a noob so). \n    submitted by    /u/anysuggestionwelcome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156myzt/best_ai_for_businesssocial_media_account_name/",
          "publishedOn": "2023-07-22T15:24:47.000Z",
          "wordCount": 2492,
          "title": "Best AI for business/social media account name generation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156ko8j/bing_ai_arrogance_and_sentiment/",
          "author": null,
          "description": "submitted by    /u/Yha_Boiii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156ko8j/bing_ai_arrogance_and_sentiment/",
          "publishedOn": "2023-07-22T13:50:22.000Z",
          "wordCount": 2456,
          "title": "Bing AI Arrogance and sentiment",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15wcpbp/the_mlpedia_newsletter/",
          "author": null,
          "description": "Every week, a selection of new Machine Learning concepts and articles added to MLpedia.ai, plus curated ML news/content from around the web (e.g. relevant papers, software, blogs).\n https://www.mlpedia.ai/newsletter\n    submitted by    /u/marcelocnet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15wcpbp/the_mlpedia_newsletter/",
          "publishedOn": "2023-08-20T14:21:58.000Z",
          "wordCount": null,
          "title": "The MLpedia Newsletter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15vd2mk/prof_greg_j_norman_the_wonderful_world_of/",
          "author": null,
          "description": "submitted by    /u/Last_Salad_5080  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15vd2mk/prof_greg_j_norman_the_wonderful_world_of/",
          "publishedOn": "2023-08-19T10:52:23.000Z",
          "wordCount": 2568,
          "title": "Prof. Greg J. Norman | The Wonderful World of Neuroscience | #166 HR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15uyfk9/open_challenges_in_llm_research/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15uyfk9/open_challenges_in_llm_research/",
          "publishedOn": "2023-08-18T22:28:03.000Z",
          "wordCount": 2573,
          "title": "Open challenges in LLM research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15uqlsi/why_you_probably_dont_need_to_finetune_an_llm/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15uqlsi/why_you_probably_dont_need_to_finetune_an_llm/",
          "publishedOn": "2023-08-18T17:21:31.000Z",
          "wordCount": 2577,
          "title": "Why You (Probably) Don't Need to Fine-tune an LLM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ug31e/short_blogpost_about_how_relus_approximate/",
          "author": null,
          "description": "I just stumbled upon a neat blog-post on how ReLUs approximate non-linear functions.\n When talking to others I often feel like the piece-wise linearity (even of composed layers) is not on peoples mind, but I often think about it when imagining the behavior of networks.\n    submitted by    /u/LeanderKu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ug31e/short_blogpost_about_how_relus_approximate/",
          "publishedOn": "2023-08-18T09:54:44.000Z",
          "wordCount": 2611,
          "title": "Short blog-post about how ReLUs approximate functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15th15a/neurons_in_a_hidden_layer/",
          "author": null,
          "description": "Hey guys, I am new to neural networks and I was confused about how to find the number of neurons in a hidden layer? Thank you in advance☺️\n    submitted by    /u/Icy-Lingonberry-8465  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15th15a/neurons_in_a_hidden_layer/",
          "publishedOn": "2023-08-17T08:14:45.000Z",
          "wordCount": 2554,
          "title": "Neurons in a hidden layer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15tatec/pc_hardware_requirements/",
          "author": null,
          "description": "I am interested in working on some deep learning projects (not professionally, just for fun) and need to get a new PC that can handle the workload. I'm thinking about simple to moderately complex models (LSTM RNNs, RL models, transformer models, etc.) trained on datasets of 10-20 million data points. What sort of hardware would be needed for this type of task?\n    submitted by    /u/NathanZubrzycki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15tatec/pc_hardware_requirements/",
          "publishedOn": "2023-08-17T02:59:18.000Z",
          "wordCount": 2586,
          "title": "PC Hardware Requirements",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ryy0i/selfwritten_network_performs_well_with_sigmoid/",
          "author": null,
          "description": "Hello everyone!\n I'm quite new to deep learning, and mostly self-taught, so if anyone can suggest some good resources or books which are relevant here, that would be great!\n Over the past few days I've been coding up a small Multilayer Perceptron from scratch in C++, and training it on MNIST. I've been able to implement a network which performs pretty well, getting ~94% accuracy on the test dataset. I read that Cross-Entropy is a better loss function than MSE for categorical classification, so I've been trying to implement that, along with Softmax as an output layer activation function, but I've been met with very underwhelming results.\n I've played around with learning rates, the number of layers and layer sizes, batch sizes, initial values for weights / biases, and nothing seems to help.…",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ryy0i/selfwritten_network_performs_well_with_sigmoid/",
          "publishedOn": "2023-08-15T17:27:25.000Z",
          "wordCount": 3057,
          "title": "Self-written network performs well with Sigmoid / MSE, but poorly with Softmax / Cross-Entropy - any ideas why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15qr5uy/community_events/",
          "author": null,
          "description": "Hi u/all am thinking of creating a series of interesting events for the broader AI-Community. I always felt most events are either too expensive or too much of a company pitch. The topics should vary each time but for sure cover technical deep dives, some high level talks and some possibility to network and get together. I already have some company sponsors who are just interested in showing their name in the venue but don't want to interact/get information on participants or anything.\n ​\n What do you think - is this worth a shot? \n What ideas do you have wrt topics, speakers?\n    submitted by    /u/CarlCarter312  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15qr5uy/community_events/",
          "publishedOn": "2023-08-14T10:42:34.000Z",
          "wordCount": 2609,
          "title": "Community Events",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15qm8tm/question_on_creation_neural_network_to_forecast/",
          "author": null,
          "description": "Data I have:\n Project Information (Cost, location, original contract duration)\n Different Reasons for extension of duration and corresponding number of days (actual record of different sample projects).\n ​\n Based on this data, will the neural network make its own analysis of the frequency and severity of each Reason for extension of duration and incorporate it in the output?\n    submitted by    /u/shearhead  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15qm8tm/question_on_creation_neural_network_to_forecast/",
          "publishedOn": "2023-08-14T06:11:12.000Z",
          "wordCount": 2574,
          "title": "Question on creation Neural Network to forecast construction duration considering delays.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15qdev6/legions_of_def_con_hackers_will_attack_generative/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15qdev6/legions_of_def_con_hackers_will_attack_generative/",
          "publishedOn": "2023-08-13T23:12:59.000Z",
          "wordCount": 2499,
          "title": "Legions of DEF CON hackers will attack generative AI models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15q1sza/is_it_possible_for_a_person_to_propose_a_new/",
          "author": null,
          "description": "How to come up with the architecture?\n    submitted by    /u/AnyJello605  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15q1sza/is_it_possible_for_a_person_to_propose_a_new/",
          "publishedOn": "2023-08-13T15:29:35.000Z",
          "wordCount": 2499,
          "title": "Is it possible for a person to propose a new variety of neural networks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15prsqv/question_about_neural_networks_and_games/",
          "author": null,
          "description": "Hello everyone, I'll go straight to the question. My pixel game needs sprites, but I know practically nothing about drawing sprites, and if on the one hand I can still draw something, then 4 directional (front, back, left, right) turn out badly, and you also need to add animation to them. Knowing that there are a lot of neural networks and for almost every task, I decided to find a neural network that will solve my problem, but I couldn't. Therefore, I ask if you know a neural network that can solve my problem. Thank you in advance.\n    submitted by    /u/Ilya-33  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15prsqv/question_about_neural_networks_and_games/",
          "publishedOn": "2023-08-13T06:49:46.000Z",
          "wordCount": 2582,
          "title": "Question about neural networks and games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15p15s9/unleash_the_future_of_ai_with_metagpt/",
          "author": null,
          "description": "submitted by    /u/ABDULKADER90H  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15p15s9/unleash_the_future_of_ai_with_metagpt/",
          "publishedOn": "2023-08-12T10:33:06.000Z",
          "wordCount": 2498,
          "title": "🚀 Unleash the Future of AI with MetaGPT! 🌟",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ot74g/sharing_100_objective_type_questions_on/",
          "author": null,
          "description": "Please provide your valuable feedback. \n  \nCNN Objective Type Questions (50)\n RNN & Generative Models Objective Type Questions (50)\n  \n   submitted by    /u/nkptcs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ot74g/sharing_100_objective_type_questions_on/",
          "publishedOn": "2023-08-12T03:11:38.000Z",
          "wordCount": 2521,
          "title": "Sharing 100 Objective Type Questions on Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs) and Generative Models divided in 2 Online Exams (50 Questions each)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15orbz0/awesome_outofdistribution_detection/",
          "author": null,
          "description": "Hi everyone,\n I have put together a repo that provides comprehensive resources for Out-of-distribution Detection, Robustness, and Generalization. The repo contains articles, talks, libraries, papers, etc. Unlike many repos, this one will actually be maintained and updated with high-quality sources! I hope it becomes a one-stop shop for anything OOD in your bookmark. Give it a star if you find it helpful ;) Check it out.\n https://github.com/continuousml/Awesome-Out-Of-Distribution-Detection\n ​\n https://preview.redd.it/s5bpdelb3lhb1.png?width=895&format=png&auto=webp&s=b1b123c709113c30b20c2f4f0ebeb995f79edf50\n    submitted by    /u/Ok-Kaleidoscope-505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15orbz0/awesome_outofdistribution_detection/",
          "publishedOn": "2023-08-12T01:41:32.000Z",
          "wordCount": 2548,
          "title": "Awesome Out-of-distribution Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15oqv3f/whats_the_current_stateconsensus_on_using_neural/",
          "author": null,
          "description": "Historically, the most practical methods for solving real-world combinatorial scheduling problems have been using heuristics or metaheurisics such as simulated annealing, tabu search, greedy randomized adaptive search, etc... I consider these more operation research-based techniques. \n However, recently we have obviously seen a lot of progress being made in the machine learning realm for many types of problems. In particular, we've seen neural networks be used to train models based on data in text, audio, or video form. \n I am wondering if we have any idea what the scientific consensus is toward applying these same sort of methods for scheduling problems. Suppose we have a history of schedules that we could train a model on. A schedule isn't really text, audio, or video so I don't understand how one could embed the information in a vector space in the same way that would accurately represent the information (specifically, constraints so that the resulting schedule is still feasible) Is there anyone doing research in this particular area?\n    submitted by    /u/nick898  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15oqv3f/whats_the_current_stateconsensus_on_using_neural/",
          "publishedOn": "2023-08-12T01:19:47.000Z",
          "wordCount": 2656,
          "title": "What's the current state/consensus on using neural networks for solving combinatorial scheduling problems?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15oi76d/finetuning_llama2_a_comprehensive_case_study_for/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15oi76d/finetuning_llama2_a_comprehensive_case_study_for/",
          "publishedOn": "2023-08-11T19:29:25.000Z",
          "wordCount": 2501,
          "title": "Fine-Tuning Llama-2: A Comprehensive Case Study for Tailoring Models to Unique Applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ml50h/llama_from_scratch_or_how_to_implement_a_paper/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ml50h/llama_from_scratch_or_how_to_implement_a_paper/",
          "publishedOn": "2023-08-09T17:07:27.000Z",
          "wordCount": 2481,
          "title": "Llama from scratch (or how to implement a paper without crying)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15m51k8/announcing_stablecode_stability_ai/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15m51k8/announcing_stablecode_stability_ai/",
          "publishedOn": "2023-08-09T04:41:16.000Z",
          "wordCount": 2486,
          "title": "Announcing StableCode — Stability AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lq8jj/growing_bonsai_networks_with_rnns/",
          "author": null,
          "description": "submitted by    /u/Ameobea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lq8jj/growing_bonsai_networks_with_rnns/",
          "publishedOn": "2023-08-08T18:30:27.000Z",
          "wordCount": 2486,
          "title": "Growing Bonsai Networks with RNNs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lj0ao/i_made_an_animated_video_explaining_effective/",
          "author": null,
          "description": "submitted by    /u/antaloaalonso  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lj0ao/i_made_an_animated_video_explaining_effective/",
          "publishedOn": "2023-08-08T13:58:35.000Z",
          "wordCount": 2512,
          "title": "I made an animated video explaining Effective Accelerationism (aka e/acc), a philosophical movement related to AI that has recently grown a lot in popularity and offers a path to a post-scarcity technological utopia. It has even been endorsed by Marc Andreessen and Garry Tan.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lgoqr/getting_the_hang_of_opencvs_inner_workings_with/",
          "author": null,
          "description": "​\n https://preview.redd.it/xdp3bkwwpvgb1.jpg?width=2800&format=pjpg&auto=webp&s=513a63ed81eec85e6bc254f84e4208094afc7d4a\n Very interesting blog post from OpenCV.ai team about how can explore ChatGPT to serve for code development debugging.\n Introduction from the article:\n As programmers, we often work with familiar development environments, but occasionally we encounter new tools that can be time-consuming and challenging to learn. In such situations, having virtual assistance can be extremely beneficial.\n In this article, I will share my experience of contributing to OpenCV, a renowned open-source library, despite having limited knowledge of C++ and understanding its architecture. I achieved this with the assistance of ChatGPT, a Large Language Model (LLM).\n I hope you can find it interesting. More details are here.\n    submitted by    /u/No-Independence5880  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lgoqr/getting_the_hang_of_opencvs_inner_workings_with/",
          "publishedOn": "2023-08-08T12:22:16.000Z",
          "wordCount": 2580,
          "title": "Getting the Hang of OpenCV’s Inner Workings with ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lfuxs/mixture_of_experts_moe/",
          "author": null,
          "description": "submitted by    /u/ABDULKADER90H  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lfuxs/mixture_of_experts_moe/",
          "publishedOn": "2023-08-08T11:45:42.000Z",
          "wordCount": 2485,
          "title": "Mixture of Experts (MoE)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kkeef/help_to_find_a_dataset_for_my_project_please/",
          "author": null,
          "description": "Hello everyone! I'm a newbie and making my project on machine learning and the aim is create a programme to recognise a spice by feeding some chemical constituents, but I can't find appropriate dataset for it. I have been searching for months, and now I'm a bit desperate, so I'm asking anyone interested for help... I know maybe it was a mistake to choose exactly this topic, but I can't drop the project.\n    submitted by    /u/Acceptable-Muscle-98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kkeef/help_to_find_a_dataset_for_my_project_please/",
          "publishedOn": "2023-08-07T13:13:22.000Z",
          "wordCount": 2543,
          "title": "Help to find a dataset for my project, please 🙏",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kfany/microgradts_a_typescript_version_of/",
          "author": null,
          "description": "submitted by    /u/trekhleb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kfany/microgradts_a_typescript_version_of/",
          "publishedOn": "2023-08-07T09:09:10.000Z",
          "wordCount": 2492,
          "title": "MicrogradTS — a TypeScript version of karpathy/micrograd — a tiny scalar-valued autograd engine and a neural net on top of it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kenut/openai_introducing_triton_opensource_gpu/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kenut/openai_introducing_triton_opensource_gpu/",
          "publishedOn": "2023-08-07T08:33:57.000Z",
          "wordCount": 2481,
          "title": "OpenAI - Introducing Triton: Open-source GPU programming for neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kenfr/nvidias_cuda_monopoly/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kenfr/nvidias_cuda_monopoly/",
          "publishedOn": "2023-08-07T08:33:14.000Z",
          "wordCount": 2474,
          "title": "NVIDIA's CUDA Monopoly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15jqysx/neural_networks_from_scratch_deep_learning/",
          "author": null,
          "description": "submitted by    /u/AeroArtz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15jqysx/neural_networks_from_scratch_deep_learning/",
          "publishedOn": "2023-08-06T14:27:38.000Z",
          "wordCount": 2430,
          "title": "Neural Networks FROM SCRATCH | Deep Learning tutorial Part 1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15jht4h/massediting_memory_in_a_transformer/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15jht4h/massediting_memory_in_a_transformer/",
          "publishedOn": "2023-08-06T05:58:28.000Z",
          "wordCount": 2438,
          "title": "Mass-Editing Memory in a Transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15j8zs2/microsofts_ai_watched_100000000_youtube_videos/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15j8zs2/microsofts_ai_watched_100000000_youtube_videos/",
          "publishedOn": "2023-08-05T22:38:11.000Z",
          "wordCount": 2432,
          "title": "Microsoft’s AI Watched 100,000,000 Youtube Videos! text input to video and sound",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15iggk9/best_books_to_learn_neural_networks_in_2023_for/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15iggk9/best_books_to_learn_neural_networks_in_2023_for/",
          "publishedOn": "2023-08-05T00:09:23.000Z",
          "wordCount": 2445,
          "title": "Best Books to Learn Neural Networks in 2023 for Beginners to advanced",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15hjynt/what_would_be_the_initial_costs_of_developing_a/",
          "author": null,
          "description": "I was wondering if this would be super expensive or not.\n The cost to develop GPT-3 was about $4 millions according to some resources online. \n Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?\n Any answer is appreciated.\n Thanks in advance.\n    submitted by    /u/Claud1ao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15hjynt/what_would_be_the_initial_costs_of_developing_a/",
          "publishedOn": "2023-08-03T23:42:57.000Z",
          "wordCount": 2510,
          "title": "What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15hikwk/creating_point_cloud_videos_from_arbitrary_rgb/",
          "author": null,
          "description": "submitted by    /u/berkanzzzz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15hikwk/creating_point_cloud_videos_from_arbitrary_rgb/",
          "publishedOn": "2023-08-03T22:45:05.000Z",
          "wordCount": 2428,
          "title": "Creating point cloud videos from arbitrary RGB videos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15h7r9c/what_source_would_you_recommend_a_15yo_to_learn/",
          "author": null,
          "description": "It's been years i've always been interested in AI. i tried to follow a few videos on yt. The best resource i could find was the \"Neural Networks from scratch\" YouTube playlist. But sadly, it interrupts in the middle, and i don't think it will ever be continued. I have programming knowledge, i made a bunch of very small project in python, and currently it's the language i'm most comfortable with. I lack of math knowledge, i struggle with calculus since i never studied it at school, the furthest i got with school was first degree equations.\n by myself i studied some math i didnt do in school, but i still suck at math. I wonder if i can start now or i should wait to study calculus at school. anyway, i'd love to get linked to a source for me to learn NNs from scratch.\n    submitted by    /u/Jealous-Bad1742  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15h7r9c/what_source_would_you_recommend_a_15yo_to_learn/",
          "publishedOn": "2023-08-03T15:44:23.000Z",
          "wordCount": 2584,
          "title": "what source would you recommend a 15yo to learn how to make a simple neural network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15h6t8g/seeking_suggestions_for_exciting_and_intriguing/",
          "author": null,
          "description": "Hey everyone, I'm in my final year of B.Tech, majoring in data science. Currently, I'm facing some challenges in choosing a topic for my capstone project. Lately, I've been really intrigued by graph databases and have been diving into learning Neo4j. I'm specifically interested in finding project ideas that allow me to combine machine learning, particularly neural networks, with graph databases. During my research, I came across GNNs (Graph Neural Networks) and PINNS (Physics-Informed Neural Networks). I'm eager to hear any suggestions for unique project topics that instantly spark curiosity just by their title. Feel free to share any ideas or topics; I welcome all suggestions. Thanks in advance! \n    submitted by    /u/EmergencyAside6551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15h6t8g/seeking_suggestions_for_exciting_and_intriguing/",
          "publishedOn": "2023-08-03T15:07:44.000Z",
          "wordCount": 2540,
          "title": "Seeking suggestions for exciting and intriguing capstone project ideas.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15h3o19/devar_a_technology_company_is_getting_ready_to/",
          "author": null,
          "description": "submitted by    /u/Tycoonstory2020  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15h3o19/devar_a_technology_company_is_getting_ready_to/",
          "publishedOn": "2023-08-03T13:02:21.000Z",
          "wordCount": 2451,
          "title": "Devar, a technology company, is getting ready to deploy the world's first generative AI neural network for augmented reality (AR).",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15gpas3/audiocraft_a_simple_onestop_shop_for_audio/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15gpas3/audiocraft_a_simple_onestop_shop_for_audio/",
          "publishedOn": "2023-08-03T00:44:57.000Z",
          "wordCount": 2441,
          "title": "AudioCraft: A simple one-stop shop for audio modeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15gaxgt/human_brain_models_literature_review_of_the/",
          "author": null,
          "description": "submitted by    /u/No-Platypus4021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15gaxgt/human_brain_models_literature_review_of_the/",
          "publishedOn": "2023-08-02T14:50:38.000Z",
          "wordCount": 2432,
          "title": "Human Brain Models (Literature Review of the Latest BNN and SNN Endeavors)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15f92j6/tfjs_format_vs_tflite/",
          "author": null,
          "description": "After analyzing 15,000 samples in the dataset, we noticed that increasing the number of images doesn't significantly improve the scoreboard recognition quality for our neural network.\n However, what's more interesting is how the network performs in different formats. When deployed in TFJS format on a website , it often behaves strangely, detecting objects where there are none. On the other hand, in TFLite format, such failures are almost non-existent.\n If you access the link on your mobile phone and grant camera permission, you'll witness the neural network (in TFJS format) attempting to find objects even when there are none.\n https://preview.redd.it/gosobymachfb1.jpg?width=585&format=pjpg&auto=webp&s=e7cb8e8e3ff49e39715009c4940d9769a1db39ab\n    submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15f92j6/tfjs_format_vs_tflite/",
          "publishedOn": "2023-08-01T10:51:49.000Z",
          "wordCount": 2521,
          "title": "TFJS Format vs. TFLite",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ec6vo/interview_with_hikaru_shindo_and_quentin_delfosse/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ec6vo/interview_with_hikaru_shindo_and_quentin_delfosse/",
          "publishedOn": "2023-07-31T10:20:23.000Z",
          "wordCount": 2425,
          "title": "Interview with Hikaru Shindo and Quentin Delfosse: Neurosymbolic Reinfor...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15djfn2/what_are_some_of_the_best_architectures_to_solve/",
          "author": null,
          "description": "Hi Guys,\n I am working on a nn model, which can help automate the building of APIs. The problem is, we are moving data in which, there are thousands of fields, however, the fields between systems are similar in nature. This to me seems like an easy classification problem, however it doesn't scale the best.\n ​\n In terms of the data I have, if I have a dataset of 10 systems, there are not enough examples for each class for the model to train well. That is with a simple classifier where every field is a class.\n ​\n I was also thinking of using a Siamese model, where I compare the similarity between them, which allows me to use my more limited dataset more effectively\n ​\n I was wondering if there are any more architectures you guys think I should consider, or will be helpful in solving my problem\n ​\n Thank you for your help!\n    submitted by    /u/eatlantis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15djfn2/what_are_some_of_the_best_architectures_to_solve/",
          "publishedOn": "2023-07-30T11:35:16.000Z",
          "wordCount": 2608,
          "title": "What are some of the best architectures to solve this problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15d4q2r/what_are_receptive_fields_and_how_do_they_effect/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15d4q2r/what_are_receptive_fields_and_how_do_they_effect/",
          "publishedOn": "2023-07-29T22:22:52.000Z",
          "wordCount": 2455,
          "title": "What are Receptive Fields and How Do They Effect Your Model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15cxj5s/researchers_discover_new_vulnerability_in_large/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15cxj5s/researchers_discover_new_vulnerability_in_large/",
          "publishedOn": "2023-07-29T17:15:14.000Z",
          "wordCount": 2454,
          "title": "Researchers Discover New Vulnerability in Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15cxid7/gzip_beats_bert_part_2_dataset_issues_improved/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15cxid7/gzip_beats_bert_part_2_dataset_issues_improved/",
          "publishedOn": "2023-07-29T17:14:16.000Z",
          "wordCount": 2457,
          "title": "\"Gzip beats BERT?\" Part 2: dataset issues, improved speed, and results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15comhm/detection_transformer_detr_explained/",
          "author": null,
          "description": "submitted by    /u/Personal-Trainer-541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15comhm/detection_transformer_detr_explained/",
          "publishedOn": "2023-07-29T10:10:46.000Z",
          "wordCount": 2448,
          "title": "Detection Transformer (DETR) Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15c45w3/deepminds_rt2_new_model_translates_vision_and/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15c45w3/deepminds_rt2_new_model_translates_vision_and/",
          "publishedOn": "2023-07-28T17:47:10.000Z",
          "wordCount": 2467,
          "title": "Deepmind's RT-2: New model translates vision and language into action",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15bkm5l/llama_and_chatgpt_are_not_opensource/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15bkm5l/llama_and_chatgpt_are_not_opensource/",
          "publishedOn": "2023-07-28T02:14:19.000Z",
          "wordCount": 2463,
          "title": "LLAMA and ChatGPT Are Not Open-Source",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15bfolm/max_min_values_for_weights_and_biases/",
          "author": null,
          "description": "I was wondering what the recommended maximum and minimum values for weights and biases are for random generation of networks and mutation\n    submitted by    /u/Mildu12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15bfolm/max_min_values_for_weights_and_biases/",
          "publishedOn": "2023-07-27T22:32:32.000Z",
          "wordCount": 2476,
          "title": "Max / min values for weights and biases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15b4uns/what_exactly_are_liquid_neurons/",
          "author": null,
          "description": "I heard about them recently. Can someone give me the basics, and maybe point me to a couple of papers?\n    submitted by    /u/SamuraiGoblin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15b4uns/what_exactly_are_liquid_neurons/",
          "publishedOn": "2023-07-27T15:28:09.000Z",
          "wordCount": 2471,
          "title": "What exactly are liquid neurons?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15awr7k/diving_into_image_dataset_preparation_for_object/",
          "author": null,
          "description": "submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15awr7k/diving_into_image_dataset_preparation_for_object/",
          "publishedOn": "2023-07-27T09:07:01.000Z",
          "wordCount": 2467,
          "title": "Diving Into Image Dataset Preparation for Object Detection in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15a4ygg/trouble_setting_up_neural_network/",
          "author": null,
          "description": "Hi there,\n I'm struggling a bit to set up a neural network with the data I've collected. These are some of the errors I'm getting. Any tips or help to fix it please? \n https://preview.redd.it/88ihxg1p2beb1.png?width=2231&format=png&auto=webp&s=acdd66a1c465d1d1a9d202605d451564c464fd22\n https://preview.redd.it/7ro6782n2beb1.png?width=2076&format=png&auto=webp&s=775778ef52b01caf331d3e0f542603626cea7888\n    submitted by    /u/LesgoLeggo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15a4ygg/trouble_setting_up_neural_network/",
          "publishedOn": "2023-07-26T12:48:23.000Z",
          "wordCount": 2484,
          "title": "Trouble setting up Neural Network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/158n424/attention_is_off_by_one/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/158n424/attention_is_off_by_one/",
          "publishedOn": "2023-07-24T21:06:58.000Z",
          "wordCount": 2462,
          "title": "Attention Is Off By One",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/158mjhq/metatransformer_a_unified_framework_for/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/158mjhq/metatransformer_a_unified_framework_for/",
          "publishedOn": "2023-07-24T20:46:10.000Z",
          "wordCount": 2453,
          "title": "Meta-Transformer: A Unified Framework for Multimodal Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/158mdhs/all_neural_network_output_activations_converging/",
          "author": null,
          "description": "I'm facing a puzzling problem with my neural network, and I could really use some help in understanding what's going wrong. For some context, I am making a neural network from scratch in C++, just as a little project I find interesting. I'm working on a digit classification task using the MNIST dataset, and my network is composed of one hidden layer, consisting of 100 nodes, and an output layer with 10 nodes, each corresponding to a digit (0 to 9). To train the network, I'm using the Mean Squared Error (MSE) cost function, where the cost is calculated as (actualNodeActivation - expectedNodeActivation)^2 and as my activation function I am using the sigmoid function. The actual algorithm I am employing is backpropagation.\n The issue I'm encountering is that regardless of the input data, my n…",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/158mdhs/all_neural_network_output_activations_converging/",
          "publishedOn": "2023-07-24T20:40:02.000Z",
          "wordCount": 3125,
          "title": "All neural network output activations converging to the same value regardless of input",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15848wp/nerf_creating_photorealistic_images_using_neural/",
          "author": null,
          "description": "​\n https://preview.redd.it/1gqd6tt1gvdb1.jpg?width=2800&format=pjpg&auto=webp&s=d21e9e5d0854022b8f25d9a6cb77e67b98487f40\n You can find in interesting. OpenCV.ai team published the post about NeRF.\n Short description:\n NeRF is an innovative technology that generates photorealistic images of scenes from novel viewpoints using a neural network and volume rendering techniques. This article explores NeRF components, training, strengths and limitations, and advancements in modern NeRF-based solutions.\n More details are here.\n    submitted by    /u/No-Independence5880  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15848wp/nerf_creating_photorealistic_images_using_neural/",
          "publishedOn": "2023-07-24T08:14:08.000Z",
          "wordCount": 2505,
          "title": "NeRF: Creating photorealistic images using Neural Network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1582l7v/zbrain_create_custom_chatgpt_apps/",
          "author": null,
          "description": "Hello Community,\n We at ZBrain have built a platform to create ChatGPT-like apps with your private data, you can import your data from multiple sources and DBs and integrate the app into any of your workflows.\n We have also added AI risk governance to mitigate the confidential data leak and now working on Flow a no-code tool to give you the freedom to create your own business logic.\n You can try the tool now at https://zbrain.ai/. We would love to hear your thoughts and feedback to improve the tool.\n    submitted by    /u/StewartBJasper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1582l7v/zbrain_create_custom_chatgpt_apps/",
          "publishedOn": "2023-07-24T06:42:48.000Z",
          "wordCount": 2540,
          "title": "ZBrain- Create custom ChatGPT apps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/157iwb3/book_preview_neuro_symbolic_reasoning_and_learning/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/157iwb3/book_preview_neuro_symbolic_reasoning_and_learning/",
          "publishedOn": "2023-07-23T16:15:44.000Z",
          "wordCount": 2451,
          "title": "Book Preview: Neuro Symbolic Reasoning and Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/156zjjh/meme_review_by_ai_bing_gets_humorous/",
          "author": null,
          "description": "submitted by    /u/Small_Championship_2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/156zjjh/meme_review_by_ai_bing_gets_humorous/",
          "publishedOn": "2023-07-23T00:05:10.000Z",
          "wordCount": 2451,
          "title": "Meme Review By AI: Bing Gets Humorous",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": []
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI Blog",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/blog",
      "articles": [
        {
          "id": "https://openai.com/research/confidence-building-measures-for-artificial-intelligence",
          "author": null,
          "description": "",
          "link": "https://openai.com/research/confidence-building-measures-for-artificial-intelligence",
          "publishedOn": "2023-08-01T07:00:00.000Z",
          "wordCount": 514,
          "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
          "imageUrl": "https://images.openai.com/blob/169a9863-5725-45cf-b096-6d2e5b6cebe9/confidence-building-measures-for-artificial-intelligence-workshop-proceedings.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/frontier-model-forum",
          "author": null,
          "description": "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
          "link": "https://openai.com/blog/frontier-model-forum",
          "publishedOn": "2023-07-26T07:00:00.000Z",
          "wordCount": 1185,
          "title": "Frontier Model Forum",
          "imageUrl": "https://images.openai.com/blob/53756fcf-bcdd-48ea-ada5-33dee6bb4494/frontier-model-forum.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/moving-ai-governance-forward",
          "author": null,
          "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
          "link": "https://openai.com/blog/moving-ai-governance-forward",
          "publishedOn": "2023-07-21T07:00:00.000Z",
          "wordCount": 1464,
          "title": "Moving AI governance forward",
          "imageUrl": "https://images.openai.com/blob/80031713-8f42-4321-b792-dff331074949/moving-ai-governance-forward.jpg?trim=231%2C0%2C217%2C0"
        },
        {
          "id": "https://openai.com/blog/custom-instructions-for-chatgpt",
          "author": null,
          "description": "We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
          "link": "https://openai.com/blog/custom-instructions-for-chatgpt",
          "publishedOn": "2023-07-20T07:00:00.000Z",
          "wordCount": 1937,
          "title": "Custom instructions for ChatGPT",
          "imageUrl": "https://images.openai.com/blob/71bddfc7-a5ca-4c77-9b3d-96659356640c/custom-instructions-for-chatgpt.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
          "author": null,
          "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
          "link": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
          "publishedOn": "2023-07-18T07:00:00.000Z",
          "wordCount": 985,
          "title": "Partnership with American Journalism Project to support local news",
          "imageUrl": "https://images.openai.com/blob/fd058dd7-4501-4eec-ab78-a86ad57ffb11/partnership-with-american-journalism-project-to-support-local-news.png?trim=0%2C80%2C0%2C110"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research/",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=962121",
          "author": "Alyssa Hughes",
          "description": "Microsoft Health Futures’ Javier Alvarez & oncologist Raj Jena have been collaborating for years on AI-assisted medical imaging. Today, their work is seeing real-world impact, helping doctors accelerate cancer patients’ access to treatment.\nThe post Collaborators: Project InnerEye with Javier Alvarez and Raj Jena appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/collaborators-project-innereye-with-javier-alvarez-and-raj-jena/",
          "publishedOn": "2023-08-17T13:18:40.000Z",
          "wordCount": 9253,
          "title": "Collaborators: Project InnerEye with Javier Alvarez and Raj Jena",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/raj-javier-collaborators-tw-li-fb-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=962358",
          "author": "Alyssa Hughes",
          "description": "In this issue: HyWay enables hybrid mingling; Auto-Tables transforms non-relational tables into standard relational forms; training dense retrievers to identify high-quality in-context examples for LLM; improving pronunciation assessment in CAPT.\nThe post Research Focus: Week of August 14, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-14-2023/",
          "publishedOn": "2023-08-16T16:00:00.000Z",
          "wordCount": 3070,
          "title": "Research Focus: Week of August 14, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF22-blog-social-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=959091",
          "author": "Brenda Potts",
          "description": "This content was given as a keynote at the Workshop of Applied Data Science for Healthcare and covered during a tutorial at the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, a premier forum for advancement, education, and adoption of the discipline of knowledge discovering and data mining. Recent and noteworthy advancements in […]\nThe post Microsoft at KDD 2023: Advancing health at the speed of AI appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-kdd-2023-advancing-health-at-the-speed-of-ai/",
          "publishedOn": "2023-08-10T16:00:00.000Z",
          "wordCount": 3583,
          "title": "Microsoft at KDD 2023: Advancing health at the speed of AI",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/KDD23-TWLIFB-1200x627-no-logo.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=958119",
          "author": "Alyssa Hughes",
          "description": "Researcher Jina Suh and manager Shamsi Iqbal are longtime collaborators. Learn how their history of working together and their unique perspectives are informing their development of tools to support decision-making for organizational leaders.\nThe post Collaborators: Data-driven decision-making with Jina Suh and Shamsi Iqbal appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/collaborators-data-driven-decision-making-with-jina-suh-and-shamsi-iqbal/",
          "publishedOn": "2023-08-03T13:00:00.000Z",
          "wordCount": 9706,
          "title": "Collaborators: Data-driven decision-making with Jina Suh and Shamsi Iqbal",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/jina-shamsi-collaborators-tw-li-fb-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=957600",
          "author": "Alyssa Hughes",
          "description": "In this edition: A new anonymous token protocol balances fraud detection and privacy; survival instinct in offline RL; Nimble offers rollback protection for confidential cloud services; improved machine learning force fields for molecular dynamics.\nThe post Research Focus: Week of July 31, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-july-31-2023/",
          "publishedOn": "2023-08-02T16:00:00.000Z",
          "wordCount": 3177,
          "title": "Research Focus: Week of July 31, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/RF21-blog-social-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=956640",
          "author": "Alyssa Hughes",
          "description": "Managing server failures at the scale of a cloud platform is challenging. The Hyrax fail-in-place approach reduces the need for immediate repairs and creates a path toward lowering water consumption and carbon emissions in cloud datacenters. \nThe post A fail-in-place approach for sustainable server operations appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/a-fail-in-place-approach-for-sustainable-server-operations/",
          "publishedOn": "2023-07-27T16:00:00.000Z",
          "wordCount": 3540,
          "title": "A fail-in-place approach for sustainable server operations",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/OSDI23-TWLIFB-1200x627-1.jpg"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://ai.googleblog.com/",
      "articles": [
        {
          "id": "http://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html",
          "author": null,
          "description": "Posted by Ziniu Hu, Student Researcher, and Alireza Fathi, Research Scientist, Google Research, Perception Team\n\n\n\n\nThere has been great progress towards adapting large language models (LLMs) to accommodate multimodal inputs for tasks including image captioning, visual question answering (VQA), and open vocabulary recognition. Despite such achievements, current state-of-the-art visual language models (VLMs) perform inadequately on visual information seeking datasets, such as Infoseek and OK-VQA, where external knowledge is required to answer the questions. \n \n\n\n\n\n\n\nExamples of visual information seeking queries where external knowledge is required to answer the question. Images are taken from the OK-VQA dataset.\n\nAVIS: Autonomous Visual Information Seeking with Large Language Models”, we i…",
          "link": "http://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html",
          "publishedOn": "2023-08-18T18:28:00.004Z",
          "wordCount": 27660,
          "title": "Autonomous visual information seeking with large language models",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEje4SF07XPWF1tjYompjrnyrqMXDjqkeotbgVq0mMaGL6fuTPtw45P0TewFTemIVW8KBVCDdWtMS89gLqNpbDNjwWRg8WlvzzkhBGBOWmM1SUFzF5vkoFiiaIylBb2jZELcM4HDYqYoAmK4eYzrvfCHgAASKIZY1kVGcL9ORQXF4Qdfo32mA8Z4bh8smHNA/w1200-h630-p-k-no-nu/AVIS.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/neural-network-pruning-with.html",
          "author": null,
          "description": "Posted by Hussein Hazimeh, Research Scientist, Athena Team, and Riade Benbaki, Graduate Student at MIT\n\n\n\n\n\nModern neural networks have achieved impressive performance across a variety of applications, such as language, mathematical reasoning, and vision. However, these networks often use large architectures that require lots of computational resources. This can make it impractical to serve such models to users, especially in resource-constrained environments like wearables and smartphones. A widely used approach to mitigate the inference costs of pre-trained networks is to prune them by removing some of their weights, in a way that doesn’t significantly affect utility. In standard neural networks, each weight defines a connection between two neurons. So after weights are pruned, the input…",
          "link": "http://ai.googleblog.com/2023/08/neural-network-pruning-with.html",
          "publishedOn": "2023-08-17T18:08:00.000Z",
          "wordCount": 27758,
          "title": "Neural network pruning with combinatorial optimization",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgyU4esZL0DIoU6gbv90zR7Fw-r8Jm9DhLix7eBHMwp50c_3l1pP0myByQ4fSPidsrfhMrOxS2hQxLJuQ4d5DVJP3n5hAocfJeAWQDNjcvrU679bnFYcww0qcNWNzr3SEEcOQqG8owJmNxIWIrqJq_6ReXBJ9PUK-tW1ou0j73P3grgASIrfudrTyjyHu5K/w1200-h630-p-k-no-nu/CHITA%20hero.gif"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/study-socially-aware-temporally-causal.html",
          "author": null,
          "description": "Posted by Eltayeb Ahmed, Research Engineer, and Subhrajit Roy, Senior Research Scientist, Google Research\n\n\n\n\nReading has many benefits for young students, such as better linguistic and life skills, and reading for pleasure has been shown to correlate with academic success. Furthermore students have reported improved emotional wellbeing from reading, as well as better general knowledge and better understanding of other cultures. With the vast amount of reading material both online and off, finding age-appropriate, relevant and engaging content can be a challenging task, but helping students do so is a necessary step to engage them in reading. Effective recommendations that present students with relevant reading material helps keep students reading, and this is where machine learning (ML) c…",
          "link": "http://ai.googleblog.com/2023/08/study-socially-aware-temporally-causal.html",
          "publishedOn": "2023-08-15T19:59:00.001Z",
          "wordCount": 28224,
          "title": "STUDY: Socially aware temporally causal decoder recommender systems",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhtKv9JocvNhtzu5Cxb5h_vVAz4y-OOQJ9YRj8gmvLlt-PLgnxqXM5KytIsUWkdtHtEvqmTvyiUqOqaJM1R4096YBLtUYQmv2nEQR0CMZvPc2ccfCIriJFGVCp94fe24etHhZrZh4JtzAV6GpumD657Q3qqPinhVpJ1Zn3UqJPE7BDa8GxE9h8CqAx8AO1_/w1200-h630-p-k-no-nu/study-hero.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/advances-in-document-understanding.html",
          "author": null,
          "description": "Posted by Sandeep Tata, Software Engineer, Google Research, Athena Team\n\n\n\n\nThe last few years have seen rapid progress in systems that can automatically process complex business documents and turn them into structured objects. A system that can automatically extract data from documents, e.g., receipts, insurance quotes, and financial statements, has the potential to dramatically improve the efficiency of business workflows by avoiding error-prone, manual work. Recent models, based on the Transformer architecture, have shown impressive gains in accuracy. Larger models, such as PaLM 2, are also being leveraged to further streamline these business workflows. However, the datasets used in academic literature fail to capture the challenges seen in real-world use cases. Consequently, academic b…",
          "link": "http://ai.googleblog.com/2023/08/advances-in-document-understanding.html",
          "publishedOn": "2023-08-09T18:32:00.001Z",
          "wordCount": 27825,
          "title": "Advances in document understanding",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi-Zs3cysjsJQsPfOZML1cR03gCO18NmC-KMsoQtctvWr7v_bwJ6MmQMXesUafsi7w53SY50YZOtnBdpAcBaplHXOPV8P1-X9deoXISeAfq85zUbcPXUOCPJSTsaIanCEIWUUkBNXE9JTU6q3OIgMZi5JqykbiN1x36LR78x4jEka2pL5MBjTdMr_Sn3FNv/w1200-h630-p-k-no-nu/Document%20understanding%20hero.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/adatape-foundation-model-with-adaptive.html",
          "author": null,
          "description": "Posted by Fuzhao Xue, Research Intern, and Mostafa Dehghani, Research Scientist, Google\n\n\n\n\n\n\n\nAdaptive computation refers to the ability of a machine learning system to adjust its behavior in response to changes in the environment. While conventional neural networks have a fixed function and computation capacity, i.e., they spend the same number of FLOPs for processing different inputs, a model with adaptive and dynamic computation modulates the computational budget it dedicates to processing each input, depending on the complexity of the input.\n\n\nAdaptive computation in neural networks is appealing for two key reasons. First, the mechanism that introduces adaptivity provides an inductive bias that can play a key role in solving some challenging tasks. For instance, enabling different num…",
          "link": "http://ai.googleblog.com/2023/08/adatape-foundation-model-with-adaptive.html",
          "publishedOn": "2023-08-08T21:02:00.000Z",
          "wordCount": 27871,
          "title": "AdaTape: Foundation model with adaptive computation and dynamic read-and-write",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjlzhnBmcyTQ940NZQduhyS5G17r9FghwVjYOPW2Ly0pRzug9DdZ7p02z1iK1g9b93xIqJhdQrg5XVmlcUQqUcSOwQXOGSm6lhcScopZX5J3OTxIsThxmAudIEpkrshjAhipDV4VKFL7Vv1r0Qad77VSiH7rGUD9-E5Jgg1HnzmSkIBt24rd3j1rPN2Ee2N/w1200-h630-p-k-no-nu/adatape.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/multimodal-medical-ai.html",
          "author": null,
          "description": "Posted by Greg Corrado, Head of Health AI, Google Research, and Yossi Matias, VP, Engineering and Research, Google Research\n\n\n\n\n\n\nMedicine is an inherently multimodal discipline. When providing care, clinicians routinely interpret data from a wide range of modalities including medical images, clinical notes, lab tests, electronic health records, genomics, and more.  Over the last decade or so, AI systems have achieved expert-level performance on specific tasks within specific modalities — some AI systems processing CT scans, while others analyzing high magnification pathology slides, and still others hunting for rare genetic variations. The inputs to these systems tend to be complex data such as images, and they typically provide structured outputs, whether in the form of discrete grades o…",
          "link": "http://ai.googleblog.com/2023/08/multimodal-medical-ai.html",
          "publishedOn": "2023-08-03T18:24:00.001Z",
          "wordCount": 27719,
          "title": "Multimodal medical AI",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhU2ypPfvmlgGQW4yp3EbUlJ4rLlIukRC9TDstIe7RV5JTxMo-THDgKPhFYbBUV4m0vKVjmG9lDTBWdy5kH_bR3-tqN8KzdhgmrLL_N2e_glc0WG-HkSm5Nouk7-MU65hu0RH5QWP0nHFNcZpERq9_agfaMqtHjhChbu_dPvWsJfZ8DsxZWnx15hogprRb3/w1200-h630-p-k-no-nu/medpalm.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/in-search-of-generalizable-method-for.html",
          "author": null,
          "description": "Posted by Eleni Triantafillou, Research Scientist, and Malik Boudiaf, Student Researcher, Google \n\n\n\n\n\n\n\n\n\nDeep learning has recently made tremendous progress in a wide range of problems and applications, but models often fail unpredictably when deployed in unseen domains or distributions. Source-free domain adaptation (SFDA) is an area of research that aims to design methods for adapting a pre-trained model (trained on a “source domain”) to a new “target domain”, using only unlabeled data from the latter. \n \n\nDesigning adaptation methods for deep models is an important area of research. While the increasing scale of models and training datasets has been a key ingredient to their success, a negative consequence of this trend is that training such models is increasingly computationally expe…",
          "link": "http://ai.googleblog.com/2023/07/in-search-of-generalizable-method-for.html",
          "publishedOn": "2023-07-26T16:33:00.002Z",
          "wordCount": 27928,
          "title": "In search of a generalizable method for source-free domain adaptation",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnKLO5myVKCSpTQa17lSR3Jj3i3D5Ll87Me9l6CHJ4eyQe_1feJitNR6CYsDURNb7OobVrh3MRU49C4epC-kkkEL7-kgiJ4MXEIvlxIxc8G7NXZxjzjgyM4nY06lQWVIGEL2yoKnK_mR9P8UyK5T_4b1pnQPOnjW2fhJVYgQkVTk7gxthW-n5WwKDdgmiA/w1200-h630-p-k-no-nu/notela.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/google-at-icml-2023.html",
          "author": null,
          "description": "Posted by Cat Armato, Program Manager, Google\n\n\n\n\nGroups across Google actively pursue research in the field of machine learning (ML), ranging from theory and application. We build ML systems to solve deep scientific and engineering challenges in areas of language, music, visual processing, algorithm development, and more. We aim to build a more collaborative ecosystem with the broader ML research community through open-sourcing tools and datasets, publishing our work, and actively participating in conferences.\n\n\n\nGoogle is proud to be a Diamond Sponsor of the 40th International Conference on Machine Learning (ICML 2023), a premier annual conference, which is being held this week in Honolulu, Hawaii. As a leader in ML research, Google has a strong presence at this year’s conference with ov…",
          "link": "http://ai.googleblog.com/2023/07/google-at-icml-2023.html",
          "publishedOn": "2023-07-23T21:13:00.000Z",
          "wordCount": 29329,
          "title": "Google at ICML 2023",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFdIolpEmmBVh-IZFfIHWjpGm5M-7N6hhQ4yBUFTBWZfQ_Wa4Reyz-YmsST7TbfiloQVKIlCaPhJgLj1nhzPr3JesD4nvXkj-FzGykvtGM7oe4MVV_Fidc0q6FuqvHXa8hrMj36TNRn_oP2_42lTJmWl3mGmaCNvqi5IQBx5PCfHKnpegwX-cVf4r3LUkU/w1200-h630-p-k-no-nu/Google-ICML-hero.jpg"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "https://www.fast.ai/atom.xml",
      "articles": [
        {
          "id": "https://www.fast.ai/2022/09/06/homeschooling/",
          "author": null,
          "description": "My husband Jeremy and I never intended to homeschool, and yet we have now, unexpectedly, committed to homeschooling long-term. Prior to the pandemic, we both worked full-time in careers that we loved and found meaningful, and we sent our daughter to a full-day Montessori school. Although I struggled with significant health issues, I felt unbelievably lucky and fulfilled in both my family life and my professional life. The pandemic upended my careful balance. Every family is different, with different needs, circumstances, and constraints, and what works for one may not work for others. My intention here is primarily to share the journey of my own (very privileged) family.\n\n  \n\n\nOur unplanned introduction to homeschooling\nFor the first year of the pandemic, most schools in California, where …",
          "link": "https://www.fast.ai/2022/09/06/homeschooling/",
          "publishedOn": "2022-09-05T14:00:00.000Z",
          "wordCount": 2118,
          "title": "My family's unlikely homeschooling journey",
          "imageUrl": null
        },
        {
          "id": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "author": null,
          "description": "Jupyter notebooks don’t work with git by default. With nbdev2, the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter.\nContents\nThe Jupyter+git problem\nThe solution    \nThe nbdev2 git merge driver\nThe nbdev2 Jupyter save hook\nBackground\nThe result\nPostscript: other Jupyter+git tools    \nReviewNB\nAn alternative solution: Jupytext\nnbdime\nThe Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interact…",
          "link": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "publishedOn": "2022-08-24T14:00:00.000Z",
          "wordCount": 2227,
          "title": "The Jupyter+git problem is now solved",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15wpvim/what_computing_resources_are_required_for/",
          "author": null,
          "description": "I have access to an University cluster, that provides GPUs/CPUs, etc. Unfortunately, I am not very well versed with Computer Architecture. I am trying to understand what resources should I request to increase the number of parallel workers while using Gymnasium by Farama Foundation. If I naively try to maximize the number of workers, the wall clock time taken by the algorithm becomes quite large. I suspect in this case, the workers are being executed serially instead of in parallel. \n ​\n This is how I execute parallel environments - \n env = gym.vector.make(\"CarRacing-v2\",num_envs = num_envs, wrappers=GrayScaleObservation) \n I initially thought that setting `num_envs` to the number of cores in my machine may be a good idea. But that slows things down - \n import multiprocessing num_envs = multiprocessing.cpu_count() \n ​\n ​\n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15wpvim/what_computing_resources_are_required_for/",
          "publishedOn": "2023-08-20T23:00:48.000Z",
          "wordCount": null,
          "title": "What computing resources are required for vectorized environments in Gymnasium",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15widy3/need_some_serious_help_with_system_delays_system/",
          "author": null,
          "description": "Hi!\n I have an environment which has some delay mechanism, which means it takes some time to see the input in the output. You can think of ovens as an example, even if we set the oven temperature to 300 celcius degrees directly, it takes time for the measured temperature to reach 300 celcius. Same applies to my problem.\n When I give acceleration as an input to the environment and get the reward as an acceleration itself, my Q-Learning algorithm solves the problem because no system delay included.\n When I give acceleration as an input to the environment and get the reward as an system response to the action, my Q-Learning algorithm cannot solve the problem.\n The Examples Illustrated With Schema \n Upperside is Action and Lower Side is Reward - Delay Mechanism is Applied - You can see that some time is needed to reach the given action input\n Upperside is Action and Lower Side is Reward - Even though Q-Learning tries different actions, reward stays near 0, this prevents learning.\n When you look at the red line, Epsilon-Greedy Algorithm takes random actions at the beginning. When this is the case, reward line has mean of 0, because actions are changing too fast and system response cannot start to settle for specific value.\n To be able to settle for specific value, lets say + 20, it should be given +20 \"consecutively\". If I continue giving random values, it cannot settle for specific value, it just stays near 0.\n As a result, even though I try a lot of different actions, learning cannot take place because the reward is always 0.\n I am lost and I do not know how to tackle this problem.\n I really need your valuable feedbacks.\n Thank you!\n ​\n ​\n    submitted by    /u/OpenToAdvices96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15widy3/need_some_serious_help_with_system_delays_system/",
          "publishedOn": "2023-08-20T18:07:40.000Z",
          "wordCount": null,
          "title": "Need Some Serious Help With System Delays. System Delay Ruins Learning - Stuck for 1 month :(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15vnat3/migrating_from_sb3_to_rllib_getting_started_with/",
          "author": null,
          "description": "Hi! I want to migrate my research from SB3 to RLLib because of the better suitability for MARL. \n The environment is based on Gym, so that part has been pretty doable. \n However, I haven't had the best time with training agents and the documentation. Does anyone know of some kind of quick start/ summary that outlines the architecture and gives some good examples for RLLib?\n    submitted by    /u/tessherelurkingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15vnat3/migrating_from_sb3_to_rllib_getting_started_with/",
          "publishedOn": "2023-08-19T18:14:51.000Z",
          "wordCount": 2652,
          "title": "Migrating from SB3 to RLLib/ Getting started with RLLib",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15vhfh5/sb3_attributeerror_dummyvecenv_object_has_no/",
          "author": null,
          "description": "When I try to combine the SB3 vec_env with AtariWrapper, I get an error -\n import gymnasium as gym from stable_baselines3 import PPO from stable_baselines3.common.env_util import make_vec_env from stable_baselines3.common.atari_wrappers import AtariWrapper # Parallel environments # vec_env = gym.make(\"PongNoFrameskip-v4\") vec_env = make_vec_env(\"PongNoFrameskip-v4\", n_envs=2, seed=3) vec_env = AtariWrapper(vec_env) model = PPO(\"CnnPolicy\", vec_env, verbose=1, n_steps=128, n_epochs=4, batch_size=256, learning_rate=2.5e-4, clip_range=0.1, vf_coef=0.5, ent_coef=0.01) model.learn(total_timesteps=1e7) model.save(\"ppo_cartpole\") \n I get this error -\n A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7) [Powered by Stella] Traceback (most recent call last): File \"D:\\q_learning\\sb3_ppo.py\", line 10, in <module> vec_env = AtariWrapper(vec_env) File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py\", line 294, in __init__ env = NoopResetEnv(env, noop_max=noop_max) File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py\", line 57, in __init__ assert env.unwrapped.get_action_meanings()[0] == \"NOOP\" # type: ignore[attr-defined] AttributeError: 'DummyVecEnv' object has no attribute 'get_action_meanings' Process finished with exit code 1 \n However, I don't get an error if I use the AtariWrapperwith a gymnasium environment -\n vec_env = gym.make(\"PongNoFrameskip-v4\") # vec_env = make_vec_env(\"PongNoFrameskip-v4\", n_envs=2, seed=3) vec_env = AtariWrapper(vec_env) model = PPO(\"CnnPolicy\", vec_env, verbose=1, n_steps=128, n_epochs=4, batch_size=256, learning_rate=2.5e-4, clip_range=0.1, vf_coef=0.5, ent_coef=0.01) model.learn(total_timesteps=1e7) model.save(\"ppo_cartpole\") \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15vhfh5/sb3_attributeerror_dummyvecenv_object_has_no/",
          "publishedOn": "2023-08-19T14:15:44.000Z",
          "wordCount": 2752,
          "title": "SB3 - AttributeError: 'DummyVecEnv' object has no attribute 'get_action_meanings'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15vfm1u/efficient_screenshots_rythm_game_ai/",
          "author": null,
          "description": "So I am trying to implement an agent that plays osu. It takes in a low resolution gray-scale image of the game and then outputs the coordinates of where it should go and also if it should click or not. I might change the actions a bit so that the movement is smooth directly from the agent. Now I’m planning on doing the training on osu directly. To get the rewards I’m planning on using something to read the memory. I’m pretty sure cheat engine can be used for that. I should also be able to speed up osu or osu lazer with the cheat engine. Now my current issue is that I don’t know how to take screenshots efficiently. Or more specifically, how to feed in data from the screen. I heard mss should be good but if you have any other ideas please tell me. Note that I will use the cheat engine only for the training part.\n    submitted by    /u/SlickVandel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15vfm1u/efficient_screenshots_rythm_game_ai/",
          "publishedOn": "2023-08-19T12:57:11.000Z",
          "wordCount": 2743,
          "title": "Efficient screenshots rythm game AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15v4x69/should_i_add_the_best_episode_in_the_training/",
          "author": null,
          "description": "I am training an agent to learn the best sequence of actions for an N-step episodic task. Multiple sequences achieve a reward of 0. I have noticed that due to the size of the state (images, height, width, channels), the agent easily forgets the information of the best sequence as the replay is flooded with a lot of samples. Although the policy gets worse, I would prefer the agent to not forget the best policy so far. \n ​\n I was wondering if I should include the best sequence so far in the batch used for training so that the agent does not forget it. \n ​\n What I am really doing is finding the best parameters to achieve the highest reward. I could use an evolutionary algorithm. Nonetheless, I want my agent to learn patterns of the best sequences for multiple instances of the problem so that it can generalize better.\n ​\n Has anyone read anything about this or has any thoughts on this? Any comment will be greatly appreciated.\n    submitted by    /u/ElvishChampion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15v4x69/should_i_add_the_best_episode_in_the_training/",
          "publishedOn": "2023-08-19T03:22:37.000Z",
          "wordCount": 2759,
          "title": "Should I add the best episode in the training batch for a short episodic task?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15uznjd/why_does_my_model_return_these_results_playing/",
          "author": null,
          "description": "class LinearQNet(nn.Module): def __init__(self, inputSize, hiddenSize, outputSize): super().__init__() self.linear1 = nn.Linear(inputSize, hiddenSize) self.linear2 = nn.Linear(hiddenSize, outputSize) def forward(self, x): x = F.relu(self.linear1(x)) x = self.linear2(x) return x def save(self, fileName='model.pth'): modelFolderPath = './model' if not os.path.exists(modelFolderPath): os.makedirs(modelFolderPath) fileName = os.path.join(modelFolderPath, fileName) torch.save(self.state_dict(), fileName) def load(self, fileName='model.pth'): modelFolderPath = './model' fileName = os.path.join(modelFolderPath, fileName) self.load_state_dict(torch.load(fileName)) self.eval() class QTrainer: def __init__(self, model, learningRate, gamma): self.learningRate = learningRate self.gamma = gamma self.model = model self.optimizer = optim.Adam(model.parameters(), lr=self.learningRate) self.criterion = nn.MSELoss() def trainStep(self, state, action, reward, nextState, done): state = torch.tensor(state, dtype=torch.float) nextState = torch.tensor(nextState, dtype=torch.float) action = torch.tensor(action, dtype=torch.long) reward = torch.tensor(reward, dtype=torch.float) if len(state.shape) == 1: state = torch.unsqueeze(state, 0) nextState = torch.unsqueeze(nextState, 0) action = torch.unsqueeze(action, 0) reward = torch.unsqueeze(reward, 0) done = (done, ) pred = self.model(state) target = pred.clone() for idx in range(len(done)): QNew = reward[idx] if not done[idx]: QNew = reward[idx] + self.gamma * torch.max(self.model(nextState[idx])) target[idx][torch.argmax(action[idx]).item()] = QNew self.optimizer.zero_grad() loss = self.criterion(target, pred) loss.backward() self.optimizer.step() \n ​\n    submitted by    /u/MrHank2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15uznjd/why_does_my_model_return_these_results_playing/",
          "publishedOn": "2023-08-18T23:18:31.000Z",
          "wordCount": 2748,
          "title": "Why does my model return these results playing the classic snake game?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15uuhbt/how_do_i_combine_stablebaselines3_with_procgen/",
          "author": null,
          "description": "I am using Procgen for the first time and am trying to combine it with SB3. I followed the official example given over here but am running into bugs. Can someone please help me with this -Here's my code -\n ​\n ​\n from procgen import ProcgenEnv from stable_baselines3 import PPO from stable_baselines3.common.vec_env import VecExtractDictObs, VecMonitor # ProcgenEnv is already vectorized venv = ProcgenEnv(num_envs=2, env_name=\"starpilot\") # To use only part of the observation: venv = VecExtractDictObs(venv, \"rgb\") Wrap with a VecMonitor to collect stats and avoid errors venv = VecMonitor(venv=venv) model = PPO(\"MultiInputPolicy\", venv, verbose=1) model.learn(10_000) \n ​\n ​\n ​\n Here's the error that I am getting -\n C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\python.exe D:/q_learning/procgen_prototype…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15uuhbt/how_do_i_combine_stablebaselines3_with_procgen/",
          "publishedOn": "2023-08-18T19:53:15.000Z",
          "wordCount": 2883,
          "title": "How do I combine Stable-Baselines3 with Procgen?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15utrps/how_good_is_this_video_regarding_the_bellman/",
          "author": null,
          "description": "https://youtu.be/YGXznUx-JOo\n It seems like a thoughtful attempt on explaining the significance of Bellman equations in Reinforcement Learning.\n    submitted by    /u/bruin0404  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15utrps/how_good_is_this_video_regarding_the_bellman/",
          "publishedOn": "2023-08-18T19:25:11.000Z",
          "wordCount": 2604,
          "title": "How good is this video regarding the bellman equations?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15uok81/rl_framework_to_optimize_my_custom_multiagent/",
          "author": null,
          "description": "I have built a custom discrete event simulator with multiple agents and want to optimize the system using RL frameworks that support multi-agent configurations. Which framework should I use? I've looked into SB3, CleanRL, Tianshou, SKRL, RLlib, Acme, and MARLlib, and here's what I found:\n  \nSB3 and CleanRL don't offer direct support for multi-agent systems.\n \nRLlib is very functional but has a steep learning curve and hard to customize.\n \nTianshou seems good, but its community is small.\n \nAcme doesn't use the PyTorch backend, which I prefer.\n \nI haven't delved deeply into SKRL or MARLlib, but they appear promising.\n \n I prioritize ease of use and documentation. What framework do you suggest? And why?\n I’d appreciate any helpful starting advice/resource to approach my problem as well.\n    submitted by    /u/FragrantCockroach8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15uok81/rl_framework_to_optimize_my_custom_multiagent/",
          "publishedOn": "2023-08-18T16:02:30.000Z",
          "wordCount": 2710,
          "title": "RL framework to optimize my custom multi-agent simulator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ukqhz/ddpg_vs_dqn/",
          "author": null,
          "description": "I have project in which there is 2D discrete states which is also finite (there is 36 state at all) also i have 1D action that must be between 2-7. I use DQN using pytorch and discretized my actions with 0.25 steps (17 actions total) and get very good result with it. Now, I use DDPG because my action is continuous and there is one problem that I want to know if it is normal or not. From the first epoch all way to the end the actions for all states are near each other. For example at first episode all actions for all state are near 4 and after some episodes all actions are near 7. But in DQN i get high actions like 7 for some state and lower actions like 3-4 for others. Also I use OU noise but my problem is with the real output of actor network. \n Thanks in advance for your responses.\n    submitted by    /u/Brief-Emotion6291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ukqhz/ddpg_vs_dqn/",
          "publishedOn": "2023-08-18T13:33:51.000Z",
          "wordCount": 2739,
          "title": "DDPG VS DQN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15uilya/how_does_one_deal_with_cases_where_the_dimension/",
          "author": null,
          "description": "Let's take the gymnasium Car Racing environment. Here the dimension of the action space is 3. The problem with this is, even though the value function and therefore advantage function will have dimension 1, the log probabilities will have dimension 3. This causes issues while computing the surrogate loss, `surr1`.\n ​\n Please let me know if you need any more information. Here's the entire code in case anyone is interested.\n ​\n act_probs, action = actor(batch_obs) batch_entropy = act_probs.entropy().mean() log_probs = act_probs.log_prob(batch_act).squeeze() print(\"log_probs = \", log_probs.shape) ratios = torch.exp(log_probs - batch_log_probs) print(\"ratios = \", ratios.shape) assert (ratios.shape == (batch_size,env.action_space.shape[1])) print(\"batch_advantages = \", batch_advantages.shape) surr1 = ratios*batch_advantages \n Thank you so much!\n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15uilya/how_does_one_deal_with_cases_where_the_dimension/",
          "publishedOn": "2023-08-18T12:00:43.000Z",
          "wordCount": 2702,
          "title": "How does one deal with cases where the dimension of the action space is more than 1?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15tyvs3/muzero_confusionhow_to_know_what_the_valuereward/",
          "author": null,
          "description": "I'm trying to code up a MuZero chess model using the LightZero repo, but I'm having conceptual difficulty understanding some of the kwargs in the tictactoe example file I was pointed toward. Specifically, in the policy dictionary, there are two kwargs called reward_support_size and value_support_size: ```\n policy=dict( model=dict( observation_shape=(3, 3, 3), action_space_size=9, image_channel=3, # We use the small size model for tictactoe. num_res_blocks=1, num_channels=16, fc_reward_layers=[8], fc_value_layers=[8], fc_policy_layers=[8], support_scale=10, reward_support_size=21, value_support_size=21, norm_type='BN', ), \n ```\n I've read the MuZero paper like 4 times at this point so I understand why these are probability supports (so we can use them to implement the MCTS that underpins the whole algorithm). I just don't understand (a) why they are both of size 21 in tictactoe and (b) how I can determine these values for the chess model I am building (which does use the conventional 8x8x111 observation space and 4672 (8x8x73) action space size)?\n    submitted by    /u/lcmaier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15tyvs3/muzero_confusionhow_to_know_what_the_valuereward/",
          "publishedOn": "2023-08-17T20:33:57.000Z",
          "wordCount": 2698,
          "title": "MuZero confusion--how to know what the value/reward support is?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15twh1o/advice_needed_for_who_is_finished_studying_rl/",
          "author": null,
          "description": "Hello, everyone, \n I started learning RL two years ago and have finished several online and written resources such that I am able to answer any oral questions that could be asked about different types of RL methods or algorithms, however, still have difficulty understanding the other codes when I am finding them on Git Hub. I am also not able to program on my own, and that is why I am trying to get some more understanding from other codes written by someone else in online resources, such as GitHub. \n I am open to any advice and would appreciate it.\n    submitted by    /u/nimageran  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15twh1o/advice_needed_for_who_is_finished_studying_rl/",
          "publishedOn": "2023-08-17T19:04:18.000Z",
          "wordCount": 2658,
          "title": "Advice needed for who is finished studying RL materials and not be able to program efficiently",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15tqfwi/challenge_of_learning_sequential_actions_in_dqn/",
          "author": null,
          "description": "I'm using the DQN method, and each time I play, it goes through 24 steps before stopping. After these 24 steps, I find out how much money I made or lost. It's like I'm making bids every hour and then seeing my total profit or loss at the end of the day.\n The issue is that I only know about my profit or loss after all 24 steps are done. This makes it hard for my agent to learn the order of actions. If I make a mistake in the first 24 steps, it can lead to a big loss at the end. So, my agent struggles to understand what actions to take.\n I'm wondering how I can solve this problem. Since the rewards I get are not frequent and I only find out my profit or loss after 24 steps, should I include the last 24 actions I took as part of the state vector? Or are there other things I can try? See below: My agent is losing money even after 50 million steps, there are only 3 discrete actions, and the size of my state vector is 15.\n https://preview.redd.it/15eon0i4toib1.png?width=1560&format=png&auto=webp&s=db8654bb904b63ce73662a68d27feb318c4796aa\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15tqfwi/challenge_of_learning_sequential_actions_in_dqn/",
          "publishedOn": "2023-08-17T15:15:48.000Z",
          "wordCount": 2743,
          "title": "Challenge of Learning Sequential Actions in DQN with Delayed Rewards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15t7ath/which_book_should_i_study_in_order_to_thoroughly/",
          "author": null,
          "description": "\"Tensor\" keeps coming up in all kinds of machine learning books I am studying and I am wondering what book would be a good start to gain a rigorous definition on what tensor is. Or would it suffice to just understand it as a generalization of vector/matrices and move on to save time?\n    submitted by    /u/Substantial-Elk-1259  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15t7ath/which_book_should_i_study_in_order_to_thoroughly/",
          "publishedOn": "2023-08-17T00:29:00.000Z",
          "wordCount": 2604,
          "title": "Which book should I study in order to thoroughly understand what tensor is?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15t5st4/why_does_the_reparameterization_trick_work_when/",
          "author": null,
          "description": "I am trying to understand the reparameterization trick. I got some intuition while looking at [this][1] popular question, but I still feel largely confused. I am putting my understanding and doubts here and would appreciate the help of the community. Let's assume - \n ​\n $y = 10$\n ​\n $\\hat{y} = w_3*z + b$\n ​\n ​\n $z \\sim N(\\mu, \\sigma^2)$\n ​\n $\\mu = w_2*4$\n ​\n $\\sigma = w_1*3$\n ​\n Now, if I had to compute, $de/d{\\mu}$ (e is the error function which is the difference between $y$ and $\\hat{y}$), I wouldn't be able to apply chain rule and compute $dz/d{\\mu}$. This is because z is a sample of the Normal distribution and therefore stochastic with parameters $\\mu$ and $\\sigma$ and therefore changing them based on z might not be a good idea. So, we come up with the following $z$ - \n ​\n $z = \\mu + \\sigma*\\epsilon$ (Apparently $z = \\mu + \\sigma*\\epsilon$ is the same as $z \\sim N(\\mu, \\sigma^2)$)\n ​\n $\\epsilon \\sim N(0,1)$\n ​\n However, I don't see why this $z$ is much different from the previous one. This $z$ is still stochastic, due to the presence of $\\epsilon$. Perhaps my understanding is wrong. \n [1]: https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15t5st4/why_does_the_reparameterization_trick_work_when/",
          "publishedOn": "2023-08-16T23:27:30.000Z",
          "wordCount": 2737,
          "title": "Why does the reparameterization trick work when some components are still stochastic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15t28y5/multiagent_reinforcement_learning/",
          "author": null,
          "description": "I want to get into multi-agent reinforcement learning. Is there an example out there that I can follow from head to toe preferably on physical hardware. I would also appreciate any recommendations for good papers, books, or videos on MARL.\n    submitted by    /u/anointedninja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15t28y5/multiagent_reinforcement_learning/",
          "publishedOn": "2023-08-16T21:12:13.000Z",
          "wordCount": 2581,
          "title": "Multi-Agent Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ss929/skrl_version_1000_available_its_paper_has_been/",
          "author": null,
          "description": "skrl-v1.0.0: Transition from pre-release versions (1.0.0-rc.1 and1.0.0-rc.2) to a stable version.\n This release also announces the publication of the skrl paper in the Journal of Machine Learning Research (JMLR): https://www.jmlr.org/papers/v24/23-0112.html\n Summary of the most relevant features:\n  \nJAX support\n New documentation theme and structure\n Multi-agent Reinforcement Learning (MARL)\n  \n   submitted by    /u/Toni-SM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ss929/skrl_version_1000_available_its_paper_has_been/",
          "publishedOn": "2023-08-16T15:00:10.000Z",
          "wordCount": 2599,
          "title": "skrl version 1.0.0.0 available! Its paper has been accepted and published in the JMLR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15soaon/issues_with_the_training_process_of_dqn/",
          "author": null,
          "description": "Hello everyone, I NEED YOUR HELP !\n Currently I´m working on a DQN agent with:\n - 42 state features that vary between 0 and 1,\n - 49 actions\n - reward that takes values in range of -1e+5\n - 3 hidden layers each with 50 neurons\n - memory size is 100000\n During the training, it seems that the agent does not learn anything and its actions tend to only some specific actions despite the exploration phase. Could you help me with this? \n https://preview.redd.it/ds423fa5sgib1.png?width=1770&format=png&auto=webp&s=86930185cb4a472d8bee442c0553a27f9d8c10ac\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15soaon/issues_with_the_training_process_of_dqn/",
          "publishedOn": "2023-08-16T12:17:16.000Z",
          "wordCount": 2620,
          "title": "Issues with the training process of DQN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15sm1hr/informations_on_the_exact_rl_process_used_in/",
          "author": null,
          "description": "Hi there,\n I'm looking for information about how RL was used in InstructGPT (ChatGPT). In the paper, the authors give no precise information about their process. They only say where the reward comes from and what learning algorithm is used (PPO). \n But, I would like to know how PPO is used in the context of generating a piece of text (what are considered states and actions, how the reward is propagated, how training is done).\n I'm currently looking into all the references given in the paper about RLHF, but I would like to know if there's more details about IntructGPT's algo specifically somewhere, or if they just gave nothing about that.\n Do some of you have information (links? code?) to provide?\n Thanks!\n    submitted by    /u/Maxtoq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15sm1hr/informations_on_the_exact_rl_process_used_in/",
          "publishedOn": "2023-08-16T10:27:52.000Z",
          "wordCount": 2669,
          "title": "Informations on the exact RL process used in IntructGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15sk7z5/removing_the_faulty_episode_and_continuing/",
          "author": null,
          "description": "I am working with the custom environment that makes a move and pulls the state of the environment from the server. Sometimes the game engine on the server may hang or there can be some unexpected errors. Is there a possible callback function that will remove the data from this faulty episode and continue training without restarting anything like in Rllib? Any kind of library, advice or literature is welcomed\n    submitted by    /u/naeson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15sk7z5/removing_the_faulty_episode_and_continuing/",
          "publishedOn": "2023-08-16T08:48:36.000Z",
          "wordCount": 2615,
          "title": "Removing the faulty episode and continuing training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15s1aqy/compatibility_issues_with_citylearn_20b4_gym_0261/",
          "author": null,
          "description": "I am currently working on a project involving CityLearn (version 2.0b4), Stable Baselines 3 (version 2.0.0), and Gym (version 0.26.1), and I have encountered an issue that I'm struggling to resolve.\n Here's a brief overview of my setup:\n Operating System: Windows Python Version: 3.10 Libraries: CityLearn: 2.0b4 Stable Baselines 3: 2.0.0 Gym: 0.26.1 I am facing the following error:\n ValueError: not enough values to unpack (expected 2, got 1) \n The error occurs when I attempt to run the code provided in the official CityLearn documentation(https://www.citylearn.net/quickstart.html). I have not modified a single line of the code, and I'm using the exact code snippet provided:\n from stable_baselines3.sac import SAC from citylearn.citylearn import CityLearnEnv from citylearn.wrappers import NormalizedObservationWrapper, StableBaselines3Wrapper dataset_name = 'baeda_3dem' env = CityLearnEnv(dataset_name, central_agent=True, simulation_end_time_step=1000) env = NormalizedObservationWrapper(env) env = StableBaselines3Wrapper(env) model = SAC('MlpPolicy', env) model.learn(total_timesteps=env.time_steps*2) observations = env.reset() while not env.done: actions, _ = model.predict(observations, deterministic=True) observations, _, _, _ = env.step(actions) kpis = env.evaluate().pivot(index='cost_function', columns='name', values='value') kpis = kpis.dropna(how='all') display(kpis) \n I have tried various solutions and referred to the official documentation, but I am unable to find a compatible version combination that resolves this issue.\n If anyone has experience with these libraries and can provide guidance or suggestions, I would greatly appreciate it. I'm following the instructions exactly as provided in the official documentation, so I'm puzzled as to why I'm encountering this issue.\n Thank you for your time and assistance!\n    submitted by    /u/zeno9698  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15s1aqy/compatibility_issues_with_citylearn_20b4_gym_0261/",
          "publishedOn": "2023-08-15T18:55:37.000Z",
          "wordCount": 2771,
          "title": "Compatibility Issues with CityLearn 2.0b4, Gym 0.26.1, and Stable Baselines 3 2.0.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15s039z/cfp_neurips_2023_workshop_on_goalconditioned_rl_5/",
          "author": null,
          "description": "submitted by    /u/b_eysenbach  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15s039z/cfp_neurips_2023_workshop_on_goalconditioned_rl_5/",
          "publishedOn": "2023-08-15T18:10:10.000Z",
          "wordCount": 2541,
          "title": "[CFP] NeurIPS 2023 Workshop on Goal-Conditioned RL: 5 min video or 2 page paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15rxhz0/how_to_handle_environment_where_the_state_is/",
          "author": null,
          "description": "Hi all,\n I started to use Gynasium with stable-baselines 3 for reinforcement learning and I have a basic question. Normally in RL you have a state then you take an action and you get an reward and a new state back in the step function of the gynasium environment.\n In my case things are a little different. The state is always externally given (by reading from a file), then an action is executed in an external environment and a new state is calculated. However, in the next iteration, not the resulting last state used but a new externally given state. \n So my quesiton now is how to handle this using gynsasium and stable-baselines 3? Shall I just return nothing as the state after the action has been executed in the external environment? Or shall I alaways return the resulting state that is however \"overwritten\" in the next iteration.\n    submitted by    /u/PBerit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15rxhz0/how_to_handle_environment_where_the_state_is/",
          "publishedOn": "2023-08-15T16:31:28.000Z",
          "wordCount": 2686,
          "title": "How to handle environment where the state is always externally given",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15rvcn5/causallm_is_not_optimal_for_incontext_learning/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15rvcn5/causallm_is_not_optimal_for_incontext_learning/",
          "publishedOn": "2023-08-15T15:08:51.000Z",
          "wordCount": 2550,
          "title": "\"CausalLM is not optimal for in-context learning\", Ding et al 2023 {G}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15r59rq/ppo_tensorboard_loss_functions_part_2/",
          "author": null,
          "description": "In my previous post ( Reinforcement Learning (reddit.com) ) I had a hard time understand the differences between the loss functions in Tensorboard, and thanks to the members here, after normalizing and changing the reward functions, they became clearer to me.\n I'd like first to give perspective of my custom gym environment.\n  \nI use PPO2 algorithm ( n_steps=512 , nminibatches=8 ) as from my understanding it means the weights will get updated within these steps instead of waiting for an episode to finish.\n  \nScenario 1: use the first 5000 rows from my dataset, I get the following results:\n 5k rows\n As seen, the entropy loss seems to increase which means the policy isn't learning and has a lot of randomness. However, the loss seems to decrease, but I'm not sure if I should continue training for more steps and it will converge eventually!\n Scenario 2: use the 50,000 rows from my dataset, I get the following results:\n 50k rows\n As seen, the loss function goes to zero very quickly, then jump really high and return back to zero, I don't understand this behavior as the mode seems to not still learning!\n Can someone please help me understand what's happening?\n    submitted by    /u/Acceptable_Egg6552  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15r59rq/ppo_tensorboard_loss_functions_part_2/",
          "publishedOn": "2023-08-14T20:00:34.000Z",
          "wordCount": 2732,
          "title": "PPO Tensorboard loss functions (Part 2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15r0rx3/p_miniwob_v10_web_interaction_environments_for_rl/",
          "author": null,
          "description": "We are releasing the mature 1.0 version of MiniWoB++ (Mini World of Bits++), an RL benchmark containing over 100 web interaction environments, ranging from simple button clicks to more complex forms and web apps.\n The environments were released by OpenAI back in 2017 as just HTML pages. With MiniWoB++, the environments run on a browser, and an RL agent can get the environment states or execute actions via Selenium WebDriver.\n This version of MiniWoB++ contains the following features:\n * Over 100 web environments, including 2 bigger environments based on real websites and 18 previously unavailable “test set” environments. All (but 4) environments are deterministic for the given random seed.\n * Full integration with Gymnasium, a fork of OpenAI Gym, which provides a standardized API for RL.\n * A wide range of implemented browser actions including clicking, dragging, scrolling, typing, and pressing keyboard shortcuts, all of which can be customized (e.g., coordinate binning or scrolling speed).\n Tweet: https://twitter.com/FaramaFound/status/1691135031798804480?s=20\n Release notes: https://github.com/Farama-Foundation/miniwob-plusplus/releases/tag/v1.0\n Documentation: https://miniwob.farama.org/\n    submitted by    /u/elliottower  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15r0rx3/p_miniwob_v10_web_interaction_environments_for_rl/",
          "publishedOn": "2023-08-14T17:16:06.000Z",
          "wordCount": 2698,
          "title": "[P] MiniWoB++ v1.0 - Web interaction environments for RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15r04if/i_made_connect_4_with_pygame_and_drl/",
          "author": null,
          "description": "submitted by    /u/Disastrous-Ladder-46  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15r04if/i_made_connect_4_with_pygame_and_drl/",
          "publishedOn": "2023-08-14T16:52:12.000Z",
          "wordCount": 2816,
          "title": "I made \"Connect 4\" with Pygame and DRL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15qzvxe/visionbased_reinforcement_learning_for_trackmania/",
          "author": null,
          "description": "We used model-free, value-based reinforcement learning (mostly dueling-IQN) to train an AI that plays Trackmania. The system is mostly vision based, along with some information taken from the game engine such as car speed and acceleration.\n On our simple training track, we believe we are close to or above human level. We have yet to find a human who sets a better racing time than our AI's.\n We tried many extensions to the algorithm (noisy, persistent advantage learning, munchausen, ...), but none of these extensions improved the ultimate performance of our AI.\n Link the the video, we're pretty proud of this result. :)\n ​\n    submitted by    /u/Linesight_rl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15qzvxe/visionbased_reinforcement_learning_for_trackmania/",
          "publishedOn": "2023-08-14T16:43:28.000Z",
          "wordCount": 2640,
          "title": "Vision-based reinforcement learning for Trackmania: close or at superhuman level",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15qk8hd/using_rl_in_a_videogame_with_only_1_state/",
          "author": null,
          "description": "I'm super new to RL, just started today amd I'm probably doing it super wrong but here goes.\n Basically I'm trying to get an AI command center base in Halo Infinite to apply RL in order to determine which loadout to apply to a bot defending the base you're attacking. The issue I'm running into is how to preditct the Q-values for the next state.\n In my map, I decided to change from one state to the next every 5 kills per team. So when that happens the Kill/death ratio of each loadout equipped by a player is updated and used as a reward in the Q-table.\n Well that's the idea, anyway. I wanted to use player kills as a sort of benchmark to gauge performance with a given loadout but I'm afraid the state space I applied is too small and I don't know how to transition from one state to the next and obtain the maximum reward from the expected future rewards of the next state.\n    submitted by    /u/swagonflyyyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15qk8hd/using_rl_in_a_videogame_with_only_1_state/",
          "publishedOn": "2023-08-14T04:28:04.000Z",
          "wordCount": 2704,
          "title": "Using RL in a videogame with only 1 state?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15qfpl2/first_contact_unsupervised_humanmachine/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15qfpl2/first_contact_unsupervised_humanmachine/",
          "publishedOn": "2023-08-14T00:53:53.000Z",
          "wordCount": 2551,
          "title": "\"First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization\", Reddy et al 2022",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15qbvto/modeling_walking_and_the_legs/",
          "author": null,
          "description": "Hello everybody, I had a question and looking for the experience from this group. I want to learn how to train models for walking. More specifically, I'm interested in looking at which muscles are active during walking. Can I use one subject for deep reinforcement learning or will I need more subjects to train the data (say 20+ subjects)? Thanks,\n    submitted by    /u/theslipguy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15qbvto/modeling_walking_and_the_legs/",
          "publishedOn": "2023-08-13T22:10:51.000Z",
          "wordCount": 2564,
          "title": "Modeling walking and the legs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15qaz94/stable_baselines_ppo_vs_rayio_ppo/",
          "author": null,
          "description": "For context, I've been experimenting with different Reinforcement learning algorithms, frameworks etc. Currently I have a custom Gym environment with Stable baselines 3 to train a PPO agent. \n I've noticed however that this setup is very slow for training as stable Baselines doesn't properly utilize GPU + parallel environments don't really work that well due to \"step lock\" where it can't continue until everything is synced up. \n I've heard really good things about Ray/RLlib. It has more advance features + according to reports it's crazy fast for training. \n I want to basically rewrite my existing SB3 implementation into Ray but I don't find the documentation very user-friendly + there aren't really that much good/usefull tutorials online as far is I can find. \n I tried GPT-4 but it just regurgitates some very old Ray implementation. I even tried not using ray and trying Tensorflow again (I hate Tensorflow, I'm definitely team Pytorch 😬) \n Do you guys have any good tutorials, videos, documentation to get started with PPO on Ray? Would love to learn more, but documentation online seems very hardcore to start even 😂.\n Would love to know your suggestions.\n    submitted by    /u/ClassicAppropriate78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15qaz94/stable_baselines_ppo_vs_rayio_ppo/",
          "publishedOn": "2023-08-13T21:35:10.000Z",
          "wordCount": 2694,
          "title": "Stable Baselines PPO vs Ray.io PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15q3weo/terminated_vs_truncated_in_gymnasium/",
          "author": null,
          "description": "Hi! \n I am not completely sure how to use these flags from the Gymnasium API (I've always used the Gym API so far and I'm switching just now...). Particularly in the environment, I'm playing with now:\n It's a 1vs1 game, and an episode can end if one of the 2 players dies or a max. number of steps is reached. In this case:\n - The max. number of steps is a hard limit rule of the game, so if these are reached should they receive truncated or terminated signals?\n - If a player dies, should both agents get a terminated = True, or one should get terminated=True and the other one truncated=True, as it was still alive, and could have continued playing? \n ​\n Thank you!\n ​\n    submitted by    /u/xWh0am1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15q3weo/terminated_vs_truncated_in_gymnasium/",
          "publishedOn": "2023-08-13T16:52:57.000Z",
          "wordCount": 2628,
          "title": "terminated vs truncated in Gymnasium",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15pdduc/which_is_the_recommended_physics_engine_for_deep/",
          "author": null,
          "description": "I am thinking of a project that will use some constraints of the physical world and then use deep reinforced learning on it. Is there any physics engine that you'll could recommend me. I came across Mujoco but the documentation is hard to understand and there are not many resources on it to learn. Any suggestion on what I could use?\n ​\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15pdduc/which_is_the_recommended_physics_engine_for_deep/",
          "publishedOn": "2023-08-12T19:34:01.000Z",
          "wordCount": 2570,
          "title": "which is the recommended physics engine for deep reinforced learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15p484p/ppo_tensorboard_loss_functions/",
          "author": null,
          "description": "I'm training a PPO algorithm using stable baseline for some stock data, and I want to know if the model is learning properly, or i should tweak some hyperparameters or increase time steps.\n I'm new to reinforcement learning, but in deep learning, the loss should decrease as a good sign of converging and learning, which is the case for the entropy loss in the picture attached, but I don't understand the difference between the other losses.\n https://preview.redd.it/7ovw2gf8iohb1.png?width=1656&format=png&auto=webp&s=09fbb112a562fad294f88c8f3d94904bdad95759\n    submitted by    /u/Acceptable_Egg6552  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15p484p/ppo_tensorboard_loss_functions/",
          "publishedOn": "2023-08-12T13:09:58.000Z",
          "wordCount": 2579,
          "title": "PPO Tensorboard loss functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15odzh3/any_suggestions_on_how_i_can_improve_my_vision/",
          "author": null,
          "description": "I am planning to throw my algorithm into a pronto server which enable me to increase the number of parallel workers. Currently, I am going with 24 workers. I'd appreciate more suggestions. Here's the pastebin link with syntax highlighting. Here's my code - \n #Modified this code - https://github.com/DeepReinforcementLearning/DeepReinforcementLearningInAction/blob/master/Chapter%204/Ch4_book.ipynb #Also, modified this code - https://github.com/higgsfield/RL-Adventure-2/blob/master/1.actor-critic.ipynb # Also, modified this code - https://github.com/ericyangyu/PPO-for-Beginners/blob/9abd435771aa84764d8d0d1f737fa39118b74019/ppo.py#L151 # Got a lot of help from the subreddit - reinforcement_learning if __name__ == '__main__': import numpy as np import gymnasium as gym from gymnasium.wrappers im…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15odzh3/any_suggestions_on_how_i_can_improve_my_vision/",
          "publishedOn": "2023-08-11T16:48:14.000Z",
          "wordCount": 3331,
          "title": "Any suggestions on how I can improve my vision based PPO algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15o2cty/dreamer_v3_in_sheeprl/",
          "author": null,
          "description": "Hi everyone, we finally ended our journey through Dreamer, and we released the last version, Dreamer V3 in SheepRL.\n Our implementation follows closely the author's one, and is very well documented, with a blog post to explain the details and differences between this version and Dreamer V2.\n Together with Dreamer, we also have Plan2Explore with Dreamer v1 and v2.\n Finally, we completed the integration with Diambra, so you can try your agents on new (funnier) benchmarks.\n Check it out and feel free to contribute. Every feedback is appreciated :) \n    submitted by    /u/TrottoDng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15o2cty/dreamer_v3_in_sheeprl/",
          "publishedOn": "2023-08-11T07:49:53.000Z",
          "wordCount": 2594,
          "title": "🐑 Dreamer V3 in SheepRL 🐑",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15o2bam/whats_the_difference_between_gvf_and_options/",
          "author": null,
          "description": "Two cool concepts - General Value Functions & Options. Seem to be for the same purpose.\n ​\n What are the differences between these 2 strategies, and what are the benefits of each? Thanks!\n    submitted by    /u/Cultural-Average3959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15o2bam/whats_the_difference_between_gvf_and_options/",
          "publishedOn": "2023-08-11T07:47:23.000Z",
          "wordCount": 2538,
          "title": "What's the difference between GVF and Options?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15nky6g/skrl_with_multiple_discrete_actions/",
          "author": null,
          "description": "I'm new to RL, and I was trying to train an agent to move items in a 2D grid. The agent needs to output the row number, column number, and item index, and right now I'm modeling them as discrete actions. I am not sure what kind of agent to use to solve this problem. I tried PPO, but I'm not sure what the output of the policy module should be in this case. I'd be grateful for any help.\n    submitted by    /u/LostPigeon25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15nky6g/skrl_with_multiple_discrete_actions/",
          "publishedOn": "2023-08-10T18:54:10.000Z",
          "wordCount": 2584,
          "title": "skrl with multiple discrete actions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15nd91l/implement_parallel_training_using_the/",
          "author": null,
          "description": "This project allows you to easily implement parallel training with the multiprocessing module.\n    submitted by    /u/NoteDancing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15nd91l/implement_parallel_training_using_the/",
          "publishedOn": "2023-08-10T13:56:28.000Z",
          "wordCount": 2532,
          "title": "Implement parallel training using the multiprocessing module.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mueec/personalization_with_vw/",
          "author": null,
          "description": "Hello! I am working off the VowpalWabbit example for explore_adf, just changing the cost function and actions but I get no learning. What I mean is that I train a model but when I ran the prediction, I just get an array of equivalent probabilities (0.25, 0.25, 0.25, 0.25). I have tried changing everything (making only one action to payoff for example) and still get the same error. Anyone has ran into a similar situation? Help please!\n    submitted by    /u/juanccs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mueec/personalization_with_vw/",
          "publishedOn": "2023-08-09T22:53:51.000Z",
          "wordCount": 2571,
          "title": "Personalization with VW",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mtvzg/inquiry_regarding_dynamic_action_space_dqn_and/",
          "author": null,
          "description": "I am currently addressing a challenge within the domain of Reinforcement Learning. The particular issue revolves around a dynamic action space, where the set of potential actions available changes based on the context or state. In light of this, I am seeking guidance on the feasibility of utilizing the Deep Q-Network (DQN) approach to specifically identify permissible actions for distinct states.\n Furthermore, if the DQN approach is not applicable in this scenario, I would appreciate recommendations for alternative algorithms that could effectively address this issue. Additionally, I am considering the option of designing a single action space and employing negative reward to discourage the agent from pursuing unauthorized actions within specific states.\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mtvzg/inquiry_regarding_dynamic_action_space_dqn_and/",
          "publishedOn": "2023-08-09T22:33:57.000Z",
          "wordCount": 2615,
          "title": "Inquiry Regarding Dynamic Action Space, DQN, and Alternative Algorithms in Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mp5l7/how_to_tell_if_your_model_is_actually_learning/",
          "author": null,
          "description": "I've been building a multi-agent model of chess, where each side of the board is represented by a Deep Q Agent. I had it play 100k training games, but the loss scores increased over time, not decreased. I've got the (relatively short) implementation and the last few output graphs from the training--is there a problem with my model architecture or does it just need more training games, perhaps against a better opponent than itself? Here's the notebook file. Thanks in advance\n    submitted by    /u/lcmaier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mp5l7/how_to_tell_if_your_model_is_actually_learning/",
          "publishedOn": "2023-08-09T19:37:07.000Z",
          "wordCount": 2581,
          "title": "How to tell if your model is actually learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mojqr/reward_shaping_in_frozenlake/",
          "author": null,
          "description": "I'm trying to use a neurosymbolic approach to solve the Frozenlake enviroment, using also stable baselines 3.\n I used the TransformReward on the enviroment, and seems that it's working (changing the reward values).\n So here it is how it works the program:\n It calculates a reward per step based on the distance of the next state to the goal state. Also I tried adding some more constraints, like punishing if it stays on the same square or if it falls into a hole.\n The thing is that I don't know if I'm doing something wrong, so if someone can help me would be much appreciated. Here is part of the code, I'll omit the neuro symbolic part because it's irrelevant.\n The rewards are:\n ​\n  \nTaking a step in a direction that makes you near the goal: less than one (it depends on how near of the objecti…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mojqr/reward_shaping_in_frozenlake/",
          "publishedOn": "2023-08-09T19:14:14.000Z",
          "wordCount": 3000,
          "title": "Reward shaping in FrozenLake",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mjlw7/cnn_features_extractor_for_categorical_data/",
          "author": null,
          "description": "I'm working on a RL Environment for my Masther Thesis where i try to explore the use of RL for Architectural Design. The environment looks like a 3D Grid of cubic 3D tiles or modules, and the agent can place tiles by choosing : Location (As x,y,z coordinates) , rotation (0 to 4 as multiples of 90 degrees around a z axis in the center) , and Tile Type (Im experimenting with many sets of tiles with different sizes). Then, I use Grasshopper3D to analyze the radiation that the interior surfaces and other metrics, that i use for my reward calculation. \n For this, the state of the environment is defined as a 3D Array with 2 channels. One for the Tile Types and one for the rotations. This is processed by a 3D CNN features extractor. \n The thing is that, I just realized that the array that represents the tile types as integers is actually categorical data, and I don't know how well this could work in a CNN. What i mean by this is that a tile=3 is not any more \"anything\" that a tile=1, it is just different. \n Am I doing something stupid then? Should i change it?\n I apologize if im saying something really dumb. I just got into RL few months ago : - ) \n    submitted by    /u/Direct-Software7378  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mjlw7/cnn_features_extractor_for_categorical_data/",
          "publishedOn": "2023-08-09T16:09:54.000Z",
          "wordCount": 2716,
          "title": "CNN Features Extractor for Categorical Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15m1hj4/alphastar_unplugged_largescale_offline/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15m1hj4/alphastar_unplugged_largescale_offline/",
          "publishedOn": "2023-08-09T01:52:47.000Z",
          "wordCount": 2514,
          "title": "\"AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning\", Mathieu et al 2023 {DM} (MuZero)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15lq3ka/studying_rl_is_hard/",
          "author": null,
          "description": "I want to study Reinforcement Learning, but the concepts are really hard and mathematical. Whenever I think I grasp something I forget it the next day completly. The Basic Concepts of MDP is the only thing which I think I understood. But I cant understand the Training algorithms like Sarsa or Q-Learning and DQN and their implementations. I am really frustrated and overwhelmed.\n Does anyone know some good resources to understand the concepts and implementations of RL?\n    submitted by    /u/Menium  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15lq3ka/studying_rl_is_hard/",
          "publishedOn": "2023-08-08T18:25:11.000Z",
          "wordCount": 2571,
          "title": "Studying RL is hard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15lofrn/is_it_necessary_to_run_episodes_in_modelfree/",
          "author": null,
          "description": "In Q-learning (image), episodes are run, in the sense that, the states are visited in the order they appear as part of one sequence in an episode.\n In Dyna-Q (image) (which is btw described to be the same as Q-learning when the planning portion is deleted), there doesn't seem to be any iteration over the states of an episode. It just picks a state, applies the e-greedy policy on it to choose the action, learns, updates the model, then plans.\n Would Q-learning also work fine if we got rid of the \"episodes\" and just picked isolated state-action pairs?\n Thank you\n    submitted by    /u/AstronautVarious3791  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15lofrn/is_it_necessary_to_run_episodes_in_modelfree/",
          "publishedOn": "2023-08-08T17:23:51.000Z",
          "wordCount": 2600,
          "title": "Is it necessary to run \"episodes\" in model-free learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15lm5nl/intuition_about_what_features_deep_rl_learns/",
          "author": null,
          "description": "I know for image recognition there is a rough intuition that neural network lower layers learn low level features like edges, and the higher layers learn more complex compositions of the lower layer features. Is there a similar intuition about what a value network or policy network learns in deep RL? If there are any papers that investigate this that would be helpful\n    submitted by    /u/Turkeydunk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15lm5nl/intuition_about_what_features_deep_rl_learns/",
          "publishedOn": "2023-08-08T15:57:13.000Z",
          "wordCount": 2561,
          "title": "Intuition about what features deep RL learns?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15jxbpk/could_someone_help_me_understand_what_is_going_on/",
          "author": null,
          "description": "https://imgur.com/WR0Tny9\n My agent needs to learn to take one action in my environment and there are only two possible actions that the agent can take at each time step. The state is just the time step, so every episode has 240 time steps and the agent just needs to learn to take one optimal action out of two possible actions for every time step. I have set this up as simply as I can as a starting point to make sure the algorithm is implemented correctly and that the agent can learn. I am using n-step expected SARSA.\n The bottom plot shows the count for how many times the agent took each action during each episode. The middle plot has the temporal difference error in blue and the \"modelling error\" in orange. The modelling error is the difference between the actual discounted return and the TD target for each time step, summed up for each episode. The red line is the return that the agent would get if it took the optimal action in every time step.\n 0.11, the blue line in the bottom plot, is the optimal action for the agent to take at every time step. The other action will never result in a reward other than 0. So it should be fairly simple for the agent to learn what action to take at every time step and it does learn that at the start. But then, as you can see in the top plot, the agent suddenly starts taking the non-optimal action more often after around episode 450. So I'm just wondering why that would happen. Why would the agent learn to take the optimal action at most time steps and then suddenly decide that it will start taking other actions?\n For more context, the learning rate is 0.6, n is 6, epsilon is decayed by 1/(n_episodes/1.1) every episode so it reaches 0 slightly before the final episode.\n Any ideas based on this information why the agent would decide to start taking the non-optimal action? Or any suggestions for how I could figure out why it would start taking the non-optimal action?\n    submitted by    /u/lifelifebalance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15jxbpk/could_someone_help_me_understand_what_is_going_on/",
          "publishedOn": "2023-08-06T18:52:40.000Z",
          "wordCount": 2813,
          "title": "Could someone help me understand what is going on with my agent in this environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15juvsd/runtimeerror_trying_to_backward_through_the_graph/",
          "author": null,
          "description": "submitted by    /u/Think_Huckleberry299  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15juvsd/runtimeerror_trying_to_backward_through_the_graph/",
          "publishedOn": "2023-08-06T17:13:32.000Z",
          "wordCount": 2488,
          "title": "RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ju299/tarmac_targeted_multiagent_communication/",
          "author": null,
          "description": "Does anyone know code implementations for TarMAC: Targeted Multi-Agent Communication?\n    submitted by    /u/tessherelurkingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ju299/tarmac_targeted_multiagent_communication/",
          "publishedOn": "2023-08-06T16:39:16.000Z",
          "wordCount": 2457,
          "title": "TarMAC: Targeted Multi-Agent Communication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15j06hu/why_isnt_there_a_sarsa_equivalent_that_uses_value/",
          "author": null,
          "description": "SARSA is a TD algorithm for control (learning optimal policies). In the book it's written like this: image. The idea is to learn the action-value function instead of the value function for a policy that we keep improving (using GPI). Once we learn the converged action-value function for all states, the optimal policy is greedily derived from the action-value function (basically take the most promising action at each state).\n In contrast, TD for value estimation is written like this: image. Here we keep the policy fixed and just keep iterating over the multiple episodes, whilst refining the value estimate.\n My question is, why can't we just change TD for value estimation to just greedily update the policy at each stage? That would be in the spirit of generalized policy iteration (GPI) too. In other words, a version of SARSA which doesn't use action-value functions, but instead use value functions?\n    submitted by    /u/AstronautVarious3791  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15j06hu/why_isnt_there_a_sarsa_equivalent_that_uses_value/",
          "publishedOn": "2023-08-05T16:34:13.000Z",
          "wordCount": 2602,
          "title": "Why isn't there a SARSA equivalent that uses value functions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15iemvu/understanding_the_concept_of_variance_in/",
          "author": null,
          "description": "I was trying to understand Generalized Advantage Estimation from here and came across the following paragraph - \n ​\n https://preview.redd.it/l41x655ea6gb1.png?width=778&format=png&auto=webp&s=ffd266c0355a03e1c98ea6de89ca2fc78ed27fd1\n I understood the reason why there could be high bias while bootstrapping the advantage. But why does $A_t^{\\inf}$ have high variance. Aren't bias and variance concepts related to estimation by an estimator? While calculating $A_t^{\\inf}$, we are literally using the reward values obtained from the environment and therefore there is no estimation involved. Could someone please help me with this?\n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15iemvu/understanding_the_concept_of_variance_in/",
          "publishedOn": "2023-08-04T22:52:51.000Z",
          "wordCount": 2528,
          "title": "Understanding the concept of Variance in Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ib8x9/interesting_rl_environments_in_github/",
          "author": null,
          "description": "I am searching for an interesting but not too complex game envs.\n Preferably with selfplay but should not be very simple nor standard atari like.\n Any recommendations?\n    submitted by    /u/Trrrrr88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ib8x9/interesting_rl_environments_in_github/",
          "publishedOn": "2023-08-04T20:41:44.000Z",
          "wordCount": 2475,
          "title": "Interesting RL environments in github",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15hwxd6/updating_custom_output_layers_of_an_lstm_network/",
          "author": null,
          "description": "I have a text generation task learning to predict the next word with an LSTM network with multiple output layers.\n After the generation of a sentence has finished, I calculate a reward for the whole sentence and try to update the output layers participated in the generation (contributing layers get the calculated reward value, others get 0).\n My problem is that even if I update only the selected output layers, it seems that other layer's weights got updated instead.\n I have a minimized example with dummy data to present the problem:\n import random import numpy as np import tensorflow as tf from keras.layers import Input, LSTM, Dense, Embedding from keras.utils import pad_sequences from tensorflow.keras.models import Model def policy_gradient_loss(y_true, y_pred): return tf.reduce_mean(tf.m…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15hwxd6/updating_custom_output_layers_of_an_lstm_network/",
          "publishedOn": "2023-08-04T10:59:47.000Z",
          "wordCount": 2764,
          "title": "Updating custom output layers of an LSTM network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15hln42/why_am_i_unable_to_reshape_my_observation_with/",
          "author": null,
          "description": "I am trying to reshape my `Breakout` vectorized environment observations to have the shape `num_envs*frames, height, width, channels`. Currently, the shape is `(3, 4, 210, 160, 3)` and basically I'd like it to be `(3*4, 210, 160, 3)`. Based on the documentation, the `TransformObservation` should solve this problem for me, but it is not doing that.\n ​\n Here's my code -\n import gym import numpy as np from gym.wrappers import AtariPreprocessing, FrameStack, GrayScaleObservation, TransformObservation if __name__ == '__main__': def reshape_image(obs): # Assuming the original observation is an image with shape (height, width, channels) new_obs = np.array(obs).reshape(12, 210, 160, 3) return new_obs env = gym.vector.make(\"ALE/Breakout-v5\", num_envs=4) env = FrameStack(env, num_stack=3) env = TransformObservation(env, reshape_image) env.reset() observation, reward, terminated, done = env.step(env.action_space.sample()) print(\"observation = \", env.observation_space.shape) \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15hln42/why_am_i_unable_to_reshape_my_observation_with/",
          "publishedOn": "2023-08-04T00:56:55.000Z",
          "wordCount": 2577,
          "title": "Why am I unable to reshape my observation with `TransformObservation` wrapper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15hjz50/skillit_a_datadriven_skills_framework_for/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15hjz50/skillit_a_datadriven_skills_framework_for/",
          "publishedOn": "2023-08-03T23:43:31.000Z",
          "wordCount": 2469,
          "title": "\"Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models\", Chen et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15h9uj8/how_do_i_add_entropy_to_a_ppo_algorithm/",
          "author": null,
          "description": "Can someone please help with this question? I have added my understanding of this problem to the question, but I suspect that it may be flawed.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15h9uj8/how_do_i_add_entropy_to_a_ppo_algorithm/",
          "publishedOn": "2023-08-03T17:09:22.000Z",
          "wordCount": 2478,
          "title": "How do I add Entropy to a PPO algorithm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15gre4h/how_to_get_better_at_programming_when_i_have_bp/",
          "author": null,
          "description": "Hi I am 30F, currently working on my thesis. I like the idea of creating logics and then implementing them using coding. I switched my major from engineering to CS bcuz I was very much inspired by AI and all. But the issue is I have bipolar disorder and I am also on ADHD spectrum so self paced online courses to learn programming are very hard for me. I am also barely managing to pay tuition so I can't pay like $100+ for a course to learn. I know it's kinda stupid but is there any way I can make my programming skills better and get better at creating/modifying algorithms?\n    submitted by    /u/Kucing_koyangi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15gre4h/how_to_get_better_at_programming_when_i_have_bp/",
          "publishedOn": "2023-08-03T02:21:19.000Z",
          "wordCount": 2568,
          "title": "How to get better at programming when I have BP disorder and on ADHD spectrum?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15glpji/tianshou_dqn_batch_size_keeps_decreasing/",
          "author": null,
          "description": "I am trying to train a DQN to play chess using a combination of Tianshou and PettingZoo. However, for a reason I cannot locate, after anwhere from 15-25 passes through the forward function, the size of the batches starts decreasing, until it falls all the way to 1, before throwing a warning that n_step isn't a multiple of the number of environments, jumping to a size = the number of training environments and then the training agent's batch size before erroring out. My best guess is that somehow truncated games aren't being properly added to the batch, but that doesn't quite explain why each subsequent batch is equal or smaller in size. I am at a loss for how to debug this. Everything is in this Python Notebook.\n    submitted by    /u/lcmaier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15glpji/tianshou_dqn_batch_size_keeps_decreasing/",
          "publishedOn": "2023-08-02T22:13:57.000Z",
          "wordCount": 2577,
          "title": "Tianshou DQN batch size keeps decreasing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15g4w3v/stable_gail_alternatives_for_imitation_learning/",
          "author": null,
          "description": "I'm currently working on a project for Imitation Learning from multiple perspectives. The base Imitation Learning algorithm I'm currently using is GAIL.\n Working with GAIL has been very frustrating because it's incredibly seed dependent and unstable. This makes progress and iteration speed for experiments/modifications built on top of it very slow.\n As I'm not an expert in Imitation Learning: Does anybody with experience know more stable alternatives (or improvements) to GAIL?\n The setting I'm considering is Learning from Observations (LfO), so I don't think that DAgger will work.\n I've done some preliminary search and found this method https://arxiv.org/pdf/2004.04650.pdf. However, the authors don't compare it to GAIL.\n Thanks in advance for any suggestions!\n    submitted by    /u/timo_kk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15g4w3v/stable_gail_alternatives_for_imitation_learning/",
          "publishedOn": "2023-08-02T10:09:24.000Z",
          "wordCount": 2563,
          "title": "Stable GAIL alternatives for Imitation Learning from pixels",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15g49ai/how_to_implement_a_policy_agent_in_pettingzoo_mpe/",
          "author": null,
          "description": "Hi all:\n I am trying to train a competitive scenario in a Multiagent particle environment( I am now using the Pettingzoo API). The Algorithm I am now using only support discrete action space. But I want to evaluate agents with one side's policy keep fixed and let the other side's policies be the trained policy. The policy can be simple( like if the target for one side agent is to chase the other side, their policy is directly following the trajectory for their target). The core.py for the petting zoo, it has \n  # return all agents controllable by external policies @property def policy_agents(self): return [agent for agent in self.agents if agent.action_callback is None] # return all agents controlled by world scripts @property def scripted_agents(self): return [agent for agent in self.agents if agent.action_callback is not None] \n But in the step for the environment, it seems the environment directly controls the policy agent. My understanding is scripted agent is RL policy output and the Policy agent can be controlled by other policies. \n My question is :\n if my policy output is the desired position for each timestep, but now the MPE's control dynamic is learned the acceleration's increment, and it's discrete, how can I implement the policy as one side of my competitive case?\n  \nif I can control the policy agent base on policy_agent, how can I step both policy and script agent in env?\n if I can control the agent separately, like my RL output can be discrete but the policy output can be continuous position.\n how to define the termination or truncation for all agents?\n  \n   submitted by    /u/Gloria_1126  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15g49ai/how_to_implement_a_policy_agent_in_pettingzoo_mpe/",
          "publishedOn": "2023-08-02T09:33:48.000Z",
          "wordCount": 2717,
          "title": "How to implement a policy agent in pettingzoo mpe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15g1j2q/training_cartpole_using_policy_gradient_and/",
          "author": null,
          "description": "I am trying to train the cartpole environment using policy gradients algorithm.\n I want to train using the GradientTape method of tensorflow. I have been trying for a long time, but still it hasn't converged.\n What am I doing wrong?\n ​\n import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers import numpy as np import keras.backend as K import matplotlib.pyplot as plt class PolicyGradientModel(keras.Model): def __init__(self, num_actions): super().__init__() self.hidden1 = layers.Dense(24, activation='relu') self.hidden2 = layers.Dense(120, activation='relu') self.out = layers.Dense(num_actions, activation='softmax') def call(self, inputs): x = self.hidden1(inputs) x = self.hidden2(x) return self.out(x) def action_prob(self, state): prob = self.predict(np.ex…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15g1j2q/training_cartpole_using_policy_gradient_and/",
          "publishedOn": "2023-08-02T06:59:49.000Z",
          "wordCount": 2760,
          "title": "Training Cartpole using policy gradient and gradient tape of tensorflow is not converging.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15fx7dh/how_can_i_make_my_vectorized_ppo_implementation/",
          "author": null,
          "description": "Here is my vectorized PPO implementation, that I wrote (with a lot of help from this community). These are my results on the Acrobot-v1 environment.\n The way I computed the reward for my vectorized implementation was that I added all the rewards across all environments. An ideal Acrobot agent should receive a reward of 0.\n Please let me know if I am missing any information or if any clarification is required. I skipped a part, which was suggested by the community a few months ago - updating the gradients using minibatches. The reason I skipped it is that, I don't understand how this works and anyway Acrobot should be an easy environment to learn.\n https://preview.redd.it/0vs9ur585mfb1.png?width=622&format=png&auto=webp&s=ebc007a9f797bd0b97b805d010dbd097c0be8906\n Also, I keep getting this error at the end of my code. But I haven't bothered fixing it as it doesn't seem to affect my algorithm - \n Exception ignored in: <function VectorEnv.__del__ at 0x0000023BBF6F2710> Traceback (most recent call last): File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\gym\\vector\\vector_env.py\", line 139, in __del__ File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\gym\\vector\\vector_env.py\", line 121, in close File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\gym\\vector\\async_vector_env.py\", line 327, in close_extras AttributeError: 'NoneType' object has no attribute 'TimeoutError' \n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15fx7dh/how_can_i_make_my_vectorized_ppo_implementation/",
          "publishedOn": "2023-08-02T03:11:04.000Z",
          "wordCount": 2631,
          "title": "How can I make my vectorized PPO implementation learn better?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15fqco8/what_do_simulations_mean_in_the_context_of_the/",
          "author": null,
          "description": "Can someone please help me with this question? Please let me know if any clarification is needed. Thanks so much!\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15fqco8/what_do_simulations_mean_in_the_context_of_the/",
          "publishedOn": "2023-08-01T22:04:53.000Z",
          "wordCount": 2470,
          "title": "What do simulations mean in the context of the AlphaGoZero paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15fos7v/drone_for_research/",
          "author": null,
          "description": "I'm currently working on a research project that involves using deep reinforcement learning with drones. I'm looking for recommendations on drones that would be suitable for this type of research. I am looking for something of the shelf.\n    submitted by    /u/anointedninja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15fos7v/drone_for_research/",
          "publishedOn": "2023-08-01T21:05:03.000Z",
          "wordCount": 2480,
          "title": "Drone for Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15f3rmc/making_a_reinforcement_learning_codein_python/",
          "author": null,
          "description": "So i want to make a bot that can play a game with only the visual data and no other fancy stuff. I did manage to get all the data i need (i hope) using a code that uses open-cv to get data in real time\n Example:Player: ['Green', 439.9180603027344, 461.7232666015625, 13.700743675231934]\n Enemy Data {0: [473.99951171875, 420.5301513671875, 'Green', 20.159990310668945]}\n Box: {0: [720, 605, 'Green_box'], 1: [957, 311, 'Green_box'], 2: [432, 268, 'Red_box'], 3: [1004, 399, 'Blue_box']} \n can anyone suggest a way to make one.\n Rules:\n - You can only move in the direction of mouse.\n -You can dash in direction of mouse by LMB.\n -You can collect boxes to get HP and change colors.\n -Red color kills Blue kills Green Kills Red.\n -There is a fixed screen.\n -You lose 25% of total HP when you dash.\n -You lose 50% of HP when you bump into players (of color that kills or there HP is > than you. \n ​\n Visualization of Data.\n    submitted by    /u/SIJ_Gamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15f3rmc/making_a_reinforcement_learning_codein_python/",
          "publishedOn": "2023-08-01T05:59:46.000Z",
          "wordCount": 2605,
          "title": "Making a reinforcement learning code(in python) that can play a game with visual data only.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15eqfi0/reinforcement_learning_an_introduction_2nd/",
          "author": null,
          "description": "Greetings!\n I'm going through the initial equations that define most of the theoretical framework for the specialization. One curious thing I noticed with equations 3.5 and 3.6 is that they use the conditional distribution p(s′,r∣s,a) without including any priors. I'm talking about priors because, unless I'm missing something huge, the definition of the expected value for the reward (for both 3.5 and 3.6) should use the joint distribution for all 4 dimensions (next state, reward, current state, action). From that joint distribution, we can factorize it to show p(s′,r∣s,a). For example, one factorization that seems to make sense for this kind of model is\n p(s′,r,s,a) = p(s′,r∣s,a) ⋅ p(s) ⋅ p(a)\n which would turn, for example, equation 3.5 into\n r(s,a) = ∑​ ∑ ​r ⋅ p(s′,r∣s,a) ⋅ p(s) ⋅ p(a) (Note: the two sums are for \"r\" and \"s' \". I wrote like that because I don't know write it in Latex or similar...)\n What am I missing? Is it because s and a are given as parameters of the function r(s,a) meaning that p(s) = p(a) = 1? If the factorization above is the right one for those equations, is this the only factorization used in the entire book?\n Thanks in advance!\n    submitted by    /u/SupBiebi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15eqfi0/reinforcement_learning_an_introduction_2nd/",
          "publishedOn": "2023-07-31T20:02:59.000Z",
          "wordCount": 2658,
          "title": "[Reinforcement Learning: an Introduction (2nd edition)] Why not the joint distribution for equations 3.5 and 3.6?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15em4ah/discussion_comprehensive_learning_resources_that/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15em4ah/discussion_comprehensive_learning_resources_that/",
          "publishedOn": "2023-07-31T17:18:12.000Z",
          "wordCount": 2507,
          "title": "[Discussion] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ekx4r/what_are_some_big_action_space_marl_stochastic/",
          "author": null,
          "description": "Are there big action space stochastic games that are implemented in OpenSpiel or equivalent? I played around Markov soccer game a lot but it's solvable with tabular methods and I was looking for games with at least more than 500 actions both players can take as a testbed for more complicated action spaces?\n    submitted by    /u/Potential_Biscotti14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ekx4r/what_are_some_big_action_space_marl_stochastic/",
          "publishedOn": "2023-07-31T16:30:58.000Z",
          "wordCount": 2506,
          "title": "What are some big action space MARL stochastic games implemented in OpenSpiel or equivalent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ehg0p/optimal_bidding_strategy_in_power_market_using/",
          "author": null,
          "description": "Hello everyone! I'm trying to use reinforcement learning to solve a problem in the power market. The problem is about finding the best strategy for bidding on electricity for each hour of the day, considering both buying and selling options. Let's say we have a generator that can produce up to 800MW of electricity per day, and it can be charged up to 200MW per hour. After charging it for 4 hours continuously, it reaches its maximum capacity, and we can't charge more until we discharge some electricity. We have access to data from the past 5 years, including information about temperature, hydro, gas prices, and locational marginal price, which is important for determining profit. For instance, if we buy 10MW of electricity for a specific hour, our profit for that hour is 10 times the locational marginal price. The goal is to maximize profit at the end of the day while making sure that the total electricity bought and sold is equal for all days. This means we want to avoid wasting electricity. I initially tried using deep Q-learning, where the agent's state consists of data from the past 3 days, and the agent can take actions to buy or sell a certain amount of electricity for one hour. However, this approach doesn't seem to provide accurate results, and it works step by step, not considering the overall outcome for the whole day. So, I'm looking for help on how to build an agent capable of producing 24 bids for 24 hours, considering the constraints of the generator's capacity and ensuring no waste of electricity. I'm new to reinforcement learning, and I'm not sure how to approach this complex problem. Any guidance would be greatly appreciated!\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ehg0p/optimal_bidding_strategy_in_power_market_using/",
          "publishedOn": "2023-07-31T14:16:52.000Z",
          "wordCount": 2735,
          "title": "Optimal Bidding Strategy in Power Market using Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ea1cu/looking_for_old_tutorial_series/",
          "author": null,
          "description": "A few years ago, I remember reading a multipart series of articles/blog posts explaining how to develop agents for classical games. I believe the series started with tic-tac-toe and definitely progressed to gomoku, before maybe moving on to more complex games. I think there was more of a focus on algorithms (maybe MCTS) and concepts than code. It's a long shot, but does anyone recall this series or know if it's archived somewhere? seems like it might have been taken down.\n  \nWasn't on Medium. I think it might've been a personal website. I vaguely remember a green UI theme?\n  \n   submitted by    /u/nothymn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ea1cu/looking_for_old_tutorial_series/",
          "publishedOn": "2023-07-31T08:20:57.000Z",
          "wordCount": 2543,
          "title": "Looking for old tutorial series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dtfw7/sb3_for_pettingzoo_simple_spread/",
          "author": null,
          "description": "I previously posted a query about the same,\n but when i tried to implement A2C model training using SB3 on simple spread environment, I am not getting good and improved reward values, it's still highly negative and the model is performing rather randomly. \n env = ss.pettingzoo_env_to_vec_env_v1(env)\n env = ss.concat_vec_envs_v1(env, 4, num_cpus=2, base_class=\"stable_baselines3\")\n policy_kwargs = dict(net_arch = [128,128])\n model = A2C(\n MlpPolicy,\n env,\n verbose=1,\n learning_rate= 0.007,\n gamma = 0.95,\n ent_coef = 0.4,\n policy_kwargs= policy_kwargs,\n tensorboard_log= logdir\n )\n This is a fragment of code for reference. I tried to give more policy_kwargs like: share_features_extractor=False, or even tried to implement entirely custom policy, but the total average reward is still not going above -300.\n Also, the tensorboard plots are not showing ep_rew_mean plot, should I be passing some parameters for that?\n    submitted by    /u/bruhhhwhats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dtfw7/sb3_for_pettingzoo_simple_spread/",
          "publishedOn": "2023-07-30T19:03:11.000Z",
          "wordCount": 2585,
          "title": "SB3 for pettingzoo simple spread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dn9wz/how_is_the_policy_network_updated_in_alphago/",
          "author": null,
          "description": "In AlphaGo, a tree search is performed, and uses the policy network to reduce the breadth of it. At the leafs, if the states are not terminal, it uses the value network. And then \"backup\" the values to update the Q value at the initial state (if 70% of my rollouts won after performing action a_1, my Q value q(initial_state, a_1) should converge to 0.7 in my initial state). But I don't see where the policy network is updated?\n ​\n Here is a slide from David Silver, the first-author of AlphaGo, but it doesn't mention how to update the policy network.\n ​\n https://preview.redd.it/f29no3xe64fb1.png?width=1523&format=png&auto=webp&s=5adb312b1d0c033aa8ebb328197fd7d917724f06\n Have I missed something?\n Thankss!\n    submitted by    /u/Potential_Biscotti14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dn9wz/how_is_the_policy_network_updated_in_alphago/",
          "publishedOn": "2023-07-30T14:42:06.000Z",
          "wordCount": 2580,
          "title": "How is the policy network updated in AlphaGo?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dgonm/what_is_wrong_with_my_codedqn/",
          "author": null,
          "description": "recently, I've been trying to make a deep q network for solving 2x2 rubik's cubeBut after months, I stuck with same output for HUNDREDS of times :(\n I tried everything: change learning rate, change discout factor but no luck\n Here's update rule: newQ=currentQ+alpha*(newR+gamma*max(futureQValue.flatten().tolist())-currentQ)\n import torch import torch.nn as nn import torch.optim as optimizer import os from tqdm import tqdm class DQN(nn.Module): def __init__(self, stateSpaceSize,actionSpaceSize): super(DQN, self).__init__() self.fc1=nn.Linear(stateSpaceSize,128) self.fc2=nn.Linear(128,128) self.fc3=nn.Linear(128,128) self.fc4=nn.Linear(128,128) self.fc5=nn.Linear(128,128) self.fc6=nn.Linear(128,actionSpaceSize) def forward(self, x): self.relu=nn.ReLU() self.sigmold=nn.Sigmoid() self.LeakyReLU…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dgonm/what_is_wrong_with_my_codedqn/",
          "publishedOn": "2023-07-30T08:52:41.000Z",
          "wordCount": 2700,
          "title": "What is wrong with my code(DQN)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dgj4f/google_colab_with_reinforcment_learning/",
          "author": null,
          "description": "I need a google colab with reinforcement learning trained to detect anomalies in computer network traffic.\n    submitted by    /u/Unable_Blacksmith_81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dgj4f/google_colab_with_reinforcment_learning/",
          "publishedOn": "2023-07-30T08:42:47.000Z",
          "wordCount": 2488,
          "title": "Google Colab With Reinforcment learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15d6ln0/how_to_calculate_reward_for_target_intercept/",
          "author": null,
          "description": "Hi all. I (believe) I have a tensorflow NN set up to learn how to intercept a target moving in the x-y plane. Right now, the agent can choose to change its velocity by a small amount in any of the 3 directions (for the 3D case later), then the simulation updates the agents position. The state of the sim is the relative distance and velocity vectors between the target and the pursuer. I am confused how to set up a reward function, however. When I first set it up to be a reward of 1/R (R being the distance magnitude between the target and pursuer) to reward for shorter distances and give less reward for further distances as well as a very large reward when a collision occurred, it seemed like the rewards converged to a small value instead of getting larger. Any advice? I'd be willing to upload a github link as well if you wanted to look at the code\n    submitted by    /u/Happylightsocket  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15d6ln0/how_to_calculate_reward_for_target_intercept/",
          "publishedOn": "2023-07-29T23:48:12.000Z",
          "wordCount": 2638,
          "title": "How to calculate reward for target intercept problem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15d2di4/how_to_disable_auto_environment_reset_in_gymnasium/",
          "author": null,
          "description": "I am trying to implement my own version of ppo using gymnasium. Here is my code for rollout - \n  def rollout(): transitions = [] disc_reward_list = [] for i in range(ppo_batch): obs = torch.tensor(env.reset(), dtype=torch.float32) print(\"obs = \", obs.shape) all_rewards = [] iter = 0 done = False tot_rewards = 0 print(\"done = \", done) while True: act_probs = torch.distributions.Categorical(actor(obs.to(device)).squeeze()) print(\"act_probs = \", act_probs) # print(\"act_probs = \", actor(obs.to(device))) action = act_probs.sample().squeeze() action = action.cpu().detach().numpy() print(\"action shape = \", action.shape) next_state, reward, done, info = env.step(action) print(\"next_state shape = \", next_state.shape) print(\"reward shape = \", reward.shape) print(\"done shape = \", done) action = torch.tensor(action, dtype=torch.float32).to(device) all_rewards.append(reward) tot_rewards += reward iter += 1 transitions.append((obs.cpu().detach().numpy(), action.cpu().detach().numpy(), act_probs.log_prob(action).cpu().detach().numpy())) obs = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0) print(\"Reward = \", tot_rewards) eps_rew = 0 eps_rew_list = [] for reward in reversed(all_rewards): eps_rew = eps_rew*gamma + reward eps_rew_list.append(eps_rew) for rtgs in reversed(eps_rew_list): disc_reward_list.append(rtgs) \n My issue is that in my while loop - The environment autoresets after the `done` variable becomes `True`\n For instance, if I have `8` environments running in parallel `env=gym.vector.make('CartPole-v1', num_envs=8)` and print out the done shape, I might get - `[False False False False False True False False]`. I want that environment where `done=True` to stop and not reset. I believe that's how PPO is supposed to work. \n I am a bit of a beginner with this stuff. Please let me know if something I said is not clear.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15d2di4/how_to_disable_auto_environment_reset_in_gymnasium/",
          "publishedOn": "2023-07-29T20:42:47.000Z",
          "wordCount": 2708,
          "title": "How to disable auto environment reset in `Gymnasium`",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15d0p33/rt2_visionlanguageaction_models_transfer_web/",
          "author": null,
          "description": "Paper: https://robotics-transformer2.github.io/assets/rt2.pdf \n Blog: https://robotics-transformer2.github.io/ \n Blog: https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action \n Github ( RT-1 as of now) : https://github.com/google-research/robotics_transformer \n Abstract:\n  \nWe study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robot…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15d0p33/rt2_visionlanguageaction_models_transfer_web/",
          "publishedOn": "2023-07-29T19:31:08.000Z",
          "wordCount": 2812,
          "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control - Google DeepMind 2023 - Is able to perform multi-stage semantic reasoning and can interpret commands not present in the robot training data!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15cwesz/resources_to_understand_how_distributed/",
          "author": null,
          "description": "Can someone please point me to resources how distributed actor-critic algorithms work? My final goal is to understand distributed PPO works. I was following thisblog and a few other books but I'm unable to see the big picture nor am I able to understand the little details. \n The big picture - Why does distributed training help in online algorithms like PPO, Actor-Critic\n The code details - I figured out how to make multiprocessing work with gym. But how does one perform learning? Should I combine all the parallel environments and feed them to my neural network? I checked cleanrl but am getting a little confused.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15cwesz/resources_to_understand_how_distributed/",
          "publishedOn": "2023-07-29T16:26:50.000Z",
          "wordCount": 2580,
          "title": "Resources to understand how distributed Actor-Critic algorithms work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15crn85/how_can_i_create_multiple_environments_using_sb3/",
          "author": null,
          "description": "​\n ​\n I know that `SB3` provides various techniques to come up with vectorized environments. I want to limit myself to only using the vectorized environments and implement the RL algorithms from scratch. Would that be possible? My final objective is to learn how to play with RL hyperparameters on parallel environments in order to accelerate learning speeds. Currently, I am stuck on -\n import os import gymnasium as gym from stable_baselines3.common.vec_env import DummyVecEnv env = DummyVecEnv([lambda: gym.make(\"CartPole-v1\")]) obs = env.reset() done = False while not done: action = env.action_space.sample() next_obs, reward, done, info = env.step(action) obs = next_obs \n But I get the following error -\n ​\n Traceback (most recent call last): File \"D:\\q_learning\\dummy_envs.py\", line 9, in <module> next_obs, reward, done, info = env.step(action) File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\", line 197, in step return self.step_wait() File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\", line 59, in step_wait self.actions[env_idx] IndexError: invalid index to scalar variable. \n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15crn85/how_can_i_create_multiple_environments_using_sb3/",
          "publishedOn": "2023-07-29T12:54:47.000Z",
          "wordCount": 2620,
          "title": "How can I create multiple environments using `SB3` for manual use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15cas37/can_i_turn_off_the_target_network_in_sb3_by/",
          "author": null,
          "description": "I am using DQN through `SB3`. I would like to know if I can turn off the target network by setting `target_update_interval=-1`. I have some sample code over here -\n import gymnasium as gym from stable_baselines3 import DQN env = gym.make(\"MountainCar-v0\") model = DQN(\"MlpPolicy\", env, learning_rate = 4e-3, batch_size = 128, buffer_size = 10000, learning_starts = 1000, gamma = 0.98, train_freq = 16, gradient_steps = 8, exploration_fraction = 0, exploration_final_eps = 0, verbose = 1, target_update_interval=-1) model.learn(total_timesteps=120000, log_interval=4) \n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15cas37/can_i_turn_off_the_target_network_in_sb3_by/",
          "publishedOn": "2023-07-28T22:09:41.000Z",
          "wordCount": 2557,
          "title": "Can I turn off the target network in `SB3` by setting `target_update_interval=-1`?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15c5rel/training_model_using_sb3_on_pettingzoo_mpe/",
          "author": null,
          "description": "Hey,\n So I am training my baseline model using A2C on simple spread environment and no matter how I am changing and testing different parameters, when evaluating the total reward is highly negative.\n Any help on that would be appreciated.\n (I used the following tutorial as reference: https://pettingzoo.farama.org/tutorials/sb3/waterworld/)\n    submitted by    /u/bruhhhwhats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15c5rel/training_model_using_sb3_on_pettingzoo_mpe/",
          "publishedOn": "2023-07-28T18:50:27.000Z",
          "wordCount": 2520,
          "title": "Training model using SB3 on pettingzoo mpe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15bsvp4/recreating_results_of_drq_algorithm_please_help/",
          "author": null,
          "description": "For quite some time now I have been looking to recreate the results of the following paper on the Atari-100k benchmark. The paper poses two slightly different algorithms, one for SAC and one for DQN, however my work only focuses on the DQN version.\n IMAGE AUGMENTATION IS ALL YOU NEED: REGULARIZING DEEP REINFORCEMENT LEARNING FROM PIXELS \n https://openreview.net/pdf?id=GY6-6sTvGaf\n Despite this, my results have come up significantly short of the results claimed by the paper, so am looking for anyone to have a look and see anything I may have done wrong. All the code is on the following Github:\n https://github.com/VIPTankz/DeepLearningDrQ/tree/main\n There should also be everything you need to run the code if you wish to do so.\n The authors claim a human-normalised benchmark of 0.270, however my code only achieves 0.108. \n Any help would be much appreciated! \n Also worth noting: for evaluation, the authors use 125k steps, however I'm using the more recent standard of doing 100 episodes, irrespective of length. I highly doubt however that this causes the change in results.\n    submitted by    /u/VIPTankz123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15bsvp4/recreating_results_of_drq_algorithm_please_help/",
          "publishedOn": "2023-07-28T09:48:48.000Z",
          "wordCount": 2645,
          "title": "Recreating results of DrQ algorithm, please help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15brnhd/confused_about_frame_skipping_in_rl/",
          "author": null,
          "description": "How does frame-skipping result in better performance, versus taking an inference every frame for RL algorithms? Wouldn't taking an inference every second speed up training, as you would have more steps to train on in the same amount of time? The only downside I could think to no frame-skip is that steps become closer to each other, but I don't understand if that leads to any bad performance, and if it does, why.\n For context I have an environment where frames are relatively slow to generate (im only getting 1000 frames per minute from each env, and I can only run 6 instances on my pc at the same time). While off policy algorithms like SAC would probably be better suited to the task, I've been having really great success with PPO, and am reluctant to spend more time learning and fine-tuning SAC, as I've heard it can take as long as DDPG to converge. \n    submitted by    /u/IllCommunication6165  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15brnhd/confused_about_frame_skipping_in_rl/",
          "publishedOn": "2023-07-28T08:38:33.000Z",
          "wordCount": 2628,
          "title": "Confused about Frame Skipping in RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15b3h82/undergrad_projectthesis_on_rl/",
          "author": null,
          "description": "Hey everyone, \n I am an undergrad student with some modest knowledge of reinforcement learning techniques. I would like to start working on a project, but I really don't want it to be something obvious like the snake game (which btw I have already done) or something similar. I would like to spend some time on this project, and eventually build my undegrad thesis on top of it. It does not necessarily have to be something with a very practical application, some research would be fine too (keeping in mind that I am undegrad ofc).\n Do you have any ideas that you could share with me? I would be very grateful!\n    submitted by    /u/PizzaPartyBro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15b3h82/undergrad_projectthesis_on_rl/",
          "publishedOn": "2023-07-27T14:32:52.000Z",
          "wordCount": 2581,
          "title": "Undergrad project/thesis on RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15adde0/multiheads_dqn_with_prioritized_buffer_replay/",
          "author": null,
          "description": "Hello everyone,\n I really need your help guys.\n ​\n Is the code (uploaded on https://pastebin.com/LgB3hM47#google_vignette) for 2-heads DQN's training correct .\n Moreover, how can I modify the code below to be suitable for a 2-heads DQN with a prioritized buffer replay such that action is a 2-element list (Please see the image below).\n https://preview.redd.it/tlmyeydjoceb1.png?width=946&format=png&auto=webp&s=7366650421906b735bb7f2fce063322d183aac10\n Thank you in advance.\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15adde0/multiheads_dqn_with_prioritized_buffer_replay/",
          "publishedOn": "2023-07-26T18:17:42.000Z",
          "wordCount": 2529,
          "title": "Multi-heads DQN with prioritized buffer replay",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15a84ra/is_there_a_way_to_control_the_epsilon_decay_in/",
          "author": null,
          "description": "I am looking at the docs for DQN in SB3. I see the following hyper-parameters for controlling exploration - ` exploration_fraction `, ` exploration_initial_eps ` and ` exploration_final_eps `. But I don't think I can control the decaying of epsilon with them. Could someone please help with this issue?\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15a84ra/is_there_a_way_to_control_the_epsilon_decay_in/",
          "publishedOn": "2023-07-26T14:59:10.000Z",
          "wordCount": 2527,
          "title": "Is there a way to control the epsilon decay in Stable-Baselines3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15a3scs/presenting_simplepydash_realtime_data_plotting/",
          "author": null,
          "description": "Hey all! I'm excited to share SimplePyDash, a new tool I've developed for real-time data visualization. It's a versatile, browser-based dashboard designed to make data plotting as straightforward as possible!\n I thought about posting this here because it started as a project to monitor agents' behaviour in an OpenAI Gym environment. But it can be used for all sorts of things!\n Whether you're monitoring an OpenAI Gym environment, plotting your latest ML model's performance, or just need a flexible way to stream data, SimplePyDash has got you covered. With a clean, column-based layout and a set of intuitive default widgets, you can create your own custom dashboard in no time.\n Installing is as easy as running pip install simple-pydash, and there are several example scripts in the repo to help get you started.\n Check out the GitHub Repository for more details. If you like it, leave a start and feel free to share your feedback or questions. Thanks for checking it out!\n    submitted by    /u/vaaal88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15a3scs/presenting_simplepydash_realtime_data_plotting/",
          "publishedOn": "2023-07-26T11:56:44.000Z",
          "wordCount": 2636,
          "title": "Presenting SimplePyDash: Real-Time Data Plotting Made Simple!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/159hkzj/the_aipowered_totally_autonomous_future_of_war_is/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/159hkzj/the_aipowered_totally_autonomous_future_of_war_is/",
          "publishedOn": "2023-07-25T19:01:44.000Z",
          "wordCount": 2494,
          "title": "\"The AI-Powered, Totally Autonomous Future of War Is Here\" (use of DRL in Navy swarms R&D)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15985oq/selffictitious_play_and_qlearning_or_evolutionary/",
          "author": null,
          "description": "I'm looking to implement Fictitious Self-Play in a model-based game (imperfect information limited to simultaneous move game, however each player has a combinatorial number of actions they can perform). EDIT: I know self-fictitious play is not the only option to solve this type of game, but I wanted to give it a try to test how it would behave (especially since I sort of like the idea behind it).\n Because of this combinatorial number of actions, solving it with linear programming is just not possible (I'd have to compute for each sequence of pair of actions (a1, b1), (a2, b2), (a3, b3), ... (ak, bk), whether player a or player b won).\n But to compute a best response I might be able to use Q-learning in a RL setting right (by that I mean, fixed environment)? Because when we calculate a best…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15985oq/selffictitious_play_and_qlearning_or_evolutionary/",
          "publishedOn": "2023-07-25T13:11:38.000Z",
          "wordCount": 2918,
          "title": "Self-fictitious play and Q-learning or evolutionary algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1595zfn/rl_continuous_control_help_needed_ml_engineer/",
          "author": null,
          "description": "Hi, I can't find the rules for this subreddit so please lmk if asking any of this breaks them\n I have a pybullet simulation of a bipedal robot wrapped as a gym env. Currently trying to train a Rl ppo algo to control it to walk. But no luck. Having the issue that it's trying everything except walking. And it seems to prioritise getting the instant reward by kicking its leg forward then lunging forward and the episode ends. Instead of walking forward and getting more score. Anyone have any tips please? (Btw gamma = 0.99)\n ​\n Btw if anyone has experience with stuff like this I am looking to hire an engineer. Comment or dm me\n ​\n Btw I am aware this is a significant undertaking\n    submitted by    /u/Harryoc494  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1595zfn/rl_continuous_control_help_needed_ml_engineer/",
          "publishedOn": "2023-07-25T11:37:48.000Z",
          "wordCount": 2601,
          "title": "RL continuous control help needed. ML Engineer wanted also",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15955tq/skrl_version_100rc1_is_now_available_with/",
          "author": null,
          "description": "skrl version 1.0.0-rc.1 is now available.\n The main features of this release are:\n  \nJAX support\n Multi-agent training (the beginning).\n Comprehensive documentation with new structure and theme\n  \nVisit https://skrl.readthedocs.io/en/latest/ to get started!\n ​\n https://preview.redd.it/ms1q5s8ce3eb1.png?width=1459&format=png&auto=webp&s=4b1f0f27cae5df4dfac3e931eabcca2b924968d1\n https://preview.redd.it/385lhqdbe3eb1.png?width=1543&format=png&auto=webp&s=2cb5ef75f4c2720e8db5adbb6b3f35b7977e3b57\n ​\n    submitted by    /u/Toni-SM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15955tq/skrl_version_100rc1_is_now_available_with/",
          "publishedOn": "2023-07-25T10:59:23.000Z",
          "wordCount": 2509,
          "title": "skrl version 1.0.0-rc.1 is now available with multi-agent and JAX support!!!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1594ibf/zbrain_empowering_businesses_with_custom_chatgpt/",
          "author": null,
          "description": "Dear All,\n It is with great enthusiasm that I introduce you to ZBrain, a revolutionary GenAI platform that unlocks the ability to craft bespoke AI applications while prioritizing data privacy and security. ZBrain ushers in an era of remarkable possibilities for businesses seeking to harness the full potential of AI while ensuring their data remains safeguarded and confidential.\n ​\n What Sets ZBrain Apart:\n  \nZBrain Flow - Codeless Brilliance: Forget complex coding! ZBrain Flow's intuitive drag-and-drop interface seamlessly connects large language models and extraction tools, simplifying the creation of sophisticated business logic without the need for coding expertise.\n \nAI Risk Governance for Data Safety: At ZBrain, we deeply understand the significance of data security. Our AI Risk Governance identifies potential risks such as Financial, Medical, Privacy, Harmful Language, and more. Through prompt engineering, your data is fortified, and sensitive information is shielded.\n \nEffortless Integration and Continuous Advancements: With ZBrain, integration with over 80 data sources is a breeze, providing you the freedom to fine-tune models and deploy them effortlessly. Our reinforcement learning approach continually enriches results through valuable human feedback.\n \nConfidence in Deployment: Choose your deployment approach with assurance. Opt for ZBrain Cloud for added security or self-hosting on your private infrastructure, ensuring data confidentiality remains at the forefront.\n \n ​\n We are genuinely elated about the endless possibilities ZBrain offers businesses spanning various industries. By merging the prowess of AI with an unwavering commitment to data privacy, we wholeheartedly believe that ZBrain will elevate your business to unparalleled heights.\n Visit ZBrain at https://zbrain.ai/ and feel free to reach out with any inquiries or to share your experiences with ZBrain.\n    submitted by    /u/StewartBJasper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1594ibf/zbrain_empowering_businesses_with_custom_chatgpt/",
          "publishedOn": "2023-07-25T10:26:25.000Z",
          "wordCount": 2743,
          "title": "ZBrain: Empowering Businesses with Custom ChatGPT apps and Data Security",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/158dpmz/carracing_v2_enviroment/",
          "author": null,
          "description": "Hi! I am kind of new to Reinforcement Learning and Im trying to implement a PPO in CarRacing enviroment but I am failing to get the model to work. I have managed to get the model working with a DQN but with the PPO I can't seem to get the exploration right as it ends up either going forward all time or in circles. \n I have looked into my code for days, but haven't been able to find an error that would cause this. (Does not say much as I am kind of a newbie to RL). I would be grateful if someone could give me a hand. This is my source code: \n CarRacing Pastebin - Pastebin.com \n ​\n Btw I also tried without greyscaling and it did the same.\n    submitted by    /u/MammothWeekend5954  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/158dpmz/carracing_v2_enviroment/",
          "publishedOn": "2023-07-24T15:22:32.000Z",
          "wordCount": 2598,
          "title": "CarRacing V2 Enviroment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/157oyyq/evaluating_superhuman_models_with_consistency/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/157oyyq/evaluating_superhuman_models_with_consistency/",
          "publishedOn": "2023-07-23T20:14:14.000Z",
          "wordCount": 2488,
          "title": "\"Evaluating Superhuman Models with Consistency Checks\", Fluri et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/157bhqk/looking_to_get_into_rl_already_working_in_cv/",
          "author": null,
          "description": "I'm in my final year of undergrad and previously have some experience with image segmentation, object detection,etc. RL is something I feel like I want to get into, but I want to understand how I can get started and what it actually involves. Also, if there's any way I can apply my new knowledge to the domain of 3D vision like SLAM or 3D reconstructed images.\n    submitted by    /u/PRAY_J  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/157bhqk/looking_to_get_into_rl_already_working_in_cv/",
          "publishedOn": "2023-07-23T10:37:08.000Z",
          "wordCount": 2542,
          "title": "Looking to get into RL, already working in CV.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1575arz/2d_drone_rl/",
          "author": null,
          "description": "Long time lurker on the sub and just finished my first semi-decent experiment with DRL so I thought I’d share it here. \n I’ve been wanting to experiment with RL and drones for a while now, ever since seeing John Buffers Autodrone project where they train a drone using the genetic algorithm. \n Finally got a basic implementation working using SAC a few days ago, and have made the environment open source as well in case others wanted to try it out.\n Project Link: https://github.com/Yyassin/senza\n    submitted by    /u/vanishedoblivion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1575arz/2d_drone_rl/",
          "publishedOn": "2023-07-23T04:51:23.000Z",
          "wordCount": 2553,
          "title": "2D Drone RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/156us2b/using_stable_baseline3_for_multi_agent_env/",
          "author": null,
          "description": "Hey,\n I am trying to use sb3 with a pettingzoo mpe environment and trying to implement parameter sharing for simple spread. Any help on how I would train a model for this multi agent environment would be appreciated, thanks.\n    submitted by    /u/bruhhhwhats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/156us2b/using_stable_baseline3_for_multi_agent_env/",
          "publishedOn": "2023-07-22T20:45:02.000Z",
          "wordCount": 2513,
          "title": "Using stable baseline3 for multi agent env",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com/",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=62917",
          "author": "Bill Schmarzo",
          "description": "My journey continues as I integrate a GenAI tool (Bing AI) with my Thinking Like a Data Scientist (TLADS) methodology. In part 1 of this series, I used Bing AI to validate, augment, and enhance the first three steps in the TLADS methodology (Figure 1): And the results yielded a much deeper understanding of the… Read More »Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part II\nThe post Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part II appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/integrating-genai-into-thinking-like-a-data-scientist-methodology-part-ii/",
          "publishedOn": "2023-08-20T17:56:07.000Z",
          "wordCount": 7007,
          "title": "Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part II",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Slide1-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62899",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 15 August 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-15-august-2023/",
          "publishedOn": "2023-08-15T18:58:21.000Z",
          "wordCount": 5928,
          "title": "DSC Weekly 15 August 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62891",
          "author": "Jane Marsh",
          "description": "A net-zero office space produces emissions equal to or less than the amount it removes from the atmosphere. Options for achieving that goal include using renewable energy and reducing waste. Data-driven actions can help decision-makers reach their net-zero goals. Identify unnecessary energy usage An office can become more emissions-intensive than people realize if they don’t… Read More »Data-driven solutions to creating a net-zero office space\nThe post Data-driven solutions to creating a net-zero office space appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-driven-solutions-to-creating-a-net-zero-office-space/",
          "publishedOn": "2023-08-15T18:03:09.000Z",
          "wordCount": 5844,
          "title": "Data-driven solutions to creating a net-zero office space",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/israel-andrade-YI_9SivVt_s-unsplash.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62572",
          "author": "Shanthababu Pandian",
          "description": "Introduction Dear Data Engineers, this article is a very interesting topic. Let me give some flashback; a few years ago, someone in the discussion coined the new word how ACID and BASE properties of DATA. Suddenly drop silence in the room. Everyone started staring at each other faces, few of them started saying H2SO4, HCL,… Read More »Understand the ACID and BASE in modern data engineering\nThe post Understand the ACID and BASE in modern data engineering appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understand-the-acid-and-base-in-modern-data-engineering/",
          "publishedOn": "2023-08-15T18:01:30.000Z",
          "wordCount": 7164,
          "title": "Understand the ACID and BASE in modern data engineering",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_53651938-1024x768.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62831",
          "author": "John Lee",
          "description": "Innovation is increasingly driven by data. As technology advances and alters human behavior, industries collect a growing quantity of information. This data is valuable once we are able to extract actionable, meaningful insights from it – insights that can accelerate better outcomes while remaining equitable and inclusive of the populations we serve, allowing us to… Read More »AI-driven predictive analytics for revenue forecasting in healthcare\nThe post AI-driven predictive analytics for revenue forecasting in healthcare appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-driven-predictive-analytics-for-revenue-forecasting-in-healthcare/",
          "publishedOn": "2023-08-14T15:43:49.000Z",
          "wordCount": 6342,
          "title": "AI-driven predictive analytics for revenue forecasting in healthcare",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/hand-medical-glove-pointing-virtual-screen-medical-technology.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62881",
          "author": "Ovais Naseem",
          "description": "In the logistics and transportation industry, carrier connectivity has long been challenging, often riddled with inefficiencies and communication barriers. Innovative tools and platforms are revolutionizing how carriers connect with shippers and other stakeholders, fostering real-time collaboration and transparency.  This new era of carrier connectivity enhances the flow of information and redefines how the industry operates.… Read More »A new era of carrier connectivity: How technology is bridging the gap\nThe post A new era of carrier connectivity: How technology is bridging the gap appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-new-era-of-carrier-connectivity-how-technology-is-bridging-the-gap/",
          "publishedOn": "2023-08-14T15:41:07.000Z",
          "wordCount": 6612,
          "title": "A new era of carrier connectivity: How technology is bridging the gap",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_382940021.62b9ce4762e71.webp"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62879",
          "author": "Ovais Naseem",
          "description": "Big Data Management has become a pivotal part of modern business, influencing decisions, shaping strategies, and offering unparalleled insights. With the exponential growth of data from myriad sources, managing it effectively is more critical than ever. However, big data’s sheer volume, variety, and velocity present a unique set of challenges. These challenges range from integration… Read More »Challenges and solutions in Big Data management\nThe post Challenges and solutions in Big Data management appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/challenges-and-solutions-in-big-data-management/",
          "publishedOn": "2023-08-11T18:05:29.000Z",
          "wordCount": 6177,
          "title": "Challenges and solutions in Big Data management",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/challenges_of_big_data.webp"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62858",
          "author": "Rudrendu Kumar Paul",
          "description": "Source: ArabianBusiness Takeaways Artificial Intelligence (AI) continues to evolve at a rapid pace, with groundbreaking strides in generative capabilities playing a critical role in defining this ever-evolving landscape. One such transformative leap is the advent of Program-Aided Language models (PAL), an innovative solution that revolutionizes how Language Learning Models (LLMs) function. This article delves into… Read More »Pushing boundaries with Generative AI: How Program-aided Language model (PAL) enhances Large Language Models (LLMs) for superior AI performance\nThe post Pushing boundaries with Generative AI: How Program-aided Language model (PAL) enhances Large Language Models (LLMs) for superior AI performance appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/pushing-boundaries-with-generative-ai-how-program-aided-language-model-pal-enhances-large-language-models-llms-for-superior-ai-performance/",
          "publishedOn": "2023-08-11T13:55:00.000Z",
          "wordCount": 6452,
          "title": "Pushing boundaries with Generative AI: How Program-aided Language model (PAL) enhances Large Language Models (LLMs) for superior AI performance",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/image-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62847",
          "author": "Noami Woods",
          "description": "Learn about the challenges of data privacy and security, and the potential of smart technologies in creating efficient, livable urban environments.\nThe post Understanding the future of smart cities through data science appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understanding-the-future-of-smart-cities-through-data-science/",
          "publishedOn": "2023-08-10T18:03:42.000Z",
          "wordCount": 6070,
          "title": "Understanding the future of smart cities through data science",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Future-Cities.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62815",
          "author": "ajitjaokar",
          "description": "Background In the previous part of this blog, we explored the limitations of GPT-4. In this post, we will explore if open source models can overcome the limitations of black box models. Specifically, we will consider the use of LLama2 in this scenario.  The llama 2 paper from Meta is very comprehensive.  Llama 2, is… Read More »Generative AI megatrends: implications of GPT-4 drift and open source models – part two\nThe post Generative AI megatrends: implications of GPT-4 drift and open source models – part two appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-implications-of-gpt-4-drift-and-open-source-models-part-two/",
          "publishedOn": "2023-08-09T15:17:47.000Z",
          "wordCount": 5675,
          "title": "Generative AI megatrends: implications of GPT-4 drift and open source models – part two",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/india-gfcc7345eb_1280-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62840",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 8 August 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-8-august-2023/",
          "publishedOn": "2023-08-08T17:36:20.000Z",
          "wordCount": 6051,
          "title": "DSC Weekly 8 August 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62837",
          "author": "Roger Brown",
          "description": "Prompt engineers are emerging as key players in the development and optimization of AI models as artificial intelligence (AI) continues its evolution and becomes an integral part of various industries. As experts at crafting effective prompts, they have been instrumental in shaping the future of artificial intelligence through their ability to enable models to deliver… Read More »The emergence of prompt engineers: The next in-demand role in AI\nThe post The emergence of prompt engineers: The next in-demand role in AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-emergence-of-prompt-engineers-the-next-in-demand-role-in-ai/",
          "publishedOn": "2023-08-08T17:21:19.000Z",
          "wordCount": 6475,
          "title": "The emergence of prompt engineers: The next in-demand role in AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Prompt-Ai.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62809",
          "author": "Alan Morrison",
          "description": "Fair Data Forecast Interview with Gregor Stühler of Scoutbee Scoutbee’s CEO and founder, Gregor Stühler, who has a background in computer science and  electrical engineering, first learned about the challenges of procurement and supply base management as a project engineer for a multinational medical device company. Scoutbee’s focus on solving supply base problems through hybrid… Read More »Scaling Supply Base Data and Reuse with Knowledge Graphs and LLMs\nThe post Scaling Supply Base Data and Reuse with Knowledge Graphs and LLMs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/scaling-supply-base-data-and-reuse-with-knowledge-graphs-and-llms/",
          "publishedOn": "2023-08-07T16:19:35.000Z",
          "wordCount": 5734,
          "title": "Scaling Supply Base Data and Reuse with Knowledge Graphs and LLMs",
          "enclosure": {
            "url": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Gregor-Stuhler-of-Scoutbee-Mixed.mp3",
            "length": "21965958",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/container-ship-7383545_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62819",
          "author": "Bill Schmarzo",
          "description": "It’s incredible how many organizations utilize Generative AI (GenAI) and Large Language Models (LLMs) to enhance their information assembly, integration, and application abilities. These GenAI technologies have been applied in various areas, from drafting legal documents and resolving service issues to coding software applications and (er, um) writing blog posts. The potential uses of GenAI… Read More »Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part I\nThe post Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part I appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/integrating-genai-into-thinking-like-a-data-scientist-methodology-part-i/",
          "publishedOn": "2023-08-06T12:16:23.000Z",
          "wordCount": 6836,
          "title": "Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part I",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Slide1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62798",
          "author": "John Lee",
          "description": "AI has revolutionized software development. AI has transformed software testing and debugging by automating mundane tasks and solving complex problems. Manual testing no longer requires hours and resources. AI has revolutionized testing, code quality, and development time. This article explores AI’s profound impact on software testing and debugging, including its benefits, risks, and how it… Read More »AI’s transformative role in software testing and debugging\nThe post AI’s transformative role in software testing and debugging appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ais-transformative-role-in-software-testing-and-debugging/",
          "publishedOn": "2023-08-04T15:12:47.000Z",
          "wordCount": 6976,
          "title": "AI’s transformative role in software testing and debugging",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AI-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62813",
          "author": "ajitjaokar",
          "description": "In this two part discussion, we will discuss two related generative AI megatrends Backgroumd A recent paper How Is ChatGPT’s Behavior Changing over Time? from Stanford University and UC Berkeley claims that the performance of GPT-4 has drifted over time. To make this claim, specific tasks were evaluated (ex: accuracy of maths) and the results… Read More »Generative AI megatrends: implications of GPT-4 drift and open source models – part one\nThe post Generative AI megatrends: implications of GPT-4 drift and open source models – part one appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-implications-of-gpt-4-drift-and-open-source-models-part-one/",
          "publishedOn": "2023-08-04T14:50:00.000Z",
          "wordCount": 5738,
          "title": "Generative AI megatrends: implications of GPT-4 drift and open source models – part one",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/india-gfcc7345eb_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62800",
          "author": "Aileen Scott",
          "description": "Introduction Data Science is a vast field that incorporates several processes. From problem definition to data collection and data cleaning to data visualization, a lot of things are included in the entire data science project development process. Data Scientists are especially responsible for these tasks. They are expert professionals who are well-versed with various data… Read More »How can Data Scientists use ChatGPT for developing Machine Learning Models?\nThe post How can Data Scientists use ChatGPT for developing Machine Learning Models? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-can-data-scientists-use-chatgpt-for-developing-machine-learning-models/",
          "publishedOn": "2023-08-03T20:27:09.000Z",
          "wordCount": 6046,
          "title": "How can Data Scientists use ChatGPT for developing Machine Learning Models?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/ChatGPT-for-developing-machine-learning-models.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?post_type=vimeo-video&p=62796",
          "author": "Ben Cole",
          "description": "The convergence of Oracle Cloud Infrastructure (OCI) and Hitachi Application Reliability Centers (HARC) to magnify outcomes for customers. Tech giants Oracle and Hitachi Vantara are marching together to magnify cloud outcomes. Join us for the Oracle and Hitachi Vantara virtual event, where we discuss how businesses can get the most out of OCI and HARC.… Read More »DSC Webinar Series: OCI & HARC: Modernizing Workloads in the Oracle Cloud\nThe post DSC Webinar Series: OCI & HARC: Modernizing Workloads in the Oracle Cloud appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-webinar-series-oci-harc-modernizing-workloads-in-the-oracle-cloud/",
          "publishedOn": "2023-08-02T20:02:15.000Z",
          "wordCount": 5355,
          "title": "DSC Webinar Series: OCI & HARC: Modernizing Workloads in the Oracle Cloud",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/p62796-vimeo-thumbnail.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62790",
          "author": "Anas Baig",
          "description": "Artificial intelligence, or AI, has often been depicted as a terrifying force, from HAL 9000’s chilling declaration in “2001: A Space Odyssey” to the apocalyptic machine uprising in the Terminator movies. However, in reality, AI has become an integral part of our daily lives, with AI-powered Android devices in our pockets. Though we may not… Read More »Emerging AI statistics and trends to watch\nThe post Emerging AI statistics and trends to watch appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/emerging-ai-statistics-and-trends-to-watch/",
          "publishedOn": "2023-08-02T18:16:53.000Z",
          "wordCount": 6088,
          "title": "Emerging AI statistics and trends to watch",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/ai-trends.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62787",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 1 August 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-1-august-2023/",
          "publishedOn": "2023-08-01T18:42:05.000Z",
          "wordCount": 5775,
          "title": "DSC Weekly 1 August 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62782",
          "author": "Kirk Borne",
          "description": "Generative AI has been around for a long time. Some sources say that it appeared as early as the 1950’s. Other sources point to the first rudimentary chatbots that were introduced in the 1960’s. Whatever the true point of origin, we can all agree that those were small pebbles on the historical timeline compared to… Read More »I bet you think this article is about ChatGPT\nThe post I bet you think this article is about ChatGPT appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/i-bet-you-think-this-article-is-about-chatgpt/",
          "publishedOn": "2023-08-01T18:32:37.000Z",
          "wordCount": 6567,
          "title": "I bet you think this article is about ChatGPT",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_558672396_Editorial_Use_Only-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62764",
          "author": "Alan Morrison",
          "description": "If I could name one reason why business will face at least one more AI winter, it’s the lack of nuance in most business AI discussions. The buzz about large language models (LLMs) has sucked much of the oxygen out of the air for complementary technologies. The truth is that LLMs are no more a… Read More »Data tribalism and the AI nuance deficit\nThe post Data tribalism and the AI nuance deficit appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-tribalism-and-the-ai-nuance-deficit/",
          "publishedOn": "2023-08-01T18:28:56.000Z",
          "wordCount": 6105,
          "title": "Data tribalism and the AI nuance deficit",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/argument-6080057_1280.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?post_type=vimeo-video&p=62778",
          "author": "Ben Cole",
          "description": "The post DSC Webinar Series: Influence Data-Driven Decisions Based On Your Communication Style appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-webinar-series-influence-data-driven-decisions-based-on-your-communication-style/",
          "publishedOn": "2023-08-01T18:00:27.000Z",
          "wordCount": 5211,
          "title": "DSC Webinar Series: Influence Data-Driven Decisions Based On Your Communication Style",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/p62778-vimeo-thumbnail.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62767",
          "author": "Vincent Granville",
          "description": "There are thousands of articles explaining the differences between data scientist and machine learning engineer. Data science gets broken down even further, with data analysts contrasted to researchers. Professionals skilled in all these domains are called unicorns and believed not to exist. Indeed, they may not work for companies, and ignored when applying for a… Read More »The Rise of the Dual Data Scientist / Machine Learning Engineer\nThe post The Rise of the Dual Data Scientist / Machine Learning Engineer appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-rise-of-the-dual-data-scientist-machine-learning-engineer/",
          "publishedOn": "2023-08-01T08:04:24.000Z",
          "wordCount": 6329,
          "title": "The Rise of the Dual Data Scientist / Machine Learning Engineer",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/sunrise2.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62737",
          "author": "Rayan Potter",
          "description": "Let’s image – with algorithms and a nerdy charm that could melt any data center, an ‘AI’ wearing lab coats and stethoscopes patrolling hospital hallways, tirelessly monitoring patients. The digital doctor will take the pulse of Mother Earth and reduce waste, cut energy consumption, and cut energy consumption! The artificial intelligence community is well aware… Read More »Doctor AI: Healing humans and mother earth hand in hand\nThe post Doctor AI: Healing humans and mother earth hand in hand appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/doctor-ai-healing-humans-and-mother-earth-hand-in-hand/",
          "publishedOn": "2023-07-31T14:43:27.000Z",
          "wordCount": 5936,
          "title": "Doctor AI: Healing humans and mother earth hand in hand",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/earth-day-environment-eco-concept-top-view.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62732",
          "author": "ManojKumar847",
          "description": "In an age where efficiency is king, manufacturing firms are in a constant race to outshine their competition. Imagine if you could boost productivity, slash downtime, and cut costs all at once. Sounds like a dream, right? The good news is, this isn’t a fantasy. It’s achievable through Internet of Things (IoT) solutions. IoT solutions… Read More »Increase efficiency of manufacturing operations with IoT solutions\nThe post Increase efficiency of manufacturing operations with IoT solutions appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/increase-efficiency-of-manufacturing-operations-with-iot-solutions/",
          "publishedOn": "2023-07-31T14:41:58.000Z",
          "wordCount": 6301,
          "title": "Increase efficiency of manufacturing operations with IoT solutions",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/IoT-Solutions-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62725",
          "author": "Alan Morrison",
          "description": "“If you start by creating your data, then it’s like you are piling up some value or you’re creating some assets,” WordLift CEO Andrea Volpini told me in our recent FAIR Data Forecast interview. Volpini’s an advocate for adding structured data such as Schema.org to your content. That way, the content becomes logically connected and… Read More »Human-centered data networking with interpersonal knowledge  graphs\nThe post Human-centered data networking with interpersonal knowledge  graphs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/human-centered-data-networking-with-interpersonal-knowledge-graphs/",
          "publishedOn": "2023-07-31T14:39:56.000Z",
          "wordCount": 6277,
          "title": "Human-centered data networking with interpersonal knowledge  graphs",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/networks-3017398_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62745",
          "author": "Bill Schmarzo",
          "description": "One of the reasons that I moved back to Iowa last year was that I saw an opportunity to work with local educational institutions to create an AI Institute for organizations in middle America that either get overlooked in the AI conversation or are unsure what AI means to them. I wanted to reduce the… Read More »Introduction to “AI & Data Literacy: Empowering Citizens of Data Science”\nThe post Introduction to “AI & Data Literacy: Empowering Citizens of Data Science” appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/introduction-to-ai-data-literacy-empowering-citizens-of-data-science/",
          "publishedOn": "2023-07-29T19:22:55.000Z",
          "wordCount": 6522,
          "title": "Introduction to “AI & Data Literacy: Empowering Citizens of Data Science”",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Book-5-Intro-graphic.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62741",
          "author": "Roger Brown",
          "description": "In various fields, such as traffic management, law enforcement, and parking management, license plate recognition is a crucial application of computer vision that is used to analyze license plates. In this article, we will review the Chinese City Parking Dataset (CCPD), which is one of the most widely used computer vision datasets for tasks that… Read More »Understanding license plate recognition with the CCPD computer vision datasets\nThe post Understanding license plate recognition with the CCPD computer vision datasets appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understanding-license-plate-recognition-with-the-ccpd-computer-vision-datasets/",
          "publishedOn": "2023-07-28T18:04:00.000Z",
          "wordCount": 6077,
          "title": "Understanding license plate recognition with the CCPD computer vision datasets",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/ccpd-dataset-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62723",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 25 July 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-25-july-2023/",
          "publishedOn": "2023-07-25T19:53:37.000Z",
          "wordCount": 5973,
          "title": "DSC Weekly 25 July 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62696",
          "author": "Alan Morrison",
          "description": "Fair Data Forecast Interview with Andreas Volpini, CEO of WordLift Andreas Volpini believes every user who wants to build a personal brand online has to proactively curate their online presence first. He sees structured data (semantic entity and attribute metadata such as Schema.org) as key to building a cohesive, disambiguated personal presence online. Volpini has… Read More »The AI content + data mandate and personal branding\nThe post The AI content + data mandate and personal branding appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-ai-content-data-mandate-and-personal-branding/",
          "publishedOn": "2023-07-25T16:30:13.000Z",
          "wordCount": 11759,
          "title": "The AI content + data mandate and personal branding",
          "enclosure": {
            "url": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Andrea-Volpini-TFDF-Final.mp3",
            "length": "30793410",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_592088739-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62580",
          "author": "Erika Balla",
          "description": "Welcome to the exciting world of digital marketing! In this blog, we’ll delve into this thrilling frontier where optimization meets automation and Artificial Intelligence is at the center. No longer must manual labor and guesswork play an essential part in developing effective marketing strategies; with AI’s capabilities now at their disposal, marketers with digital presence… Read More »From automation to optimization: How AI is revolutionizing digital marketing campaigns\nThe post From automation to optimization: How AI is revolutionizing digital marketing campaigns appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/from-automation-to-optimization-how-ai-is-revolutionizing-digital-marketing-campaigns/",
          "publishedOn": "2023-07-25T16:26:10.000Z",
          "wordCount": 7324,
          "title": "From automation to optimization: How AI is revolutionizing digital marketing campaigns",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/internet-4463031_1280-942x600-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62707",
          "author": "ajitjaokar",
          "description": "In this blog, I will now focus on generative AI megatrends. By that, I mean, trends and underlying trends that could be big in the future – focusing on the technology of LLM but also the wider impact of LLMs on the economy and society. I will hence identify and follow some key trends –… Read More »Generative AI megatrends: Are companies using the excuse of AI to get rid of jobs?\nThe post Generative AI megatrends: Are companies using the excuse of AI to get rid of jobs? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-are-companies-using-the-excuse-of-ai-to-get-rid-of-jobs/",
          "publishedOn": "2023-07-24T16:30:00.000Z",
          "wordCount": 5694,
          "title": "Generative AI megatrends: Are companies using the excuse of AI to get rid of jobs?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Screenshot-2023-07-24-13.29.07.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62710",
          "author": "David Stephen",
          "description": "There is a recent paper in Synthese, Qualia share their correlates’ locations, where the abstract stated that “This paper presents the location-sharing argument, which concludes that qualia must share the locations of their physical correlates. The first premise is a consequence of relativity: If something shares a time with a physical event in all reference… Read More »Sentience: Consciousness is inessential for LLMs, AI\nThe post Sentience: Consciousness is inessential for LLMs, AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/sentience-consciousness-is-inessential-for-llms-ai/",
          "publishedOn": "2023-07-24T15:53:08.000Z",
          "wordCount": 5954,
          "title": "Sentience: Consciousness is inessential for LLMs, AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_562116144-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62690",
          "author": "Dan Allen",
          "description": "In October 2022, the White House Office of Science and Technology Policy published “The Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People”. This attention from our government given to what could be called an AI EQ (emotional quotient) is reminiscent of how-to parent or raise a child. This… Read More »AI is a child: How do we raise it?\nThe post AI is a child: How do we raise it? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-is-a-child-how-do-we-raise-it/",
          "publishedOn": "2023-07-24T15:39:00.000Z",
          "wordCount": 7466,
          "title": "AI is a child: How do we raise it?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_592515883.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62678",
          "author": "Prasanna Chitanand",
          "description": "With the introduction of ChatGPT-3 and DALL-E2, the majority of investors started showing interest in businesses building generative AI. Moreover, the fact is generative AI is not enough to reach the needs of the AI revolution. The success of predictive models is relevant to the science fiction future that the majority of the customers want… Read More »Innovations in predictive analytics: ML and generative AI\nThe post Innovations in predictive analytics: ML and generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/innovations-in-predictive-analytics-ml-and-generative-ai/",
          "publishedOn": "2023-07-24T14:10:13.000Z",
          "wordCount": 7372,
          "title": "Innovations in predictive analytics: ML and generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Innovations-in-Predictive-Analytics-ML-and-Generative-AI.jpg"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=203783",
          "author": "John",
          "description": "I’ve been thinking about things that were ruined by doing about 5% more than was necessary, like an actor whose plastic surgery looks plastic. Sometimes excellence requires pushing ourselves to do more than we want to do or more than we think we can do. But sometimes excellence requires restraint. Context is everything. A few […]\nDo 5% less first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/18/five-percent-less/",
          "publishedOn": "2023-08-18T11:26:47.000Z",
          "wordCount": 1458,
          "title": "Do 5% less",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=203635",
          "author": "John",
          "description": "Suppose you are in an air traffic control tower observing a plane moving in a straight line and you want to rotate your frame of reference to align with the plane. In the new frame the plane is moving along a coordinate axis with no component of motion in the other directions. You could do […]\nTracking and the Euler rotation theorem first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/17/tracking-euler/",
          "publishedOn": "2023-08-17T16:20:15.000Z",
          "wordCount": 1548,
          "title": "Tracking and the Euler rotation theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=203639",
          "author": "John",
          "description": "NLP software infers parts of speech by context. For example, the SpaCy NLP software can determine the parts of speech in the poem Jabberwocky even though the words are nonsense. More on this here. If you want to tell the parts of speech for isolated words, maybe software like SpaCy isn’t the right tool. You […]\nUsing WordNet to create a PAO system first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/17/wordnet-pao/",
          "publishedOn": "2023-08-17T16:05:29.000Z",
          "wordCount": 1876,
          "title": "Using WordNet to create a PAO system",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=203637",
          "author": "John",
          "description": "The Major mnemonic system is a method of converting numbers to words that can be more easily memorized. The basics of the system can be written on an index card, but there are practical details that are seldom written down. Presentations of the Major system can be misleading, intentionally or unintentionally, by implying that it […]\nMemorizing four-digit numbers first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/17/memorizing-four-digit-numbers/",
          "publishedOn": "2023-08-17T15:27:47.000Z",
          "wordCount": 1777,
          "title": "Memorizing four-digit numbers",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=203550",
          "author": "John",
          "description": "Let A be an n × n complex matrix. The numerical range of A is the image of x*Ax over the unit sphere. That is, the numerical range of A is the set W(A) in defined by W(A) = {x*Ax | x ∈ ℂn and ||x|| = 1} where x* is the conjugate transpose of […]\nThe numerical range ellipse first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/16/numerical-range-ellipse/",
          "publishedOn": "2023-08-17T01:46:13.000Z",
          "wordCount": 1651,
          "title": "The numerical range ellipse",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=203283",
          "author": "John",
          "description": "Ben Grimmer posted something yesterday on Twitter: A nice mathematical puzzle🧐 If you take a 4-norm ball and cut it carefully, you will find a two-norm ball. 3D printed visual evidence below. The puzzle: Why does this happen and how much more generally does it happen? (This question was first posed to me by Pablo […]\nRandom slices of a sphube first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/15/random-slices-of-a-sphube/",
          "publishedOn": "2023-08-15T10:56:49.000Z",
          "wordCount": 1678,
          "title": "Random slices of a sphube",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=203244",
          "author": "John",
          "description": "Are there more twin stars or twin primes? If the twin prime conjecture is true, there are an infinite number of twin primes, and that would settle the question. We don’t know whether there are infinitely many twin primes, and it’s a little challenging to find any results on how many twin primes we’re sure […]\nTwin stars and twin primes first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/14/twin-stars-and-twin-primes/",
          "publishedOn": "2023-08-15T02:28:25.000Z",
          "wordCount": 1571,
          "title": "Twin stars and twin primes",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202896",
          "author": "John",
          "description": "Evenly placing points on a sphere is a difficult problem. It’s impossible in general, and so you distribute the points as evenly as you can. The results vary according to how you measure how evenly the points are spread. However, there is a fast and simple way to distribute points that may be good enough, […]\nSimple way to distribute points on a sphere first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/12/fibonacci-lattice/",
          "publishedOn": "2023-08-12T17:10:13.000Z",
          "wordCount": 1464,
          "title": "Simple way to distribute points on a sphere",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202907",
          "author": "John",
          "description": "If you’ve only seen one definition of spherical coordinates, you may be shocked to discover that there are multiple conventions. In particular, mathematicians and geoscientists have different conventions. As Volker Michel put it in book on constructive approximation, Many mathematicians have faced weird jigsaw puzzles with misplaced continents after using a data set from a […]\nSpherical coordinate Rosetta Stone first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/12/spherical-coordinate-rosetta-stone/",
          "publishedOn": "2023-08-12T16:13:41.000Z",
          "wordCount": 2097,
          "title": "Spherical coordinate Rosetta Stone",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202611",
          "author": "John",
          "description": "A Traveling Salesman tour visits a list of destinations using the shortest path. There’s an obvious way to find the shortest path connecting N points: try all N! paths and see which one is shortest. Unfortunately, that might take a while. Texas has 254 counties, and so calculating a tour of Texas counties by brute […]\nCreating a Traveling Salesman Tour of Texas with Mathematica first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/10/texas-tour/",
          "publishedOn": "2023-08-10T14:47:07.000Z",
          "wordCount": 1659,
          "title": "Creating a Traveling Salesman Tour of Texas with Mathematica",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202532",
          "author": "John",
          "description": "A spherical cap is the portion of a sphere above some horizontal plane. For example, the polar ice cap of the earth is the region above some latitude. I mentioned in this post that the area above a latitude φ is where R is the earth’s radius. Latitude is the angle up from the equator. […]\nArea and volume of hypersphere cap first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/09/hypersphere-cap/",
          "publishedOn": "2023-08-10T01:44:58.000Z",
          "wordCount": 1566,
          "title": "Area and volume of hypersphere cap",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202525",
          "author": "John",
          "description": "In high dimensions, randomly chosen vectors are very likely nearly orthogonal. I’ll unpack this a little bit then demonstrate it by simulation. Then I’ll look at what happens when we restrict our attention to points with positive coordinates. *** The lengths of vectors don’t contribute to the angles between them, so we may as well […]\nRandom points in a high-dimensional orthant first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/09/random-points-hypersphere-orthant/",
          "publishedOn": "2023-08-10T00:31:56.000Z",
          "wordCount": 1782,
          "title": "Random points in a high-dimensional orthant",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202444",
          "author": "John",
          "description": "The previous post looked at cosine similarity for embeddings of words in vector spaces. Word embeddings like word2vec map words into high-dimensional vector spaces in such a way that related words correspond to vectors that are roughly parallel. Ideally the more similar the words, the smaller the angle between their corresponding vectors. The cosine similarity […]\nCosine similarity does not satisfy the triangle inequality first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/09/cosine-similarity-not-a-metric/",
          "publishedOn": "2023-08-09T15:15:38.000Z",
          "wordCount": 1882,
          "title": "Cosine similarity does not satisfy the triangle inequality",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202355",
          "author": "John",
          "description": "Natural language processing represents words as high-dimensional vectors, on the order of 100 dimensions. For example, the glove-wiki-gigaword-50 set of word vectors contains 50-dimensional vectors, and the the glove-wiki-gigaword-200 set of word vectors contains 200-dimensional vectors. The intent is to represent words in such a way that the angle between vectors is related to similarity […]\nAngles between words first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/08/angles-between-words/",
          "publishedOn": "2023-08-09T00:56:00.000Z",
          "wordCount": 2030,
          "title": "Angles between words",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202307",
          "author": "John",
          "description": "This post will discuss two scripting languages, but that’s not what the post is really about. It’s really about expressiveness and (or versus) productivity. *** I was excited to discover the awk programming language sometime in college because I had not used a scripting language before. Compared to C, awk was high-level luxury. Then a […]\nProductive constraints first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/08/productive-constraints/",
          "publishedOn": "2023-08-08T18:14:06.000Z",
          "wordCount": 1891,
          "title": "Productive constraints",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202282",
          "author": "John",
          "description": "A Möbius transformation is a function of the form where ad – bc = 1. We usually think of z as a complex number, but it doesn’t have to be. We could define Möbius transformations in any context where we can multiply, add, and divide, i.e. over any field. In particular, we could work over […]\nMöbius transformations over a finite field first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/08/finite-mobius/",
          "publishedOn": "2023-08-08T14:01:26.000Z",
          "wordCount": 1862,
          "title": "Möbius transformations over a finite field",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202146",
          "author": "John",
          "description": "A common idiom in command line processing of text files is ... | sort | uniq | ... Some process produces lines of text. You want to pipe that text through sort to sort the lines in alphabetical order, then pass it to uniq to filter out all but the unique lines. The uniq utility […]\nSort and remove duplicates first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/07/sort-u/",
          "publishedOn": "2023-08-07T18:36:34.000Z",
          "wordCount": 1577,
          "title": "Sort and remove duplicates",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201882",
          "author": "John",
          "description": "The previous post looked at the swish function and related activation functions for deep neural networks designed to address the “dying ReLU problem.” Unlike many activation functions, the function f(x) is not monotone but has a minimum near x0 = -1.2784. The exact location of the minimum is where W is the Lambert W function, […]\nSwish function and a Swiss mathematician first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/06/swish-swiss/",
          "publishedOn": "2023-08-06T17:24:24.000Z",
          "wordCount": 1458,
          "title": "Swish function and a Swiss mathematician",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201867",
          "author": "John",
          "description": "Swish, mish, and serf are neural net activation functions. The names are fun to say, but more importantly the functions have been shown to improve neural network performance by solving the “dying ReLU problem.” Softplus can also be used as an activation function, but our interest in softplus here is as part of the definition […]\nSwish, mish, and serf first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/06/swish-mish-and-serf/",
          "publishedOn": "2023-08-06T16:50:23.000Z",
          "wordCount": 1955,
          "title": "Swish, mish, and serf",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201814",
          "author": "John",
          "description": "In principle you generate an RSA key by finding two large prime numbers, p and q, and computing n = pq. You could, for example, generate random numbers by rolling dice, then type the numbers into Mathematica to test each for primaility until you find a couple prime numbers of the right size. In practice […]\nGenerating and inspecting an RSA private key first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/05/rsa-private-key/",
          "publishedOn": "2023-08-05T21:06:15.000Z",
          "wordCount": 1689,
          "title": "Generating and inspecting an RSA private key",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201771",
          "author": "John",
          "description": "At its core, RSA encryption is modular exponentiation. That is, given a message m, the encrypted form of m is x = me mod n where e is a publicly known exponent and n is a product of two large primes. The number n is made public but only the holder of the private key […]\nRSA encryption in practice first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/05/rsa-oaep/",
          "publishedOn": "2023-08-05T15:22:01.000Z",
          "wordCount": 1610,
          "title": "RSA encryption in practice",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201750",
          "author": "John",
          "description": "A few days ago I wrote about using the CMU Pronouncing Dictionary to search for words that decode to certain numbers in the Major mnemonic system. You can find a brief description of the Major system in that post. As large as the CMU dictionary is, it did not contain words mapping to some three-digit […]\nCode to convert words to Major system numbers first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/05/word-to-number/",
          "publishedOn": "2023-08-05T13:48:11.000Z",
          "wordCount": 1911,
          "title": "Code to convert words to Major system numbers",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201632",
          "author": "John",
          "description": "The Allee effect is named after Warder Clyde Allee who added a term to the famous logistic equation. His added term is highlighted in blue. Here N is the population of a species over time, r is the intrinsic rate of increase, K is the carrying capacity, and A is the critical point. If you […]\nSoftware and the Allee effect first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/04/allee-effect/",
          "publishedOn": "2023-08-04T16:58:25.000Z",
          "wordCount": 1602,
          "title": "Software and the Allee effect",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201621",
          "author": "John",
          "description": "“That’s a solved problem. So nobody knows how to solve it anymore.” Once a problem is deemed “solved” interest in the problem plummets. “Solved” problems may not be fully solved, but sufficiently solved that the problem is no longer fashionable. Practical issues remain, but interest moves elsewhere. The software written for the problem slowly decays. […]\nSolved problems becoming unsolved first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/04/solved-problems/",
          "publishedOn": "2023-08-04T15:34:46.000Z",
          "wordCount": 1381,
          "title": "Solved problems becoming unsolved",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201618",
          "author": "John",
          "description": "There’s an old saying “The cobbler’s son has no shoes.” It’s generally taken to mean that we can neglect to do for ourselves something we do for other people. I’ve been writing a few scripts for my personal use, things I’ve long intended to do but only recently got around to doing. I said something […]\nThe cobbler’s son first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/04/the-cobblers-son/",
          "publishedOn": "2023-08-04T14:35:10.000Z",
          "wordCount": 1437,
          "title": "The cobbler’s son",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201466",
          "author": "John",
          "description": "I was looking back at Jeroen Janssen’s book Data Science at the Command Line and his dseq utility caught my eye. This utility prints out a sequence of dates relative to the current date. I’ve needed this and didn’t know it. Suppose you have a CSV file and you need to add a column of […]\nDate sequence from the command line first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/03/date-sequence/",
          "publishedOn": "2023-08-03T13:17:20.000Z",
          "wordCount": 1905,
          "title": "Date sequence from the command line",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201073",
          "author": "John",
          "description": "An up-down permutation of an ordered set is a permutation such that as you move from left to right the permutation alternates up and down. For example 1, 5, 3, 4, 2 is an up-down permutation of 1, 2, 3, 4, 5 because 1 < 5 > 3 < 4 > 2. Up-down permutations are […]\nUp-down permutations first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/31/alternating-permutations/",
          "publishedOn": "2023-07-31T23:03:24.000Z",
          "wordCount": 1490,
          "title": "Up-down permutations",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201040",
          "author": "John",
          "description": "Suppose you have data that for some reason has been summarized into bins of width h. You don’t have the original data, only the number of counts in each bin. You can’t exactly find the sample mean or sample variance of the data because you don’t actually have the data. But what’s the best you […]\nVariance of binned data first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/31/sheppard/",
          "publishedOn": "2023-07-31T16:25:32.000Z",
          "wordCount": 1597,
          "title": "Variance of binned data",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200864",
          "author": "John",
          "description": "A very crude way to estimate π would be to find the perimeter of squares inside and outside a unit circle. The outside square has sides of length 2, so 2π < 8. The inside square has sides of length 2/√2, so 8/√2 < 2π. This tells us π is between 2.82 and 4. Not […]\nAncient estimate of π and modern numerical analysis first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/30/archimedes-richardson/",
          "publishedOn": "2023-07-31T00:18:38.000Z",
          "wordCount": 1851,
          "title": "Ancient estimate of π and modern numerical analysis",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200719",
          "author": "John",
          "description": "ARPAbet is a phonetic spelling system developed by— you guessed it—ARPA, before it became DARPA. The ARPAbet system is less expressive than IPA, but much easier for English speakers to understand. Every sound is encoded as one or two English letters. So, for example, the sound denoted ʒ in IPA is ZH in ARPAbet. In […]\nARPAbet and the Major mnemonic system first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/29/arpabet-major/",
          "publishedOn": "2023-07-30T01:16:20.000Z",
          "wordCount": 1876,
          "title": "ARPAbet and the Major mnemonic system",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200647",
          "author": "John",
          "description": "A few days ago I wrote about Jaccard distance, a way of defining a distance between sets. The Ruzsa distance is similar, except it defines the distance between two subsets of an Abelian group. Subset difference Let A and B be two subsets of an Abelian (commutative) group G. Then the difference A − B […]\nRuzsa distance first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/29/ruzsa-distance/",
          "publishedOn": "2023-07-29T16:02:57.000Z",
          "wordCount": 1679,
          "title": "Ruzsa distance",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200444",
          "author": "John",
          "description": "A function f of a complex variable z = x + iy can be factored into real and imaginary parts: where x and y are real numbers, and u and v are real-valued functions of two real values. Suppose you are given u(x, y) and you want to find v(x, y). The function v is called […]\nFinding the imaginary part of an analytic function from the real part first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/28/harmonic-conjugate/",
          "publishedOn": "2023-07-28T15:18:10.000Z",
          "wordCount": 1584,
          "title": "Finding the imaginary part of an analytic function from the real part",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200310",
          "author": "John",
          "description": "It’s well known that the population of Japan has been decreasing for years, and so I was a little puzzled by a recent headline saying that Japan’s population has dropped in every one of its 47 prefectures. Although the national population is in decline, until now not all of the nation’s 47 prefectures dropped in […]\nEvery Japanese prefecture shrinking first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/27/japanese-population/",
          "publishedOn": "2023-07-27T16:21:46.000Z",
          "wordCount": 1520,
          "title": "Every Japanese prefecture shrinking",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200287",
          "author": "John",
          "description": "Named entity recognition (NER) is a task of natural language processing: pull out named things text. It sounds like trivial at first. Just create a giant list of named things and compare against that. But suppose, for example, University of Texas is on your list. If Texas is also on your list, do you report […]\nNamed entity recognition first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/27/ner/",
          "publishedOn": "2023-07-27T15:05:06.000Z",
          "wordCount": 1619,
          "title": "Named entity recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200061",
          "author": "John",
          "description": "Jaccard index is a way of measuring the similarity of sets. The Jaccard index, or Jaccard similarity coefficient, of two sets A and B is the number of elements in their intersection, A ∩ B, divided by the number of elements in their union, A ∪ B. Jaccard similarity is a robust way to compare […]\nJaccard index and jazz albums first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/26/jaccard-jazz/",
          "publishedOn": "2023-07-26T08:47:26.000Z",
          "wordCount": 1640,
          "title": "Jaccard index and jazz albums",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200007",
          "author": "John",
          "description": "It’s not fair to evaluate NLP software on a language it wasn’t designed to process, but I wanted to try it anyway. The models in the spaCy software library were trained on modern English text and not on Middle English. Nevertheless, spaCy does a pretty good job of parsing Chaucer’s Canterbury Tales, written over 600 […]\nTrying NLP on Middle English first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/25/nlp-chaucer/",
          "publishedOn": "2023-07-25T18:15:23.000Z",
          "wordCount": 1379,
          "title": "Trying NLP on Middle English",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199970",
          "author": "John",
          "description": "For a positive integer n, the nth harmonic number is defined to be the sum of the reciprocals of the first n positive integers: How might we extend this definition so that n does not have to be a positive integer? First approach One way to extend harmonic numbers is as follows. Start with the […]\nExtending harmonic numbers first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/25/extending-harmonic-numbers/",
          "publishedOn": "2023-07-25T14:58:51.000Z",
          "wordCount": 1494,
          "title": "Extending harmonic numbers",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199949",
          "author": "John",
          "description": "Very often when a number is large, and we don’t know or care exactly how large it is, we can model it as infinite. This may make no practical difference and can make calculations much easier. I give several examples of this in the article Infinite is easier than big. When you run across a […]\nA note on Zipf’s law first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/25/a-note-on-zipfs-law/",
          "publishedOn": "2023-07-25T11:18:26.000Z",
          "wordCount": 1936,
          "title": "A note on Zipf’s law",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199788",
          "author": "John",
          "description": "I recently evaluated two software applications designed to find PII (personally identifiable information) in free text using natural language processing. Both failed badly, passing over obvious examples of PII. By contrast, I also tried natural language processing software on a nonsensical poem, it the software did quite well. Doctor’s notes It occurred to me later […]\nNatural language processing and unnatural text first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/24/nlp/",
          "publishedOn": "2023-07-24T13:50:42.000Z",
          "wordCount": 1862,
          "title": "Natural language processing and unnatural text",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199672",
          "author": "John",
          "description": "I recently ran across a paper on typesetting rare Chinese characters. From the abstract: Written Chinese has tens of thousands of characters. But most available fonts contain only around 6 to 12 thousand common characters that can meet the needs of everyday users. However, in publications and information exchange in many professional fields, a number […]\nHow rare is it to encounter a rare word? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/23/rare-words/",
          "publishedOn": "2023-07-23T21:01:09.000Z",
          "wordCount": 1586,
          "title": "How rare is it to encounter a rare word?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198464",
          "author": "John",
          "description": "Machine learning models occasionally memorize training data. Under the right prompt, a model could return portions of the training data verbatim. If a large language model is trained on deidentified medical data, along with data that overlaps with the medical data, it could potentially leak details of a person’s medical history. I’m not saying that […]\nHow an LLM might leak medical data first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/23/ai-leak-medical-data/",
          "publishedOn": "2023-07-23T17:58:09.000Z",
          "wordCount": 1628,
          "title": "How an LLM might leak medical data",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}